{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tnc-br/ddf-isoscapes/blob/validation_pipeline/validation_pipeline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PHFjYvuU7f_D"
      },
      "source": [
        "# Validation Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DEBUG = False #@param {type:\"boolean\"}\n",
        "GDRIVE_BASE = \"/content/gdrive\" #@param\n",
        "\n",
        "ISOSCAPE_MEANS_FILENAME = \"xgb_means_oxygen_isoscape_ucd_42.tiff\" #@param\n",
        "ISOSCAPE_VARS_FILENAME = \"xgb_variances_oxygen_isoscape_ucd_42.tiff\" #@param\n",
        "# Used in unit tests (generated from Kriging)\n",
        "TEST_ISOSCAPE_FILENAME = \"uc_davis_d18O_cel_kriging_means_2.tiff\" #@param\n",
        "\n",
        "TEST_SET_FILENAME = '2023_06_23_Results_Google.csv' #@param\n",
        "# Columns of values to read ground truths from. Invalid values are 'truth'\n",
        "# and 'prediction'.\n",
        "MEAN_TRUTH_NAME = 'd18O_cel_mean' #@param\n",
        "VAR_TRUTH_NAME = 'd18O_cel_variance' #@param\n",
        "# Columns of values to write temporary predictions to (for RMSE calculation).\n",
        "# Invalid values are 'truth' and 'prediction'.\n",
        "MEAN_PREDICTED_NAME = 'd18O_predicted_mean' #@param\n",
        "VAR_PREDICTED_NAME = 'd18O_predicted_variance' #@param"
      ],
      "metadata": {
        "id": "8HWuJSu_5LyN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Access data stored on Google Drive\n",
        "if GDRIVE_BASE:\n",
        "    from google.colab import drive\n",
        "    drive.mount(GDRIVE_BASE)\n",
        "\n",
        "if DEBUG:\n",
        "    %pip install -Uqq ipdb\n",
        "    import ipdb\n",
        "    %pdb on"
      ],
      "metadata": {
        "id": "3JXHUfyWo0R5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import"
      ],
      "metadata": {
        "id": "ChXSNjEJn30d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "!if [ ! -d \"/content/ddf_common_stub\" ] ; then git clone -b test https://github.com/tnc-br/ddf_common_stub.git; fi\n",
        "sys.path.append(\"/content/ddf_common_stub/\")\n",
        "import ddfimport\n",
        "ddfimport.ddf_source_control_pane()\n",
        "# ddfimport.ddf_import_common()"
      ],
      "metadata": {
        "id": "rNaw-yntoBzK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import importlib\n",
        "import raster\n",
        "import hypothesis\n",
        "importlib.reload(raster)\n",
        "importlib.reload(hypothesis)"
      ],
      "metadata": {
        "id": "MXJvPG1EIwEM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Isoscape: Calculate RMSE"
      ],
      "metadata": {
        "id": "2e68ABg9jChp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "import pandas as pd\n",
        "import dataset"
      ],
      "metadata": {
        "id": "ye2sQhIn2sQ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Required to both import raster and read GDrive files\n",
        "raster.RASTER_BASE = \"/MyDrive/amazon_rainforest_files/amazon_rasters/\" #@param\n",
        "raster.SAMPLE_DATA_BASE = \"/MyDrive/amazon_rainforest_files/amazon_sample_data/\" #@param\n",
        "raster.TEST_DATA_BASE = \"/MyDrive/amazon_rainforest_files/amazon_test_data/\" #@param\n",
        "raster.ANIMATIONS_BASE = \"/MyDrive/amazon_rainforest_files/amazon_animations/\" #@param\n",
        "raster.GDRIVE_BASE = \"/content/gdrive\" #@param"
      ],
      "metadata": {
        "id": "EQ3snfmVEa-O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_rmse(df, means_isoscape, vars_isoscape, mean_true_name, var_true_name, mean_pred_name, var_pred_name):\n",
        "  '''\n",
        "  Calculates the mean, variance and overall (mean and variance) RMSE of df using\n",
        "  the provided columns mean_true_name, var_true_name, mean_pred_name, var_pred_name\n",
        "  can take any value except 'truth' and 'prediction'\n",
        "  '''\n",
        "  # Make sure names do not collide.\n",
        "  assert(\n",
        "      len([mean_true_name, var_true_name, mean_pred_name, var_pred_name, 'truth', 'prediction']) ==\n",
        "      len(set([mean_true_name, var_true_name, mean_pred_name, var_pred_name, 'truth', 'prediction'])))\n",
        "\n",
        "  df[mean_pred_name] = df.apply(lambda row:raster.get_data_at_coords(means_isoscape, row['long'],row['lat'],-1), axis=1)\n",
        "  df[var_pred_name] = df.apply(lambda row:raster.get_data_at_coords(vars_isoscape, row['long'],row['lat'],-1), axis=1)\n",
        "\n",
        "  predictions = list(df.apply(lambda row: [row[mean_pred_name], row[var_pred_name]], axis=1).values)\n",
        "  truths = list(df.apply(lambda row: [row[mean_true_name], row[var_true_name]], axis=1).values)\n",
        "\n",
        "  return (mean_squared_error(df[mean_true_name].values, df[mean_pred_name].values, squared=False),\n",
        "         mean_squared_error(df[var_true_name].values, df[var_pred_name].values, squared=False),\n",
        "         mean_squared_error(truths, predictions, squared=False))"
      ],
      "metadata": {
        "id": "3oT_Iy4A3sz5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pytest\n",
        "\n",
        "def test_calculate_rmse():\n",
        "  test_means_isoscape = raster.load_raster(raster.get_raster_path(TEST_ISOSCAPE_FILENAME), use_only_band_index=0)\n",
        "  test_vars_isoscape = raster.load_raster(raster.get_raster_path(TEST_ISOSCAPE_FILENAME), use_only_band_index=0)\n",
        "  bounds =  raster.get_extent(test_means_isoscape.gdal_dataset)\n",
        "  print(bounds)\n",
        "  df = pd.DataFrame({\n",
        "      'long': [-70, -68],\n",
        "      'lat': [-4, -3],\n",
        "      'd18O_cel_mean': [0, 5],\n",
        "      'd18O_cel_var': [1, 0.5]\n",
        "  })\n",
        "  mean_true_name = 'd18O_cel_mean'\n",
        "  var_true_name = 'd18O_cel_var'\n",
        "  mean_pred_name = 'd18O_cel_mean_pred'\n",
        "  var_pred_name = 'd18O_cel_var_pred'\n",
        "  truth_name = 'd18O_cel_truth'\n",
        "  pred_name = 'd18O_cel_pred'\n",
        "\n",
        "  mean_rmse, var_rmse, overall_rmse = calculate_rmse(\n",
        "      df, test_means_isoscape, test_vars_isoscape,\n",
        "      mean_true_name, var_true_name, mean_pred_name, var_pred_name)\n",
        "  print(mean_rmse, var_rmse, overall_rmse)\n",
        "\n",
        "  assert(mean_rmse == pytest.approx(22.221530876037058))\n",
        "  assert(var_rmse == pytest.approx(23.85633857749663))\n",
        "  assert(overall_rmse == pytest.approx(23.038934726766843))\n",
        "\n",
        "test_calculate_rmse()"
      ],
      "metadata": {
        "id": "I14J29TG9g3w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "means_isoscape = raster.load_raster(raster.get_raster_path(ISOSCAPE_MEANS_FILENAME), use_only_band_index=0)\n",
        "vars_isoscape = raster.load_raster(raster.get_raster_path(ISOSCAPE_VARS_FILENAME), use_only_band_index=0)"
      ],
      "metadata": {
        "id": "sg8rmx1dcm_n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eval_dataset = pd.read_csv(raster.get_sample_db_path(TEST_SET_FILENAME), index_col=0)\n",
        "eval_dataset.head()"
      ],
      "metadata": {
        "id": "zq1W3KchmBws"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mean_rmse, var_rmse, overall_rmse = calculate_rmse(eval_dataset, means_isoscape, vars_isoscape, MEAN_TRUTH_NAME, VAR_TRUTH_NAME, MEAN_PREDICTED_NAME, VAR_PREDICTED_NAME)"
      ],
      "metadata": {
        "id": "t0hRIUpr2tLd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"RMSE of Means:\", mean_rmse)\n",
        "print(\"RMSE of Vars:\", var_rmse)\n",
        "print(\"Overall RMSE:\", overall_rmse)"
      ],
      "metadata": {
        "id": "jZ3_B1bPJAIx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TODO: Fraud Detection Hypothesis Test"
      ],
      "metadata": {
        "id": "CMKleGCVidxg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Utility function for randomly sampling a point around a sample site"
      ],
      "metadata": {
        "id": "kzvM5y1kedvT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#verify if we need to change this coords_to_indices and get_data_at_coords on raster.py\n",
        "def coords_to_indices(bounds: raster.Bounds, x: float, y: float):\n",
        "  if x < bounds.minx or x > bounds.maxx or y < bounds.miny or y > bounds.maxy:\n",
        "    return None, None\n",
        "\n",
        "  lat_idx = bounds.raster_size_y - int(math.ceil((y - bounds.miny) / abs(bounds.pixel_size_y)))\n",
        "  lon_idx = int((x - bounds.minx) / abs(bounds.pixel_size_x))\n",
        "\n",
        "  return lat_idx, lon_idx\n",
        "\n",
        "def get_data_at_coords(dataset: raster.AmazonGeoTiff, x: float, y: float, month: int) -> float:\n",
        "  # x = longitude\n",
        "  # y = latitude\n",
        "  bounds = raster.get_extent(dataset.gdal_dataset)\n",
        "  x_idx, y_idx = coords_to_indices(bounds, x, y)\n",
        "  if not x_idx and not y_idx:\n",
        "    return None\n",
        "  if month == -1:\n",
        "    value = dataset.yearly_masked_image[x_idx, y_idx]\n",
        "  else:\n",
        "    value = dataset.masked_image[x_idx, y_idx, month]\n",
        "  if np.ma.is_masked(value):\n",
        "    raise ValueError(\"Coordinates are masked\")\n",
        "  else:\n",
        "    return value\n",
        "\n",
        "from geopy import distance\n",
        "import numpy as np\n",
        "import math\n",
        "import random\n",
        "import pytest\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def is_valid_point(lat: float, lon: float, reference_isocape: raster.AmazonGeoTiff):\n",
        "  return True if get_data_at_coords(reference_isocape, lon, lat, 0) else False\n",
        "\n",
        "# Pick a random point around (lat, lon) within max_distance_km. If edge_only is\n",
        "# true, only pick points exactly max_distance_km away from (lat, lon).\n",
        "def random_nearby_point(lat, lon, max_distance_km, edge_only=False):\n",
        "  # Pick a random angle pointing outward from the origin.\n",
        "  # 0 == North, 90 == East, 180 == South, 270 == West\n",
        "  angle = 360 * random.random()\n",
        "\n",
        "  # sqrt() is required for an equal radial distribution, otherwise samples\n",
        "  # cluster around origin.\n",
        "  dist = max_distance_km if edge_only else max_distance_km * math.sqrt(random.random())\n",
        "\n",
        "  # WGS-84 is the most accurate ellipsoidal model of Earth, but we should double\n",
        "  # check to make sure this matches the model used by our sample collectors.\n",
        "  point = distance.geodesic(\n",
        "      ellipsoid='WGS-84', kilometers=dist).destination((lat, lon), bearing=angle)\n",
        "  return point.latitude, point.longitude\n",
        "\n",
        "# Given a list of real_points, returns true if (lat, lon) is within threshold\n",
        "# of any of those points.\n",
        "def is_nearby_real_point(lat, lon, real_points, threshold_km):\n",
        "  for point, _ in real_points:\n",
        "    if distance.geodesic((lat, lon), point).km < threshold_km:\n",
        "      return True\n",
        "  return False"
      ],
      "metadata": {
        "id": "IJlhcLEqyEQG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating fraudulent samples"
      ],
      "metadata": {
        "id": "GQ0jXl9dLayE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_fraudulent_samples(real_samples_data, mean_iso,element,max_trusted_radius,max_fraud_radius,min_fraud_radius):\n",
        "    '''\n",
        "    This function creates a dataset based on real samples adding a Fraud column, where True represents a real lat/lon and False represents a fraudulent lat/lon\n",
        "    Input:\n",
        "    - real_samples_data: real samples\n",
        "    - element: element e.g d18O_cel\n",
        "    - mean_iso: isoscape averages\n",
        "    - max_trusted_radius, In km, the maximum distance from a real point where its value is still considered legitimate.\n",
        "    - max_fraud_radius: In km, the maximum distance from a real point to randomly sample a fraudalent coordinate.\n",
        "    - min_fraud_radius: In km, the minimum distance from a real point to randomly sample a fraudalent coordinate.\n",
        "    Output:\n",
        "    - fake_data: pd.DataFrame with lat, long, isotope_value and fraudulent columns\n",
        "    '''\n",
        "\n",
        "    real_samples_data.dropna(subset=[element], how='all', inplace=True)\n",
        "\n",
        "    real_samples = real_samples_data.groupby(['lat','long'])[element]\n",
        "\n",
        "    count = 0\n",
        "    lab_samp = real_samples\n",
        "\n",
        "    if max_fraud_radius <= min_fraud_radius:\n",
        "      raise ValueError(\"max_fraud_radius {} <= min_fraud_radius {}\".format(\n",
        "          max_fraud_radius, min_fraud_radius))\n",
        "\n",
        "    fake_sample = pd.DataFrame(columns=['Code',\n",
        "            'lat',\n",
        "            'long',\n",
        "            element,\n",
        "            'fraud'])\n",
        "\n",
        "    # Max number of times to attempt to generate random coordinates.\n",
        "    MAX_RANDOM_SAMPLE_ATTEMPTS = 1000\n",
        "\n",
        "    for coord, lab_samp in real_samples:\n",
        "      if lab_samp.size <= 1:\n",
        "        continue\n",
        "\n",
        "      lat, lon, attempts = 0, 0, 0\n",
        "      while((not is_valid_point(lat, lon, mean_iso) or\n",
        "            is_nearby_real_point(lat, lon, real_samples, min_fraud_radius)) and\n",
        "            attempts < MAX_RANDOM_SAMPLE_ATTEMPTS):\n",
        "        lat, lon = random_nearby_point(coord[0], coord[1], max_fraud_radius)\n",
        "        new_row = {'Code': 'mad5000', 'lat': lat, 'long': lon,element: lab_samp.mean(),'fraud': True, }\n",
        "        #Hardcoded the code as mad5000 for fake coordinates\n",
        "        fake_sample.loc[len(fake_sample)] = new_row\n",
        "        attempts += 1\n",
        "\n",
        "    return(fake_sample)"
      ],
      "metadata": {
        "id": "ctVdFCnVuwnu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "real_samples_data = pd.read_csv(raster.get_sample_db_path(TEST_SET_FILENAME), encoding=\"ISO-8859-1\", sep=',')\n",
        "mean_iso = means_isoscape\n",
        "element = 'd18O_cel'\n",
        "\n",
        "\n",
        "fake_sample = create_fraudulent_samples(real_samples_data,mean_iso,element,0.1,30,5)"
      ],
      "metadata": {
        "id": "-CHsCJuw8BF4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Combine fraudulent and real samples in a Dataframe, identified by 'fraud' column"
      ],
      "metadata": {
        "id": "BvhYcAwvLKzC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "real = real_samples_data[['Code','lat','long',element]]\n",
        "\n",
        "real = real.assign(fraud=False)\n",
        "\n",
        "test_dataset = pd.concat([real, fake_sample], axis=1, join='outer')\n",
        "\n",
        "test_dataset = real.append(fake_sample, ignore_index=True)"
      ],
      "metadata": {
        "id": "5AZ-ReCQLlTO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calling t-test function that expects the Dataframe with the fraud column"
      ],
      "metadata": {
        "id": "JDyEfqLRompU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "isotope_column_name = 'd18O_cel'\n",
        "test_means_isoscape = means_isoscape\n",
        "test_vars_isoscape = vars_isoscape\n",
        "sample_size_per_location = 5\n",
        "p_value_target = 0.05\n",
        "\n",
        "accuracy, precision, recall = (\n",
        "  hypothesis.fraud_metrics(test_dataset,\n",
        "                isotope_column_name,\n",
        "                test_means_isoscape,\n",
        "                test_vars_isoscape,\n",
        "                sample_size_per_location,\n",
        "                p_value_target)\n",
        ")\n",
        "\n",
        "print(\"accuracy\", accuracy)\n",
        "print(\"precision\", precision)\n",
        "print(\"recall\", recall)\n"
      ],
      "metadata": {
        "id": "2lixfNCDotiP"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "4qCnFGsvx39s",
        "WlM3FIGXx6F2",
        "vJc7jGf533ag"
      ],
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}