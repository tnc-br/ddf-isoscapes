{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tnc-br/ddf-isoscapes/blob/validation_pipeline_rmse/validation_pipeline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PHFjYvuU7f_D"
      },
      "source": [
        "# Validation Pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4qCnFGsvx39s"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c8kW8zuCdZ6W"
      },
      "outputs": [],
      "source": [
        "from osgeo import gdal, gdal_array\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from dataclasses import dataclass\n",
        "import matplotlib.animation as animation\n",
        "from matplotlib import rc\n",
        "from typing import List\n",
        "from numpy.random import MT19937, RandomState, SeedSequence\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from io import StringIO\n",
        "import xgboost as xgb\n",
        "import os\n",
        "import math\n",
        "import glob\n",
        "\n",
        "rc('animation', html='jshtml')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K0tG92Yw1CYk"
      },
      "outputs": [],
      "source": [
        "# Raster directory. Contains:\n",
        "# iso_O_cellulose.tif: Isoscape of 18O from Precipitation; <-- MODELING TARGET\n",
        "# Iso_Oxi_Stack.tif: Isoscape of 18O from Precipitation; <-- Model input\n",
        "# R.rh_Stack.tif: Atmospheric Relative humidity <-- Model input\n",
        "# R.vpd_Stack.tif: Vapor Pressure Deficit - VPD <-- Model input\n",
        "# Temperature_Stack.tif: Atmospheric Temperature <-- Model input\n",
        "RASTER_BASE = \"/MyDrive/amazon_rainforest_files/amazon_rasters/\" #@param\n",
        "MODEL_BASE = \"/MyDrive/amazon_rainforest_files/amazon_isoscape_models/\" #@param\n",
        "SAMPLE_DATA_BASE = \"/MyDrive/amazon_rainforest_files/amazon_sample_data/\" #@param\n",
        "TEST_DATA_BASE = \"/MyDrive/amazon_rainforest_files/amazon_test_data/\" #@param\n",
        "BIOME_DATA_PATH = \"/MyDrive/amazon_rainforest_files/christian_files/lm_bioma_250.shp\" #@param\n",
        "GDRIVE_BASE = \"/content/drive\" #@param\n",
        "\n",
        "# How often should XGB log training metadata? 0 is the default, which indicates never.\n",
        "XGB_VERBOSITY_LEVEL = 0 #@param"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xtFtoKnsx83s"
      },
      "outputs": [],
      "source": [
        "@dataclass\n",
        "class AmazonGeoTiff:\n",
        "  \"\"\"Represents a geotiff from our dataset.\"\"\"\n",
        "  gdal_dataset: gdal.Dataset\n",
        "  image_value_array: np.ndarray # ndarray of floats\n",
        "  image_mask_array: np.ndarray # ndarray of uint8\n",
        "  masked_image: np.ma.masked_array\n",
        "  yearly_masked_image: np.ma.masked_array\n",
        "\n",
        "@dataclass\n",
        "class Bounds:\n",
        "  \"\"\"Represents geographic bounds and size information.\"\"\"\n",
        "  minx: float\n",
        "  maxx: float\n",
        "  miny: float\n",
        "  maxy: float\n",
        "  pixel_size_x: float\n",
        "  pixel_size_y: float\n",
        "  raster_size_x: float\n",
        "  raster_size_y: float\n",
        "\n",
        "  def to_matplotlib(self) -> List[float]:\n",
        "    return [self.minx, self.maxx, self.miny, self.maxy]\n",
        "\n",
        "@dataclass\n",
        "class PartitionedDataset:\n",
        "  train: pd.DataFrame\n",
        "  test: pd.DataFrame\n",
        "  validation: pd.DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AeGYKXlS33ag"
      },
      "outputs": [],
      "source": [
        "def get_raster_path(filename: str) -> str:\n",
        "  return f\"{GDRIVE_BASE}{RASTER_BASE}{filename}\"\n",
        "\n",
        "def get_model_path(filename: str) -> str:\n",
        "  return f\"{GDRIVE_BASE}{MODEL_BASE}{filename}\"\n",
        "\n",
        "def get_sample_db_path(filename: str) -> str:\n",
        "  return f\"{GDRIVE_BASE}{SAMPLE_DATA_BASE}{filename}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b89tGCn8ztnO"
      },
      "outputs": [],
      "source": [
        "def print_raster_info(raster):\n",
        "  dataset = raster\n",
        "  print(\"Driver: {}/{}\".format(dataset.GetDriver().ShortName,\n",
        "                              dataset.GetDriver().LongName))\n",
        "  print(\"Size is {} x {} x {}\".format(dataset.RasterXSize,\n",
        "                                      dataset.RasterYSize,\n",
        "                                      dataset.RasterCount))\n",
        "  print(\"Projection is {}\".format(dataset.GetProjection()))\n",
        "  geotransform = dataset.GetGeoTransform()\n",
        "  if geotransform:\n",
        "      print(\"Origin = ({}, {})\".format(geotransform[0], geotransform[3]))\n",
        "      print(\"Pixel Size = ({}, {})\".format(geotransform[1], geotransform[5]))\n",
        "\n",
        "  for band in range(dataset.RasterCount):\n",
        "    band = dataset.GetRasterBand(band+1)\n",
        "    #print(\"Band Type={}\".format(gdal.GetDataTypeName(band.DataType)))\n",
        "\n",
        "    min = band.GetMinimum()\n",
        "    max = band.GetMaximum()\n",
        "    if not min or not max:\n",
        "        (min,max) = band.ComputeRasterMinMax(False)\n",
        "    #print(\"Min={:.3f}, Max={:.3f}\".format(min,max))\n",
        "\n",
        "    if band.GetOverviewCount() > 0:\n",
        "        print(\"Band has {} overviews\".format(band.GetOverviewCount()))\n",
        "\n",
        "    if band.GetRasterColorTable():\n",
        "        print(\"Band has a color table with {} entries\".format(band.GetRasterColorTable().GetCount()))\n",
        "\n",
        "def load_raster(path: str, use_only_band_index: int = -1) -> AmazonGeoTiff:\n",
        "  \"\"\"\n",
        "  TODO: Refactor (is_single_band, etc., should be a better design)\n",
        "  --> Find a way to simplify this logic. Maybe it needs to be more abstract.\n",
        "  \"\"\"\n",
        "  dataset = gdal.Open(path, gdal.GA_ReadOnly)\n",
        "  print_raster_info(dataset)\n",
        "  image_datatype = dataset.GetRasterBand(1).DataType\n",
        "  mask_datatype = dataset.GetRasterBand(1).GetMaskBand().DataType\n",
        "  image = np.zeros((dataset.RasterYSize, dataset.RasterXSize, 12),\n",
        "                  dtype=gdal_array.GDALTypeCodeToNumericTypeCode(image_datatype))\n",
        "  mask = np.zeros((dataset.RasterYSize, dataset.RasterXSize, 12),\n",
        "                  dtype=gdal_array.GDALTypeCodeToNumericTypeCode(image_datatype))\n",
        "\n",
        "  if use_only_band_index == -1:\n",
        "    if dataset.RasterCount != 12 and dataset.RasterCount != 1:\n",
        "      raise ValueError(f\"Expected 12 raster bands (one for each month) or one annual average, but found {dataset.RasterCount}\")\n",
        "    if dataset.RasterCount == 1:\n",
        "      use_only_band_index = 0\n",
        "\n",
        "  is_single_band = use_only_band_index != -1\n",
        "\n",
        "  if is_single_band and use_only_band_index >= dataset.RasterCount:\n",
        "    raise IndexError(f\"Specified raster band index {use_only_band_index}\"\n",
        "    f\" but there are only {dataset.RasterCount} rasters\")\n",
        "\n",
        "  for band_index in range(12):\n",
        "    band = dataset.GetRasterBand(use_only_band_index+1 if is_single_band else band_index+1)\n",
        "    image[:, :, band_index] = band.ReadAsArray()\n",
        "    mask[:, :, band_index] = band.GetMaskBand().ReadAsArray()\n",
        "  masked_image = np.ma.masked_where(mask == 0, image)\n",
        "  yearly_masked_image = masked_image.mean(axis=2)\n",
        "\n",
        "  return AmazonGeoTiff(dataset, image, mask, masked_image, yearly_masked_image)\n",
        "\n",
        "def get_extent(dataset):\n",
        "  geoTransform = dataset.GetGeoTransform()\n",
        "  minx = geoTransform[0]\n",
        "  miny = geoTransform[3]\n",
        "  maxx = minx + geoTransform[1] * dataset.RasterXSize\n",
        "  maxy = miny + geoTransform[5] * dataset.RasterYSize\n",
        "  return Bounds(minx, maxx, miny, maxy, geoTransform[1], geoTransform[5], dataset.RasterXSize, dataset.RasterYSize)\n",
        "\n",
        "def plot_band(geotiff: AmazonGeoTiff, month_index, figsize=None):\n",
        "  if figsize:\n",
        "    plt.figure(figsize=figsize)\n",
        "  im = plt.imshow(geotiff.masked_image[:,:,month_index], extent=get_extent(geotiff.gdal_dataset).to_matplotlib(), interpolation='none')\n",
        "  plt.colorbar(im)\n",
        "\n",
        "def animate(geotiff: AmazonGeoTiff, nSeconds, fps):\n",
        "  fig = plt.figure( figsize=(8,8) )\n",
        "\n",
        "  months = []\n",
        "  labels = []\n",
        "  for m in range(12):\n",
        "    months.append(geotiff.masked_image[:,:,m])\n",
        "    labels.append(f\"Month: {m+1}\")\n",
        "  a = months[0]\n",
        "  extent = get_extent(geotiff.gdal_dataset).to_matplotlib()\n",
        "  ax = fig.add_subplot()\n",
        "  im = fig.axes[0].imshow(a, interpolation='none', aspect='auto', extent = extent)\n",
        "  txt = fig.text(0.3,0,\"\", fontsize=24)\n",
        "  fig.colorbar(im)\n",
        "\n",
        "  def animate_func(i):\n",
        "    if i % fps == 0:\n",
        "      print( '.', end ='' )\n",
        "\n",
        "    im.set_array(months[i])\n",
        "    txt.set_text(labels[i])\n",
        "    return [im, txt]\n",
        "\n",
        "  anim = animation.FuncAnimation(\n",
        "                                fig,\n",
        "                                animate_func,\n",
        "                                frames = nSeconds * fps,\n",
        "                                interval = 1000 / fps, # in ms\n",
        "                                )\n",
        "  plt.close()\n",
        "\n",
        "  return anim\n",
        "\n",
        "def save_numpy_to_geotiff(bounds: Bounds, prediction: np.ma.MaskedArray, path: str):\n",
        "  \"\"\"Copy metadata from a base geotiff and write raster data + mask from `data`\"\"\"\n",
        "  driver = gdal.GetDriverByName(\"GTiff\")\n",
        "  metadata = driver.GetMetadata()\n",
        "  if metadata.get(gdal.DCAP_CREATE) != \"YES\":\n",
        "      raise RuntimeError(\"GTiff driver does not support required method Create().\")\n",
        "  if metadata.get(gdal.DCAP_CREATECOPY) != \"YES\":\n",
        "      raise RuntimeError(\"GTiff driver does not support required method CreateCopy().\")\n",
        "\n",
        "  dataset = driver.Create(path, bounds.raster_size_x, bounds.raster_size_y, prediction.shape[2], eType=gdal.GDT_Float64)\n",
        "  dataset.SetGeoTransform([bounds.minx, bounds.pixel_size_x, 0, bounds.maxy, 0, bounds.pixel_size_y])\n",
        "  dataset.SetProjection('GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563,AUTHORITY[\"EPSG\",\"7030\"]],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0],UNIT[\"degree\",0.0174532925199433],AUTHORITY[\"EPSG\",\"4326\"]]')\n",
        "\n",
        "  #dataset = driver.CreateCopy(path, base.gdal_dataset, strict=0)\n",
        "  if len(prediction.shape) != 3 or prediction.shape[0] != bounds.raster_size_x or prediction.shape[1] != bounds.raster_size_y:\n",
        "    raise ValueError(\"Shape of prediction does not match base geotiff\")\n",
        "  #if prediction.shape[2] > base.gdal_dataset.RasterCount:\n",
        "  #  raise ValueError(f\"Expected fewer than {dataset.RasterCount} bands in prediction but found {prediction.shape[2]}\")\n",
        "\n",
        "  prediction_transformed = np.flip(np.transpose(prediction, axes=[1,0,2]), axis=0)\n",
        "  for band_index in range(dataset.RasterCount):\n",
        "    band = dataset.GetRasterBand(band_index+1)\n",
        "    if band.CreateMaskBand(0) == gdal.CE_Failure:\n",
        "      raise RuntimeError(\"Failed to create mask band\")\n",
        "    mask_band = band.GetMaskBand()\n",
        "    band.WriteArray(np.choose(prediction_transformed[:, :, band_index].mask, (prediction_transformed[:, :, band_index].data,np.array(band.GetNoDataValue()),)))\n",
        "    mask_band.WriteArray(np.logical_not(prediction_transformed[:, :, band_index].mask))\n",
        "\n",
        "def coords_to_indices(bounds: Bounds, x: float, y: float):\n",
        "  if x < bounds.minx or x > bounds.maxx or y < bounds.miny or y > bounds.maxy:\n",
        "    raise ValueError(\"Coordinates out of bounds\")\n",
        "\n",
        "  # X => lat, Y => lon\n",
        "  x_idx = bounds.raster_size_y - int(math.ceil((y - bounds.miny) / abs(bounds.pixel_size_y)))\n",
        "  y_idx = int((x - bounds.minx) / abs(bounds.pixel_size_x))\n",
        "\n",
        "  return x_idx, y_idx\n",
        "\n",
        "def test_coords_to_indices():\n",
        "  bounds = Bounds(50, 100, 50, 100, 1, 1, 50, 50)\n",
        "  x, y = coords_to_indices(bounds, 55, 55)\n",
        "  assert x == 45\n",
        "  assert y == 5\n",
        "\n",
        "  bounds = Bounds(-100, -50, -100, -50, 1, 1, 50, 50)\n",
        "  x, y = coords_to_indices(bounds, -55, -55)\n",
        "  assert x == 5\n",
        "  assert y == 45\n",
        "\n",
        "  bounds = Bounds(-10, 50, -10, 50, 1, 1, 60, 60)\n",
        "  x, y = coords_to_indices(bounds, -1, 13)\n",
        "  assert x == 37\n",
        "  assert y == 9\n",
        "\n",
        "  bounds = Bounds(minx=-73.97513931345594, maxx=-34.808472803053895, miny=-33.73347244751509, maxy=5.266527396029211, pixel_size_x=0.04166666650042771, pixel_size_y=-0.041666666499513144, raster_size_x=937, raster_size_y=941)\n",
        "  x, y = coords_to_indices(bounds, -67.14342073173958, -7.273271869467912e-05)\n",
        "  #print(x)\n",
        "  assert x == 131 # was: 132\n",
        "  assert y == 163\n",
        "\n",
        "test_coords_to_indices()\n",
        "\n",
        "def get_data_at_coords(dataset: AmazonGeoTiff, x: float, y: float, month: int) -> float:\n",
        "  # x = longitude\n",
        "  # y = latitude\n",
        "  bounds = get_extent(dataset.gdal_dataset)\n",
        "  x_idx, y_idx = coords_to_indices(bounds, x, y)\n",
        "  if month == -1:\n",
        "    value = dataset.yearly_masked_image[x_idx, y_idx]\n",
        "  else:\n",
        "    value = dataset.masked_image[x_idx, y_idx, month]\n",
        "  if np.ma.is_masked(value):\n",
        "    raise ValueError(\"Coordinates are masked\")\n",
        "  else:\n",
        "    return value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4CZHpf2v33ai"
      },
      "outputs": [],
      "source": [
        "# Access data stored on Google Drive\n",
        "if GDRIVE_BASE:\n",
        "    from google.colab import drive\n",
        "    drive.mount(GDRIVE_BASE)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Calculate RMSE"
      ],
      "metadata": {
        "id": "2e68ABg9jChp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MEANS_ISOSCAPE_FILENAME = \"uc_davis_d18O_cel_means_fixed_grouped.tiff\" #@param\n",
        "VARS_ISOSCAPE_FILENAME = \"uc_davis_d18O_cel_vars_fixed_grouped.tiff\" #@param\n",
        "\n",
        "TEST_SET_FILENAME = 'uc_davis_2023_08_12_test_fixed_grouped.csv' #@param\n",
        "MEAN_TRUTH_NAME = 'd18O_cel_mean'\n",
        "VAR_TRUTH_NAME = 'd18O_cel_variance'\n",
        "MEAN_PREDICTED_NAME = 'd18O_predicted_mean'\n",
        "VAR_PREDICTED_NAME = 'd18O_predicted_variance'\n",
        "TRUTH_NAME = 'truth'\n",
        "PREDICTION_NAME = 'prediction'"
      ],
      "metadata": {
        "id": "8HWuJSu_5LyN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "means_isoscape = load_raster(get_raster_path(MEANS_ISOSCAPE_FILENAME), use_only_band_index=0)"
      ],
      "metadata": {
        "id": "sg8rmx1dcm_n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vars_isoscape = load_raster(get_raster_path(VARS_ISOSCAPE_FILENAME), use_only_band_index=0)"
      ],
      "metadata": {
        "id": "K_crN7VclXaF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eval_dataset = pd.read_csv(get_sample_db_path(TEST_SET_FILENAME), index_col=0)\n",
        "eval_dataset.head()"
      ],
      "metadata": {
        "id": "zq1W3KchmBws"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error"
      ],
      "metadata": {
        "id": "ye2sQhIn2sQ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_rmse(df, mean_true_name, var_true_name, mean_pred_name, var_pred_name, truth_name, pred_name):\n",
        "  df[mean_pred_name] = eval_dataset.apply(lambda row:get_data_at_coords(means_isoscape, row['long'],row['lat'],-1), axis=1)\n",
        "  df[var_pred_name] = eval_dataset.apply(lambda row:get_data_at_coords(vars_isoscape, row['long'],row['lat'],-1), axis=1)\n",
        "\n",
        "  df[pred_name] = df.apply(lambda row: [row[mean_pred_name], row[var_pred_name]], axis=1)\n",
        "  df[truth_name] = eval_dataset.apply(lambda row: [row[mean_true_name], row[var_true_name]], axis=1)\n",
        "\n",
        "  y_pred = list(df[pred_name].values)\n",
        "  y_true = list(df[truth_name].values)\n",
        "\n",
        "  return mean_squared_error(y_true, y_pred, squared=False)"
      ],
      "metadata": {
        "id": "3oT_Iy4A3sz5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calculate_rmse(eval_dataset, MEAN_TRUTH_NAME, VAR_TRUTH_NAME, MEAN_PREDICTED_NAME, VAR_PREDICTED_NAME, TRUTH_NAME, PREDICTION_NAME)"
      ],
      "metadata": {
        "id": "t0hRIUpr2tLd"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "4qCnFGsvx39s",
        "WlM3FIGXx6F2",
        "vJc7jGf533ag"
      ],
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}