{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tnc-br/ddf-isoscapes/blob/new_kl/dnn/briso_d13C_ensemble.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Variational model\n",
        "\n",
        "Find the mean/variance of O18 ratios (as well as N15 and C13 in the future) at a particular lat/lon across Brazil. At the bottom of the colab, train and evaluate 4 different versions of the model with different data partitioning strategies."
      ],
      "metadata": {
        "id": "-0IfT3kGwgK6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "henIPlAPCb4i",
        "outputId": "e34b31e8-06c1-4e91-ab09-3f60fd483560",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from collections import defaultdict\n",
        "import math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import datetime\n",
        "import os\n",
        "from typing import List, Tuple, Dict\n",
        "from dataclasses import dataclass\n",
        "from joblib import dump\n",
        "\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, regularizers\n",
        "from matplotlib import pyplot as plt\n",
        "from tensorflow.python.ops import math_ops\n",
        "from sklearn.preprocessing import StandardScaler, Normalizer, MinMaxScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "\n",
        "#@title Debugging\n",
        "# See https://zohaib.me/debugging-in-google-collab-notebook/ for tips,\n",
        "# as well as docs for pdb and ipdb.\n",
        "DEBUG = False #@param {type:\"boolean\"}\n",
        "USE_LOCAL_DRIVE = False #@param {type:\"boolean\"}\n",
        "LOCAL_DIR = \"/usr/local/google/home/ruru/Downloads/amazon_sample_data-20230712T203059Z-001\" #@param\n",
        "GDRIVE_DIR = \"MyDrive/amazon_rainforest_files/\" #@param\n",
        "FP_ROOT = LOCAL_DIR\n",
        "\n",
        "MODEL_SAVE_LOCATION = \"MyDrive/amazon_rainforest_files/variational/model\" #@param\n",
        "\n",
        "def get_model_save_location(filename) -> str:\n",
        "  root = '' if USE_LOCAL_DRIVE else '/content/gdrive'\n",
        "  return os.path.join(root, MODEL_SAVE_LOCATION, filename)\n",
        "\n",
        "# Access data stored on Google Drive if not reading data locally.\n",
        "if not USE_LOCAL_DRIVE:\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/gdrive')\n",
        "  global FP_ROOT\n",
        "  FP_ROOT = os.path.join('/content/gdrive', GDRIVE_DIR)\n",
        "\n",
        "if DEBUG:\n",
        "    %pip install -Uqq ipdb\n",
        "    import ipdb\n",
        "    %pdb on"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "\n",
        "!if [ ! -d \"/content/ddf_common_stub\" ] ; then git clone -b test https://github.com/tnc-br/ddf_common_stub.git; fi\n",
        "sys.path.append(\"/content/ddf_common_stub/\")\n",
        "import ddfimport\n",
        "ddfimport.ddf_source_control_pane()\n",
        "\n"
      ],
      "metadata": {
        "id": "AXh86HFwXiax",
        "outputId": "c1666efa-90dc-46ee-d074-74d46cbb2b49",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 470,
          "referenced_widgets": [
            "70bfdc7ee2bd490181b70fd4abd2508f",
            "8d6e76aa1506472e9ac0025470e508c8",
            "ecad0b67a823441ea9e2bfaf1040014c",
            "a811ba449e4645eca6f055881e5d5ee4",
            "b41f3416523c4fdeb6715a3bd0800297",
            "8f4c97c8a317402e8cd87e2a9f68b110",
            "79d54b7b7d9544bc88b83876a9f90b76",
            "65e718a7efcf4110825afcc58175451b",
            "459ebaa22b5045d38717346cf92c50bd",
            "9effba8769064b20b43b0f8b71bbae53",
            "9a2f3f4e1bd84bb18e478c45f75aa1dc",
            "6ec745afa16e44d18c6267ee871875a9",
            "f8d09ea1a1b845128b6a2dc8f146ff87",
            "7c8783981c9c4d599c743f4accfd6e4b",
            "6da1e760f1c14114a3a8f19875afdd12",
            "0b9bbac4365f410dabb92987ee6f49e4",
            "919e5f838acf480f8c6a478cf434ddcd",
            "37e61ed537774c75abce882b8fb642cf",
            "5c3b3d66a2c549568086dc5b4520e375",
            "b136df15d48f4833a62f847901a2d306",
            "c4f3815be1f14075a159b6b76e98676e",
            "aaa5ed5f345948fc91619f49fabf3573",
            "7b212a12d61547978eb7ab925447fa59"
          ]
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'ddf_common_stub'...\n",
            "remote: Enumerating objects: 11, done.\u001b[K\n",
            "remote: Counting objects: 100% (11/11), done.\u001b[K\n",
            "remote: Compressing objects: 100% (11/11), done.\u001b[K\n",
            "remote: Total 11 (delta 4), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (11/11), 5.50 KiB | 5.50 MiB/s, done.\n",
            "Resolving deltas: 100% (4/4), done.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "interactive(children=(Text(value='', description='Email', placeholder='Enter email'), Text(value='', descripti…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "70bfdc7ee2bd490181b70fd4abd2508f"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import raster\n",
        "import importlib\n",
        "importlib.reload(raster)"
      ],
      "metadata": {
        "id": "0mUB0y0AXivp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40d2eb49-c850-476c-a004-4adfa80f7008"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<module 'raster' from '/content/gdrive/MyDrive/gen_isoscape/ddf_common/raster.py'>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GQrEv57zCb4q"
      },
      "source": [
        "# Data preparation\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_dataset(path: str, columns_to_keep: List[str], side_raster_input):\n",
        "  df = pd.read_csv(path, encoding=\"ISO-8859-1\", sep=',')\n",
        "  df = df[df['d18O_cel_variance'].notna()]\n",
        "  X = df\n",
        "  X = X.drop(df.columns.difference(columns_to_keep), axis=1)\n",
        "\n",
        "  for name, geotiff in side_raster_input.items():\n",
        "    X[name] = X.apply(lambda row: geotiff.value_at(row['long'], row['lat']), axis=1)\n",
        "    # The last two kriging columns need to remain last. Move new columns forward.\n",
        "    X.insert(len(X.columns)-3, name, X.pop(name))\n",
        "\n",
        "  Y = df[[\"d18O_cel_mean\", \"d18O_cel_variance\"]]\n",
        "  return X, Y"
      ],
      "metadata": {
        "id": "6XMee1aHfcik"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Standardization"
      ],
      "metadata": {
        "id": "DtkKhMOtb6cS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@dataclass\n",
        "class FeaturesToLabels:\n",
        "  def __init__(self, X: pd.DataFrame, Y: pd.DataFrame):\n",
        "    self.X = X\n",
        "    self.Y = Y\n",
        "\n",
        "  def as_tuple(self):\n",
        "    return (self.X, self.Y)\n",
        "\n",
        "\n",
        "def create_feature_scaler(X: pd.DataFrame,\n",
        "                          columns_to_passthrough,\n",
        "                          columns_to_scale,\n",
        "                          columns_to_standardize) -> ColumnTransformer:\n",
        "  columns_to_standardize = columns_to_standardize\n",
        "  feature_scaler = ColumnTransformer(\n",
        "      [(column+'_normalizer', MinMaxScaler(), [column]) for column in columns_to_scale] +\n",
        "      [(column+'_standardizer', StandardScaler(), [column]) for column in columns_to_standardize],\n",
        "      remainder='passthrough')\n",
        "  feature_scaler.fit(X)\n",
        "  print(feature_scaler)\n",
        "  return feature_scaler\n",
        "\n",
        "def create_label_scaler(Y: pd.DataFrame) -> ColumnTransformer:\n",
        "  label_scaler = ColumnTransformer([\n",
        "      ('mean_std_scaler', StandardScaler(), ['d18O_cel_mean']),\n",
        "      ('var_minmax_scaler', MinMaxScaler(), ['d18O_cel_variance'])],\n",
        "      remainder='passthrough')\n",
        "  label_scaler.fit(Y)\n",
        "  return label_scaler\n",
        "\n",
        "def scale(X: pd.DataFrame, feature_scaler):\n",
        "  # transform() outputs numpy arrays :(  need to convert back to DataFrame.\n",
        "  X_standardized = pd.DataFrame(feature_scaler.transform(X),\n",
        "                        index=X.index, columns=X.columns)\n",
        "  return X_standardized"
      ],
      "metadata": {
        "id": "XSDwdvMkb7w8"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Just a class organization, holds each scaled dataset and the scaler used.\n",
        "# Useful for unscaling predictions.\n",
        "@dataclass\n",
        "class ScaledPartitions():\n",
        "  def __init__(self,\n",
        "               feature_scaler: ColumnTransformer,\n",
        "               label_scaler: ColumnTransformer,\n",
        "               train: FeaturesToLabels, val: FeaturesToLabels,\n",
        "               test: FeaturesToLabels):\n",
        "    self.feature_scaler = feature_scaler\n",
        "    self.label_scaler = label_scaler\n",
        "    self.train = train\n",
        "    self.val = val\n",
        "    self.test = test\n",
        "\n",
        "\n",
        "def load_and_scale(config: Dict,\n",
        "                   columns_to_passthrough: List[str],\n",
        "                   columns_to_scale: List[str],\n",
        "                   columns_to_standardize: List[str]) -> ScaledPartitions:\n",
        "\n",
        "  geotiff_side_input = {\n",
        "      \"brisoscape_mean_ISORIX\" : raster.load_raster(raster.get_raster_path(\"brisoscape_mean_ISORIX.tif\")),\n",
        "      \"d13C_cel_mean\" : raster.load_raster(raster.get_raster_path(\"d13C_cel_map_BRAZIL_stack.tiff\"), use_only_band_index=0),\n",
        "      \"d13C_cel_var\" : raster.load_raster(raster.get_raster_path(\"d13C_cel_map_BRAZIL_stack.tiff\"), use_only_band_index=1)\n",
        "  }\n",
        "  columns_to_keep = columns_to_passthrough + columns_to_scale + columns_to_standardize\n",
        "  X_train, Y_train = load_dataset(config['TRAIN'], columns_to_keep, geotiff_side_input)\n",
        "  X_val, Y_val = load_dataset(config['VALIDATION'], columns_to_keep, geotiff_side_input)\n",
        "  X_test, Y_test = load_dataset(config['TEST'], columns_to_keep, geotiff_side_input)\n",
        "\n",
        "  # Fit the scaler:\n",
        "  feature_scaler = create_feature_scaler(\n",
        "      X_train,\n",
        "      columns_to_passthrough,\n",
        "      columns_to_scale,\n",
        "      columns_to_standardize)\n",
        "\n",
        "  # Apply the scaler:\n",
        "  label_scaler = create_label_scaler(Y_train)\n",
        "  train = FeaturesToLabels(scale(X_train, feature_scaler), Y_train)\n",
        "  val = FeaturesToLabels(scale(X_val, feature_scaler), Y_val)\n",
        "  test = FeaturesToLabels(scale(X_test, feature_scaler), Y_test)\n",
        "  return ScaledPartitions(feature_scaler, label_scaler, train, val, test)\n"
      ],
      "metadata": {
        "id": "_kf2e_fKon2P"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Definition\n",
        "\n"
      ],
      "metadata": {
        "id": "usGznR593LZc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The KL Loss function:"
      ],
      "metadata": {
        "id": "khK7C8WvU8ZR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sample_normal_distribution(\n",
        "    mean: tf.Tensor,\n",
        "    stdev: tf.Tensor,\n",
        "    n: int) -> tf.Tensor:\n",
        "    '''\n",
        "    Given a batch of normal distributions described by a mean and stdev in\n",
        "    a tf.Tensor, sample n elements from each distribution and return the mean\n",
        "    and standard deviation per sample.\n",
        "    '''\n",
        "    batch_size = tf.shape(mean)[0]\n",
        "\n",
        "    # Output tensor is (n, batch_size, 1)\n",
        "    sample_values = tfp.distributions.Normal(\n",
        "        loc=mean,\n",
        "        scale=stdev).sample(\n",
        "            sample_shape=n)\n",
        "    # Reshaped tensor will be (batch_size, n)\n",
        "    sample_values = tf.transpose(sample_values)\n",
        "    # Get the mean per sample in the batch.\n",
        "    sample_mean = tf.transpose(tf.math.reduce_mean(sample_values, 2))\n",
        "    sample_stdev = tf.transpose(tf.math.reduce_std(sample_values, 2))\n",
        "\n",
        "    return sample_mean, sample_stdev\n",
        "\n",
        "import tensorflow_probability as tfp\n",
        "\n",
        "# log(σ2/σ1) + ( σ1^2+(μ1−μ2)^2 ) / 2* σ^2   − 1/2\n",
        "def kl_divergence_helper(real, predicted, sample):\n",
        "    '''\n",
        "    real: tf.Tensor of the real mean and standard deviation of sample to compare\n",
        "    predicted: tf.Tensor of the predicted mean and standard deviation to compare\n",
        "    sample: Whether or not to sample the predicted distribution to get a new\n",
        "            mean and standard deviation.\n",
        "    '''\n",
        "    if real.shape != predicted.shape:\n",
        "      raise ValueError(\n",
        "          f\"real.shape {real.shape} != predicted.shape {predicted.shape}\")\n",
        "\n",
        "    real_value = tf.gather(real, [0], axis=1)\n",
        "    real_std = tf.math.sqrt(tf.gather(real, [1], axis=1))\n",
        "\n",
        "\n",
        "    predicted_value = tf.gather(predicted, [0], axis=1)\n",
        "    predicted_std = tf.math.sqrt(tf.gather(predicted, [1], axis=1))\n",
        "    # If true, sample from the distribution defined by the predicted mean and\n",
        "    # standard deviation to use for mean and stdev used in KL divergence loss.\n",
        "    if sample:\n",
        "      predicted_value, predicted_std = sample_normal_distribution(\n",
        "          mean=predicted_value, stdev=predicted_std, n=15)\n",
        "\n",
        "    kl_loss = -0.5 + tf.math.log(predicted_std/real_std) + \\\n",
        "     (tf.square(real_std) + tf.square(real_value - predicted_value))/ \\\n",
        "     (2*tf.square(predicted_std))\n",
        "\n",
        "    if tf.math.is_nan(tf.math.reduce_mean(kl_loss)):\n",
        "       tf.print(predicted)\n",
        "       sess = tf.compat.v1.Session()\n",
        "       sess.close()\n",
        "\n",
        "    return tf.math.reduce_mean(kl_loss)\n",
        "\n",
        "def kl_divergence(real, predicted):\n",
        "  return kl_divergence_helper(real, predicted, True)"
      ],
      "metadata": {
        "id": "urGjYNNnemX6"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test the loss function:"
      ],
      "metadata": {
        "id": "fJzBFWQVeqNE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model definition"
      ],
      "metadata": {
        "id": "8rI6qPRh7oO7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "\n",
        "def get_early_stopping_callback():\n",
        "  return EarlyStopping(monitor='val_loss', patience=1000, min_delta=0.001,\n",
        "                       verbose=1, restore_best_weights=True, start_from_epoch=0)\n",
        "\n",
        "tf.keras.utils.set_random_seed(18731)\n",
        "\n",
        "# I was experimenting with models that took longer to train, and used this\n",
        "# checkpointing callback to periodically save the model. It's optional.\n",
        "def get_checkpoint_callback(model_file):\n",
        "  return ModelCheckpoint(\n",
        "      get_model_save_location(model_file),\n",
        "      monitor='val_loss', verbose=0, save_best_only=True, mode='min')\n",
        "\n",
        "def train_or_update_variational_model(\n",
        "        sp: ScaledPartitions,\n",
        "        hidden_layers: List[int],\n",
        "        epochs: int,\n",
        "        batch_size: int,\n",
        "        lr: float,\n",
        "        model_file=None,\n",
        "        use_checkpoint=False):\n",
        "  callbacks_list = [get_early_stopping_callback(),\n",
        "                    get_checkpoint_callback(model_file)]\n",
        "  if not use_checkpoint:\n",
        "    inputs = keras.Input(shape=(sp.train.X.shape[1],))\n",
        "    x = inputs\n",
        "    for layer_size in hidden_layers:\n",
        "      x = keras.layers.Dense(\n",
        "          layer_size, activation='relu')(x)\n",
        "    mean_output = keras.layers.Dense(\n",
        "        1, name='mean_output')(x)\n",
        "\n",
        "    # We can not have negative variance. Apply very little variance.\n",
        "    var_output = keras.layers.Dense(\n",
        "        1, name='var_output')(x)\n",
        "\n",
        "    # Invert the normalization on our outputs\n",
        "    mean_scaler = sp.label_scaler.named_transformers_['mean_std_scaler']\n",
        "    untransformed_mean = mean_output * mean_scaler.var_ + mean_scaler.mean_\n",
        "\n",
        "    var_scaler = sp.label_scaler.named_transformers_['var_minmax_scaler']\n",
        "    unscaled_var = var_output * var_scaler.scale_ + var_scaler.min_\n",
        "    untransformed_var = keras.layers.Lambda(lambda t: tf.math.log(1 + tf.exp(t)))(unscaled_var)\n",
        "\n",
        "    # Output mean,  tuples.\n",
        "    outputs = keras.layers.concatenate([untransformed_mean, untransformed_var])\n",
        "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "    optimizer = keras.optimizers.Adam(learning_rate=lr)\n",
        "    model.compile(optimizer=optimizer, loss=kl_divergence)\n",
        "    model.summary()\n",
        "  else:\n",
        "    model = keras.models.load_model(\n",
        "        get_model_save_location(model_file),\n",
        "        custom_objects={\"kl_divergence\": kl_divergence})\n",
        "  history = model.fit(sp.train.X, sp.train.Y, verbose=1, validation_data=sp.val.as_tuple(), shuffle=True,\n",
        "                      epochs=epochs, batch_size=batch_size, callbacks=callbacks_list)\n",
        "  return history, model"
      ],
      "metadata": {
        "id": "HCkGSPUo3KqY"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "def render_plot_loss(history, name):\n",
        "  plt.plot(history.history['loss'])\n",
        "  plt.plot(history.history['val_loss'])\n",
        "  plt.title(name + ' model loss')\n",
        "  plt.ylabel('loss')\n",
        "  plt.yscale(\"log\")\n",
        "  plt.ylim((0, 10))\n",
        "  plt.xlabel('epoch')\n",
        "  plt.legend(['loss', 'val_loss'], loc='upper left')\n",
        "  plt.show()\n",
        "\n",
        "def destandardize(sd: ScaledPartitions, df: pd.DataFrame):\n",
        "  means = pd.DataFrame(\n",
        "      sd.label_scaler.named_transformers_['var_std_scaler'].inverse_transform(df[['d18O_cel_mean']]),\n",
        "      index=df.index, columns=['d18O_cel_mean'])\n",
        "  vars = df['d18O_cel_variance']\n",
        "  return means.join(vars)\n",
        "\n",
        "def train_and_evaluate(sp: ScaledPartitions, run_id: str, training_batch_size=5):\n",
        "  print(\"==================\")\n",
        "  print(run_id)\n",
        "  history, model = train_or_update_variational_model(\n",
        "      sp, hidden_layers=[20, 20], epochs=5000, batch_size=training_batch_size,\n",
        "      lr=0.0001, model_file=run_id+\".h5\", use_checkpoint=False)\n",
        "  render_plot_loss(history, run_id+\" kl_loss\")\n",
        "  model.save(get_model_save_location(run_id+\".h5\"), save_format=\"h5\")\n",
        "\n",
        "  best_epoch_index = history.history['val_loss'].index(min(history.history['val_loss']))\n",
        "  print('Val loss:', history.history['val_loss'][best_epoch_index])\n",
        "  print('Train loss:', history.history['loss'][best_epoch_index])\n",
        "  print('Test loss:', model.evaluate(x=sp.test.X, y=sp.test.Y, verbose=0))\n",
        "\n",
        "  predictions = model.predict_on_batch(sp.test.X)\n",
        "  predictions = pd.DataFrame(predictions, columns=['d18O_cel_mean', 'd18O_cel_variance'])\n",
        "  rmse = np.sqrt(mean_squared_error(sp.test.Y['d18O_cel_mean'], predictions['d18O_cel_mean']))\n",
        "  print(\"dO18 RMSE: \"+ str(rmse))\n",
        "  print(\"EXPECTED:\")\n",
        "  print(sp.test.Y.to_string())\n",
        "  print()\n",
        "  print(\"PREDICTED:\")\n",
        "  print(predictions.to_string())\n",
        "  return model"
      ],
      "metadata": {
        "id": "DALuUm8UOgNu"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1) Grouped, random (jupyter crashed halfway so I reloaded a checkpoint)\n",
        "\n",
        "We can't (easily) generate isoscapes with these because the isoscapes for 'predkrig_br_lat_ISORG', 'Iso_Oxi_Stack_mean_TERZER', 'isoscape_fullmodel_d18O_prec_REGRESSION' are not easily retrievable... but I'm curious how much better the model is if these columns are included."
      ],
      "metadata": {
        "id": "n8pNR1CrvF2a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "grouped_random_fileset = {\n",
        "    'TRAIN' : os.path.join(FP_ROOT, 'amazon_sample_data/canonical/uc_davis_train_random_grouped.csv'),\n",
        "    'TEST' : os.path.join(FP_ROOT, 'amazon_sample_data/canonical/uc_davis_test_random_grouped.csv'),\n",
        "    'VALIDATION' : os.path.join(FP_ROOT, 'amazon_sample_data/canonical/uc_davis_validation_random_grouped.csv'),\n",
        "}\n",
        "\n",
        "columns_to_passthrough = [\n",
        "    'ordinary_kriging_linear_d18O_predicted_mean',\n",
        "    'ordinary_kriging_linear_d18O_predicted_variance']\n",
        "columns_to_scale = []\n",
        "columns_to_standardize = [\n",
        "    'lat', 'long', 'VPD', 'RH', 'PET', 'DEM', 'PA',\n",
        "    'Mean Annual Temperature', 'Mean Annual Precipitation',\n",
        "    'Iso_Oxi_Stack_mean_TERZER', 'isoscape_fullmodel_d18O_prec_REGRESSION']\n",
        "\n",
        "data = load_and_scale(grouped_random_fileset, columns_to_passthrough, columns_to_scale, columns_to_standardize)\n",
        "model = train_and_evaluate(data, \"random_all_isorix_carbon_ensemble\", training_batch_size=3)\n",
        "model.save(get_model_save_location(\"random_all_isorix_carbon_ensemble.tf\"), save_format='tf')\n",
        "dump(data.feature_scaler, get_model_save_location('random_all_isorix_carbon_ensemble.pkl'))\n"
      ],
      "metadata": {
        "id": "rPONfgkjvJWz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b45695d1-f74e-417f-cde2-3e375a876807"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Epoch 1319/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9277 - val_loss: 0.5517\n",
            "Epoch 1320/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9542 - val_loss: 0.7652\n",
            "Epoch 1321/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8427 - val_loss: 0.6073\n",
            "Epoch 1322/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9103 - val_loss: 0.6266\n",
            "Epoch 1323/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8924 - val_loss: 0.5490\n",
            "Epoch 1324/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8635 - val_loss: 0.5654\n",
            "Epoch 1325/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8231 - val_loss: 0.6964\n",
            "Epoch 1326/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8823 - val_loss: 0.5986\n",
            "Epoch 1327/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.1581 - val_loss: 0.6111\n",
            "Epoch 1328/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8504 - val_loss: 0.6612\n",
            "Epoch 1329/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9213 - val_loss: 0.7355\n",
            "Epoch 1330/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8242 - val_loss: 0.7098\n",
            "Epoch 1331/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8971 - val_loss: 0.8934\n",
            "Epoch 1332/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8838 - val_loss: 0.6809\n",
            "Epoch 1333/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8139 - val_loss: 0.6713\n",
            "Epoch 1334/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.9280 - val_loss: 0.6688\n",
            "Epoch 1335/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9493 - val_loss: 0.6385\n",
            "Epoch 1336/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8611 - val_loss: 0.5856\n",
            "Epoch 1337/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9296 - val_loss: 0.7741\n",
            "Epoch 1338/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8539 - val_loss: 0.7175\n",
            "Epoch 1339/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8532 - val_loss: 0.6152\n",
            "Epoch 1340/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8252 - val_loss: 0.5950\n",
            "Epoch 1341/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8411 - val_loss: 0.8773\n",
            "Epoch 1342/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9318 - val_loss: 0.9259\n",
            "Epoch 1343/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 1.0870 - val_loss: 0.6487\n",
            "Epoch 1344/5000\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 1.0382 - val_loss: 0.7163\n",
            "Epoch 1345/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9064 - val_loss: 0.6356\n",
            "Epoch 1346/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9423 - val_loss: 0.6035\n",
            "Epoch 1347/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8635 - val_loss: 0.7008\n",
            "Epoch 1348/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.9082 - val_loss: 0.7830\n",
            "Epoch 1349/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8942 - val_loss: 0.6724\n",
            "Epoch 1350/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8443 - val_loss: 0.6050\n",
            "Epoch 1351/5000\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.8623 - val_loss: 0.6705\n",
            "Epoch 1352/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.9342 - val_loss: 0.6521\n",
            "Epoch 1353/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9462 - val_loss: 0.6319\n",
            "Epoch 1354/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8883 - val_loss: 0.6955\n",
            "Epoch 1355/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 1.0534 - val_loss: 0.6363\n",
            "Epoch 1356/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8334 - val_loss: 0.6431\n",
            "Epoch 1357/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.9593 - val_loss: 0.6848\n",
            "Epoch 1358/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8386 - val_loss: 0.6234\n",
            "Epoch 1359/5000\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.8993 - val_loss: 0.6868\n",
            "Epoch 1360/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9155 - val_loss: 0.7782\n",
            "Epoch 1361/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8843 - val_loss: 0.7336\n",
            "Epoch 1362/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8850 - val_loss: 0.6078\n",
            "Epoch 1363/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8952 - val_loss: 0.6420\n",
            "Epoch 1364/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8788 - val_loss: 0.5876\n",
            "Epoch 1365/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8703 - val_loss: 0.7921\n",
            "Epoch 1366/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8121 - val_loss: 0.6494\n",
            "Epoch 1367/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9303 - val_loss: 0.6466\n",
            "Epoch 1368/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8657 - val_loss: 0.6300\n",
            "Epoch 1369/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8488 - val_loss: 0.5171\n",
            "Epoch 1370/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8671 - val_loss: 0.6130\n",
            "Epoch 1371/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8757 - val_loss: 0.6067\n",
            "Epoch 1372/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9032 - val_loss: 0.6278\n",
            "Epoch 1373/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8553 - val_loss: 0.6466\n",
            "Epoch 1374/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8778 - val_loss: 0.6979\n",
            "Epoch 1375/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8297 - val_loss: 0.6975\n",
            "Epoch 1376/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9130 - val_loss: 0.6497\n",
            "Epoch 1377/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8218 - val_loss: 0.6265\n",
            "Epoch 1378/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8507 - val_loss: 0.8866\n",
            "Epoch 1379/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9974 - val_loss: 0.6313\n",
            "Epoch 1380/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8491 - val_loss: 0.5933\n",
            "Epoch 1381/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8503 - val_loss: 0.5632\n",
            "Epoch 1382/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8981 - val_loss: 0.6302\n",
            "Epoch 1383/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8765 - val_loss: 0.6782\n",
            "Epoch 1384/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8239 - val_loss: 0.7981\n",
            "Epoch 1385/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8344 - val_loss: 0.5664\n",
            "Epoch 1386/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9136 - val_loss: 0.9972\n",
            "Epoch 1387/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8857 - val_loss: 0.7260\n",
            "Epoch 1388/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8783 - val_loss: 0.8422\n",
            "Epoch 1389/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8971 - val_loss: 0.7037\n",
            "Epoch 1390/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8517 - val_loss: 0.6390\n",
            "Epoch 1391/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.0287 - val_loss: 0.7124\n",
            "Epoch 1392/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9688 - val_loss: 0.6474\n",
            "Epoch 1393/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8939 - val_loss: 0.5803\n",
            "Epoch 1394/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9348 - val_loss: 0.5610\n",
            "Epoch 1395/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9025 - val_loss: 0.6306\n",
            "Epoch 1396/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8703 - val_loss: 0.6194\n",
            "Epoch 1397/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9251 - val_loss: 0.6361\n",
            "Epoch 1398/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8842 - val_loss: 0.6293\n",
            "Epoch 1399/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8558 - val_loss: 0.6295\n",
            "Epoch 1400/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8878 - val_loss: 0.6261\n",
            "Epoch 1401/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8272 - val_loss: 0.8496\n",
            "Epoch 1402/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8716 - val_loss: 0.6538\n",
            "Epoch 1403/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8494 - val_loss: 0.6971\n",
            "Epoch 1404/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9328 - val_loss: 0.5781\n",
            "Epoch 1405/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8923 - val_loss: 0.5546\n",
            "Epoch 1406/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8457 - val_loss: 0.6222\n",
            "Epoch 1407/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9979 - val_loss: 0.5696\n",
            "Epoch 1408/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9276 - val_loss: 0.5312\n",
            "Epoch 1409/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9132 - val_loss: 0.5543\n",
            "Epoch 1410/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8599 - val_loss: 0.8296\n",
            "Epoch 1411/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8825 - val_loss: 0.6751\n",
            "Epoch 1412/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8157 - val_loss: 0.5893\n",
            "Epoch 1413/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8516 - val_loss: 0.5871\n",
            "Epoch 1414/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9345 - val_loss: 0.5791\n",
            "Epoch 1415/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8378 - val_loss: 0.6154\n",
            "Epoch 1416/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8638 - val_loss: 0.6206\n",
            "Epoch 1417/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8547 - val_loss: 0.6326\n",
            "Epoch 1418/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9080 - val_loss: 0.5910\n",
            "Epoch 1419/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8565 - val_loss: 0.6643\n",
            "Epoch 1420/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8747 - val_loss: 0.6060\n",
            "Epoch 1421/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0001 - val_loss: 0.6030\n",
            "Epoch 1422/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9177 - val_loss: 0.6647\n",
            "Epoch 1423/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8403 - val_loss: 0.7185\n",
            "Epoch 1424/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9060 - val_loss: 0.5715\n",
            "Epoch 1425/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8365 - val_loss: 0.6126\n",
            "Epoch 1426/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8674 - val_loss: 0.5417\n",
            "Epoch 1427/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8596 - val_loss: 0.5897\n",
            "Epoch 1428/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9269 - val_loss: 0.6066\n",
            "Epoch 1429/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9163 - val_loss: 0.6942\n",
            "Epoch 1430/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9321 - val_loss: 0.6944\n",
            "Epoch 1431/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8907 - val_loss: 0.7175\n",
            "Epoch 1432/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8952 - val_loss: 0.6497\n",
            "Epoch 1433/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9148 - val_loss: 0.7588\n",
            "Epoch 1434/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9231 - val_loss: 0.6978\n",
            "Epoch 1435/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9142 - val_loss: 0.8516\n",
            "Epoch 1436/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9148 - val_loss: 0.7620\n",
            "Epoch 1437/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8326 - val_loss: 0.6252\n",
            "Epoch 1438/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.9525 - val_loss: 0.5070\n",
            "Epoch 1439/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8535 - val_loss: 0.6710\n",
            "Epoch 1440/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8000 - val_loss: 0.6410\n",
            "Epoch 1441/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9330 - val_loss: 0.5775\n",
            "Epoch 1442/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8369 - val_loss: 0.6695\n",
            "Epoch 1443/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8865 - val_loss: 0.5773\n",
            "Epoch 1444/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8589 - val_loss: 0.6226\n",
            "Epoch 1445/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8883 - val_loss: 0.7592\n",
            "Epoch 1446/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.9150 - val_loss: 0.6139\n",
            "Epoch 1447/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8720 - val_loss: 0.6099\n",
            "Epoch 1448/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8578 - val_loss: 0.5876\n",
            "Epoch 1449/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8798 - val_loss: 0.7434\n",
            "Epoch 1450/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8193 - val_loss: 0.5552\n",
            "Epoch 1451/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8216 - val_loss: 0.6505\n",
            "Epoch 1452/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9696 - val_loss: 0.4926\n",
            "Epoch 1453/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8557 - val_loss: 0.7364\n",
            "Epoch 1454/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8695 - val_loss: 0.5597\n",
            "Epoch 1455/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8693 - val_loss: 0.5811\n",
            "Epoch 1456/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8544 - val_loss: 0.6021\n",
            "Epoch 1457/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.9444 - val_loss: 0.7731\n",
            "Epoch 1458/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8304 - val_loss: 0.7863\n",
            "Epoch 1459/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9917 - val_loss: 0.5759\n",
            "Epoch 1460/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.9746 - val_loss: 0.7225\n",
            "Epoch 1461/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 1.0201 - val_loss: 0.6867\n",
            "Epoch 1462/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8423 - val_loss: 0.6734\n",
            "Epoch 1463/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8804 - val_loss: 0.6531\n",
            "Epoch 1464/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8404 - val_loss: 0.5919\n",
            "Epoch 1465/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.9989 - val_loss: 0.7388\n",
            "Epoch 1466/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8514 - val_loss: 0.8827\n",
            "Epoch 1467/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8717 - val_loss: 0.5570\n",
            "Epoch 1468/5000\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.8621 - val_loss: 0.5411\n",
            "Epoch 1469/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.9137 - val_loss: 0.5352\n",
            "Epoch 1470/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8576 - val_loss: 0.6963\n",
            "Epoch 1471/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8586 - val_loss: 0.7039\n",
            "Epoch 1472/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8663 - val_loss: 0.6736\n",
            "Epoch 1473/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9460 - val_loss: 0.5626\n",
            "Epoch 1474/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8896 - val_loss: 0.7242\n",
            "Epoch 1475/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0591 - val_loss: 0.7057\n",
            "Epoch 1476/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8590 - val_loss: 0.5535\n",
            "Epoch 1477/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8488 - val_loss: 0.7042\n",
            "Epoch 1478/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9134 - val_loss: 0.7221\n",
            "Epoch 1479/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8769 - val_loss: 0.6161\n",
            "Epoch 1480/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8795 - val_loss: 0.5249\n",
            "Epoch 1481/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8863 - val_loss: 0.6918\n",
            "Epoch 1482/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8833 - val_loss: 0.7922\n",
            "Epoch 1483/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8896 - val_loss: 0.5904\n",
            "Epoch 1484/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8772 - val_loss: 0.7162\n",
            "Epoch 1485/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8672 - val_loss: 0.4903\n",
            "Epoch 1486/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8804 - val_loss: 0.7779\n",
            "Epoch 1487/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9130 - val_loss: 0.5705\n",
            "Epoch 1488/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9584 - val_loss: 0.5885\n",
            "Epoch 1489/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8865 - val_loss: 0.5769\n",
            "Epoch 1490/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8667 - val_loss: 0.5980\n",
            "Epoch 1491/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9118 - val_loss: 0.6000\n",
            "Epoch 1492/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8853 - val_loss: 0.5949\n",
            "Epoch 1493/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9683 - val_loss: 0.5785\n",
            "Epoch 1494/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8734 - val_loss: 0.6177\n",
            "Epoch 1495/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8526 - val_loss: 0.6008\n",
            "Epoch 1496/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8820 - val_loss: 0.7182\n",
            "Epoch 1497/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9257 - val_loss: 0.6073\n",
            "Epoch 1498/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8366 - val_loss: 0.7009\n",
            "Epoch 1499/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8524 - val_loss: 0.5946\n",
            "Epoch 1500/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8660 - val_loss: 0.6207\n",
            "Epoch 1501/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9296 - val_loss: 0.6075\n",
            "Epoch 1502/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8428 - val_loss: 0.7962\n",
            "Epoch 1503/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8168 - val_loss: 0.6506\n",
            "Epoch 1504/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8942 - val_loss: 0.6190\n",
            "Epoch 1505/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9138 - val_loss: 0.6093\n",
            "Epoch 1506/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9270 - val_loss: 0.6012\n",
            "Epoch 1507/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8976 - val_loss: 0.6308\n",
            "Epoch 1508/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.0178 - val_loss: 0.6424\n",
            "Epoch 1509/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8283 - val_loss: 0.5453\n",
            "Epoch 1510/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8622 - val_loss: 0.5482\n",
            "Epoch 1511/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8750 - val_loss: 0.6654\n",
            "Epoch 1512/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8469 - val_loss: 0.7908\n",
            "Epoch 1513/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8968 - val_loss: 0.6599\n",
            "Epoch 1514/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9759 - val_loss: 0.7186\n",
            "Epoch 1515/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8093 - val_loss: 0.6154\n",
            "Epoch 1516/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8853 - val_loss: 0.7106\n",
            "Epoch 1517/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9041 - val_loss: 0.6718\n",
            "Epoch 1518/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9510 - val_loss: 0.5984\n",
            "Epoch 1519/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8560 - val_loss: 0.6158\n",
            "Epoch 1520/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8112 - val_loss: 0.5664\n",
            "Epoch 1521/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8657 - val_loss: 0.6131\n",
            "Epoch 1522/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9033 - val_loss: 0.5471\n",
            "Epoch 1523/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9283 - val_loss: 0.6138\n",
            "Epoch 1524/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8816 - val_loss: 0.6329\n",
            "Epoch 1525/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9984 - val_loss: 0.5482\n",
            "Epoch 1526/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9364 - val_loss: 0.6547\n",
            "Epoch 1527/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8943 - val_loss: 0.6162\n",
            "Epoch 1528/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9122 - val_loss: 0.6137\n",
            "Epoch 1529/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8716 - val_loss: 0.5649\n",
            "Epoch 1530/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9321 - val_loss: 0.5551\n",
            "Epoch 1531/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9287 - val_loss: 0.5740\n",
            "Epoch 1532/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8701 - val_loss: 0.6837\n",
            "Epoch 1533/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8298 - val_loss: 0.6836\n",
            "Epoch 1534/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8894 - val_loss: 0.6368\n",
            "Epoch 1535/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8792 - val_loss: 0.6000\n",
            "Epoch 1536/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9293 - val_loss: 0.7108\n",
            "Epoch 1537/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8624 - val_loss: 0.6319\n",
            "Epoch 1538/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8251 - val_loss: 0.5692\n",
            "Epoch 1539/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8716 - val_loss: 0.6284\n",
            "Epoch 1540/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8445 - val_loss: 0.6231\n",
            "Epoch 1541/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9084 - val_loss: 0.6110\n",
            "Epoch 1542/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8727 - val_loss: 0.6894\n",
            "Epoch 1543/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8785 - val_loss: 0.5785\n",
            "Epoch 1544/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8443 - val_loss: 0.9694\n",
            "Epoch 1545/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8203 - val_loss: 0.6439\n",
            "Epoch 1546/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 1.0888 - val_loss: 0.6262\n",
            "Epoch 1547/5000\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.9214 - val_loss: 0.7772\n",
            "Epoch 1548/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.7998 - val_loss: 0.8204\n",
            "Epoch 1549/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.9160 - val_loss: 0.6157\n",
            "Epoch 1550/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.9903 - val_loss: 0.6315\n",
            "Epoch 1551/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8512 - val_loss: 0.6446\n",
            "Epoch 1552/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9879 - val_loss: 0.6132\n",
            "Epoch 1553/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8607 - val_loss: 0.5516\n",
            "Epoch 1554/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8587 - val_loss: 0.5457\n",
            "Epoch 1555/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.9168 - val_loss: 0.6564\n",
            "Epoch 1556/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8803 - val_loss: 0.8139\n",
            "Epoch 1557/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8408 - val_loss: 0.6874\n",
            "Epoch 1558/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8110 - val_loss: 0.5905\n",
            "Epoch 1559/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8529 - val_loss: 0.7099\n",
            "Epoch 1560/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.9273 - val_loss: 0.5591\n",
            "Epoch 1561/5000\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.8406 - val_loss: 0.5740\n",
            "Epoch 1562/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.9080 - val_loss: 0.6287\n",
            "Epoch 1563/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9398 - val_loss: 0.5214\n",
            "Epoch 1564/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8364 - val_loss: 0.7332\n",
            "Epoch 1565/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8959 - val_loss: 0.5597\n",
            "Epoch 1566/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8364 - val_loss: 0.6335\n",
            "Epoch 1567/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.9892 - val_loss: 0.6555\n",
            "Epoch 1568/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9684 - val_loss: 0.5949\n",
            "Epoch 1569/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8581 - val_loss: 0.5772\n",
            "Epoch 1570/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.9299 - val_loss: 0.6837\n",
            "Epoch 1571/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9175 - val_loss: 0.6169\n",
            "Epoch 1572/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8371 - val_loss: 0.5976\n",
            "Epoch 1573/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7755 - val_loss: 0.6528\n",
            "Epoch 1574/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9193 - val_loss: 0.6603\n",
            "Epoch 1575/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.1165 - val_loss: 0.7196\n",
            "Epoch 1576/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8575 - val_loss: 0.6445\n",
            "Epoch 1577/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8693 - val_loss: 0.6636\n",
            "Epoch 1578/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9180 - val_loss: 0.6126\n",
            "Epoch 1579/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8461 - val_loss: 0.5235\n",
            "Epoch 1580/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8235 - val_loss: 0.5532\n",
            "Epoch 1581/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8556 - val_loss: 0.6967\n",
            "Epoch 1582/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8850 - val_loss: 0.7461\n",
            "Epoch 1583/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9155 - val_loss: 0.6426\n",
            "Epoch 1584/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8646 - val_loss: 0.6271\n",
            "Epoch 1585/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7898 - val_loss: 0.5970\n",
            "Epoch 1586/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9038 - val_loss: 0.6025\n",
            "Epoch 1587/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8775 - val_loss: 0.5645\n",
            "Epoch 1588/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8895 - val_loss: 0.6881\n",
            "Epoch 1589/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8725 - val_loss: 0.6818\n",
            "Epoch 1590/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8830 - val_loss: 0.6004\n",
            "Epoch 1591/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8931 - val_loss: 0.7387\n",
            "Epoch 1592/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8530 - val_loss: 0.5752\n",
            "Epoch 1593/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8437 - val_loss: 0.6368\n",
            "Epoch 1594/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8858 - val_loss: 0.7616\n",
            "Epoch 1595/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8756 - val_loss: 0.6695\n",
            "Epoch 1596/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8894 - val_loss: 0.6144\n",
            "Epoch 1597/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9494 - val_loss: 0.5745\n",
            "Epoch 1598/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8852 - val_loss: 0.6437\n",
            "Epoch 1599/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7984 - val_loss: 0.5655\n",
            "Epoch 1600/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9668 - val_loss: 0.6709\n",
            "Epoch 1601/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8396 - val_loss: 0.6846\n",
            "Epoch 1602/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8441 - val_loss: 0.6506\n",
            "Epoch 1603/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8579 - val_loss: 0.6732\n",
            "Epoch 1604/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9035 - val_loss: 0.7175\n",
            "Epoch 1605/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8547 - val_loss: 0.5671\n",
            "Epoch 1606/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8882 - val_loss: 0.6300\n",
            "Epoch 1607/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8097 - val_loss: 0.6879\n",
            "Epoch 1608/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8762 - val_loss: 0.7497\n",
            "Epoch 1609/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8164 - val_loss: 0.6463\n",
            "Epoch 1610/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8290 - val_loss: 0.5734\n",
            "Epoch 1611/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8154 - val_loss: 0.6069\n",
            "Epoch 1612/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8284 - val_loss: 0.7236\n",
            "Epoch 1613/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9966 - val_loss: 0.7230\n",
            "Epoch 1614/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8770 - val_loss: 0.5954\n",
            "Epoch 1615/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8851 - val_loss: 0.5440\n",
            "Epoch 1616/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9857 - val_loss: 0.5614\n",
            "Epoch 1617/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9485 - val_loss: 0.6869\n",
            "Epoch 1618/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8684 - val_loss: 0.6492\n",
            "Epoch 1619/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8536 - val_loss: 0.6010\n",
            "Epoch 1620/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8530 - val_loss: 0.6830\n",
            "Epoch 1621/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8430 - val_loss: 0.6070\n",
            "Epoch 1622/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8832 - val_loss: 0.5675\n",
            "Epoch 1623/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8993 - val_loss: 0.5992\n",
            "Epoch 1624/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8822 - val_loss: 0.5772\n",
            "Epoch 1625/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.9300 - val_loss: 0.6747\n",
            "Epoch 1626/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9243 - val_loss: 0.4908\n",
            "Epoch 1627/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8728 - val_loss: 0.5187\n",
            "Epoch 1628/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8455 - val_loss: 0.6480\n",
            "Epoch 1629/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0553 - val_loss: 0.6283\n",
            "Epoch 1630/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9257 - val_loss: 0.6780\n",
            "Epoch 1631/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7920 - val_loss: 0.6551\n",
            "Epoch 1632/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0226 - val_loss: 0.5233\n",
            "Epoch 1633/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8376 - val_loss: 0.5627\n",
            "Epoch 1634/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0081 - val_loss: 0.6882\n",
            "Epoch 1635/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8664 - val_loss: 0.6079\n",
            "Epoch 1636/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8211 - val_loss: 0.7451\n",
            "Epoch 1637/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9237 - val_loss: 0.9229\n",
            "Epoch 1638/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8251 - val_loss: 0.5950\n",
            "Epoch 1639/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8919 - val_loss: 0.5985\n",
            "Epoch 1640/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8974 - val_loss: 0.5771\n",
            "Epoch 1641/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9219 - val_loss: 0.6140\n",
            "Epoch 1642/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8976 - val_loss: 0.5788\n",
            "Epoch 1643/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.9702 - val_loss: 0.4818\n",
            "Epoch 1644/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9203 - val_loss: 0.6251\n",
            "Epoch 1645/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8531 - val_loss: 0.6697\n",
            "Epoch 1646/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8700 - val_loss: 0.6188\n",
            "Epoch 1647/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9152 - val_loss: 0.6479\n",
            "Epoch 1648/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8332 - val_loss: 0.6072\n",
            "Epoch 1649/5000\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.9001 - val_loss: 0.5070\n",
            "Epoch 1650/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8606 - val_loss: 0.6097\n",
            "Epoch 1651/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.9142 - val_loss: 0.7772\n",
            "Epoch 1652/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8922 - val_loss: 0.7461\n",
            "Epoch 1653/5000\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.8445 - val_loss: 0.6528\n",
            "Epoch 1654/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8652 - val_loss: 0.7314\n",
            "Epoch 1655/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.9752 - val_loss: 0.7263\n",
            "Epoch 1656/5000\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.8499 - val_loss: 0.6194\n",
            "Epoch 1657/5000\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.8358 - val_loss: 0.6016\n",
            "Epoch 1658/5000\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.8410 - val_loss: 0.5831\n",
            "Epoch 1659/5000\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.9047 - val_loss: 0.8306\n",
            "Epoch 1660/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9009 - val_loss: 0.7434\n",
            "Epoch 1661/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8630 - val_loss: 0.5829\n",
            "Epoch 1662/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9143 - val_loss: 0.7979\n",
            "Epoch 1663/5000\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.8781 - val_loss: 0.6948\n",
            "Epoch 1664/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.9020 - val_loss: 0.8447\n",
            "Epoch 1665/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.9012 - val_loss: 0.5959\n",
            "Epoch 1666/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8601 - val_loss: 0.4910\n",
            "Epoch 1667/5000\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.8606 - val_loss: 0.6861\n",
            "Epoch 1668/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8671 - val_loss: 0.5564\n",
            "Epoch 1669/5000\n",
            "33/33 [==============================] - 0s 8ms/step - loss: 0.8598 - val_loss: 0.6258\n",
            "Epoch 1670/5000\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.8897 - val_loss: 0.6278\n",
            "Epoch 1671/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8891 - val_loss: 0.6935\n",
            "Epoch 1672/5000\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 1.0154 - val_loss: 0.4905\n",
            "Epoch 1673/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8943 - val_loss: 0.7808\n",
            "Epoch 1674/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8573 - val_loss: 0.9121\n",
            "Epoch 1675/5000\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.8712 - val_loss: 0.6582\n",
            "Epoch 1676/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.9088 - val_loss: 0.5696\n",
            "Epoch 1677/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.9184 - val_loss: 0.6876\n",
            "Epoch 1678/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.9253 - val_loss: 0.5797\n",
            "Epoch 1679/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8548 - val_loss: 0.7775\n",
            "Epoch 1680/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8623 - val_loss: 0.5867\n",
            "Epoch 1681/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8299 - val_loss: 0.5698\n",
            "Epoch 1682/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8319 - val_loss: 0.7027\n",
            "Epoch 1683/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8508 - val_loss: 0.5520\n",
            "Epoch 1684/5000\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.8803 - val_loss: 0.5570\n",
            "Epoch 1685/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8428 - val_loss: 0.6254\n",
            "Epoch 1686/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8527 - val_loss: 0.5773\n",
            "Epoch 1687/5000\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.8489 - val_loss: 0.6243\n",
            "Epoch 1688/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9403 - val_loss: 0.6082\n",
            "Epoch 1689/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9356 - val_loss: 0.5830\n",
            "Epoch 1690/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9646 - val_loss: 0.7429\n",
            "Epoch 1691/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8284 - val_loss: 0.5512\n",
            "Epoch 1692/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.0139 - val_loss: 0.6560\n",
            "Epoch 1693/5000\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.8667 - val_loss: 0.7141\n",
            "Epoch 1694/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.9087 - val_loss: 0.6783\n",
            "Epoch 1695/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9651 - val_loss: 0.6028\n",
            "Epoch 1696/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8809 - val_loss: 0.5568\n",
            "Epoch 1697/5000\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.8492 - val_loss: 0.6912\n",
            "Epoch 1698/5000\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.8795 - val_loss: 0.6452\n",
            "Epoch 1699/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8349 - val_loss: 0.6177\n",
            "Epoch 1700/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7844 - val_loss: 0.7314\n",
            "Epoch 1701/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8547 - val_loss: 0.7103\n",
            "Epoch 1702/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8865 - val_loss: 0.4956\n",
            "Epoch 1703/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8604 - val_loss: 0.6650\n",
            "Epoch 1704/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8703 - val_loss: 0.6929\n",
            "Epoch 1705/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9745 - val_loss: 0.6345\n",
            "Epoch 1706/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8553 - val_loss: 0.6172\n",
            "Epoch 1707/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8232 - val_loss: 0.7293\n",
            "Epoch 1708/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.9367 - val_loss: 0.6783\n",
            "Epoch 1709/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.9226 - val_loss: 0.5814\n",
            "Epoch 1710/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9367 - val_loss: 0.7998\n",
            "Epoch 1711/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8530 - val_loss: 0.6644\n",
            "Epoch 1712/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9493 - val_loss: 0.6846\n",
            "Epoch 1713/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8268 - val_loss: 0.5876\n",
            "Epoch 1714/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9123 - val_loss: 0.5424\n",
            "Epoch 1715/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8793 - val_loss: 0.6438\n",
            "Epoch 1716/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8916 - val_loss: 0.6495\n",
            "Epoch 1717/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9075 - val_loss: 0.5330\n",
            "Epoch 1718/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8800 - val_loss: 0.5474\n",
            "Epoch 1719/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8938 - val_loss: 0.5970\n",
            "Epoch 1720/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8783 - val_loss: 0.5218\n",
            "Epoch 1721/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9324 - val_loss: 0.7078\n",
            "Epoch 1722/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9504 - val_loss: 0.5888\n",
            "Epoch 1723/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9005 - val_loss: 0.5658\n",
            "Epoch 1724/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9159 - val_loss: 0.5863\n",
            "Epoch 1725/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8507 - val_loss: 0.6746\n",
            "Epoch 1726/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8228 - val_loss: 0.7803\n",
            "Epoch 1727/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8128 - val_loss: 0.7216\n",
            "Epoch 1728/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8620 - val_loss: 0.6940\n",
            "Epoch 1729/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9302 - val_loss: 0.6185\n",
            "Epoch 1730/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9490 - val_loss: 0.5290\n",
            "Epoch 1731/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9111 - val_loss: 0.5490\n",
            "Epoch 1732/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8130 - val_loss: 0.5156\n",
            "Epoch 1733/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8562 - val_loss: 0.7879\n",
            "Epoch 1734/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8914 - val_loss: 0.7182\n",
            "Epoch 1735/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8082 - val_loss: 0.5814\n",
            "Epoch 1736/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8868 - val_loss: 0.8273\n",
            "Epoch 1737/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8745 - val_loss: 0.5970\n",
            "Epoch 1738/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8343 - val_loss: 0.7195\n",
            "Epoch 1739/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8454 - val_loss: 0.8003\n",
            "Epoch 1740/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8493 - val_loss: 0.6331\n",
            "Epoch 1741/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8287 - val_loss: 0.6179\n",
            "Epoch 1742/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9577 - val_loss: 0.6932\n",
            "Epoch 1743/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8907 - val_loss: 0.5782\n",
            "Epoch 1744/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8711 - val_loss: 0.7159\n",
            "Epoch 1745/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9352 - val_loss: 0.6108\n",
            "Epoch 1746/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9130 - val_loss: 0.6366\n",
            "Epoch 1747/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8601 - val_loss: 0.6678\n",
            "Epoch 1748/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8454 - val_loss: 0.7328\n",
            "Epoch 1749/5000\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.8676 - val_loss: 0.6145\n",
            "Epoch 1750/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.9140 - val_loss: 0.5931\n",
            "Epoch 1751/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8921 - val_loss: 0.6592\n",
            "Epoch 1752/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8953 - val_loss: 0.5619\n",
            "Epoch 1753/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.9184 - val_loss: 0.6613\n",
            "Epoch 1754/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8205 - val_loss: 0.6090\n",
            "Epoch 1755/5000\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.8895 - val_loss: 0.6740\n",
            "Epoch 1756/5000\n",
            "33/33 [==============================] - 0s 8ms/step - loss: 0.8816 - val_loss: 0.6456\n",
            "Epoch 1757/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.9128 - val_loss: 0.5809\n",
            "Epoch 1758/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8956 - val_loss: 0.5960\n",
            "Epoch 1759/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8494 - val_loss: 0.6376\n",
            "Epoch 1760/5000\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.8580 - val_loss: 0.5506\n",
            "Epoch 1761/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.9063 - val_loss: 1.0581\n",
            "Epoch 1762/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8705 - val_loss: 0.6215\n",
            "Epoch 1763/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9199 - val_loss: 0.6324\n",
            "Epoch 1764/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8562 - val_loss: 0.6210\n",
            "Epoch 1765/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8435 - val_loss: 0.6363\n",
            "Epoch 1766/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8727 - val_loss: 0.7116\n",
            "Epoch 1767/5000\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.8956 - val_loss: 0.7329\n",
            "Epoch 1768/5000\n",
            "33/33 [==============================] - 0s 8ms/step - loss: 0.8807 - val_loss: 0.5820\n",
            "Epoch 1769/5000\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.8894 - val_loss: 0.5644\n",
            "Epoch 1770/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8697 - val_loss: 0.5874\n",
            "Epoch 1771/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8477 - val_loss: 0.6945\n",
            "Epoch 1772/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9247 - val_loss: 0.6778\n",
            "Epoch 1773/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8940 - val_loss: 0.6619\n",
            "Epoch 1774/5000\n",
            "33/33 [==============================] - 1s 21ms/step - loss: 0.8941 - val_loss: 0.4769\n",
            "Epoch 1775/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8613 - val_loss: 0.6121\n",
            "Epoch 1776/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9752 - val_loss: 0.6252\n",
            "Epoch 1777/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8600 - val_loss: 0.7637\n",
            "Epoch 1778/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9494 - val_loss: 0.5516\n",
            "Epoch 1779/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9109 - val_loss: 0.6059\n",
            "Epoch 1780/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8497 - val_loss: 0.6321\n",
            "Epoch 1781/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9065 - val_loss: 0.5418\n",
            "Epoch 1782/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8156 - val_loss: 0.6877\n",
            "Epoch 1783/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9486 - val_loss: 0.5136\n",
            "Epoch 1784/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8795 - val_loss: 0.6433\n",
            "Epoch 1785/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9812 - val_loss: 0.6305\n",
            "Epoch 1786/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8696 - val_loss: 0.8844\n",
            "Epoch 1787/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8893 - val_loss: 0.5713\n",
            "Epoch 1788/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9185 - val_loss: 0.6794\n",
            "Epoch 1789/5000\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.8788 - val_loss: 0.4711\n",
            "Epoch 1790/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9057 - val_loss: 0.6283\n",
            "Epoch 1791/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8772 - val_loss: 0.6829\n",
            "Epoch 1792/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8374 - val_loss: 0.5504\n",
            "Epoch 1793/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8830 - val_loss: 0.5394\n",
            "Epoch 1794/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8036 - val_loss: 0.6719\n",
            "Epoch 1795/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8712 - val_loss: 0.6092\n",
            "Epoch 1796/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8080 - val_loss: 0.6860\n",
            "Epoch 1797/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8297 - val_loss: 0.6201\n",
            "Epoch 1798/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9199 - val_loss: 0.6726\n",
            "Epoch 1799/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9087 - val_loss: 0.5490\n",
            "Epoch 1800/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9136 - val_loss: 0.5489\n",
            "Epoch 1801/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8656 - val_loss: 0.5033\n",
            "Epoch 1802/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8965 - val_loss: 0.5869\n",
            "Epoch 1803/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8686 - val_loss: 1.0129\n",
            "Epoch 1804/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8562 - val_loss: 0.5746\n",
            "Epoch 1805/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8674 - val_loss: 0.6351\n",
            "Epoch 1806/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8266 - val_loss: 0.6244\n",
            "Epoch 1807/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8613 - val_loss: 0.5649\n",
            "Epoch 1808/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8620 - val_loss: 0.6324\n",
            "Epoch 1809/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8133 - val_loss: 0.6090\n",
            "Epoch 1810/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9696 - val_loss: 0.5568\n",
            "Epoch 1811/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9522 - val_loss: 0.6119\n",
            "Epoch 1812/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8698 - val_loss: 0.6146\n",
            "Epoch 1813/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8869 - val_loss: 0.6711\n",
            "Epoch 1814/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8378 - val_loss: 0.5779\n",
            "Epoch 1815/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0255 - val_loss: 0.6962\n",
            "Epoch 1816/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9563 - val_loss: 0.5640\n",
            "Epoch 1817/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8832 - val_loss: 0.7889\n",
            "Epoch 1818/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8589 - val_loss: 0.5549\n",
            "Epoch 1819/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8834 - val_loss: 0.5622\n",
            "Epoch 1820/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8370 - val_loss: 0.5766\n",
            "Epoch 1821/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9482 - val_loss: 0.5298\n",
            "Epoch 1822/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8588 - val_loss: 0.6027\n",
            "Epoch 1823/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8585 - val_loss: 0.5783\n",
            "Epoch 1824/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8144 - val_loss: 0.6392\n",
            "Epoch 1825/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9272 - val_loss: 0.5369\n",
            "Epoch 1826/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8514 - val_loss: 0.6897\n",
            "Epoch 1827/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8524 - val_loss: 0.5208\n",
            "Epoch 1828/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8824 - val_loss: 0.6544\n",
            "Epoch 1829/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8751 - val_loss: 0.6103\n",
            "Epoch 1830/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8919 - val_loss: 0.5715\n",
            "Epoch 1831/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9087 - val_loss: 0.5691\n",
            "Epoch 1832/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8884 - val_loss: 0.5840\n",
            "Epoch 1833/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8787 - val_loss: 0.7785\n",
            "Epoch 1834/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.9718 - val_loss: 0.6621\n",
            "Epoch 1835/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9133 - val_loss: 0.6536\n",
            "Epoch 1836/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8292 - val_loss: 0.5651\n",
            "Epoch 1837/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8597 - val_loss: 0.6106\n",
            "Epoch 1838/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8555 - val_loss: 0.6296\n",
            "Epoch 1839/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 1.0449 - val_loss: 0.6738\n",
            "Epoch 1840/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8861 - val_loss: 0.5468\n",
            "Epoch 1841/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8636 - val_loss: 0.5704\n",
            "Epoch 1842/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9079 - val_loss: 0.5124\n",
            "Epoch 1843/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8799 - val_loss: 0.5079\n",
            "Epoch 1844/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8151 - val_loss: 0.7244\n",
            "Epoch 1845/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.9193 - val_loss: 0.6057\n",
            "Epoch 1846/5000\n",
            "33/33 [==============================] - 1s 31ms/step - loss: 0.8505 - val_loss: 0.4557\n",
            "Epoch 1847/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9489 - val_loss: 0.5354\n",
            "Epoch 1848/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8192 - val_loss: 0.4838\n",
            "Epoch 1849/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7854 - val_loss: 0.6866\n",
            "Epoch 1850/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8000 - val_loss: 0.7782\n",
            "Epoch 1851/5000\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.8768 - val_loss: 0.6581\n",
            "Epoch 1852/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8779 - val_loss: 0.6270\n",
            "Epoch 1853/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8859 - val_loss: 0.7101\n",
            "Epoch 1854/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.9668 - val_loss: 0.6304\n",
            "Epoch 1855/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8489 - val_loss: 0.6271\n",
            "Epoch 1856/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8489 - val_loss: 0.4964\n",
            "Epoch 1857/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 1.0830 - val_loss: 0.5689\n",
            "Epoch 1858/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8512 - val_loss: 0.6142\n",
            "Epoch 1859/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8812 - val_loss: 0.7564\n",
            "Epoch 1860/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9044 - val_loss: 0.4793\n",
            "Epoch 1861/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8220 - val_loss: 0.5789\n",
            "Epoch 1862/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.9149 - val_loss: 0.8183\n",
            "Epoch 1863/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9100 - val_loss: 0.6287\n",
            "Epoch 1864/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9452 - val_loss: 0.5429\n",
            "Epoch 1865/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8285 - val_loss: 0.6248\n",
            "Epoch 1866/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8547 - val_loss: 0.6640\n",
            "Epoch 1867/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8951 - val_loss: 0.5970\n",
            "Epoch 1868/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.9136 - val_loss: 0.7007\n",
            "Epoch 1869/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8185 - val_loss: 0.4605\n",
            "Epoch 1870/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8601 - val_loss: 0.6526\n",
            "Epoch 1871/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0876 - val_loss: 0.8407\n",
            "Epoch 1872/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8930 - val_loss: 0.6883\n",
            "Epoch 1873/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8390 - val_loss: 0.5246\n",
            "Epoch 1874/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8597 - val_loss: 0.6440\n",
            "Epoch 1875/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.9493 - val_loss: 0.5600\n",
            "Epoch 1876/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8638 - val_loss: 0.6890\n",
            "Epoch 1877/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8311 - val_loss: 0.6426\n",
            "Epoch 1878/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8004 - val_loss: 0.6037\n",
            "Epoch 1879/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8700 - val_loss: 0.9105\n",
            "Epoch 1880/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9380 - val_loss: 0.6075\n",
            "Epoch 1881/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.0560 - val_loss: 0.5735\n",
            "Epoch 1882/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8123 - val_loss: 0.6143\n",
            "Epoch 1883/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8518 - val_loss: 0.6458\n",
            "Epoch 1884/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8479 - val_loss: 0.5716\n",
            "Epoch 1885/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8813 - val_loss: 0.5440\n",
            "Epoch 1886/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8565 - val_loss: 0.6794\n",
            "Epoch 1887/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8416 - val_loss: 0.5919\n",
            "Epoch 1888/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8644 - val_loss: 0.7274\n",
            "Epoch 1889/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8310 - val_loss: 0.5748\n",
            "Epoch 1890/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8268 - val_loss: 0.8826\n",
            "Epoch 1891/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8958 - val_loss: 0.6718\n",
            "Epoch 1892/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9266 - val_loss: 0.5758\n",
            "Epoch 1893/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7926 - val_loss: 0.5951\n",
            "Epoch 1894/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8541 - val_loss: 0.5589\n",
            "Epoch 1895/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8408 - val_loss: 0.5195\n",
            "Epoch 1896/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8822 - val_loss: 0.5768\n",
            "Epoch 1897/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8828 - val_loss: 0.7166\n",
            "Epoch 1898/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8709 - val_loss: 0.6217\n",
            "Epoch 1899/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8010 - val_loss: 0.5780\n",
            "Epoch 1900/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8727 - val_loss: 0.6465\n",
            "Epoch 1901/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7852 - val_loss: 0.6451\n",
            "Epoch 1902/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8846 - val_loss: 0.6060\n",
            "Epoch 1903/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8879 - val_loss: 0.5431\n",
            "Epoch 1904/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8098 - val_loss: 0.5433\n",
            "Epoch 1905/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8723 - val_loss: 0.5849\n",
            "Epoch 1906/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8855 - val_loss: 0.5981\n",
            "Epoch 1907/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8449 - val_loss: 0.6566\n",
            "Epoch 1908/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8195 - val_loss: 0.5615\n",
            "Epoch 1909/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9371 - val_loss: 0.6009\n",
            "Epoch 1910/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9203 - val_loss: 0.6059\n",
            "Epoch 1911/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8564 - val_loss: 0.5376\n",
            "Epoch 1912/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8772 - val_loss: 0.5631\n",
            "Epoch 1913/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8502 - val_loss: 0.4897\n",
            "Epoch 1914/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9096 - val_loss: 0.6728\n",
            "Epoch 1915/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8451 - val_loss: 0.6398\n",
            "Epoch 1916/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8636 - val_loss: 0.6303\n",
            "Epoch 1917/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9193 - val_loss: 0.5671\n",
            "Epoch 1918/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8737 - val_loss: 0.6427\n",
            "Epoch 1919/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9032 - val_loss: 0.5224\n",
            "Epoch 1920/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8405 - val_loss: 0.5561\n",
            "Epoch 1921/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8718 - val_loss: 0.5552\n",
            "Epoch 1922/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9171 - val_loss: 0.4970\n",
            "Epoch 1923/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8856 - val_loss: 0.5672\n",
            "Epoch 1924/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9532 - val_loss: 0.5703\n",
            "Epoch 1925/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9723 - val_loss: 0.6040\n",
            "Epoch 1926/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8491 - val_loss: 0.6380\n",
            "Epoch 1927/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8761 - val_loss: 0.5513\n",
            "Epoch 1928/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8965 - val_loss: 0.6453\n",
            "Epoch 1929/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9581 - val_loss: 0.5866\n",
            "Epoch 1930/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8182 - val_loss: 0.7091\n",
            "Epoch 1931/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8577 - val_loss: 0.5621\n",
            "Epoch 1932/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8057 - val_loss: 0.6573\n",
            "Epoch 1933/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8891 - val_loss: 0.6703\n",
            "Epoch 1934/5000\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 1.0023 - val_loss: 0.6539\n",
            "Epoch 1935/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8458 - val_loss: 0.6219\n",
            "Epoch 1936/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8507 - val_loss: 0.6070\n",
            "Epoch 1937/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.9920 - val_loss: 0.6316\n",
            "Epoch 1938/5000\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.8218 - val_loss: 0.5595\n",
            "Epoch 1939/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8625 - val_loss: 0.5459\n",
            "Epoch 1940/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8324 - val_loss: 0.6515\n",
            "Epoch 1941/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8302 - val_loss: 0.5305\n",
            "Epoch 1942/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8258 - val_loss: 0.6822\n",
            "Epoch 1943/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.7912 - val_loss: 0.6054\n",
            "Epoch 1944/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8687 - val_loss: 0.4905\n",
            "Epoch 1945/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8990 - val_loss: 0.5922\n",
            "Epoch 1946/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9053 - val_loss: 0.5927\n",
            "Epoch 1947/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9038 - val_loss: 0.6556\n",
            "Epoch 1948/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9056 - val_loss: 0.5653\n",
            "Epoch 1949/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9548 - val_loss: 0.6332\n",
            "Epoch 1950/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8972 - val_loss: 0.7030\n",
            "Epoch 1951/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8798 - val_loss: 0.6285\n",
            "Epoch 1952/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7838 - val_loss: 0.5953\n",
            "Epoch 1953/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8527 - val_loss: 0.5999\n",
            "Epoch 1954/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8446 - val_loss: 0.5359\n",
            "Epoch 1955/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8725 - val_loss: 0.6663\n",
            "Epoch 1956/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8785 - val_loss: 0.5702\n",
            "Epoch 1957/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8671 - val_loss: 0.5905\n",
            "Epoch 1958/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8453 - val_loss: 0.6089\n",
            "Epoch 1959/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9738 - val_loss: 0.5380\n",
            "Epoch 1960/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9357 - val_loss: 0.6192\n",
            "Epoch 1961/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8504 - val_loss: 0.5640\n",
            "Epoch 1962/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8662 - val_loss: 0.5505\n",
            "Epoch 1963/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8965 - val_loss: 0.5853\n",
            "Epoch 1964/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8465 - val_loss: 0.5201\n",
            "Epoch 1965/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8545 - val_loss: 0.4692\n",
            "Epoch 1966/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8293 - val_loss: 0.6343\n",
            "Epoch 1967/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8537 - val_loss: 0.5914\n",
            "Epoch 1968/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9706 - val_loss: 0.6239\n",
            "Epoch 1969/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8853 - val_loss: 0.7190\n",
            "Epoch 1970/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8323 - val_loss: 0.6780\n",
            "Epoch 1971/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8518 - val_loss: 0.6127\n",
            "Epoch 1972/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9198 - val_loss: 0.7019\n",
            "Epoch 1973/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8276 - val_loss: 0.6495\n",
            "Epoch 1974/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8620 - val_loss: 0.6347\n",
            "Epoch 1975/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8768 - val_loss: 0.6775\n",
            "Epoch 1976/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8663 - val_loss: 0.6119\n",
            "Epoch 1977/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8702 - val_loss: 0.5782\n",
            "Epoch 1978/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8916 - val_loss: 0.6529\n",
            "Epoch 1979/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9016 - val_loss: 0.7556\n",
            "Epoch 1980/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8787 - val_loss: 0.5851\n",
            "Epoch 1981/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8257 - val_loss: 0.5864\n",
            "Epoch 1982/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8451 - val_loss: 0.8459\n",
            "Epoch 1983/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8994 - val_loss: 0.6945\n",
            "Epoch 1984/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9166 - val_loss: 0.5025\n",
            "Epoch 1985/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9073 - val_loss: 0.5737\n",
            "Epoch 1986/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8417 - val_loss: 0.4738\n",
            "Epoch 1987/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8846 - val_loss: 0.5823\n",
            "Epoch 1988/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8351 - val_loss: 0.5949\n",
            "Epoch 1989/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8177 - val_loss: 0.6213\n",
            "Epoch 1990/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8643 - val_loss: 0.7142\n",
            "Epoch 1991/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8895 - val_loss: 0.6262\n",
            "Epoch 1992/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9057 - val_loss: 0.7435\n",
            "Epoch 1993/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8706 - val_loss: 0.5294\n",
            "Epoch 1994/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8274 - val_loss: 0.4904\n",
            "Epoch 1995/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8527 - val_loss: 0.6151\n",
            "Epoch 1996/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8664 - val_loss: 0.8299\n",
            "Epoch 1997/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8401 - val_loss: 0.6206\n",
            "Epoch 1998/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8481 - val_loss: 0.5913\n",
            "Epoch 1999/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8988 - val_loss: 0.8155\n",
            "Epoch 2000/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8711 - val_loss: 0.6560\n",
            "Epoch 2001/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8708 - val_loss: 0.5760\n",
            "Epoch 2002/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.0733 - val_loss: 0.6151\n",
            "Epoch 2003/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8985 - val_loss: 0.5975\n",
            "Epoch 2004/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8000 - val_loss: 0.6202\n",
            "Epoch 2005/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8538 - val_loss: 0.5611\n",
            "Epoch 2006/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0024 - val_loss: 0.7562\n",
            "Epoch 2007/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8151 - val_loss: 0.6095\n",
            "Epoch 2008/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9236 - val_loss: 0.5643\n",
            "Epoch 2009/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8222 - val_loss: 0.5595\n",
            "Epoch 2010/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8675 - val_loss: 0.5873\n",
            "Epoch 2011/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8784 - val_loss: 0.5885\n",
            "Epoch 2012/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8771 - val_loss: 0.6433\n",
            "Epoch 2013/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9600 - val_loss: 0.5679\n",
            "Epoch 2014/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9180 - val_loss: 0.5232\n",
            "Epoch 2015/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8429 - val_loss: 0.5942\n",
            "Epoch 2016/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8814 - val_loss: 0.7958\n",
            "Epoch 2017/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8073 - val_loss: 0.6030\n",
            "Epoch 2018/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8743 - val_loss: 0.6017\n",
            "Epoch 2019/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9855 - val_loss: 0.4919\n",
            "Epoch 2020/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8973 - val_loss: 0.5552\n",
            "Epoch 2021/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8332 - val_loss: 0.5475\n",
            "Epoch 2022/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8596 - val_loss: 0.5492\n",
            "Epoch 2023/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9459 - val_loss: 0.5547\n",
            "Epoch 2024/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9402 - val_loss: 0.6878\n",
            "Epoch 2025/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9001 - val_loss: 0.5588\n",
            "Epoch 2026/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8479 - val_loss: 0.5523\n",
            "Epoch 2027/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8664 - val_loss: 0.6475\n",
            "Epoch 2028/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8533 - val_loss: 0.7015\n",
            "Epoch 2029/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8625 - val_loss: 0.5639\n",
            "Epoch 2030/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9357 - val_loss: 0.6930\n",
            "Epoch 2031/5000\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.8977 - val_loss: 0.5939\n",
            "Epoch 2032/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8644 - val_loss: 0.6376\n",
            "Epoch 2033/5000\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.8765 - val_loss: 0.6964\n",
            "Epoch 2034/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8756 - val_loss: 0.7248\n",
            "Epoch 2035/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8032 - val_loss: 0.5682\n",
            "Epoch 2036/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8284 - val_loss: 0.7116\n",
            "Epoch 2037/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8047 - val_loss: 0.5296\n",
            "Epoch 2038/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9166 - val_loss: 0.7271\n",
            "Epoch 2039/5000\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.8672 - val_loss: 0.6165\n",
            "Epoch 2040/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.9132 - val_loss: 0.6347\n",
            "Epoch 2041/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8551 - val_loss: 0.5681\n",
            "Epoch 2042/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8387 - val_loss: 0.6218\n",
            "Epoch 2043/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8208 - val_loss: 0.5969\n",
            "Epoch 2044/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8521 - val_loss: 0.6422\n",
            "Epoch 2045/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.9320 - val_loss: 0.5862\n",
            "Epoch 2046/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8388 - val_loss: 0.7813\n",
            "Epoch 2047/5000\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.8034 - val_loss: 0.7211\n",
            "Epoch 2048/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.9978 - val_loss: 0.6118\n",
            "Epoch 2049/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8427 - val_loss: 0.5484\n",
            "Epoch 2050/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8935 - val_loss: 0.7107\n",
            "Epoch 2051/5000\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.8360 - val_loss: 0.6632\n",
            "Epoch 2052/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8063 - val_loss: 0.6030\n",
            "Epoch 2053/5000\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.8488 - val_loss: 0.6697\n",
            "Epoch 2054/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8405 - val_loss: 0.5510\n",
            "Epoch 2055/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8718 - val_loss: 0.6631\n",
            "Epoch 2056/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8558 - val_loss: 0.6428\n",
            "Epoch 2057/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8317 - val_loss: 0.5712\n",
            "Epoch 2058/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8944 - val_loss: 0.5913\n",
            "Epoch 2059/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8914 - val_loss: 0.7415\n",
            "Epoch 2060/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8745 - val_loss: 0.6154\n",
            "Epoch 2061/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8795 - val_loss: 0.5498\n",
            "Epoch 2062/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8546 - val_loss: 0.5115\n",
            "Epoch 2063/5000\n",
            "33/33 [==============================] - 0s 8ms/step - loss: 0.9056 - val_loss: 0.7430\n",
            "Epoch 2064/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8395 - val_loss: 0.6466\n",
            "Epoch 2065/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8174 - val_loss: 0.8390\n",
            "Epoch 2066/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8579 - val_loss: 0.5257\n",
            "Epoch 2067/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 1.0040 - val_loss: 0.6194\n",
            "Epoch 2068/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8148 - val_loss: 0.8746\n",
            "Epoch 2069/5000\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.8955 - val_loss: 0.7729\n",
            "Epoch 2070/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.9171 - val_loss: 0.6019\n",
            "Epoch 2071/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8703 - val_loss: 0.6385\n",
            "Epoch 2072/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9545 - val_loss: 0.6059\n",
            "Epoch 2073/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8640 - val_loss: 0.7455\n",
            "Epoch 2074/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8081 - val_loss: 0.4791\n",
            "Epoch 2075/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8945 - val_loss: 0.5667\n",
            "Epoch 2076/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8561 - val_loss: 0.4721\n",
            "Epoch 2077/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8707 - val_loss: 0.5978\n",
            "Epoch 2078/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8875 - val_loss: 0.5425\n",
            "Epoch 2079/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8288 - val_loss: 0.5925\n",
            "Epoch 2080/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9231 - val_loss: 0.5252\n",
            "Epoch 2081/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9447 - val_loss: 0.7543\n",
            "Epoch 2082/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8765 - val_loss: 0.5081\n",
            "Epoch 2083/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8522 - val_loss: 0.6760\n",
            "Epoch 2084/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8738 - val_loss: 0.7637\n",
            "Epoch 2085/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8212 - val_loss: 0.5383\n",
            "Epoch 2086/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8470 - val_loss: 0.6164\n",
            "Epoch 2087/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9091 - val_loss: 0.6341\n",
            "Epoch 2088/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7844 - val_loss: 0.6243\n",
            "Epoch 2089/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8098 - val_loss: 0.5570\n",
            "Epoch 2090/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9465 - val_loss: 0.6799\n",
            "Epoch 2091/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8562 - val_loss: 0.5360\n",
            "Epoch 2092/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0101 - val_loss: 0.5070\n",
            "Epoch 2093/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8659 - val_loss: 0.7084\n",
            "Epoch 2094/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8139 - val_loss: 0.5177\n",
            "Epoch 2095/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8464 - val_loss: 0.6376\n",
            "Epoch 2096/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0689 - val_loss: 0.6965\n",
            "Epoch 2097/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9244 - val_loss: 0.6393\n",
            "Epoch 2098/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8293 - val_loss: 0.7312\n",
            "Epoch 2099/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9280 - val_loss: 0.5312\n",
            "Epoch 2100/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8499 - val_loss: 0.5606\n",
            "Epoch 2101/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8013 - val_loss: 0.5547\n",
            "Epoch 2102/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8462 - val_loss: 0.8951\n",
            "Epoch 2103/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8344 - val_loss: 0.5648\n",
            "Epoch 2104/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7965 - val_loss: 0.6916\n",
            "Epoch 2105/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8534 - val_loss: 0.4691\n",
            "Epoch 2106/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8358 - val_loss: 0.5325\n",
            "Epoch 2107/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8311 - val_loss: 0.5725\n",
            "Epoch 2108/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8523 - val_loss: 0.6917\n",
            "Epoch 2109/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8295 - val_loss: 0.5205\n",
            "Epoch 2110/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9076 - val_loss: 0.6177\n",
            "Epoch 2111/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8978 - val_loss: 0.7297\n",
            "Epoch 2112/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.7998 - val_loss: 0.5765\n",
            "Epoch 2113/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.9107 - val_loss: 0.6120\n",
            "Epoch 2114/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8419 - val_loss: 0.8788\n",
            "Epoch 2115/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8455 - val_loss: 0.7327\n",
            "Epoch 2116/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8545 - val_loss: 0.5973\n",
            "Epoch 2117/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8708 - val_loss: 0.6548\n",
            "Epoch 2118/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8223 - val_loss: 0.6587\n",
            "Epoch 2119/5000\n",
            "33/33 [==============================] - 1s 20ms/step - loss: 0.8252 - val_loss: 0.4536\n",
            "Epoch 2120/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8496 - val_loss: 0.6293\n",
            "Epoch 2121/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8127 - val_loss: 0.7915\n",
            "Epoch 2122/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9662 - val_loss: 0.6533\n",
            "Epoch 2123/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8634 - val_loss: 0.6095\n",
            "Epoch 2124/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9055 - val_loss: 0.5301\n",
            "Epoch 2125/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8360 - val_loss: 0.6372\n",
            "Epoch 2126/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8717 - val_loss: 0.5162\n",
            "Epoch 2127/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9446 - val_loss: 0.6015\n",
            "Epoch 2128/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8523 - val_loss: 0.5078\n",
            "Epoch 2129/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8403 - val_loss: 0.7040\n",
            "Epoch 2130/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8249 - val_loss: 0.6286\n",
            "Epoch 2131/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8500 - val_loss: 0.6771\n",
            "Epoch 2132/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8296 - val_loss: 0.6565\n",
            "Epoch 2133/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9015 - val_loss: 0.5981\n",
            "Epoch 2134/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8865 - val_loss: 0.5748\n",
            "Epoch 2135/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8408 - val_loss: 0.5803\n",
            "Epoch 2136/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8842 - val_loss: 0.6675\n",
            "Epoch 2137/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8359 - val_loss: 0.5231\n",
            "Epoch 2138/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9224 - val_loss: 0.6290\n",
            "Epoch 2139/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8645 - val_loss: 0.6340\n",
            "Epoch 2140/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.9556 - val_loss: 0.5605\n",
            "Epoch 2141/5000\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.8271 - val_loss: 0.7687\n",
            "Epoch 2142/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8836 - val_loss: 0.6370\n",
            "Epoch 2143/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8748 - val_loss: 0.5627\n",
            "Epoch 2144/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8229 - val_loss: 0.6387\n",
            "Epoch 2145/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8352 - val_loss: 0.4655\n",
            "Epoch 2146/5000\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 1.0455 - val_loss: 0.6703\n",
            "Epoch 2147/5000\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.8095 - val_loss: 0.5043\n",
            "Epoch 2148/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8604 - val_loss: 0.6965\n",
            "Epoch 2149/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7835 - val_loss: 0.6978\n",
            "Epoch 2150/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8431 - val_loss: 0.5810\n",
            "Epoch 2151/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8569 - val_loss: 0.5887\n",
            "Epoch 2152/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8026 - val_loss: 0.6630\n",
            "Epoch 2153/5000\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.9083 - val_loss: 0.5978\n",
            "Epoch 2154/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8612 - val_loss: 0.7121\n",
            "Epoch 2155/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8663 - val_loss: 0.6579\n",
            "Epoch 2156/5000\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.9073 - val_loss: 0.5010\n",
            "Epoch 2157/5000\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.8676 - val_loss: 0.5983\n",
            "Epoch 2158/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8582 - val_loss: 0.6137\n",
            "Epoch 2159/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8272 - val_loss: 0.6061\n",
            "Epoch 2160/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.7945 - val_loss: 0.7630\n",
            "Epoch 2161/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9240 - val_loss: 0.8639\n",
            "Epoch 2162/5000\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.8516 - val_loss: 0.5462\n",
            "Epoch 2163/5000\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.8388 - val_loss: 0.4791\n",
            "Epoch 2164/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8887 - val_loss: 0.5013\n",
            "Epoch 2165/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8996 - val_loss: 0.6378\n",
            "Epoch 2166/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9458 - val_loss: 0.5390\n",
            "Epoch 2167/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8508 - val_loss: 0.5620\n",
            "Epoch 2168/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8053 - val_loss: 0.5749\n",
            "Epoch 2169/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.9156 - val_loss: 0.9017\n",
            "Epoch 2170/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8084 - val_loss: 0.5763\n",
            "Epoch 2171/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8983 - val_loss: 0.6616\n",
            "Epoch 2172/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8540 - val_loss: 0.5220\n",
            "Epoch 2173/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8724 - val_loss: 0.5038\n",
            "Epoch 2174/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9629 - val_loss: 0.5685\n",
            "Epoch 2175/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8607 - val_loss: 0.5467\n",
            "Epoch 2176/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9067 - val_loss: 0.4993\n",
            "Epoch 2177/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9319 - val_loss: 0.5670\n",
            "Epoch 2178/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8170 - val_loss: 0.5812\n",
            "Epoch 2179/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8437 - val_loss: 0.7236\n",
            "Epoch 2180/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7964 - val_loss: 0.6003\n",
            "Epoch 2181/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9863 - val_loss: 0.7441\n",
            "Epoch 2182/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8901 - val_loss: 0.5430\n",
            "Epoch 2183/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8535 - val_loss: 0.6177\n",
            "Epoch 2184/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8224 - val_loss: 0.6029\n",
            "Epoch 2185/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8754 - val_loss: 0.6071\n",
            "Epoch 2186/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8555 - val_loss: 0.5281\n",
            "Epoch 2187/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8612 - val_loss: 0.5520\n",
            "Epoch 2188/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9288 - val_loss: 0.6516\n",
            "Epoch 2189/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9023 - val_loss: 0.5813\n",
            "Epoch 2190/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8414 - val_loss: 0.4870\n",
            "Epoch 2191/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8945 - val_loss: 0.4979\n",
            "Epoch 2192/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8708 - val_loss: 0.4951\n",
            "Epoch 2193/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8245 - val_loss: 0.8211\n",
            "Epoch 2194/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8969 - val_loss: 0.6147\n",
            "Epoch 2195/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9093 - val_loss: 0.5589\n",
            "Epoch 2196/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8409 - val_loss: 0.5726\n",
            "Epoch 2197/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8658 - val_loss: 0.6559\n",
            "Epoch 2198/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9412 - val_loss: 0.8300\n",
            "Epoch 2199/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8985 - val_loss: 0.5749\n",
            "Epoch 2200/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8396 - val_loss: 0.7481\n",
            "Epoch 2201/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8639 - val_loss: 0.7926\n",
            "Epoch 2202/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8535 - val_loss: 0.4772\n",
            "Epoch 2203/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8405 - val_loss: 0.6144\n",
            "Epoch 2204/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8405 - val_loss: 0.7908\n",
            "Epoch 2205/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8554 - val_loss: 0.5875\n",
            "Epoch 2206/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8472 - val_loss: 0.4672\n",
            "Epoch 2207/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8451 - val_loss: 0.5928\n",
            "Epoch 2208/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9684 - val_loss: 0.5806\n",
            "Epoch 2209/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8855 - val_loss: 0.6068\n",
            "Epoch 2210/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8410 - val_loss: 0.5755\n",
            "Epoch 2211/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8382 - val_loss: 0.6548\n",
            "Epoch 2212/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8270 - val_loss: 0.7055\n",
            "Epoch 2213/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8238 - val_loss: 0.7144\n",
            "Epoch 2214/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8287 - val_loss: 0.6336\n",
            "Epoch 2215/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8185 - val_loss: 0.6047\n",
            "Epoch 2216/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8213 - val_loss: 0.5705\n",
            "Epoch 2217/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8656 - val_loss: 0.7139\n",
            "Epoch 2218/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8109 - val_loss: 0.6482\n",
            "Epoch 2219/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8217 - val_loss: 0.6047\n",
            "Epoch 2220/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8784 - val_loss: 0.5436\n",
            "Epoch 2221/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9015 - val_loss: 0.6497\n",
            "Epoch 2222/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8774 - val_loss: 0.5314\n",
            "Epoch 2223/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9067 - val_loss: 0.6485\n",
            "Epoch 2224/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8107 - val_loss: 0.6989\n",
            "Epoch 2225/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8685 - val_loss: 0.6110\n",
            "Epoch 2226/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8662 - val_loss: 0.6890\n",
            "Epoch 2227/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8741 - val_loss: 0.5914\n",
            "Epoch 2228/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8659 - val_loss: 0.4882\n",
            "Epoch 2229/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9003 - val_loss: 0.7105\n",
            "Epoch 2230/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7909 - val_loss: 0.5707\n",
            "Epoch 2231/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8316 - val_loss: 0.6167\n",
            "Epoch 2232/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8267 - val_loss: 0.6731\n",
            "Epoch 2233/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8851 - val_loss: 0.5414\n",
            "Epoch 2234/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8467 - val_loss: 0.5066\n",
            "Epoch 2235/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8170 - val_loss: 0.6614\n",
            "Epoch 2236/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8265 - val_loss: 0.6669\n",
            "Epoch 2237/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8429 - val_loss: 0.8202\n",
            "Epoch 2238/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9158 - val_loss: 0.5570\n",
            "Epoch 2239/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8526 - val_loss: 0.7181\n",
            "Epoch 2240/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8621 - val_loss: 0.6429\n",
            "Epoch 2241/5000\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.8665 - val_loss: 0.5398\n",
            "Epoch 2242/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8519 - val_loss: 0.5438\n",
            "Epoch 2243/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8590 - val_loss: 0.5674\n",
            "Epoch 2244/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9410 - val_loss: 0.7908\n",
            "Epoch 2245/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8629 - val_loss: 0.6890\n",
            "Epoch 2246/5000\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.9310 - val_loss: 0.6601\n",
            "Epoch 2247/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8614 - val_loss: 0.5471\n",
            "Epoch 2248/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.9064 - val_loss: 0.5285\n",
            "Epoch 2249/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8513 - val_loss: 0.5883\n",
            "Epoch 2250/5000\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.8859 - val_loss: 0.5073\n",
            "Epoch 2251/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8516 - val_loss: 0.5947\n",
            "Epoch 2252/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8626 - val_loss: 0.8036\n",
            "Epoch 2253/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8508 - val_loss: 0.4772\n",
            "Epoch 2254/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8279 - val_loss: 0.4875\n",
            "Epoch 2255/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8216 - val_loss: 0.5211\n",
            "Epoch 2256/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.9219 - val_loss: 0.6282\n",
            "Epoch 2257/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8151 - val_loss: 0.5859\n",
            "Epoch 2258/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9023 - val_loss: 0.5825\n",
            "Epoch 2259/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8974 - val_loss: 0.5047\n",
            "Epoch 2260/5000\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.8766 - val_loss: 0.5958\n",
            "Epoch 2261/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.9058 - val_loss: 0.5493\n",
            "Epoch 2262/5000\n",
            "33/33 [==============================] - 0s 8ms/step - loss: 0.8633 - val_loss: 0.6001\n",
            "Epoch 2263/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8848 - val_loss: 0.6622\n",
            "Epoch 2264/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8385 - val_loss: 0.4923\n",
            "Epoch 2265/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.9060 - val_loss: 0.5610\n",
            "Epoch 2266/5000\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.9275 - val_loss: 0.5491\n",
            "Epoch 2267/5000\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.9608 - val_loss: 0.5814\n",
            "Epoch 2268/5000\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.8510 - val_loss: 0.5433\n",
            "Epoch 2269/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8507 - val_loss: 1.0074\n",
            "Epoch 2270/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9281 - val_loss: 0.5969\n",
            "Epoch 2271/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9034 - val_loss: 0.5821\n",
            "Epoch 2272/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8757 - val_loss: 0.5093\n",
            "Epoch 2273/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8493 - val_loss: 0.6196\n",
            "Epoch 2274/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8655 - val_loss: 0.5188\n",
            "Epoch 2275/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9869 - val_loss: 0.6183\n",
            "Epoch 2276/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8437 - val_loss: 0.5941\n",
            "Epoch 2277/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9212 - val_loss: 0.7638\n",
            "Epoch 2278/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8511 - val_loss: 0.6120\n",
            "Epoch 2279/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8978 - val_loss: 0.5267\n",
            "Epoch 2280/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8257 - val_loss: 0.5555\n",
            "Epoch 2281/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8019 - val_loss: 0.5146\n",
            "Epoch 2282/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9295 - val_loss: 0.5340\n",
            "Epoch 2283/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8650 - val_loss: 0.5640\n",
            "Epoch 2284/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8362 - val_loss: 0.6246\n",
            "Epoch 2285/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7993 - val_loss: 0.6685\n",
            "Epoch 2286/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8537 - val_loss: 0.5890\n",
            "Epoch 2287/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8667 - val_loss: 0.6072\n",
            "Epoch 2288/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9103 - val_loss: 0.7742\n",
            "Epoch 2289/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7836 - val_loss: 0.6089\n",
            "Epoch 2290/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8105 - val_loss: 0.5491\n",
            "Epoch 2291/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9414 - val_loss: 0.6185\n",
            "Epoch 2292/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8406 - val_loss: 0.6598\n",
            "Epoch 2293/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8187 - val_loss: 0.5142\n",
            "Epoch 2294/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8621 - val_loss: 0.5725\n",
            "Epoch 2295/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8434 - val_loss: 0.5968\n",
            "Epoch 2296/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8493 - val_loss: 0.8573\n",
            "Epoch 2297/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8549 - val_loss: 0.6208\n",
            "Epoch 2298/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8660 - val_loss: 0.7127\n",
            "Epoch 2299/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9001 - val_loss: 0.5264\n",
            "Epoch 2300/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8096 - val_loss: 1.1645\n",
            "Epoch 2301/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9072 - val_loss: 0.6390\n",
            "Epoch 2302/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8587 - val_loss: 0.6588\n",
            "Epoch 2303/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8646 - val_loss: 0.4661\n",
            "Epoch 2304/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8480 - val_loss: 0.5881\n",
            "Epoch 2305/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8783 - val_loss: 0.5431\n",
            "Epoch 2306/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9088 - val_loss: 0.6912\n",
            "Epoch 2307/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8909 - val_loss: 0.5008\n",
            "Epoch 2308/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8628 - val_loss: 0.7245\n",
            "Epoch 2309/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8360 - val_loss: 0.5847\n",
            "Epoch 2310/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8827 - val_loss: 0.6890\n",
            "Epoch 2311/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8239 - val_loss: 0.7138\n",
            "Epoch 2312/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8992 - val_loss: 0.6597\n",
            "Epoch 2313/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8896 - val_loss: 0.6326\n",
            "Epoch 2314/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8328 - val_loss: 0.7957\n",
            "Epoch 2315/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8082 - val_loss: 0.6183\n",
            "Epoch 2316/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8919 - val_loss: 0.6673\n",
            "Epoch 2317/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8434 - val_loss: 0.7040\n",
            "Epoch 2318/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8119 - val_loss: 0.6538\n",
            "Epoch 2319/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8998 - val_loss: 0.8607\n",
            "Epoch 2320/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8503 - val_loss: 1.0388\n",
            "Epoch 2321/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8222 - val_loss: 0.6217\n",
            "Epoch 2322/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9274 - val_loss: 0.6194\n",
            "Epoch 2323/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9366 - val_loss: 0.9499\n",
            "Epoch 2324/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.7872 - val_loss: 0.6769\n",
            "Epoch 2325/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8016 - val_loss: 0.6957\n",
            "Epoch 2326/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8709 - val_loss: 0.5595\n",
            "Epoch 2327/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8909 - val_loss: 0.6024\n",
            "Epoch 2328/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8678 - val_loss: 0.6870\n",
            "Epoch 2329/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8642 - val_loss: 0.5717\n",
            "Epoch 2330/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8827 - val_loss: 0.5691\n",
            "Epoch 2331/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9229 - val_loss: 0.5043\n",
            "Epoch 2332/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9833 - val_loss: 0.5842\n",
            "Epoch 2333/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8568 - val_loss: 0.6076\n",
            "Epoch 2334/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8640 - val_loss: 0.6645\n",
            "Epoch 2335/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8854 - val_loss: 0.5091\n",
            "Epoch 2336/5000\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.8248 - val_loss: 0.5714\n",
            "Epoch 2337/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8343 - val_loss: 0.6386\n",
            "Epoch 2338/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8613 - val_loss: 0.5402\n",
            "Epoch 2339/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8861 - val_loss: 0.5329\n",
            "Epoch 2340/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8569 - val_loss: 0.5805\n",
            "Epoch 2341/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8487 - val_loss: 0.7417\n",
            "Epoch 2342/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8631 - val_loss: 0.6049\n",
            "Epoch 2343/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8753 - val_loss: 0.7604\n",
            "Epoch 2344/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9198 - val_loss: 0.8231\n",
            "Epoch 2345/5000\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.8644 - val_loss: 0.5805\n",
            "Epoch 2346/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8418 - val_loss: 0.6203\n",
            "Epoch 2347/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.9105 - val_loss: 0.6674\n",
            "Epoch 2348/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8727 - val_loss: 0.5430\n",
            "Epoch 2349/5000\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.9152 - val_loss: 0.5976\n",
            "Epoch 2350/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8177 - val_loss: 0.6409\n",
            "Epoch 2351/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8651 - val_loss: 0.5172\n",
            "Epoch 2352/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8178 - val_loss: 0.5768\n",
            "Epoch 2353/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8720 - val_loss: 0.6687\n",
            "Epoch 2354/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8210 - val_loss: 0.6934\n",
            "Epoch 2355/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8486 - val_loss: 0.7741\n",
            "Epoch 2356/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8660 - val_loss: 0.5187\n",
            "Epoch 2357/5000\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.8475 - val_loss: 0.5222\n",
            "Epoch 2358/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.9768 - val_loss: 0.7349\n",
            "Epoch 2359/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8714 - val_loss: 0.6444\n",
            "Epoch 2360/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8971 - val_loss: 0.6561\n",
            "Epoch 2361/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8111 - val_loss: 0.6739\n",
            "Epoch 2362/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8359 - val_loss: 0.6613\n",
            "Epoch 2363/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8107 - val_loss: 0.6699\n",
            "Epoch 2364/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8537 - val_loss: 0.6582\n",
            "Epoch 2365/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8321 - val_loss: 0.8027\n",
            "Epoch 2366/5000\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.8499 - val_loss: 0.6884\n",
            "Epoch 2367/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8286 - val_loss: 0.5132\n",
            "Epoch 2368/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8672 - val_loss: 0.6022\n",
            "Epoch 2369/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8117 - val_loss: 0.6701\n",
            "Epoch 2370/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8922 - val_loss: 0.6711\n",
            "Epoch 2371/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8031 - val_loss: 0.5962\n",
            "Epoch 2372/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8635 - val_loss: 0.5864\n",
            "Epoch 2373/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9688 - val_loss: 0.5340\n",
            "Epoch 2374/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9561 - val_loss: 0.6172\n",
            "Epoch 2375/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8345 - val_loss: 0.5379\n",
            "Epoch 2376/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9454 - val_loss: 0.5957\n",
            "Epoch 2377/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8430 - val_loss: 0.5606\n",
            "Epoch 2378/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8458 - val_loss: 0.5312\n",
            "Epoch 2379/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8767 - val_loss: 0.6354\n",
            "Epoch 2380/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7886 - val_loss: 0.6047\n",
            "Epoch 2381/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8301 - val_loss: 0.7240\n",
            "Epoch 2382/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9043 - val_loss: 0.7083\n",
            "Epoch 2383/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8554 - val_loss: 0.5889\n",
            "Epoch 2384/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8872 - val_loss: 0.5546\n",
            "Epoch 2385/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7802 - val_loss: 0.7117\n",
            "Epoch 2386/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8662 - val_loss: 0.6188\n",
            "Epoch 2387/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9128 - val_loss: 0.6128\n",
            "Epoch 2388/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8313 - val_loss: 0.6461\n",
            "Epoch 2389/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8646 - val_loss: 0.6269\n",
            "Epoch 2390/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8467 - val_loss: 0.7198\n",
            "Epoch 2391/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8917 - val_loss: 0.4691\n",
            "Epoch 2392/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8881 - val_loss: 0.6567\n",
            "Epoch 2393/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8233 - val_loss: 0.5441\n",
            "Epoch 2394/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8632 - val_loss: 0.7031\n",
            "Epoch 2395/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8471 - val_loss: 0.5643\n",
            "Epoch 2396/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8420 - val_loss: 0.5841\n",
            "Epoch 2397/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8290 - val_loss: 0.6523\n",
            "Epoch 2398/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8768 - val_loss: 0.4623\n",
            "Epoch 2399/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8878 - val_loss: 0.6225\n",
            "Epoch 2400/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8678 - val_loss: 0.6649\n",
            "Epoch 2401/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8204 - val_loss: 0.8660\n",
            "Epoch 2402/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7952 - val_loss: 0.6857\n",
            "Epoch 2403/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8578 - val_loss: 0.7410\n",
            "Epoch 2404/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8283 - val_loss: 0.8104\n",
            "Epoch 2405/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8259 - val_loss: 0.6686\n",
            "Epoch 2406/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8753 - val_loss: 0.5881\n",
            "Epoch 2407/5000\n",
            "33/33 [==============================] - 1s 20ms/step - loss: 0.8911 - val_loss: 0.4523\n",
            "Epoch 2408/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8839 - val_loss: 0.5516\n",
            "Epoch 2409/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8526 - val_loss: 0.5505\n",
            "Epoch 2410/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8774 - val_loss: 0.6461\n",
            "Epoch 2411/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8240 - val_loss: 0.5281\n",
            "Epoch 2412/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8620 - val_loss: 0.6070\n",
            "Epoch 2413/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9156 - val_loss: 0.5204\n",
            "Epoch 2414/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9275 - val_loss: 0.5584\n",
            "Epoch 2415/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8865 - val_loss: 0.7178\n",
            "Epoch 2416/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9132 - val_loss: 0.6077\n",
            "Epoch 2417/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8233 - val_loss: 0.6442\n",
            "Epoch 2418/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9232 - val_loss: 0.6931\n",
            "Epoch 2419/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8667 - val_loss: 0.5526\n",
            "Epoch 2420/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8842 - val_loss: 0.5041\n",
            "Epoch 2421/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8270 - val_loss: 0.5692\n",
            "Epoch 2422/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9769 - val_loss: 0.7488\n",
            "Epoch 2423/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8745 - val_loss: 0.5862\n",
            "Epoch 2424/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8651 - val_loss: 0.7241\n",
            "Epoch 2425/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8986 - val_loss: 0.5549\n",
            "Epoch 2426/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7969 - val_loss: 0.6984\n",
            "Epoch 2427/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.1214 - val_loss: 0.6712\n",
            "Epoch 2428/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8346 - val_loss: 0.5429\n",
            "Epoch 2429/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8436 - val_loss: 0.9943\n",
            "Epoch 2430/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8373 - val_loss: 0.6918\n",
            "Epoch 2431/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9435 - val_loss: 0.5819\n",
            "Epoch 2432/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8838 - val_loss: 0.7543\n",
            "Epoch 2433/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8997 - val_loss: 0.7107\n",
            "Epoch 2434/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8317 - val_loss: 0.6720\n",
            "Epoch 2435/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.9901 - val_loss: 0.4833\n",
            "Epoch 2436/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.9498 - val_loss: 0.6598\n",
            "Epoch 2437/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8432 - val_loss: 0.6775\n",
            "Epoch 2438/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8086 - val_loss: 0.4665\n",
            "Epoch 2439/5000\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 1.0000 - val_loss: 0.5305\n",
            "Epoch 2440/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7893 - val_loss: 0.6370\n",
            "Epoch 2441/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.0422 - val_loss: 0.6160\n",
            "Epoch 2442/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.9031 - val_loss: 0.5074\n",
            "Epoch 2443/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8577 - val_loss: 0.6864\n",
            "Epoch 2444/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8052 - val_loss: 0.6664\n",
            "Epoch 2445/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8665 - val_loss: 0.5767\n",
            "Epoch 2446/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9213 - val_loss: 0.7913\n",
            "Epoch 2447/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9053 - val_loss: 0.5570\n",
            "Epoch 2448/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8961 - val_loss: 0.5190\n",
            "Epoch 2449/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8842 - val_loss: 0.6546\n",
            "Epoch 2450/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.7996 - val_loss: 0.4843\n",
            "Epoch 2451/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8336 - val_loss: 0.6125\n",
            "Epoch 2452/5000\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.8158 - val_loss: 0.4934\n",
            "Epoch 2453/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8460 - val_loss: 0.6386\n",
            "Epoch 2454/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8564 - val_loss: 0.4849\n",
            "Epoch 2455/5000\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.8242 - val_loss: 0.6992\n",
            "Epoch 2456/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8702 - val_loss: 0.7440\n",
            "Epoch 2457/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8530 - val_loss: 0.6399\n",
            "Epoch 2458/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.9047 - val_loss: 0.7186\n",
            "Epoch 2459/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8233 - val_loss: 0.7170\n",
            "Epoch 2460/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.9226 - val_loss: 0.5456\n",
            "Epoch 2461/5000\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.9404 - val_loss: 0.7376\n",
            "Epoch 2462/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8633 - val_loss: 0.5857\n",
            "Epoch 2463/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.9043 - val_loss: 0.7370\n",
            "Epoch 2464/5000\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.8541 - val_loss: 0.6496\n",
            "Epoch 2465/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.9456 - val_loss: 0.5361\n",
            "Epoch 2466/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8535 - val_loss: 0.5638\n",
            "Epoch 2467/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8563 - val_loss: 0.5369\n",
            "Epoch 2468/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8285 - val_loss: 0.7173\n",
            "Epoch 2469/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9013 - val_loss: 0.5356\n",
            "Epoch 2470/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9285 - val_loss: 0.4735\n",
            "Epoch 2471/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8929 - val_loss: 0.4968\n",
            "Epoch 2472/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8344 - val_loss: 0.5905\n",
            "Epoch 2473/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8769 - val_loss: 0.5574\n",
            "Epoch 2474/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8299 - val_loss: 0.5950\n",
            "Epoch 2475/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7797 - val_loss: 0.5019\n",
            "Epoch 2476/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8118 - val_loss: 0.7225\n",
            "Epoch 2477/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9392 - val_loss: 0.5811\n",
            "Epoch 2478/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8724 - val_loss: 0.5975\n",
            "Epoch 2479/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8728 - val_loss: 0.5905\n",
            "Epoch 2480/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8478 - val_loss: 0.6694\n",
            "Epoch 2481/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8456 - val_loss: 0.6058\n",
            "Epoch 2482/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9017 - val_loss: 0.6386\n",
            "Epoch 2483/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9108 - val_loss: 0.5797\n",
            "Epoch 2484/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9137 - val_loss: 0.5585\n",
            "Epoch 2485/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9050 - val_loss: 0.7133\n",
            "Epoch 2486/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8458 - val_loss: 0.7268\n",
            "Epoch 2487/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9341 - val_loss: 0.5700\n",
            "Epoch 2488/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8421 - val_loss: 0.6837\n",
            "Epoch 2489/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9352 - val_loss: 0.6090\n",
            "Epoch 2490/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9313 - val_loss: 0.6562\n",
            "Epoch 2491/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8351 - val_loss: 0.9548\n",
            "Epoch 2492/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8572 - val_loss: 0.5518\n",
            "Epoch 2493/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9440 - val_loss: 0.5800\n",
            "Epoch 2494/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9922 - val_loss: 0.7464\n",
            "Epoch 2495/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8336 - val_loss: 0.4951\n",
            "Epoch 2496/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8414 - val_loss: 0.5964\n",
            "Epoch 2497/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8196 - val_loss: 0.4947\n",
            "Epoch 2498/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7757 - val_loss: 0.5912\n",
            "Epoch 2499/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8723 - val_loss: 0.7408\n",
            "Epoch 2500/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7965 - val_loss: 0.6190\n",
            "Epoch 2501/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9487 - val_loss: 0.6427\n",
            "Epoch 2502/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8051 - val_loss: 0.5653\n",
            "Epoch 2503/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9249 - val_loss: 0.5226\n",
            "Epoch 2504/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8814 - val_loss: 0.6030\n",
            "Epoch 2505/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8758 - val_loss: 0.6223\n",
            "Epoch 2506/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8443 - val_loss: 0.5824\n",
            "Epoch 2507/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8514 - val_loss: 0.6170\n",
            "Epoch 2508/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8419 - val_loss: 0.6059\n",
            "Epoch 2509/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8779 - val_loss: 0.6175\n",
            "Epoch 2510/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8343 - val_loss: 0.5109\n",
            "Epoch 2511/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9053 - val_loss: 0.4594\n",
            "Epoch 2512/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8179 - val_loss: 0.7270\n",
            "Epoch 2513/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8685 - val_loss: 0.5861\n",
            "Epoch 2514/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8839 - val_loss: 0.5468\n",
            "Epoch 2515/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8479 - val_loss: 0.5849\n",
            "Epoch 2516/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8771 - val_loss: 0.7788\n",
            "Epoch 2517/5000\n",
            "33/33 [==============================] - 1s 26ms/step - loss: 0.9161 - val_loss: 0.4475\n",
            "Epoch 2518/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8256 - val_loss: 0.6569\n",
            "Epoch 2519/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9021 - val_loss: 0.5908\n",
            "Epoch 2520/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8578 - val_loss: 0.4614\n",
            "Epoch 2521/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9345 - val_loss: 0.5727\n",
            "Epoch 2522/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8860 - val_loss: 0.6406\n",
            "Epoch 2523/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8833 - val_loss: 0.5532\n",
            "Epoch 2524/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8613 - val_loss: 0.6591\n",
            "Epoch 2525/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8427 - val_loss: 0.5917\n",
            "Epoch 2526/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9314 - val_loss: 0.5651\n",
            "Epoch 2527/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8859 - val_loss: 0.6772\n",
            "Epoch 2528/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8899 - val_loss: 0.6068\n",
            "Epoch 2529/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8095 - val_loss: 0.6894\n",
            "Epoch 2530/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 1.1099 - val_loss: 0.6314\n",
            "Epoch 2531/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.7990 - val_loss: 0.6660\n",
            "Epoch 2532/5000\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.8480 - val_loss: 0.5864\n",
            "Epoch 2533/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8443 - val_loss: 0.6893\n",
            "Epoch 2534/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.9515 - val_loss: 0.7930\n",
            "Epoch 2535/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8847 - val_loss: 0.7907\n",
            "Epoch 2536/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.9410 - val_loss: 0.5342\n",
            "Epoch 2537/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9085 - val_loss: 0.8187\n",
            "Epoch 2538/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8313 - val_loss: 0.6702\n",
            "Epoch 2539/5000\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.9180 - val_loss: 0.5443\n",
            "Epoch 2540/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8774 - val_loss: 0.6795\n",
            "Epoch 2541/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9111 - val_loss: 0.5113\n",
            "Epoch 2542/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9231 - val_loss: 0.6494\n",
            "Epoch 2543/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8994 - val_loss: 0.5740\n",
            "Epoch 2544/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9028 - val_loss: 0.7949\n",
            "Epoch 2545/5000\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.9198 - val_loss: 0.5701\n",
            "Epoch 2546/5000\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.9532 - val_loss: 0.5736\n",
            "Epoch 2547/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.9531 - val_loss: 0.7544\n",
            "Epoch 2548/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8834 - val_loss: 0.5860\n",
            "Epoch 2549/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8761 - val_loss: 0.7525\n",
            "Epoch 2550/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8558 - val_loss: 0.6859\n",
            "Epoch 2551/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9279 - val_loss: 0.6380\n",
            "Epoch 2552/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8520 - val_loss: 0.6615\n",
            "Epoch 2553/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8891 - val_loss: 0.5959\n",
            "Epoch 2554/5000\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.8542 - val_loss: 0.6315\n",
            "Epoch 2555/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9330 - val_loss: 0.5605\n",
            "Epoch 2556/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8954 - val_loss: 0.4982\n",
            "Epoch 2557/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8456 - val_loss: 0.5973\n",
            "Epoch 2558/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8132 - val_loss: 0.6028\n",
            "Epoch 2559/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8477 - val_loss: 0.6425\n",
            "Epoch 2560/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8460 - val_loss: 0.7569\n",
            "Epoch 2561/5000\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.9932 - val_loss: 0.7828\n",
            "Epoch 2562/5000\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.7849 - val_loss: 0.8045\n",
            "Epoch 2563/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8910 - val_loss: 0.7529\n",
            "Epoch 2564/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8674 - val_loss: 0.7162\n",
            "Epoch 2565/5000\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.9665 - val_loss: 0.5601\n",
            "Epoch 2566/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7982 - val_loss: 0.7424\n",
            "Epoch 2567/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.9274 - val_loss: 0.5425\n",
            "Epoch 2568/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8680 - val_loss: 0.6608\n",
            "Epoch 2569/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8319 - val_loss: 0.6479\n",
            "Epoch 2570/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8133 - val_loss: 0.5788\n",
            "Epoch 2571/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9754 - val_loss: 0.5760\n",
            "Epoch 2572/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8140 - val_loss: 0.8081\n",
            "Epoch 2573/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8505 - val_loss: 0.6298\n",
            "Epoch 2574/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8299 - val_loss: 0.6197\n",
            "Epoch 2575/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8811 - val_loss: 0.6752\n",
            "Epoch 2576/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8350 - val_loss: 0.6730\n",
            "Epoch 2577/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8014 - val_loss: 0.5127\n",
            "Epoch 2578/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8118 - val_loss: 0.6596\n",
            "Epoch 2579/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8785 - val_loss: 0.7280\n",
            "Epoch 2580/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8214 - val_loss: 0.5321\n",
            "Epoch 2581/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8398 - val_loss: 0.6600\n",
            "Epoch 2582/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8479 - val_loss: 0.7429\n",
            "Epoch 2583/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8992 - val_loss: 0.6178\n",
            "Epoch 2584/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8050 - val_loss: 0.5930\n",
            "Epoch 2585/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8127 - val_loss: 0.6070\n",
            "Epoch 2586/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9695 - val_loss: 0.6739\n",
            "Epoch 2587/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9541 - val_loss: 0.8771\n",
            "Epoch 2588/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9952 - val_loss: 0.5437\n",
            "Epoch 2589/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9299 - val_loss: 0.5280\n",
            "Epoch 2590/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8376 - val_loss: 0.5933\n",
            "Epoch 2591/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9480 - val_loss: 0.5665\n",
            "Epoch 2592/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8823 - val_loss: 0.5939\n",
            "Epoch 2593/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8912 - val_loss: 0.6477\n",
            "Epoch 2594/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8022 - val_loss: 0.5800\n",
            "Epoch 2595/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8850 - val_loss: 0.5353\n",
            "Epoch 2596/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8649 - val_loss: 0.6227\n",
            "Epoch 2597/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8658 - val_loss: 0.5746\n",
            "Epoch 2598/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9020 - val_loss: 0.8875\n",
            "Epoch 2599/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8568 - val_loss: 0.5718\n",
            "Epoch 2600/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8454 - val_loss: 0.5420\n",
            "Epoch 2601/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9091 - val_loss: 0.9853\n",
            "Epoch 2602/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9469 - val_loss: 0.6285\n",
            "Epoch 2603/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8280 - val_loss: 0.6227\n",
            "Epoch 2604/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8837 - val_loss: 0.5449\n",
            "Epoch 2605/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8207 - val_loss: 0.5602\n",
            "Epoch 2606/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8448 - val_loss: 0.5842\n",
            "Epoch 2607/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8056 - val_loss: 0.6608\n",
            "Epoch 2608/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8516 - val_loss: 0.5465\n",
            "Epoch 2609/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8855 - val_loss: 0.5688\n",
            "Epoch 2610/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8586 - val_loss: 0.6213\n",
            "Epoch 2611/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8057 - val_loss: 0.7961\n",
            "Epoch 2612/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8069 - val_loss: 0.6661\n",
            "Epoch 2613/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9430 - val_loss: 0.6050\n",
            "Epoch 2614/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8735 - val_loss: 0.5383\n",
            "Epoch 2615/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9404 - val_loss: 0.6006\n",
            "Epoch 2616/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8582 - val_loss: 0.7320\n",
            "Epoch 2617/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8789 - val_loss: 0.6204\n",
            "Epoch 2618/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8734 - val_loss: 0.6347\n",
            "Epoch 2619/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9101 - val_loss: 0.7185\n",
            "Epoch 2620/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8493 - val_loss: 0.7278\n",
            "Epoch 2621/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8124 - val_loss: 0.6401\n",
            "Epoch 2622/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8939 - val_loss: 0.5866\n",
            "Epoch 2623/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8152 - val_loss: 0.7053\n",
            "Epoch 2624/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9742 - val_loss: 0.5902\n",
            "Epoch 2625/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8269 - val_loss: 0.5653\n",
            "Epoch 2626/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7970 - val_loss: 0.5707\n",
            "Epoch 2627/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9473 - val_loss: 0.5669\n",
            "Epoch 2628/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9180 - val_loss: 0.5332\n",
            "Epoch 2629/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.9154 - val_loss: 0.5779\n",
            "Epoch 2630/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9443 - val_loss: 0.6417\n",
            "Epoch 2631/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8824 - val_loss: 0.6095\n",
            "Epoch 2632/5000\n",
            "33/33 [==============================] - 0s 8ms/step - loss: 0.8610 - val_loss: 0.5379\n",
            "Epoch 2633/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8539 - val_loss: 0.5446\n",
            "Epoch 2634/5000\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.8567 - val_loss: 0.5681\n",
            "Epoch 2635/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8629 - val_loss: 0.5613\n",
            "Epoch 2636/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.9893 - val_loss: 0.6238\n",
            "Epoch 2637/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8532 - val_loss: 0.8692\n",
            "Epoch 2638/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8715 - val_loss: 0.5856\n",
            "Epoch 2639/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.9204 - val_loss: 0.5559\n",
            "Epoch 2640/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8657 - val_loss: 0.5974\n",
            "Epoch 2641/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8673 - val_loss: 0.6855\n",
            "Epoch 2642/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8733 - val_loss: 0.5857\n",
            "Epoch 2643/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8566 - val_loss: 0.5886\n",
            "Epoch 2644/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8051 - val_loss: 0.5411\n",
            "Epoch 2645/5000\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.8476 - val_loss: 0.5738\n",
            "Epoch 2646/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8182 - val_loss: 0.6071\n",
            "Epoch 2647/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8699 - val_loss: 0.6421\n",
            "Epoch 2648/5000\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 1.0067 - val_loss: 0.7036\n",
            "Epoch 2649/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8308 - val_loss: 0.6292\n",
            "Epoch 2650/5000\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.8840 - val_loss: 0.5543\n",
            "Epoch 2651/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8465 - val_loss: 0.6102\n",
            "Epoch 2652/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8949 - val_loss: 0.5789\n",
            "Epoch 2653/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.9213 - val_loss: 0.5909\n",
            "Epoch 2654/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9188 - val_loss: 0.6432\n",
            "Epoch 2655/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8656 - val_loss: 0.5863\n",
            "Epoch 2656/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8996 - val_loss: 0.6137\n",
            "Epoch 2657/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9074 - val_loss: 0.4723\n",
            "Epoch 2658/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8139 - val_loss: 0.5710\n",
            "Epoch 2659/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8202 - val_loss: 0.4820\n",
            "Epoch 2660/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8207 - val_loss: 0.9019\n",
            "Epoch 2661/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9248 - val_loss: 0.6512\n",
            "Epoch 2662/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8797 - val_loss: 0.6168\n",
            "Epoch 2663/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.9207 - val_loss: 0.5706\n",
            "Epoch 2664/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8881 - val_loss: 0.6227\n",
            "Epoch 2665/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8086 - val_loss: 0.6535\n",
            "Epoch 2666/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8095 - val_loss: 0.6158\n",
            "Epoch 2667/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.7819 - val_loss: 0.7213\n",
            "Epoch 2668/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8237 - val_loss: 0.6273\n",
            "Epoch 2669/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8052 - val_loss: 0.6512\n",
            "Epoch 2670/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.9166 - val_loss: 0.5979\n",
            "Epoch 2671/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8224 - val_loss: 0.7956\n",
            "Epoch 2672/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8897 - val_loss: 0.5297\n",
            "Epoch 2673/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9080 - val_loss: 0.5435\n",
            "Epoch 2674/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8590 - val_loss: 0.5825\n",
            "Epoch 2675/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8467 - val_loss: 0.5803\n",
            "Epoch 2676/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.1109 - val_loss: 0.7127\n",
            "Epoch 2677/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8567 - val_loss: 0.6380\n",
            "Epoch 2678/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9814 - val_loss: 0.7442\n",
            "Epoch 2679/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9002 - val_loss: 0.7601\n",
            "Epoch 2680/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9147 - val_loss: 0.7737\n",
            "Epoch 2681/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8369 - val_loss: 0.5988\n",
            "Epoch 2682/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8169 - val_loss: 0.5330\n",
            "Epoch 2683/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8310 - val_loss: 0.6163\n",
            "Epoch 2684/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8947 - val_loss: 0.5903\n",
            "Epoch 2685/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7902 - val_loss: 0.5520\n",
            "Epoch 2686/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8775 - val_loss: 0.6653\n",
            "Epoch 2687/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8339 - val_loss: 0.5504\n",
            "Epoch 2688/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8773 - val_loss: 0.7481\n",
            "Epoch 2689/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8375 - val_loss: 0.6845\n",
            "Epoch 2690/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8695 - val_loss: 0.7913\n",
            "Epoch 2691/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8622 - val_loss: 0.6394\n",
            "Epoch 2692/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8159 - val_loss: 0.7428\n",
            "Epoch 2693/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8442 - val_loss: 0.6079\n",
            "Epoch 2694/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8086 - val_loss: 0.5779\n",
            "Epoch 2695/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8757 - val_loss: 0.5876\n",
            "Epoch 2696/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8422 - val_loss: 0.5955\n",
            "Epoch 2697/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8146 - val_loss: 0.6304\n",
            "Epoch 2698/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8796 - val_loss: 0.6976\n",
            "Epoch 2699/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8587 - val_loss: 0.5010\n",
            "Epoch 2700/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8612 - val_loss: 0.6303\n",
            "Epoch 2701/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8647 - val_loss: 0.5712\n",
            "Epoch 2702/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8827 - val_loss: 0.5512\n",
            "Epoch 2703/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8683 - val_loss: 0.6503\n",
            "Epoch 2704/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8469 - val_loss: 0.8164\n",
            "Epoch 2705/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8575 - val_loss: 0.7977\n",
            "Epoch 2706/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8447 - val_loss: 0.6659\n",
            "Epoch 2707/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8301 - val_loss: 0.6416\n",
            "Epoch 2708/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7869 - val_loss: 0.6079\n",
            "Epoch 2709/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8554 - val_loss: 0.5667\n",
            "Epoch 2710/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8619 - val_loss: 0.6426\n",
            "Epoch 2711/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8923 - val_loss: 0.6623\n",
            "Epoch 2712/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.0092 - val_loss: 0.6443\n",
            "Epoch 2713/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8159 - val_loss: 0.6026\n",
            "Epoch 2714/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8781 - val_loss: 0.6110\n",
            "Epoch 2715/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.7977 - val_loss: 0.5269\n",
            "Epoch 2716/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8441 - val_loss: 0.5637\n",
            "Epoch 2717/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8566 - val_loss: 0.7024\n",
            "Epoch 2718/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8384 - val_loss: 0.4631\n",
            "Epoch 2719/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8475 - val_loss: 0.6531\n",
            "Epoch 2720/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8006 - val_loss: 0.6367\n",
            "Epoch 2721/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8517 - val_loss: 0.6416\n",
            "Epoch 2722/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8423 - val_loss: 0.5901\n",
            "Epoch 2723/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8721 - val_loss: 0.6933\n",
            "Epoch 2724/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8094 - val_loss: 0.6432\n",
            "Epoch 2725/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0637 - val_loss: 0.7305\n",
            "Epoch 2726/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8053 - val_loss: 0.5582\n",
            "Epoch 2727/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8988 - val_loss: 0.6539\n",
            "Epoch 2728/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7777 - val_loss: 0.6940\n",
            "Epoch 2729/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8651 - val_loss: 0.6595\n",
            "Epoch 2730/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9455 - val_loss: 0.6256\n",
            "Epoch 2731/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9379 - val_loss: 0.6067\n",
            "Epoch 2732/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8241 - val_loss: 0.7074\n",
            "Epoch 2733/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8949 - val_loss: 0.6166\n",
            "Epoch 2734/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8686 - val_loss: 0.6456\n",
            "Epoch 2735/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8897 - val_loss: 0.5027\n",
            "Epoch 2736/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8765 - val_loss: 0.6171\n",
            "Epoch 2737/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8399 - val_loss: 0.6687\n",
            "Epoch 2738/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8959 - val_loss: 0.6613\n",
            "Epoch 2739/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8806 - val_loss: 0.4581\n",
            "Epoch 2740/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8290 - val_loss: 0.5059\n",
            "Epoch 2741/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8053 - val_loss: 0.6064\n",
            "Epoch 2742/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8462 - val_loss: 0.6313\n",
            "Epoch 2743/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.9107 - val_loss: 0.6247\n",
            "Epoch 2744/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.9910 - val_loss: 0.6041\n",
            "Epoch 2745/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8324 - val_loss: 0.4609\n",
            "Epoch 2746/5000\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.8477 - val_loss: 0.5024\n",
            "Epoch 2747/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8195 - val_loss: 0.7178\n",
            "Epoch 2748/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8819 - val_loss: 0.4763\n",
            "Epoch 2749/5000\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.7920 - val_loss: 0.6111\n",
            "Epoch 2750/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8851 - val_loss: 0.7769\n",
            "Epoch 2751/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8274 - val_loss: 0.6045\n",
            "Epoch 2752/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8551 - val_loss: 0.7031\n",
            "Epoch 2753/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7895 - val_loss: 0.6533\n",
            "Epoch 2754/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8486 - val_loss: 0.6869\n",
            "Epoch 2755/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8573 - val_loss: 0.5270\n",
            "Epoch 2756/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8245 - val_loss: 0.6308\n",
            "Epoch 2757/5000\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.8868 - val_loss: 0.5079\n",
            "Epoch 2758/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8869 - val_loss: 0.6815\n",
            "Epoch 2759/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8988 - val_loss: 0.7997\n",
            "Epoch 2760/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8959 - val_loss: 0.5736\n",
            "Epoch 2761/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.9003 - val_loss: 0.6113\n",
            "Epoch 2762/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8790 - val_loss: 0.4682\n",
            "Epoch 2763/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8136 - val_loss: 0.8642\n",
            "Epoch 2764/5000\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.8211 - val_loss: 0.5728\n",
            "Epoch 2765/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.7851 - val_loss: 0.5466\n",
            "Epoch 2766/5000\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.8737 - val_loss: 0.5546\n",
            "Epoch 2767/5000\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.8674 - val_loss: 0.6960\n",
            "Epoch 2768/5000\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.8136 - val_loss: 0.5471\n",
            "Epoch 2769/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.9750 - val_loss: 0.5881\n",
            "Epoch 2770/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8442 - val_loss: 0.7355\n",
            "Epoch 2771/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8607 - val_loss: 0.7639\n",
            "Epoch 2772/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7817 - val_loss: 0.6838\n",
            "Epoch 2773/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9382 - val_loss: 0.7288\n",
            "Epoch 2774/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8582 - val_loss: 0.6341\n",
            "Epoch 2775/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8969 - val_loss: 0.5827\n",
            "Epoch 2776/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9094 - val_loss: 0.6751\n",
            "Epoch 2777/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8674 - val_loss: 0.6360\n",
            "Epoch 2778/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8118 - val_loss: 0.6650\n",
            "Epoch 2779/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9573 - val_loss: 0.7715\n",
            "Epoch 2780/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8909 - val_loss: 0.6724\n",
            "Epoch 2781/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8315 - val_loss: 0.5058\n",
            "Epoch 2782/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8457 - val_loss: 0.6946\n",
            "Epoch 2783/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8254 - val_loss: 0.5658\n",
            "Epoch 2784/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9467 - val_loss: 0.6113\n",
            "Epoch 2785/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8767 - val_loss: 0.6686\n",
            "Epoch 2786/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8433 - val_loss: 0.5616\n",
            "Epoch 2787/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8889 - val_loss: 0.6061\n",
            "Epoch 2788/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8578 - val_loss: 0.5428\n",
            "Epoch 2789/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8749 - val_loss: 0.6600\n",
            "Epoch 2790/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8790 - val_loss: 0.4620\n",
            "Epoch 2791/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8257 - val_loss: 0.5684\n",
            "Epoch 2792/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8503 - val_loss: 0.4486\n",
            "Epoch 2793/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.7756 - val_loss: 0.7402\n",
            "Epoch 2794/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8677 - val_loss: 0.6329\n",
            "Epoch 2795/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8352 - val_loss: 0.5546\n",
            "Epoch 2796/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9005 - val_loss: 0.5000\n",
            "Epoch 2797/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9003 - val_loss: 0.8336\n",
            "Epoch 2798/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8531 - val_loss: 0.6523\n",
            "Epoch 2799/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8854 - val_loss: 0.6035\n",
            "Epoch 2800/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8987 - val_loss: 0.6852\n",
            "Epoch 2801/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9140 - val_loss: 0.7870\n",
            "Epoch 2802/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8955 - val_loss: 0.5167\n",
            "Epoch 2803/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8850 - val_loss: 0.4619\n",
            "Epoch 2804/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9536 - val_loss: 0.5295\n",
            "Epoch 2805/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8624 - val_loss: 0.6990\n",
            "Epoch 2806/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8363 - val_loss: 0.7612\n",
            "Epoch 2807/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8315 - val_loss: 0.6931\n",
            "Epoch 2808/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8789 - val_loss: 0.5708\n",
            "Epoch 2809/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7892 - val_loss: 0.4739\n",
            "Epoch 2810/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8521 - val_loss: 0.5335\n",
            "Epoch 2811/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8081 - val_loss: 0.6066\n",
            "Epoch 2812/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8545 - val_loss: 1.0704\n",
            "Epoch 2813/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.7996 - val_loss: 0.6515\n",
            "Epoch 2814/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8136 - val_loss: 0.5322\n",
            "Epoch 2815/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8685 - val_loss: 0.6316\n",
            "Epoch 2816/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8201 - val_loss: 0.6878\n",
            "Epoch 2817/5000\n",
            "33/33 [==============================] - 1s 20ms/step - loss: 0.9577 - val_loss: 0.4176\n",
            "Epoch 2818/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8920 - val_loss: 0.5938\n",
            "Epoch 2819/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8456 - val_loss: 0.6079\n",
            "Epoch 2820/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8438 - val_loss: 0.6252\n",
            "Epoch 2821/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8163 - val_loss: 0.6387\n",
            "Epoch 2822/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8748 - val_loss: 0.5790\n",
            "Epoch 2823/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8952 - val_loss: 0.7153\n",
            "Epoch 2824/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9184 - val_loss: 0.7023\n",
            "Epoch 2825/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8259 - val_loss: 0.7547\n",
            "Epoch 2826/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8378 - val_loss: 0.6000\n",
            "Epoch 2827/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8765 - val_loss: 0.6373\n",
            "Epoch 2828/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8591 - val_loss: 0.5583\n",
            "Epoch 2829/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8816 - val_loss: 0.7644\n",
            "Epoch 2830/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8123 - val_loss: 0.6453\n",
            "Epoch 2831/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8265 - val_loss: 0.5410\n",
            "Epoch 2832/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8366 - val_loss: 1.1008\n",
            "Epoch 2833/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.7966 - val_loss: 0.7167\n",
            "Epoch 2834/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.7875 - val_loss: 0.7646\n",
            "Epoch 2835/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8099 - val_loss: 0.6499\n",
            "Epoch 2836/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8286 - val_loss: 0.6348\n",
            "Epoch 2837/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8851 - val_loss: 0.5094\n",
            "Epoch 2838/5000\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.8495 - val_loss: 0.7480\n",
            "Epoch 2839/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8581 - val_loss: 0.4805\n",
            "Epoch 2840/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8606 - val_loss: 0.7099\n",
            "Epoch 2841/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8624 - val_loss: 0.7113\n",
            "Epoch 2842/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8629 - val_loss: 0.5474\n",
            "Epoch 2843/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.9058 - val_loss: 0.6897\n",
            "Epoch 2844/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 1.0052 - val_loss: 0.5578\n",
            "Epoch 2845/5000\n",
            "33/33 [==============================] - 0s 9ms/step - loss: 0.8754 - val_loss: 0.6332\n",
            "Epoch 2846/5000\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.7841 - val_loss: 0.6284\n",
            "Epoch 2847/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8660 - val_loss: 0.5622\n",
            "Epoch 2848/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7700 - val_loss: 0.6608\n",
            "Epoch 2849/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8327 - val_loss: 0.5016\n",
            "Epoch 2850/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.9282 - val_loss: 0.6765\n",
            "Epoch 2851/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8831 - val_loss: 0.6546\n",
            "Epoch 2852/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8527 - val_loss: 0.5699\n",
            "Epoch 2853/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.9378 - val_loss: 0.8222\n",
            "Epoch 2854/5000\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.9219 - val_loss: 0.5408\n",
            "Epoch 2855/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8161 - val_loss: 0.6647\n",
            "Epoch 2856/5000\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.8086 - val_loss: 0.7997\n",
            "Epoch 2857/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9065 - val_loss: 0.7812\n",
            "Epoch 2858/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8035 - val_loss: 0.5385\n",
            "Epoch 2859/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.9055 - val_loss: 0.6251\n",
            "Epoch 2860/5000\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.8756 - val_loss: 0.5842\n",
            "Epoch 2861/5000\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.8684 - val_loss: 0.7697\n",
            "Epoch 2862/5000\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.8863 - val_loss: 1.0555\n",
            "Epoch 2863/5000\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.8718 - val_loss: 0.6463\n",
            "Epoch 2864/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8897 - val_loss: 0.5390\n",
            "Epoch 2865/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8604 - val_loss: 0.5571\n",
            "Epoch 2866/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8925 - val_loss: 0.5590\n",
            "Epoch 2867/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8462 - val_loss: 0.7226\n",
            "Epoch 2868/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8585 - val_loss: 0.5674\n",
            "Epoch 2869/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9506 - val_loss: 0.5680\n",
            "Epoch 2870/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8766 - val_loss: 0.6152\n",
            "Epoch 2871/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9610 - val_loss: 0.7951\n",
            "Epoch 2872/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9025 - val_loss: 0.5546\n",
            "Epoch 2873/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8728 - val_loss: 0.5794\n",
            "Epoch 2874/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8701 - val_loss: 0.7386\n",
            "Epoch 2875/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8313 - val_loss: 0.5683\n",
            "Epoch 2876/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8550 - val_loss: 0.7127\n",
            "Epoch 2877/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8772 - val_loss: 0.5912\n",
            "Epoch 2878/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.9139 - val_loss: 0.5588\n",
            "Epoch 2879/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9165 - val_loss: 0.5954\n",
            "Epoch 2880/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7965 - val_loss: 0.4800\n",
            "Epoch 2881/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8402 - val_loss: 0.5526\n",
            "Epoch 2882/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8896 - val_loss: 0.5146\n",
            "Epoch 2883/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8902 - val_loss: 0.7648\n",
            "Epoch 2884/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9087 - val_loss: 0.6521\n",
            "Epoch 2885/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8605 - val_loss: 0.7162\n",
            "Epoch 2886/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8567 - val_loss: 0.6245\n",
            "Epoch 2887/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8249 - val_loss: 0.6041\n",
            "Epoch 2888/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9089 - val_loss: 0.7760\n",
            "Epoch 2889/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8378 - val_loss: 0.6127\n",
            "Epoch 2890/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8751 - val_loss: 0.5780\n",
            "Epoch 2891/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8764 - val_loss: 0.5341\n",
            "Epoch 2892/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8597 - val_loss: 0.7266\n",
            "Epoch 2893/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8399 - val_loss: 0.5629\n",
            "Epoch 2894/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8810 - val_loss: 0.5496\n",
            "Epoch 2895/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8890 - val_loss: 0.5361\n",
            "Epoch 2896/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7872 - val_loss: 0.6289\n",
            "Epoch 2897/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8637 - val_loss: 0.6453\n",
            "Epoch 2898/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8978 - val_loss: 0.5483\n",
            "Epoch 2899/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8335 - val_loss: 0.5241\n",
            "Epoch 2900/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8678 - val_loss: 0.6002\n",
            "Epoch 2901/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8550 - val_loss: 0.7840\n",
            "Epoch 2902/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8037 - val_loss: 0.8022\n",
            "Epoch 2903/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8261 - val_loss: 0.7530\n",
            "Epoch 2904/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8530 - val_loss: 0.5848\n",
            "Epoch 2905/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8794 - val_loss: 0.9346\n",
            "Epoch 2906/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8599 - val_loss: 0.7619\n",
            "Epoch 2907/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8746 - val_loss: 0.7271\n",
            "Epoch 2908/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9365 - val_loss: 0.7122\n",
            "Epoch 2909/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9882 - val_loss: 0.5221\n",
            "Epoch 2910/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8162 - val_loss: 0.5407\n",
            "Epoch 2911/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.9007 - val_loss: 0.7777\n",
            "Epoch 2912/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8062 - val_loss: 0.5417\n",
            "Epoch 2913/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8528 - val_loss: 0.8406\n",
            "Epoch 2914/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8762 - val_loss: 0.6008\n",
            "Epoch 2915/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8398 - val_loss: 0.6662\n",
            "Epoch 2916/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8637 - val_loss: 0.9652\n",
            "Epoch 2917/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8241 - val_loss: 0.5227\n",
            "Epoch 2918/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8595 - val_loss: 0.5722\n",
            "Epoch 2919/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8653 - val_loss: 0.7246\n",
            "Epoch 2920/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8723 - val_loss: 0.5481\n",
            "Epoch 2921/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8742 - val_loss: 0.5809\n",
            "Epoch 2922/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9120 - val_loss: 0.4991\n",
            "Epoch 2923/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8865 - val_loss: 0.7091\n",
            "Epoch 2924/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9624 - val_loss: 0.7631\n",
            "Epoch 2925/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.9363 - val_loss: 0.6708\n",
            "Epoch 2926/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8365 - val_loss: 0.7703\n",
            "Epoch 2927/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8726 - val_loss: 0.6219\n",
            "Epoch 2928/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8206 - val_loss: 0.6633\n",
            "Epoch 2929/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8803 - val_loss: 0.6847\n",
            "Epoch 2930/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8191 - val_loss: 0.6615\n",
            "Epoch 2931/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.9035 - val_loss: 0.6686\n",
            "Epoch 2932/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8724 - val_loss: 0.6094\n",
            "Epoch 2933/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8273 - val_loss: 0.5919\n",
            "Epoch 2934/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9293 - val_loss: 0.5052\n",
            "Epoch 2935/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8582 - val_loss: 0.6105\n",
            "Epoch 2936/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8733 - val_loss: 0.6186\n",
            "Epoch 2937/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8354 - val_loss: 0.5386\n",
            "Epoch 2938/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8321 - val_loss: 0.7260\n",
            "Epoch 2939/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.9114 - val_loss: 0.6654\n",
            "Epoch 2940/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8443 - val_loss: 0.6533\n",
            "Epoch 2941/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8545 - val_loss: 0.6815\n",
            "Epoch 2942/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8709 - val_loss: 0.6525\n",
            "Epoch 2943/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8667 - val_loss: 0.6940\n",
            "Epoch 2944/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8850 - val_loss: 0.6556\n",
            "Epoch 2945/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8610 - val_loss: 0.5475\n",
            "Epoch 2946/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.9048 - val_loss: 0.7216\n",
            "Epoch 2947/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8605 - val_loss: 0.5813\n",
            "Epoch 2948/5000\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.9029 - val_loss: 0.7274\n",
            "Epoch 2949/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9151 - val_loss: 0.6216\n",
            "Epoch 2950/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8839 - val_loss: 0.7305\n",
            "Epoch 2951/5000\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.8104 - val_loss: 1.1394\n",
            "Epoch 2952/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8007 - val_loss: 0.7760\n",
            "Epoch 2953/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.9666 - val_loss: 0.7737\n",
            "Epoch 2954/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8450 - val_loss: 0.7329\n",
            "Epoch 2955/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8408 - val_loss: 0.6327\n",
            "Epoch 2956/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8444 - val_loss: 0.9667\n",
            "Epoch 2957/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8437 - val_loss: 0.6995\n",
            "Epoch 2958/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8250 - val_loss: 0.5818\n",
            "Epoch 2959/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8453 - val_loss: 0.6460\n",
            "Epoch 2960/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8523 - val_loss: 0.6348\n",
            "Epoch 2961/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8679 - val_loss: 0.5709\n",
            "Epoch 2962/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8853 - val_loss: 0.7092\n",
            "Epoch 2963/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8159 - val_loss: 0.5860\n",
            "Epoch 2964/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.9310 - val_loss: 0.5532\n",
            "Epoch 2965/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9639 - val_loss: 0.4948\n",
            "Epoch 2966/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8803 - val_loss: 0.5363\n",
            "Epoch 2967/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8613 - val_loss: 0.5421\n",
            "Epoch 2968/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8623 - val_loss: 1.0770\n",
            "Epoch 2969/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8810 - val_loss: 0.6796\n",
            "Epoch 2970/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8542 - val_loss: 0.6748\n",
            "Epoch 2971/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8555 - val_loss: 0.5765\n",
            "Epoch 2972/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8933 - val_loss: 0.6575\n",
            "Epoch 2973/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9127 - val_loss: 0.5933\n",
            "Epoch 2974/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8468 - val_loss: 0.7096\n",
            "Epoch 2975/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8136 - val_loss: 0.5671\n",
            "Epoch 2976/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7902 - val_loss: 0.6732\n",
            "Epoch 2977/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8545 - val_loss: 0.6756\n",
            "Epoch 2978/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8797 - val_loss: 0.6718\n",
            "Epoch 2979/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8377 - val_loss: 0.6146\n",
            "Epoch 2980/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8359 - val_loss: 0.6925\n",
            "Epoch 2981/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8541 - val_loss: 0.7413\n",
            "Epoch 2982/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8443 - val_loss: 0.7565\n",
            "Epoch 2983/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7691 - val_loss: 0.7013\n",
            "Epoch 2984/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7901 - val_loss: 0.5524\n",
            "Epoch 2985/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7762 - val_loss: 0.5793\n",
            "Epoch 2986/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8319 - val_loss: 0.4995\n",
            "Epoch 2987/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7939 - val_loss: 0.8171\n",
            "Epoch 2988/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8264 - val_loss: 0.4933\n",
            "Epoch 2989/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9493 - val_loss: 0.6845\n",
            "Epoch 2990/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8134 - val_loss: 0.5442\n",
            "Epoch 2991/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8684 - val_loss: 0.7490\n",
            "Epoch 2992/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8577 - val_loss: 0.8272\n",
            "Epoch 2993/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8666 - val_loss: 0.5788\n",
            "Epoch 2994/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9091 - val_loss: 0.6076\n",
            "Epoch 2995/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8249 - val_loss: 0.7039\n",
            "Epoch 2996/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9561 - val_loss: 0.6465\n",
            "Epoch 2997/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8921 - val_loss: 0.4984\n",
            "Epoch 2998/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8706 - val_loss: 0.8156\n",
            "Epoch 2999/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8583 - val_loss: 0.5715\n",
            "Epoch 3000/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8176 - val_loss: 0.5877\n",
            "Epoch 3001/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9292 - val_loss: 0.5563\n",
            "Epoch 3002/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8435 - val_loss: 0.5332\n",
            "Epoch 3003/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9218 - val_loss: 0.6527\n",
            "Epoch 3004/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9657 - val_loss: 0.7543\n",
            "Epoch 3005/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8854 - val_loss: 0.4935\n",
            "Epoch 3006/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8623 - val_loss: 0.7000\n",
            "Epoch 3007/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8271 - val_loss: 0.5591\n",
            "Epoch 3008/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8663 - val_loss: 0.4324\n",
            "Epoch 3009/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8215 - val_loss: 0.7112\n",
            "Epoch 3010/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8799 - val_loss: 0.6625\n",
            "Epoch 3011/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8465 - val_loss: 0.7279\n",
            "Epoch 3012/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8930 - val_loss: 0.5311\n",
            "Epoch 3013/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8500 - val_loss: 0.5529\n",
            "Epoch 3014/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7845 - val_loss: 0.7882\n",
            "Epoch 3015/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8526 - val_loss: 0.6393\n",
            "Epoch 3016/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8521 - val_loss: 0.5542\n",
            "Epoch 3017/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9105 - val_loss: 0.5591\n",
            "Epoch 3018/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8103 - val_loss: 0.7381\n",
            "Epoch 3019/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8128 - val_loss: 0.7497\n",
            "Epoch 3020/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8923 - val_loss: 0.5432\n",
            "Epoch 3021/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9342 - val_loss: 0.8629\n",
            "Epoch 3022/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8711 - val_loss: 0.6369\n",
            "Epoch 3023/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8710 - val_loss: 0.6068\n",
            "Epoch 3024/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8213 - val_loss: 0.7595\n",
            "Epoch 3025/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8209 - val_loss: 0.6591\n",
            "Epoch 3026/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7899 - val_loss: 0.8463\n",
            "Epoch 3027/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9946 - val_loss: 0.5013\n",
            "Epoch 3028/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8491 - val_loss: 0.5847\n",
            "Epoch 3029/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7929 - val_loss: 0.5853\n",
            "Epoch 3030/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8323 - val_loss: 0.5053\n",
            "Epoch 3031/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8452 - val_loss: 0.5812\n",
            "Epoch 3032/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.7936 - val_loss: 0.6080\n",
            "Epoch 3033/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8782 - val_loss: 0.9249\n",
            "Epoch 3034/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8424 - val_loss: 0.6164\n",
            "Epoch 3035/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8461 - val_loss: 0.6198\n",
            "Epoch 3036/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8292 - val_loss: 0.6687\n",
            "Epoch 3037/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8816 - val_loss: 0.6415\n",
            "Epoch 3038/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.9479 - val_loss: 0.5317\n",
            "Epoch 3039/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8568 - val_loss: 0.6986\n",
            "Epoch 3040/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8909 - val_loss: 0.4842\n",
            "Epoch 3041/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.7927 - val_loss: 0.8716\n",
            "Epoch 3042/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.7821 - val_loss: 0.6650\n",
            "Epoch 3043/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8194 - val_loss: 0.8700\n",
            "Epoch 3044/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.9019 - val_loss: 0.6209\n",
            "Epoch 3045/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8400 - val_loss: 0.8179\n",
            "Epoch 3046/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8629 - val_loss: 0.5428\n",
            "Epoch 3047/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8307 - val_loss: 0.6649\n",
            "Epoch 3048/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8287 - val_loss: 0.7254\n",
            "Epoch 3049/5000\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.8724 - val_loss: 0.5407\n",
            "Epoch 3050/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8347 - val_loss: 0.5676\n",
            "Epoch 3051/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8611 - val_loss: 0.7324\n",
            "Epoch 3052/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8152 - val_loss: 0.7996\n",
            "Epoch 3053/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8889 - val_loss: 0.8582\n",
            "Epoch 3054/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8464 - val_loss: 0.7074\n",
            "Epoch 3055/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8796 - val_loss: 0.5932\n",
            "Epoch 3056/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.7701 - val_loss: 0.6686\n",
            "Epoch 3057/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.7918 - val_loss: 0.5631\n",
            "Epoch 3058/5000\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.8101 - val_loss: 0.6110\n",
            "Epoch 3059/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8662 - val_loss: 0.7117\n",
            "Epoch 3060/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8603 - val_loss: 0.5174\n",
            "Epoch 3061/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8688 - val_loss: 0.5690\n",
            "Epoch 3062/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.9043 - val_loss: 0.6351\n",
            "Epoch 3063/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.9419 - val_loss: 0.4940\n",
            "Epoch 3064/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8768 - val_loss: 0.6685\n",
            "Epoch 3065/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8310 - val_loss: 0.6440\n",
            "Epoch 3066/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8890 - val_loss: 0.6260\n",
            "Epoch 3067/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8451 - val_loss: 0.6201\n",
            "Epoch 3068/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8444 - val_loss: 0.5157\n",
            "Epoch 3069/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8672 - val_loss: 0.9122\n",
            "Epoch 3070/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8667 - val_loss: 0.6603\n",
            "Epoch 3071/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8707 - val_loss: 0.6995\n",
            "Epoch 3072/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8688 - val_loss: 0.6879\n",
            "Epoch 3073/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8261 - val_loss: 0.8679\n",
            "Epoch 3074/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9005 - val_loss: 0.6018\n",
            "Epoch 3075/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8163 - val_loss: 0.9148\n",
            "Epoch 3076/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8657 - val_loss: 0.6066\n",
            "Epoch 3077/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9206 - val_loss: 0.5645\n",
            "Epoch 3078/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8213 - val_loss: 0.5342\n",
            "Epoch 3079/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8804 - val_loss: 0.7378\n",
            "Epoch 3080/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8675 - val_loss: 0.5992\n",
            "Epoch 3081/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8826 - val_loss: 0.7481\n",
            "Epoch 3082/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8628 - val_loss: 0.5188\n",
            "Epoch 3083/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8559 - val_loss: 0.4969\n",
            "Epoch 3084/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8427 - val_loss: 0.5463\n",
            "Epoch 3085/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9426 - val_loss: 0.5712\n",
            "Epoch 3086/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8365 - val_loss: 0.5324\n",
            "Epoch 3087/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7813 - val_loss: 0.7041\n",
            "Epoch 3088/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9437 - val_loss: 0.5618\n",
            "Epoch 3089/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8666 - val_loss: 0.6095\n",
            "Epoch 3090/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8680 - val_loss: 0.6466\n",
            "Epoch 3091/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9041 - val_loss: 0.5558\n",
            "Epoch 3092/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7701 - val_loss: 0.6811\n",
            "Epoch 3093/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9081 - val_loss: 0.6589\n",
            "Epoch 3094/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8702 - val_loss: 0.8055\n",
            "Epoch 3095/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8358 - val_loss: 0.5826\n",
            "Epoch 3096/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8231 - val_loss: 0.6663\n",
            "Epoch 3097/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9040 - val_loss: 0.6395\n",
            "Epoch 3098/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9469 - val_loss: 0.6959\n",
            "Epoch 3099/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9027 - val_loss: 0.6956\n",
            "Epoch 3100/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8246 - val_loss: 0.7280\n",
            "Epoch 3101/5000\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.8617 - val_loss: 0.5522\n",
            "Epoch 3102/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9474 - val_loss: 0.5169\n",
            "Epoch 3103/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8776 - val_loss: 0.4677\n",
            "Epoch 3104/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8076 - val_loss: 0.5710\n",
            "Epoch 3105/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8247 - val_loss: 0.5111\n",
            "Epoch 3106/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.9540 - val_loss: 0.6988\n",
            "Epoch 3107/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9706 - val_loss: 0.6462\n",
            "Epoch 3108/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9161 - val_loss: 0.6697\n",
            "Epoch 3109/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8898 - val_loss: 0.5583\n",
            "Epoch 3110/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8510 - val_loss: 0.5638\n",
            "Epoch 3111/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8481 - val_loss: 0.8782\n",
            "Epoch 3112/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8689 - val_loss: 0.6493\n",
            "Epoch 3113/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7849 - val_loss: 0.6218\n",
            "Epoch 3114/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8395 - val_loss: 0.6260\n",
            "Epoch 3115/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8711 - val_loss: 0.5788\n",
            "Epoch 3116/5000\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.7980 - val_loss: 0.7793\n",
            "Epoch 3117/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9091 - val_loss: 0.7396\n",
            "Epoch 3118/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8766 - val_loss: 0.5785\n",
            "Epoch 3119/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8288 - val_loss: 0.6233\n",
            "Epoch 3120/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8027 - val_loss: 0.7617\n",
            "Epoch 3121/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8545 - val_loss: 0.8160\n",
            "Epoch 3122/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8705 - val_loss: 0.7990\n",
            "Epoch 3123/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7927 - val_loss: 0.5579\n",
            "Epoch 3124/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8819 - val_loss: 0.5594\n",
            "Epoch 3125/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.7969 - val_loss: 0.5758\n",
            "Epoch 3126/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.7801 - val_loss: 0.6456\n",
            "Epoch 3127/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8737 - val_loss: 0.6093\n",
            "Epoch 3128/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8811 - val_loss: 0.5171\n",
            "Epoch 3129/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.9392 - val_loss: 0.5426\n",
            "Epoch 3130/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8218 - val_loss: 0.6540\n",
            "Epoch 3131/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8335 - val_loss: 0.5227\n",
            "Epoch 3132/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8531 - val_loss: 0.5394\n",
            "Epoch 3133/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8305 - val_loss: 0.5687\n",
            "Epoch 3134/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8334 - val_loss: 0.5140\n",
            "Epoch 3135/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8333 - val_loss: 0.5927\n",
            "Epoch 3136/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9538 - val_loss: 0.5398\n",
            "Epoch 3137/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8288 - val_loss: 0.7090\n",
            "Epoch 3138/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8830 - val_loss: 0.6113\n",
            "Epoch 3139/5000\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.8154 - val_loss: 0.7080\n",
            "Epoch 3140/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8114 - val_loss: 0.5252\n",
            "Epoch 3141/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8920 - val_loss: 0.7183\n",
            "Epoch 3142/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8761 - val_loss: 0.6507\n",
            "Epoch 3143/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8691 - val_loss: 0.8354\n",
            "Epoch 3144/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8169 - val_loss: 0.5340\n",
            "Epoch 3145/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8386 - val_loss: 0.7330\n",
            "Epoch 3146/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.9598 - val_loss: 0.4933\n",
            "Epoch 3147/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.7750 - val_loss: 0.6880\n",
            "Epoch 3148/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.9054 - val_loss: 0.6797\n",
            "Epoch 3149/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8233 - val_loss: 0.8458\n",
            "Epoch 3150/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8620 - val_loss: 0.6416\n",
            "Epoch 3151/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8310 - val_loss: 0.6557\n",
            "Epoch 3152/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8937 - val_loss: 0.7168\n",
            "Epoch 3153/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8382 - val_loss: 0.5397\n",
            "Epoch 3154/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8137 - val_loss: 0.5648\n",
            "Epoch 3155/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8887 - val_loss: 0.7730\n",
            "Epoch 3156/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8920 - val_loss: 0.6770\n",
            "Epoch 3157/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8313 - val_loss: 0.4995\n",
            "Epoch 3158/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8691 - val_loss: 0.5879\n",
            "Epoch 3159/5000\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.8137 - val_loss: 0.6605\n",
            "Epoch 3160/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8564 - val_loss: 0.6261\n",
            "Epoch 3161/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8772 - val_loss: 0.6140\n",
            "Epoch 3162/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9937 - val_loss: 0.5638\n",
            "Epoch 3163/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8504 - val_loss: 0.5579\n",
            "Epoch 3164/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8137 - val_loss: 0.6084\n",
            "Epoch 3165/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8295 - val_loss: 0.5748\n",
            "Epoch 3166/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8147 - val_loss: 0.6137\n",
            "Epoch 3167/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8503 - val_loss: 0.6087\n",
            "Epoch 3168/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8554 - val_loss: 0.4700\n",
            "Epoch 3169/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8454 - val_loss: 1.0168\n",
            "Epoch 3170/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8762 - val_loss: 0.6064\n",
            "Epoch 3171/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8762 - val_loss: 0.5769\n",
            "Epoch 3172/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8578 - val_loss: 0.6183\n",
            "Epoch 3173/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9018 - val_loss: 0.8147\n",
            "Epoch 3174/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8478 - val_loss: 0.6211\n",
            "Epoch 3175/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8456 - val_loss: 0.5654\n",
            "Epoch 3176/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8809 - val_loss: 0.8130\n",
            "Epoch 3177/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9233 - val_loss: 0.6747\n",
            "Epoch 3178/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8659 - val_loss: 0.5231\n",
            "Epoch 3179/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8712 - val_loss: 0.8520\n",
            "Epoch 3180/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9869 - val_loss: 0.6551\n",
            "Epoch 3181/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8289 - val_loss: 0.6125\n",
            "Epoch 3182/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.7985 - val_loss: 0.6638\n",
            "Epoch 3183/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8199 - val_loss: 0.6357\n",
            "Epoch 3184/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9863 - val_loss: 0.4821\n",
            "Epoch 3185/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8759 - val_loss: 0.9566\n",
            "Epoch 3186/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8745 - val_loss: 0.6412\n",
            "Epoch 3187/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8190 - val_loss: 0.5806\n",
            "Epoch 3188/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8400 - val_loss: 0.6760\n",
            "Epoch 3189/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8561 - val_loss: 0.7865\n",
            "Epoch 3190/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8494 - val_loss: 0.6745\n",
            "Epoch 3191/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9007 - val_loss: 0.4785\n",
            "Epoch 3192/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8624 - val_loss: 0.5386\n",
            "Epoch 3193/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8683 - val_loss: 0.5608\n",
            "Epoch 3194/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9146 - val_loss: 0.7116\n",
            "Epoch 3195/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8586 - val_loss: 0.6067\n",
            "Epoch 3196/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8787 - val_loss: 0.5508\n",
            "Epoch 3197/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8541 - val_loss: 0.5446\n",
            "Epoch 3198/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8744 - val_loss: 0.5903\n",
            "Epoch 3199/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8353 - val_loss: 0.7001\n",
            "Epoch 3200/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8491 - val_loss: 0.6626\n",
            "Epoch 3201/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8831 - val_loss: 0.7726\n",
            "Epoch 3202/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8417 - val_loss: 0.5454\n",
            "Epoch 3203/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7891 - val_loss: 0.6624\n",
            "Epoch 3204/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9248 - val_loss: 0.9570\n",
            "Epoch 3205/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8287 - val_loss: 0.5964\n",
            "Epoch 3206/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8773 - val_loss: 0.6136\n",
            "Epoch 3207/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8789 - val_loss: 0.7233\n",
            "Epoch 3208/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.9041 - val_loss: 0.5163\n",
            "Epoch 3209/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8206 - val_loss: 0.6000\n",
            "Epoch 3210/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9468 - val_loss: 0.6150\n",
            "Epoch 3211/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8522 - val_loss: 0.6720\n",
            "Epoch 3212/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8593 - val_loss: 0.5394\n",
            "Epoch 3213/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9064 - val_loss: 0.6422\n",
            "Epoch 3214/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8733 - val_loss: 0.6640\n",
            "Epoch 3215/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8550 - val_loss: 0.5213\n",
            "Epoch 3216/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9001 - val_loss: 0.7216\n",
            "Epoch 3217/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0268 - val_loss: 0.6595\n",
            "Epoch 3218/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9058 - val_loss: 0.4591\n",
            "Epoch 3219/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8854 - val_loss: 0.6828\n",
            "Epoch 3220/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8836 - val_loss: 0.5363\n",
            "Epoch 3221/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8274 - val_loss: 0.6196\n",
            "Epoch 3222/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.7777 - val_loss: 0.4456\n",
            "Epoch 3223/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8996 - val_loss: 0.5530\n",
            "Epoch 3224/5000\n",
            "33/33 [==============================] - 0s 8ms/step - loss: 0.8190 - val_loss: 0.5591\n",
            "Epoch 3225/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8687 - val_loss: 0.6112\n",
            "Epoch 3226/5000\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.9210 - val_loss: 0.6744\n",
            "Epoch 3227/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8600 - val_loss: 0.5854\n",
            "Epoch 3228/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8614 - val_loss: 0.6361\n",
            "Epoch 3229/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9509 - val_loss: 0.5297\n",
            "Epoch 3230/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8676 - val_loss: 0.6983\n",
            "Epoch 3231/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8879 - val_loss: 0.6089\n",
            "Epoch 3232/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8304 - val_loss: 0.5294\n",
            "Epoch 3233/5000\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.7798 - val_loss: 0.7133\n",
            "Epoch 3234/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8518 - val_loss: 0.6222\n",
            "Epoch 3235/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8193 - val_loss: 0.5939\n",
            "Epoch 3236/5000\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.8264 - val_loss: 0.5659\n",
            "Epoch 3237/5000\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.8241 - val_loss: 0.5789\n",
            "Epoch 3238/5000\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.8424 - val_loss: 0.7276\n",
            "Epoch 3239/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8450 - val_loss: 0.6439\n",
            "Epoch 3240/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8909 - val_loss: 0.5318\n",
            "Epoch 3241/5000\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.8116 - val_loss: 0.5924\n",
            "Epoch 3242/5000\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.8609 - val_loss: 0.5811\n",
            "Epoch 3243/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8936 - val_loss: 0.6015\n",
            "Epoch 3244/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8756 - val_loss: 0.6609\n",
            "Epoch 3245/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9134 - val_loss: 0.5821\n",
            "Epoch 3246/5000\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.8607 - val_loss: 0.4974\n",
            "Epoch 3247/5000\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.8299 - val_loss: 0.5875\n",
            "Epoch 3248/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.9025 - val_loss: 0.5261\n",
            "Epoch 3249/5000\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.9688 - val_loss: 0.5656\n",
            "Epoch 3250/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.9000 - val_loss: 0.7578\n",
            "Epoch 3251/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8597 - val_loss: 0.7764\n",
            "Epoch 3252/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8408 - val_loss: 0.7732\n",
            "Epoch 3253/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8626 - val_loss: 0.5854\n",
            "Epoch 3254/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8598 - val_loss: 0.5688\n",
            "Epoch 3255/5000\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.8322 - val_loss: 0.4937\n",
            "Epoch 3256/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8249 - val_loss: 0.6178\n",
            "Epoch 3257/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.9079 - val_loss: 0.6037\n",
            "Epoch 3258/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8623 - val_loss: 0.8328\n",
            "Epoch 3259/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8742 - val_loss: 0.5309\n",
            "Epoch 3260/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8816 - val_loss: 0.6976\n",
            "Epoch 3261/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8564 - val_loss: 0.5278\n",
            "Epoch 3262/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8167 - val_loss: 0.6549\n",
            "Epoch 3263/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8393 - val_loss: 0.6549\n",
            "Epoch 3264/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.9282 - val_loss: 0.5787\n",
            "Epoch 3265/5000\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.8512 - val_loss: 0.6139\n",
            "Epoch 3266/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8072 - val_loss: 0.9236\n",
            "Epoch 3267/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8824 - val_loss: 0.6768\n",
            "Epoch 3268/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8735 - val_loss: 0.9913\n",
            "Epoch 3269/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8587 - val_loss: 0.6400\n",
            "Epoch 3270/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9043 - val_loss: 0.8426\n",
            "Epoch 3271/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.7633 - val_loss: 0.6356\n",
            "Epoch 3272/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8543 - val_loss: 0.6825\n",
            "Epoch 3273/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8350 - val_loss: 0.6565\n",
            "Epoch 3274/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8806 - val_loss: 0.7761\n",
            "Epoch 3275/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.9053 - val_loss: 0.7081\n",
            "Epoch 3276/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8373 - val_loss: 0.5923\n",
            "Epoch 3277/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8588 - val_loss: 0.8541\n",
            "Epoch 3278/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.7621 - val_loss: 0.6292\n",
            "Epoch 3279/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8177 - val_loss: 0.5261\n",
            "Epoch 3280/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8002 - val_loss: 0.6636\n",
            "Epoch 3281/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8386 - val_loss: 0.6166\n",
            "Epoch 3282/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8204 - val_loss: 0.5693\n",
            "Epoch 3283/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8520 - val_loss: 0.6678\n",
            "Epoch 3284/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8108 - val_loss: 0.6927\n",
            "Epoch 3285/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8823 - val_loss: 0.6409\n",
            "Epoch 3286/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8689 - val_loss: 0.6137\n",
            "Epoch 3287/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8680 - val_loss: 0.6724\n",
            "Epoch 3288/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8504 - val_loss: 0.6367\n",
            "Epoch 3289/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8673 - val_loss: 0.7065\n",
            "Epoch 3290/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9057 - val_loss: 0.4655\n",
            "Epoch 3291/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7904 - val_loss: 0.6876\n",
            "Epoch 3292/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9359 - val_loss: 0.8424\n",
            "Epoch 3293/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8751 - val_loss: 0.6252\n",
            "Epoch 3294/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8180 - val_loss: 0.6777\n",
            "Epoch 3295/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8529 - val_loss: 0.7108\n",
            "Epoch 3296/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0087 - val_loss: 0.4470\n",
            "Epoch 3297/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9614 - val_loss: 0.7558\n",
            "Epoch 3298/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8524 - val_loss: 0.5426\n",
            "Epoch 3299/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8677 - val_loss: 0.5097\n",
            "Epoch 3300/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8231 - val_loss: 0.6967\n",
            "Epoch 3301/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8036 - val_loss: 0.4682\n",
            "Epoch 3302/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8076 - val_loss: 0.6178\n",
            "Epoch 3303/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8660 - val_loss: 0.5105\n",
            "Epoch 3304/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8268 - val_loss: 0.6176\n",
            "Epoch 3305/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8117 - val_loss: 0.7157\n",
            "Epoch 3306/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.0177 - val_loss: 0.5390\n",
            "Epoch 3307/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8763 - val_loss: 0.5526\n",
            "Epoch 3308/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9051 - val_loss: 0.7921\n",
            "Epoch 3309/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9199 - val_loss: 0.6721\n",
            "Epoch 3310/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8059 - val_loss: 0.9425\n",
            "Epoch 3311/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8390 - val_loss: 0.6654\n",
            "Epoch 3312/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8190 - val_loss: 0.5735\n",
            "Epoch 3313/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8385 - val_loss: 0.6356\n",
            "Epoch 3314/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8691 - val_loss: 0.8456\n",
            "Epoch 3315/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9744 - val_loss: 0.6103\n",
            "Epoch 3316/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8641 - val_loss: 0.6902\n",
            "Epoch 3317/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8400 - val_loss: 0.6105\n",
            "Epoch 3318/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9005 - val_loss: 0.7211\n",
            "Epoch 3319/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7912 - val_loss: 0.6557\n",
            "Epoch 3320/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8312 - val_loss: 0.5960\n",
            "Epoch 3321/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7759 - val_loss: 0.8405\n",
            "Epoch 3322/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8815 - val_loss: 0.7822\n",
            "Epoch 3323/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9353 - val_loss: 0.7412\n",
            "Epoch 3324/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8260 - val_loss: 0.5890\n",
            "Epoch 3325/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9404 - val_loss: 0.6937\n",
            "Epoch 3326/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8952 - val_loss: 0.7370\n",
            "Epoch 3327/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8280 - val_loss: 0.6582\n",
            "Epoch 3328/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8364 - val_loss: 0.5925\n",
            "Epoch 3329/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8531 - val_loss: 0.6665\n",
            "Epoch 3330/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8798 - val_loss: 0.7716\n",
            "Epoch 3331/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9291 - val_loss: 0.6555\n",
            "Epoch 3332/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8498 - val_loss: 0.6313\n",
            "Epoch 3333/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8928 - val_loss: 0.8246\n",
            "Epoch 3334/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8754 - val_loss: 0.8555\n",
            "Epoch 3335/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8640 - val_loss: 0.6527\n",
            "Epoch 3336/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8376 - val_loss: 0.5757\n",
            "Epoch 3337/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8259 - val_loss: 0.7280\n",
            "Epoch 3338/5000\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.8185 - val_loss: 0.5318\n",
            "Epoch 3339/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9267 - val_loss: 0.5567\n",
            "Epoch 3340/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8294 - val_loss: 0.6264\n",
            "Epoch 3341/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8850 - val_loss: 0.6422\n",
            "Epoch 3342/5000\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.9516 - val_loss: 0.5878\n",
            "Epoch 3343/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.7981 - val_loss: 0.9179\n",
            "Epoch 3344/5000\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.9259 - val_loss: 0.5823\n",
            "Epoch 3345/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8045 - val_loss: 0.5341\n",
            "Epoch 3346/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9509 - val_loss: 0.5561\n",
            "Epoch 3347/5000\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.8521 - val_loss: 0.8111\n",
            "Epoch 3348/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8744 - val_loss: 0.5823\n",
            "Epoch 3349/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8368 - val_loss: 0.6991\n",
            "Epoch 3350/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8276 - val_loss: 0.6462\n",
            "Epoch 3351/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8009 - val_loss: 0.6300\n",
            "Epoch 3352/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8791 - val_loss: 0.5345\n",
            "Epoch 3353/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8502 - val_loss: 0.6116\n",
            "Epoch 3354/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7910 - val_loss: 0.6245\n",
            "Epoch 3355/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8623 - val_loss: 0.6681\n",
            "Epoch 3356/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8976 - val_loss: 0.6945\n",
            "Epoch 3357/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9285 - val_loss: 0.7270\n",
            "Epoch 3358/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8614 - val_loss: 0.5831\n",
            "Epoch 3359/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8209 - val_loss: 0.5698\n",
            "Epoch 3360/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8775 - val_loss: 1.0130\n",
            "Epoch 3361/5000\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.8937 - val_loss: 0.6677\n",
            "Epoch 3362/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8261 - val_loss: 0.6094\n",
            "Epoch 3363/5000\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.8907 - val_loss: 0.6799\n",
            "Epoch 3364/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8034 - val_loss: 0.8157\n",
            "Epoch 3365/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.9546 - val_loss: 0.5737\n",
            "Epoch 3366/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8002 - val_loss: 0.9845\n",
            "Epoch 3367/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9174 - val_loss: 0.5011\n",
            "Epoch 3368/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8661 - val_loss: 0.8272\n",
            "Epoch 3369/5000\n",
            "33/33 [==============================] - 0s 8ms/step - loss: 0.7932 - val_loss: 0.7876\n",
            "Epoch 3370/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8333 - val_loss: 0.6440\n",
            "Epoch 3371/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8913 - val_loss: 0.5914\n",
            "Epoch 3372/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8373 - val_loss: 0.5480\n",
            "Epoch 3373/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8425 - val_loss: 0.7126\n",
            "Epoch 3374/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8775 - val_loss: 0.7836\n",
            "Epoch 3375/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8332 - val_loss: 0.5869\n",
            "Epoch 3376/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9406 - val_loss: 0.5301\n",
            "Epoch 3377/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8035 - val_loss: 0.5355\n",
            "Epoch 3378/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8276 - val_loss: 0.6317\n",
            "Epoch 3379/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8429 - val_loss: 0.7294\n",
            "Epoch 3380/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8956 - val_loss: 0.6352\n",
            "Epoch 3381/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8066 - val_loss: 0.7062\n",
            "Epoch 3382/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8712 - val_loss: 0.7805\n",
            "Epoch 3383/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7973 - val_loss: 1.2058\n",
            "Epoch 3384/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8502 - val_loss: 0.5672\n",
            "Epoch 3385/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8328 - val_loss: 0.6364\n",
            "Epoch 3386/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8343 - val_loss: 0.7028\n",
            "Epoch 3387/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8098 - val_loss: 0.6998\n",
            "Epoch 3388/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9209 - val_loss: 0.6820\n",
            "Epoch 3389/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8422 - val_loss: 0.9456\n",
            "Epoch 3390/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8275 - val_loss: 0.5272\n",
            "Epoch 3391/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8617 - val_loss: 0.6286\n",
            "Epoch 3392/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8805 - val_loss: 0.7186\n",
            "Epoch 3393/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9075 - val_loss: 0.5109\n",
            "Epoch 3394/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8874 - val_loss: 0.7064\n",
            "Epoch 3395/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9456 - val_loss: 0.6995\n",
            "Epoch 3396/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8291 - val_loss: 0.5661\n",
            "Epoch 3397/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8184 - val_loss: 0.6712\n",
            "Epoch 3398/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8560 - val_loss: 0.7726\n",
            "Epoch 3399/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8967 - val_loss: 0.7127\n",
            "Epoch 3400/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8236 - val_loss: 0.9211\n",
            "Epoch 3401/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8283 - val_loss: 1.0938\n",
            "Epoch 3402/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8705 - val_loss: 0.6737\n",
            "Epoch 3403/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8711 - val_loss: 0.6604\n",
            "Epoch 3404/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8200 - val_loss: 0.5970\n",
            "Epoch 3405/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8259 - val_loss: 0.6171\n",
            "Epoch 3406/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9415 - val_loss: 0.6235\n",
            "Epoch 3407/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8840 - val_loss: 0.5270\n",
            "Epoch 3408/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8259 - val_loss: 0.6382\n",
            "Epoch 3409/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8375 - val_loss: 0.5360\n",
            "Epoch 3410/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8967 - val_loss: 0.6658\n",
            "Epoch 3411/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9187 - val_loss: 0.6093\n",
            "Epoch 3412/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8782 - val_loss: 0.5686\n",
            "Epoch 3413/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8380 - val_loss: 0.5291\n",
            "Epoch 3414/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8876 - val_loss: 0.6763\n",
            "Epoch 3415/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8343 - val_loss: 0.5000\n",
            "Epoch 3416/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8739 - val_loss: 0.5063\n",
            "Epoch 3417/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8527 - val_loss: 0.5791\n",
            "Epoch 3418/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8082 - val_loss: 0.4801\n",
            "Epoch 3419/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9272 - val_loss: 0.7014\n",
            "Epoch 3420/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8975 - val_loss: 0.7041\n",
            "Epoch 3421/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8393 - val_loss: 0.6663\n",
            "Epoch 3422/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8524 - val_loss: 0.6094\n",
            "Epoch 3423/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8858 - val_loss: 0.6302\n",
            "Epoch 3424/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8558 - val_loss: 0.6782\n",
            "Epoch 3425/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8272 - val_loss: 0.6866\n",
            "Epoch 3426/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9594 - val_loss: 0.5641\n",
            "Epoch 3427/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9541 - val_loss: 0.7182\n",
            "Epoch 3428/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8817 - val_loss: 0.6075\n",
            "Epoch 3429/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8506 - val_loss: 0.5570\n",
            "Epoch 3430/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8774 - val_loss: 0.5388\n",
            "Epoch 3431/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9339 - val_loss: 0.6292\n",
            "Epoch 3432/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8360 - val_loss: 0.8218\n",
            "Epoch 3433/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8603 - val_loss: 0.7479\n",
            "Epoch 3434/5000\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 1.0278 - val_loss: 0.5714\n",
            "Epoch 3435/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8113 - val_loss: 0.7411\n",
            "Epoch 3436/5000\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.8410 - val_loss: 0.5172\n",
            "Epoch 3437/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8059 - val_loss: 0.6592\n",
            "Epoch 3438/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8898 - val_loss: 0.7176\n",
            "Epoch 3439/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8382 - val_loss: 0.8432\n",
            "Epoch 3440/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8503 - val_loss: 0.7809\n",
            "Epoch 3441/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8453 - val_loss: 0.6543\n",
            "Epoch 3442/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8758 - val_loss: 0.6894\n",
            "Epoch 3443/5000\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.8828 - val_loss: 0.5364\n",
            "Epoch 3444/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8301 - val_loss: 0.6759\n",
            "Epoch 3445/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.9101 - val_loss: 0.5886\n",
            "Epoch 3446/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8630 - val_loss: 0.6195\n",
            "Epoch 3447/5000\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.8334 - val_loss: 0.5567\n",
            "Epoch 3448/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.9739 - val_loss: 0.7238\n",
            "Epoch 3449/5000\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.9188 - val_loss: 0.7172\n",
            "Epoch 3450/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8364 - val_loss: 0.6755\n",
            "Epoch 3451/5000\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.8337 - val_loss: 0.7271\n",
            "Epoch 3452/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8381 - val_loss: 0.6425\n",
            "Epoch 3453/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9806 - val_loss: 0.7187\n",
            "Epoch 3454/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7982 - val_loss: 0.6667\n",
            "Epoch 3455/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8812 - val_loss: 0.6822\n",
            "Epoch 3456/5000\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.8044 - val_loss: 0.7165\n",
            "Epoch 3457/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8362 - val_loss: 0.6450\n",
            "Epoch 3458/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8419 - val_loss: 0.7030\n",
            "Epoch 3459/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9292 - val_loss: 0.5206\n",
            "Epoch 3460/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8283 - val_loss: 0.6890\n",
            "Epoch 3461/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7871 - val_loss: 0.7010\n",
            "Epoch 3462/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9174 - val_loss: 0.8142\n",
            "Epoch 3463/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8125 - val_loss: 0.7196\n",
            "Epoch 3464/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8716 - val_loss: 0.5702\n",
            "Epoch 3465/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.9303 - val_loss: 0.5003\n",
            "Epoch 3466/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8672 - val_loss: 0.7278\n",
            "Epoch 3467/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8206 - val_loss: 0.6133\n",
            "Epoch 3468/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8093 - val_loss: 0.6706\n",
            "Epoch 3469/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8404 - val_loss: 0.7034\n",
            "Epoch 3470/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8118 - val_loss: 0.5803\n",
            "Epoch 3471/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8562 - val_loss: 0.6830\n",
            "Epoch 3472/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8304 - val_loss: 0.6884\n",
            "Epoch 3473/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8453 - val_loss: 0.6110\n",
            "Epoch 3474/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8762 - val_loss: 0.6804\n",
            "Epoch 3475/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8450 - val_loss: 0.7563\n",
            "Epoch 3476/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8716 - val_loss: 0.6033\n",
            "Epoch 3477/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8804 - val_loss: 0.5384\n",
            "Epoch 3478/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8484 - val_loss: 0.6438\n",
            "Epoch 3479/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8514 - val_loss: 0.6690\n",
            "Epoch 3480/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8812 - val_loss: 0.7877\n",
            "Epoch 3481/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8722 - val_loss: 0.6203\n",
            "Epoch 3482/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8375 - val_loss: 0.9458\n",
            "Epoch 3483/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9974 - val_loss: 0.7193\n",
            "Epoch 3484/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9168 - val_loss: 0.5543\n",
            "Epoch 3485/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8303 - val_loss: 0.7535\n",
            "Epoch 3486/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8936 - val_loss: 0.7158\n",
            "Epoch 3487/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8487 - val_loss: 0.5903\n",
            "Epoch 3488/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8559 - val_loss: 0.7585\n",
            "Epoch 3489/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9443 - val_loss: 0.6905\n",
            "Epoch 3490/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8359 - val_loss: 0.5669\n",
            "Epoch 3491/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8765 - val_loss: 0.5546\n",
            "Epoch 3492/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8952 - val_loss: 0.7664\n",
            "Epoch 3493/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8492 - val_loss: 0.6570\n",
            "Epoch 3494/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8350 - val_loss: 0.8378\n",
            "Epoch 3495/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8239 - val_loss: 0.7367\n",
            "Epoch 3496/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9325 - val_loss: 0.6435\n",
            "Epoch 3497/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8775 - val_loss: 0.7926\n",
            "Epoch 3498/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.7991 - val_loss: 0.7796\n",
            "Epoch 3499/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8510 - val_loss: 0.7486\n",
            "Epoch 3500/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7965 - val_loss: 0.9188\n",
            "Epoch 3501/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8694 - val_loss: 0.7636\n",
            "Epoch 3502/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8690 - val_loss: 0.6763\n",
            "Epoch 3503/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8879 - val_loss: 0.7323\n",
            "Epoch 3504/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8689 - val_loss: 0.6435\n",
            "Epoch 3505/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8714 - val_loss: 0.7759\n",
            "Epoch 3506/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8242 - val_loss: 0.8607\n",
            "Epoch 3507/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8585 - val_loss: 0.7570\n",
            "Epoch 3508/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8083 - val_loss: 0.8494\n",
            "Epoch 3509/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8784 - val_loss: 0.6127\n",
            "Epoch 3510/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0277 - val_loss: 0.5898\n",
            "Epoch 3511/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8713 - val_loss: 0.5752\n",
            "Epoch 3512/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8955 - val_loss: 0.6470\n",
            "Epoch 3513/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8482 - val_loss: 0.7091\n",
            "Epoch 3514/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8468 - val_loss: 0.7943\n",
            "Epoch 3515/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8414 - val_loss: 0.7156\n",
            "Epoch 3516/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8327 - val_loss: 0.6335\n",
            "Epoch 3517/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8662 - val_loss: 0.5569\n",
            "Epoch 3518/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8127 - val_loss: 0.5772\n",
            "Epoch 3519/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8699 - val_loss: 0.9684\n",
            "Epoch 3520/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9011 - val_loss: 0.7785\n",
            "Epoch 3521/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8704 - val_loss: 0.5475\n",
            "Epoch 3522/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8263 - val_loss: 0.7368\n",
            "Epoch 3523/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8503 - val_loss: 0.5326\n",
            "Epoch 3524/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7847 - val_loss: 0.7627\n",
            "Epoch 3525/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8721 - val_loss: 0.6916\n",
            "Epoch 3526/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8655 - val_loss: 0.6596\n",
            "Epoch 3527/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8306 - val_loss: 0.7096\n",
            "Epoch 3528/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9331 - val_loss: 0.6079\n",
            "Epoch 3529/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8591 - val_loss: 0.8671\n",
            "Epoch 3530/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8020 - val_loss: 0.5564\n",
            "Epoch 3531/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.9185 - val_loss: 0.7089\n",
            "Epoch 3532/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.7879 - val_loss: 0.7116\n",
            "Epoch 3533/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8318 - val_loss: 0.5570\n",
            "Epoch 3534/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8991 - val_loss: 0.7906\n",
            "Epoch 3535/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8458 - val_loss: 0.7056\n",
            "Epoch 3536/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8271 - val_loss: 0.5333\n",
            "Epoch 3537/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8900 - val_loss: 0.7983\n",
            "Epoch 3538/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 1.2213 - val_loss: 0.8453\n",
            "Epoch 3539/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8984 - val_loss: 0.5389\n",
            "Epoch 3540/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8004 - val_loss: 0.8734\n",
            "Epoch 3541/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.0134 - val_loss: 0.5699\n",
            "Epoch 3542/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.9051 - val_loss: 0.7008\n",
            "Epoch 3543/5000\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.8738 - val_loss: 0.6741\n",
            "Epoch 3544/5000\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.8386 - val_loss: 0.6725\n",
            "Epoch 3545/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8410 - val_loss: 0.5575\n",
            "Epoch 3546/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8208 - val_loss: 0.8200\n",
            "Epoch 3547/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.9201 - val_loss: 0.5877\n",
            "Epoch 3548/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8470 - val_loss: 0.5907\n",
            "Epoch 3549/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.9172 - val_loss: 0.6808\n",
            "Epoch 3550/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.9471 - val_loss: 0.6541\n",
            "Epoch 3551/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8819 - val_loss: 0.4836\n",
            "Epoch 3552/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8200 - val_loss: 0.6758\n",
            "Epoch 3553/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8444 - val_loss: 0.6216\n",
            "Epoch 3554/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8324 - val_loss: 0.5832\n",
            "Epoch 3555/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.9394 - val_loss: 0.7652\n",
            "Epoch 3556/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.9239 - val_loss: 0.6869\n",
            "Epoch 3557/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8442 - val_loss: 0.6948\n",
            "Epoch 3558/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8575 - val_loss: 0.7002\n",
            "Epoch 3559/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8048 - val_loss: 0.5217\n",
            "Epoch 3560/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8295 - val_loss: 0.6520\n",
            "Epoch 3561/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.9336 - val_loss: 0.4857\n",
            "Epoch 3562/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8918 - val_loss: 0.6907\n",
            "Epoch 3563/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8144 - val_loss: 0.4698\n",
            "Epoch 3564/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8884 - val_loss: 0.6656\n",
            "Epoch 3565/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8604 - val_loss: 0.5416\n",
            "Epoch 3566/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8873 - val_loss: 0.8191\n",
            "Epoch 3567/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9298 - val_loss: 0.4998\n",
            "Epoch 3568/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8350 - val_loss: 0.5549\n",
            "Epoch 3569/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9174 - val_loss: 0.6123\n",
            "Epoch 3570/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8872 - val_loss: 0.5474\n",
            "Epoch 3571/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8753 - val_loss: 0.5732\n",
            "Epoch 3572/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8820 - val_loss: 0.6221\n",
            "Epoch 3573/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8206 - val_loss: 0.5298\n",
            "Epoch 3574/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8038 - val_loss: 0.9120\n",
            "Epoch 3575/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8511 - val_loss: 0.7874\n",
            "Epoch 3576/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.9703 - val_loss: 0.4432\n",
            "Epoch 3577/5000\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.8160 - val_loss: 0.6507\n",
            "Epoch 3578/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8128 - val_loss: 0.7288\n",
            "Epoch 3579/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8754 - val_loss: 1.1253\n",
            "Epoch 3580/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8234 - val_loss: 0.6714\n",
            "Epoch 3581/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9020 - val_loss: 0.6455\n",
            "Epoch 3582/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7799 - val_loss: 0.7492\n",
            "Epoch 3583/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8546 - val_loss: 0.7022\n",
            "Epoch 3584/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7622 - val_loss: 0.8408\n",
            "Epoch 3585/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8552 - val_loss: 0.7005\n",
            "Epoch 3586/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8535 - val_loss: 0.5479\n",
            "Epoch 3587/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7991 - val_loss: 0.5692\n",
            "Epoch 3588/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9694 - val_loss: 0.6883\n",
            "Epoch 3589/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8761 - val_loss: 0.5586\n",
            "Epoch 3590/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8710 - val_loss: 0.5390\n",
            "Epoch 3591/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8335 - val_loss: 0.6477\n",
            "Epoch 3592/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7910 - val_loss: 0.5674\n",
            "Epoch 3593/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8369 - val_loss: 0.5798\n",
            "Epoch 3594/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8398 - val_loss: 0.5905\n",
            "Epoch 3595/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7744 - val_loss: 0.8392\n",
            "Epoch 3596/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8590 - val_loss: 0.6540\n",
            "Epoch 3597/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8863 - val_loss: 0.5674\n",
            "Epoch 3598/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8613 - val_loss: 0.5955\n",
            "Epoch 3599/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8306 - val_loss: 0.6961\n",
            "Epoch 3600/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8789 - val_loss: 0.5746\n",
            "Epoch 3601/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9312 - val_loss: 0.7867\n",
            "Epoch 3602/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8208 - val_loss: 0.6374\n",
            "Epoch 3603/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8117 - val_loss: 0.6388\n",
            "Epoch 3604/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8928 - val_loss: 0.6187\n",
            "Epoch 3605/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8694 - val_loss: 0.7920\n",
            "Epoch 3606/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8279 - val_loss: 0.5142\n",
            "Epoch 3607/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7874 - val_loss: 1.1476\n",
            "Epoch 3608/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8178 - val_loss: 0.5528\n",
            "Epoch 3609/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8326 - val_loss: 0.7426\n",
            "Epoch 3610/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8582 - val_loss: 0.6849\n",
            "Epoch 3611/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8295 - val_loss: 0.6752\n",
            "Epoch 3612/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8931 - val_loss: 0.7257\n",
            "Epoch 3613/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8788 - val_loss: 0.7131\n",
            "Epoch 3614/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8810 - val_loss: 0.6745\n",
            "Epoch 3615/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8759 - val_loss: 0.7411\n",
            "Epoch 3616/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8735 - val_loss: 0.5275\n",
            "Epoch 3617/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9057 - val_loss: 0.5992\n",
            "Epoch 3618/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8382 - val_loss: 0.8760\n",
            "Epoch 3619/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8918 - val_loss: 0.4805\n",
            "Epoch 3620/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8699 - val_loss: 0.6170\n",
            "Epoch 3621/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8484 - val_loss: 0.5010\n",
            "Epoch 3622/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8075 - val_loss: 0.9282\n",
            "Epoch 3623/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9131 - val_loss: 0.4357\n",
            "Epoch 3624/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9497 - val_loss: 0.7412\n",
            "Epoch 3625/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8750 - val_loss: 0.6510\n",
            "Epoch 3626/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8468 - val_loss: 0.8442\n",
            "Epoch 3627/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8576 - val_loss: 0.5790\n",
            "Epoch 3628/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.9329 - val_loss: 0.8578\n",
            "Epoch 3629/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9042 - val_loss: 0.6962\n",
            "Epoch 3630/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8570 - val_loss: 0.6744\n",
            "Epoch 3631/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8240 - val_loss: 0.6660\n",
            "Epoch 3632/5000\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.8376 - val_loss: 0.5409\n",
            "Epoch 3633/5000\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.9348 - val_loss: 0.5788\n",
            "Epoch 3634/5000\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.8893 - val_loss: 0.8197\n",
            "Epoch 3635/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8190 - val_loss: 0.6008\n",
            "Epoch 3636/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8514 - val_loss: 0.7471\n",
            "Epoch 3637/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8419 - val_loss: 0.6889\n",
            "Epoch 3638/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8350 - val_loss: 0.6228\n",
            "Epoch 3639/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8633 - val_loss: 0.6264\n",
            "Epoch 3640/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7930 - val_loss: 0.7301\n",
            "Epoch 3641/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8772 - val_loss: 0.6320\n",
            "Epoch 3642/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8751 - val_loss: 0.4643\n",
            "Epoch 3643/5000\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.8583 - val_loss: 0.7501\n",
            "Epoch 3644/5000\n",
            "33/33 [==============================] - 0s 8ms/step - loss: 0.9658 - val_loss: 0.6174\n",
            "Epoch 3645/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8159 - val_loss: 0.5816\n",
            "Epoch 3646/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8388 - val_loss: 0.6124\n",
            "Epoch 3647/5000\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.8689 - val_loss: 0.6425\n",
            "Epoch 3648/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.7847 - val_loss: 0.7168\n",
            "Epoch 3649/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8629 - val_loss: 0.4871\n",
            "Epoch 3650/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8753 - val_loss: 1.1117\n",
            "Epoch 3651/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8448 - val_loss: 0.6170\n",
            "Epoch 3652/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8428 - val_loss: 0.5546\n",
            "Epoch 3653/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8541 - val_loss: 0.6218\n",
            "Epoch 3654/5000\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.9788 - val_loss: 0.5326\n",
            "Epoch 3655/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8735 - val_loss: 0.5463\n",
            "Epoch 3656/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8624 - val_loss: 0.6132\n",
            "Epoch 3657/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8461 - val_loss: 0.5624\n",
            "Epoch 3658/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8548 - val_loss: 0.6038\n",
            "Epoch 3659/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8536 - val_loss: 0.5783\n",
            "Epoch 3660/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8841 - val_loss: 0.5716\n",
            "Epoch 3661/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8119 - val_loss: 0.5989\n",
            "Epoch 3662/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8066 - val_loss: 0.6575\n",
            "Epoch 3663/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7949 - val_loss: 0.8072\n",
            "Epoch 3664/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8327 - val_loss: 0.7020\n",
            "Epoch 3665/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8399 - val_loss: 0.6704\n",
            "Epoch 3666/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8404 - val_loss: 0.5926\n",
            "Epoch 3667/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8079 - val_loss: 0.6778\n",
            "Epoch 3668/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8501 - val_loss: 0.7124\n",
            "Epoch 3669/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8593 - val_loss: 0.8487\n",
            "Epoch 3670/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8559 - val_loss: 0.8069\n",
            "Epoch 3671/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8466 - val_loss: 0.5830\n",
            "Epoch 3672/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8974 - val_loss: 0.5726\n",
            "Epoch 3673/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8056 - val_loss: 0.6854\n",
            "Epoch 3674/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7973 - val_loss: 0.4926\n",
            "Epoch 3675/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8361 - val_loss: 0.8321\n",
            "Epoch 3676/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8250 - val_loss: 0.8150\n",
            "Epoch 3677/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8755 - val_loss: 0.6816\n",
            "Epoch 3678/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8199 - val_loss: 0.5742\n",
            "Epoch 3679/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7797 - val_loss: 0.7702\n",
            "Epoch 3680/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8505 - val_loss: 0.8278\n",
            "Epoch 3681/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8437 - val_loss: 0.7199\n",
            "Epoch 3682/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9284 - val_loss: 0.8055\n",
            "Epoch 3683/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8211 - val_loss: 0.8034\n",
            "Epoch 3684/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9112 - val_loss: 0.6018\n",
            "Epoch 3685/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8620 - val_loss: 0.7254\n",
            "Epoch 3686/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8403 - val_loss: 0.7446\n",
            "Epoch 3687/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8374 - val_loss: 0.7819\n",
            "Epoch 3688/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8415 - val_loss: 0.7433\n",
            "Epoch 3689/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8240 - val_loss: 0.7566\n",
            "Epoch 3690/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7990 - val_loss: 0.6444\n",
            "Epoch 3691/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8797 - val_loss: 0.6019\n",
            "Epoch 3692/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8758 - val_loss: 0.6378\n",
            "Epoch 3693/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8893 - val_loss: 0.6103\n",
            "Epoch 3694/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8263 - val_loss: 0.5032\n",
            "Epoch 3695/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8896 - val_loss: 0.7634\n",
            "Epoch 3696/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7987 - val_loss: 0.8587\n",
            "Epoch 3697/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8797 - val_loss: 0.5664\n",
            "Epoch 3698/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8565 - val_loss: 1.0464\n",
            "Epoch 3699/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9337 - val_loss: 0.6400\n",
            "Epoch 3700/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8661 - val_loss: 0.6844\n",
            "Epoch 3701/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8224 - val_loss: 0.7938\n",
            "Epoch 3702/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9296 - val_loss: 0.6409\n",
            "Epoch 3703/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8652 - val_loss: 0.6725\n",
            "Epoch 3704/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8387 - val_loss: 0.6332\n",
            "Epoch 3705/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.9449 - val_loss: 0.6631\n",
            "Epoch 3706/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8154 - val_loss: 0.7228\n",
            "Epoch 3707/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8586 - val_loss: 0.6620\n",
            "Epoch 3708/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8248 - val_loss: 0.6846\n",
            "Epoch 3709/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8659 - val_loss: 0.8101\n",
            "Epoch 3710/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8561 - val_loss: 0.7820\n",
            "Epoch 3711/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8838 - val_loss: 0.6832\n",
            "Epoch 3712/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8456 - val_loss: 0.5809\n",
            "Epoch 3713/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8129 - val_loss: 0.6634\n",
            "Epoch 3714/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8868 - val_loss: 0.6961\n",
            "Epoch 3715/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8484 - val_loss: 0.6266\n",
            "Epoch 3716/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8463 - val_loss: 0.5768\n",
            "Epoch 3717/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9042 - val_loss: 0.6766\n",
            "Epoch 3718/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8924 - val_loss: 0.5319\n",
            "Epoch 3719/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8691 - val_loss: 0.4724\n",
            "Epoch 3720/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8316 - val_loss: 0.7080\n",
            "Epoch 3721/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8523 - val_loss: 0.8872\n",
            "Epoch 3722/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8084 - val_loss: 0.5007\n",
            "Epoch 3723/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8199 - val_loss: 0.6286\n",
            "Epoch 3724/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8621 - val_loss: 0.6471\n",
            "Epoch 3725/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.9067 - val_loss: 0.6915\n",
            "Epoch 3726/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8011 - val_loss: 0.6273\n",
            "Epoch 3727/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8864 - val_loss: 0.7376\n",
            "Epoch 3728/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8658 - val_loss: 0.7412\n",
            "Epoch 3729/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7877 - val_loss: 0.5854\n",
            "Epoch 3730/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8198 - val_loss: 0.9171\n",
            "Epoch 3731/5000\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.8778 - val_loss: 0.6182\n",
            "Epoch 3732/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8056 - val_loss: 0.7601\n",
            "Epoch 3733/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8550 - val_loss: 0.8193\n",
            "Epoch 3734/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8582 - val_loss: 0.7613\n",
            "Epoch 3735/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8502 - val_loss: 0.5761\n",
            "Epoch 3736/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.9004 - val_loss: 0.6829\n",
            "Epoch 3737/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8462 - val_loss: 0.5577\n",
            "Epoch 3738/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8119 - val_loss: 0.5718\n",
            "Epoch 3739/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8089 - val_loss: 0.6025\n",
            "Epoch 3740/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8715 - val_loss: 0.8808\n",
            "Epoch 3741/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8412 - val_loss: 0.5435\n",
            "Epoch 3742/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8367 - val_loss: 0.6476\n",
            "Epoch 3743/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8499 - val_loss: 0.6077\n",
            "Epoch 3744/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9349 - val_loss: 0.5423\n",
            "Epoch 3745/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8892 - val_loss: 0.6750\n",
            "Epoch 3746/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8036 - val_loss: 0.5802\n",
            "Epoch 3747/5000\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.8328 - val_loss: 0.7014\n",
            "Epoch 3748/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8691 - val_loss: 0.5662\n",
            "Epoch 3749/5000\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.8682 - val_loss: 0.6285\n",
            "Epoch 3750/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8704 - val_loss: 0.7848\n",
            "Epoch 3751/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8750 - val_loss: 0.7028\n",
            "Epoch 3752/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8508 - val_loss: 0.6598\n",
            "Epoch 3753/5000\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.8573 - val_loss: 0.4365\n",
            "Epoch 3754/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.9157 - val_loss: 0.4699\n",
            "Epoch 3755/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8497 - val_loss: 0.7244\n",
            "Epoch 3756/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8564 - val_loss: 0.8372\n",
            "Epoch 3757/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8772 - val_loss: 0.6376\n",
            "Epoch 3758/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8554 - val_loss: 0.7082\n",
            "Epoch 3759/5000\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.8479 - val_loss: 0.8460\n",
            "Epoch 3760/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8541 - val_loss: 0.6409\n",
            "Epoch 3761/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8752 - val_loss: 0.6629\n",
            "Epoch 3762/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8286 - val_loss: 0.7752\n",
            "Epoch 3763/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7998 - val_loss: 0.5246\n",
            "Epoch 3764/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8450 - val_loss: 0.5296\n",
            "Epoch 3765/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8993 - val_loss: 0.8317\n",
            "Epoch 3766/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8115 - val_loss: 0.5730\n",
            "Epoch 3767/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7656 - val_loss: 0.5418\n",
            "Epoch 3768/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9163 - val_loss: 0.6181\n",
            "Epoch 3769/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8856 - val_loss: 0.6653\n",
            "Epoch 3770/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8636 - val_loss: 0.6172\n",
            "Epoch 3771/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8519 - val_loss: 0.7818\n",
            "Epoch 3772/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8475 - val_loss: 0.9565\n",
            "Epoch 3773/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9155 - val_loss: 0.6178\n",
            "Epoch 3774/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8153 - val_loss: 0.6697\n",
            "Epoch 3775/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.9022 - val_loss: 0.6226\n",
            "Epoch 3776/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8853 - val_loss: 0.8726\n",
            "Epoch 3777/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9088 - val_loss: 0.7137\n",
            "Epoch 3778/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7951 - val_loss: 0.8442\n",
            "Epoch 3779/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8522 - val_loss: 0.7379\n",
            "Epoch 3780/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8088 - val_loss: 0.6297\n",
            "Epoch 3781/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9040 - val_loss: 0.7866\n",
            "Epoch 3782/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8163 - val_loss: 0.6113\n",
            "Epoch 3783/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8251 - val_loss: 0.8562\n",
            "Epoch 3784/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8762 - val_loss: 0.6908\n",
            "Epoch 3785/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8749 - val_loss: 0.9744\n",
            "Epoch 3786/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7828 - val_loss: 0.6331\n",
            "Epoch 3787/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8974 - val_loss: 0.7153\n",
            "Epoch 3788/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8131 - val_loss: 0.7046\n",
            "Epoch 3789/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8999 - val_loss: 0.7024\n",
            "Epoch 3790/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9046 - val_loss: 0.7879\n",
            "Epoch 3791/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8154 - val_loss: 0.6684\n",
            "Epoch 3792/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8291 - val_loss: 0.6530\n",
            "Epoch 3793/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8723 - val_loss: 0.8387\n",
            "Epoch 3794/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8058 - val_loss: 0.6198\n",
            "Epoch 3795/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8892 - val_loss: 0.7589\n",
            "Epoch 3796/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8518 - val_loss: 0.8589\n",
            "Epoch 3797/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8039 - val_loss: 0.5649\n",
            "Epoch 3798/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8724 - val_loss: 0.8183\n",
            "Epoch 3799/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8599 - val_loss: 0.7610\n",
            "Epoch 3800/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8276 - val_loss: 0.6126\n",
            "Epoch 3801/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9804 - val_loss: 0.7734\n",
            "Epoch 3802/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8692 - val_loss: 0.8919\n",
            "Epoch 3803/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9031 - val_loss: 0.6641\n",
            "Epoch 3804/5000\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8343 - val_loss: 0.8124\n",
            "Epoch 3805/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8588 - val_loss: 0.7326\n",
            "Epoch 3806/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9029 - val_loss: 0.7072\n",
            "Epoch 3807/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8273 - val_loss: 0.8269\n",
            "Epoch 3808/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8252 - val_loss: 0.6672\n",
            "Epoch 3809/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8179 - val_loss: 0.8085\n",
            "Epoch 3810/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8784 - val_loss: 0.6180\n",
            "Epoch 3811/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8211 - val_loss: 0.7352\n",
            "Epoch 3812/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8160 - val_loss: 0.6866\n",
            "Epoch 3813/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8960 - val_loss: 0.6686\n",
            "Epoch 3814/5000\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8649 - val_loss: 0.5021\n",
            "Epoch 3815/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8449 - val_loss: 0.7948\n",
            "Epoch 3816/5000\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7952 - val_loss: 0.9047\n",
            "Epoch 3817/5000\n",
            "23/33 [===================>..........] - ETA: 0s - loss: 1.0025Restoring model weights from the end of the best epoch: 2817.\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.9009 - val_loss: 0.5989\n",
            "Epoch 3817: early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-b383c653ffcb>:9: UserWarning: Attempt to set non-positive ylim on a log-scaled axis will be ignored.\n",
            "  plt.ylim((0, 10))\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val loss: 0.41763997077941895\n",
            "Train loss: 0.9576510787010193\n",
            "Test loss: 0.971544623374939\n",
            "dO18 RMSE: 1.0398559752210232\n",
            "EXPECTED:\n",
            "    d18O_cel_mean  d18O_cel_variance\n",
            "0          26.130            0.19025\n",
            "1          26.984            0.40123\n",
            "2          24.656            0.17728\n",
            "3          26.356            0.03953\n",
            "4          23.962            0.30992\n",
            "5          24.848            0.15842\n",
            "6          25.080            0.05125\n",
            "7          26.546            2.14378\n",
            "8          25.682            0.94472\n",
            "9          24.028            0.45852\n",
            "10         23.944            0.15813\n",
            "11         23.752            0.52437\n",
            "12         26.018            0.96417\n",
            "\n",
            "PREDICTED:\n",
            "    d18O_cel_mean  d18O_cel_variance\n",
            "0       26.516935           1.434427\n",
            "1       26.516935           1.434427\n",
            "2       24.791250           3.040311\n",
            "3       24.847542           2.923729\n",
            "4       24.733768           3.338661\n",
            "5       23.633116           3.713480\n",
            "6       23.633116           3.713480\n",
            "7       24.733780           3.338667\n",
            "8       24.791265           3.040316\n",
            "9       23.633095           3.713480\n",
            "10      25.071346           2.422783\n",
            "11      24.662874           3.345450\n",
            "12      25.071346           2.422783\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/gdrive/MyDrive/amazon_rainforest_files/variational/model/random_all_isorix_carbon_ensemble.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2) Grouped, fixed, all columns\n",
        "\n",
        "We can't (easily) generate isoscapes with these because the isoscapes for 'predkrig_br_lat_ISORG', 'Iso_Oxi_Stack_mean_TERZER',\n",
        "                   'isoscape_fullmodel_d18O_prec_REGRESSION' are not easily retrievable... but I'm curious how much better the model is if these columns are included."
      ],
      "metadata": {
        "id": "wPDSSm__DR53"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "grouped_fixed_fileset = {\n",
        "    'TRAIN' : os.path.join(FP_ROOT, 'amazon_sample_data/canonical/uc_davis_train_fixed_grouped.csv'),\n",
        "    'TEST' : os.path.join(FP_ROOT, 'amazon_sample_data/canonical/uc_davis_test_fixed_grouped.csv'),\n",
        "    'VALIDATION' : os.path.join(FP_ROOT, 'amazon_sample_data/canonical/uc_davis_validation_fixed_grouped.csv'),\n",
        "}\n",
        "\n",
        "columns_to_passthrough = [\n",
        "    'ordinary_kriging_linear_d18O_predicted_mean',\n",
        "    'ordinary_kriging_linear_d18O_predicted_variance']\n",
        "columns_to_scale = []\n",
        "columns_to_standardize = [\n",
        "    'lat', 'long', 'VPD', 'RH', 'PET', 'DEM', 'PA',\n",
        "    'Mean Annual Temperature','Mean Annual Precipitation',\n",
        "    'Iso_Oxi_Stack_mean_TERZER',\n",
        "    'isoscape_fullmodel_d18O_prec_REGRESSION']\n",
        "\n",
        "data = load_and_scale(grouped_fixed_fileset, columns_to_passthrough, columns_to_scale, columns_to_standardize)\n",
        "model = train_and_evaluate(data, \"fixed_all_isorix_carbon_ensemble\", training_batch_size=3)\n",
        "model.save(get_model_save_location(\"fixed_all_isorix_carbon_ensemble.tf\"), save_format='tf')\n",
        "dump(data.feature_scaler, get_model_save_location('fixed_all_isorix_carbon_ensemble.pkl'))"
      ],
      "metadata": {
        "id": "V9_5iUkDVoCV",
        "outputId": "0ccff17e-40a0-4975-aac7-991ea07b673c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Driver: GTiff/GeoTIFF\n",
            "Size is 541 x 467 x 1\n",
            "Projection is GEOGCS[\"SIRGAS 2000\",DATUM[\"Sistema_de_Referencia_Geocentrico_para_las_AmericaS_2000\",SPHEROID[\"GRS 1980\",6378137,298.257222101004,AUTHORITY[\"EPSG\",\"7019\"]],AUTHORITY[\"EPSG\",\"6674\"]],PRIMEM[\"Greenwich\",0],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AXIS[\"Latitude\",NORTH],AXIS[\"Longitude\",EAST],AUTHORITY[\"EPSG\",\"4674\"]]\n",
            "Origin = (-73.922043, 5.233124)\n",
            "Pixel Size = (0.08333, -0.08333)\n",
            "[[[-- -- -- ... -- -- --]\n",
            "  [-- -- -- ... -- -- --]\n",
            "  [-- -- -- ... -- -- --]\n",
            "  ...\n",
            "  [-- -- -- ... -- -- --]\n",
            "  [-- -- -- ... -- -- --]\n",
            "  [-- -- -- ... -- -- --]]\n",
            "\n",
            " [[-- -- -- ... -- -- --]\n",
            "  [-- -- -- ... -- -- --]\n",
            "  [-- -- -- ... -- -- --]\n",
            "  ...\n",
            "  [-- -- -- ... -- -- --]\n",
            "  [-- -- -- ... -- -- --]\n",
            "  [-- -- -- ... -- -- --]]\n",
            "\n",
            " [[-- -- -- ... -- -- --]\n",
            "  [-- -- -- ... -- -- --]\n",
            "  [-- -- -- ... -- -- --]\n",
            "  ...\n",
            "  [-- -- -- ... -- -- --]\n",
            "  [-- -- -- ... -- -- --]\n",
            "  [-- -- -- ... -- -- --]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[-- -- -- ... -- -- --]\n",
            "  [-- -- -- ... -- -- --]\n",
            "  [-- -- -- ... -- -- --]\n",
            "  ...\n",
            "  [-- -- -- ... -- -- --]\n",
            "  [-- -- -- ... -- -- --]\n",
            "  [-- -- -- ... -- -- --]]\n",
            "\n",
            " [[-- -- -- ... -- -- --]\n",
            "  [-- -- -- ... -- -- --]\n",
            "  [-- -- -- ... -- -- --]\n",
            "  ...\n",
            "  [-- -- -- ... -- -- --]\n",
            "  [-- -- -- ... -- -- --]\n",
            "  [-- -- -- ... -- -- --]]\n",
            "\n",
            " [[-- -- -- ... -- -- --]\n",
            "  [-- -- -- ... -- -- --]\n",
            "  [-- -- -- ... -- -- --]\n",
            "  ...\n",
            "  [-- -- -- ... -- -- --]\n",
            "  [-- -- -- ... -- -- --]\n",
            "  [-- -- -- ... -- -- --]]]\n",
            "[[-- -- -- ... -- -- --]\n",
            " [-- -- -- ... -- -- --]\n",
            " [-- -- -- ... -- -- --]\n",
            " ...\n",
            " [-- -- -- ... -- -- --]\n",
            " [-- -- -- ... -- -- --]\n",
            " [-- -- -- ... -- -- --]]\n",
            "Driver: GTiff/GeoTIFF\n",
            "Size is 235 x 218 x 2\n",
            "Projection is GEOGCS[\"SIRGAS 2000\",DATUM[\"Sistema_de_Referencia_Geocentrico_para_las_AmericaS_2000\",SPHEROID[\"GRS 1980\",6378137,298.257222101004,AUTHORITY[\"EPSG\",\"7019\"]],AUTHORITY[\"EPSG\",\"6674\"]],PRIMEM[\"Greenwich\",0],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AXIS[\"Latitude\",NORTH],AXIS[\"Longitude\",EAST],AUTHORITY[\"EPSG\",\"4674\"]]\n",
            "Origin = (-74.0, 4.500000000659528)\n",
            "Pixel Size = (0.166666666667993, -0.16666666666799657)\n",
            "[[[-- -- -- ... -- -- --]\n",
            "  [-- -- -- ... -- -- --]\n",
            "  [-- -- -- ... -- -- --]\n",
            "  ...\n",
            "  [-- -- -- ... -- -- --]\n",
            "  [-- -- -- ... -- -- --]\n",
            "  [-- -- -- ... -- -- --]]\n",
            "\n",
            " [[-- -- -- ... -- -- --]\n",
            "  [-- -- -- ... -- -- --]\n",
            "  [-- -- -- ... -- -- --]\n",
            "  ...\n",
            "  [-- -- -- ... -- -- --]\n",
            "  [-- -- -- ... -- -- --]\n",
            "  [-- -- -- ... -- -- --]]\n",
            "\n",
            " [[-- -- -- ... -- -- --]\n",
            "  [-- -- -- ... -- -- --]\n",
            "  [-- -- -- ... -- -- --]\n",
            "  ...\n",
            "  [-- -- -- ... -- -- --]\n",
            "  [-- -- -- ... -- -- --]\n",
            "  [-- -- -- ... -- -- --]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[-- -- -- ... -- -- --]\n",
            "  [-- -- -- ... -- -- --]\n",
            "  [-- -- -- ... -- -- --]\n",
            "  ...\n",
            "  [-- -- -- ... -- -- --]\n",
            "  [-- -- -- ... -- -- --]\n",
            "  [-- -- -- ... -- -- --]]\n",
            "\n",
            " [[-- -- -- ... -- -- --]\n",
            "  [-- -- -- ... -- -- --]\n",
            "  [-- -- -- ... -- -- --]\n",
            "  ...\n",
            "  [-- -- -- ... -- -- --]\n",
            "  [-- -- -- ... -- -- --]\n",
            "  [-- -- -- ... -- -- --]]\n",
            "\n",
            " [[-- -- -- ... -- -- --]\n",
            "  [-- -- -- ... -- -- --]\n",
            "  [-- -- -- ... -- -- --]\n",
            "  ...\n",
            "  [-- -- -- ... -- -- --]\n",
            "  [-- -- -- ... -- -- --]\n",
            "  [-- -- -- ... -- -- --]]]\n",
            "[[-- -- -- ... -- -- --]\n",
            " [-- -- -- ... -- -- --]\n",
            " [-- -- -- ... -- -- --]\n",
            " ...\n",
            " [-- -- -- ... -- -- --]\n",
            " [-- -- -- ... -- -- --]\n",
            " [-- -- -- ... -- -- --]]\n",
            "Driver: GTiff/GeoTIFF\n",
            "Size is 235 x 218 x 2\n",
            "Projection is GEOGCS[\"SIRGAS 2000\",DATUM[\"Sistema_de_Referencia_Geocentrico_para_las_AmericaS_2000\",SPHEROID[\"GRS 1980\",6378137,298.257222101004,AUTHORITY[\"EPSG\",\"7019\"]],AUTHORITY[\"EPSG\",\"6674\"]],PRIMEM[\"Greenwich\",0],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AXIS[\"Latitude\",NORTH],AXIS[\"Longitude\",EAST],AUTHORITY[\"EPSG\",\"4674\"]]\n",
            "Origin = (-74.0, 4.500000000659528)\n",
            "Pixel Size = (0.166666666667993, -0.16666666666799657)\n",
            "[[[-- -- -- ... -- -- --]\n",
            "  [-- -- -- ... -- -- --]\n",
            "  [-- -- -- ... -- -- --]\n",
            "  ...\n",
            "  [-- -- -- ... -- -- --]\n",
            "  [-- -- -- ... -- -- --]\n",
            "  [-- -- -- ... -- -- --]]\n",
            "\n",
            " [[-- -- -- ... -- -- --]\n",
            "  [-- -- -- ... -- -- --]\n",
            "  [-- -- -- ... -- -- --]\n",
            "  ...\n",
            "  [-- -- -- ... -- -- --]\n",
            "  [-- -- -- ... -- -- --]\n",
            "  [-- -- -- ... -- -- --]]\n",
            "\n",
            " [[-- -- -- ... -- -- --]\n",
            "  [-- -- -- ... -- -- --]\n",
            "  [-- -- -- ... -- -- --]\n",
            "  ...\n",
            "  [-- -- -- ... -- -- --]\n",
            "  [-- -- -- ... -- -- --]\n",
            "  [-- -- -- ... -- -- --]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[-- -- -- ... -- -- --]\n",
            "  [-- -- -- ... -- -- --]\n",
            "  [-- -- -- ... -- -- --]\n",
            "  ...\n",
            "  [-- -- -- ... -- -- --]\n",
            "  [-- -- -- ... -- -- --]\n",
            "  [-- -- -- ... -- -- --]]\n",
            "\n",
            " [[-- -- -- ... -- -- --]\n",
            "  [-- -- -- ... -- -- --]\n",
            "  [-- -- -- ... -- -- --]\n",
            "  ...\n",
            "  [-- -- -- ... -- -- --]\n",
            "  [-- -- -- ... -- -- --]\n",
            "  [-- -- -- ... -- -- --]]\n",
            "\n",
            " [[-- -- -- ... -- -- --]\n",
            "  [-- -- -- ... -- -- --]\n",
            "  [-- -- -- ... -- -- --]\n",
            "  ...\n",
            "  [-- -- -- ... -- -- --]\n",
            "  [-- -- -- ... -- -- --]\n",
            "  [-- -- -- ... -- -- --]]]\n",
            "[[-- -- -- ... -- -- --]\n",
            " [-- -- -- ... -- -- --]\n",
            " [-- -- -- ... -- -- --]\n",
            " ...\n",
            " [-- -- -- ... -- -- --]\n",
            " [-- -- -- ... -- -- --]\n",
            " [-- -- -- ... -- -- --]]\n",
            "-3.7896652221679688 -3.995544837 -57.58927257\n",
            "-3.5083389282226562 -3.9923 -54.908\n",
            "-3.5083389282226562 -3.9923 -54.908\n",
            "-3.5083389282226562 -3.9923 -54.908\n",
            "-3.5083389282226562 -3.9923 -54.908\n",
            "-3.5083389282226562 -3.9923 -54.908\n",
            "-3.5083389282226562 -3.9923 -54.908\n",
            "-3.5083389282226562 -3.9923 -54.908\n",
            "-3.7896652221679688 -3.995544837 -57.58927257\n",
            "-3.7896652221679688 -3.995544837 -57.58927257\n",
            "-3.7896652221679688 -3.995544837 -57.58927257\n",
            "-4.08642578125 -2.63795 -60.14972\n",
            "-4.08642578125 -2.63795 -60.14972\n",
            "-4.08642578125 -2.63795 -60.14972\n",
            "-4.08642578125 -2.63795 -60.14972\n",
            "-4.08642578125 -2.63795 -60.14972\n",
            "-3.861750602722168 -0.90361 -60.43406\n",
            "-3.7896652221679688 -3.995544837 -57.58927257\n",
            "-4.08642578125 -2.63795 -60.14972\n",
            "-3.861750602722168 -0.90361 -60.43406\n",
            "-3.861750602722168 -0.90361 -60.43406\n",
            "-3.861750602722168 -0.90361 -60.43406\n",
            "-3.861750602722168 -0.90361 -60.43406\n",
            "-3.861750602722168 -0.90361 -60.43406\n",
            "-3.861750602722168 -0.90361 -60.43406\n",
            "-3.981933275858561 -2.499 -59.121\n",
            "-3.981933275858561 -2.496 -59.126\n",
            "-3.981933275858561 -2.495 -59.12\n",
            "-3.981933275858561 -2.497 -59.116\n",
            "-3.981933275858561 -2.495 -59.124\n",
            "-3.981933275858561 -2.493 -59.121\n",
            "-3.981933275858561 -2.498 -59.118\n",
            "-3.981933275858561 -2.482 -59.126\n",
            "-3.981933275858561 -2.483 -59.126\n",
            "-3.981933275858561 -2.496 -59.125\n",
            "-3.981933275858561 -2.495 -59.123\n",
            "-3.981933275858561 -2.495 -59.122\n",
            "-3.981933275858561 -2.496 -59.125\n",
            "-3.981933275858561 -2.485 -59.125\n",
            "-3.981933275858561 -2.492 -59.123\n",
            "-3.981933275858561 -2.495 -59.124\n",
            "-3.981933275858561 -2.496 -59.121\n",
            "-3.7896652221679688 -3.995544837 -57.58927257\n",
            "-3.981933275858561 -2.485 -59.124\n",
            "-3.981933275858561 -2.495 -59.119\n",
            "-3.981933275858561 -2.494 -59.119\n",
            "-3.981933275858561 -2.486 -59.126\n",
            "-3.981933275858561 -2.496 -59.121\n",
            "-3.981933275858561 -2.495 -59.122\n",
            "-3.981933275858561 -2.495 -59.121\n",
            "-3.981933275858561 -2.496 -59.118\n",
            "-3.981933275858561 -2.496 -59.12\n",
            "-3.981933275858561 -2.493 -59.121\n",
            "-3.981933275858561 -2.497 -59.121\n",
            "-3.981933275858561 -2.483 -59.124\n",
            "-3.563809076944987 -3.3983972 -54.973982\n",
            "-3.563809076944987 -3.3983972 -54.973982\n",
            "-3.563809076944987 -3.3983972 -54.973982\n",
            "-3.563809076944987 -3.3983972 -54.973982\n",
            "-3.563809076944987 -3.3983972 -54.973982\n",
            "-3.563809076944987 -3.3983972 -54.973982\n",
            "-3.563809076944987 -3.3983972 -54.973982\n",
            "-3.563809076944987 -3.3983972 -54.973982\n",
            "-3.563809076944987 -3.3983972 -54.973982\n",
            "-3.5083389282226562 -3.9923 -54.908\n",
            "-3.5083389282226562 -3.9923 -54.908\n",
            "-3.5083389282226562 -3.9923 -54.908\n",
            "-3.5083389282226562 -3.9923 -54.908\n",
            "-27.921724955240887 -3.995544837 -57.58927257\n",
            "-26.60095977783203 -3.9923 -54.908\n",
            "-26.60095977783203 -3.9923 -54.908\n",
            "-26.60095977783203 -3.9923 -54.908\n",
            "-26.60095977783203 -3.9923 -54.908\n",
            "-26.60095977783203 -3.9923 -54.908\n",
            "-26.60095977783203 -3.9923 -54.908\n",
            "-26.60095977783203 -3.9923 -54.908\n",
            "-27.921724955240887 -3.995544837 -57.58927257\n",
            "-27.921724955240887 -3.995544837 -57.58927257\n",
            "-27.921724955240887 -3.995544837 -57.58927257\n",
            "-27.24651336669922 -2.63795 -60.14972\n",
            "-27.24651336669922 -2.63795 -60.14972\n",
            "-27.24651336669922 -2.63795 -60.14972\n",
            "-27.24651336669922 -2.63795 -60.14972\n",
            "-27.24651336669922 -2.63795 -60.14972\n",
            "-26.286356608072918 -0.90361 -60.43406\n",
            "-27.921724955240887 -3.995544837 -57.58927257\n",
            "-27.24651336669922 -2.63795 -60.14972\n",
            "-26.286356608072918 -0.90361 -60.43406\n",
            "-26.286356608072918 -0.90361 -60.43406\n",
            "-26.286356608072918 -0.90361 -60.43406\n",
            "-26.286356608072918 -0.90361 -60.43406\n",
            "-26.286356608072918 -0.90361 -60.43406\n",
            "-26.286356608072918 -0.90361 -60.43406\n",
            "-26.38085428873698 -2.499 -59.121\n",
            "-26.38085428873698 -2.496 -59.126\n",
            "-26.38085428873698 -2.495 -59.12\n",
            "-26.38085428873698 -2.497 -59.116\n",
            "-26.38085428873698 -2.495 -59.124\n",
            "-26.38085428873698 -2.493 -59.121\n",
            "-26.38085428873698 -2.498 -59.118\n",
            "-26.38085428873698 -2.482 -59.126\n",
            "-26.38085428873698 -2.483 -59.126\n",
            "-26.38085428873698 -2.496 -59.125\n",
            "-26.38085428873698 -2.495 -59.123\n",
            "-26.38085428873698 -2.495 -59.122\n",
            "-26.38085428873698 -2.496 -59.125\n",
            "-26.38085428873698 -2.485 -59.125\n",
            "-26.38085428873698 -2.492 -59.123\n",
            "-26.38085428873698 -2.495 -59.124\n",
            "-26.38085428873698 -2.496 -59.121\n",
            "-27.921724955240887 -3.995544837 -57.58927257\n",
            "-26.38085428873698 -2.485 -59.124\n",
            "-26.38085428873698 -2.495 -59.119\n",
            "-26.38085428873698 -2.494 -59.119\n",
            "-26.38085428873698 -2.486 -59.126\n",
            "-26.38085428873698 -2.496 -59.121\n",
            "-26.38085428873698 -2.495 -59.122\n",
            "-26.38085428873698 -2.495 -59.121\n",
            "-26.38085428873698 -2.496 -59.118\n",
            "-26.38085428873698 -2.496 -59.12\n",
            "-26.38085428873698 -2.493 -59.121\n",
            "-26.38085428873698 -2.497 -59.121\n",
            "-26.38085428873698 -2.483 -59.124\n",
            "-26.48528798421224 -3.3983972 -54.973982\n",
            "-26.48528798421224 -3.3983972 -54.973982\n",
            "-26.48528798421224 -3.3983972 -54.973982\n",
            "-26.48528798421224 -3.3983972 -54.973982\n",
            "-26.48528798421224 -3.3983972 -54.973982\n",
            "-26.48528798421224 -3.3983972 -54.973982\n",
            "-26.48528798421224 -3.3983972 -54.973982\n",
            "-26.48528798421224 -3.3983972 -54.973982\n",
            "-26.48528798421224 -3.3983972 -54.973982\n",
            "-26.60095977783203 -3.9923 -54.908\n",
            "-26.60095977783203 -3.9923 -54.908\n",
            "-26.60095977783203 -3.9923 -54.908\n",
            "-26.60095977783203 -3.9923 -54.908\n",
            "0.033720908065636955 -3.995544837 -57.58927257\n",
            "0.07311890522638957 -3.9923 -54.908\n",
            "0.07311890522638957 -3.9923 -54.908\n",
            "0.07311890522638957 -3.9923 -54.908\n",
            "0.07311890522638957 -3.9923 -54.908\n",
            "0.07311890522638957 -3.9923 -54.908\n",
            "0.07311890522638957 -3.9923 -54.908\n",
            "0.07311890522638957 -3.9923 -54.908\n",
            "0.033720908065636955 -3.995544837 -57.58927257\n",
            "0.033720908065636955 -3.995544837 -57.58927257\n",
            "0.033720908065636955 -3.995544837 -57.58927257\n",
            "0.023719047506650288 -2.63795 -60.14972\n",
            "0.023719047506650288 -2.63795 -60.14972\n",
            "0.023719047506650288 -2.63795 -60.14972\n",
            "0.023719047506650288 -2.63795 -60.14972\n",
            "0.023719047506650288 -2.63795 -60.14972\n",
            "0.010363364592194557 -0.90361 -60.43406\n",
            "0.033720908065636955 -3.995544837 -57.58927257\n",
            "0.023719047506650288 -2.63795 -60.14972\n",
            "0.010363364592194557 -0.90361 -60.43406\n",
            "0.010363364592194557 -0.90361 -60.43406\n",
            "0.010363364592194557 -0.90361 -60.43406\n",
            "0.010363364592194557 -0.90361 -60.43406\n",
            "0.010363364592194557 -0.90361 -60.43406\n",
            "0.010363364592194557 -0.90361 -60.43406\n",
            "0.02884835998217265 -2.499 -59.121\n",
            "0.02884835998217265 -2.496 -59.126\n",
            "0.02884835998217265 -2.495 -59.12\n",
            "0.02884835998217265 -2.497 -59.116\n",
            "0.02884835998217265 -2.495 -59.124\n",
            "0.02884835998217265 -2.493 -59.121\n",
            "0.02884835998217265 -2.498 -59.118\n",
            "0.02884835998217265 -2.482 -59.126\n",
            "0.02884835998217265 -2.483 -59.126\n",
            "0.02884835998217265 -2.496 -59.125\n",
            "0.02884835998217265 -2.495 -59.123\n",
            "0.02884835998217265 -2.495 -59.122\n",
            "0.02884835998217265 -2.496 -59.125\n",
            "0.02884835998217265 -2.485 -59.125\n",
            "0.02884835998217265 -2.492 -59.123\n",
            "0.02884835998217265 -2.495 -59.124\n",
            "0.02884835998217265 -2.496 -59.121\n",
            "0.033720908065636955 -3.995544837 -57.58927257\n",
            "0.02884835998217265 -2.485 -59.124\n",
            "0.02884835998217265 -2.495 -59.119\n",
            "0.02884835998217265 -2.494 -59.119\n",
            "0.02884835998217265 -2.486 -59.126\n",
            "0.02884835998217265 -2.496 -59.121\n",
            "0.02884835998217265 -2.495 -59.122\n",
            "0.02884835998217265 -2.495 -59.121\n",
            "0.02884835998217265 -2.496 -59.118\n",
            "0.02884835998217265 -2.496 -59.12\n",
            "0.02884835998217265 -2.493 -59.121\n",
            "0.02884835998217265 -2.497 -59.121\n",
            "0.02884835998217265 -2.483 -59.124\n",
            "0.11904677748680115 -3.3983972 -54.973982\n",
            "0.11904677748680115 -3.3983972 -54.973982\n",
            "0.11904677748680115 -3.3983972 -54.973982\n",
            "0.11904677748680115 -3.3983972 -54.973982\n",
            "0.11904677748680115 -3.3983972 -54.973982\n",
            "0.11904677748680115 -3.3983972 -54.973982\n",
            "0.11904677748680115 -3.3983972 -54.973982\n",
            "0.11904677748680115 -3.3983972 -54.973982\n",
            "0.11904677748680115 -3.3983972 -54.973982\n",
            "0.07311890522638957 -3.9923 -54.908\n",
            "0.07311890522638957 -3.9923 -54.908\n",
            "0.07311890522638957 -3.9923 -54.908\n",
            "0.07311890522638957 -3.9923 -54.908\n",
            "-3.919083913167318 -0.121 -67.013\n",
            "-3.9246060053507485 -0.041 -66.872\n",
            "-3.919083913167318 -0.121229892 -67.01310259\n",
            "-4.564406394958496 -3.907183314 -66.05514576\n",
            "-5.123162269592285 -4.303698078 -70.29106779\n",
            "-3.919083913167318 -0.121229892 -67.01310259\n",
            "-5.123162269592285 -4.303698078 -70.29106779\n",
            "-3.919083913167318 -0.121229892 -67.01310259\n",
            "-5.123162269592285 -4.303698078 -70.29106779\n",
            "-3.919083913167318 -0.121229892 -67.01310259\n",
            "-5.123162269592285 -4.303698078 -70.29106779\n",
            "-4.564406394958496 -3.907 -66.055\n",
            "-3.919083913167318 -0.121229892 -67.01310259\n",
            "-5.123162269592285 -4.303698078 -70.29106779\n",
            "-3.919083913167318 -0.121229892 -67.01310259\n",
            "-3.919083913167318 -0.121229892 -67.01310259\n",
            "-3.919083913167318 -0.121229892 -67.01310259\n",
            "-4.564406394958496 -3.907 -66.055\n",
            "-4.564406394958496 -3.907183314 -66.05514576\n",
            "-4.564406394958496 -3.907183314 -66.05514576\n",
            "-4.564406394958496 -3.907183314 -66.05514576\n",
            "-4.564406394958496 -3.907183314 -66.05514576\n",
            "-5.123162269592285 -4.303698078 -70.29106779\n",
            "-5.123162269592285 -4.303698078 -70.29106779\n",
            "-4.564406394958496 -3.907183314 -66.05514576\n",
            "-3.919083913167318 -0.121 -67.013\n",
            "-3.9246060053507485 -0.041 -66.872\n",
            "-4.564406394958496 -3.907 -66.055\n",
            "-5.123162269592285 -4.304 -70.291\n",
            "-5.123162269592285 -4.304 -70.291\n",
            "-4.564406394958496 -3.907183314 -66.05514576\n",
            "-3.919083913167318 -0.121229892 -67.01310259\n",
            "-5.123162269592285 -4.303698078 -70.29106779\n",
            "-4.541958808898926 -3.758533554 -66.0737537\n",
            "-28.60016632080078 -0.121 -67.013\n",
            "-28.472923278808594 -0.041 -66.872\n",
            "-28.60016632080078 -0.121229892 -67.01310259\n",
            "-29.709925333658855 -3.907183314 -66.05514576\n",
            "-29.38927968343099 -4.303698078 -70.29106779\n",
            "-28.60016632080078 -0.121229892 -67.01310259\n",
            "-29.38927968343099 -4.303698078 -70.29106779\n",
            "-28.60016632080078 -0.121229892 -67.01310259\n",
            "-29.38927968343099 -4.303698078 -70.29106779\n",
            "-28.60016632080078 -0.121229892 -67.01310259\n",
            "-29.38927968343099 -4.303698078 -70.29106779\n",
            "-29.709925333658855 -3.907 -66.055\n",
            "-28.60016632080078 -0.121229892 -67.01310259\n",
            "-29.38927968343099 -4.303698078 -70.29106779\n",
            "-28.60016632080078 -0.121229892 -67.01310259\n",
            "-28.60016632080078 -0.121229892 -67.01310259\n",
            "-28.60016632080078 -0.121229892 -67.01310259\n",
            "-29.709925333658855 -3.907 -66.055\n",
            "-29.709925333658855 -3.907183314 -66.05514576\n",
            "-29.709925333658855 -3.907183314 -66.05514576\n",
            "-29.709925333658855 -3.907183314 -66.05514576\n",
            "-29.709925333658855 -3.907183314 -66.05514576\n",
            "-29.38927968343099 -4.303698078 -70.29106779\n",
            "-29.38927968343099 -4.303698078 -70.29106779\n",
            "-29.709925333658855 -3.907183314 -66.05514576\n",
            "-28.60016632080078 -0.121 -67.013\n",
            "-28.472923278808594 -0.041 -66.872\n",
            "-29.709925333658855 -3.907 -66.055\n",
            "-29.38927968343099 -4.304 -70.291\n",
            "-29.38927968343099 -4.304 -70.291\n",
            "-29.709925333658855 -3.907183314 -66.05514576\n",
            "-28.60016632080078 -0.121229892 -67.01310259\n",
            "-29.38927968343099 -4.303698078 -70.29106779\n",
            "-29.837618509928387 -3.758533554 -66.0737537\n",
            "0.04461692770322164 -0.121 -67.013\n",
            "0.07063479721546173 -0.041 -66.872\n",
            "0.04461692770322164 -0.121229892 -67.01310259\n",
            "0.017363741993904114 -3.907183314 -66.05514576\n",
            "0.1553064783414205 -4.303698078 -70.29106779\n",
            "0.04461692770322164 -0.121229892 -67.01310259\n",
            "0.1553064783414205 -4.303698078 -70.29106779\n",
            "0.04461692770322164 -0.121229892 -67.01310259\n",
            "0.1553064783414205 -4.303698078 -70.29106779\n",
            "0.04461692770322164 -0.121229892 -67.01310259\n",
            "0.1553064783414205 -4.303698078 -70.29106779\n",
            "0.017363741993904114 -3.907 -66.055\n",
            "0.04461692770322164 -0.121229892 -67.01310259\n",
            "0.1553064783414205 -4.303698078 -70.29106779\n",
            "0.04461692770322164 -0.121229892 -67.01310259\n",
            "0.04461692770322164 -0.121229892 -67.01310259\n",
            "0.04461692770322164 -0.121229892 -67.01310259\n",
            "0.017363741993904114 -3.907 -66.055\n",
            "0.017363741993904114 -3.907183314 -66.05514576\n",
            "0.017363741993904114 -3.907183314 -66.05514576\n",
            "0.017363741993904114 -3.907183314 -66.05514576\n",
            "0.017363741993904114 -3.907183314 -66.05514576\n",
            "0.1553064783414205 -4.303698078 -70.29106779\n",
            "0.1553064783414205 -4.303698078 -70.29106779\n",
            "0.017363741993904114 -3.907183314 -66.05514576\n",
            "0.04461692770322164 -0.121 -67.013\n",
            "0.07063479721546173 -0.041 -66.872\n",
            "0.017363741993904114 -3.907 -66.055\n",
            "0.1553064783414205 -4.304 -70.291\n",
            "0.1553064783414205 -4.304 -70.291\n",
            "0.017363741993904114 -3.907183314 -66.05514576\n",
            "0.04461692770322164 -0.121229892 -67.01310259\n",
            "0.1553064783414205 -4.303698078 -70.29106779\n",
            "0.09625222285588582 -3.758533554 -66.0737537\n",
            "-4.4540205001831055 -6.009706576 -61.8686565\n",
            "-4.4540205001831055 -6.009706576 -61.8686565\n",
            "-4.4540205001831055 -6.009706576 -61.8686565\n",
            "-4.4540205001831055 -6.009706576 -61.8686565\n",
            "-4.4540205001831055 -6.009706576 -61.8686565\n",
            "-3.716785113016764 -13.0813 -52.3771\n",
            "-3.716785113016764 -13.079 -52.3864\n",
            "-3.716785113016764 -13.079 -52.3864\n",
            "-3.716785113016764 -13.079 -52.3864\n",
            "-3.716785113016764 -13.079 -52.3864\n",
            "-3.716785113016764 -13.079 -52.3864\n",
            "-3.716785113016764 -13.079 -52.3864\n",
            "-3.716785113016764 -13.0813 -52.3771\n",
            "-3.716785113016764 -13.079 -52.3864\n",
            "-4.641689936319987 -9.318 -60.978\n",
            "-4.901630719502767 -9.312 -62.982\n",
            "-4.901630719502767 -9.311 -62.974\n",
            "-4.901630719502767 -9.317 -62.981\n",
            "-4.901630719502767 -9.299 -62.977\n",
            "-4.4540205001831055 -6.009706576 -61.8686565\n",
            "-4.4540205001831055 -6.009706576 -61.8686565\n",
            "-4.4540205001831055 -6.009706576 -61.8686565\n",
            "-28.70690155029297 -6.009706576 -61.8686565\n",
            "-28.70690155029297 -6.009706576 -61.8686565\n",
            "-28.70690155029297 -6.009706576 -61.8686565\n",
            "-28.70690155029297 -6.009706576 -61.8686565\n",
            "-28.70690155029297 -6.009706576 -61.8686565\n",
            "-26.659779866536457 -13.0813 -52.3771\n",
            "-26.659779866536457 -13.079 -52.3864\n",
            "-26.659779866536457 -13.079 -52.3864\n",
            "-26.659779866536457 -13.079 -52.3864\n",
            "-26.659779866536457 -13.079 -52.3864\n",
            "-26.659779866536457 -13.079 -52.3864\n",
            "-26.659779866536457 -13.079 -52.3864\n",
            "-26.659779866536457 -13.0813 -52.3771\n",
            "-26.659779866536457 -13.079 -52.3864\n",
            "-25.785423278808594 -9.318 -60.978\n",
            "-26.46899922688802 -9.312 -62.982\n",
            "-26.46899922688802 -9.311 -62.974\n",
            "-26.46899922688802 -9.317 -62.981\n",
            "-26.46899922688802 -9.299 -62.977\n",
            "-28.70690155029297 -6.009706576 -61.8686565\n",
            "-28.70690155029297 -6.009706576 -61.8686565\n",
            "-28.70690155029297 -6.009706576 -61.8686565\n",
            "0.050410677989323936 -6.009706576 -61.8686565\n",
            "0.050410677989323936 -6.009706576 -61.8686565\n",
            "0.050410677989323936 -6.009706576 -61.8686565\n",
            "0.050410677989323936 -6.009706576 -61.8686565\n",
            "0.050410677989323936 -6.009706576 -61.8686565\n",
            "0.022945558031400044 -13.0813 -52.3771\n",
            "0.022945558031400044 -13.079 -52.3864\n",
            "0.022945558031400044 -13.079 -52.3864\n",
            "0.022945558031400044 -13.079 -52.3864\n",
            "0.022945558031400044 -13.079 -52.3864\n",
            "0.022945558031400044 -13.079 -52.3864\n",
            "0.022945558031400044 -13.079 -52.3864\n",
            "0.022945558031400044 -13.0813 -52.3771\n",
            "0.022945558031400044 -13.079 -52.3864\n",
            "0.04144644737243652 -9.318 -60.978\n",
            "0.13500848412513733 -9.312 -62.982\n",
            "0.13500848412513733 -9.311 -62.974\n",
            "0.13500848412513733 -9.317 -62.981\n",
            "0.13500848412513733 -9.299 -62.977\n",
            "0.050410677989323936 -6.009706576 -61.8686565\n",
            "0.050410677989323936 -6.009706576 -61.8686565\n",
            "0.050410677989323936 -6.009706576 -61.8686565\n",
            "ColumnTransformer(remainder='passthrough',\n",
            "                  transformers=[('lat_standardizer', StandardScaler(), ['lat']),\n",
            "                                ('long_standardizer', StandardScaler(),\n",
            "                                 ['long']),\n",
            "                                ('VPD_standardizer', StandardScaler(), ['VPD']),\n",
            "                                ('RH_standardizer', StandardScaler(), ['RH']),\n",
            "                                ('PET_standardizer', StandardScaler(), ['PET']),\n",
            "                                ('DEM_standardizer', StandardScaler(), ['DEM']),\n",
            "                                ('PA_standardizer'...\n",
            "                                ('Mean Annual Temperature_standardizer',\n",
            "                                 StandardScaler(),\n",
            "                                 ['Mean Annual Temperature']),\n",
            "                                ('Mean Annual Precipitation_standardizer',\n",
            "                                 StandardScaler(),\n",
            "                                 ['Mean Annual Precipitation']),\n",
            "                                ('Iso_Oxi_Stack_mean_TERZER_standardizer',\n",
            "                                 StandardScaler(),\n",
            "                                 ['Iso_Oxi_Stack_mean_TERZER']),\n",
            "                                ('isoscape_fullmodel_d18O_prec_REGRESSION_standardizer',\n",
            "                                 StandardScaler(),\n",
            "                                 ['isoscape_fullmodel_d18O_prec_REGRESSION'])])\n",
            "==================\n",
            "fixed_all_isorix_carbon_ensemble\n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_2 (InputLayer)           [(None, 16)]         0           []                               \n",
            "                                                                                                  \n",
            " dense_2 (Dense)                (None, 20)           340         ['input_2[0][0]']                \n",
            "                                                                                                  \n",
            " dense_3 (Dense)                (None, 20)           420         ['dense_2[0][0]']                \n",
            "                                                                                                  \n",
            " var_output (Dense)             (None, 1)            21          ['dense_3[0][0]']                \n",
            "                                                                                                  \n",
            " mean_output (Dense)            (None, 1)            21          ['dense_3[0][0]']                \n",
            "                                                                                                  \n",
            " tf.math.multiply_3 (TFOpLambda  (None, 1)           0           ['var_output[0][0]']             \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " tf.math.multiply_2 (TFOpLambda  (None, 1)           0           ['mean_output[0][0]']            \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " tf.__operators__.add_3 (TFOpLa  (None, 1)           0           ['tf.math.multiply_3[0][0]']     \n",
            " mbda)                                                                                            \n",
            "                                                                                                  \n",
            " tf.__operators__.add_2 (TFOpLa  (None, 1)           0           ['tf.math.multiply_2[0][0]']     \n",
            " mbda)                                                                                            \n",
            "                                                                                                  \n",
            " lambda_1 (Lambda)              (None, 1)            0           ['tf.__operators__.add_3[0][0]'] \n",
            "                                                                                                  \n",
            " concatenate_1 (Concatenate)    (None, 2)            0           ['tf.__operators__.add_2[0][0]', \n",
            "                                                                  'lambda_1[0][0]']               \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 802\n",
            "Trainable params: 802\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/5000\n",
            "23/23 [==============================] - 3s 30ms/step - loss: 8.7383 - val_loss: 6.0979\n",
            "Epoch 2/5000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 6.0337 - val_loss: 3.7562\n",
            "Epoch 3/5000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 4.4877 - val_loss: 2.7186\n",
            "Epoch 4/5000\n",
            "23/23 [==============================] - 0s 12ms/step - loss: 3.3020 - val_loss: 2.0350\n",
            "Epoch 5/5000\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 2.4623 - val_loss: 1.6559\n",
            "Epoch 6/5000\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 1.8309 - val_loss: 1.3365\n",
            "Epoch 7/5000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 1.4713 - val_loss: 1.0809\n",
            "Epoch 8/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 1.2125 - val_loss: 1.1496\n",
            "Epoch 9/5000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 1.1011 - val_loss: 1.3370\n",
            "Epoch 10/5000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 1.0143 - val_loss: 1.3835\n",
            "Epoch 11/5000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.9377 - val_loss: 1.1275\n",
            "Epoch 12/5000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.9961 - val_loss: 1.4713\n",
            "Epoch 13/5000\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 0.9627 - val_loss: 1.5132\n",
            "Epoch 14/5000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.9326 - val_loss: 1.2942\n",
            "Epoch 15/5000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.9871 - val_loss: 1.1029\n",
            "Epoch 16/5000\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.9157 - val_loss: 1.0788\n",
            "Epoch 17/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.9155 - val_loss: 1.1236\n",
            "Epoch 18/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.9750 - val_loss: 1.1663\n",
            "Epoch 19/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.9245 - val_loss: 1.4759\n",
            "Epoch 20/5000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.9487 - val_loss: 1.0587\n",
            "Epoch 21/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.9879 - val_loss: 1.1428\n",
            "Epoch 22/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.8959 - val_loss: 1.1401\n",
            "Epoch 23/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.9222 - val_loss: 1.3506\n",
            "Epoch 24/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.8843 - val_loss: 1.1654\n",
            "Epoch 25/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.9632 - val_loss: 1.3194\n",
            "Epoch 26/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.8872 - val_loss: 1.0909\n",
            "Epoch 27/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.8719 - val_loss: 1.3888\n",
            "Epoch 28/5000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.8655 - val_loss: 1.2893\n",
            "Epoch 29/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.9328 - val_loss: 1.1471\n",
            "Epoch 30/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.8587 - val_loss: 1.4242\n",
            "Epoch 31/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.9348 - val_loss: 1.1934\n",
            "Epoch 32/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.9068 - val_loss: 1.2034\n",
            "Epoch 33/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.8883 - val_loss: 1.1795\n",
            "Epoch 34/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.8689 - val_loss: 1.2650\n",
            "Epoch 35/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.8860 - val_loss: 1.1300\n",
            "Epoch 36/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.9015 - val_loss: 1.1463\n",
            "Epoch 37/5000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.8581 - val_loss: 1.2836\n",
            "Epoch 38/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.9792 - val_loss: 1.2877\n",
            "Epoch 39/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.8473 - val_loss: 1.1816\n",
            "Epoch 40/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.9286 - val_loss: 1.2313\n",
            "Epoch 41/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.8405 - val_loss: 1.0877\n",
            "Epoch 42/5000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.9073 - val_loss: 0.9823\n",
            "Epoch 43/5000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.8604 - val_loss: 1.2274\n",
            "Epoch 44/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.8682 - val_loss: 1.1089\n",
            "Epoch 45/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.8873 - val_loss: 1.2892\n",
            "Epoch 46/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.9149 - val_loss: 1.1039\n",
            "Epoch 47/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7797 - val_loss: 1.2956\n",
            "Epoch 48/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.8676 - val_loss: 1.1062\n",
            "Epoch 49/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.8392 - val_loss: 1.2122\n",
            "Epoch 50/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.8818 - val_loss: 1.2374\n",
            "Epoch 51/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.8165 - val_loss: 1.1187\n",
            "Epoch 52/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.9314 - val_loss: 1.1700\n",
            "Epoch 53/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.8177 - val_loss: 1.2905\n",
            "Epoch 54/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.8303 - val_loss: 1.1897\n",
            "Epoch 55/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.8435 - val_loss: 1.3292\n",
            "Epoch 56/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.8196 - val_loss: 1.1798\n",
            "Epoch 57/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.8557 - val_loss: 1.3593\n",
            "Epoch 58/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.8692 - val_loss: 1.5214\n",
            "Epoch 59/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.9289 - val_loss: 1.0481\n",
            "Epoch 60/5000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.9106 - val_loss: 1.2008\n",
            "Epoch 61/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.8446 - val_loss: 1.1303\n",
            "Epoch 62/5000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.8360 - val_loss: 1.0749\n",
            "Epoch 63/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.9424 - val_loss: 1.3556\n",
            "Epoch 64/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.8780 - val_loss: 0.9927\n",
            "Epoch 65/5000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.7460 - val_loss: 1.5053\n",
            "Epoch 66/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.8586 - val_loss: 1.6638\n",
            "Epoch 67/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7712 - val_loss: 1.5059\n",
            "Epoch 68/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7897 - val_loss: 1.1228\n",
            "Epoch 69/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7846 - val_loss: 1.3028\n",
            "Epoch 70/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7838 - val_loss: 1.2058\n",
            "Epoch 71/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.8621 - val_loss: 1.3809\n",
            "Epoch 72/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.8526 - val_loss: 1.2497\n",
            "Epoch 73/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.8570 - val_loss: 1.1368\n",
            "Epoch 74/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.8121 - val_loss: 1.3327\n",
            "Epoch 75/5000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.8488 - val_loss: 1.0438\n",
            "Epoch 76/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.8305 - val_loss: 1.2736\n",
            "Epoch 77/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.8128 - val_loss: 1.1268\n",
            "Epoch 78/5000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.8030 - val_loss: 1.1820\n",
            "Epoch 79/5000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.8161 - val_loss: 1.1784\n",
            "Epoch 80/5000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.7915 - val_loss: 1.2132\n",
            "Epoch 81/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.8413 - val_loss: 1.1322\n",
            "Epoch 82/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7582 - val_loss: 1.0745\n",
            "Epoch 83/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.8761 - val_loss: 1.2283\n",
            "Epoch 84/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.8020 - val_loss: 1.2935\n",
            "Epoch 85/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.8381 - val_loss: 1.2298\n",
            "Epoch 86/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.8176 - val_loss: 1.3575\n",
            "Epoch 87/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.9169 - val_loss: 1.4302\n",
            "Epoch 88/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.8112 - val_loss: 1.2428\n",
            "Epoch 89/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.8457 - val_loss: 1.0805\n",
            "Epoch 90/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7895 - val_loss: 1.3072\n",
            "Epoch 91/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.8229 - val_loss: 1.2325\n",
            "Epoch 92/5000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.7691 - val_loss: 1.0389\n",
            "Epoch 93/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.8391 - val_loss: 1.5193\n",
            "Epoch 94/5000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.8336 - val_loss: 1.4001\n",
            "Epoch 95/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7799 - val_loss: 1.3349\n",
            "Epoch 96/5000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.7704 - val_loss: 1.4384\n",
            "Epoch 97/5000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.8512 - val_loss: 1.1625\n",
            "Epoch 98/5000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.8131 - val_loss: 1.4014\n",
            "Epoch 99/5000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.8678 - val_loss: 1.3047\n",
            "Epoch 100/5000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.7674 - val_loss: 1.0914\n",
            "Epoch 101/5000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.8256 - val_loss: 1.0635\n",
            "Epoch 102/5000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.8399 - val_loss: 1.1886\n",
            "Epoch 103/5000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.7809 - val_loss: 1.2783\n",
            "Epoch 104/5000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.8747 - val_loss: 1.3882\n",
            "Epoch 105/5000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.8465 - val_loss: 1.1788\n",
            "Epoch 106/5000\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 0.8330 - val_loss: 1.2139\n",
            "Epoch 107/5000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.8366 - val_loss: 1.1387\n",
            "Epoch 108/5000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.8242 - val_loss: 1.1120\n",
            "Epoch 109/5000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.8454 - val_loss: 1.5600\n",
            "Epoch 110/5000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.7939 - val_loss: 1.2793\n",
            "Epoch 111/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7766 - val_loss: 1.1111\n",
            "Epoch 112/5000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.7984 - val_loss: 1.0566\n",
            "Epoch 113/5000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.7619 - val_loss: 1.3878\n",
            "Epoch 114/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.8252 - val_loss: 1.2073\n",
            "Epoch 115/5000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.8898 - val_loss: 1.3434\n",
            "Epoch 116/5000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.8754 - val_loss: 1.0587\n",
            "Epoch 117/5000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.8326 - val_loss: 1.0337\n",
            "Epoch 118/5000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.8339 - val_loss: 1.4633\n",
            "Epoch 119/5000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.7920 - val_loss: 1.0778\n",
            "Epoch 120/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.8787 - val_loss: 1.0828\n",
            "Epoch 121/5000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.8250 - val_loss: 1.0519\n",
            "Epoch 122/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7731 - val_loss: 1.2494\n",
            "Epoch 123/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.8128 - val_loss: 1.2298\n",
            "Epoch 124/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.8001 - val_loss: 1.2902\n",
            "Epoch 125/5000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.8103 - val_loss: 1.3355\n",
            "Epoch 126/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7674 - val_loss: 1.2485\n",
            "Epoch 127/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.8813 - val_loss: 1.3846\n",
            "Epoch 128/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7701 - val_loss: 1.0211\n",
            "Epoch 129/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7356 - val_loss: 0.9907\n",
            "Epoch 130/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.8182 - val_loss: 1.1805\n",
            "Epoch 131/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7211 - val_loss: 1.1072\n",
            "Epoch 132/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7981 - val_loss: 1.3117\n",
            "Epoch 133/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7919 - val_loss: 1.0277\n",
            "Epoch 134/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.8801 - val_loss: 1.2137\n",
            "Epoch 135/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.8415 - val_loss: 1.1175\n",
            "Epoch 136/5000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.8043 - val_loss: 1.1421\n",
            "Epoch 137/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7812 - val_loss: 1.3613\n",
            "Epoch 138/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7639 - val_loss: 1.4461\n",
            "Epoch 139/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7523 - val_loss: 1.2409\n",
            "Epoch 140/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7293 - val_loss: 1.0948\n",
            "Epoch 141/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7473 - val_loss: 1.2699\n",
            "Epoch 142/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.8191 - val_loss: 1.3226\n",
            "Epoch 143/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.8003 - val_loss: 1.2076\n",
            "Epoch 144/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.8411 - val_loss: 1.2017\n",
            "Epoch 145/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.8577 - val_loss: 1.2109\n",
            "Epoch 146/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.8871 - val_loss: 1.2354\n",
            "Epoch 147/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7310 - val_loss: 1.2440\n",
            "Epoch 148/5000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.7457 - val_loss: 1.4355\n",
            "Epoch 149/5000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.8153 - val_loss: 1.2747\n",
            "Epoch 150/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7540 - val_loss: 1.0933\n",
            "Epoch 151/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7572 - val_loss: 1.1551\n",
            "Epoch 152/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7971 - val_loss: 1.4266\n",
            "Epoch 153/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7744 - val_loss: 1.1728\n",
            "Epoch 154/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7812 - val_loss: 1.4510\n",
            "Epoch 155/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.8103 - val_loss: 1.0536\n",
            "Epoch 156/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7983 - val_loss: 1.2415\n",
            "Epoch 157/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7473 - val_loss: 1.0889\n",
            "Epoch 158/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.8042 - val_loss: 1.1075\n",
            "Epoch 159/5000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.8129 - val_loss: 1.0696\n",
            "Epoch 160/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7549 - val_loss: 1.1502\n",
            "Epoch 161/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.8163 - val_loss: 1.3412\n",
            "Epoch 162/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7672 - val_loss: 1.1772\n",
            "Epoch 163/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.8404 - val_loss: 1.0090\n",
            "Epoch 164/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.8126 - val_loss: 1.2814\n",
            "Epoch 165/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.8065 - val_loss: 1.0400\n",
            "Epoch 166/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7528 - val_loss: 1.0566\n",
            "Epoch 167/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7908 - val_loss: 1.2339\n",
            "Epoch 168/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7347 - val_loss: 1.1237\n",
            "Epoch 169/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7984 - val_loss: 1.2182\n",
            "Epoch 170/5000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.8150 - val_loss: 1.1941\n",
            "Epoch 171/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.8058 - val_loss: 1.0632\n",
            "Epoch 172/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7719 - val_loss: 1.1536\n",
            "Epoch 173/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.8475 - val_loss: 1.0954\n",
            "Epoch 174/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.8316 - val_loss: 1.3144\n",
            "Epoch 175/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7423 - val_loss: 1.1583\n",
            "Epoch 176/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7251 - val_loss: 1.2686\n",
            "Epoch 177/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7751 - val_loss: 1.2422\n",
            "Epoch 178/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7780 - val_loss: 1.1213\n",
            "Epoch 179/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7244 - val_loss: 1.0812\n",
            "Epoch 180/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7778 - val_loss: 1.2511\n",
            "Epoch 181/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7582 - val_loss: 1.2417\n",
            "Epoch 182/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7381 - val_loss: 1.2848\n",
            "Epoch 183/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7455 - val_loss: 1.2045\n",
            "Epoch 184/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7466 - val_loss: 1.2502\n",
            "Epoch 185/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7648 - val_loss: 1.0859\n",
            "Epoch 186/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7855 - val_loss: 1.1206\n",
            "Epoch 187/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7403 - val_loss: 1.1918\n",
            "Epoch 188/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.8452 - val_loss: 1.7864\n",
            "Epoch 189/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7720 - val_loss: 1.0654\n",
            "Epoch 190/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.8565 - val_loss: 1.0509\n",
            "Epoch 191/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.8100 - val_loss: 1.2990\n",
            "Epoch 192/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.8524 - val_loss: 1.1202\n",
            "Epoch 193/5000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.7850 - val_loss: 1.0750\n",
            "Epoch 194/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7883 - val_loss: 1.3007\n",
            "Epoch 195/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7996 - val_loss: 1.1180\n",
            "Epoch 196/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.8060 - val_loss: 1.1400\n",
            "Epoch 197/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7505 - val_loss: 1.9263\n",
            "Epoch 198/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7618 - val_loss: 1.2100\n",
            "Epoch 199/5000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.7384 - val_loss: 1.4353\n",
            "Epoch 200/5000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.7412 - val_loss: 1.1920\n",
            "Epoch 201/5000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.8271 - val_loss: 1.3908\n",
            "Epoch 202/5000\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 0.7065 - val_loss: 1.2265\n",
            "Epoch 203/5000\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 0.7689 - val_loss: 1.2047\n",
            "Epoch 204/5000\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 0.7694 - val_loss: 1.2514\n",
            "Epoch 205/5000\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 0.8377 - val_loss: 1.2799\n",
            "Epoch 206/5000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.7919 - val_loss: 1.1631\n",
            "Epoch 207/5000\n",
            "23/23 [==============================] - 0s 12ms/step - loss: 0.7350 - val_loss: 1.0666\n",
            "Epoch 208/5000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.7429 - val_loss: 1.0741\n",
            "Epoch 209/5000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.7454 - val_loss: 1.0824\n",
            "Epoch 210/5000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.7435 - val_loss: 1.0252\n",
            "Epoch 211/5000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.8012 - val_loss: 1.0970\n",
            "Epoch 212/5000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.8608 - val_loss: 1.5538\n",
            "Epoch 213/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7818 - val_loss: 1.2092\n",
            "Epoch 214/5000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.7705 - val_loss: 1.0797\n",
            "Epoch 215/5000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.7800 - val_loss: 1.1293\n",
            "Epoch 216/5000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.7331 - val_loss: 1.8869\n",
            "Epoch 217/5000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.8447 - val_loss: 1.4115\n",
            "Epoch 218/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7708 - val_loss: 1.2658\n",
            "Epoch 219/5000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.7395 - val_loss: 1.2129\n",
            "Epoch 220/5000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.7282 - val_loss: 1.6259\n",
            "Epoch 221/5000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.7511 - val_loss: 1.1506\n",
            "Epoch 222/5000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.7998 - val_loss: 1.2817\n",
            "Epoch 223/5000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.7943 - val_loss: 1.2363\n",
            "Epoch 224/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7120 - val_loss: 1.0746\n",
            "Epoch 225/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7151 - val_loss: 1.2988\n",
            "Epoch 226/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7116 - val_loss: 1.2347\n",
            "Epoch 227/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7455 - val_loss: 1.3416\n",
            "Epoch 228/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7201 - val_loss: 1.0950\n",
            "Epoch 229/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.8051 - val_loss: 1.7318\n",
            "Epoch 230/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7713 - val_loss: 1.2745\n",
            "Epoch 231/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7633 - val_loss: 1.3957\n",
            "Epoch 232/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.8007 - val_loss: 1.2389\n",
            "Epoch 233/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7747 - val_loss: 1.1314\n",
            "Epoch 234/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.8497 - val_loss: 1.6713\n",
            "Epoch 235/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7226 - val_loss: 1.2238\n",
            "Epoch 236/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.8097 - val_loss: 1.5461\n",
            "Epoch 237/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7908 - val_loss: 1.1475\n",
            "Epoch 238/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7781 - val_loss: 1.1312\n",
            "Epoch 239/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7574 - val_loss: 1.2674\n",
            "Epoch 240/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7696 - val_loss: 1.1686\n",
            "Epoch 241/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7808 - val_loss: 1.1248\n",
            "Epoch 242/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7407 - val_loss: 1.2187\n",
            "Epoch 243/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7828 - val_loss: 1.1454\n",
            "Epoch 244/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7519 - val_loss: 1.3913\n",
            "Epoch 245/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7666 - val_loss: 1.0271\n",
            "Epoch 246/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7662 - val_loss: 1.2381\n",
            "Epoch 247/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7352 - val_loss: 1.1963\n",
            "Epoch 248/5000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.7275 - val_loss: 1.5469\n",
            "Epoch 249/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7531 - val_loss: 1.1482\n",
            "Epoch 250/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.8016 - val_loss: 1.1143\n",
            "Epoch 251/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7483 - val_loss: 1.1667\n",
            "Epoch 252/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7447 - val_loss: 1.0704\n",
            "Epoch 253/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.8371 - val_loss: 1.1833\n",
            "Epoch 254/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7135 - val_loss: 1.1698\n",
            "Epoch 255/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7219 - val_loss: 1.2923\n",
            "Epoch 256/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.8824 - val_loss: 1.4065\n",
            "Epoch 257/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7536 - val_loss: 1.1809\n",
            "Epoch 258/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7721 - val_loss: 1.2609\n",
            "Epoch 259/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7730 - val_loss: 1.1398\n",
            "Epoch 260/5000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.7116 - val_loss: 1.0600\n",
            "Epoch 261/5000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.7501 - val_loss: 1.1130\n",
            "Epoch 262/5000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.7546 - val_loss: 1.0802\n",
            "Epoch 263/5000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.7655 - val_loss: 1.4447\n",
            "Epoch 264/5000\n",
            "23/23 [==============================] - 1s 38ms/step - loss: 0.7329 - val_loss: 0.9713\n",
            "Epoch 265/5000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.7823 - val_loss: 1.1602\n",
            "Epoch 266/5000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.7904 - val_loss: 1.0450\n",
            "Epoch 267/5000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.7560 - val_loss: 1.1000\n",
            "Epoch 268/5000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.8281 - val_loss: 1.0439\n",
            "Epoch 269/5000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.7825 - val_loss: 1.0666\n",
            "Epoch 270/5000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.7594 - val_loss: 1.0077\n",
            "Epoch 271/5000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.7426 - val_loss: 1.2221\n",
            "Epoch 272/5000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.7409 - val_loss: 0.9866\n",
            "Epoch 273/5000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.7522 - val_loss: 1.0636\n",
            "Epoch 274/5000\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 0.8082 - val_loss: 1.0133\n",
            "Epoch 275/5000\n",
            "23/23 [==============================] - 0s 12ms/step - loss: 0.7341 - val_loss: 0.9655\n",
            "Epoch 276/5000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.7078 - val_loss: 1.1216\n",
            "Epoch 277/5000\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 0.7791 - val_loss: 1.2040\n",
            "Epoch 278/5000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.7474 - val_loss: 1.0007\n",
            "Epoch 279/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7834 - val_loss: 1.1936\n",
            "Epoch 280/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7713 - val_loss: 1.1503\n",
            "Epoch 281/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7946 - val_loss: 1.4776\n",
            "Epoch 282/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7864 - val_loss: 1.4658\n",
            "Epoch 283/5000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.8149 - val_loss: 1.0906\n",
            "Epoch 284/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7248 - val_loss: 1.2041\n",
            "Epoch 285/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.8032 - val_loss: 1.0524\n",
            "Epoch 286/5000\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 0.8059 - val_loss: 1.2131\n",
            "Epoch 287/5000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.7644 - val_loss: 1.0961\n",
            "Epoch 288/5000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.7259 - val_loss: 1.1193\n",
            "Epoch 289/5000\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 0.7494 - val_loss: 1.5414\n",
            "Epoch 290/5000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.7373 - val_loss: 1.2985\n",
            "Epoch 291/5000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.8243 - val_loss: 1.4922\n",
            "Epoch 292/5000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.7476 - val_loss: 1.3764\n",
            "Epoch 293/5000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.7939 - val_loss: 1.1701\n",
            "Epoch 294/5000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.8157 - val_loss: 1.2083\n",
            "Epoch 295/5000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.7155 - val_loss: 1.0464\n",
            "Epoch 296/5000\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 0.7580 - val_loss: 1.1921\n",
            "Epoch 297/5000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.7342 - val_loss: 1.1901\n",
            "Epoch 298/5000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.7452 - val_loss: 1.2080\n",
            "Epoch 299/5000\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 0.7292 - val_loss: 1.3093\n",
            "Epoch 300/5000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.7534 - val_loss: 1.0679\n",
            "Epoch 301/5000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.7635 - val_loss: 1.0535\n",
            "Epoch 302/5000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.7788 - val_loss: 1.0628\n",
            "Epoch 303/5000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.7852 - val_loss: 1.2582\n",
            "Epoch 304/5000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.7156 - val_loss: 1.0863\n",
            "Epoch 305/5000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.7851 - val_loss: 1.0866\n",
            "Epoch 306/5000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.7436 - val_loss: 1.1873\n",
            "Epoch 307/5000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.8109 - val_loss: 1.2858\n",
            "Epoch 308/5000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.7162 - val_loss: 1.4027\n",
            "Epoch 309/5000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.7608 - val_loss: 1.0464\n",
            "Epoch 310/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.8389 - val_loss: 1.2276\n",
            "Epoch 311/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7844 - val_loss: 1.0640\n",
            "Epoch 312/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7659 - val_loss: 1.2630\n",
            "Epoch 313/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.8458 - val_loss: 1.0855\n",
            "Epoch 314/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7729 - val_loss: 1.0606\n",
            "Epoch 315/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7038 - val_loss: 1.0593\n",
            "Epoch 316/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6893 - val_loss: 1.2226\n",
            "Epoch 317/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7406 - val_loss: 1.0992\n",
            "Epoch 318/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.8887 - val_loss: 1.1175\n",
            "Epoch 319/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7613 - val_loss: 1.0080\n",
            "Epoch 320/5000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.7186 - val_loss: 1.0451\n",
            "Epoch 321/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6822 - val_loss: 1.2294\n",
            "Epoch 322/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7566 - val_loss: 1.1386\n",
            "Epoch 323/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7482 - val_loss: 1.1403\n",
            "Epoch 324/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7417 - val_loss: 1.3176\n",
            "Epoch 325/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7376 - val_loss: 1.1531\n",
            "Epoch 326/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7744 - val_loss: 1.0608\n",
            "Epoch 327/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7723 - val_loss: 1.0185\n",
            "Epoch 328/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7312 - val_loss: 1.1382\n",
            "Epoch 329/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7705 - val_loss: 1.2436\n",
            "Epoch 330/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7149 - val_loss: 1.4527\n",
            "Epoch 331/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7848 - val_loss: 1.5478\n",
            "Epoch 332/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7020 - val_loss: 1.1954\n",
            "Epoch 333/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7429 - val_loss: 1.1259\n",
            "Epoch 334/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7672 - val_loss: 1.0376\n",
            "Epoch 335/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7842 - val_loss: 1.3132\n",
            "Epoch 336/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7659 - val_loss: 1.5751\n",
            "Epoch 337/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7710 - val_loss: 1.1213\n",
            "Epoch 338/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7745 - val_loss: 1.0784\n",
            "Epoch 339/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.8025 - val_loss: 1.1407\n",
            "Epoch 340/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7540 - val_loss: 1.5980\n",
            "Epoch 341/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7606 - val_loss: 1.0723\n",
            "Epoch 342/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7779 - val_loss: 1.0595\n",
            "Epoch 343/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.8898 - val_loss: 1.0824\n",
            "Epoch 344/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.8199 - val_loss: 1.0555\n",
            "Epoch 345/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.8447 - val_loss: 1.1522\n",
            "Epoch 346/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.8039 - val_loss: 1.3977\n",
            "Epoch 347/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7140 - val_loss: 0.9905\n",
            "Epoch 348/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7922 - val_loss: 1.1948\n",
            "Epoch 349/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6865 - val_loss: 1.1814\n",
            "Epoch 350/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7247 - val_loss: 1.2089\n",
            "Epoch 351/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7505 - val_loss: 1.1262\n",
            "Epoch 352/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.8544 - val_loss: 1.0562\n",
            "Epoch 353/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7530 - val_loss: 1.3473\n",
            "Epoch 354/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7756 - val_loss: 1.1066\n",
            "Epoch 355/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7739 - val_loss: 1.0607\n",
            "Epoch 356/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7567 - val_loss: 1.2958\n",
            "Epoch 357/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7833 - val_loss: 1.1226\n",
            "Epoch 358/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7880 - val_loss: 1.1404\n",
            "Epoch 359/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7586 - val_loss: 1.1614\n",
            "Epoch 360/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.8046 - val_loss: 1.1447\n",
            "Epoch 361/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6946 - val_loss: 1.0641\n",
            "Epoch 362/5000\n",
            "23/23 [==============================] - 1s 34ms/step - loss: 0.7303 - val_loss: 0.9551\n",
            "Epoch 363/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6925 - val_loss: 1.1614\n",
            "Epoch 364/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7825 - val_loss: 1.1670\n",
            "Epoch 365/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7861 - val_loss: 1.1598\n",
            "Epoch 366/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7515 - val_loss: 1.3778\n",
            "Epoch 367/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7504 - val_loss: 1.1403\n",
            "Epoch 368/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7543 - val_loss: 1.2177\n",
            "Epoch 369/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.9532 - val_loss: 1.0985\n",
            "Epoch 370/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6872 - val_loss: 1.3295\n",
            "Epoch 371/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.8454 - val_loss: 1.1599\n",
            "Epoch 372/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7473 - val_loss: 1.0836\n",
            "Epoch 373/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7463 - val_loss: 1.2736\n",
            "Epoch 374/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.8137 - val_loss: 1.1213\n",
            "Epoch 375/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7903 - val_loss: 1.0425\n",
            "Epoch 376/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7491 - val_loss: 1.0387\n",
            "Epoch 377/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7195 - val_loss: 1.4180\n",
            "Epoch 378/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7741 - val_loss: 1.2489\n",
            "Epoch 379/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6958 - val_loss: 1.2407\n",
            "Epoch 380/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7882 - val_loss: 1.0180\n",
            "Epoch 381/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7783 - val_loss: 1.9118\n",
            "Epoch 382/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.8547 - val_loss: 1.1581\n",
            "Epoch 383/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7841 - val_loss: 1.0554\n",
            "Epoch 384/5000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.7512 - val_loss: 1.2923\n",
            "Epoch 385/5000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.7294 - val_loss: 1.2417\n",
            "Epoch 386/5000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.7971 - val_loss: 1.3474\n",
            "Epoch 387/5000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.7286 - val_loss: 1.6628\n",
            "Epoch 388/5000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.7637 - val_loss: 1.1001\n",
            "Epoch 389/5000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.7193 - val_loss: 1.4010\n",
            "Epoch 390/5000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.7880 - val_loss: 1.1568\n",
            "Epoch 391/5000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.7636 - val_loss: 1.1876\n",
            "Epoch 392/5000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.7365 - val_loss: 1.0358\n",
            "Epoch 393/5000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.8049 - val_loss: 1.3084\n",
            "Epoch 394/5000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.8483 - val_loss: 1.2969\n",
            "Epoch 395/5000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.7055 - val_loss: 1.3299\n",
            "Epoch 396/5000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.7686 - val_loss: 1.1236\n",
            "Epoch 397/5000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.7136 - val_loss: 1.1617\n",
            "Epoch 398/5000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.7149 - val_loss: 1.2543\n",
            "Epoch 399/5000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.7421 - val_loss: 1.1102\n",
            "Epoch 400/5000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.7434 - val_loss: 1.1739\n",
            "Epoch 401/5000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.6942 - val_loss: 1.1907\n",
            "Epoch 402/5000\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 0.7628 - val_loss: 1.0077\n",
            "Epoch 403/5000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.7302 - val_loss: 1.0702\n",
            "Epoch 404/5000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.7367 - val_loss: 1.2676\n",
            "Epoch 405/5000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.6835 - val_loss: 1.1041\n",
            "Epoch 406/5000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.7917 - val_loss: 1.0966\n",
            "Epoch 407/5000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.8739 - val_loss: 1.2377\n",
            "Epoch 408/5000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.6960 - val_loss: 1.0325\n",
            "Epoch 409/5000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.7134 - val_loss: 1.0926\n",
            "Epoch 410/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7060 - val_loss: 0.9915\n",
            "Epoch 411/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7657 - val_loss: 1.0677\n",
            "Epoch 412/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7046 - val_loss: 1.1388\n",
            "Epoch 413/5000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.7303 - val_loss: 1.1704\n",
            "Epoch 414/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.8512 - val_loss: 1.0798\n",
            "Epoch 415/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7757 - val_loss: 1.2235\n",
            "Epoch 416/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7347 - val_loss: 1.3162\n",
            "Epoch 417/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7315 - val_loss: 1.2219\n",
            "Epoch 418/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7368 - val_loss: 1.6201\n",
            "Epoch 419/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6805 - val_loss: 1.0237\n",
            "Epoch 420/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6927 - val_loss: 0.9713\n",
            "Epoch 421/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7576 - val_loss: 1.0911\n",
            "Epoch 422/5000\n",
            "23/23 [==============================] - 1s 34ms/step - loss: 0.8024 - val_loss: 0.9009\n",
            "Epoch 423/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6681 - val_loss: 1.0731\n",
            "Epoch 424/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.8525 - val_loss: 0.9968\n",
            "Epoch 425/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7866 - val_loss: 1.2342\n",
            "Epoch 426/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7786 - val_loss: 1.0610\n",
            "Epoch 427/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7917 - val_loss: 1.2648\n",
            "Epoch 428/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7779 - val_loss: 1.0162\n",
            "Epoch 429/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6940 - val_loss: 1.1800\n",
            "Epoch 430/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7181 - val_loss: 1.6565\n",
            "Epoch 431/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.8053 - val_loss: 1.1672\n",
            "Epoch 432/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7768 - val_loss: 1.0704\n",
            "Epoch 433/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7592 - val_loss: 0.9741\n",
            "Epoch 434/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7025 - val_loss: 0.9937\n",
            "Epoch 435/5000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.7777 - val_loss: 1.0594\n",
            "Epoch 436/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6967 - val_loss: 1.0086\n",
            "Epoch 437/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6706 - val_loss: 1.3336\n",
            "Epoch 438/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7978 - val_loss: 1.1947\n",
            "Epoch 439/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7587 - val_loss: 0.9367\n",
            "Epoch 440/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7229 - val_loss: 1.2449\n",
            "Epoch 441/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7722 - val_loss: 1.2463\n",
            "Epoch 442/5000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.7648 - val_loss: 1.1714\n",
            "Epoch 443/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7337 - val_loss: 1.1672\n",
            "Epoch 444/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7189 - val_loss: 1.0066\n",
            "Epoch 445/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7313 - val_loss: 1.2834\n",
            "Epoch 446/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7455 - val_loss: 1.1067\n",
            "Epoch 447/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6930 - val_loss: 1.1345\n",
            "Epoch 448/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7743 - val_loss: 1.0984\n",
            "Epoch 449/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7356 - val_loss: 1.1066\n",
            "Epoch 450/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7865 - val_loss: 1.1613\n",
            "Epoch 451/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.8050 - val_loss: 1.2465\n",
            "Epoch 452/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7602 - val_loss: 1.3003\n",
            "Epoch 453/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.8143 - val_loss: 1.1691\n",
            "Epoch 454/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7784 - val_loss: 1.0557\n",
            "Epoch 455/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7289 - val_loss: 1.1335\n",
            "Epoch 456/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7454 - val_loss: 1.1407\n",
            "Epoch 457/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7942 - val_loss: 1.1030\n",
            "Epoch 458/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7136 - val_loss: 1.1724\n",
            "Epoch 459/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.8166 - val_loss: 1.1876\n",
            "Epoch 460/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7583 - val_loss: 1.1768\n",
            "Epoch 461/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7900 - val_loss: 1.2602\n",
            "Epoch 462/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7340 - val_loss: 1.5273\n",
            "Epoch 463/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.8419 - val_loss: 1.0883\n",
            "Epoch 464/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7329 - val_loss: 1.2082\n",
            "Epoch 465/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7769 - val_loss: 1.1177\n",
            "Epoch 466/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7819 - val_loss: 1.1933\n",
            "Epoch 467/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7693 - val_loss: 1.2501\n",
            "Epoch 468/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.8153 - val_loss: 1.2330\n",
            "Epoch 469/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7496 - val_loss: 1.0785\n",
            "Epoch 470/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7490 - val_loss: 1.0540\n",
            "Epoch 471/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.8170 - val_loss: 1.1920\n",
            "Epoch 472/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.8006 - val_loss: 1.1156\n",
            "Epoch 473/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7288 - val_loss: 1.1482\n",
            "Epoch 474/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7285 - val_loss: 1.0709\n",
            "Epoch 475/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7203 - val_loss: 1.2811\n",
            "Epoch 476/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7168 - val_loss: 1.0433\n",
            "Epoch 477/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7403 - val_loss: 1.1372\n",
            "Epoch 478/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7423 - val_loss: 1.0148\n",
            "Epoch 479/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7428 - val_loss: 1.2456\n",
            "Epoch 480/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7795 - val_loss: 1.1709\n",
            "Epoch 481/5000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.7121 - val_loss: 1.1793\n",
            "Epoch 482/5000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.6848 - val_loss: 1.2247\n",
            "Epoch 483/5000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.7279 - val_loss: 1.1738\n",
            "Epoch 484/5000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.7351 - val_loss: 1.2302\n",
            "Epoch 485/5000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.7121 - val_loss: 1.3844\n",
            "Epoch 486/5000\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 0.7665 - val_loss: 1.0603\n",
            "Epoch 487/5000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.7674 - val_loss: 1.2172\n",
            "Epoch 488/5000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.7247 - val_loss: 1.0601\n",
            "Epoch 489/5000\n",
            "23/23 [==============================] - 0s 15ms/step - loss: 0.7706 - val_loss: 1.2368\n",
            "Epoch 490/5000\n",
            "23/23 [==============================] - 1s 29ms/step - loss: 0.6739 - val_loss: 1.1935\n",
            "Epoch 491/5000\n",
            "23/23 [==============================] - 1s 29ms/step - loss: 0.7873 - val_loss: 1.2631\n",
            "Epoch 492/5000\n",
            "23/23 [==============================] - 1s 23ms/step - loss: 0.7212 - val_loss: 1.1563\n",
            "Epoch 493/5000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.7391 - val_loss: 1.4797\n",
            "Epoch 494/5000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.7323 - val_loss: 0.9947\n",
            "Epoch 495/5000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.7468 - val_loss: 1.2367\n",
            "Epoch 496/5000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.7158 - val_loss: 1.0419\n",
            "Epoch 497/5000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.6997 - val_loss: 1.0132\n",
            "Epoch 498/5000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.7846 - val_loss: 1.2233\n",
            "Epoch 499/5000\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 0.8070 - val_loss: 1.1466\n",
            "Epoch 500/5000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.7887 - val_loss: 1.0661\n",
            "Epoch 501/5000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.7065 - val_loss: 1.3433\n",
            "Epoch 502/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7265 - val_loss: 1.1520\n",
            "Epoch 503/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7933 - val_loss: 1.6237\n",
            "Epoch 504/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.8068 - val_loss: 1.1010\n",
            "Epoch 505/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7381 - val_loss: 1.4647\n",
            "Epoch 506/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7313 - val_loss: 1.2062\n",
            "Epoch 507/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7269 - val_loss: 1.1273\n",
            "Epoch 508/5000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.7051 - val_loss: 0.9802\n",
            "Epoch 509/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7963 - val_loss: 1.0900\n",
            "Epoch 510/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7169 - val_loss: 1.1588\n",
            "Epoch 511/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7375 - val_loss: 1.0946\n",
            "Epoch 512/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.8032 - val_loss: 1.0474\n",
            "Epoch 513/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7767 - val_loss: 1.4566\n",
            "Epoch 514/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7787 - val_loss: 1.1456\n",
            "Epoch 515/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.9206 - val_loss: 1.5723\n",
            "Epoch 516/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7011 - val_loss: 1.1194\n",
            "Epoch 517/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7803 - val_loss: 1.4315\n",
            "Epoch 518/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7662 - val_loss: 1.3262\n",
            "Epoch 519/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7756 - val_loss: 1.1497\n",
            "Epoch 520/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7180 - val_loss: 1.1696\n",
            "Epoch 521/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7380 - val_loss: 1.5683\n",
            "Epoch 522/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6838 - val_loss: 1.0659\n",
            "Epoch 523/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7301 - val_loss: 1.4093\n",
            "Epoch 524/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7233 - val_loss: 1.2160\n",
            "Epoch 525/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7922 - val_loss: 1.1137\n",
            "Epoch 526/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7555 - val_loss: 1.1545\n",
            "Epoch 527/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6920 - val_loss: 1.1071\n",
            "Epoch 528/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.8231 - val_loss: 1.1468\n",
            "Epoch 529/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.8418 - val_loss: 1.1854\n",
            "Epoch 530/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7386 - val_loss: 1.0935\n",
            "Epoch 531/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7345 - val_loss: 1.0755\n",
            "Epoch 532/5000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.7842 - val_loss: 1.1465\n",
            "Epoch 533/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.8021 - val_loss: 1.0953\n",
            "Epoch 534/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7828 - val_loss: 1.1773\n",
            "Epoch 535/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6516 - val_loss: 1.1611\n",
            "Epoch 536/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7393 - val_loss: 1.1493\n",
            "Epoch 537/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7249 - val_loss: 1.2078\n",
            "Epoch 538/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7305 - val_loss: 1.7710\n",
            "Epoch 539/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7715 - val_loss: 1.4864\n",
            "Epoch 540/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.8076 - val_loss: 1.1091\n",
            "Epoch 541/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7659 - val_loss: 1.1424\n",
            "Epoch 542/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6758 - val_loss: 1.0346\n",
            "Epoch 543/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7431 - val_loss: 1.9713\n",
            "Epoch 544/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7508 - val_loss: 1.1372\n",
            "Epoch 545/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7117 - val_loss: 1.0437\n",
            "Epoch 546/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7775 - val_loss: 1.1107\n",
            "Epoch 547/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6778 - val_loss: 1.0695\n",
            "Epoch 548/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7383 - val_loss: 1.1482\n",
            "Epoch 549/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7642 - val_loss: 1.1238\n",
            "Epoch 550/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6528 - val_loss: 1.0563\n",
            "Epoch 551/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7272 - val_loss: 1.2661\n",
            "Epoch 552/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6827 - val_loss: 1.0492\n",
            "Epoch 553/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7192 - val_loss: 1.0719\n",
            "Epoch 554/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7411 - val_loss: 1.0560\n",
            "Epoch 555/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.6806 - val_loss: 1.0393\n",
            "Epoch 556/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7670 - val_loss: 1.2547\n",
            "Epoch 557/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7443 - val_loss: 1.3914\n",
            "Epoch 558/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7634 - val_loss: 0.9906\n",
            "Epoch 559/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7423 - val_loss: 1.1395\n",
            "Epoch 560/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7060 - val_loss: 1.1520\n",
            "Epoch 561/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7314 - val_loss: 1.0979\n",
            "Epoch 562/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7060 - val_loss: 1.2964\n",
            "Epoch 563/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7492 - val_loss: 1.1922\n",
            "Epoch 564/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7139 - val_loss: 1.6718\n",
            "Epoch 565/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7031 - val_loss: 1.1251\n",
            "Epoch 566/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7321 - val_loss: 1.0043\n",
            "Epoch 567/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7152 - val_loss: 1.5921\n",
            "Epoch 568/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7785 - val_loss: 1.3948\n",
            "Epoch 569/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.8200 - val_loss: 1.1196\n",
            "Epoch 570/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7361 - val_loss: 1.1189\n",
            "Epoch 571/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7423 - val_loss: 1.0302\n",
            "Epoch 572/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7445 - val_loss: 1.0092\n",
            "Epoch 573/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7274 - val_loss: 1.0584\n",
            "Epoch 574/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7885 - val_loss: 1.1278\n",
            "Epoch 575/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7807 - val_loss: 1.0799\n",
            "Epoch 576/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.8065 - val_loss: 1.1318\n",
            "Epoch 577/5000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.7617 - val_loss: 1.1131\n",
            "Epoch 578/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7662 - val_loss: 1.0705\n",
            "Epoch 579/5000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.7286 - val_loss: 1.0412\n",
            "Epoch 580/5000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.7565 - val_loss: 1.4005\n",
            "Epoch 581/5000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.7377 - val_loss: 1.1998\n",
            "Epoch 582/5000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.6949 - val_loss: 1.2210\n",
            "Epoch 583/5000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.6746 - val_loss: 1.1840\n",
            "Epoch 584/5000\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 0.7446 - val_loss: 1.0228\n",
            "Epoch 585/5000\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 0.7503 - val_loss: 1.0728\n",
            "Epoch 586/5000\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.7553 - val_loss: 1.1563\n",
            "Epoch 587/5000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.7440 - val_loss: 1.0595\n",
            "Epoch 588/5000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.7809 - val_loss: 1.1052\n",
            "Epoch 589/5000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.6982 - val_loss: 1.3410\n",
            "Epoch 590/5000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.7653 - val_loss: 1.0730\n",
            "Epoch 591/5000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.7215 - val_loss: 1.0802\n",
            "Epoch 592/5000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.8300 - val_loss: 1.1744\n",
            "Epoch 593/5000\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 0.7256 - val_loss: 1.2868\n",
            "Epoch 594/5000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.6754 - val_loss: 1.0377\n",
            "Epoch 595/5000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.7198 - val_loss: 1.1440\n",
            "Epoch 596/5000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.7740 - val_loss: 1.1915\n",
            "Epoch 597/5000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.7527 - val_loss: 1.5322\n",
            "Epoch 598/5000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.6710 - val_loss: 1.3010\n",
            "Epoch 599/5000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.7726 - val_loss: 1.4347\n",
            "Epoch 600/5000\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 0.6764 - val_loss: 1.2547\n",
            "Epoch 601/5000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.6846 - val_loss: 1.2398\n",
            "Epoch 602/5000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.7777 - val_loss: 1.1278\n",
            "Epoch 603/5000\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 0.7232 - val_loss: 1.2248\n",
            "Epoch 604/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6814 - val_loss: 1.0997\n",
            "Epoch 605/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7489 - val_loss: 1.1733\n",
            "Epoch 606/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.6879 - val_loss: 1.2197\n",
            "Epoch 607/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.8401 - val_loss: 1.0777\n",
            "Epoch 608/5000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.7343 - val_loss: 1.1818\n",
            "Epoch 609/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.8167 - val_loss: 1.1711\n",
            "Epoch 610/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7475 - val_loss: 1.1376\n",
            "Epoch 611/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7518 - val_loss: 1.2323\n",
            "Epoch 612/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7741 - val_loss: 1.2713\n",
            "Epoch 613/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6648 - val_loss: 1.2407\n",
            "Epoch 614/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7620 - val_loss: 1.0583\n",
            "Epoch 615/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7816 - val_loss: 1.2127\n",
            "Epoch 616/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7634 - val_loss: 1.2302\n",
            "Epoch 617/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7403 - val_loss: 1.0939\n",
            "Epoch 618/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7847 - val_loss: 1.0528\n",
            "Epoch 619/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.8797 - val_loss: 1.5268\n",
            "Epoch 620/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7408 - val_loss: 1.1988\n",
            "Epoch 621/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6889 - val_loss: 1.4394\n",
            "Epoch 622/5000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.7118 - val_loss: 1.1873\n",
            "Epoch 623/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.8748 - val_loss: 1.0236\n",
            "Epoch 624/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7314 - val_loss: 1.0975\n",
            "Epoch 625/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7597 - val_loss: 1.2894\n",
            "Epoch 626/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7266 - val_loss: 1.1883\n",
            "Epoch 627/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7326 - val_loss: 1.1623\n",
            "Epoch 628/5000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.7104 - val_loss: 1.0719\n",
            "Epoch 629/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7672 - val_loss: 1.1582\n",
            "Epoch 630/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7482 - val_loss: 1.1921\n",
            "Epoch 631/5000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.7317 - val_loss: 1.2420\n",
            "Epoch 632/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7284 - val_loss: 1.0272\n",
            "Epoch 633/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7858 - val_loss: 1.4412\n",
            "Epoch 634/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7422 - val_loss: 1.1619\n",
            "Epoch 635/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7108 - val_loss: 1.3397\n",
            "Epoch 636/5000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.7413 - val_loss: 1.4538\n",
            "Epoch 637/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7595 - val_loss: 1.0895\n",
            "Epoch 638/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7271 - val_loss: 1.1029\n",
            "Epoch 639/5000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.7194 - val_loss: 1.2056\n",
            "Epoch 640/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7461 - val_loss: 1.1311\n",
            "Epoch 641/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7402 - val_loss: 1.1546\n",
            "Epoch 642/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.8228 - val_loss: 0.9988\n",
            "Epoch 643/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7370 - val_loss: 1.1458\n",
            "Epoch 644/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7143 - val_loss: 1.2495\n",
            "Epoch 645/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6729 - val_loss: 1.2420\n",
            "Epoch 646/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.8161 - val_loss: 1.2859\n",
            "Epoch 647/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7395 - val_loss: 1.1747\n",
            "Epoch 648/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6799 - val_loss: 1.4898\n",
            "Epoch 649/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.8037 - val_loss: 1.1678\n",
            "Epoch 650/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7282 - val_loss: 1.1134\n",
            "Epoch 651/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7770 - val_loss: 1.1861\n",
            "Epoch 652/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7267 - val_loss: 1.2226\n",
            "Epoch 653/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7396 - val_loss: 1.0796\n",
            "Epoch 654/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7540 - val_loss: 1.1023\n",
            "Epoch 655/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7196 - val_loss: 1.0693\n",
            "Epoch 656/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7042 - val_loss: 1.0765\n",
            "Epoch 657/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7401 - val_loss: 1.3946\n",
            "Epoch 658/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7452 - val_loss: 1.0291\n",
            "Epoch 659/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7771 - val_loss: 1.1533\n",
            "Epoch 660/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6654 - val_loss: 1.4566\n",
            "Epoch 661/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7337 - val_loss: 1.2297\n",
            "Epoch 662/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7992 - val_loss: 1.3839\n",
            "Epoch 663/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7332 - val_loss: 1.2444\n",
            "Epoch 664/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7248 - val_loss: 1.2768\n",
            "Epoch 665/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7138 - val_loss: 1.1509\n",
            "Epoch 666/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.6890 - val_loss: 1.2410\n",
            "Epoch 667/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7129 - val_loss: 1.4261\n",
            "Epoch 668/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7162 - val_loss: 1.1631\n",
            "Epoch 669/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7503 - val_loss: 1.0906\n",
            "Epoch 670/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7058 - val_loss: 1.1660\n",
            "Epoch 671/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6861 - val_loss: 1.5581\n",
            "Epoch 672/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6684 - val_loss: 1.1182\n",
            "Epoch 673/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7440 - val_loss: 1.2611\n",
            "Epoch 674/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7815 - val_loss: 1.2169\n",
            "Epoch 675/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7041 - val_loss: 1.1524\n",
            "Epoch 676/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7541 - val_loss: 1.1010\n",
            "Epoch 677/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.6561 - val_loss: 1.1403\n",
            "Epoch 678/5000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.6954 - val_loss: 1.2805\n",
            "Epoch 679/5000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.7953 - val_loss: 1.0678\n",
            "Epoch 680/5000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.7331 - val_loss: 1.0718\n",
            "Epoch 681/5000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.7292 - val_loss: 1.0995\n",
            "Epoch 682/5000\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 0.7617 - val_loss: 1.0577\n",
            "Epoch 683/5000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.7448 - val_loss: 1.1110\n",
            "Epoch 684/5000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.8073 - val_loss: 1.0726\n",
            "Epoch 685/5000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.6935 - val_loss: 1.0317\n",
            "Epoch 686/5000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.7805 - val_loss: 1.3477\n",
            "Epoch 687/5000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.7134 - val_loss: 1.3986\n",
            "Epoch 688/5000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.8073 - val_loss: 1.1593\n",
            "Epoch 689/5000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.6718 - val_loss: 1.1733\n",
            "Epoch 690/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7341 - val_loss: 1.1855\n",
            "Epoch 691/5000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.7147 - val_loss: 1.2460\n",
            "Epoch 692/5000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.7514 - val_loss: 1.1176\n",
            "Epoch 693/5000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.6757 - val_loss: 1.2767\n",
            "Epoch 694/5000\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.7332 - val_loss: 1.4932\n",
            "Epoch 695/5000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.7431 - val_loss: 1.2387\n",
            "Epoch 696/5000\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 0.7137 - val_loss: 1.0854\n",
            "Epoch 697/5000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.7454 - val_loss: 1.4534\n",
            "Epoch 698/5000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.8498 - val_loss: 1.2278\n",
            "Epoch 699/5000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.7365 - val_loss: 1.1534\n",
            "Epoch 700/5000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.7905 - val_loss: 1.0711\n",
            "Epoch 701/5000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.7843 - val_loss: 1.2399\n",
            "Epoch 702/5000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.7667 - val_loss: 1.2907\n",
            "Epoch 703/5000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.7357 - val_loss: 1.0407\n",
            "Epoch 704/5000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.7836 - val_loss: 1.1561\n",
            "Epoch 705/5000\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 0.7433 - val_loss: 1.2932\n",
            "Epoch 706/5000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.7173 - val_loss: 1.3140\n",
            "Epoch 707/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7268 - val_loss: 1.2838\n",
            "Epoch 708/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7381 - val_loss: 1.2729\n",
            "Epoch 709/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7284 - val_loss: 1.1544\n",
            "Epoch 710/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7306 - val_loss: 1.1695\n",
            "Epoch 711/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7316 - val_loss: 1.0565\n",
            "Epoch 712/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.8195 - val_loss: 1.0853\n",
            "Epoch 713/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.8147 - val_loss: 1.4179\n",
            "Epoch 714/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6871 - val_loss: 1.1479\n",
            "Epoch 715/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7431 - val_loss: 1.2551\n",
            "Epoch 716/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7828 - val_loss: 1.1079\n",
            "Epoch 717/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7573 - val_loss: 1.0645\n",
            "Epoch 718/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7021 - val_loss: 1.1600\n",
            "Epoch 719/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6986 - val_loss: 1.0661\n",
            "Epoch 720/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7197 - val_loss: 1.3618\n",
            "Epoch 721/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7404 - val_loss: 0.9501\n",
            "Epoch 722/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7962 - val_loss: 1.0910\n",
            "Epoch 723/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7114 - val_loss: 1.1934\n",
            "Epoch 724/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7813 - val_loss: 1.1301\n",
            "Epoch 725/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7549 - val_loss: 1.2212\n",
            "Epoch 726/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7846 - val_loss: 1.2611\n",
            "Epoch 727/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7070 - val_loss: 1.2179\n",
            "Epoch 728/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7385 - val_loss: 1.0928\n",
            "Epoch 729/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7592 - val_loss: 1.1634\n",
            "Epoch 730/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7487 - val_loss: 1.2461\n",
            "Epoch 731/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7419 - val_loss: 1.0553\n",
            "Epoch 732/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.8340 - val_loss: 1.1939\n",
            "Epoch 733/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7759 - val_loss: 1.3944\n",
            "Epoch 734/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7253 - val_loss: 1.2185\n",
            "Epoch 735/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7235 - val_loss: 1.1268\n",
            "Epoch 736/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.8195 - val_loss: 1.1031\n",
            "Epoch 737/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7548 - val_loss: 1.1478\n",
            "Epoch 738/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7635 - val_loss: 1.1826\n",
            "Epoch 739/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7668 - val_loss: 1.1663\n",
            "Epoch 740/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6961 - val_loss: 1.2310\n",
            "Epoch 741/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7451 - val_loss: 1.2550\n",
            "Epoch 742/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7066 - val_loss: 1.1600\n",
            "Epoch 743/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7293 - val_loss: 1.3357\n",
            "Epoch 744/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7143 - val_loss: 1.1375\n",
            "Epoch 745/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6866 - val_loss: 1.2225\n",
            "Epoch 746/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.8577 - val_loss: 1.5918\n",
            "Epoch 747/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.6889 - val_loss: 1.3234\n",
            "Epoch 748/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7404 - val_loss: 1.6230\n",
            "Epoch 749/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7560 - val_loss: 1.0959\n",
            "Epoch 750/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.6998 - val_loss: 1.0856\n",
            "Epoch 751/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7255 - val_loss: 1.3965\n",
            "Epoch 752/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7358 - val_loss: 1.1943\n",
            "Epoch 753/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7605 - val_loss: 1.4341\n",
            "Epoch 754/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.8021 - val_loss: 1.1453\n",
            "Epoch 755/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7384 - val_loss: 1.0371\n",
            "Epoch 756/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7324 - val_loss: 1.1140\n",
            "Epoch 757/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7240 - val_loss: 1.1256\n",
            "Epoch 758/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7398 - val_loss: 1.1319\n",
            "Epoch 759/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7569 - val_loss: 1.3316\n",
            "Epoch 760/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7183 - val_loss: 1.1717\n",
            "Epoch 761/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7461 - val_loss: 1.1694\n",
            "Epoch 762/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6717 - val_loss: 1.3163\n",
            "Epoch 763/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7514 - val_loss: 1.1445\n",
            "Epoch 764/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7437 - val_loss: 1.3377\n",
            "Epoch 765/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7903 - val_loss: 1.1874\n",
            "Epoch 766/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7065 - val_loss: 1.1091\n",
            "Epoch 767/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7317 - val_loss: 1.2177\n",
            "Epoch 768/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7364 - val_loss: 1.1930\n",
            "Epoch 769/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7661 - val_loss: 1.0834\n",
            "Epoch 770/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7524 - val_loss: 1.2339\n",
            "Epoch 771/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.8241 - val_loss: 0.9888\n",
            "Epoch 772/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7511 - val_loss: 1.3527\n",
            "Epoch 773/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7169 - val_loss: 1.3146\n",
            "Epoch 774/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.6920 - val_loss: 1.0489\n",
            "Epoch 775/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7427 - val_loss: 1.2690\n",
            "Epoch 776/5000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.7625 - val_loss: 1.2073\n",
            "Epoch 777/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7269 - val_loss: 1.1545\n",
            "Epoch 778/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7832 - val_loss: 1.1077\n",
            "Epoch 779/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7688 - val_loss: 1.0737\n",
            "Epoch 780/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7245 - val_loss: 1.2374\n",
            "Epoch 781/5000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.7583 - val_loss: 0.9656\n",
            "Epoch 782/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7467 - val_loss: 1.1964\n",
            "Epoch 783/5000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.7354 - val_loss: 1.0490\n",
            "Epoch 784/5000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.7296 - val_loss: 1.1135\n",
            "Epoch 785/5000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.7444 - val_loss: 1.0334\n",
            "Epoch 786/5000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.7362 - val_loss: 1.2147\n",
            "Epoch 787/5000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.7683 - val_loss: 0.9882\n",
            "Epoch 788/5000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.7693 - val_loss: 1.0667\n",
            "Epoch 789/5000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.8247 - val_loss: 1.0754\n",
            "Epoch 790/5000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.7057 - val_loss: 1.1630\n",
            "Epoch 791/5000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.8502 - val_loss: 1.2278\n",
            "Epoch 792/5000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.7893 - val_loss: 1.1858\n",
            "Epoch 793/5000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.7441 - val_loss: 1.3098\n",
            "Epoch 794/5000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.7187 - val_loss: 1.0339\n",
            "Epoch 795/5000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.7279 - val_loss: 1.1280\n",
            "Epoch 796/5000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.7909 - val_loss: 1.0655\n",
            "Epoch 797/5000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.7035 - val_loss: 1.1745\n",
            "Epoch 798/5000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.7351 - val_loss: 1.0817\n",
            "Epoch 799/5000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.7306 - val_loss: 1.1263\n",
            "Epoch 800/5000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.7376 - val_loss: 1.1876\n",
            "Epoch 801/5000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.7383 - val_loss: 1.1827\n",
            "Epoch 802/5000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.7459 - val_loss: 1.1938\n",
            "Epoch 803/5000\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.7851 - val_loss: 1.1841\n",
            "Epoch 804/5000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.6895 - val_loss: 1.6888\n",
            "Epoch 805/5000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.7366 - val_loss: 1.2693\n",
            "Epoch 806/5000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.7509 - val_loss: 1.2871\n",
            "Epoch 807/5000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.7663 - val_loss: 1.1039\n",
            "Epoch 808/5000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.6940 - val_loss: 1.2946\n",
            "Epoch 809/5000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.7454 - val_loss: 1.1568\n",
            "Epoch 810/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7021 - val_loss: 1.1023\n",
            "Epoch 811/5000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.7455 - val_loss: 1.1720\n",
            "Epoch 812/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7323 - val_loss: 1.1559\n",
            "Epoch 813/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7145 - val_loss: 1.1471\n",
            "Epoch 814/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7224 - val_loss: 1.3472\n",
            "Epoch 815/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7430 - val_loss: 1.1663\n",
            "Epoch 816/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6952 - val_loss: 1.4173\n",
            "Epoch 817/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7426 - val_loss: 1.1323\n",
            "Epoch 818/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.6919 - val_loss: 1.1890\n",
            "Epoch 819/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7629 - val_loss: 1.1446\n",
            "Epoch 820/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7600 - val_loss: 1.0660\n",
            "Epoch 821/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7888 - val_loss: 1.0824\n",
            "Epoch 822/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7525 - val_loss: 1.3045\n",
            "Epoch 823/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6994 - val_loss: 1.6181\n",
            "Epoch 824/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7774 - val_loss: 1.5773\n",
            "Epoch 825/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6829 - val_loss: 1.2002\n",
            "Epoch 826/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.6948 - val_loss: 1.3003\n",
            "Epoch 827/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7152 - val_loss: 1.2077\n",
            "Epoch 828/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6820 - val_loss: 1.2456\n",
            "Epoch 829/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7404 - val_loss: 1.2715\n",
            "Epoch 830/5000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.7275 - val_loss: 1.1607\n",
            "Epoch 831/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7654 - val_loss: 1.0723\n",
            "Epoch 832/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.8038 - val_loss: 1.0407\n",
            "Epoch 833/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7228 - val_loss: 1.2949\n",
            "Epoch 834/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7153 - val_loss: 1.1242\n",
            "Epoch 835/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7810 - val_loss: 1.1561\n",
            "Epoch 836/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.8004 - val_loss: 1.1420\n",
            "Epoch 837/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7282 - val_loss: 1.0954\n",
            "Epoch 838/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7061 - val_loss: 1.0813\n",
            "Epoch 839/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6966 - val_loss: 1.0636\n",
            "Epoch 840/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.6730 - val_loss: 1.2758\n",
            "Epoch 841/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7516 - val_loss: 1.1808\n",
            "Epoch 842/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7465 - val_loss: 1.1461\n",
            "Epoch 843/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7704 - val_loss: 1.5922\n",
            "Epoch 844/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6520 - val_loss: 1.3766\n",
            "Epoch 845/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.6798 - val_loss: 1.5823\n",
            "Epoch 846/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7642 - val_loss: 1.0566\n",
            "Epoch 847/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7290 - val_loss: 1.1618\n",
            "Epoch 848/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.8150 - val_loss: 1.2978\n",
            "Epoch 849/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7095 - val_loss: 1.3256\n",
            "Epoch 850/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6840 - val_loss: 1.1273\n",
            "Epoch 851/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7012 - val_loss: 1.2652\n",
            "Epoch 852/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7300 - val_loss: 1.1726\n",
            "Epoch 853/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6955 - val_loss: 1.1952\n",
            "Epoch 854/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.6892 - val_loss: 1.1478\n",
            "Epoch 855/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7153 - val_loss: 1.1746\n",
            "Epoch 856/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6975 - val_loss: 1.0540\n",
            "Epoch 857/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7488 - val_loss: 1.1902\n",
            "Epoch 858/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7751 - val_loss: 1.1979\n",
            "Epoch 859/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7931 - val_loss: 1.1872\n",
            "Epoch 860/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7193 - val_loss: 1.0333\n",
            "Epoch 861/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6900 - val_loss: 1.3440\n",
            "Epoch 862/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7393 - val_loss: 1.1216\n",
            "Epoch 863/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7206 - val_loss: 1.2430\n",
            "Epoch 864/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7324 - val_loss: 1.1984\n",
            "Epoch 865/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7885 - val_loss: 1.4891\n",
            "Epoch 866/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7821 - val_loss: 1.2281\n",
            "Epoch 867/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7019 - val_loss: 1.2907\n",
            "Epoch 868/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7060 - val_loss: 1.1589\n",
            "Epoch 869/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7553 - val_loss: 1.1432\n",
            "Epoch 870/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7835 - val_loss: 1.2807\n",
            "Epoch 871/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7305 - val_loss: 1.3022\n",
            "Epoch 872/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6942 - val_loss: 1.0753\n",
            "Epoch 873/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7381 - val_loss: 1.0922\n",
            "Epoch 874/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7256 - val_loss: 1.0826\n",
            "Epoch 875/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7387 - val_loss: 1.1693\n",
            "Epoch 876/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6688 - val_loss: 1.1656\n",
            "Epoch 877/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.6815 - val_loss: 1.4203\n",
            "Epoch 878/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.8395 - val_loss: 1.2185\n",
            "Epoch 879/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.6587 - val_loss: 1.0949\n",
            "Epoch 880/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7106 - val_loss: 1.1754\n",
            "Epoch 881/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.6654 - val_loss: 1.1239\n",
            "Epoch 882/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7546 - val_loss: 1.2310\n",
            "Epoch 883/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7154 - val_loss: 1.3080\n",
            "Epoch 884/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7161 - val_loss: 1.2277\n",
            "Epoch 885/5000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.6630 - val_loss: 1.4106\n",
            "Epoch 886/5000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.7102 - val_loss: 1.2950\n",
            "Epoch 887/5000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.7216 - val_loss: 1.2410\n",
            "Epoch 888/5000\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 0.7128 - val_loss: 1.2899\n",
            "Epoch 889/5000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.6860 - val_loss: 2.0953\n",
            "Epoch 890/5000\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.7761 - val_loss: 1.3413\n",
            "Epoch 891/5000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.7054 - val_loss: 1.1643\n",
            "Epoch 892/5000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.6795 - val_loss: 1.2952\n",
            "Epoch 893/5000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.7965 - val_loss: 1.3696\n",
            "Epoch 894/5000\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 0.6775 - val_loss: 1.2783\n",
            "Epoch 895/5000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.6933 - val_loss: 1.2040\n",
            "Epoch 896/5000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.6935 - val_loss: 1.4479\n",
            "Epoch 897/5000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.7278 - val_loss: 1.0650\n",
            "Epoch 898/5000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.6821 - val_loss: 1.0738\n",
            "Epoch 899/5000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.7369 - val_loss: 2.0547\n",
            "Epoch 900/5000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.7287 - val_loss: 1.1962\n",
            "Epoch 901/5000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.8149 - val_loss: 1.2007\n",
            "Epoch 902/5000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.7322 - val_loss: 1.5560\n",
            "Epoch 903/5000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.7255 - val_loss: 1.1386\n",
            "Epoch 904/5000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.7020 - val_loss: 1.3727\n",
            "Epoch 905/5000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.6612 - val_loss: 2.2817\n",
            "Epoch 906/5000\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 0.7209 - val_loss: 1.8843\n",
            "Epoch 907/5000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.8054 - val_loss: 1.1990\n",
            "Epoch 908/5000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.7799 - val_loss: 1.1686\n",
            "Epoch 909/5000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.6497 - val_loss: 1.1200\n",
            "Epoch 910/5000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.7084 - val_loss: 0.9930\n",
            "Epoch 911/5000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.6792 - val_loss: 1.1379\n",
            "Epoch 912/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7937 - val_loss: 1.1925\n",
            "Epoch 913/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.6811 - val_loss: 1.1169\n",
            "Epoch 914/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7243 - val_loss: 1.2032\n",
            "Epoch 915/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6989 - val_loss: 1.4665\n",
            "Epoch 916/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6799 - val_loss: 1.1363\n",
            "Epoch 917/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7275 - val_loss: 1.0999\n",
            "Epoch 918/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.6830 - val_loss: 1.1822\n",
            "Epoch 919/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.6905 - val_loss: 1.1872\n",
            "Epoch 920/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.6266 - val_loss: 1.2482\n",
            "Epoch 921/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6859 - val_loss: 1.1765\n",
            "Epoch 922/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7477 - val_loss: 1.3682\n",
            "Epoch 923/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6992 - val_loss: 1.3060\n",
            "Epoch 924/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6991 - val_loss: 1.2444\n",
            "Epoch 925/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7830 - val_loss: 1.0552\n",
            "Epoch 926/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7232 - val_loss: 1.2690\n",
            "Epoch 927/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.8084 - val_loss: 1.2204\n",
            "Epoch 928/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.6545 - val_loss: 1.1291\n",
            "Epoch 929/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7179 - val_loss: 1.2332\n",
            "Epoch 930/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7131 - val_loss: 1.2366\n",
            "Epoch 931/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7363 - val_loss: 1.2343\n",
            "Epoch 932/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7525 - val_loss: 1.0568\n",
            "Epoch 933/5000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.6545 - val_loss: 1.1626\n",
            "Epoch 934/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7373 - val_loss: 1.3317\n",
            "Epoch 935/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7399 - val_loss: 1.3599\n",
            "Epoch 936/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7046 - val_loss: 1.1388\n",
            "Epoch 937/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7084 - val_loss: 1.1617\n",
            "Epoch 938/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7911 - val_loss: 1.1488\n",
            "Epoch 939/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7947 - val_loss: 1.1771\n",
            "Epoch 940/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7724 - val_loss: 1.2184\n",
            "Epoch 941/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.6601 - val_loss: 1.4237\n",
            "Epoch 942/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6963 - val_loss: 1.1980\n",
            "Epoch 943/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.6540 - val_loss: 1.1832\n",
            "Epoch 944/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7005 - val_loss: 1.0396\n",
            "Epoch 945/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7155 - val_loss: 1.2439\n",
            "Epoch 946/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6938 - val_loss: 1.2925\n",
            "Epoch 947/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7411 - val_loss: 1.3077\n",
            "Epoch 948/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7600 - val_loss: 1.5725\n",
            "Epoch 949/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7541 - val_loss: 1.3135\n",
            "Epoch 950/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.6941 - val_loss: 1.2616\n",
            "Epoch 951/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7128 - val_loss: 1.1256\n",
            "Epoch 952/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6605 - val_loss: 1.2269\n",
            "Epoch 953/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7020 - val_loss: 1.4521\n",
            "Epoch 954/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7453 - val_loss: 1.1967\n",
            "Epoch 955/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7558 - val_loss: 1.0891\n",
            "Epoch 956/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.8212 - val_loss: 1.1842\n",
            "Epoch 957/5000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.6517 - val_loss: 1.5782\n",
            "Epoch 958/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7377 - val_loss: 1.1869\n",
            "Epoch 959/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7514 - val_loss: 1.2356\n",
            "Epoch 960/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7658 - val_loss: 1.0771\n",
            "Epoch 961/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7093 - val_loss: 1.0031\n",
            "Epoch 962/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7235 - val_loss: 1.1529\n",
            "Epoch 963/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6760 - val_loss: 1.5428\n",
            "Epoch 964/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.8454 - val_loss: 1.1436\n",
            "Epoch 965/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7180 - val_loss: 1.2310\n",
            "Epoch 966/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7272 - val_loss: 1.1934\n",
            "Epoch 967/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7126 - val_loss: 1.1739\n",
            "Epoch 968/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7767 - val_loss: 1.4452\n",
            "Epoch 969/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7432 - val_loss: 1.1361\n",
            "Epoch 970/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7102 - val_loss: 1.2804\n",
            "Epoch 971/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7030 - val_loss: 1.4529\n",
            "Epoch 972/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7390 - val_loss: 1.0935\n",
            "Epoch 973/5000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.7469 - val_loss: 1.0851\n",
            "Epoch 974/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7231 - val_loss: 1.0669\n",
            "Epoch 975/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7229 - val_loss: 1.1896\n",
            "Epoch 976/5000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.7405 - val_loss: 1.0567\n",
            "Epoch 977/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7224 - val_loss: 1.1741\n",
            "Epoch 978/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7341 - val_loss: 1.4277\n",
            "Epoch 979/5000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.7128 - val_loss: 1.3549\n",
            "Epoch 980/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7108 - val_loss: 1.4087\n",
            "Epoch 981/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7004 - val_loss: 1.3191\n",
            "Epoch 982/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.6860 - val_loss: 1.2706\n",
            "Epoch 983/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7621 - val_loss: 1.0862\n",
            "Epoch 984/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7337 - val_loss: 1.1712\n",
            "Epoch 985/5000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.7274 - val_loss: 1.0867\n",
            "Epoch 986/5000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.7051 - val_loss: 1.0760\n",
            "Epoch 987/5000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.7314 - val_loss: 1.6431\n",
            "Epoch 988/5000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.7291 - val_loss: 1.0879\n",
            "Epoch 989/5000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.7071 - val_loss: 1.1369\n",
            "Epoch 990/5000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.7081 - val_loss: 1.5334\n",
            "Epoch 991/5000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.6554 - val_loss: 1.2459\n",
            "Epoch 992/5000\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 0.7193 - val_loss: 1.2977\n",
            "Epoch 993/5000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.7533 - val_loss: 1.2544\n",
            "Epoch 994/5000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.7355 - val_loss: 1.2906\n",
            "Epoch 995/5000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.7194 - val_loss: 1.1434\n",
            "Epoch 996/5000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.6831 - val_loss: 1.0501\n",
            "Epoch 997/5000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.7384 - val_loss: 1.1438\n",
            "Epoch 998/5000\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 0.7527 - val_loss: 1.4449\n",
            "Epoch 999/5000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.7194 - val_loss: 1.5366\n",
            "Epoch 1000/5000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.6488 - val_loss: 1.5078\n",
            "Epoch 1001/5000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.6534 - val_loss: 1.2316\n",
            "Epoch 1002/5000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.7396 - val_loss: 1.1136\n",
            "Epoch 1003/5000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.7462 - val_loss: 1.3839\n",
            "Epoch 1004/5000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.6928 - val_loss: 1.4860\n",
            "Epoch 1005/5000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.6497 - val_loss: 1.0681\n",
            "Epoch 1006/5000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.6950 - val_loss: 1.0426\n",
            "Epoch 1007/5000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.6755 - val_loss: 1.5462\n",
            "Epoch 1008/5000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.7108 - val_loss: 1.3403\n",
            "Epoch 1009/5000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.7592 - val_loss: 1.1455\n",
            "Epoch 1010/5000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.6855 - val_loss: 1.2425\n",
            "Epoch 1011/5000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.6849 - val_loss: 1.1571\n",
            "Epoch 1012/5000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.7178 - val_loss: 1.1455\n",
            "Epoch 1013/5000\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 0.7058 - val_loss: 1.3713\n",
            "Epoch 1014/5000\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 0.7105 - val_loss: 1.1250\n",
            "Epoch 1015/5000\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.7327 - val_loss: 1.2838\n",
            "Epoch 1016/5000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.7502 - val_loss: 1.1750\n",
            "Epoch 1017/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.6657 - val_loss: 1.2418\n",
            "Epoch 1018/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7326 - val_loss: 1.2227\n",
            "Epoch 1019/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7362 - val_loss: 1.0403\n",
            "Epoch 1020/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.6861 - val_loss: 1.0678\n",
            "Epoch 1021/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7135 - val_loss: 1.4662\n",
            "Epoch 1022/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.6886 - val_loss: 1.7675\n",
            "Epoch 1023/5000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.7123 - val_loss: 1.3705\n",
            "Epoch 1024/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7471 - val_loss: 1.4990\n",
            "Epoch 1025/5000\n",
            "23/23 [==============================] - 0s 12ms/step - loss: 0.7415 - val_loss: 1.4054\n",
            "Epoch 1026/5000\n",
            "23/23 [==============================] - 1s 22ms/step - loss: 0.6663 - val_loss: 1.4734\n",
            "Epoch 1027/5000\n",
            "23/23 [==============================] - 0s 18ms/step - loss: 0.6978 - val_loss: 1.3340\n",
            "Epoch 1028/5000\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 0.7284 - val_loss: 1.1244\n",
            "Epoch 1029/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7303 - val_loss: 1.1848\n",
            "Epoch 1030/5000\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.7093 - val_loss: 1.0334\n",
            "Epoch 1031/5000\n",
            "23/23 [==============================] - 1s 26ms/step - loss: 0.6915 - val_loss: 1.3796\n",
            "Epoch 1032/5000\n",
            "23/23 [==============================] - 0s 19ms/step - loss: 0.6749 - val_loss: 1.2169\n",
            "Epoch 1033/5000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.7137 - val_loss: 1.2664\n",
            "Epoch 1034/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7107 - val_loss: 1.2373\n",
            "Epoch 1035/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7536 - val_loss: 1.1423\n",
            "Epoch 1036/5000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.7011 - val_loss: 1.1100\n",
            "Epoch 1037/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7481 - val_loss: 1.1325\n",
            "Epoch 1038/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.6937 - val_loss: 1.2649\n",
            "Epoch 1039/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7281 - val_loss: 1.1931\n",
            "Epoch 1040/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7289 - val_loss: 1.3072\n",
            "Epoch 1041/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7495 - val_loss: 1.5496\n",
            "Epoch 1042/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7094 - val_loss: 1.3626\n",
            "Epoch 1043/5000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.6856 - val_loss: 1.1770\n",
            "Epoch 1044/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7288 - val_loss: 1.3833\n",
            "Epoch 1045/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7963 - val_loss: 1.1369\n",
            "Epoch 1046/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.6954 - val_loss: 1.2471\n",
            "Epoch 1047/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.6845 - val_loss: 1.3299\n",
            "Epoch 1048/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7237 - val_loss: 1.2975\n",
            "Epoch 1049/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.8159 - val_loss: 1.3533\n",
            "Epoch 1050/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7698 - val_loss: 1.1723\n",
            "Epoch 1051/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.6821 - val_loss: 1.1696\n",
            "Epoch 1052/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7012 - val_loss: 1.2159\n",
            "Epoch 1053/5000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.7197 - val_loss: 1.2099\n",
            "Epoch 1054/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7423 - val_loss: 1.4793\n",
            "Epoch 1055/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7483 - val_loss: 1.1844\n",
            "Epoch 1056/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7526 - val_loss: 0.9792\n",
            "Epoch 1057/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7140 - val_loss: 1.1194\n",
            "Epoch 1058/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7488 - val_loss: 1.4124\n",
            "Epoch 1059/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6551 - val_loss: 1.2263\n",
            "Epoch 1060/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.8888 - val_loss: 1.0560\n",
            "Epoch 1061/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7018 - val_loss: 1.1445\n",
            "Epoch 1062/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.6827 - val_loss: 1.2913\n",
            "Epoch 1063/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7194 - val_loss: 1.1942\n",
            "Epoch 1064/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7829 - val_loss: 1.1925\n",
            "Epoch 1065/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.6866 - val_loss: 1.8276\n",
            "Epoch 1066/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.6900 - val_loss: 1.3228\n",
            "Epoch 1067/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7433 - val_loss: 1.0795\n",
            "Epoch 1068/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6947 - val_loss: 1.1231\n",
            "Epoch 1069/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.6989 - val_loss: 1.1290\n",
            "Epoch 1070/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.6658 - val_loss: 1.1835\n",
            "Epoch 1071/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7121 - val_loss: 1.0971\n",
            "Epoch 1072/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7279 - val_loss: 1.1327\n",
            "Epoch 1073/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7127 - val_loss: 1.0734\n",
            "Epoch 1074/5000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.7143 - val_loss: 1.0473\n",
            "Epoch 1075/5000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.7554 - val_loss: 1.0816\n",
            "Epoch 1076/5000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.6775 - val_loss: 1.1621\n",
            "Epoch 1077/5000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.7033 - val_loss: 1.3019\n",
            "Epoch 1078/5000\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 0.8311 - val_loss: 1.1610\n",
            "Epoch 1079/5000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.6892 - val_loss: 1.1465\n",
            "Epoch 1080/5000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.7514 - val_loss: 1.0603\n",
            "Epoch 1081/5000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.7329 - val_loss: 1.4547\n",
            "Epoch 1082/5000\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.7325 - val_loss: 1.0854\n",
            "Epoch 1083/5000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.7813 - val_loss: 1.0000\n",
            "Epoch 1084/5000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.7104 - val_loss: 1.1306\n",
            "Epoch 1085/5000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.7272 - val_loss: 1.1770\n",
            "Epoch 1086/5000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.6423 - val_loss: 1.0646\n",
            "Epoch 1087/5000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.7131 - val_loss: 1.2546\n",
            "Epoch 1088/5000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.7220 - val_loss: 1.1880\n",
            "Epoch 1089/5000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.6758 - val_loss: 1.3168\n",
            "Epoch 1090/5000\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.7569 - val_loss: 1.1456\n",
            "Epoch 1091/5000\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 0.7257 - val_loss: 1.3682\n",
            "Epoch 1092/5000\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 0.6913 - val_loss: 1.2058\n",
            "Epoch 1093/5000\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 0.8417 - val_loss: 1.1767\n",
            "Epoch 1094/5000\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 0.7446 - val_loss: 1.0175\n",
            "Epoch 1095/5000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.7174 - val_loss: 1.5535\n",
            "Epoch 1096/5000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.7810 - val_loss: 1.1380\n",
            "Epoch 1097/5000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.6491 - val_loss: 1.0254\n",
            "Epoch 1098/5000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.6889 - val_loss: 1.1805\n",
            "Epoch 1099/5000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.6739 - val_loss: 1.0578\n",
            "Epoch 1100/5000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.6652 - val_loss: 1.1608\n",
            "Epoch 1101/5000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.6807 - val_loss: 1.2435\n",
            "Epoch 1102/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7498 - val_loss: 1.2673\n",
            "Epoch 1103/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6871 - val_loss: 1.1762\n",
            "Epoch 1104/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.6933 - val_loss: 1.3641\n",
            "Epoch 1105/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7201 - val_loss: 1.0333\n",
            "Epoch 1106/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7811 - val_loss: 1.0430\n",
            "Epoch 1107/5000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.7303 - val_loss: 1.1234\n",
            "Epoch 1108/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.6771 - val_loss: 1.1777\n",
            "Epoch 1109/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6954 - val_loss: 1.1915\n",
            "Epoch 1110/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.6639 - val_loss: 1.4937\n",
            "Epoch 1111/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7496 - val_loss: 1.1932\n",
            "Epoch 1112/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.6759 - val_loss: 1.2896\n",
            "Epoch 1113/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.6901 - val_loss: 1.0586\n",
            "Epoch 1114/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7590 - val_loss: 1.3839\n",
            "Epoch 1115/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7376 - val_loss: 1.5971\n",
            "Epoch 1116/5000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.7272 - val_loss: 1.1264\n",
            "Epoch 1117/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.6674 - val_loss: 1.2761\n",
            "Epoch 1118/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7268 - val_loss: 1.1549\n",
            "Epoch 1119/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.6890 - val_loss: 1.1511\n",
            "Epoch 1120/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6952 - val_loss: 1.6014\n",
            "Epoch 1121/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6961 - val_loss: 1.4887\n",
            "Epoch 1122/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.6904 - val_loss: 1.4993\n",
            "Epoch 1123/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7251 - val_loss: 1.0887\n",
            "Epoch 1124/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7452 - val_loss: 0.9741\n",
            "Epoch 1125/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7202 - val_loss: 1.1523\n",
            "Epoch 1126/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.6839 - val_loss: 1.1610\n",
            "Epoch 1127/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7487 - val_loss: 1.2330\n",
            "Epoch 1128/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.6965 - val_loss: 1.1494\n",
            "Epoch 1129/5000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.7010 - val_loss: 1.1789\n",
            "Epoch 1130/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.6988 - val_loss: 1.2980\n",
            "Epoch 1131/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7469 - val_loss: 1.2150\n",
            "Epoch 1132/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7074 - val_loss: 1.1571\n",
            "Epoch 1133/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7223 - val_loss: 1.3735\n",
            "Epoch 1134/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.6825 - val_loss: 1.1593\n",
            "Epoch 1135/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.6989 - val_loss: 1.2034\n",
            "Epoch 1136/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7024 - val_loss: 0.9820\n",
            "Epoch 1137/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7005 - val_loss: 1.3112\n",
            "Epoch 1138/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.6945 - val_loss: 1.0217\n",
            "Epoch 1139/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.6832 - val_loss: 1.1829\n",
            "Epoch 1140/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6670 - val_loss: 1.1892\n",
            "Epoch 1141/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7527 - val_loss: 1.1895\n",
            "Epoch 1142/5000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.6999 - val_loss: 1.6664\n",
            "Epoch 1143/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7409 - val_loss: 1.1043\n",
            "Epoch 1144/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7119 - val_loss: 1.3976\n",
            "Epoch 1145/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.8004 - val_loss: 1.1518\n",
            "Epoch 1146/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.8201 - val_loss: 1.2838\n",
            "Epoch 1147/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.6966 - val_loss: 1.3807\n",
            "Epoch 1148/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.6993 - val_loss: 1.1266\n",
            "Epoch 1149/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7082 - val_loss: 1.2005\n",
            "Epoch 1150/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.6655 - val_loss: 1.4106\n",
            "Epoch 1151/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7470 - val_loss: 1.1593\n",
            "Epoch 1152/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.6780 - val_loss: 1.2698\n",
            "Epoch 1153/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7295 - val_loss: 1.3258\n",
            "Epoch 1154/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6761 - val_loss: 1.2448\n",
            "Epoch 1155/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6861 - val_loss: 1.0274\n",
            "Epoch 1156/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.6872 - val_loss: 1.4020\n",
            "Epoch 1157/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7563 - val_loss: 1.4357\n",
            "Epoch 1158/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7029 - val_loss: 1.9309\n",
            "Epoch 1159/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7099 - val_loss: 1.0111\n",
            "Epoch 1160/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.6924 - val_loss: 1.2826\n",
            "Epoch 1161/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7433 - val_loss: 1.4035\n",
            "Epoch 1162/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7343 - val_loss: 1.2861\n",
            "Epoch 1163/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7594 - val_loss: 1.2036\n",
            "Epoch 1164/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7766 - val_loss: 1.5454\n",
            "Epoch 1165/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.6671 - val_loss: 1.7572\n",
            "Epoch 1166/5000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.7225 - val_loss: 1.2093\n",
            "Epoch 1167/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7185 - val_loss: 1.1200\n",
            "Epoch 1168/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7230 - val_loss: 1.1585\n",
            "Epoch 1169/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7330 - val_loss: 1.1531\n",
            "Epoch 1170/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7176 - val_loss: 1.2628\n",
            "Epoch 1171/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7172 - val_loss: 1.3294\n",
            "Epoch 1172/5000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.7133 - val_loss: 1.2617\n",
            "Epoch 1173/5000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.6351 - val_loss: 1.1503\n",
            "Epoch 1174/5000\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 0.8615 - val_loss: 1.4029\n",
            "Epoch 1175/5000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.7640 - val_loss: 1.1886\n",
            "Epoch 1176/5000\n",
            "23/23 [==============================] - 0s 13ms/step - loss: 0.6791 - val_loss: 1.2024\n",
            "Epoch 1177/5000\n",
            "23/23 [==============================] - 0s 19ms/step - loss: 0.7815 - val_loss: 1.5192\n",
            "Epoch 1178/5000\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 0.7738 - val_loss: 1.2866\n",
            "Epoch 1179/5000\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 0.8112 - val_loss: 1.0625\n",
            "Epoch 1180/5000\n",
            "23/23 [==============================] - 0s 18ms/step - loss: 0.6994 - val_loss: 1.2254\n",
            "Epoch 1181/5000\n",
            "23/23 [==============================] - 0s 14ms/step - loss: 0.6534 - val_loss: 1.1897\n",
            "Epoch 1182/5000\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 0.6775 - val_loss: 1.3021\n",
            "Epoch 1183/5000\n",
            "23/23 [==============================] - 0s 21ms/step - loss: 0.7414 - val_loss: 1.3226\n",
            "Epoch 1184/5000\n",
            "23/23 [==============================] - 0s 18ms/step - loss: 0.6968 - val_loss: 1.3792\n",
            "Epoch 1185/5000\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 0.7434 - val_loss: 1.2091\n",
            "Epoch 1186/5000\n",
            "23/23 [==============================] - 0s 22ms/step - loss: 0.7272 - val_loss: 1.0187\n",
            "Epoch 1187/5000\n",
            "23/23 [==============================] - 0s 19ms/step - loss: 0.6964 - val_loss: 1.0110\n",
            "Epoch 1188/5000\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.7706 - val_loss: 1.3163\n",
            "Epoch 1189/5000\n",
            "23/23 [==============================] - 0s 21ms/step - loss: 0.7067 - val_loss: 1.5341\n",
            "Epoch 1190/5000\n",
            "23/23 [==============================] - 0s 21ms/step - loss: 0.7244 - val_loss: 1.3927\n",
            "Epoch 1191/5000\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.7359 - val_loss: 1.3002\n",
            "Epoch 1192/5000\n",
            "23/23 [==============================] - 0s 18ms/step - loss: 0.7290 - val_loss: 1.2793\n",
            "Epoch 1193/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7008 - val_loss: 1.1514\n",
            "Epoch 1194/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7155 - val_loss: 1.2807\n",
            "Epoch 1195/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7717 - val_loss: 1.1003\n",
            "Epoch 1196/5000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.7111 - val_loss: 1.1170\n",
            "Epoch 1197/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.6781 - val_loss: 2.1613\n",
            "Epoch 1198/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7015 - val_loss: 1.3614\n",
            "Epoch 1199/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7137 - val_loss: 1.4762\n",
            "Epoch 1200/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7768 - val_loss: 1.0774\n",
            "Epoch 1201/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7401 - val_loss: 1.3391\n",
            "Epoch 1202/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7302 - val_loss: 1.0637\n",
            "Epoch 1203/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7091 - val_loss: 1.3563\n",
            "Epoch 1204/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7243 - val_loss: 1.0613\n",
            "Epoch 1205/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7466 - val_loss: 1.2638\n",
            "Epoch 1206/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7544 - val_loss: 1.0569\n",
            "Epoch 1207/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7111 - val_loss: 1.1521\n",
            "Epoch 1208/5000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.6609 - val_loss: 1.1085\n",
            "Epoch 1209/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7937 - val_loss: 1.3524\n",
            "Epoch 1210/5000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.7341 - val_loss: 1.1919\n",
            "Epoch 1211/5000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.6798 - val_loss: 1.1942\n",
            "Epoch 1212/5000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.7329 - val_loss: 1.1623\n",
            "Epoch 1213/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7100 - val_loss: 1.2861\n",
            "Epoch 1214/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7553 - val_loss: 1.2264\n",
            "Epoch 1215/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7636 - val_loss: 1.1801\n",
            "Epoch 1216/5000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.7540 - val_loss: 1.1005\n",
            "Epoch 1217/5000\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 0.7490 - val_loss: 1.1779\n",
            "Epoch 1218/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7217 - val_loss: 1.2450\n",
            "Epoch 1219/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.8361 - val_loss: 1.1269\n",
            "Epoch 1220/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6893 - val_loss: 1.1189\n",
            "Epoch 1221/5000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.7491 - val_loss: 1.0684\n",
            "Epoch 1222/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7867 - val_loss: 1.1965\n",
            "Epoch 1223/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7129 - val_loss: 1.1402\n",
            "Epoch 1224/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7160 - val_loss: 1.5074\n",
            "Epoch 1225/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6989 - val_loss: 1.1499\n",
            "Epoch 1226/5000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.6857 - val_loss: 1.0238\n",
            "Epoch 1227/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7134 - val_loss: 1.3785\n",
            "Epoch 1228/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7765 - val_loss: 1.2180\n",
            "Epoch 1229/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.6910 - val_loss: 1.1525\n",
            "Epoch 1230/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7108 - val_loss: 1.0844\n",
            "Epoch 1231/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.6538 - val_loss: 1.2088\n",
            "Epoch 1232/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7742 - val_loss: 1.1671\n",
            "Epoch 1233/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7478 - val_loss: 1.3003\n",
            "Epoch 1234/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7900 - val_loss: 1.0841\n",
            "Epoch 1235/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7299 - val_loss: 1.2346\n",
            "Epoch 1236/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7493 - val_loss: 1.3277\n",
            "Epoch 1237/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.6846 - val_loss: 1.2990\n",
            "Epoch 1238/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.6880 - val_loss: 1.1424\n",
            "Epoch 1239/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7620 - val_loss: 1.1258\n",
            "Epoch 1240/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7032 - val_loss: 1.1159\n",
            "Epoch 1241/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7880 - val_loss: 1.0701\n",
            "Epoch 1242/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7168 - val_loss: 1.2068\n",
            "Epoch 1243/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7407 - val_loss: 1.4492\n",
            "Epoch 1244/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.6981 - val_loss: 1.2571\n",
            "Epoch 1245/5000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.7466 - val_loss: 1.1752\n",
            "Epoch 1246/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7161 - val_loss: 1.2295\n",
            "Epoch 1247/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7474 - val_loss: 1.2439\n",
            "Epoch 1248/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7045 - val_loss: 1.4313\n",
            "Epoch 1249/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7344 - val_loss: 0.9610\n",
            "Epoch 1250/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.6874 - val_loss: 1.0452\n",
            "Epoch 1251/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.6645 - val_loss: 1.1999\n",
            "Epoch 1252/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7200 - val_loss: 1.1422\n",
            "Epoch 1253/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.6975 - val_loss: 1.1121\n",
            "Epoch 1254/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7018 - val_loss: 1.1294\n",
            "Epoch 1255/5000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.7600 - val_loss: 1.2636\n",
            "Epoch 1256/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7322 - val_loss: 1.3097\n",
            "Epoch 1257/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7248 - val_loss: 1.0993\n",
            "Epoch 1258/5000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.6724 - val_loss: 1.2055\n",
            "Epoch 1259/5000\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 0.6832 - val_loss: 1.4141\n",
            "Epoch 1260/5000\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 0.6970 - val_loss: 1.2606\n",
            "Epoch 1261/5000\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 0.7448 - val_loss: 1.3254\n",
            "Epoch 1262/5000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.6877 - val_loss: 1.2267\n",
            "Epoch 1263/5000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.7573 - val_loss: 1.2792\n",
            "Epoch 1264/5000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.7372 - val_loss: 1.2500\n",
            "Epoch 1265/5000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.7500 - val_loss: 1.4788\n",
            "Epoch 1266/5000\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.7440 - val_loss: 1.2982\n",
            "Epoch 1267/5000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.8451 - val_loss: 1.4085\n",
            "Epoch 1268/5000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.7045 - val_loss: 1.4311\n",
            "Epoch 1269/5000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.7253 - val_loss: 1.2056\n",
            "Epoch 1270/5000\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.6933 - val_loss: 1.1488\n",
            "Epoch 1271/5000\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 0.6636 - val_loss: 1.4776\n",
            "Epoch 1272/5000\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 0.7242 - val_loss: 1.4357\n",
            "Epoch 1273/5000\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 0.7139 - val_loss: 1.3295\n",
            "Epoch 1274/5000\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 0.7145 - val_loss: 1.2846\n",
            "Epoch 1275/5000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.8003 - val_loss: 1.3934\n",
            "Epoch 1276/5000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.7092 - val_loss: 1.0005\n",
            "Epoch 1277/5000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.6704 - val_loss: 1.4283\n",
            "Epoch 1278/5000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.7043 - val_loss: 1.0795\n",
            "Epoch 1279/5000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.7790 - val_loss: 1.5873\n",
            "Epoch 1280/5000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.7719 - val_loss: 1.0554\n",
            "Epoch 1281/5000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.6764 - val_loss: 1.1413\n",
            "Epoch 1282/5000\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 0.7206 - val_loss: 1.1763\n",
            "Epoch 1283/5000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.7152 - val_loss: 1.1487\n",
            "Epoch 1284/5000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.6790 - val_loss: 1.2298\n",
            "Epoch 1285/5000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.6970 - val_loss: 1.0996\n",
            "Epoch 1286/5000\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 0.7121 - val_loss: 1.2766\n",
            "Epoch 1287/5000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.8108 - val_loss: 1.1814\n",
            "Epoch 1288/5000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.6696 - val_loss: 1.0317\n",
            "Epoch 1289/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.6471 - val_loss: 1.2860\n",
            "Epoch 1290/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7131 - val_loss: 1.5925\n",
            "Epoch 1291/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7391 - val_loss: 1.3331\n",
            "Epoch 1292/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7088 - val_loss: 1.1509\n",
            "Epoch 1293/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.6911 - val_loss: 0.9953\n",
            "Epoch 1294/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7363 - val_loss: 1.0670\n",
            "Epoch 1295/5000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.6248 - val_loss: 1.0928\n",
            "Epoch 1296/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7298 - val_loss: 1.1978\n",
            "Epoch 1297/5000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.6982 - val_loss: 1.5384\n",
            "Epoch 1298/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.8004 - val_loss: 1.4200\n",
            "Epoch 1299/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7013 - val_loss: 1.1166\n",
            "Epoch 1300/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.6541 - val_loss: 1.1115\n",
            "Epoch 1301/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.6954 - val_loss: 1.0745\n",
            "Epoch 1302/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7250 - val_loss: 1.6021\n",
            "Epoch 1303/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.8062 - val_loss: 1.1932\n",
            "Epoch 1304/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7532 - val_loss: 1.5825\n",
            "Epoch 1305/5000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.6783 - val_loss: 1.6248\n",
            "Epoch 1306/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.6563 - val_loss: 1.2006\n",
            "Epoch 1307/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7781 - val_loss: 1.1426\n",
            "Epoch 1308/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.6415 - val_loss: 1.2475\n",
            "Epoch 1309/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7049 - val_loss: 1.0632\n",
            "Epoch 1310/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.6390 - val_loss: 1.3483\n",
            "Epoch 1311/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7307 - val_loss: 1.2743\n",
            "Epoch 1312/5000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.7137 - val_loss: 1.0501\n",
            "Epoch 1313/5000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.7029 - val_loss: 1.1392\n",
            "Epoch 1314/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.6518 - val_loss: 1.0168\n",
            "Epoch 1315/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7356 - val_loss: 1.0912\n",
            "Epoch 1316/5000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.7737 - val_loss: 1.2375\n",
            "Epoch 1317/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.6766 - val_loss: 1.1442\n",
            "Epoch 1318/5000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.6323 - val_loss: 1.3187\n",
            "Epoch 1319/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.6896 - val_loss: 1.4566\n",
            "Epoch 1320/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.6671 - val_loss: 1.2632\n",
            "Epoch 1321/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.6792 - val_loss: 1.1966\n",
            "Epoch 1322/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.6507 - val_loss: 1.1190\n",
            "Epoch 1323/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.6880 - val_loss: 1.5738\n",
            "Epoch 1324/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7610 - val_loss: 1.1394\n",
            "Epoch 1325/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.6788 - val_loss: 1.0596\n",
            "Epoch 1326/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7571 - val_loss: 1.2111\n",
            "Epoch 1327/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7192 - val_loss: 1.2356\n",
            "Epoch 1328/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7563 - val_loss: 1.1139\n",
            "Epoch 1329/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7274 - val_loss: 1.1130\n",
            "Epoch 1330/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7313 - val_loss: 1.2360\n",
            "Epoch 1331/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7348 - val_loss: 1.1632\n",
            "Epoch 1332/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7317 - val_loss: 1.2047\n",
            "Epoch 1333/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.6842 - val_loss: 1.3791\n",
            "Epoch 1334/5000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.6723 - val_loss: 1.2250\n",
            "Epoch 1335/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7228 - val_loss: 1.0908\n",
            "Epoch 1336/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.6794 - val_loss: 1.1910\n",
            "Epoch 1337/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7442 - val_loss: 1.2369\n",
            "Epoch 1338/5000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.6585 - val_loss: 1.1872\n",
            "Epoch 1339/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7658 - val_loss: 1.1752\n",
            "Epoch 1340/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.6798 - val_loss: 1.1424\n",
            "Epoch 1341/5000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.8296 - val_loss: 1.2459\n",
            "Epoch 1342/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7667 - val_loss: 1.2432\n",
            "Epoch 1343/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7513 - val_loss: 1.1109\n",
            "Epoch 1344/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7051 - val_loss: 0.9943\n",
            "Epoch 1345/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.6839 - val_loss: 1.5343\n",
            "Epoch 1346/5000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.6494 - val_loss: 1.2362\n",
            "Epoch 1347/5000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.7524 - val_loss: 1.1419\n",
            "Epoch 1348/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7535 - val_loss: 1.3962\n",
            "Epoch 1349/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7419 - val_loss: 1.0453\n",
            "Epoch 1350/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.6642 - val_loss: 1.1989\n",
            "Epoch 1351/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7466 - val_loss: 1.1591\n",
            "Epoch 1352/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7196 - val_loss: 1.1688\n",
            "Epoch 1353/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7300 - val_loss: 1.1452\n",
            "Epoch 1354/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7024 - val_loss: 1.1796\n",
            "Epoch 1355/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.6867 - val_loss: 1.0989\n",
            "Epoch 1356/5000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.7086 - val_loss: 1.3745\n",
            "Epoch 1357/5000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.7194 - val_loss: 1.0458\n",
            "Epoch 1358/5000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.7189 - val_loss: 1.2998\n",
            "Epoch 1359/5000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.7176 - val_loss: 1.1768\n",
            "Epoch 1360/5000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.6880 - val_loss: 1.2980\n",
            "Epoch 1361/5000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.6980 - val_loss: 1.2518\n",
            "Epoch 1362/5000\n",
            "23/23 [==============================] - 0s 12ms/step - loss: 0.7124 - val_loss: 1.4375\n",
            "Epoch 1363/5000\n",
            "23/23 [==============================] - 0s 15ms/step - loss: 0.8103 - val_loss: 1.2320\n",
            "Epoch 1364/5000\n",
            "23/23 [==============================] - 0s 19ms/step - loss: 0.7774 - val_loss: 1.2782\n",
            "Epoch 1365/5000\n",
            "23/23 [==============================] - 0s 19ms/step - loss: 0.6222 - val_loss: 1.2303\n",
            "Epoch 1366/5000\n",
            "23/23 [==============================] - 0s 15ms/step - loss: 0.6936 - val_loss: 1.1264\n",
            "Epoch 1367/5000\n",
            "23/23 [==============================] - 0s 18ms/step - loss: 0.6778 - val_loss: 1.1887\n",
            "Epoch 1368/5000\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.8311 - val_loss: 1.3017\n",
            "Epoch 1369/5000\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 0.7150 - val_loss: 1.3000\n",
            "Epoch 1370/5000\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.6920 - val_loss: 1.1549\n",
            "Epoch 1371/5000\n",
            "23/23 [==============================] - 0s 20ms/step - loss: 0.7459 - val_loss: 1.0824\n",
            "Epoch 1372/5000\n",
            "23/23 [==============================] - 0s 14ms/step - loss: 0.7279 - val_loss: 0.9827\n",
            "Epoch 1373/5000\n",
            "23/23 [==============================] - 0s 12ms/step - loss: 0.7042 - val_loss: 1.4349\n",
            "Epoch 1374/5000\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.7513 - val_loss: 1.0964\n",
            "Epoch 1375/5000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.6934 - val_loss: 1.2883\n",
            "Epoch 1376/5000\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.6941 - val_loss: 1.1607\n",
            "Epoch 1377/5000\n",
            "23/23 [==============================] - 0s 13ms/step - loss: 0.7102 - val_loss: 1.6841\n",
            "Epoch 1378/5000\n",
            "23/23 [==============================] - 0s 13ms/step - loss: 0.7387 - val_loss: 1.3316\n",
            "Epoch 1379/5000\n",
            "23/23 [==============================] - 0s 13ms/step - loss: 0.7023 - val_loss: 1.1900\n",
            "Epoch 1380/5000\n",
            "23/23 [==============================] - 0s 13ms/step - loss: 0.6483 - val_loss: 1.0147\n",
            "Epoch 1381/5000\n",
            "23/23 [==============================] - 0s 15ms/step - loss: 0.7209 - val_loss: 1.2116\n",
            "Epoch 1382/5000\n",
            "23/23 [==============================] - 0s 12ms/step - loss: 0.7485 - val_loss: 1.1813\n",
            "Epoch 1383/5000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.7123 - val_loss: 1.2627\n",
            "Epoch 1384/5000\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.6830 - val_loss: 1.0687\n",
            "Epoch 1385/5000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.8285 - val_loss: 1.1235\n",
            "Epoch 1386/5000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.7258 - val_loss: 1.0836\n",
            "Epoch 1387/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.6811 - val_loss: 1.9335\n",
            "Epoch 1388/5000\n",
            "23/23 [==============================] - 0s 12ms/step - loss: 0.6801 - val_loss: 1.1043\n",
            "Epoch 1389/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.6683 - val_loss: 1.4196\n",
            "Epoch 1390/5000\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.7538 - val_loss: 1.3931\n",
            "Epoch 1391/5000\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.6848 - val_loss: 1.1597\n",
            "Epoch 1392/5000\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 0.7166 - val_loss: 1.3096\n",
            "Epoch 1393/5000\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.6862 - val_loss: 1.6232\n",
            "Epoch 1394/5000\n",
            "23/23 [==============================] - 0s 15ms/step - loss: 0.6649 - val_loss: 1.3656\n",
            "Epoch 1395/5000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.7457 - val_loss: 1.1461\n",
            "Epoch 1396/5000\n",
            "23/23 [==============================] - 0s 18ms/step - loss: 0.6687 - val_loss: 2.6432\n",
            "Epoch 1397/5000\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.7060 - val_loss: 1.2966\n",
            "Epoch 1398/5000\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 0.7220 - val_loss: 1.4201\n",
            "Epoch 1399/5000\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.7465 - val_loss: 1.7242\n",
            "Epoch 1400/5000\n",
            "23/23 [==============================] - 0s 14ms/step - loss: 0.6873 - val_loss: 1.2397\n",
            "Epoch 1401/5000\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.7172 - val_loss: 1.4356\n",
            "Epoch 1402/5000\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.7553 - val_loss: 1.2637\n",
            "Epoch 1403/5000\n",
            "23/23 [==============================] - 0s 12ms/step - loss: 0.6582 - val_loss: 1.0165\n",
            "Epoch 1404/5000\n",
            "23/23 [==============================] - 0s 12ms/step - loss: 0.7413 - val_loss: 1.6150\n",
            "Epoch 1405/5000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.6760 - val_loss: 1.4314\n",
            "Epoch 1406/5000\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 0.7069 - val_loss: 1.1414\n",
            "Epoch 1407/5000\n",
            "23/23 [==============================] - 0s 18ms/step - loss: 0.6916 - val_loss: 1.0270\n",
            "Epoch 1408/5000\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.6486 - val_loss: 1.1798\n",
            "Epoch 1409/5000\n",
            "23/23 [==============================] - 0s 21ms/step - loss: 0.6725 - val_loss: 1.0519\n",
            "Epoch 1410/5000\n",
            "23/23 [==============================] - 0s 15ms/step - loss: 0.7171 - val_loss: 1.3476\n",
            "Epoch 1411/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7019 - val_loss: 1.2000\n",
            "Epoch 1412/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7454 - val_loss: 1.2595\n",
            "Epoch 1413/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.6944 - val_loss: 1.3062\n",
            "Epoch 1414/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7414 - val_loss: 1.1938\n",
            "Epoch 1415/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7541 - val_loss: 1.2381\n",
            "Epoch 1416/5000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6701 - val_loss: 1.2232\n",
            "Epoch 1417/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.6976 - val_loss: 1.1470\n",
            "Epoch 1418/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.6717 - val_loss: 1.4246\n",
            "Epoch 1419/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.6939 - val_loss: 1.2646\n",
            "Epoch 1420/5000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.7151 - val_loss: 1.1782\n",
            "Epoch 1421/5000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7089 - val_loss: 1.2910\n",
            "Epoch 1422/5000\n",
            "17/23 [=====================>........] - ETA: 0s - loss: 0.6335Restoring model weights from the end of the best epoch: 422.\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.6894 - val_loss: 1.1626\n",
            "Epoch 1422: early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-b383c653ffcb>:9: UserWarning: Attempt to set non-positive ylim on a log-scaled axis will be ignored.\n",
            "  plt.ylim((0, 10))\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val loss: 0.9009193778038025\n",
            "Train loss: 0.8023808002471924\n",
            "Test loss: 3.3909249305725098\n",
            "dO18 RMSE: 3.2635571513978787\n",
            "EXPECTED:\n",
            "    d18O_cel_mean  d18O_cel_variance\n",
            "0       24.042000           0.345970\n",
            "1       25.240000           0.035950\n",
            "2       25.782000           0.372220\n",
            "3       25.076000           0.230280\n",
            "4       25.966000           0.172480\n",
            "5       27.434000           0.501030\n",
            "6       28.156000           0.999030\n",
            "7       26.836000           0.120880\n",
            "8       28.180000           0.778250\n",
            "9       26.834000           0.094930\n",
            "10      26.644000           0.488430\n",
            "11      26.772000           0.373370\n",
            "12      27.684280           1.216389\n",
            "13      27.403235           0.892280\n",
            "14      24.777670           0.736571\n",
            "15      25.551850           0.312355\n",
            "16      25.115885           0.033519\n",
            "17      25.987815           5.280825\n",
            "18      24.132031           0.389042\n",
            "19      24.898000           0.236070\n",
            "20      23.944000           0.158130\n",
            "21      26.018000           0.964170\n",
            "\n",
            "PREDICTED:\n",
            "    d18O_cel_mean  d18O_cel_variance\n",
            "0       24.837303           1.879802\n",
            "1       24.837303           1.879802\n",
            "2       24.837303           1.879802\n",
            "3       24.837303           1.879802\n",
            "4       24.837303           1.879802\n",
            "5       22.644062           1.778405\n",
            "6       22.728319           1.782687\n",
            "7       22.728319           1.782687\n",
            "8       22.728319           1.782687\n",
            "9       22.728319           1.782687\n",
            "10      22.728319           1.782687\n",
            "11      22.728319           1.782687\n",
            "12      22.644062           1.778405\n",
            "13      22.728319           1.782687\n",
            "14      22.557999           1.877691\n",
            "15      22.583136           1.905089\n",
            "16      22.611982           1.902155\n",
            "17      22.532345           1.910216\n",
            "18      22.596558           1.904221\n",
            "19      24.837303           1.879802\n",
            "20      24.837303           1.879802\n",
            "21      24.837303           1.879802\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/gdrive/MyDrive/amazon_rainforest_files/variational/model/fixed_all_isorix_carbon_ensemble.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "70bfdc7ee2bd490181b70fd4abd2508f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [
              "widget-interact"
            ],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8d6e76aa1506472e9ac0025470e508c8",
              "IPY_MODEL_ecad0b67a823441ea9e2bfaf1040014c",
              "IPY_MODEL_a811ba449e4645eca6f055881e5d5ee4",
              "IPY_MODEL_b41f3416523c4fdeb6715a3bd0800297"
            ],
            "layout": "IPY_MODEL_8f4c97c8a317402e8cd87e2a9f68b110"
          }
        },
        "8d6e76aa1506472e9ac0025470e508c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "TextModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "TextModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "TextView",
            "continuous_update": true,
            "description": "Email",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_79d54b7b7d9544bc88b83876a9f90b76",
            "placeholder": "Enter email",
            "style": "IPY_MODEL_65e718a7efcf4110825afcc58175451b",
            "value": "tripiace@yahoo.com"
          }
        },
        "ecad0b67a823441ea9e2bfaf1040014c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "TextModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "TextModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "TextView",
            "continuous_update": true,
            "description": "Branch name",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_459ebaa22b5045d38717346cf92c50bd",
            "placeholder": "Enter branch name",
            "style": "IPY_MODEL_9effba8769064b20b43b0f8b71bbae53",
            "value": "gen_isoscape"
          }
        },
        "a811ba449e4645eca6f055881e5d5ee4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Checkout Code",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_9a2f3f4e1bd84bb18e478c45f75aa1dc",
            "style": "IPY_MODEL_6ec745afa16e44d18c6267ee871875a9",
            "tooltip": ""
          }
        },
        "b41f3416523c4fdeb6715a3bd0800297": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_f8d09ea1a1b845128b6a2dc8f146ff87",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "executing checkout_branch gen_isoscape...\n",
                  "Branch gen_isosca already checked out.\n",
                  "Remember to reload your imports with `importlib.reload(module)`.\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "b\"fatal: destination path 'ddf_common' already exists and is not an empty directory.\\nRepository already exists.\\n\"\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "b'Already up to date.\\n'\n",
                  "b''\n",
                  "gen_isoscape branch checked out at \"/content/gdrive/MyDrive/gen_isoscape/ddf_common\". You may now use ddf_common imports and change common files.\n"
                ]
              },
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "interactive(children=(Text(value='required', description='Commit Msg', placeholder='Enter commit message'), Bu…",
                  "application/vnd.jupyter.widget-view+json": {
                    "version_major": 2,
                    "version_minor": 0,
                    "model_id": "7c8783981c9c4d599c743f4accfd6e4b"
                  }
                },
                "metadata": {}
              }
            ]
          }
        },
        "8f4c97c8a317402e8cd87e2a9f68b110": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "79d54b7b7d9544bc88b83876a9f90b76": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "65e718a7efcf4110825afcc58175451b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "459ebaa22b5045d38717346cf92c50bd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9effba8769064b20b43b0f8b71bbae53": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9a2f3f4e1bd84bb18e478c45f75aa1dc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6ec745afa16e44d18c6267ee871875a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "f8d09ea1a1b845128b6a2dc8f146ff87": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7c8783981c9c4d599c743f4accfd6e4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [
              "widget-interact"
            ],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6da1e760f1c14114a3a8f19875afdd12",
              "IPY_MODEL_0b9bbac4365f410dabb92987ee6f49e4",
              "IPY_MODEL_919e5f838acf480f8c6a478cf434ddcd"
            ],
            "layout": "IPY_MODEL_37e61ed537774c75abce882b8fb642cf"
          }
        },
        "6da1e760f1c14114a3a8f19875afdd12": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "TextModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "TextModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "TextView",
            "continuous_update": true,
            "description": "Commit Msg",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_5c3b3d66a2c549568086dc5b4520e375",
            "placeholder": "Enter commit message",
            "style": "IPY_MODEL_b136df15d48f4833a62f847901a2d306",
            "value": "required"
          }
        },
        "0b9bbac4365f410dabb92987ee6f49e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Commit All Changes",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_c4f3815be1f14075a159b6b76e98676e",
            "style": "IPY_MODEL_aaa5ed5f345948fc91619f49fabf3573",
            "tooltip": ""
          }
        },
        "919e5f838acf480f8c6a478cf434ddcd": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_7b212a12d61547978eb7ab925447fa59",
            "msg_id": "",
            "outputs": []
          }
        },
        "37e61ed537774c75abce882b8fb642cf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5c3b3d66a2c549568086dc5b4520e375": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b136df15d48f4833a62f847901a2d306": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c4f3815be1f14075a159b6b76e98676e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aaa5ed5f345948fc91619f49fabf3573": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "7b212a12d61547978eb7ab925447fa59": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}