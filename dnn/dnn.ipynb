{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "henIPlAPCb4i"
      },
      "outputs": [],
      "source": [
        "from collections import defaultdict\n",
        "import math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from typing import List\n",
        "\n",
        "#@title Debugging\n",
        "# See https://zohaib.me/debugging-in-google-collab-notebook/ for tips,\n",
        "# as well as docs for pdb and ipdb.\n",
        "DEBUG = False #@param {type:\"boolean\"}\n",
        "GDRIVE_BASE = \"/content/drive\" #@param\n",
        "DATAFRAME_PATH = \"/MyDrive/amazon_rainforest_files/monthly_large.csv\" #@param\n",
        "RASTER_BASE = \"/MyDrive/amazon_rainforest_files/amazon_rasters/\" #@param\n",
        "MODEL_SAVE_LOCATION = \"/MyDrive/amazon_rainforest_files/dnn_model.h5\" #@param\n",
        "\n",
        "def get_dataframe_path_from_params() -> str:\n",
        "  root = GDRIVE_BASE if GDRIVE_BASE else \"\"\n",
        "  return f\"{root}{DATAFRAME_PATH}\"\n",
        "\n",
        "def get_model_save_location() -> str:\n",
        "  root = GDRIVE_BASE if GDRIVE_BASE else \"\"\n",
        "  return f\"{root}{MODEL_SAVE_LOCATION}\"\n",
        "\n",
        "def get_raster_path_from_params(filename) -> str:\n",
        "  root = GDRIVE_BASE if GDRIVE_BASE else \"\"\n",
        "  return f\"{root}{RASTER_BASE}{filename}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xeNtt6exCb4n"
      },
      "outputs": [],
      "source": [
        "# Access data stored on Google Drive\n",
        "if GDRIVE_BASE:\n",
        "    from google.colab import drive\n",
        "    drive.mount(GDRIVE_BASE)\n",
        "\n",
        "if DEBUG:\n",
        "    %pip install -Uqq ipdb\n",
        "    import ipdb\n",
        "    %pdb on"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 148,
      "metadata": {
        "id": "dEhjp8rhCb4o"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, regularizers\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "def kl_divergence_loss(real, predicted):\n",
        "    real_value = real[0]\n",
        "    real_variance = real[1] + 0.00000001\n",
        "    predicted_value = predicted[0]\n",
        "    predicted_variance = predicted[1] + 0.00000001\n",
        "\n",
        "    kl_loss = -0.5 + tf.math.log(predicted_variance/real_variance) + \\\n",
        "     (tf.square(real_variance) + tf.square(real_value - predicted_value))/ \\\n",
        "     2*tf.square(predicted_variance)\n",
        "    return tf.math.reduce_mean(kl_loss)\n",
        "\n",
        "def train_nn(\n",
        "        X: pd.DataFrame,\n",
        "        Y: pd.DataFrame,\n",
        "        hidden_layers: List[int],\n",
        "        epochs: int,\n",
        "        batch_size: int):\n",
        "    # Layers share between mean and variance regressors.\n",
        "    shared_layers = []\n",
        "    for num_nodes in hidden_layers:\n",
        "        shared_layers.append(layers.Dense(\n",
        "            num_nodes,\n",
        "            activation='sigmoid'))\n",
        "\n",
        "    #Initialize input layers and connect them to shared layers.\n",
        "    num_inputs = X.shape[1]\n",
        "    inputs = keras.Input(shape=(num_inputs,))\n",
        "    x = inputs\n",
        "    for shared_layer in shared_layers:\n",
        "        x = shared_layer(x)\n",
        "\n",
        "    # Output is variance and mean, and connect to shared nodes.\n",
        "    mean_output_layer = layers.Dense(1, activation='linear', name='mean_output')\n",
        "    mean_output_node = mean_output_layer(x)\n",
        "    variance_output_layer = layers.Dense(1, activation='sigmoid', name='variance_output')\n",
        "    variance_output_node = variance_output_layer(x)\n",
        "    outputs = [mean_output_node, variance_output_node]\n",
        "\n",
        "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "    optimizer = keras.optimizers.Adam(learning_rate=0.001)\n",
        "    model.compile(optimizer=optimizer, loss={'mean_output': 'mse', 'variance_output': kl_divergence_loss})\n",
        "    history = model.fit(X, Y, epochs=epochs, batch_size=batch_size, validation_split=0.2, shuffle=True)\n",
        "    return history, model\n",
        "\n",
        "def render_plot_loss(history):\n",
        "  plt.plot(history.history['mean_output_loss'])\n",
        "  plt.plot(history.history['variance_output_loss'])\n",
        "  plt.title('model loss')\n",
        "  plt.ylabel('loss')\n",
        "  plt.xlabel('epoch')\n",
        "  plt.legend(['mean', 'variance'], loc='upper left')\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GQrEv57zCb4q"
      },
      "source": [
        "Data preparation:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 144,
      "metadata": {
        "id": "6eSNtXphCb4s"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "df = pd.read_csv(get_dataframe_path_from_params())\n",
        "\n",
        "group_on = ['sample_site_lon', 'sample_site_lat', 'month_of_year']\n",
        "grouped = df.groupby(group_on)\n",
        "\n",
        "# ASSUMPTION: Taking the mean and variance of a sample site doesn't lower quality of the data.\n",
        "# We need to do this to use KL-divergence loss.\n",
        "means = grouped.mean()\n",
        "O18_var = grouped.var()['cellulose_oxygen_ratio']\n",
        "\n",
        "# Merging results in some unreadable column names. Rename the oxygen columns.\n",
        "merged = pd.merge(means, O18_var, on=group_on, how='inner').reset_index()\n",
        "merged = merged.rename(columns={\n",
        "    'cellulose_oxygen_ratio_x': 'O18_mean',\n",
        "    'cellulose_oxygen_ratio_y' : 'O18_var'})\n",
        "\n",
        "# ...and drop sample_site_lon/sample_site_lat. These were keys used to identify\n",
        "# sample sites. They are basically duplicates of the 'lat' 'lon' columns.\n",
        "merged.drop(merged.columns[merged.columns.str.contains('unnamed',case = False)], axis = 1, inplace = True)\n",
        "merged.drop('sample_site_lon', axis = 1, inplace = True)\n",
        "merged.drop('sample_site_lat', axis = 1, inplace = True)\n",
        "\n",
        "train, test = train_test_split(merged, test_size=0.25, random_state=25)\n",
        "\n",
        "# Target data: Mean and variance\n",
        "Y_train = train[[\"O18_mean\", \"O18_var\"]]\n",
        "Y_test = test[[\"O18_mean\", \"O18_var\"]]\n",
        "\n",
        "def format_output(Y):\n",
        "  y1 = Y.pop(\"O18_mean\")\n",
        "  y1 = np.array(y1)\n",
        "  y2 = Y.pop(\"O18_var\")\n",
        "  y2 = np.array(y2)\n",
        "  return y1, y2\n",
        "\n",
        "Y_train = format_output(Y_train)\n",
        "Y_test = format_output(Y_test)\n",
        "\n",
        "# Features: Everything besides mean and variance\n",
        "X_train = train.drop([\"O18_mean\", \"O18_var\"], axis=1)\n",
        "X_test = test.drop([\"O18_mean\", \"O18_var\"], axis=1)\n",
        "X_train.drop(X_train.columns[X_train.columns.str.contains('unnamed',case = False)],axis = 1, inplace = True)\n",
        "X_test.drop(X_test.columns[X_test.columns.str.contains('unnamed',case = False)],axis = 1, inplace = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nUDsOgFJCb4t"
      },
      "source": [
        "Variance KL-loss: 0.9\n",
        "\n",
        "Mean MSE loss: 26.37\n",
        "\n",
        "\"General loss\": 27.03"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train\n",
        "history, model = train_nn(X_train, Y_train, hidden_layers=[12, 20], epochs=5000, batch_size=60)\n",
        "render_plot_loss(history)"
      ],
      "metadata": {
        "id": "IecLJ7D5DIQ-",
        "outputId": "961042fc-5699-4f2d-c69f-5cc410603bec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 1468.2520 - mean_output_loss: 1466.0281 - variance_output_loss: 2.2239"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 19 calls to <function Model.make_test_function.<locals>.test_function at 0x7f7d8208f880> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2/2 [==============================] - 1s 226ms/step - loss: 1486.2655 - mean_output_loss: 1484.0350 - variance_output_loss: 2.2305 - val_loss: 1420.4620 - val_mean_output_loss: 1417.0760 - val_variance_output_loss: 3.3862\n",
            "Epoch 2/5000\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 1483.1398 - mean_output_loss: 1480.3823 - variance_output_loss: 2.7575 - val_loss: 1416.8003 - val_mean_output_loss: 1413.4315 - val_variance_output_loss: 3.3688\n",
            "Epoch 3/5000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 1479.1317 - mean_output_loss: 1476.7300 - variance_output_loss: 2.4017 - val_loss: 1413.1183 - val_mean_output_loss: 1409.7671 - val_variance_output_loss: 3.3513\n",
            "Epoch 4/5000\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 1474.8779 - mean_output_loss: 1473.0408 - variance_output_loss: 1.8369 - val_loss: 1409.4141 - val_mean_output_loss: 1406.0804 - val_variance_output_loss: 3.3337\n",
            "Epoch 5/5000\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 1471.3385 - mean_output_loss: 1469.3680 - variance_output_loss: 1.9705 - val_loss: 1405.6836 - val_mean_output_loss: 1402.3677 - val_variance_output_loss: 3.3159\n",
            "Epoch 6/5000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 1468.8959 - mean_output_loss: 1465.6421 - variance_output_loss: 3.2537 - val_loss: 1401.9279 - val_mean_output_loss: 1398.6299 - val_variance_output_loss: 3.2980\n",
            "Epoch 7/5000\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 1463.7803 - mean_output_loss: 1461.8990 - variance_output_loss: 1.8812 - val_loss: 1398.1453 - val_mean_output_loss: 1394.8654 - val_variance_output_loss: 3.2799\n",
            "Epoch 8/5000\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 1459.9518 - mean_output_loss: 1458.1681 - variance_output_loss: 1.7838 - val_loss: 1394.3335 - val_mean_output_loss: 1391.0718 - val_variance_output_loss: 3.2617\n",
            "Epoch 9/5000\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 1456.6567 - mean_output_loss: 1454.3595 - variance_output_loss: 2.2972 - val_loss: 1390.5011 - val_mean_output_loss: 1387.2578 - val_variance_output_loss: 3.2433\n",
            "Epoch 10/5000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 1452.6786 - mean_output_loss: 1450.6030 - variance_output_loss: 2.0756 - val_loss: 1386.6431 - val_mean_output_loss: 1383.4185 - val_variance_output_loss: 3.2246\n",
            "Epoch 11/5000\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 1449.7037 - mean_output_loss: 1446.7919 - variance_output_loss: 2.9119 - val_loss: 1382.7662 - val_mean_output_loss: 1379.5604 - val_variance_output_loss: 3.2058\n",
            "Epoch 12/5000\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 1444.8018 - mean_output_loss: 1442.9420 - variance_output_loss: 1.8599 - val_loss: 1378.8773 - val_mean_output_loss: 1375.6907 - val_variance_output_loss: 3.1867\n",
            "Epoch 13/5000\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 1441.0541 - mean_output_loss: 1439.0944 - variance_output_loss: 1.9599 - val_loss: 1374.9789 - val_mean_output_loss: 1371.8115 - val_variance_output_loss: 3.1674\n",
            "Epoch 14/5000\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 1437.9977 - mean_output_loss: 1435.2358 - variance_output_loss: 2.7617 - val_loss: 1371.0765 - val_mean_output_loss: 1367.9287 - val_variance_output_loss: 3.1479\n",
            "Epoch 15/5000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 1434.3403 - mean_output_loss: 1431.3439 - variance_output_loss: 2.9964 - val_loss: 1367.1780 - val_mean_output_loss: 1364.0499 - val_variance_output_loss: 3.1281\n",
            "Epoch 16/5000\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 1428.8319 - mean_output_loss: 1427.4907 - variance_output_loss: 1.3411 - val_loss: 1363.2838 - val_mean_output_loss: 1360.1757 - val_variance_output_loss: 3.1082\n",
            "Epoch 17/5000\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 1426.4427 - mean_output_loss: 1423.5604 - variance_output_loss: 2.8822 - val_loss: 1359.4052 - val_mean_output_loss: 1356.3170 - val_variance_output_loss: 3.0881\n",
            "Epoch 18/5000\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 1421.5443 - mean_output_loss: 1419.6774 - variance_output_loss: 1.8668 - val_loss: 1355.5381 - val_mean_output_loss: 1352.4702 - val_variance_output_loss: 3.0679\n",
            "Epoch 19/5000\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 1417.6478 - mean_output_loss: 1415.7886 - variance_output_loss: 1.8593 - val_loss: 1351.6866 - val_mean_output_loss: 1348.6390 - val_variance_output_loss: 3.0476\n",
            "Epoch 20/5000\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 1414.5663 - mean_output_loss: 1411.8666 - variance_output_loss: 2.6997 - val_loss: 1347.8538 - val_mean_output_loss: 1344.8265 - val_variance_output_loss: 3.0272\n",
            "Epoch 21/5000\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 1409.8967 - mean_output_loss: 1407.9745 - variance_output_loss: 1.9223 - val_loss: 1344.0359 - val_mean_output_loss: 1341.0292 - val_variance_output_loss: 3.0067\n",
            "Epoch 22/5000\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 1407.0642 - mean_output_loss: 1404.0784 - variance_output_loss: 2.9858 - val_loss: 1340.2319 - val_mean_output_loss: 1337.2460 - val_variance_output_loss: 2.9860\n",
            "Epoch 23/5000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 1402.9248 - mean_output_loss: 1400.1539 - variance_output_loss: 2.7708 - val_loss: 1336.4399 - val_mean_output_loss: 1333.4750 - val_variance_output_loss: 2.9650\n",
            "Epoch 24/5000\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 1398.0033 - mean_output_loss: 1396.2421 - variance_output_loss: 1.7614 - val_loss: 1332.6505 - val_mean_output_loss: 1329.7068 - val_variance_output_loss: 2.9437\n",
            "Epoch 25/5000\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 1395.5990 - mean_output_loss: 1392.3339 - variance_output_loss: 3.2652 - val_loss: 1328.8524 - val_mean_output_loss: 1325.9304 - val_variance_output_loss: 2.9220\n",
            "Epoch 26/5000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 1389.4517 - mean_output_loss: 1388.3978 - variance_output_loss: 1.0538 - val_loss: 1325.0314 - val_mean_output_loss: 1322.1315 - val_variance_output_loss: 2.8999\n",
            "Epoch 27/5000\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 1386.8674 - mean_output_loss: 1384.4259 - variance_output_loss: 2.4415 - val_loss: 1321.1740 - val_mean_output_loss: 1318.2966 - val_variance_output_loss: 2.8773\n",
            "Epoch 28/5000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 1382.3232 - mean_output_loss: 1380.4073 - variance_output_loss: 1.9157 - val_loss: 1317.2579 - val_mean_output_loss: 1314.4039 - val_variance_output_loss: 2.8540\n",
            "Epoch 29/5000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 1378.9612 - mean_output_loss: 1376.3053 - variance_output_loss: 2.6559 - val_loss: 1313.2661 - val_mean_output_loss: 1310.4360 - val_variance_output_loss: 2.8300\n",
            "Epoch 30/5000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 1373.8995 - mean_output_loss: 1372.0815 - variance_output_loss: 1.8178 - val_loss: 1309.1813 - val_mean_output_loss: 1306.3760 - val_variance_output_loss: 2.8052\n",
            "Epoch 31/5000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 1368.5560 - mean_output_loss: 1367.7638 - variance_output_loss: 0.7923 - val_loss: 1304.9924 - val_mean_output_loss: 1302.2130 - val_variance_output_loss: 2.7795\n",
            "Epoch 32/5000\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 1366.8506 - mean_output_loss: 1363.3600 - variance_output_loss: 3.4905 - val_loss: 1300.7059 - val_mean_output_loss: 1297.9532 - val_variance_output_loss: 2.7526\n",
            "Epoch 33/5000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 1360.9602 - mean_output_loss: 1358.8383 - variance_output_loss: 2.1218 - val_loss: 1296.3490 - val_mean_output_loss: 1293.6244 - val_variance_output_loss: 2.7246\n",
            "Epoch 34/5000\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 1356.3154 - mean_output_loss: 1354.2732 - variance_output_loss: 2.0422 - val_loss: 1291.9669 - val_mean_output_loss: 1289.2712 - val_variance_output_loss: 2.6957\n",
            "Epoch 35/5000\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 1352.6022 - mean_output_loss: 1349.7070 - variance_output_loss: 2.8952 - val_loss: 1287.6180 - val_mean_output_loss: 1284.9521 - val_variance_output_loss: 2.6659\n",
            "Epoch 36/5000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 1348.4944 - mean_output_loss: 1345.2328 - variance_output_loss: 3.2615 - val_loss: 1283.3596 - val_mean_output_loss: 1280.7240 - val_variance_output_loss: 2.6356\n",
            "Epoch 37/5000\n",
            "2/2 [==============================] - 0s 76ms/step - loss: 1341.3273 - mean_output_loss: 1340.8900 - variance_output_loss: 0.4371 - val_loss: 1279.2394 - val_mean_output_loss: 1276.6345 - val_variance_output_loss: 2.6050\n",
            "Epoch 38/5000\n",
            "2/2 [==============================] - 0s 66ms/step - loss: 1338.4767 - mean_output_loss: 1336.7208 - variance_output_loss: 1.7559 - val_loss: 1275.2828 - val_mean_output_loss: 1272.7086 - val_variance_output_loss: 2.5742\n",
            "Epoch 39/5000\n",
            "2/2 [==============================] - 0s 107ms/step - loss: 1335.4252 - mean_output_loss: 1332.7345 - variance_output_loss: 2.6907 - val_loss: 1271.4937 - val_mean_output_loss: 1268.9503 - val_variance_output_loss: 2.5433\n",
            "Epoch 40/5000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 1330.3835 - mean_output_loss: 1328.9280 - variance_output_loss: 1.4556 - val_loss: 1267.8573 - val_mean_output_loss: 1265.3452 - val_variance_output_loss: 2.5122\n",
            "Epoch 41/5000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 1328.2593 - mean_output_loss: 1325.2966 - variance_output_loss: 2.9626 - val_loss: 1264.3521 - val_mean_output_loss: 1261.8710 - val_variance_output_loss: 2.4809\n",
            "Epoch 42/5000\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 1322.6492 - mean_output_loss: 1321.7568 - variance_output_loss: 0.8924 - val_loss: 1260.9584 - val_mean_output_loss: 1258.5089 - val_variance_output_loss: 2.4494\n",
            "Epoch 43/5000\n",
            "2/2 [==============================] - 0s 66ms/step - loss: 1320.0411 - mean_output_loss: 1318.3438 - variance_output_loss: 1.6974 - val_loss: 1257.6530 - val_mean_output_loss: 1255.2354 - val_variance_output_loss: 2.4176\n",
            "Epoch 44/5000\n",
            "2/2 [==============================] - 0s 77ms/step - loss: 1317.5884 - mean_output_loss: 1314.9855 - variance_output_loss: 2.6030 - val_loss: 1254.4209 - val_mean_output_loss: 1252.0354 - val_variance_output_loss: 2.3855\n",
            "Epoch 45/5000\n",
            "2/2 [==============================] - 0s 72ms/step - loss: 1312.8752 - mean_output_loss: 1311.7256 - variance_output_loss: 1.1496 - val_loss: 1251.2435 - val_mean_output_loss: 1248.8905 - val_variance_output_loss: 2.3531\n",
            "Epoch 46/5000\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 1310.9850 - mean_output_loss: 1308.5085 - variance_output_loss: 2.4765 - val_loss: 1248.1128 - val_mean_output_loss: 1245.7925 - val_variance_output_loss: 2.3203\n",
            "Epoch 47/5000\n",
            "2/2 [==============================] - 0s 69ms/step - loss: 1306.5251 - mean_output_loss: 1305.3300 - variance_output_loss: 1.1951 - val_loss: 1245.0206 - val_mean_output_loss: 1242.7334 - val_variance_output_loss: 2.2872\n",
            "Epoch 48/5000\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 1302.6938 - mean_output_loss: 1302.1843 - variance_output_loss: 0.5094 - val_loss: 1241.9614 - val_mean_output_loss: 1239.7075 - val_variance_output_loss: 2.2537\n",
            "Epoch 49/5000\n",
            "2/2 [==============================] - 0s 74ms/step - loss: 1299.9028 - mean_output_loss: 1299.0891 - variance_output_loss: 0.8136 - val_loss: 1238.9269 - val_mean_output_loss: 1236.7070 - val_variance_output_loss: 2.2200\n",
            "Epoch 50/5000\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 1297.5076 - mean_output_loss: 1296.0266 - variance_output_loss: 1.4809 - val_loss: 1235.9149 - val_mean_output_loss: 1233.7290 - val_variance_output_loss: 2.1859\n",
            "Epoch 51/5000\n",
            "2/2 [==============================] - 0s 66ms/step - loss: 1294.1381 - mean_output_loss: 1292.9708 - variance_output_loss: 1.1673 - val_loss: 1232.9248 - val_mean_output_loss: 1230.7733 - val_variance_output_loss: 2.1515\n",
            "Epoch 52/5000\n",
            "2/2 [==============================] - 0s 80ms/step - loss: 1291.9603 - mean_output_loss: 1289.9271 - variance_output_loss: 2.0332 - val_loss: 1229.9546 - val_mean_output_loss: 1227.8378 - val_variance_output_loss: 2.1168\n",
            "Epoch 53/5000\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 1287.6304 - mean_output_loss: 1286.9288 - variance_output_loss: 0.7016 - val_loss: 1226.9990 - val_mean_output_loss: 1224.9172 - val_variance_output_loss: 2.0818\n",
            "Epoch 54/5000\n",
            "2/2 [==============================] - 0s 66ms/step - loss: 1285.8264 - mean_output_loss: 1283.9401 - variance_output_loss: 1.8863 - val_loss: 1224.0585 - val_mean_output_loss: 1222.0120 - val_variance_output_loss: 2.0465\n",
            "Epoch 55/5000\n",
            "2/2 [==============================] - 0s 73ms/step - loss: 1282.9041 - mean_output_loss: 1280.9523 - variance_output_loss: 1.9519 - val_loss: 1221.1335 - val_mean_output_loss: 1219.1226 - val_variance_output_loss: 2.0110\n",
            "Epoch 56/5000\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 1278.5851 - mean_output_loss: 1278.0002 - variance_output_loss: 0.5848 - val_loss: 1218.2198 - val_mean_output_loss: 1216.2448 - val_variance_output_loss: 1.9751\n",
            "Epoch 57/5000\n",
            "2/2 [==============================] - 0s 90ms/step - loss: 1277.2300 - mean_output_loss: 1275.0627 - variance_output_loss: 2.1672 - val_loss: 1215.3179 - val_mean_output_loss: 1213.3788 - val_variance_output_loss: 1.9391\n",
            "Epoch 58/5000\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 1274.5480 - mean_output_loss: 1272.1294 - variance_output_loss: 2.4187 - val_loss: 1212.4283 - val_mean_output_loss: 1210.5255 - val_variance_output_loss: 1.9028\n",
            "Epoch 59/5000\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 1270.1259 - mean_output_loss: 1269.2070 - variance_output_loss: 0.9187 - val_loss: 1209.5513 - val_mean_output_loss: 1207.6849 - val_variance_output_loss: 1.8663\n",
            "Epoch 60/5000\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 1266.0669 - mean_output_loss: 1266.2990 - variance_output_loss: -0.2321 - val_loss: 1206.6853 - val_mean_output_loss: 1204.8557 - val_variance_output_loss: 1.8296\n",
            "Epoch 61/5000\n",
            "2/2 [==============================] - 0s 66ms/step - loss: 1264.1157 - mean_output_loss: 1263.3967 - variance_output_loss: 0.7191 - val_loss: 1203.8308 - val_mean_output_loss: 1202.0382 - val_variance_output_loss: 1.7926\n",
            "Epoch 62/5000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 1261.0250 - mean_output_loss: 1260.5179 - variance_output_loss: 0.5071 - val_loss: 1200.9857 - val_mean_output_loss: 1199.2302 - val_variance_output_loss: 1.7555\n",
            "Epoch 63/5000\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 1257.9919 - mean_output_loss: 1257.6473 - variance_output_loss: 0.3448 - val_loss: 1198.1505 - val_mean_output_loss: 1196.4323 - val_variance_output_loss: 1.7183\n",
            "Epoch 64/5000\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 1256.3920 - mean_output_loss: 1254.7805 - variance_output_loss: 1.6115 - val_loss: 1195.3259 - val_mean_output_loss: 1193.6451 - val_variance_output_loss: 1.6808\n",
            "Epoch 65/5000\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 1253.4432 - mean_output_loss: 1251.9237 - variance_output_loss: 1.5196 - val_loss: 1192.5115 - val_mean_output_loss: 1190.8682 - val_variance_output_loss: 1.6433\n",
            "Epoch 66/5000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 1250.4333 - mean_output_loss: 1249.0718 - variance_output_loss: 1.3616 - val_loss: 1189.7074 - val_mean_output_loss: 1188.1018 - val_variance_output_loss: 1.6056\n",
            "Epoch 67/5000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 1247.5054 - mean_output_loss: 1246.2567 - variance_output_loss: 1.2487 - val_loss: 1186.9098 - val_mean_output_loss: 1185.3420 - val_variance_output_loss: 1.5677\n",
            "Epoch 68/5000\n",
            "2/2 [==============================] - 0s 67ms/step - loss: 1243.5933 - mean_output_loss: 1243.4299 - variance_output_loss: 0.1634 - val_loss: 1184.1224 - val_mean_output_loss: 1182.5927 - val_variance_output_loss: 1.5298\n",
            "Epoch 69/5000\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 1242.1836 - mean_output_loss: 1240.6233 - variance_output_loss: 1.5603 - val_loss: 1181.3439 - val_mean_output_loss: 1179.8522 - val_variance_output_loss: 1.4917\n",
            "Epoch 70/5000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 1238.3843 - mean_output_loss: 1237.8169 - variance_output_loss: 0.5675 - val_loss: 1178.5762 - val_mean_output_loss: 1177.1226 - val_variance_output_loss: 1.4536\n",
            "Epoch 71/5000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 1234.7920 - mean_output_loss: 1235.0280 - variance_output_loss: -0.2360 - val_loss: 1175.8180 - val_mean_output_loss: 1174.4026 - val_variance_output_loss: 1.4154\n",
            "Epoch 72/5000\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 1233.8409 - mean_output_loss: 1232.2310 - variance_output_loss: 1.6101 - val_loss: 1173.0717 - val_mean_output_loss: 1171.6946 - val_variance_output_loss: 1.3771\n",
            "Epoch 73/5000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 1231.3313 - mean_output_loss: 1229.4731 - variance_output_loss: 1.8583 - val_loss: 1170.3326 - val_mean_output_loss: 1168.9939 - val_variance_output_loss: 1.3388\n",
            "Epoch 74/5000\n",
            "2/2 [==============================] - 0s 68ms/step - loss: 1226.3467 - mean_output_loss: 1226.7065 - variance_output_loss: -0.3599 - val_loss: 1167.6044 - val_mean_output_loss: 1166.3040 - val_variance_output_loss: 1.3004\n",
            "Epoch 75/5000\n",
            "2/2 [==============================] - 0s 69ms/step - loss: 1224.2493 - mean_output_loss: 1223.9565 - variance_output_loss: 0.2927 - val_loss: 1164.8861 - val_mean_output_loss: 1163.6241 - val_variance_output_loss: 1.2620\n",
            "Epoch 76/5000\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 1222.8687 - mean_output_loss: 1221.2148 - variance_output_loss: 1.6539 - val_loss: 1162.1781 - val_mean_output_loss: 1160.9546 - val_variance_output_loss: 1.2236\n",
            "Epoch 77/5000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 1216.7880 - mean_output_loss: 1218.4728 - variance_output_loss: -1.6849 - val_loss: 1159.4818 - val_mean_output_loss: 1158.2966 - val_variance_output_loss: 1.1851\n",
            "Epoch 78/5000\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 1216.3573 - mean_output_loss: 1215.7697 - variance_output_loss: 0.5878 - val_loss: 1156.7930 - val_mean_output_loss: 1155.6462 - val_variance_output_loss: 1.1467\n",
            "Epoch 79/5000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 1214.3436 - mean_output_loss: 1213.0529 - variance_output_loss: 1.2909 - val_loss: 1154.1161 - val_mean_output_loss: 1153.0078 - val_variance_output_loss: 1.1082\n",
            "Epoch 80/5000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 1209.9469 - mean_output_loss: 1210.3625 - variance_output_loss: -0.4157 - val_loss: 1151.4489 - val_mean_output_loss: 1150.3790 - val_variance_output_loss: 1.0698\n",
            "Epoch 81/5000\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 1208.3688 - mean_output_loss: 1207.6611 - variance_output_loss: 0.7075 - val_loss: 1148.7946 - val_mean_output_loss: 1147.7632 - val_variance_output_loss: 1.0314\n",
            "Epoch 82/5000\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 1204.8307 - mean_output_loss: 1204.9923 - variance_output_loss: -0.1617 - val_loss: 1146.1500 - val_mean_output_loss: 1145.1570 - val_variance_output_loss: 0.9930\n",
            "Epoch 83/5000\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 1202.0392 - mean_output_loss: 1202.3306 - variance_output_loss: -0.2914 - val_loss: 1143.5162 - val_mean_output_loss: 1142.5615 - val_variance_output_loss: 0.9547\n",
            "Epoch 84/5000\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 1199.1923 - mean_output_loss: 1199.6691 - variance_output_loss: -0.4769 - val_loss: 1140.8947 - val_mean_output_loss: 1139.9783 - val_variance_output_loss: 0.9164\n",
            "Epoch 85/5000\n",
            "2/2 [==============================] - 0s 66ms/step - loss: 1197.5883 - mean_output_loss: 1197.0365 - variance_output_loss: 0.5518 - val_loss: 1138.2831 - val_mean_output_loss: 1137.4049 - val_variance_output_loss: 0.8781\n",
            "Epoch 86/5000\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 1192.8865 - mean_output_loss: 1194.3928 - variance_output_loss: -1.5064 - val_loss: 1135.6849 - val_mean_output_loss: 1134.8450 - val_variance_output_loss: 0.8399\n",
            "Epoch 87/5000\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 1190.8483 - mean_output_loss: 1191.7806 - variance_output_loss: -0.9323 - val_loss: 1133.0968 - val_mean_output_loss: 1132.2950 - val_variance_output_loss: 0.8018\n",
            "Epoch 88/5000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 1189.5011 - mean_output_loss: 1189.1787 - variance_output_loss: 0.3224 - val_loss: 1130.5197 - val_mean_output_loss: 1129.7560 - val_variance_output_loss: 0.7637\n",
            "Epoch 89/5000\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 1187.5702 - mean_output_loss: 1186.5771 - variance_output_loss: 0.9931 - val_loss: 1127.9553 - val_mean_output_loss: 1127.2296 - val_variance_output_loss: 0.7257\n",
            "Epoch 90/5000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 1182.6757 - mean_output_loss: 1183.9885 - variance_output_loss: -1.3129 - val_loss: 1125.4032 - val_mean_output_loss: 1124.7155 - val_variance_output_loss: 0.6878\n",
            "Epoch 91/5000\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 1180.6351 - mean_output_loss: 1181.4224 - variance_output_loss: -0.7872 - val_loss: 1122.8618 - val_mean_output_loss: 1122.2119 - val_variance_output_loss: 0.6499\n",
            "Epoch 92/5000\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 1179.3247 - mean_output_loss: 1178.8599 - variance_output_loss: 0.4649 - val_loss: 1120.3325 - val_mean_output_loss: 1119.7203 - val_variance_output_loss: 0.6122\n",
            "Epoch 93/5000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 1177.0553 - mean_output_loss: 1176.3054 - variance_output_loss: 0.7499 - val_loss: 1117.8157 - val_mean_output_loss: 1117.2412 - val_variance_output_loss: 0.5745\n",
            "Epoch 94/5000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 1173.8721 - mean_output_loss: 1173.7808 - variance_output_loss: 0.0914 - val_loss: 1115.3086 - val_mean_output_loss: 1114.7717 - val_variance_output_loss: 0.5369\n",
            "Epoch 95/5000\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 1170.5088 - mean_output_loss: 1171.2527 - variance_output_loss: -0.7439 - val_loss: 1112.8142 - val_mean_output_loss: 1112.3148 - val_variance_output_loss: 0.4994\n",
            "Epoch 96/5000\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 1169.1675 - mean_output_loss: 1168.7330 - variance_output_loss: 0.4345 - val_loss: 1110.3326 - val_mean_output_loss: 1109.8706 - val_variance_output_loss: 0.4620\n",
            "Epoch 97/5000\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 1166.2902 - mean_output_loss: 1166.2440 - variance_output_loss: 0.0462 - val_loss: 1107.8608 - val_mean_output_loss: 1107.4362 - val_variance_output_loss: 0.4247\n",
            "Epoch 98/5000\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 1164.0153 - mean_output_loss: 1163.7433 - variance_output_loss: 0.2720 - val_loss: 1105.4030 - val_mean_output_loss: 1105.0155 - val_variance_output_loss: 0.3875\n",
            "Epoch 99/5000\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 1161.8622 - mean_output_loss: 1161.2677 - variance_output_loss: 0.5944 - val_loss: 1102.9559 - val_mean_output_loss: 1102.6056 - val_variance_output_loss: 0.3504\n",
            "Epoch 100/5000\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 1158.1685 - mean_output_loss: 1158.8048 - variance_output_loss: -0.6363 - val_loss: 1100.5201 - val_mean_output_loss: 1100.2068 - val_variance_output_loss: 0.3133\n",
            "Epoch 101/5000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 1155.8407 - mean_output_loss: 1156.3534 - variance_output_loss: -0.5128 - val_loss: 1098.0952 - val_mean_output_loss: 1097.8188 - val_variance_output_loss: 0.2764\n",
            "Epoch 102/5000\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 1154.2013 - mean_output_loss: 1153.9098 - variance_output_loss: 0.2915 - val_loss: 1095.6820 - val_mean_output_loss: 1095.4424 - val_variance_output_loss: 0.2396\n",
            "Epoch 103/5000\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 1152.3541 - mean_output_loss: 1151.4722 - variance_output_loss: 0.8819 - val_loss: 1093.2805 - val_mean_output_loss: 1093.0776 - val_variance_output_loss: 0.2029\n",
            "Epoch 104/5000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 1148.6864 - mean_output_loss: 1149.0516 - variance_output_loss: -0.3652 - val_loss: 1090.8892 - val_mean_output_loss: 1090.7229 - val_variance_output_loss: 0.1662\n",
            "Epoch 105/5000\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 1146.5183 - mean_output_loss: 1146.6447 - variance_output_loss: -0.1263 - val_loss: 1088.5065 - val_mean_output_loss: 1088.3767 - val_variance_output_loss: 0.1297\n",
            "Epoch 106/5000\n",
            "2/2 [==============================] - 0s 70ms/step - loss: 1142.7137 - mean_output_loss: 1144.2443 - variance_output_loss: -1.5304 - val_loss: 1086.1317 - val_mean_output_loss: 1086.0385 - val_variance_output_loss: 0.0933\n",
            "Epoch 107/5000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 1141.3345 - mean_output_loss: 1141.8422 - variance_output_loss: -0.5077 - val_loss: 1083.7637 - val_mean_output_loss: 1083.7068 - val_variance_output_loss: 0.0569\n",
            "Epoch 108/5000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 1139.1979 - mean_output_loss: 1139.4576 - variance_output_loss: -0.2597 - val_loss: 1081.3958 - val_mean_output_loss: 1081.3752 - val_variance_output_loss: 0.0206\n",
            "Epoch 109/5000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 1135.4845 - mean_output_loss: 1137.0448 - variance_output_loss: -1.5603 - val_loss: 1079.0251 - val_mean_output_loss: 1079.0409 - val_variance_output_loss: -0.0158\n",
            "Epoch 110/5000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 1133.4338 - mean_output_loss: 1134.6310 - variance_output_loss: -1.1971 - val_loss: 1076.6345 - val_mean_output_loss: 1076.6866 - val_variance_output_loss: -0.0522\n",
            "Epoch 111/5000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 1130.6239 - mean_output_loss: 1132.1630 - variance_output_loss: -1.5391 - val_loss: 1074.2047 - val_mean_output_loss: 1074.2936 - val_variance_output_loss: -0.0888\n",
            "Epoch 112/5000\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 1128.5865 - mean_output_loss: 1129.6387 - variance_output_loss: -1.0522 - val_loss: 1071.6969 - val_mean_output_loss: 1071.8229 - val_variance_output_loss: -0.1260\n",
            "Epoch 113/5000\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 1126.5452 - mean_output_loss: 1127.0063 - variance_output_loss: -0.4613 - val_loss: 1069.0669 - val_mean_output_loss: 1069.2312 - val_variance_output_loss: -0.1643\n",
            "Epoch 114/5000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 1122.9919 - mean_output_loss: 1124.2443 - variance_output_loss: -1.2523 - val_loss: 1066.2588 - val_mean_output_loss: 1066.4635 - val_variance_output_loss: -0.2048\n",
            "Epoch 115/5000\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 1120.2395 - mean_output_loss: 1121.3234 - variance_output_loss: -1.0838 - val_loss: 1063.2446 - val_mean_output_loss: 1063.4932 - val_variance_output_loss: -0.2485\n",
            "Epoch 116/5000\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 1116.3605 - mean_output_loss: 1118.2518 - variance_output_loss: -1.8913 - val_loss: 1060.0469 - val_mean_output_loss: 1060.3433 - val_variance_output_loss: -0.2964\n",
            "Epoch 117/5000\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 1114.1815 - mean_output_loss: 1115.0562 - variance_output_loss: -0.8746 - val_loss: 1056.7546 - val_mean_output_loss: 1057.1021 - val_variance_output_loss: -0.3474\n",
            "Epoch 118/5000\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 1109.6387 - mean_output_loss: 1111.8306 - variance_output_loss: -2.1919 - val_loss: 1053.4902 - val_mean_output_loss: 1053.8884 - val_variance_output_loss: -0.3982\n",
            "Epoch 119/5000\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 1108.4716 - mean_output_loss: 1108.6581 - variance_output_loss: -0.1866 - val_loss: 1050.3597 - val_mean_output_loss: 1050.8055 - val_variance_output_loss: -0.4458\n",
            "Epoch 120/5000\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 1103.7529 - mean_output_loss: 1105.6229 - variance_output_loss: -1.8700 - val_loss: 1047.4161 - val_mean_output_loss: 1047.9056 - val_variance_output_loss: -0.4895\n",
            "Epoch 121/5000\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 1102.0964 - mean_output_loss: 1102.7228 - variance_output_loss: -0.6262 - val_loss: 1044.6577 - val_mean_output_loss: 1045.1879 - val_variance_output_loss: -0.5301\n",
            "Epoch 122/5000\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 1098.9540 - mean_output_loss: 1099.9670 - variance_output_loss: -1.0131 - val_loss: 1042.0483 - val_mean_output_loss: 1042.6172 - val_variance_output_loss: -0.5688\n",
            "Epoch 123/5000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 1096.6753 - mean_output_loss: 1097.3693 - variance_output_loss: -0.6940 - val_loss: 1039.5444 - val_mean_output_loss: 1040.1510 - val_variance_output_loss: -0.6065\n",
            "Epoch 124/5000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 1093.7863 - mean_output_loss: 1094.8627 - variance_output_loss: -1.0763 - val_loss: 1037.1162 - val_mean_output_loss: 1037.7599 - val_variance_output_loss: -0.6436\n",
            "Epoch 125/5000\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 1091.2430 - mean_output_loss: 1092.4171 - variance_output_loss: -1.1740 - val_loss: 1034.7438 - val_mean_output_loss: 1035.4241 - val_variance_output_loss: -0.6803\n",
            "Epoch 126/5000\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 1087.6606 - mean_output_loss: 1090.0178 - variance_output_loss: -2.3572 - val_loss: 1032.4130 - val_mean_output_loss: 1033.1298 - val_variance_output_loss: -0.7168\n",
            "Epoch 127/5000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 1084.4968 - mean_output_loss: 1087.6884 - variance_output_loss: -3.1917 - val_loss: 1030.1110 - val_mean_output_loss: 1030.8640 - val_variance_output_loss: -0.7531\n",
            "Epoch 128/5000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 1083.5848 - mean_output_loss: 1085.3635 - variance_output_loss: -1.7788 - val_loss: 1027.8352 - val_mean_output_loss: 1028.6244 - val_variance_output_loss: -0.7892\n",
            "Epoch 129/5000\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 1081.2791 - mean_output_loss: 1083.0765 - variance_output_loss: -1.7975 - val_loss: 1025.5796 - val_mean_output_loss: 1026.4048 - val_variance_output_loss: -0.8252\n",
            "Epoch 130/5000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 1078.7126 - mean_output_loss: 1080.7982 - variance_output_loss: -2.0856 - val_loss: 1023.3428 - val_mean_output_loss: 1024.2040 - val_variance_output_loss: -0.8611\n",
            "Epoch 131/5000\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 1077.3076 - mean_output_loss: 1078.5577 - variance_output_loss: -1.2501 - val_loss: 1021.1204 - val_mean_output_loss: 1022.0173 - val_variance_output_loss: -0.8970\n",
            "Epoch 132/5000\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 1074.6892 - mean_output_loss: 1076.3140 - variance_output_loss: -1.6247 - val_loss: 1018.9138 - val_mean_output_loss: 1019.8465 - val_variance_output_loss: -0.9327\n",
            "Epoch 133/5000\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 1073.1875 - mean_output_loss: 1074.0939 - variance_output_loss: -0.9063 - val_loss: 1016.7202 - val_mean_output_loss: 1017.6885 - val_variance_output_loss: -0.9685\n",
            "Epoch 134/5000\n",
            "2/2 [==============================] - 0s 70ms/step - loss: 1071.2029 - mean_output_loss: 1071.8860 - variance_output_loss: -0.6831 - val_loss: 1014.5383 - val_mean_output_loss: 1015.5424 - val_variance_output_loss: -1.0041\n",
            "Epoch 135/5000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 1067.1315 - mean_output_loss: 1069.6844 - variance_output_loss: -2.5530 - val_loss: 1012.3681 - val_mean_output_loss: 1013.4079 - val_variance_output_loss: -1.0398\n",
            "Epoch 136/5000\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 1065.7170 - mean_output_loss: 1067.5116 - variance_output_loss: -1.7945 - val_loss: 1010.2062 - val_mean_output_loss: 1011.2817 - val_variance_output_loss: -1.0754\n",
            "Epoch 137/5000\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 1063.3500 - mean_output_loss: 1065.3236 - variance_output_loss: -1.9736 - val_loss: 1008.0558 - val_mean_output_loss: 1009.1668 - val_variance_output_loss: -1.1110\n",
            "Epoch 138/5000\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 1061.6124 - mean_output_loss: 1063.1539 - variance_output_loss: -1.5415 - val_loss: 1005.9136 - val_mean_output_loss: 1007.0602 - val_variance_output_loss: -1.1466\n",
            "Epoch 139/5000\n",
            "2/2 [==============================] - 0s 67ms/step - loss: 1058.4565 - mean_output_loss: 1061.0042 - variance_output_loss: -2.5475 - val_loss: 1003.7774 - val_mean_output_loss: 1004.9597 - val_variance_output_loss: -1.1823\n",
            "Epoch 140/5000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 1056.3126 - mean_output_loss: 1058.8492 - variance_output_loss: -2.5367 - val_loss: 1001.6485 - val_mean_output_loss: 1002.8664 - val_variance_output_loss: -1.2179\n",
            "Epoch 141/5000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 1055.5604 - mean_output_loss: 1056.7056 - variance_output_loss: -1.1452 - val_loss: 999.5255 - val_mean_output_loss: 1000.7791 - val_variance_output_loss: -1.2535\n",
            "Epoch 142/5000\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 1052.0338 - mean_output_loss: 1054.5673 - variance_output_loss: -2.5334 - val_loss: 997.4077 - val_mean_output_loss: 998.6970 - val_variance_output_loss: -1.2892\n",
            "Epoch 143/5000\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 1050.8180 - mean_output_loss: 1052.4429 - variance_output_loss: -1.6249 - val_loss: 995.2934 - val_mean_output_loss: 996.6184 - val_variance_output_loss: -1.3250\n",
            "Epoch 144/5000\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 1047.8976 - mean_output_loss: 1050.3051 - variance_output_loss: -2.4075 - val_loss: 993.1851 - val_mean_output_loss: 994.5458 - val_variance_output_loss: -1.3608\n",
            "Epoch 145/5000\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 1045.2203 - mean_output_loss: 1048.1841 - variance_output_loss: -2.9637 - val_loss: 991.0795 - val_mean_output_loss: 992.4761 - val_variance_output_loss: -1.3966\n",
            "Epoch 146/5000\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 1043.7839 - mean_output_loss: 1046.0634 - variance_output_loss: -2.2794 - val_loss: 988.9771 - val_mean_output_loss: 990.4096 - val_variance_output_loss: -1.4326\n",
            "Epoch 147/5000\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 1041.5814 - mean_output_loss: 1043.9515 - variance_output_loss: -2.3700 - val_loss: 986.8760 - val_mean_output_loss: 988.3446 - val_variance_output_loss: -1.4686\n",
            "Epoch 148/5000\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 1038.8207 - mean_output_loss: 1041.8259 - variance_output_loss: -3.0053 - val_loss: 984.7786 - val_mean_output_loss: 986.2833 - val_variance_output_loss: -1.5046\n",
            "Epoch 149/5000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 1036.2852 - mean_output_loss: 1039.7144 - variance_output_loss: -3.4293 - val_loss: 982.6819 - val_mean_output_loss: 984.2228 - val_variance_output_loss: -1.5408\n",
            "Epoch 150/5000\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 1034.9410 - mean_output_loss: 1037.6001 - variance_output_loss: -2.6591 - val_loss: 980.5862 - val_mean_output_loss: 982.1632 - val_variance_output_loss: -1.5771\n",
            "Epoch 151/5000\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 1033.8021 - mean_output_loss: 1035.4955 - variance_output_loss: -1.6934 - val_loss: 978.4894 - val_mean_output_loss: 980.1028 - val_variance_output_loss: -1.6134\n",
            "Epoch 152/5000\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 1030.3752 - mean_output_loss: 1033.3751 - variance_output_loss: -2.9999 - val_loss: 976.3938 - val_mean_output_loss: 978.0437 - val_variance_output_loss: -1.6499\n",
            "Epoch 153/5000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 1028.4386 - mean_output_loss: 1031.2626 - variance_output_loss: -2.8239 - val_loss: 974.2972 - val_mean_output_loss: 975.9837 - val_variance_output_loss: -1.6864\n",
            "Epoch 154/5000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 1026.6685 - mean_output_loss: 1029.1613 - variance_output_loss: -2.4928 - val_loss: 972.1981 - val_mean_output_loss: 973.9212 - val_variance_output_loss: -1.7231\n",
            "Epoch 155/5000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 1023.1950 - mean_output_loss: 1027.0463 - variance_output_loss: -3.8514 - val_loss: 970.0982 - val_mean_output_loss: 971.8582 - val_variance_output_loss: -1.7599\n",
            "Epoch 156/5000\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 1022.6852 - mean_output_loss: 1024.9181 - variance_output_loss: -2.2329 - val_loss: 967.9992 - val_mean_output_loss: 969.7960 - val_variance_output_loss: -1.7968\n",
            "Epoch 157/5000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 1020.5851 - mean_output_loss: 1022.8035 - variance_output_loss: -2.2184 - val_loss: 965.8972 - val_mean_output_loss: 967.7310 - val_variance_output_loss: -1.8339\n",
            "Epoch 158/5000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 1017.0657 - mean_output_loss: 1020.6982 - variance_output_loss: -3.6324 - val_loss: 963.7908 - val_mean_output_loss: 965.6619 - val_variance_output_loss: -1.8710\n",
            "Epoch 159/5000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 1017.0357 - mean_output_loss: 1018.5727 - variance_output_loss: -1.5370 - val_loss: 961.6837 - val_mean_output_loss: 963.5919 - val_variance_output_loss: -1.9083\n",
            "Epoch 160/5000\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 1013.1334 - mean_output_loss: 1016.4520 - variance_output_loss: -3.3185 - val_loss: 959.5738 - val_mean_output_loss: 961.5195 - val_variance_output_loss: -1.9457\n",
            "Epoch 161/5000\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 1011.5282 - mean_output_loss: 1014.3188 - variance_output_loss: -2.7905 - val_loss: 957.4629 - val_mean_output_loss: 959.4460 - val_variance_output_loss: -1.9832\n",
            "Epoch 162/5000\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 1010.1276 - mean_output_loss: 1012.1984 - variance_output_loss: -2.0708 - val_loss: 955.3481 - val_mean_output_loss: 957.3689 - val_variance_output_loss: -2.0208\n",
            "Epoch 163/5000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 1007.2143 - mean_output_loss: 1010.0613 - variance_output_loss: -2.8471 - val_loss: 953.2316 - val_mean_output_loss: 955.2902 - val_variance_output_loss: -2.0585\n",
            "Epoch 164/5000\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 1005.3339 - mean_output_loss: 1007.9426 - variance_output_loss: -2.6087 - val_loss: 951.1106 - val_mean_output_loss: 953.2070 - val_variance_output_loss: -2.0964\n",
            "Epoch 165/5000\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 1003.0737 - mean_output_loss: 1005.7972 - variance_output_loss: -2.7235 - val_loss: 948.9888 - val_mean_output_loss: 951.1232 - val_variance_output_loss: -2.1344\n",
            "Epoch 166/5000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 1000.2935 - mean_output_loss: 1003.6541 - variance_output_loss: -3.3606 - val_loss: 946.8650 - val_mean_output_loss: 949.0375 - val_variance_output_loss: -2.1724\n",
            "Epoch 167/5000\n",
            "2/2 [==============================] - 0s 67ms/step - loss: 997.3907 - mean_output_loss: 1001.5201 - variance_output_loss: -4.1294 - val_loss: 944.7375 - val_mean_output_loss: 946.9481 - val_variance_output_loss: -2.2106\n",
            "Epoch 168/5000\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 995.9443 - mean_output_loss: 999.3752 - variance_output_loss: -3.4309 - val_loss: 942.6077 - val_mean_output_loss: 944.8565 - val_variance_output_loss: -2.2488\n",
            "Epoch 169/5000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 994.5904 - mean_output_loss: 997.2403 - variance_output_loss: -2.6498 - val_loss: 940.4744 - val_mean_output_loss: 942.7615 - val_variance_output_loss: -2.2871\n",
            "Epoch 170/5000\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 992.0832 - mean_output_loss: 995.0878 - variance_output_loss: -3.0045 - val_loss: 938.3403 - val_mean_output_loss: 940.6659 - val_variance_output_loss: -2.3255\n",
            "Epoch 171/5000\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 990.0743 - mean_output_loss: 992.9271 - variance_output_loss: -2.8527 - val_loss: 936.2063 - val_mean_output_loss: 938.5703 - val_variance_output_loss: -2.3640\n",
            "Epoch 172/5000\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 987.2374 - mean_output_loss: 990.7831 - variance_output_loss: -3.5456 - val_loss: 934.0689 - val_mean_output_loss: 936.4714 - val_variance_output_loss: -2.4026\n",
            "Epoch 173/5000\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 985.0406 - mean_output_loss: 988.6237 - variance_output_loss: -3.5830 - val_loss: 931.9307 - val_mean_output_loss: 934.3718 - val_variance_output_loss: -2.4412\n",
            "Epoch 174/5000\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 981.9894 - mean_output_loss: 986.4764 - variance_output_loss: -4.4869 - val_loss: 929.7898 - val_mean_output_loss: 932.2696 - val_variance_output_loss: -2.4798\n",
            "Epoch 175/5000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 981.1085 - mean_output_loss: 984.3192 - variance_output_loss: -3.2106 - val_loss: 927.6482 - val_mean_output_loss: 930.1667 - val_variance_output_loss: -2.5185\n",
            "Epoch 176/5000\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 978.5967 - mean_output_loss: 982.1627 - variance_output_loss: -3.5660 - val_loss: 925.5056 - val_mean_output_loss: 928.0629 - val_variance_output_loss: -2.5572\n",
            "Epoch 177/5000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 977.1536 - mean_output_loss: 980.0031 - variance_output_loss: -2.8495 - val_loss: 923.3633 - val_mean_output_loss: 925.9593 - val_variance_output_loss: -2.5960\n",
            "Epoch 178/5000\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 974.0063 - mean_output_loss: 977.8446 - variance_output_loss: -3.8383 - val_loss: 921.2204 - val_mean_output_loss: 923.8552 - val_variance_output_loss: -2.6348\n",
            "Epoch 179/5000\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 973.0897 - mean_output_loss: 975.6874 - variance_output_loss: -2.5976 - val_loss: 919.0775 - val_mean_output_loss: 921.7510 - val_variance_output_loss: -2.6736\n",
            "Epoch 180/5000\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 969.7538 - mean_output_loss: 973.5350 - variance_output_loss: -3.7813 - val_loss: 916.9341 - val_mean_output_loss: 919.6465 - val_variance_output_loss: -2.7124\n",
            "Epoch 181/5000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 967.5113 - mean_output_loss: 971.3741 - variance_output_loss: -3.8628 - val_loss: 914.7925 - val_mean_output_loss: 917.5436 - val_variance_output_loss: -2.7512\n",
            "Epoch 182/5000\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 965.6195 - mean_output_loss: 969.2131 - variance_output_loss: -3.5936 - val_loss: 912.6522 - val_mean_output_loss: 915.4422 - val_variance_output_loss: -2.7900\n",
            "Epoch 183/5000\n",
            "2/2 [==============================] - 0s 78ms/step - loss: 962.5128 - mean_output_loss: 967.0622 - variance_output_loss: -4.5496 - val_loss: 910.5125 - val_mean_output_loss: 913.3412 - val_variance_output_loss: -2.8288\n",
            "Epoch 184/5000\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 961.8262 - mean_output_loss: 964.8977 - variance_output_loss: -3.0715 - val_loss: 908.3754 - val_mean_output_loss: 911.2429 - val_variance_output_loss: -2.8675\n",
            "Epoch 185/5000\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 958.7571 - mean_output_loss: 962.7471 - variance_output_loss: -3.9899 - val_loss: 906.2387 - val_mean_output_loss: 909.1450 - val_variance_output_loss: -2.9063\n",
            "Epoch 186/5000\n",
            "2/2 [==============================] - 0s 67ms/step - loss: 956.2719 - mean_output_loss: 960.5944 - variance_output_loss: -4.3226 - val_loss: 904.1036 - val_mean_output_loss: 907.0486 - val_variance_output_loss: -2.9450\n",
            "Epoch 187/5000\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 954.5427 - mean_output_loss: 958.4420 - variance_output_loss: -3.8993 - val_loss: 901.9702 - val_mean_output_loss: 904.9539 - val_variance_output_loss: -2.9837\n",
            "Epoch 188/5000\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 951.4904 - mean_output_loss: 956.2875 - variance_output_loss: -4.7971 - val_loss: 899.8388 - val_mean_output_loss: 902.8613 - val_variance_output_loss: -3.0224\n",
            "Epoch 189/5000\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 950.0836 - mean_output_loss: 954.1473 - variance_output_loss: -4.0637 - val_loss: 897.7079 - val_mean_output_loss: 900.7690 - val_variance_output_loss: -3.0611\n",
            "Epoch 190/5000\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 948.1596 - mean_output_loss: 951.9984 - variance_output_loss: -3.8387 - val_loss: 895.5797 - val_mean_output_loss: 898.6794 - val_variance_output_loss: -3.0997\n",
            "Epoch 191/5000\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 944.9234 - mean_output_loss: 949.8533 - variance_output_loss: -4.9300 - val_loss: 893.4536 - val_mean_output_loss: 896.5918 - val_variance_output_loss: -3.1383\n",
            "Epoch 192/5000\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 943.7165 - mean_output_loss: 947.7171 - variance_output_loss: -4.0005 - val_loss: 891.3290 - val_mean_output_loss: 894.5058 - val_variance_output_loss: -3.1768\n",
            "Epoch 193/5000\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 942.1434 - mean_output_loss: 945.5797 - variance_output_loss: -3.4363 - val_loss: 889.2070 - val_mean_output_loss: 892.4223 - val_variance_output_loss: -3.2153\n",
            "Epoch 194/5000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 939.8426 - mean_output_loss: 943.4307 - variance_output_loss: -3.5882 - val_loss: 887.0894 - val_mean_output_loss: 890.3432 - val_variance_output_loss: -3.2538\n",
            "Epoch 195/5000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 936.3766 - mean_output_loss: 941.3130 - variance_output_loss: -4.9364 - val_loss: 884.9719 - val_mean_output_loss: 888.2642 - val_variance_output_loss: -3.2922\n",
            "Epoch 196/5000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 934.2411 - mean_output_loss: 939.1775 - variance_output_loss: -4.9364 - val_loss: 882.8585 - val_mean_output_loss: 886.1891 - val_variance_output_loss: -3.3306\n",
            "Epoch 197/5000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 933.3643 - mean_output_loss: 937.0438 - variance_output_loss: -3.6795 - val_loss: 880.7491 - val_mean_output_loss: 884.1180 - val_variance_output_loss: -3.3690\n",
            "Epoch 198/5000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 929.8290 - mean_output_loss: 934.9227 - variance_output_loss: -5.0936 - val_loss: 878.6420 - val_mean_output_loss: 882.0493 - val_variance_output_loss: -3.4073\n",
            "Epoch 199/5000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 928.0552 - mean_output_loss: 932.7883 - variance_output_loss: -4.7331 - val_loss: 876.5393 - val_mean_output_loss: 879.9848 - val_variance_output_loss: -3.4455\n",
            "Epoch 200/5000\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 926.0497 - mean_output_loss: 930.6697 - variance_output_loss: -4.6200 - val_loss: 874.4385 - val_mean_output_loss: 877.9223 - val_variance_output_loss: -3.4838\n",
            "Epoch 201/5000\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 923.7442 - mean_output_loss: 928.5548 - variance_output_loss: -4.8106 - val_loss: 872.3396 - val_mean_output_loss: 875.8616 - val_variance_output_loss: -3.5220\n",
            "Epoch 202/5000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 921.3335 - mean_output_loss: 926.4371 - variance_output_loss: -5.1035 - val_loss: 870.2433 - val_mean_output_loss: 873.8035 - val_variance_output_loss: -3.5602\n",
            "Epoch 203/5000\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 919.7153 - mean_output_loss: 924.3253 - variance_output_loss: -4.6100 - val_loss: 868.1492 - val_mean_output_loss: 871.7476 - val_variance_output_loss: -3.5983\n",
            "Epoch 204/5000\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 918.4992 - mean_output_loss: 922.2188 - variance_output_loss: -3.7196 - val_loss: 866.0571 - val_mean_output_loss: 869.6936 - val_variance_output_loss: -3.6365\n",
            "Epoch 205/5000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 916.6675 - mean_output_loss: 920.1010 - variance_output_loss: -3.4335 - val_loss: 863.9691 - val_mean_output_loss: 867.6436 - val_variance_output_loss: -3.6746\n",
            "Epoch 206/5000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 915.4061 - mean_output_loss: 918.0050 - variance_output_loss: -2.5989 - val_loss: 861.8816 - val_mean_output_loss: 865.5942 - val_variance_output_loss: -3.7126\n",
            "Epoch 207/5000\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 911.2512 - mean_output_loss: 915.9089 - variance_output_loss: -4.6577 - val_loss: 859.7963 - val_mean_output_loss: 863.5470 - val_variance_output_loss: -3.7507\n",
            "Epoch 208/5000\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 910.9325 - mean_output_loss: 913.8054 - variance_output_loss: -2.8729 - val_loss: 857.7151 - val_mean_output_loss: 861.5039 - val_variance_output_loss: -3.7888\n",
            "Epoch 209/5000\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 907.7181 - mean_output_loss: 911.7034 - variance_output_loss: -3.9853 - val_loss: 855.6376 - val_mean_output_loss: 859.4644 - val_variance_output_loss: -3.8268\n",
            "Epoch 210/5000\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 905.0926 - mean_output_loss: 909.6146 - variance_output_loss: -4.5220 - val_loss: 853.5624 - val_mean_output_loss: 857.4272 - val_variance_output_loss: -3.8648\n",
            "Epoch 211/5000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 901.8638 - mean_output_loss: 907.5207 - variance_output_loss: -5.6568 - val_loss: 851.4910 - val_mean_output_loss: 855.3937 - val_variance_output_loss: -3.9028\n",
            "Epoch 212/5000\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 899.7126 - mean_output_loss: 905.4314 - variance_output_loss: -5.7188 - val_loss: 849.4224 - val_mean_output_loss: 853.3632 - val_variance_output_loss: -3.9408\n",
            "Epoch 213/5000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 899.2453 - mean_output_loss: 903.3504 - variance_output_loss: -4.1052 - val_loss: 847.3564 - val_mean_output_loss: 851.3351 - val_variance_output_loss: -3.9787\n",
            "Epoch 214/5000\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 897.3477 - mean_output_loss: 901.2720 - variance_output_loss: -3.9244 - val_loss: 845.2933 - val_mean_output_loss: 849.3101 - val_variance_output_loss: -4.0167\n",
            "Epoch 215/5000\n",
            "2/2 [==============================] - 0s 68ms/step - loss: 893.4764 - mean_output_loss: 899.1871 - variance_output_loss: -5.7106 - val_loss: 843.2347 - val_mean_output_loss: 847.2893 - val_variance_output_loss: -4.0547\n",
            "Epoch 216/5000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 892.6367 - mean_output_loss: 897.1074 - variance_output_loss: -4.4707 - val_loss: 841.1796 - val_mean_output_loss: 845.2722 - val_variance_output_loss: -4.0926\n",
            "Epoch 217/5000\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 890.3517 - mean_output_loss: 895.0392 - variance_output_loss: -4.6874 - val_loss: 839.1267 - val_mean_output_loss: 843.2573 - val_variance_output_loss: -4.1305\n",
            "Epoch 218/5000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 887.5932 - mean_output_loss: 892.9731 - variance_output_loss: -5.3798 - val_loss: 837.0767 - val_mean_output_loss: 841.2452 - val_variance_output_loss: -4.1685\n",
            "Epoch 219/5000\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 884.9637 - mean_output_loss: 890.9094 - variance_output_loss: -5.9457 - val_loss: 835.0301 - val_mean_output_loss: 839.2365 - val_variance_output_loss: -4.2064\n",
            "Epoch 220/5000\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 883.2166 - mean_output_loss: 888.8492 - variance_output_loss: -5.6327 - val_loss: 832.9871 - val_mean_output_loss: 837.2314 - val_variance_output_loss: -4.2443\n",
            "Epoch 221/5000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 880.9438 - mean_output_loss: 886.7859 - variance_output_loss: -5.8422 - val_loss: 830.9489 - val_mean_output_loss: 835.2310 - val_variance_output_loss: -4.2822\n",
            "Epoch 222/5000\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 878.5670 - mean_output_loss: 884.7337 - variance_output_loss: -6.1667 - val_loss: 828.9143 - val_mean_output_loss: 833.2343 - val_variance_output_loss: -4.3201\n",
            "Epoch 223/5000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 877.2324 - mean_output_loss: 882.6786 - variance_output_loss: -5.4462 - val_loss: 826.8839 - val_mean_output_loss: 831.2419 - val_variance_output_loss: -4.3580\n",
            "Epoch 224/5000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 875.0110 - mean_output_loss: 880.6335 - variance_output_loss: -5.6225 - val_loss: 824.8574 - val_mean_output_loss: 829.2532 - val_variance_output_loss: -4.3958\n",
            "Epoch 225/5000\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 873.0262 - mean_output_loss: 878.5948 - variance_output_loss: -5.5686 - val_loss: 822.8343 - val_mean_output_loss: 827.2680 - val_variance_output_loss: -4.4337\n",
            "Epoch 226/5000\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 870.6487 - mean_output_loss: 876.5502 - variance_output_loss: -5.9016 - val_loss: 820.8163 - val_mean_output_loss: 825.2879 - val_variance_output_loss: -4.4715\n",
            "Epoch 227/5000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 868.6022 - mean_output_loss: 874.5270 - variance_output_loss: -5.9248 - val_loss: 818.8011 - val_mean_output_loss: 823.3105 - val_variance_output_loss: -4.5094\n",
            "Epoch 228/5000\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 868.0010 - mean_output_loss: 872.4954 - variance_output_loss: -4.4944 - val_loss: 816.7913 - val_mean_output_loss: 821.3384 - val_variance_output_loss: -4.5472\n",
            "Epoch 229/5000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 864.4278 - mean_output_loss: 870.4684 - variance_output_loss: -6.0406 - val_loss: 814.7866 - val_mean_output_loss: 819.3716 - val_variance_output_loss: -4.5849\n",
            "Epoch 230/5000\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 861.4241 - mean_output_loss: 868.4504 - variance_output_loss: -7.0264 - val_loss: 812.7869 - val_mean_output_loss: 817.4096 - val_variance_output_loss: -4.6227\n",
            "Epoch 231/5000\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 861.7183 - mean_output_loss: 866.4312 - variance_output_loss: -4.7129 - val_loss: 810.7927 - val_mean_output_loss: 815.4532 - val_variance_output_loss: -4.6604\n",
            "Epoch 232/5000\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 859.5112 - mean_output_loss: 864.4138 - variance_output_loss: -4.9027 - val_loss: 808.8043 - val_mean_output_loss: 813.5024 - val_variance_output_loss: -4.6981\n",
            "Epoch 233/5000\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 857.0789 - mean_output_loss: 862.4263 - variance_output_loss: -5.3474 - val_loss: 806.8181 - val_mean_output_loss: 811.5539 - val_variance_output_loss: -4.7358\n",
            "Epoch 234/5000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 854.5670 - mean_output_loss: 860.4197 - variance_output_loss: -5.8528 - val_loss: 804.8386 - val_mean_output_loss: 809.6121 - val_variance_output_loss: -4.7735\n",
            "Epoch 235/5000\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 853.8020 - mean_output_loss: 858.4188 - variance_output_loss: -4.6168 - val_loss: 802.8652 - val_mean_output_loss: 807.6763 - val_variance_output_loss: -4.8111\n",
            "Epoch 236/5000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 849.2281 - mean_output_loss: 856.4355 - variance_output_loss: -7.2074 - val_loss: 800.8960 - val_mean_output_loss: 805.7447 - val_variance_output_loss: -4.8487\n",
            "Epoch 237/5000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 847.6872 - mean_output_loss: 854.4487 - variance_output_loss: -6.7614 - val_loss: 798.9328 - val_mean_output_loss: 803.8190 - val_variance_output_loss: -4.8862\n",
            "Epoch 238/5000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 846.6511 - mean_output_loss: 852.4731 - variance_output_loss: -5.8219 - val_loss: 796.9744 - val_mean_output_loss: 801.8981 - val_variance_output_loss: -4.9237\n",
            "Epoch 239/5000\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 844.1160 - mean_output_loss: 850.5081 - variance_output_loss: -6.3920 - val_loss: 795.0208 - val_mean_output_loss: 799.9819 - val_variance_output_loss: -4.9612\n",
            "Epoch 240/5000\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 843.4004 - mean_output_loss: 848.5289 - variance_output_loss: -5.1285 - val_loss: 793.0748 - val_mean_output_loss: 798.0735 - val_variance_output_loss: -4.9986\n",
            "Epoch 241/5000\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 841.0704 - mean_output_loss: 846.5716 - variance_output_loss: -5.5012 - val_loss: 791.1340 - val_mean_output_loss: 796.1700 - val_variance_output_loss: -5.0360\n",
            "Epoch 242/5000\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 837.0643 - mean_output_loss: 844.6156 - variance_output_loss: -7.5513 - val_loss: 789.1988 - val_mean_output_loss: 794.2722 - val_variance_output_loss: -5.0734\n",
            "Epoch 243/5000\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 836.4509 - mean_output_loss: 842.6632 - variance_output_loss: -6.2121 - val_loss: 787.2695 - val_mean_output_loss: 792.3802 - val_variance_output_loss: -5.1107\n",
            "Epoch 244/5000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 834.4238 - mean_output_loss: 840.7224 - variance_output_loss: -6.2985 - val_loss: 785.3455 - val_mean_output_loss: 790.4934 - val_variance_output_loss: -5.1479\n",
            "Epoch 245/5000\n",
            "2/2 [==============================] - 0s 81ms/step - loss: 832.9619 - mean_output_loss: 838.7871 - variance_output_loss: -5.8253 - val_loss: 783.4269 - val_mean_output_loss: 788.6121 - val_variance_output_loss: -5.1851\n",
            "Epoch 246/5000\n",
            "2/2 [==============================] - 0s 78ms/step - loss: 831.0656 - mean_output_loss: 836.8542 - variance_output_loss: -5.7887 - val_loss: 781.5145 - val_mean_output_loss: 786.7368 - val_variance_output_loss: -5.2223\n",
            "Epoch 247/5000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 828.9520 - mean_output_loss: 834.9239 - variance_output_loss: -5.9719 - val_loss: 779.6089 - val_mean_output_loss: 784.8683 - val_variance_output_loss: -5.2594\n",
            "Epoch 248/5000\n",
            "2/2 [==============================] - 0s 79ms/step - loss: 827.1200 - mean_output_loss: 833.0062 - variance_output_loss: -5.8862 - val_loss: 777.7086 - val_mean_output_loss: 783.0050 - val_variance_output_loss: -5.2964\n",
            "Epoch 249/5000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 824.8774 - mean_output_loss: 831.0988 - variance_output_loss: -6.2213 - val_loss: 775.8134 - val_mean_output_loss: 781.1469 - val_variance_output_loss: -5.3334\n",
            "Epoch 250/5000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 822.8284 - mean_output_loss: 829.1810 - variance_output_loss: -6.3525 - val_loss: 773.9260 - val_mean_output_loss: 779.2964 - val_variance_output_loss: -5.3704\n",
            "Epoch 251/5000\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 821.2310 - mean_output_loss: 827.2876 - variance_output_loss: -6.0566 - val_loss: 772.0432 - val_mean_output_loss: 777.4505 - val_variance_output_loss: -5.4073\n",
            "Epoch 252/5000\n",
            "2/2 [==============================] - 0s 69ms/step - loss: 819.7251 - mean_output_loss: 825.3793 - variance_output_loss: -5.6541 - val_loss: 770.1686 - val_mean_output_loss: 775.6127 - val_variance_output_loss: -5.4441\n",
            "Epoch 253/5000\n",
            "2/2 [==============================] - 0s 77ms/step - loss: 816.8857 - mean_output_loss: 823.4939 - variance_output_loss: -6.6082 - val_loss: 768.2986 - val_mean_output_loss: 773.7795 - val_variance_output_loss: -5.4809\n",
            "Epoch 254/5000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 816.8675 - mean_output_loss: 821.6149 - variance_output_loss: -4.7474 - val_loss: 766.4335 - val_mean_output_loss: 771.9512 - val_variance_output_loss: -5.5176\n",
            "Epoch 255/5000\n",
            "2/2 [==============================] - 0s 71ms/step - loss: 813.0422 - mean_output_loss: 819.7344 - variance_output_loss: -6.6922 - val_loss: 764.5750 - val_mean_output_loss: 770.1293 - val_variance_output_loss: -5.5543\n",
            "Epoch 256/5000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 812.4391 - mean_output_loss: 817.8651 - variance_output_loss: -5.4260 - val_loss: 762.7220 - val_mean_output_loss: 768.3129 - val_variance_output_loss: -5.5909\n",
            "Epoch 257/5000\n",
            "2/2 [==============================] - 0s 68ms/step - loss: 809.3242 - mean_output_loss: 815.9983 - variance_output_loss: -6.6741 - val_loss: 760.8754 - val_mean_output_loss: 766.5029 - val_variance_output_loss: -5.6275\n",
            "Epoch 258/5000\n",
            "2/2 [==============================] - 0s 68ms/step - loss: 806.8292 - mean_output_loss: 814.1370 - variance_output_loss: -7.3078 - val_loss: 759.0348 - val_mean_output_loss: 764.6988 - val_variance_output_loss: -5.6640\n",
            "Epoch 259/5000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 805.8022 - mean_output_loss: 812.2812 - variance_output_loss: -6.4789 - val_loss: 757.2004 - val_mean_output_loss: 762.9009 - val_variance_output_loss: -5.7004\n",
            "Epoch 260/5000\n",
            "2/2 [==============================] - 0s 82ms/step - loss: 804.2455 - mean_output_loss: 810.4316 - variance_output_loss: -6.1860 - val_loss: 755.3720 - val_mean_output_loss: 761.1088 - val_variance_output_loss: -5.7368\n",
            "Epoch 261/5000\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 800.4633 - mean_output_loss: 808.5911 - variance_output_loss: -8.1278 - val_loss: 753.5487 - val_mean_output_loss: 759.3219 - val_variance_output_loss: -5.7732\n",
            "Epoch 262/5000\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 800.3964 - mean_output_loss: 806.7578 - variance_output_loss: -6.3614 - val_loss: 751.7308 - val_mean_output_loss: 757.5402 - val_variance_output_loss: -5.8095\n",
            "Epoch 263/5000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 797.9692 - mean_output_loss: 804.9257 - variance_output_loss: -6.9564 - val_loss: 749.9190 - val_mean_output_loss: 755.7647 - val_variance_output_loss: -5.8457\n",
            "Epoch 264/5000\n",
            "2/2 [==============================] - 0s 80ms/step - loss: 795.4290 - mean_output_loss: 803.0991 - variance_output_loss: -7.6702 - val_loss: 748.1130 - val_mean_output_loss: 753.9950 - val_variance_output_loss: -5.8819\n",
            "Epoch 265/5000\n",
            "2/2 [==============================] - 0s 73ms/step - loss: 795.1827 - mean_output_loss: 801.2745 - variance_output_loss: -6.0917 - val_loss: 746.3137 - val_mean_output_loss: 752.2317 - val_variance_output_loss: -5.9180\n",
            "Epoch 266/5000\n",
            "2/2 [==============================] - 0s 74ms/step - loss: 794.1542 - mean_output_loss: 799.4664 - variance_output_loss: -5.3123 - val_loss: 744.5185 - val_mean_output_loss: 750.4726 - val_variance_output_loss: -5.9541\n",
            "Epoch 267/5000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 791.9825 - mean_output_loss: 797.6539 - variance_output_loss: -5.6715 - val_loss: 742.7294 - val_mean_output_loss: 748.7195 - val_variance_output_loss: -5.9901\n",
            "Epoch 268/5000\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 788.2841 - mean_output_loss: 795.8577 - variance_output_loss: -7.5736 - val_loss: 740.9449 - val_mean_output_loss: 746.9709 - val_variance_output_loss: -6.0260\n",
            "Epoch 269/5000\n",
            "2/2 [==============================] - 0s 66ms/step - loss: 787.3505 - mean_output_loss: 794.0637 - variance_output_loss: -6.7131 - val_loss: 739.1655 - val_mean_output_loss: 745.2274 - val_variance_output_loss: -6.0619\n",
            "Epoch 270/5000\n",
            "2/2 [==============================] - 0s 70ms/step - loss: 784.5613 - mean_output_loss: 792.2692 - variance_output_loss: -7.7079 - val_loss: 737.3925 - val_mean_output_loss: 743.4903 - val_variance_output_loss: -6.0978\n",
            "Epoch 271/5000\n",
            "2/2 [==============================] - 0s 73ms/step - loss: 783.6421 - mean_output_loss: 790.4902 - variance_output_loss: -6.8480 - val_loss: 735.6246 - val_mean_output_loss: 741.7582 - val_variance_output_loss: -6.1336\n",
            "Epoch 272/5000\n",
            "2/2 [==============================] - 0s 89ms/step - loss: 781.4758 - mean_output_loss: 788.7042 - variance_output_loss: -7.2284 - val_loss: 733.8636 - val_mean_output_loss: 740.0330 - val_variance_output_loss: -6.1693\n",
            "Epoch 273/5000\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 779.5966 - mean_output_loss: 786.9298 - variance_output_loss: -7.3332 - val_loss: 732.1083 - val_mean_output_loss: 738.3133 - val_variance_output_loss: -6.2050\n",
            "Epoch 274/5000\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 776.9293 - mean_output_loss: 785.1566 - variance_output_loss: -8.2272 - val_loss: 730.3588 - val_mean_output_loss: 736.5995 - val_variance_output_loss: -6.2406\n",
            "Epoch 275/5000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 776.9034 - mean_output_loss: 783.3890 - variance_output_loss: -6.4857 - val_loss: 728.6149 - val_mean_output_loss: 734.8911 - val_variance_output_loss: -6.2762\n",
            "Epoch 276/5000\n",
            "2/2 [==============================] - 0s 72ms/step - loss: 775.1227 - mean_output_loss: 781.6360 - variance_output_loss: -6.5132 - val_loss: 726.8749 - val_mean_output_loss: 733.1866 - val_variance_output_loss: -6.3118\n",
            "Epoch 277/5000\n",
            "2/2 [==============================] - 0s 69ms/step - loss: 772.5151 - mean_output_loss: 779.8888 - variance_output_loss: -7.3737 - val_loss: 725.1390 - val_mean_output_loss: 731.4862 - val_variance_output_loss: -6.3472\n",
            "Epoch 278/5000\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 771.5463 - mean_output_loss: 778.1370 - variance_output_loss: -6.5907 - val_loss: 723.4090 - val_mean_output_loss: 729.7917 - val_variance_output_loss: -6.3827\n",
            "Epoch 279/5000\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 768.6409 - mean_output_loss: 776.3928 - variance_output_loss: -7.7519 - val_loss: 721.6843 - val_mean_output_loss: 728.1024 - val_variance_output_loss: -6.4181\n",
            "Epoch 280/5000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 769.0340 - mean_output_loss: 774.6581 - variance_output_loss: -5.6240 - val_loss: 719.9642 - val_mean_output_loss: 726.4175 - val_variance_output_loss: -6.4534\n",
            "Epoch 281/5000\n",
            "2/2 [==============================] - 0s 66ms/step - loss: 766.4219 - mean_output_loss: 772.9211 - variance_output_loss: -6.4993 - val_loss: 718.2496 - val_mean_output_loss: 724.7383 - val_variance_output_loss: -6.4887\n",
            "Epoch 282/5000\n",
            "2/2 [==============================] - 0s 76ms/step - loss: 764.1859 - mean_output_loss: 771.1903 - variance_output_loss: -7.0045 - val_loss: 716.5402 - val_mean_output_loss: 723.0641 - val_variance_output_loss: -6.5239\n",
            "Epoch 283/5000\n",
            "2/2 [==============================] - 0s 66ms/step - loss: 762.2275 - mean_output_loss: 769.4828 - variance_output_loss: -7.2553 - val_loss: 714.8333 - val_mean_output_loss: 721.3923 - val_variance_output_loss: -6.5591\n",
            "Epoch 284/5000\n",
            "2/2 [==============================] - 0s 84ms/step - loss: 759.2043 - mean_output_loss: 767.7568 - variance_output_loss: -8.5524 - val_loss: 713.1334 - val_mean_output_loss: 719.7276 - val_variance_output_loss: -6.5943\n",
            "Epoch 285/5000\n",
            "2/2 [==============================] - 0s 70ms/step - loss: 758.5622 - mean_output_loss: 766.0417 - variance_output_loss: -7.4795 - val_loss: 711.4386 - val_mean_output_loss: 718.0679 - val_variance_output_loss: -6.6293\n",
            "Epoch 286/5000\n",
            "2/2 [==============================] - 0s 84ms/step - loss: 757.8273 - mean_output_loss: 764.3391 - variance_output_loss: -6.5118 - val_loss: 709.7480 - val_mean_output_loss: 716.4124 - val_variance_output_loss: -6.6644\n",
            "Epoch 287/5000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 753.4450 - mean_output_loss: 762.6309 - variance_output_loss: -9.1858 - val_loss: 708.0632 - val_mean_output_loss: 714.7626 - val_variance_output_loss: -6.6994\n",
            "Epoch 288/5000\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 753.0239 - mean_output_loss: 760.9420 - variance_output_loss: -7.9181 - val_loss: 706.3819 - val_mean_output_loss: 713.1163 - val_variance_output_loss: -6.7344\n",
            "Epoch 289/5000\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 752.4682 - mean_output_loss: 759.2493 - variance_output_loss: -6.7812 - val_loss: 704.7060 - val_mean_output_loss: 711.4753 - val_variance_output_loss: -6.7693\n",
            "Epoch 290/5000\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 749.7790 - mean_output_loss: 757.5486 - variance_output_loss: -7.7696 - val_loss: 703.0369 - val_mean_output_loss: 709.8410 - val_variance_output_loss: -6.8041\n",
            "Epoch 291/5000\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 748.1113 - mean_output_loss: 755.8723 - variance_output_loss: -7.7610 - val_loss: 701.3710 - val_mean_output_loss: 708.2100 - val_variance_output_loss: -6.8390\n",
            "Epoch 292/5000\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 747.4031 - mean_output_loss: 754.1913 - variance_output_loss: -6.7882 - val_loss: 699.7099 - val_mean_output_loss: 706.5837 - val_variance_output_loss: -6.8738\n",
            "Epoch 293/5000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 744.7007 - mean_output_loss: 752.5191 - variance_output_loss: -7.8185 - val_loss: 698.0529 - val_mean_output_loss: 704.9614 - val_variance_output_loss: -6.9085\n",
            "Epoch 294/5000\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 743.6344 - mean_output_loss: 750.8510 - variance_output_loss: -7.2166 - val_loss: 696.4003 - val_mean_output_loss: 703.3434 - val_variance_output_loss: -6.9432\n",
            "Epoch 295/5000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 743.5306 - mean_output_loss: 749.1874 - variance_output_loss: -5.6567 - val_loss: 694.7518 - val_mean_output_loss: 701.7297 - val_variance_output_loss: -6.9779\n",
            "Epoch 296/5000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 739.4837 - mean_output_loss: 747.5284 - variance_output_loss: -8.0447 - val_loss: 693.1079 - val_mean_output_loss: 700.1204 - val_variance_output_loss: -7.0125\n",
            "Epoch 297/5000\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 736.7137 - mean_output_loss: 745.8718 - variance_output_loss: -9.1583 - val_loss: 691.4687 - val_mean_output_loss: 698.5157 - val_variance_output_loss: -7.0471\n",
            "Epoch 298/5000\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 735.1588 - mean_output_loss: 744.2153 - variance_output_loss: -9.0566 - val_loss: 689.8347 - val_mean_output_loss: 696.9163 - val_variance_output_loss: -7.0816\n",
            "Epoch 299/5000\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 735.0307 - mean_output_loss: 742.5751 - variance_output_loss: -7.5445 - val_loss: 688.2040 - val_mean_output_loss: 695.3201 - val_variance_output_loss: -7.1161\n",
            "Epoch 300/5000\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 733.9647 - mean_output_loss: 740.9243 - variance_output_loss: -6.9596 - val_loss: 686.5790 - val_mean_output_loss: 693.7296 - val_variance_output_loss: -7.1505\n",
            "Epoch 301/5000\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 731.1000 - mean_output_loss: 739.2980 - variance_output_loss: -8.1980 - val_loss: 684.9561 - val_mean_output_loss: 692.1411 - val_variance_output_loss: -7.1850\n",
            "Epoch 302/5000\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 729.3934 - mean_output_loss: 737.6558 - variance_output_loss: -8.2624 - val_loss: 683.3394 - val_mean_output_loss: 690.5587 - val_variance_output_loss: -7.2194\n",
            "Epoch 303/5000\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 728.8267 - mean_output_loss: 736.0336 - variance_output_loss: -7.2068 - val_loss: 681.7255 - val_mean_output_loss: 688.9793 - val_variance_output_loss: -7.2537\n",
            "Epoch 304/5000\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 726.9550 - mean_output_loss: 734.4024 - variance_output_loss: -7.4475 - val_loss: 680.1173 - val_mean_output_loss: 687.4053 - val_variance_output_loss: -7.2880\n",
            "Epoch 305/5000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 725.5344 - mean_output_loss: 732.7811 - variance_output_loss: -7.2467 - val_loss: 678.5131 - val_mean_output_loss: 685.8354 - val_variance_output_loss: -7.3223\n",
            "Epoch 306/5000\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 723.1532 - mean_output_loss: 731.1691 - variance_output_loss: -8.0159 - val_loss: 676.9122 - val_mean_output_loss: 684.2687 - val_variance_output_loss: -7.3565\n",
            "Epoch 307/5000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 719.8860 - mean_output_loss: 729.5491 - variance_output_loss: -9.6631 - val_loss: 675.3165 - val_mean_output_loss: 682.7073 - val_variance_output_loss: -7.3907\n",
            "Epoch 308/5000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 719.3281 - mean_output_loss: 727.9426 - variance_output_loss: -8.6145 - val_loss: 673.7242 - val_mean_output_loss: 681.1491 - val_variance_output_loss: -7.4249\n",
            "Epoch 309/5000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 717.7321 - mean_output_loss: 726.3403 - variance_output_loss: -8.6082 - val_loss: 672.1353 - val_mean_output_loss: 679.5943 - val_variance_output_loss: -7.4590\n",
            "Epoch 310/5000\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 717.1866 - mean_output_loss: 724.7370 - variance_output_loss: -7.5503 - val_loss: 670.5505 - val_mean_output_loss: 678.0437 - val_variance_output_loss: -7.4932\n",
            "Epoch 311/5000\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 714.6077 - mean_output_loss: 723.1482 - variance_output_loss: -8.5406 - val_loss: 668.9685 - val_mean_output_loss: 676.4958 - val_variance_output_loss: -7.5272\n",
            "Epoch 312/5000\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 712.4446 - mean_output_loss: 721.5516 - variance_output_loss: -9.1071 - val_loss: 667.3914 - val_mean_output_loss: 674.9527 - val_variance_output_loss: -7.5613\n",
            "Epoch 313/5000\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 711.2141 - mean_output_loss: 719.9554 - variance_output_loss: -8.7414 - val_loss: 665.8192 - val_mean_output_loss: 673.4145 - val_variance_output_loss: -7.5953\n",
            "Epoch 314/5000\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 709.6559 - mean_output_loss: 718.3666 - variance_output_loss: -8.7107 - val_loss: 664.2507 - val_mean_output_loss: 671.8800 - val_variance_output_loss: -7.6293\n",
            "Epoch 315/5000\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 708.6848 - mean_output_loss: 716.7966 - variance_output_loss: -8.1118 - val_loss: 662.6837 - val_mean_output_loss: 670.3469 - val_variance_output_loss: -7.6632\n",
            "Epoch 316/5000\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 706.5900 - mean_output_loss: 715.2232 - variance_output_loss: -8.6332 - val_loss: 661.1203 - val_mean_output_loss: 668.8174 - val_variance_output_loss: -7.6971\n",
            "Epoch 317/5000\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 704.7550 - mean_output_loss: 713.6414 - variance_output_loss: -8.8863 - val_loss: 659.5621 - val_mean_output_loss: 667.2931 - val_variance_output_loss: -7.7310\n",
            "Epoch 318/5000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 703.6295 - mean_output_loss: 712.0690 - variance_output_loss: -8.4395 - val_loss: 658.0078 - val_mean_output_loss: 665.7727 - val_variance_output_loss: -7.7649\n",
            "Epoch 319/5000\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 700.8683 - mean_output_loss: 710.5058 - variance_output_loss: -9.6374 - val_loss: 656.4566 - val_mean_output_loss: 664.2554 - val_variance_output_loss: -7.7987\n",
            "Epoch 320/5000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 699.6441 - mean_output_loss: 708.9466 - variance_output_loss: -9.3025 - val_loss: 654.9086 - val_mean_output_loss: 662.7411 - val_variance_output_loss: -7.8326\n",
            "Epoch 321/5000\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 699.4437 - mean_output_loss: 707.3929 - variance_output_loss: -7.9491 - val_loss: 653.3638 - val_mean_output_loss: 661.2302 - val_variance_output_loss: -7.8663\n",
            "Epoch 322/5000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 697.0375 - mean_output_loss: 705.8285 - variance_output_loss: -8.7910 - val_loss: 651.8248 - val_mean_output_loss: 659.7249 - val_variance_output_loss: -7.9001\n",
            "Epoch 323/5000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 695.3215 - mean_output_loss: 704.2789 - variance_output_loss: -8.9574 - val_loss: 650.2888 - val_mean_output_loss: 658.2227 - val_variance_output_loss: -7.9338\n",
            "Epoch 324/5000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 692.6515 - mean_output_loss: 702.7288 - variance_output_loss: -10.0773 - val_loss: 648.7568 - val_mean_output_loss: 656.7243 - val_variance_output_loss: -7.9676\n",
            "Epoch 325/5000\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 692.7755 - mean_output_loss: 701.1901 - variance_output_loss: -8.4146 - val_loss: 647.2271 - val_mean_output_loss: 655.2285 - val_variance_output_loss: -8.0013\n",
            "Epoch 326/5000\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 691.5495 - mean_output_loss: 699.6469 - variance_output_loss: -8.0973 - val_loss: 645.7017 - val_mean_output_loss: 653.7366 - val_variance_output_loss: -8.0349\n",
            "Epoch 327/5000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 689.2708 - mean_output_loss: 698.1057 - variance_output_loss: -8.8349 - val_loss: 644.1799 - val_mean_output_loss: 652.2485 - val_variance_output_loss: -8.0686\n",
            "Epoch 328/5000\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 686.1799 - mean_output_loss: 696.5746 - variance_output_loss: -10.3947 - val_loss: 642.6609 - val_mean_output_loss: 650.7631 - val_variance_output_loss: -8.1022\n",
            "Epoch 329/5000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 685.7645 - mean_output_loss: 695.0492 - variance_output_loss: -9.2847 - val_loss: 641.1443 - val_mean_output_loss: 649.2802 - val_variance_output_loss: -8.1358\n",
            "Epoch 330/5000\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 684.4243 - mean_output_loss: 693.5134 - variance_output_loss: -9.0891 - val_loss: 639.6324 - val_mean_output_loss: 647.8019 - val_variance_output_loss: -8.1694\n",
            "Epoch 331/5000\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 682.3464 - mean_output_loss: 691.9926 - variance_output_loss: -9.6462 - val_loss: 638.1228 - val_mean_output_loss: 646.3259 - val_variance_output_loss: -8.2030\n",
            "Epoch 332/5000\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 682.1879 - mean_output_loss: 690.4686 - variance_output_loss: -8.2807 - val_loss: 636.6166 - val_mean_output_loss: 644.8532 - val_variance_output_loss: -8.2366\n",
            "Epoch 333/5000\n",
            "2/2 [==============================] - 0s 76ms/step - loss: 679.5958 - mean_output_loss: 688.9493 - variance_output_loss: -9.3535 - val_loss: 635.1133 - val_mean_output_loss: 643.3834 - val_variance_output_loss: -8.2701\n",
            "Epoch 334/5000\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 677.4932 - mean_output_loss: 687.4321 - variance_output_loss: -9.9389 - val_loss: 633.6127 - val_mean_output_loss: 641.9164 - val_variance_output_loss: -8.3036\n",
            "Epoch 335/5000\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 676.3915 - mean_output_loss: 685.9285 - variance_output_loss: -9.5369 - val_loss: 632.1135 - val_mean_output_loss: 640.4506 - val_variance_output_loss: -8.3372\n",
            "Epoch 336/5000\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 674.6991 - mean_output_loss: 684.4168 - variance_output_loss: -9.7177 - val_loss: 630.6176 - val_mean_output_loss: 638.9883 - val_variance_output_loss: -8.3707\n",
            "Epoch 337/5000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 674.7012 - mean_output_loss: 682.9133 - variance_output_loss: -8.2121 - val_loss: 629.1245 - val_mean_output_loss: 637.5286 - val_variance_output_loss: -8.4042\n",
            "Epoch 338/5000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 670.4332 - mean_output_loss: 681.4043 - variance_output_loss: -10.9711 - val_loss: 627.6350 - val_mean_output_loss: 636.0727 - val_variance_output_loss: -8.4377\n",
            "Epoch 339/5000\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 670.5743 - mean_output_loss: 679.9067 - variance_output_loss: -9.3324 - val_loss: 626.1480 - val_mean_output_loss: 634.6192 - val_variance_output_loss: -8.4712\n",
            "Epoch 340/5000\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 669.8184 - mean_output_loss: 678.4062 - variance_output_loss: -8.5877 - val_loss: 624.6642 - val_mean_output_loss: 633.1689 - val_variance_output_loss: -8.5047\n",
            "Epoch 341/5000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 668.1762 - mean_output_loss: 676.9136 - variance_output_loss: -8.7375 - val_loss: 623.1827 - val_mean_output_loss: 631.7208 - val_variance_output_loss: -8.5382\n",
            "Epoch 342/5000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 665.6793 - mean_output_loss: 675.4244 - variance_output_loss: -9.7451 - val_loss: 621.7035 - val_mean_output_loss: 630.2751 - val_variance_output_loss: -8.5717\n",
            "Epoch 343/5000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 663.9727 - mean_output_loss: 673.9309 - variance_output_loss: -9.9582 - val_loss: 620.2278 - val_mean_output_loss: 628.8329 - val_variance_output_loss: -8.6051\n",
            "Epoch 344/5000\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 663.1817 - mean_output_loss: 672.4445 - variance_output_loss: -9.2627 - val_loss: 618.7545 - val_mean_output_loss: 627.3931 - val_variance_output_loss: -8.6386\n",
            "Epoch 345/5000\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 661.7144 - mean_output_loss: 670.9688 - variance_output_loss: -9.2544 - val_loss: 617.2827 - val_mean_output_loss: 625.9548 - val_variance_output_loss: -8.6721\n",
            "Epoch 346/5000\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 660.7994 - mean_output_loss: 669.4789 - variance_output_loss: -8.6795 - val_loss: 615.8149 - val_mean_output_loss: 624.5206 - val_variance_output_loss: -8.7057\n",
            "Epoch 347/5000\n",
            "2/2 [==============================] - 0s 72ms/step - loss: 659.5233 - mean_output_loss: 667.9964 - variance_output_loss: -8.4730 - val_loss: 614.3497 - val_mean_output_loss: 623.0889 - val_variance_output_loss: -8.7392\n",
            "Epoch 348/5000\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 655.7534 - mean_output_loss: 666.5229 - variance_output_loss: -10.7696 - val_loss: 612.8859 - val_mean_output_loss: 621.6586 - val_variance_output_loss: -8.7727\n",
            "Epoch 349/5000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 655.5751 - mean_output_loss: 665.0427 - variance_output_loss: -9.4675 - val_loss: 611.4247 - val_mean_output_loss: 620.2310 - val_variance_output_loss: -8.8063\n",
            "Epoch 350/5000\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 653.5952 - mean_output_loss: 663.5643 - variance_output_loss: -9.9691 - val_loss: 609.9653 - val_mean_output_loss: 618.8052 - val_variance_output_loss: -8.8399\n",
            "Epoch 351/5000\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 653.3365 - mean_output_loss: 662.0942 - variance_output_loss: -8.7577 - val_loss: 608.5064 - val_mean_output_loss: 617.3799 - val_variance_output_loss: -8.8735\n",
            "Epoch 352/5000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 650.4478 - mean_output_loss: 660.6312 - variance_output_loss: -10.1834 - val_loss: 607.0474 - val_mean_output_loss: 615.9546 - val_variance_output_loss: -8.9071\n",
            "Epoch 353/5000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 649.1464 - mean_output_loss: 659.1600 - variance_output_loss: -10.0136 - val_loss: 605.5901 - val_mean_output_loss: 614.5309 - val_variance_output_loss: -8.9408\n",
            "Epoch 354/5000\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 648.6046 - mean_output_loss: 657.6934 - variance_output_loss: -9.0889 - val_loss: 604.1337 - val_mean_output_loss: 613.1082 - val_variance_output_loss: -8.9745\n",
            "Epoch 355/5000\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 647.4178 - mean_output_loss: 656.2276 - variance_output_loss: -8.8098 - val_loss: 602.6785 - val_mean_output_loss: 611.6867 - val_variance_output_loss: -9.0083\n",
            "Epoch 356/5000\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 644.6207 - mean_output_loss: 654.7585 - variance_output_loss: -10.1378 - val_loss: 601.2247 - val_mean_output_loss: 610.2667 - val_variance_output_loss: -9.0421\n",
            "Epoch 357/5000\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 644.7056 - mean_output_loss: 653.2834 - variance_output_loss: -8.5778 - val_loss: 599.7728 - val_mean_output_loss: 608.8488 - val_variance_output_loss: -9.0759\n",
            "Epoch 358/5000\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 641.6790 - mean_output_loss: 651.8273 - variance_output_loss: -10.1483 - val_loss: 598.3195 - val_mean_output_loss: 607.4294 - val_variance_output_loss: -9.1098\n",
            "Epoch 359/5000\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 639.9278 - mean_output_loss: 650.3754 - variance_output_loss: -10.4477 - val_loss: 596.8648 - val_mean_output_loss: 606.0087 - val_variance_output_loss: -9.1438\n",
            "Epoch 360/5000\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 637.9084 - mean_output_loss: 648.9012 - variance_output_loss: -10.9928 - val_loss: 595.4127 - val_mean_output_loss: 604.5906 - val_variance_output_loss: -9.1779\n",
            "Epoch 361/5000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 636.5117 - mean_output_loss: 647.4360 - variance_output_loss: -10.9244 - val_loss: 593.9604 - val_mean_output_loss: 603.1724 - val_variance_output_loss: -9.2120\n",
            "Epoch 362/5000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 636.1706 - mean_output_loss: 645.9641 - variance_output_loss: -9.7935 - val_loss: 592.5089 - val_mean_output_loss: 601.7551 - val_variance_output_loss: -9.2463\n",
            "Epoch 363/5000\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 634.3086 - mean_output_loss: 644.5068 - variance_output_loss: -10.1982 - val_loss: 591.0546 - val_mean_output_loss: 600.3353 - val_variance_output_loss: -9.2806\n",
            "Epoch 364/5000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 632.9468 - mean_output_loss: 643.0447 - variance_output_loss: -10.0979 - val_loss: 589.5989 - val_mean_output_loss: 598.9140 - val_variance_output_loss: -9.3151\n",
            "Epoch 365/5000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 631.5548 - mean_output_loss: 641.5702 - variance_output_loss: -10.0154 - val_loss: 588.1430 - val_mean_output_loss: 597.4926 - val_variance_output_loss: -9.3496\n",
            "Epoch 366/5000\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 629.7825 - mean_output_loss: 640.1038 - variance_output_loss: -10.3211 - val_loss: 586.6846 - val_mean_output_loss: 596.0689 - val_variance_output_loss: -9.3843\n",
            "Epoch 367/5000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 628.5536 - mean_output_loss: 638.6376 - variance_output_loss: -10.0840 - val_loss: 585.2233 - val_mean_output_loss: 594.6424 - val_variance_output_loss: -9.4191\n",
            "Epoch 368/5000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 626.8141 - mean_output_loss: 637.1689 - variance_output_loss: -10.3549 - val_loss: 583.7592 - val_mean_output_loss: 593.2133 - val_variance_output_loss: -9.4541\n",
            "Epoch 369/5000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 625.0419 - mean_output_loss: 635.6909 - variance_output_loss: -10.6489 - val_loss: 582.2930 - val_mean_output_loss: 591.7822 - val_variance_output_loss: -9.4893\n",
            "Epoch 370/5000\n",
            "2/2 [==============================] - 0s 72ms/step - loss: 622.9786 - mean_output_loss: 634.2123 - variance_output_loss: -11.2336 - val_loss: 580.8238 - val_mean_output_loss: 590.3484 - val_variance_output_loss: -9.5246\n",
            "Epoch 371/5000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 623.1255 - mean_output_loss: 632.7344 - variance_output_loss: -9.6088 - val_loss: 579.3507 - val_mean_output_loss: 588.9108 - val_variance_output_loss: -9.5601\n",
            "Epoch 372/5000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 621.5264 - mean_output_loss: 631.2408 - variance_output_loss: -9.7144 - val_loss: 577.8748 - val_mean_output_loss: 587.4706 - val_variance_output_loss: -9.5958\n",
            "Epoch 373/5000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 618.5950 - mean_output_loss: 629.7523 - variance_output_loss: -11.1573 - val_loss: 576.3936 - val_mean_output_loss: 586.0253 - val_variance_output_loss: -9.6317\n",
            "Epoch 374/5000\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 618.9036 - mean_output_loss: 628.2720 - variance_output_loss: -9.3684 - val_loss: 574.9052 - val_mean_output_loss: 584.5731 - val_variance_output_loss: -9.6679\n",
            "Epoch 375/5000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 616.5957 - mean_output_loss: 626.7661 - variance_output_loss: -10.1703 - val_loss: 573.4127 - val_mean_output_loss: 583.1169 - val_variance_output_loss: -9.7043\n",
            "Epoch 376/5000\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 614.4410 - mean_output_loss: 625.2590 - variance_output_loss: -10.8179 - val_loss: 571.9144 - val_mean_output_loss: 581.6554 - val_variance_output_loss: -9.7409\n",
            "Epoch 377/5000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 612.4149 - mean_output_loss: 623.7435 - variance_output_loss: -11.3286 - val_loss: 570.4100 - val_mean_output_loss: 580.1879 - val_variance_output_loss: -9.7779\n",
            "Epoch 378/5000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 611.3811 - mean_output_loss: 622.2336 - variance_output_loss: -10.8525 - val_loss: 568.8970 - val_mean_output_loss: 578.7120 - val_variance_output_loss: -9.8151\n",
            "Epoch 379/5000\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 609.8524 - mean_output_loss: 620.6995 - variance_output_loss: -10.8471 - val_loss: 567.3775 - val_mean_output_loss: 577.2300 - val_variance_output_loss: -9.8526\n",
            "Epoch 380/5000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 607.7034 - mean_output_loss: 619.1780 - variance_output_loss: -11.4747 - val_loss: 565.8480 - val_mean_output_loss: 575.7384 - val_variance_output_loss: -9.8904\n",
            "Epoch 381/5000\n",
            "2/2 [==============================] - 0s 66ms/step - loss: 606.4774 - mean_output_loss: 617.6327 - variance_output_loss: -11.1553 - val_loss: 564.3110 - val_mean_output_loss: 574.2395 - val_variance_output_loss: -9.9285\n",
            "Epoch 382/5000\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 605.0397 - mean_output_loss: 616.0796 - variance_output_loss: -11.0399 - val_loss: 562.7657 - val_mean_output_loss: 572.7325 - val_variance_output_loss: -9.9669\n",
            "Epoch 383/5000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 603.8581 - mean_output_loss: 614.5226 - variance_output_loss: -10.6644 - val_loss: 561.2109 - val_mean_output_loss: 571.2165 - val_variance_output_loss: -10.0056\n",
            "Epoch 384/5000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 601.3158 - mean_output_loss: 612.9560 - variance_output_loss: -11.6402 - val_loss: 559.6466 - val_mean_output_loss: 569.6912 - val_variance_output_loss: -10.0446\n",
            "Epoch 385/5000\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 599.4663 - mean_output_loss: 611.3724 - variance_output_loss: -11.9061 - val_loss: 558.0737 - val_mean_output_loss: 568.1577 - val_variance_output_loss: -10.0840\n",
            "Epoch 386/5000\n",
            "2/2 [==============================] - 0s 66ms/step - loss: 600.2714 - mean_output_loss: 609.7841 - variance_output_loss: -9.5127 - val_loss: 556.4908 - val_mean_output_loss: 566.6145 - val_variance_output_loss: -10.1236\n",
            "Epoch 387/5000\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 597.1595 - mean_output_loss: 608.1894 - variance_output_loss: -11.0299 - val_loss: 554.8979 - val_mean_output_loss: 565.0615 - val_variance_output_loss: -10.1636\n",
            "Epoch 388/5000\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 595.3530 - mean_output_loss: 606.5826 - variance_output_loss: -11.2297 - val_loss: 553.2953 - val_mean_output_loss: 563.4991 - val_variance_output_loss: -10.2038\n",
            "Epoch 389/5000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 593.6035 - mean_output_loss: 604.9693 - variance_output_loss: -11.3658 - val_loss: 551.6832 - val_mean_output_loss: 561.9276 - val_variance_output_loss: -10.2443\n",
            "Epoch 390/5000\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 592.0269 - mean_output_loss: 603.3401 - variance_output_loss: -11.3133 - val_loss: 550.0631 - val_mean_output_loss: 560.3481 - val_variance_output_loss: -10.2851\n",
            "Epoch 391/5000\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 590.6476 - mean_output_loss: 601.7147 - variance_output_loss: -11.0671 - val_loss: 548.4337 - val_mean_output_loss: 558.7597 - val_variance_output_loss: -10.3260\n",
            "Epoch 392/5000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 588.8154 - mean_output_loss: 600.0665 - variance_output_loss: -11.2512 - val_loss: 546.7982 - val_mean_output_loss: 557.1653 - val_variance_output_loss: -10.3671\n",
            "Epoch 393/5000\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 588.1440 - mean_output_loss: 598.4122 - variance_output_loss: -10.2682 - val_loss: 545.1567 - val_mean_output_loss: 555.5651 - val_variance_output_loss: -10.4084\n",
            "Epoch 394/5000\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 585.4028 - mean_output_loss: 596.7573 - variance_output_loss: -11.3546 - val_loss: 543.5087 - val_mean_output_loss: 553.9586 - val_variance_output_loss: -10.4498\n",
            "Epoch 395/5000\n",
            "2/2 [==============================] - 0s 71ms/step - loss: 584.1790 - mean_output_loss: 595.1000 - variance_output_loss: -10.9210 - val_loss: 541.8549 - val_mean_output_loss: 552.3463 - val_variance_output_loss: -10.4914\n",
            "Epoch 396/5000\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 581.9229 - mean_output_loss: 593.4432 - variance_output_loss: -11.5203 - val_loss: 540.1961 - val_mean_output_loss: 550.7290 - val_variance_output_loss: -10.5329\n",
            "Epoch 397/5000\n",
            "2/2 [==============================] - 0s 67ms/step - loss: 580.4573 - mean_output_loss: 591.7572 - variance_output_loss: -11.2999 - val_loss: 538.5371 - val_mean_output_loss: 549.1116 - val_variance_output_loss: -10.5745\n",
            "Epoch 398/5000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 578.8702 - mean_output_loss: 590.0878 - variance_output_loss: -11.2176 - val_loss: 536.8753 - val_mean_output_loss: 547.4914 - val_variance_output_loss: -10.6161\n",
            "Epoch 399/5000\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 578.8661 - mean_output_loss: 588.4097 - variance_output_loss: -9.5436 - val_loss: 535.2128 - val_mean_output_loss: 545.8704 - val_variance_output_loss: -10.6576\n",
            "Epoch 400/5000\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 575.9188 - mean_output_loss: 586.7402 - variance_output_loss: -10.8215 - val_loss: 533.5493 - val_mean_output_loss: 544.2484 - val_variance_output_loss: -10.6990\n",
            "Epoch 401/5000\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 572.8177 - mean_output_loss: 585.0577 - variance_output_loss: -12.2400 - val_loss: 531.8878 - val_mean_output_loss: 542.6282 - val_variance_output_loss: -10.7403\n",
            "Epoch 402/5000\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 571.8847 - mean_output_loss: 583.3832 - variance_output_loss: -11.4985 - val_loss: 530.2280 - val_mean_output_loss: 541.0095 - val_variance_output_loss: -10.7815\n",
            "Epoch 403/5000\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 570.4054 - mean_output_loss: 581.7110 - variance_output_loss: -11.3055 - val_loss: 528.5706 - val_mean_output_loss: 539.3931 - val_variance_output_loss: -10.8225\n",
            "Epoch 404/5000\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 568.2446 - mean_output_loss: 580.0511 - variance_output_loss: -11.8064 - val_loss: 526.9156 - val_mean_output_loss: 537.7789 - val_variance_output_loss: -10.8633\n",
            "Epoch 405/5000\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 566.4720 - mean_output_loss: 578.3749 - variance_output_loss: -11.9029 - val_loss: 525.2671 - val_mean_output_loss: 536.1710 - val_variance_output_loss: -10.9039\n",
            "Epoch 406/5000\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 565.4816 - mean_output_loss: 576.7130 - variance_output_loss: -11.2313 - val_loss: 523.6237 - val_mean_output_loss: 534.5679 - val_variance_output_loss: -10.9443\n",
            "Epoch 407/5000\n",
            "2/2 [==============================] - 0s 69ms/step - loss: 563.0018 - mean_output_loss: 575.0626 - variance_output_loss: -12.0609 - val_loss: 521.9851 - val_mean_output_loss: 532.9695 - val_variance_output_loss: -10.9844\n",
            "Epoch 408/5000\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 562.0133 - mean_output_loss: 573.4061 - variance_output_loss: -11.3928 - val_loss: 520.3541 - val_mean_output_loss: 531.3783 - val_variance_output_loss: -11.0242\n",
            "Epoch 409/5000\n",
            "2/2 [==============================] - 0s 72ms/step - loss: 559.9661 - mean_output_loss: 571.7569 - variance_output_loss: -11.7908 - val_loss: 518.7303 - val_mean_output_loss: 529.7941 - val_variance_output_loss: -11.0637\n",
            "Epoch 410/5000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 558.6650 - mean_output_loss: 570.1304 - variance_output_loss: -11.4654 - val_loss: 517.1118 - val_mean_output_loss: 528.2148 - val_variance_output_loss: -11.1030\n",
            "Epoch 411/5000\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 556.3880 - mean_output_loss: 568.4940 - variance_output_loss: -12.1060 - val_loss: 515.5021 - val_mean_output_loss: 526.6440 - val_variance_output_loss: -11.1419\n",
            "Epoch 412/5000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 554.7654 - mean_output_loss: 566.8676 - variance_output_loss: -12.1022 - val_loss: 513.9005 - val_mean_output_loss: 525.0810 - val_variance_output_loss: -11.1806\n",
            "Epoch 413/5000\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 552.9702 - mean_output_loss: 565.2581 - variance_output_loss: -12.2880 - val_loss: 512.3058 - val_mean_output_loss: 523.5247 - val_variance_output_loss: -11.2189\n",
            "Epoch 414/5000\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 552.4626 - mean_output_loss: 563.6514 - variance_output_loss: -11.1887 - val_loss: 510.7193 - val_mean_output_loss: 521.9762 - val_variance_output_loss: -11.2569\n",
            "Epoch 415/5000\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 550.2544 - mean_output_loss: 562.0533 - variance_output_loss: -11.7989 - val_loss: 509.1413 - val_mean_output_loss: 520.4359 - val_variance_output_loss: -11.2946\n",
            "Epoch 416/5000\n",
            "2/2 [==============================] - 0s 66ms/step - loss: 548.5175 - mean_output_loss: 560.4606 - variance_output_loss: -11.9432 - val_loss: 507.5722 - val_mean_output_loss: 518.9041 - val_variance_output_loss: -11.3319\n",
            "Epoch 417/5000\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 546.8570 - mean_output_loss: 558.8771 - variance_output_loss: -12.0201 - val_loss: 506.0119 - val_mean_output_loss: 517.3809 - val_variance_output_loss: -11.3690\n",
            "Epoch 418/5000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 544.8644 - mean_output_loss: 557.3027 - variance_output_loss: -12.4383 - val_loss: 504.4601 - val_mean_output_loss: 515.8657 - val_variance_output_loss: -11.4057\n",
            "Epoch 419/5000\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 542.0712 - mean_output_loss: 555.7366 - variance_output_loss: -13.6654 - val_loss: 502.9168 - val_mean_output_loss: 514.3588 - val_variance_output_loss: -11.4421\n",
            "Epoch 420/5000\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 542.4872 - mean_output_loss: 554.1749 - variance_output_loss: -11.6876 - val_loss: 501.3823 - val_mean_output_loss: 512.8604 - val_variance_output_loss: -11.4781\n",
            "Epoch 421/5000\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 541.4964 - mean_output_loss: 552.6288 - variance_output_loss: -11.1325 - val_loss: 499.8553 - val_mean_output_loss: 511.3691 - val_variance_output_loss: -11.5139\n",
            "Epoch 422/5000\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 538.3839 - mean_output_loss: 551.0895 - variance_output_loss: -12.7056 - val_loss: 498.3362 - val_mean_output_loss: 509.8855 - val_variance_output_loss: -11.5493\n",
            "Epoch 423/5000\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 536.4745 - mean_output_loss: 549.5499 - variance_output_loss: -13.0755 - val_loss: 496.8260 - val_mean_output_loss: 508.4104 - val_variance_output_loss: -11.5844\n",
            "Epoch 424/5000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 535.1824 - mean_output_loss: 548.0211 - variance_output_loss: -12.8387 - val_loss: 495.3238 - val_mean_output_loss: 506.9430 - val_variance_output_loss: -11.6192\n",
            "Epoch 425/5000\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 534.1796 - mean_output_loss: 546.5199 - variance_output_loss: -12.3402 - val_loss: 493.8269 - val_mean_output_loss: 505.4805 - val_variance_output_loss: -11.6536\n",
            "Epoch 426/5000\n",
            "2/2 [==============================] - 0s 68ms/step - loss: 531.6917 - mean_output_loss: 544.9951 - variance_output_loss: -13.3034 - val_loss: 492.3402 - val_mean_output_loss: 504.0280 - val_variance_output_loss: -11.6878\n",
            "Epoch 427/5000\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 530.2605 - mean_output_loss: 543.4965 - variance_output_loss: -13.2359 - val_loss: 490.8603 - val_mean_output_loss: 502.5819 - val_variance_output_loss: -11.7216\n",
            "Epoch 428/5000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 529.4900 - mean_output_loss: 542.0090 - variance_output_loss: -12.5189 - val_loss: 489.3869 - val_mean_output_loss: 501.1421 - val_variance_output_loss: -11.7551\n",
            "Epoch 429/5000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 527.0120 - mean_output_loss: 540.5124 - variance_output_loss: -13.5005 - val_loss: 487.9227 - val_mean_output_loss: 499.7111 - val_variance_output_loss: -11.7884\n",
            "Epoch 430/5000\n",
            "2/2 [==============================] - 0s 67ms/step - loss: 528.0864 - mean_output_loss: 539.0347 - variance_output_loss: -10.9484 - val_loss: 486.4652 - val_mean_output_loss: 498.2865 - val_variance_output_loss: -11.8213\n",
            "Epoch 431/5000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 525.4606 - mean_output_loss: 537.5605 - variance_output_loss: -12.0998 - val_loss: 485.0152 - val_mean_output_loss: 496.8690 - val_variance_output_loss: -11.8538\n",
            "Epoch 432/5000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 522.5481 - mean_output_loss: 536.0934 - variance_output_loss: -13.5453 - val_loss: 483.5722 - val_mean_output_loss: 495.4583 - val_variance_output_loss: -11.8861\n",
            "Epoch 433/5000\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 523.0161 - mean_output_loss: 534.6340 - variance_output_loss: -11.6179 - val_loss: 482.1361 - val_mean_output_loss: 494.0542 - val_variance_output_loss: -11.9181\n",
            "Epoch 434/5000\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 519.8342 - mean_output_loss: 533.1881 - variance_output_loss: -13.3539 - val_loss: 480.7058 - val_mean_output_loss: 492.6556 - val_variance_output_loss: -11.9498\n",
            "Epoch 435/5000\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 519.6302 - mean_output_loss: 531.7344 - variance_output_loss: -12.1042 - val_loss: 479.2837 - val_mean_output_loss: 491.2648 - val_variance_output_loss: -11.9811\n",
            "Epoch 436/5000\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 518.0920 - mean_output_loss: 530.2950 - variance_output_loss: -12.2030 - val_loss: 477.8680 - val_mean_output_loss: 489.8801 - val_variance_output_loss: -12.0122\n",
            "Epoch 437/5000\n",
            "2/2 [==============================] - 0s 69ms/step - loss: 515.9069 - mean_output_loss: 528.8635 - variance_output_loss: -12.9565 - val_loss: 476.4583 - val_mean_output_loss: 488.5012 - val_variance_output_loss: -12.0429\n",
            "Epoch 438/5000\n",
            "2/2 [==============================] - 0s 69ms/step - loss: 514.4529 - mean_output_loss: 527.4322 - variance_output_loss: -12.9794 - val_loss: 475.0553 - val_mean_output_loss: 487.1287 - val_variance_output_loss: -12.0733\n",
            "Epoch 439/5000\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 512.9703 - mean_output_loss: 526.0204 - variance_output_loss: -13.0501 - val_loss: 473.6572 - val_mean_output_loss: 485.7606 - val_variance_output_loss: -12.1035\n",
            "Epoch 440/5000\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 511.1986 - mean_output_loss: 524.6071 - variance_output_loss: -13.4085 - val_loss: 472.2654 - val_mean_output_loss: 484.3986 - val_variance_output_loss: -12.1333\n",
            "Epoch 441/5000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 509.7799 - mean_output_loss: 523.1917 - variance_output_loss: -13.4117 - val_loss: 470.8809 - val_mean_output_loss: 483.0437 - val_variance_output_loss: -12.1628\n",
            "Epoch 442/5000\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 510.1707 - mean_output_loss: 521.7858 - variance_output_loss: -11.6151 - val_loss: 469.5027 - val_mean_output_loss: 481.6946 - val_variance_output_loss: -12.1920\n",
            "Epoch 443/5000\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 506.8840 - mean_output_loss: 520.3992 - variance_output_loss: -13.5153 - val_loss: 468.1287 - val_mean_output_loss: 480.3495 - val_variance_output_loss: -12.2209\n",
            "Epoch 444/5000\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 506.0404 - mean_output_loss: 519.0001 - variance_output_loss: -12.9596 - val_loss: 466.7619 - val_mean_output_loss: 479.0114 - val_variance_output_loss: -12.2494\n",
            "Epoch 445/5000\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 502.5438 - mean_output_loss: 517.6190 - variance_output_loss: -15.0752 - val_loss: 465.4002 - val_mean_output_loss: 477.6779 - val_variance_output_loss: -12.2777\n",
            "Epoch 446/5000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 501.9328 - mean_output_loss: 516.2397 - variance_output_loss: -14.3069 - val_loss: 464.0441 - val_mean_output_loss: 476.3498 - val_variance_output_loss: -12.3057\n",
            "Epoch 447/5000\n",
            "2/2 [==============================] - 0s 66ms/step - loss: 501.3664 - mean_output_loss: 514.8627 - variance_output_loss: -13.4964 - val_loss: 462.6942 - val_mean_output_loss: 475.0275 - val_variance_output_loss: -12.3333\n",
            "Epoch 448/5000\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 501.4550 - mean_output_loss: 513.4938 - variance_output_loss: -12.0388 - val_loss: 461.3497 - val_mean_output_loss: 473.7104 - val_variance_output_loss: -12.3606\n",
            "Epoch 449/5000\n",
            "2/2 [==============================] - 0s 71ms/step - loss: 498.7949 - mean_output_loss: 512.1298 - variance_output_loss: -13.3349 - val_loss: 460.0107 - val_mean_output_loss: 472.3983 - val_variance_output_loss: -12.3876\n",
            "Epoch 450/5000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 496.8710 - mean_output_loss: 510.7676 - variance_output_loss: -13.8967 - val_loss: 458.6775 - val_mean_output_loss: 471.0918 - val_variance_output_loss: -12.4144\n",
            "Epoch 451/5000\n",
            "2/2 [==============================] - 0s 81ms/step - loss: 495.2173 - mean_output_loss: 509.4258 - variance_output_loss: -14.2085 - val_loss: 457.3476 - val_mean_output_loss: 469.7883 - val_variance_output_loss: -12.4407\n",
            "Epoch 452/5000\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 494.0011 - mean_output_loss: 508.0735 - variance_output_loss: -14.0724 - val_loss: 456.0242 - val_mean_output_loss: 468.4910 - val_variance_output_loss: -12.4668\n",
            "Epoch 453/5000\n",
            "2/2 [==============================] - 0s 87ms/step - loss: 494.1915 - mean_output_loss: 506.7279 - variance_output_loss: -12.5364 - val_loss: 454.7066 - val_mean_output_loss: 467.1992 - val_variance_output_loss: -12.4926\n",
            "Epoch 454/5000\n",
            "2/2 [==============================] - 0s 72ms/step - loss: 492.0345 - mean_output_loss: 505.3965 - variance_output_loss: -13.3620 - val_loss: 453.3933 - val_mean_output_loss: 465.9113 - val_variance_output_loss: -12.5180\n",
            "Epoch 455/5000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 491.3854 - mean_output_loss: 504.0509 - variance_output_loss: -12.6655 - val_loss: 452.0870 - val_mean_output_loss: 464.6302 - val_variance_output_loss: -12.5432\n",
            "Epoch 456/5000\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 488.7859 - mean_output_loss: 502.7287 - variance_output_loss: -13.9428 - val_loss: 450.7846 - val_mean_output_loss: 463.3525 - val_variance_output_loss: -12.5680\n",
            "Epoch 457/5000\n",
            "2/2 [==============================] - 0s 83ms/step - loss: 487.2917 - mean_output_loss: 501.4010 - variance_output_loss: -14.1093 - val_loss: 449.4874 - val_mean_output_loss: 462.0799 - val_variance_output_loss: -12.5925\n",
            "Epoch 458/5000\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 486.3697 - mean_output_loss: 500.0814 - variance_output_loss: -13.7117 - val_loss: 448.1947 - val_mean_output_loss: 460.8114 - val_variance_output_loss: -12.6166\n",
            "Epoch 459/5000\n",
            "2/2 [==============================] - 0s 66ms/step - loss: 484.6877 - mean_output_loss: 498.7768 - variance_output_loss: -14.0891 - val_loss: 446.9051 - val_mean_output_loss: 459.5456 - val_variance_output_loss: -12.6405\n",
            "Epoch 460/5000\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 485.6629 - mean_output_loss: 497.4599 - variance_output_loss: -11.7970 - val_loss: 445.6215 - val_mean_output_loss: 458.2855 - val_variance_output_loss: -12.6641\n",
            "Epoch 461/5000\n",
            "2/2 [==============================] - 0s 85ms/step - loss: 482.1120 - mean_output_loss: 496.1522 - variance_output_loss: -14.0402 - val_loss: 444.3426 - val_mean_output_loss: 457.0299 - val_variance_output_loss: -12.6873\n",
            "Epoch 462/5000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 480.7324 - mean_output_loss: 494.8555 - variance_output_loss: -14.1232 - val_loss: 443.0675 - val_mean_output_loss: 455.7777 - val_variance_output_loss: -12.7102\n",
            "Epoch 463/5000\n",
            "2/2 [==============================] - 0s 74ms/step - loss: 478.8644 - mean_output_loss: 493.5542 - variance_output_loss: -14.6897 - val_loss: 441.7976 - val_mean_output_loss: 454.5304 - val_variance_output_loss: -12.7328\n",
            "Epoch 464/5000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 479.3246 - mean_output_loss: 492.2652 - variance_output_loss: -12.9406 - val_loss: 440.5314 - val_mean_output_loss: 453.2865 - val_variance_output_loss: -12.7551\n",
            "Epoch 465/5000\n",
            "2/2 [==============================] - 0s 70ms/step - loss: 478.2148 - mean_output_loss: 490.9805 - variance_output_loss: -12.7657 - val_loss: 439.2694 - val_mean_output_loss: 452.0464 - val_variance_output_loss: -12.7771\n",
            "Epoch 466/5000\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 475.5353 - mean_output_loss: 489.6952 - variance_output_loss: -14.1599 - val_loss: 438.0125 - val_mean_output_loss: 450.8112 - val_variance_output_loss: -12.7987\n",
            "Epoch 467/5000\n",
            "2/2 [==============================] - 0s 74ms/step - loss: 476.4963 - mean_output_loss: 488.4068 - variance_output_loss: -11.9105 - val_loss: 436.7612 - val_mean_output_loss: 449.5813 - val_variance_output_loss: -12.8201\n",
            "Epoch 468/5000\n",
            "2/2 [==============================] - 0s 80ms/step - loss: 473.2394 - mean_output_loss: 487.1336 - variance_output_loss: -13.8942 - val_loss: 435.5135 - val_mean_output_loss: 448.3547 - val_variance_output_loss: -12.8411\n",
            "Epoch 469/5000\n",
            "2/2 [==============================] - 0s 83ms/step - loss: 471.3480 - mean_output_loss: 485.8611 - variance_output_loss: -14.5132 - val_loss: 434.2701 - val_mean_output_loss: 447.1319 - val_variance_output_loss: -12.8618\n",
            "Epoch 470/5000\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 470.2275 - mean_output_loss: 484.5984 - variance_output_loss: -14.3709 - val_loss: 433.0299 - val_mean_output_loss: 445.9121 - val_variance_output_loss: -12.8822\n",
            "Epoch 471/5000\n",
            "2/2 [==============================] - 0s 71ms/step - loss: 469.8898 - mean_output_loss: 483.3286 - variance_output_loss: -13.4388 - val_loss: 431.7947 - val_mean_output_loss: 444.6970 - val_variance_output_loss: -12.9023\n",
            "Epoch 472/5000\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 468.1877 - mean_output_loss: 482.0740 - variance_output_loss: -13.8864 - val_loss: 430.5628 - val_mean_output_loss: 443.4849 - val_variance_output_loss: -12.9221\n",
            "Epoch 473/5000\n",
            "2/2 [==============================] - 0s 85ms/step - loss: 466.0222 - mean_output_loss: 480.8184 - variance_output_loss: -14.7961 - val_loss: 429.3350 - val_mean_output_loss: 442.2766 - val_variance_output_loss: -12.9416\n",
            "Epoch 474/5000\n",
            "2/2 [==============================] - 0s 71ms/step - loss: 465.6413 - mean_output_loss: 479.5626 - variance_output_loss: -13.9213 - val_loss: 428.1120 - val_mean_output_loss: 441.0728 - val_variance_output_loss: -12.9608\n",
            "Epoch 475/5000\n",
            "2/2 [==============================] - 0s 86ms/step - loss: 465.5710 - mean_output_loss: 478.3162 - variance_output_loss: -12.7452 - val_loss: 426.8927 - val_mean_output_loss: 439.8723 - val_variance_output_loss: -12.9797\n",
            "Epoch 476/5000\n",
            "2/2 [==============================] - 0s 76ms/step - loss: 462.0004 - mean_output_loss: 477.0678 - variance_output_loss: -15.0675 - val_loss: 425.6779 - val_mean_output_loss: 438.6761 - val_variance_output_loss: -12.9982\n",
            "Epoch 477/5000\n",
            "2/2 [==============================] - 0s 68ms/step - loss: 463.1177 - mean_output_loss: 475.8269 - variance_output_loss: -12.7092 - val_loss: 424.4669 - val_mean_output_loss: 437.4834 - val_variance_output_loss: -13.0165\n",
            "Epoch 478/5000\n",
            "2/2 [==============================] - 0s 71ms/step - loss: 460.5725 - mean_output_loss: 474.5914 - variance_output_loss: -14.0188 - val_loss: 423.2592 - val_mean_output_loss: 436.2938 - val_variance_output_loss: -13.0345\n",
            "Epoch 479/5000\n",
            "2/2 [==============================] - 0s 68ms/step - loss: 460.3053 - mean_output_loss: 473.3664 - variance_output_loss: -13.0611 - val_loss: 422.0544 - val_mean_output_loss: 435.1066 - val_variance_output_loss: -13.0522\n",
            "Epoch 480/5000\n",
            "2/2 [==============================] - 0s 87ms/step - loss: 458.3601 - mean_output_loss: 472.1295 - variance_output_loss: -13.7695 - val_loss: 420.8549 - val_mean_output_loss: 433.9245 - val_variance_output_loss: -13.0696\n",
            "Epoch 481/5000\n",
            "2/2 [==============================] - 0s 83ms/step - loss: 456.2370 - mean_output_loss: 470.9034 - variance_output_loss: -14.6664 - val_loss: 419.6593 - val_mean_output_loss: 432.7460 - val_variance_output_loss: -13.0867\n",
            "Epoch 482/5000\n",
            "2/2 [==============================] - 0s 68ms/step - loss: 457.4848 - mean_output_loss: 469.6886 - variance_output_loss: -12.2038 - val_loss: 418.4667 - val_mean_output_loss: 431.5703 - val_variance_output_loss: -13.1035\n",
            "Epoch 483/5000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 454.7068 - mean_output_loss: 468.4685 - variance_output_loss: -13.7617 - val_loss: 417.2787 - val_mean_output_loss: 430.3988 - val_variance_output_loss: -13.1201\n",
            "Epoch 484/5000\n",
            "2/2 [==============================] - 0s 70ms/step - loss: 451.8491 - mean_output_loss: 467.2487 - variance_output_loss: -15.3996 - val_loss: 416.0956 - val_mean_output_loss: 429.2320 - val_variance_output_loss: -13.1363\n",
            "Epoch 485/5000\n",
            "2/2 [==============================] - 0s 74ms/step - loss: 452.2867 - mean_output_loss: 466.0351 - variance_output_loss: -13.7484 - val_loss: 414.9167 - val_mean_output_loss: 428.0689 - val_variance_output_loss: -13.1523\n",
            "Epoch 486/5000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 450.4719 - mean_output_loss: 464.8280 - variance_output_loss: -14.3562 - val_loss: 413.7409 - val_mean_output_loss: 426.9089 - val_variance_output_loss: -13.1680\n",
            "Epoch 487/5000\n",
            "2/2 [==============================] - 0s 81ms/step - loss: 450.5164 - mean_output_loss: 463.6205 - variance_output_loss: -13.1042 - val_loss: 412.5689 - val_mean_output_loss: 425.7523 - val_variance_output_loss: -13.1834\n",
            "Epoch 488/5000\n",
            "2/2 [==============================] - 0s 71ms/step - loss: 447.5770 - mean_output_loss: 462.4269 - variance_output_loss: -14.8499 - val_loss: 411.3990 - val_mean_output_loss: 424.5975 - val_variance_output_loss: -13.1986\n",
            "Epoch 489/5000\n",
            "2/2 [==============================] - 0s 69ms/step - loss: 447.7896 - mean_output_loss: 461.2315 - variance_output_loss: -13.4418 - val_loss: 410.2325 - val_mean_output_loss: 423.4459 - val_variance_output_loss: -13.2135\n",
            "Epoch 490/5000\n",
            "2/2 [==============================] - 0s 67ms/step - loss: 446.2679 - mean_output_loss: 460.0317 - variance_output_loss: -13.7639 - val_loss: 409.0705 - val_mean_output_loss: 422.2986 - val_variance_output_loss: -13.2281\n",
            "Epoch 491/5000\n",
            "2/2 [==============================] - 0s 84ms/step - loss: 446.1874 - mean_output_loss: 458.8419 - variance_output_loss: -12.6545 - val_loss: 407.9116 - val_mean_output_loss: 421.1541 - val_variance_output_loss: -13.2425\n",
            "Epoch 492/5000\n",
            "2/2 [==============================] - 0s 115ms/step - loss: 443.3444 - mean_output_loss: 457.6610 - variance_output_loss: -14.3167 - val_loss: 406.7554 - val_mean_output_loss: 420.0120 - val_variance_output_loss: -13.2566\n",
            "Epoch 493/5000\n",
            "2/2 [==============================] - 0s 77ms/step - loss: 441.8600 - mean_output_loss: 456.4698 - variance_output_loss: -14.6099 - val_loss: 405.6040 - val_mean_output_loss: 418.8744 - val_variance_output_loss: -13.2704\n",
            "Epoch 494/5000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 442.2312 - mean_output_loss: 455.2928 - variance_output_loss: -13.0616 - val_loss: 404.4554 - val_mean_output_loss: 417.7395 - val_variance_output_loss: -13.2840\n",
            "Epoch 495/5000\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 439.9312 - mean_output_loss: 454.1123 - variance_output_loss: -14.1810 - val_loss: 403.3109 - val_mean_output_loss: 416.6083 - val_variance_output_loss: -13.2974\n",
            "Epoch 496/5000\n",
            "2/2 [==============================] - 0s 72ms/step - loss: 438.1792 - mean_output_loss: 452.9340 - variance_output_loss: -14.7548 - val_loss: 402.1703 - val_mean_output_loss: 415.4808 - val_variance_output_loss: -13.3105\n",
            "Epoch 497/5000\n",
            "2/2 [==============================] - 0s 70ms/step - loss: 437.9820 - mean_output_loss: 451.7701 - variance_output_loss: -13.7881 - val_loss: 401.0315 - val_mean_output_loss: 414.3549 - val_variance_output_loss: -13.3234\n",
            "Epoch 498/5000\n",
            "2/2 [==============================] - 0s 71ms/step - loss: 436.8364 - mean_output_loss: 450.6002 - variance_output_loss: -13.7638 - val_loss: 399.8967 - val_mean_output_loss: 413.2328 - val_variance_output_loss: -13.3360\n",
            "Epoch 499/5000\n",
            "2/2 [==============================] - 0s 68ms/step - loss: 434.9085 - mean_output_loss: 449.4297 - variance_output_loss: -14.5212 - val_loss: 398.7660 - val_mean_output_loss: 412.1144 - val_variance_output_loss: -13.3484\n",
            "Epoch 500/5000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 434.2043 - mean_output_loss: 448.2659 - variance_output_loss: -14.0616 - val_loss: 397.6382 - val_mean_output_loss: 410.9988 - val_variance_output_loss: -13.3606\n",
            "Epoch 501/5000\n",
            "2/2 [==============================] - 0s 70ms/step - loss: 432.0849 - mean_output_loss: 447.1152 - variance_output_loss: -15.0302 - val_loss: 396.5120 - val_mean_output_loss: 409.8846 - val_variance_output_loss: -13.3726\n",
            "Epoch 502/5000\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 432.6443 - mean_output_loss: 445.9510 - variance_output_loss: -13.3066 - val_loss: 395.3902 - val_mean_output_loss: 408.7745 - val_variance_output_loss: -13.3843\n",
            "Epoch 503/5000\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 430.1750 - mean_output_loss: 444.8064 - variance_output_loss: -14.6313 - val_loss: 394.2701 - val_mean_output_loss: 407.6659 - val_variance_output_loss: -13.3958\n",
            "Epoch 504/5000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 430.0597 - mean_output_loss: 443.6508 - variance_output_loss: -13.5911 - val_loss: 393.1541 - val_mean_output_loss: 406.5612 - val_variance_output_loss: -13.4071\n",
            "Epoch 505/5000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 427.3446 - mean_output_loss: 442.5091 - variance_output_loss: -15.1645 - val_loss: 392.0403 - val_mean_output_loss: 405.4585 - val_variance_output_loss: -13.4182\n",
            "Epoch 506/5000\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 426.3090 - mean_output_loss: 441.3591 - variance_output_loss: -15.0501 - val_loss: 390.9307 - val_mean_output_loss: 404.3598 - val_variance_output_loss: -13.4291\n",
            "Epoch 507/5000\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 425.1285 - mean_output_loss: 440.2213 - variance_output_loss: -15.0928 - val_loss: 389.8237 - val_mean_output_loss: 403.2635 - val_variance_output_loss: -13.4398\n",
            "Epoch 508/5000\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 424.4744 - mean_output_loss: 439.0819 - variance_output_loss: -14.6075 - val_loss: 388.7201 - val_mean_output_loss: 402.1703 - val_variance_output_loss: -13.4503\n",
            "Epoch 509/5000\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 423.5276 - mean_output_loss: 437.9421 - variance_output_loss: -14.4145 - val_loss: 387.6202 - val_mean_output_loss: 401.0807 - val_variance_output_loss: -13.4605\n",
            "Epoch 510/5000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 422.3690 - mean_output_loss: 436.8134 - variance_output_loss: -14.4444 - val_loss: 386.5224 - val_mean_output_loss: 399.9930 - val_variance_output_loss: -13.4706\n",
            "Epoch 511/5000\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 422.1473 - mean_output_loss: 435.6749 - variance_output_loss: -13.5276 - val_loss: 385.4288 - val_mean_output_loss: 398.9093 - val_variance_output_loss: -13.4805\n",
            "Epoch 512/5000\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 420.8625 - mean_output_loss: 434.5540 - variance_output_loss: -13.6914 - val_loss: 384.3365 - val_mean_output_loss: 397.8267 - val_variance_output_loss: -13.4902\n",
            "Epoch 513/5000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 419.7737 - mean_output_loss: 433.4272 - variance_output_loss: -13.6535 - val_loss: 383.2472 - val_mean_output_loss: 396.7469 - val_variance_output_loss: -13.4998\n",
            "Epoch 514/5000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 417.2836 - mean_output_loss: 432.3088 - variance_output_loss: -15.0252 - val_loss: 382.1600 - val_mean_output_loss: 395.6692 - val_variance_output_loss: -13.5091\n",
            "Epoch 515/5000\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 417.0690 - mean_output_loss: 431.1868 - variance_output_loss: -14.1178 - val_loss: 381.0760 - val_mean_output_loss: 394.5944 - val_variance_output_loss: -13.5183\n",
            "Epoch 516/5000\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 416.0775 - mean_output_loss: 430.0759 - variance_output_loss: -13.9984 - val_loss: 379.9943 - val_mean_output_loss: 393.5215 - val_variance_output_loss: -13.5273\n",
            "Epoch 517/5000\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 413.3769 - mean_output_loss: 428.9622 - variance_output_loss: -15.5854 - val_loss: 378.9155 - val_mean_output_loss: 392.4517 - val_variance_output_loss: -13.5361\n",
            "Epoch 518/5000\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 412.1047 - mean_output_loss: 427.8473 - variance_output_loss: -15.7426 - val_loss: 377.8407 - val_mean_output_loss: 391.3855 - val_variance_output_loss: -13.5448\n",
            "Epoch 519/5000\n",
            "2/2 [==============================] - 0s 72ms/step - loss: 413.1660 - mean_output_loss: 426.7449 - variance_output_loss: -13.5790 - val_loss: 376.7680 - val_mean_output_loss: 390.3213 - val_variance_output_loss: -13.5533\n",
            "Epoch 520/5000\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 411.0713 - mean_output_loss: 425.6323 - variance_output_loss: -14.5610 - val_loss: 375.6996 - val_mean_output_loss: 389.2613 - val_variance_output_loss: -13.5617\n",
            "Epoch 521/5000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 411.0042 - mean_output_loss: 424.5346 - variance_output_loss: -13.5304 - val_loss: 374.6331 - val_mean_output_loss: 388.2030 - val_variance_output_loss: -13.5699\n",
            "Epoch 522/5000\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 409.0696 - mean_output_loss: 423.4341 - variance_output_loss: -14.3645 - val_loss: 373.5698 - val_mean_output_loss: 387.1477 - val_variance_output_loss: -13.5779\n",
            "Epoch 523/5000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 406.2980 - mean_output_loss: 422.3328 - variance_output_loss: -16.0349 - val_loss: 372.5100 - val_mean_output_loss: 386.0959 - val_variance_output_loss: -13.5858\n",
            "Epoch 524/5000\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 407.8710 - mean_output_loss: 421.2466 - variance_output_loss: -13.3756 - val_loss: 371.4516 - val_mean_output_loss: 385.0451 - val_variance_output_loss: -13.5936\n",
            "Epoch 525/5000\n",
            "2/2 [==============================] - 0s 66ms/step - loss: 404.1494 - mean_output_loss: 420.1465 - variance_output_loss: -15.9971 - val_loss: 370.3972 - val_mean_output_loss: 383.9984 - val_variance_output_loss: -13.6012\n",
            "Epoch 526/5000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 403.7169 - mean_output_loss: 419.0574 - variance_output_loss: -15.3405 - val_loss: 369.3452 - val_mean_output_loss: 382.9539 - val_variance_output_loss: -13.6086\n",
            "Epoch 527/5000\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 403.7053 - mean_output_loss: 417.9728 - variance_output_loss: -14.2675 - val_loss: 368.2953 - val_mean_output_loss: 381.9112 - val_variance_output_loss: -13.6160\n",
            "Epoch 528/5000\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 401.7779 - mean_output_loss: 416.8971 - variance_output_loss: -15.1193 - val_loss: 367.2466 - val_mean_output_loss: 380.8698 - val_variance_output_loss: -13.6231\n",
            "Epoch 529/5000\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 401.1619 - mean_output_loss: 415.8100 - variance_output_loss: -14.6480 - val_loss: 366.2019 - val_mean_output_loss: 379.8321 - val_variance_output_loss: -13.6302\n",
            "Epoch 530/5000\n",
            "2/2 [==============================] - 0s 69ms/step - loss: 400.5859 - mean_output_loss: 414.7263 - variance_output_loss: -14.1405 - val_loss: 365.1603 - val_mean_output_loss: 378.7975 - val_variance_output_loss: -13.6371\n",
            "Epoch 531/5000\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 399.4585 - mean_output_loss: 413.6522 - variance_output_loss: -14.1938 - val_loss: 364.1208 - val_mean_output_loss: 377.7648 - val_variance_output_loss: -13.6439\n",
            "Epoch 532/5000\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 397.8557 - mean_output_loss: 412.5748 - variance_output_loss: -14.7191 - val_loss: 363.0840 - val_mean_output_loss: 376.7346 - val_variance_output_loss: -13.6506\n",
            "Epoch 533/5000\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 396.7319 - mean_output_loss: 411.5038 - variance_output_loss: -14.7720 - val_loss: 362.0491 - val_mean_output_loss: 375.7063 - val_variance_output_loss: -13.6572\n",
            "Epoch 534/5000\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 396.0613 - mean_output_loss: 410.4382 - variance_output_loss: -14.3769 - val_loss: 361.0159 - val_mean_output_loss: 374.6796 - val_variance_output_loss: -13.6636\n",
            "Epoch 535/5000\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 394.7537 - mean_output_loss: 409.3692 - variance_output_loss: -14.6155 - val_loss: 359.9855 - val_mean_output_loss: 373.6555 - val_variance_output_loss: -13.6700\n",
            "Epoch 536/5000\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 393.7567 - mean_output_loss: 408.3019 - variance_output_loss: -14.5451 - val_loss: 358.9577 - val_mean_output_loss: 372.6339 - val_variance_output_loss: -13.6762\n",
            "Epoch 537/5000\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 392.3045 - mean_output_loss: 407.2406 - variance_output_loss: -14.9362 - val_loss: 357.9320 - val_mean_output_loss: 371.6143 - val_variance_output_loss: -13.6823\n",
            "Epoch 538/5000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 391.4778 - mean_output_loss: 406.1793 - variance_output_loss: -14.7015 - val_loss: 356.9087 - val_mean_output_loss: 370.5969 - val_variance_output_loss: -13.6883\n",
            "Epoch 539/5000\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 390.9526 - mean_output_loss: 405.1217 - variance_output_loss: -14.1691 - val_loss: 355.8876 - val_mean_output_loss: 369.5818 - val_variance_output_loss: -13.6942\n",
            "Epoch 540/5000\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 389.9402 - mean_output_loss: 404.0648 - variance_output_loss: -14.1246 - val_loss: 354.8688 - val_mean_output_loss: 368.5687 - val_variance_output_loss: -13.6999\n",
            "Epoch 541/5000\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 389.2310 - mean_output_loss: 403.0121 - variance_output_loss: -13.7810 - val_loss: 353.8523 - val_mean_output_loss: 367.5579 - val_variance_output_loss: -13.7056\n",
            "Epoch 542/5000\n",
            "2/2 [==============================] - 0s 70ms/step - loss: 387.1384 - mean_output_loss: 401.9586 - variance_output_loss: -14.8202 - val_loss: 352.8382 - val_mean_output_loss: 366.5494 - val_variance_output_loss: -13.7112\n",
            "Epoch 543/5000\n",
            "2/2 [==============================] - 0s 85ms/step - loss: 386.3994 - mean_output_loss: 400.9076 - variance_output_loss: -14.5081 - val_loss: 351.8264 - val_mean_output_loss: 365.5432 - val_variance_output_loss: -13.7167\n",
            "Epoch 544/5000\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 383.7935 - mean_output_loss: 399.8542 - variance_output_loss: -16.0607 - val_loss: 350.8175 - val_mean_output_loss: 364.5396 - val_variance_output_loss: -13.7221\n",
            "Epoch 545/5000\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 384.1132 - mean_output_loss: 398.8157 - variance_output_loss: -14.7025 - val_loss: 349.8090 - val_mean_output_loss: 363.5364 - val_variance_output_loss: -13.7274\n",
            "Epoch 546/5000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 383.5563 - mean_output_loss: 397.7668 - variance_output_loss: -14.2105 - val_loss: 348.8033 - val_mean_output_loss: 362.5359 - val_variance_output_loss: -13.7326\n",
            "Epoch 547/5000\n",
            "2/2 [==============================] - 0s 75ms/step - loss: 381.6482 - mean_output_loss: 396.7347 - variance_output_loss: -15.0865 - val_loss: 347.7980 - val_mean_output_loss: 361.5357 - val_variance_output_loss: -13.7378\n",
            "Epoch 548/5000\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 380.9834 - mean_output_loss: 395.6902 - variance_output_loss: -14.7069 - val_loss: 346.7959 - val_mean_output_loss: 360.5387 - val_variance_output_loss: -13.7428\n",
            "Epoch 549/5000\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 380.0725 - mean_output_loss: 394.6552 - variance_output_loss: -14.5827 - val_loss: 345.7954 - val_mean_output_loss: 359.5432 - val_variance_output_loss: -13.7478\n",
            "Epoch 550/5000\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 378.5138 - mean_output_loss: 393.6183 - variance_output_loss: -15.1044 - val_loss: 344.7976 - val_mean_output_loss: 358.5502 - val_variance_output_loss: -13.7526\n",
            "Epoch 551/5000\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 378.0940 - mean_output_loss: 392.5820 - variance_output_loss: -14.4880 - val_loss: 343.8024 - val_mean_output_loss: 357.5598 - val_variance_output_loss: -13.7574\n",
            "Epoch 552/5000\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 377.5869 - mean_output_loss: 391.5508 - variance_output_loss: -13.9639 - val_loss: 342.8089 - val_mean_output_loss: 356.5710 - val_variance_output_loss: -13.7621\n",
            "Epoch 553/5000\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 375.6826 - mean_output_loss: 390.5255 - variance_output_loss: -14.8428 - val_loss: 341.8169 - val_mean_output_loss: 355.5836 - val_variance_output_loss: -13.7668\n",
            "Epoch 554/5000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 373.9214 - mean_output_loss: 389.4927 - variance_output_loss: -15.5713 - val_loss: 340.8277 - val_mean_output_loss: 354.5991 - val_variance_output_loss: -13.7714\n",
            "Epoch 555/5000\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 374.7129 - mean_output_loss: 388.4658 - variance_output_loss: -13.7529 - val_loss: 339.8404 - val_mean_output_loss: 353.6162 - val_variance_output_loss: -13.7758\n",
            "Epoch 556/5000\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 372.6321 - mean_output_loss: 387.4410 - variance_output_loss: -14.8090 - val_loss: 338.8547 - val_mean_output_loss: 352.6350 - val_variance_output_loss: -13.7803\n",
            "Epoch 557/5000\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 371.3850 - mean_output_loss: 386.4240 - variance_output_loss: -15.0390 - val_loss: 337.8698 - val_mean_output_loss: 351.6545 - val_variance_output_loss: -13.7846\n",
            "Epoch 558/5000\n",
            "2/2 [==============================] - 0s 67ms/step - loss: 370.7492 - mean_output_loss: 385.3967 - variance_output_loss: -14.6475 - val_loss: 336.8877 - val_mean_output_loss: 350.6766 - val_variance_output_loss: -13.7889\n",
            "Epoch 559/5000\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 369.8518 - mean_output_loss: 384.3824 - variance_output_loss: -14.5306 - val_loss: 335.9064 - val_mean_output_loss: 349.6995 - val_variance_output_loss: -13.7931\n",
            "Epoch 560/5000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 368.4622 - mean_output_loss: 383.3670 - variance_output_loss: -14.9048 - val_loss: 334.9264 - val_mean_output_loss: 348.7237 - val_variance_output_loss: -13.7973\n",
            "Epoch 561/5000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 367.8148 - mean_output_loss: 382.3437 - variance_output_loss: -14.5288 - val_loss: 333.9491 - val_mean_output_loss: 347.7505 - val_variance_output_loss: -13.8014\n",
            "Epoch 562/5000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 365.1796 - mean_output_loss: 381.3371 - variance_output_loss: -16.1575 - val_loss: 332.9722 - val_mean_output_loss: 346.7776 - val_variance_output_loss: -13.8054\n",
            "Epoch 563/5000\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 364.9892 - mean_output_loss: 380.3256 - variance_output_loss: -15.3364 - val_loss: 331.9971 - val_mean_output_loss: 345.8065 - val_variance_output_loss: -13.8094\n",
            "Epoch 564/5000\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 363.0836 - mean_output_loss: 379.3120 - variance_output_loss: -16.2283 - val_loss: 331.0240 - val_mean_output_loss: 344.8374 - val_variance_output_loss: -13.8133\n",
            "Epoch 565/5000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 363.9509 - mean_output_loss: 378.2946 - variance_output_loss: -14.3437 - val_loss: 330.0537 - val_mean_output_loss: 343.8709 - val_variance_output_loss: -13.8172\n",
            "Epoch 566/5000\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 362.4375 - mean_output_loss: 377.2885 - variance_output_loss: -14.8510 - val_loss: 329.0840 - val_mean_output_loss: 342.9049 - val_variance_output_loss: -13.8210\n",
            "Epoch 567/5000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 360.8167 - mean_output_loss: 376.2824 - variance_output_loss: -15.4657 - val_loss: 328.1151 - val_mean_output_loss: 341.9399 - val_variance_output_loss: -13.8247\n",
            "Epoch 568/5000\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 361.0198 - mean_output_loss: 375.2780 - variance_output_loss: -14.2582 - val_loss: 327.1470 - val_mean_output_loss: 340.9755 - val_variance_output_loss: -13.8284\n",
            "Epoch 569/5000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 359.0497 - mean_output_loss: 374.2748 - variance_output_loss: -15.2251 - val_loss: 326.1800 - val_mean_output_loss: 340.0121 - val_variance_output_loss: -13.8321\n",
            "Epoch 570/5000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 358.8222 - mean_output_loss: 373.2678 - variance_output_loss: -14.4456 - val_loss: 325.2147 - val_mean_output_loss: 339.0503 - val_variance_output_loss: -13.8357\n",
            "Epoch 571/5000\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 358.4152 - mean_output_loss: 372.2610 - variance_output_loss: -13.8458 - val_loss: 324.2507 - val_mean_output_loss: 338.0899 - val_variance_output_loss: -13.8392\n",
            "Epoch 572/5000\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 355.8242 - mean_output_loss: 371.2621 - variance_output_loss: -15.4379 - val_loss: 323.2869 - val_mean_output_loss: 337.1296 - val_variance_output_loss: -13.8427\n",
            "Epoch 573/5000\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 355.2585 - mean_output_loss: 370.2584 - variance_output_loss: -15.0000 - val_loss: 322.3241 - val_mean_output_loss: 336.1703 - val_variance_output_loss: -13.8462\n",
            "Epoch 574/5000\n",
            "2/2 [==============================] - 0s 78ms/step - loss: 354.4379 - mean_output_loss: 369.2700 - variance_output_loss: -14.8321 - val_loss: 321.3604 - val_mean_output_loss: 335.2100 - val_variance_output_loss: -13.8496\n",
            "Epoch 575/5000\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 352.4308 - mean_output_loss: 368.2587 - variance_output_loss: -15.8280 - val_loss: 320.3996 - val_mean_output_loss: 334.2526 - val_variance_output_loss: -13.8530\n",
            "Epoch 576/5000\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 352.0198 - mean_output_loss: 367.2584 - variance_output_loss: -15.2387 - val_loss: 319.4395 - val_mean_output_loss: 333.2958 - val_variance_output_loss: -13.8563\n",
            "Epoch 577/5000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 350.8044 - mean_output_loss: 366.2665 - variance_output_loss: -15.4621 - val_loss: 318.4789 - val_mean_output_loss: 332.3385 - val_variance_output_loss: -13.8596\n",
            "Epoch 578/5000\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 351.5840 - mean_output_loss: 365.2612 - variance_output_loss: -13.6772 - val_loss: 317.5199 - val_mean_output_loss: 331.3828 - val_variance_output_loss: -13.8628\n",
            "Epoch 579/5000\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 350.2277 - mean_output_loss: 364.2683 - variance_output_loss: -14.0407 - val_loss: 316.5604 - val_mean_output_loss: 330.4264 - val_variance_output_loss: -13.8660\n",
            "Epoch 580/5000\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 349.2228 - mean_output_loss: 363.2741 - variance_output_loss: -14.0513 - val_loss: 315.6009 - val_mean_output_loss: 329.4701 - val_variance_output_loss: -13.8692\n",
            "Epoch 581/5000\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 345.0453 - mean_output_loss: 362.2701 - variance_output_loss: -17.2247 - val_loss: 314.6429 - val_mean_output_loss: 328.5152 - val_variance_output_loss: -13.8724\n",
            "Epoch 582/5000\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 345.3357 - mean_output_loss: 361.2722 - variance_output_loss: -15.9365 - val_loss: 313.6848 - val_mean_output_loss: 327.5603 - val_variance_output_loss: -13.8755\n",
            "Epoch 583/5000\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 344.2953 - mean_output_loss: 360.2849 - variance_output_loss: -15.9896 - val_loss: 312.7253 - val_mean_output_loss: 326.6038 - val_variance_output_loss: -13.8785\n",
            "Epoch 584/5000\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 345.0961 - mean_output_loss: 359.2863 - variance_output_loss: -14.1903 - val_loss: 311.7665 - val_mean_output_loss: 325.6481 - val_variance_output_loss: -13.8816\n",
            "Epoch 585/5000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 342.9375 - mean_output_loss: 358.2888 - variance_output_loss: -15.3513 - val_loss: 310.8082 - val_mean_output_loss: 324.6927 - val_variance_output_loss: -13.8846\n",
            "Epoch 586/5000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 343.1401 - mean_output_loss: 357.2804 - variance_output_loss: -14.1403 - val_loss: 309.8513 - val_mean_output_loss: 323.7389 - val_variance_output_loss: -13.8876\n",
            "Epoch 587/5000\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 341.2582 - mean_output_loss: 356.2834 - variance_output_loss: -15.0251 - val_loss: 308.8933 - val_mean_output_loss: 322.7838 - val_variance_output_loss: -13.8905\n",
            "Epoch 588/5000\n",
            "2/2 [==============================] - 0s 74ms/step - loss: 339.7965 - mean_output_loss: 355.2979 - variance_output_loss: -15.5013 - val_loss: 307.9325 - val_mean_output_loss: 321.8260 - val_variance_output_loss: -13.8934\n",
            "Epoch 589/5000\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 339.2826 - mean_output_loss: 354.2921 - variance_output_loss: -15.0095 - val_loss: 306.9726 - val_mean_output_loss: 320.8689 - val_variance_output_loss: -13.8963\n",
            "Epoch 590/5000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 338.9879 - mean_output_loss: 353.2980 - variance_output_loss: -14.3101 - val_loss: 306.0111 - val_mean_output_loss: 319.9103 - val_variance_output_loss: -13.8992\n",
            "Epoch 591/5000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 337.5382 - mean_output_loss: 352.2906 - variance_output_loss: -14.7524 - val_loss: 305.0501 - val_mean_output_loss: 318.9521 - val_variance_output_loss: -13.9020\n",
            "Epoch 592/5000\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 337.8071 - mean_output_loss: 351.2879 - variance_output_loss: -13.4808 - val_loss: 304.0881 - val_mean_output_loss: 317.9930 - val_variance_output_loss: -13.9048\n",
            "Epoch 593/5000\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 333.6530 - mean_output_loss: 350.2922 - variance_output_loss: -16.6391 - val_loss: 303.1239 - val_mean_output_loss: 317.0315 - val_variance_output_loss: -13.9076\n",
            "Epoch 594/5000\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 333.7925 - mean_output_loss: 349.2841 - variance_output_loss: -15.4916 - val_loss: 302.1593 - val_mean_output_loss: 316.0697 - val_variance_output_loss: -13.9104\n",
            "Epoch 595/5000\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 333.4298 - mean_output_loss: 348.2796 - variance_output_loss: -14.8498 - val_loss: 301.1933 - val_mean_output_loss: 315.1064 - val_variance_output_loss: -13.9131\n",
            "Epoch 596/5000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 332.9499 - mean_output_loss: 347.2810 - variance_output_loss: -14.3310 - val_loss: 300.2249 - val_mean_output_loss: 314.1407 - val_variance_output_loss: -13.9158\n",
            "Epoch 597/5000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 331.6142 - mean_output_loss: 346.2622 - variance_output_loss: -14.6480 - val_loss: 299.2571 - val_mean_output_loss: 313.1757 - val_variance_output_loss: -13.9185\n",
            "Epoch 598/5000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 328.6849 - mean_output_loss: 345.2482 - variance_output_loss: -16.5633 - val_loss: 298.2880 - val_mean_output_loss: 312.2092 - val_variance_output_loss: -13.9212\n",
            "Epoch 599/5000\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 328.3083 - mean_output_loss: 344.2426 - variance_output_loss: -15.9343 - val_loss: 297.3157 - val_mean_output_loss: 311.2396 - val_variance_output_loss: -13.9238\n",
            "Epoch 600/5000\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 328.2048 - mean_output_loss: 343.2314 - variance_output_loss: -15.0266 - val_loss: 296.3412 - val_mean_output_loss: 310.2677 - val_variance_output_loss: -13.9265\n",
            "Epoch 601/5000\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 328.0209 - mean_output_loss: 342.2172 - variance_output_loss: -14.1963 - val_loss: 295.3649 - val_mean_output_loss: 309.2939 - val_variance_output_loss: -13.9291\n",
            "Epoch 602/5000\n",
            "2/2 [==============================] - 0s 73ms/step - loss: 325.9183 - mean_output_loss: 341.1954 - variance_output_loss: -15.2771 - val_loss: 294.3874 - val_mean_output_loss: 308.3191 - val_variance_output_loss: -13.9317\n",
            "Epoch 603/5000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 324.8030 - mean_output_loss: 340.1837 - variance_output_loss: -15.3806 - val_loss: 293.4068 - val_mean_output_loss: 307.3411 - val_variance_output_loss: -13.9342\n",
            "Epoch 604/5000\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 323.0391 - mean_output_loss: 339.1542 - variance_output_loss: -16.1151 - val_loss: 292.4259 - val_mean_output_loss: 306.3627 - val_variance_output_loss: -13.9368\n",
            "Epoch 605/5000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 323.4253 - mean_output_loss: 338.1348 - variance_output_loss: -14.7095 - val_loss: 291.4424 - val_mean_output_loss: 305.3817 - val_variance_output_loss: -13.9393\n",
            "Epoch 606/5000\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 322.9199 - mean_output_loss: 337.1125 - variance_output_loss: -14.1926 - val_loss: 290.4567 - val_mean_output_loss: 304.3985 - val_variance_output_loss: -13.9418\n",
            "Epoch 607/5000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 320.3869 - mean_output_loss: 336.0787 - variance_output_loss: -15.6919 - val_loss: 289.4703 - val_mean_output_loss: 303.4146 - val_variance_output_loss: -13.9443\n",
            "Epoch 608/5000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 319.8878 - mean_output_loss: 335.0572 - variance_output_loss: -15.1694 - val_loss: 288.4809 - val_mean_output_loss: 302.4276 - val_variance_output_loss: -13.9467\n",
            "Epoch 609/5000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 319.2240 - mean_output_loss: 334.0202 - variance_output_loss: -14.7962 - val_loss: 287.4910 - val_mean_output_loss: 301.4401 - val_variance_output_loss: -13.9491\n",
            "Epoch 610/5000\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 319.5621 - mean_output_loss: 332.9898 - variance_output_loss: -13.4278 - val_loss: 286.4989 - val_mean_output_loss: 300.4504 - val_variance_output_loss: -13.9515\n",
            "Epoch 611/5000\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 316.7735 - mean_output_loss: 331.9527 - variance_output_loss: -15.1792 - val_loss: 285.5057 - val_mean_output_loss: 299.4596 - val_variance_output_loss: -13.9539\n",
            "Epoch 612/5000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 316.7271 - mean_output_loss: 330.9174 - variance_output_loss: -14.1903 - val_loss: 284.5107 - val_mean_output_loss: 298.4670 - val_variance_output_loss: -13.9563\n",
            "Epoch 613/5000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 314.9889 - mean_output_loss: 329.8716 - variance_output_loss: -14.8828 - val_loss: 283.5152 - val_mean_output_loss: 297.4738 - val_variance_output_loss: -13.9586\n",
            "Epoch 614/5000\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 313.8633 - mean_output_loss: 328.8361 - variance_output_loss: -14.9728 - val_loss: 282.5173 - val_mean_output_loss: 296.4781 - val_variance_output_loss: -13.9609\n",
            "Epoch 615/5000\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 313.1992 - mean_output_loss: 327.7955 - variance_output_loss: -14.5963 - val_loss: 281.5177 - val_mean_output_loss: 295.4808 - val_variance_output_loss: -13.9632\n",
            "Epoch 616/5000\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 312.9557 - mean_output_loss: 326.7567 - variance_output_loss: -13.8010 - val_loss: 280.5165 - val_mean_output_loss: 294.4819 - val_variance_output_loss: -13.9654\n",
            "Epoch 617/5000\n",
            "2/2 [==============================] - 0s 77ms/step - loss: 310.1395 - mean_output_loss: 325.7089 - variance_output_loss: -15.5694 - val_loss: 279.5152 - val_mean_output_loss: 293.4828 - val_variance_output_loss: -13.9676\n",
            "Epoch 618/5000\n",
            "2/2 [==============================] - 0s 77ms/step - loss: 310.8564 - mean_output_loss: 324.6619 - variance_output_loss: -13.8054 - val_loss: 278.5135 - val_mean_output_loss: 292.4833 - val_variance_output_loss: -13.9698\n",
            "Epoch 619/5000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 309.4180 - mean_output_loss: 323.6180 - variance_output_loss: -14.2000 - val_loss: 277.5110 - val_mean_output_loss: 291.4830 - val_variance_output_loss: -13.9719\n",
            "Epoch 620/5000\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 307.8382 - mean_output_loss: 322.5674 - variance_output_loss: -14.7292 - val_loss: 276.5089 - val_mean_output_loss: 290.4829 - val_variance_output_loss: -13.9741\n",
            "Epoch 621/5000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 306.3896 - mean_output_loss: 321.5194 - variance_output_loss: -15.1298 - val_loss: 275.5064 - val_mean_output_loss: 289.4826 - val_variance_output_loss: -13.9762\n",
            "Epoch 622/5000\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 306.2600 - mean_output_loss: 320.4804 - variance_output_loss: -14.2204 - val_loss: 274.5027 - val_mean_output_loss: 288.4809 - val_variance_output_loss: -13.9782\n",
            "Epoch 623/5000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 303.5913 - mean_output_loss: 319.4240 - variance_output_loss: -15.8327 - val_loss: 273.5009 - val_mean_output_loss: 287.4811 - val_variance_output_loss: -13.9802\n",
            "Epoch 624/5000\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 303.7866 - mean_output_loss: 318.3876 - variance_output_loss: -14.6010 - val_loss: 272.4980 - val_mean_output_loss: 286.4802 - val_variance_output_loss: -13.9822\n",
            "Epoch 625/5000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 302.1808 - mean_output_loss: 317.3288 - variance_output_loss: -15.1480 - val_loss: 271.4980 - val_mean_output_loss: 285.4822 - val_variance_output_loss: -13.9842\n",
            "Epoch 626/5000\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 301.9326 - mean_output_loss: 316.2846 - variance_output_loss: -14.3521 - val_loss: 270.4983 - val_mean_output_loss: 284.4844 - val_variance_output_loss: -13.9861\n",
            "Epoch 627/5000\n",
            "2/2 [==============================] - 0s 66ms/step - loss: 300.4485 - mean_output_loss: 315.2442 - variance_output_loss: -14.7957 - val_loss: 269.4989 - val_mean_output_loss: 283.4869 - val_variance_output_loss: -13.9880\n",
            "Epoch 628/5000\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 299.3961 - mean_output_loss: 314.1986 - variance_output_loss: -14.8025 - val_loss: 268.5011 - val_mean_output_loss: 282.4910 - val_variance_output_loss: -13.9899\n",
            "Epoch 629/5000\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 298.0467 - mean_output_loss: 313.1606 - variance_output_loss: -15.1138 - val_loss: 267.5045 - val_mean_output_loss: 281.4962 - val_variance_output_loss: -13.9917\n",
            "Epoch 630/5000\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 295.7149 - mean_output_loss: 312.1088 - variance_output_loss: -16.3940 - val_loss: 266.5114 - val_mean_output_loss: 280.5049 - val_variance_output_loss: -13.9935\n",
            "Epoch 631/5000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 297.0682 - mean_output_loss: 311.0742 - variance_output_loss: -14.0060 - val_loss: 265.5190 - val_mean_output_loss: 279.5142 - val_variance_output_loss: -13.9952\n",
            "Epoch 632/5000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 295.5046 - mean_output_loss: 310.0418 - variance_output_loss: -14.5372 - val_loss: 264.5280 - val_mean_output_loss: 278.5250 - val_variance_output_loss: -13.9969\n",
            "Epoch 633/5000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 293.1168 - mean_output_loss: 309.0114 - variance_output_loss: -15.8946 - val_loss: 263.5392 - val_mean_output_loss: 277.5378 - val_variance_output_loss: -13.9986\n",
            "Epoch 634/5000\n",
            "2/2 [==============================] - 0s 69ms/step - loss: 293.4800 - mean_output_loss: 307.9754 - variance_output_loss: -14.4954 - val_loss: 262.5540 - val_mean_output_loss: 276.5543 - val_variance_output_loss: -14.0003\n",
            "Epoch 635/5000\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 291.5527 - mean_output_loss: 306.9471 - variance_output_loss: -15.3943 - val_loss: 261.5717 - val_mean_output_loss: 275.5736 - val_variance_output_loss: -14.0019\n",
            "Epoch 636/5000\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 291.6173 - mean_output_loss: 305.9225 - variance_output_loss: -14.3052 - val_loss: 260.5926 - val_mean_output_loss: 274.5960 - val_variance_output_loss: -14.0035\n",
            "Epoch 637/5000\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 289.3682 - mean_output_loss: 304.8882 - variance_output_loss: -15.5200 - val_loss: 259.6183 - val_mean_output_loss: 273.6233 - val_variance_output_loss: -14.0050\n",
            "Epoch 638/5000\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 288.8716 - mean_output_loss: 303.8693 - variance_output_loss: -14.9977 - val_loss: 258.6462 - val_mean_output_loss: 272.6528 - val_variance_output_loss: -14.0066\n",
            "Epoch 639/5000\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 288.1077 - mean_output_loss: 302.8584 - variance_output_loss: -14.7507 - val_loss: 257.6762 - val_mean_output_loss: 271.6843 - val_variance_output_loss: -14.0081\n",
            "Epoch 640/5000\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 288.5259 - mean_output_loss: 301.8422 - variance_output_loss: -13.3163 - val_loss: 256.7099 - val_mean_output_loss: 270.7195 - val_variance_output_loss: -14.0095\n",
            "Epoch 641/5000\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 285.5716 - mean_output_loss: 300.8308 - variance_output_loss: -15.2593 - val_loss: 255.7470 - val_mean_output_loss: 269.7579 - val_variance_output_loss: -14.0110\n",
            "Epoch 642/5000\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 285.5302 - mean_output_loss: 299.8362 - variance_output_loss: -14.3060 - val_loss: 254.7859 - val_mean_output_loss: 268.7982 - val_variance_output_loss: -14.0124\n",
            "Epoch 643/5000\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 283.4276 - mean_output_loss: 298.8202 - variance_output_loss: -15.3925 - val_loss: 253.8308 - val_mean_output_loss: 267.8446 - val_variance_output_loss: -14.0137\n",
            "Epoch 644/5000\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 283.0813 - mean_output_loss: 297.8218 - variance_output_loss: -14.7405 - val_loss: 252.8791 - val_mean_output_loss: 266.8942 - val_variance_output_loss: -14.0151\n",
            "Epoch 645/5000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 283.0214 - mean_output_loss: 296.8335 - variance_output_loss: -13.8122 - val_loss: 251.9300 - val_mean_output_loss: 265.9464 - val_variance_output_loss: -14.0164\n",
            "Epoch 646/5000\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 281.0933 - mean_output_loss: 295.8368 - variance_output_loss: -14.7435 - val_loss: 250.9858 - val_mean_output_loss: 265.0035 - val_variance_output_loss: -14.0177\n",
            "Epoch 647/5000\n",
            "2/2 [==============================] - 0s 91ms/step - loss: 281.1932 - mean_output_loss: 294.8495 - variance_output_loss: -13.6563 - val_loss: 250.0453 - val_mean_output_loss: 264.0643 - val_variance_output_loss: -14.0190\n",
            "Epoch 648/5000\n",
            "2/2 [==============================] - 0s 82ms/step - loss: 278.8137 - mean_output_loss: 293.8747 - variance_output_loss: -15.0610 - val_loss: 249.1077 - val_mean_output_loss: 263.1280 - val_variance_output_loss: -14.0202\n",
            "Epoch 649/5000\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 278.1292 - mean_output_loss: 292.8827 - variance_output_loss: -14.7535 - val_loss: 248.1764 - val_mean_output_loss: 262.1978 - val_variance_output_loss: -14.0215\n",
            "Epoch 650/5000\n",
            "2/2 [==============================] - 0s 67ms/step - loss: 276.4711 - mean_output_loss: 291.9064 - variance_output_loss: -15.4353 - val_loss: 247.2486 - val_mean_output_loss: 261.2712 - val_variance_output_loss: -14.0227\n",
            "Epoch 651/5000\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 276.3611 - mean_output_loss: 290.9294 - variance_output_loss: -14.5683 - val_loss: 246.3249 - val_mean_output_loss: 260.3488 - val_variance_output_loss: -14.0238\n",
            "Epoch 652/5000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 274.1731 - mean_output_loss: 289.9745 - variance_output_loss: -15.8014 - val_loss: 245.4026 - val_mean_output_loss: 259.4276 - val_variance_output_loss: -14.0250\n",
            "Epoch 653/5000\n",
            "2/2 [==============================] - 0s 80ms/step - loss: 273.3590 - mean_output_loss: 289.0039 - variance_output_loss: -15.6449 - val_loss: 244.4854 - val_mean_output_loss: 258.5115 - val_variance_output_loss: -14.0261\n",
            "Epoch 654/5000\n",
            "2/2 [==============================] - 0s 91ms/step - loss: 272.3672 - mean_output_loss: 288.0439 - variance_output_loss: -15.6768 - val_loss: 243.5716 - val_mean_output_loss: 257.5989 - val_variance_output_loss: -14.0272\n",
            "Epoch 655/5000\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 271.9743 - mean_output_loss: 287.0914 - variance_output_loss: -15.1171 - val_loss: 242.6611 - val_mean_output_loss: 256.6895 - val_variance_output_loss: -14.0283\n",
            "Epoch 656/5000\n",
            "2/2 [==============================] - 0s 70ms/step - loss: 270.2209 - mean_output_loss: 286.1261 - variance_output_loss: -15.9052 - val_loss: 241.7563 - val_mean_output_loss: 255.7857 - val_variance_output_loss: -14.0294\n",
            "Epoch 657/5000\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 269.4243 - mean_output_loss: 285.1889 - variance_output_loss: -15.7646 - val_loss: 240.8530 - val_mean_output_loss: 254.8834 - val_variance_output_loss: -14.0305\n",
            "Epoch 658/5000\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 269.1997 - mean_output_loss: 284.2355 - variance_output_loss: -15.0358 - val_loss: 239.9547 - val_mean_output_loss: 253.9861 - val_variance_output_loss: -14.0315\n",
            "Epoch 659/5000\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 269.0744 - mean_output_loss: 283.3041 - variance_output_loss: -14.2298 - val_loss: 239.0583 - val_mean_output_loss: 253.0908 - val_variance_output_loss: -14.0325\n",
            "Epoch 660/5000\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 266.9830 - mean_output_loss: 282.3588 - variance_output_loss: -15.3758 - val_loss: 238.1673 - val_mean_output_loss: 252.2007 - val_variance_output_loss: -14.0335\n",
            "Epoch 661/5000\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 266.0440 - mean_output_loss: 281.4278 - variance_output_loss: -15.3838 - val_loss: 237.2793 - val_mean_output_loss: 251.3138 - val_variance_output_loss: -14.0345\n",
            "Epoch 662/5000\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 265.0500 - mean_output_loss: 280.4948 - variance_output_loss: -15.4447 - val_loss: 236.3954 - val_mean_output_loss: 250.4309 - val_variance_output_loss: -14.0355\n",
            "Epoch 663/5000\n",
            "2/2 [==============================] - 0s 82ms/step - loss: 262.4993 - mean_output_loss: 279.5678 - variance_output_loss: -17.0685 - val_loss: 235.5153 - val_mean_output_loss: 249.5517 - val_variance_output_loss: -14.0364\n",
            "Epoch 664/5000\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 263.8286 - mean_output_loss: 278.6501 - variance_output_loss: -14.8215 - val_loss: 234.6378 - val_mean_output_loss: 248.6751 - val_variance_output_loss: -14.0373\n",
            "Epoch 665/5000\n",
            "2/2 [==============================] - 0s 68ms/step - loss: 262.9192 - mean_output_loss: 277.7289 - variance_output_loss: -14.8096 - val_loss: 233.7645 - val_mean_output_loss: 247.8028 - val_variance_output_loss: -14.0383\n",
            "Epoch 666/5000\n",
            "2/2 [==============================] - 0s 66ms/step - loss: 262.2187 - mean_output_loss: 276.8127 - variance_output_loss: -14.5940 - val_loss: 232.8949 - val_mean_output_loss: 246.9341 - val_variance_output_loss: -14.0392\n",
            "Epoch 667/5000\n",
            "2/2 [==============================] - 0s 79ms/step - loss: 260.5396 - mean_output_loss: 275.9030 - variance_output_loss: -15.3633 - val_loss: 232.0287 - val_mean_output_loss: 246.0688 - val_variance_output_loss: -14.0401\n",
            "Epoch 668/5000\n",
            "2/2 [==============================] - 0s 66ms/step - loss: 259.6393 - mean_output_loss: 274.9887 - variance_output_loss: -15.3495 - val_loss: 231.1669 - val_mean_output_loss: 245.2078 - val_variance_output_loss: -14.0409\n",
            "Epoch 669/5000\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 258.8560 - mean_output_loss: 274.0907 - variance_output_loss: -15.2347 - val_loss: 230.3074 - val_mean_output_loss: 244.3492 - val_variance_output_loss: -14.0418\n",
            "Epoch 670/5000\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 257.4590 - mean_output_loss: 273.1862 - variance_output_loss: -15.7271 - val_loss: 229.4519 - val_mean_output_loss: 243.4946 - val_variance_output_loss: -14.0427\n",
            "Epoch 671/5000\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 257.6767 - mean_output_loss: 272.2945 - variance_output_loss: -14.6178 - val_loss: 228.5991 - val_mean_output_loss: 242.6426 - val_variance_output_loss: -14.0435\n",
            "Epoch 672/5000\n",
            "2/2 [==============================] - 0s 72ms/step - loss: 256.7083 - mean_output_loss: 271.3979 - variance_output_loss: -14.6896 - val_loss: 227.7504 - val_mean_output_loss: 241.7947 - val_variance_output_loss: -14.0443\n",
            "Epoch 673/5000\n",
            "2/2 [==============================] - 0s 86ms/step - loss: 255.1000 - mean_output_loss: 270.5071 - variance_output_loss: -15.4071 - val_loss: 226.9053 - val_mean_output_loss: 240.9504 - val_variance_output_loss: -14.0451\n",
            "Epoch 674/5000\n",
            "2/2 [==============================] - 0s 70ms/step - loss: 255.9372 - mean_output_loss: 269.6157 - variance_output_loss: -13.6785 - val_loss: 226.0640 - val_mean_output_loss: 240.1100 - val_variance_output_loss: -14.0459\n",
            "Epoch 675/5000\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 254.2846 - mean_output_loss: 268.7362 - variance_output_loss: -14.4516 - val_loss: 225.2253 - val_mean_output_loss: 239.2720 - val_variance_output_loss: -14.0467\n",
            "Epoch 676/5000\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 254.1573 - mean_output_loss: 267.8550 - variance_output_loss: -13.6978 - val_loss: 224.3899 - val_mean_output_loss: 238.4374 - val_variance_output_loss: -14.0475\n",
            "Epoch 677/5000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 251.9155 - mean_output_loss: 266.9809 - variance_output_loss: -15.0654 - val_loss: 223.5573 - val_mean_output_loss: 237.6056 - val_variance_output_loss: -14.0483\n",
            "Epoch 678/5000\n",
            "2/2 [==============================] - 0s 74ms/step - loss: 249.7283 - mean_output_loss: 266.1055 - variance_output_loss: -16.3772 - val_loss: 222.7283 - val_mean_output_loss: 236.7774 - val_variance_output_loss: -14.0490\n",
            "Epoch 679/5000\n",
            "2/2 [==============================] - 0s 68ms/step - loss: 249.1252 - mean_output_loss: 265.2383 - variance_output_loss: -16.1131 - val_loss: 221.9022 - val_mean_output_loss: 235.9519 - val_variance_output_loss: -14.0498\n",
            "Epoch 680/5000\n",
            "2/2 [==============================] - 0s 75ms/step - loss: 249.9803 - mean_output_loss: 264.3694 - variance_output_loss: -14.3891 - val_loss: 221.0796 - val_mean_output_loss: 235.1301 - val_variance_output_loss: -14.0505\n",
            "Epoch 681/5000\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 247.8920 - mean_output_loss: 263.5092 - variance_output_loss: -15.6172 - val_loss: 220.2600 - val_mean_output_loss: 234.3112 - val_variance_output_loss: -14.0512\n",
            "Epoch 682/5000\n",
            "2/2 [==============================] - 0s 67ms/step - loss: 247.3357 - mean_output_loss: 262.6471 - variance_output_loss: -15.3113 - val_loss: 219.4439 - val_mean_output_loss: 233.4959 - val_variance_output_loss: -14.0520\n",
            "Epoch 683/5000\n",
            "2/2 [==============================] - 0s 71ms/step - loss: 246.9182 - mean_output_loss: 261.7936 - variance_output_loss: -14.8753 - val_loss: 218.6308 - val_mean_output_loss: 232.6835 - val_variance_output_loss: -14.0527\n",
            "Epoch 684/5000\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 245.7605 - mean_output_loss: 260.9401 - variance_output_loss: -15.1795 - val_loss: 217.8212 - val_mean_output_loss: 231.8745 - val_variance_output_loss: -14.0534\n",
            "Epoch 685/5000\n",
            "2/2 [==============================] - 0s 75ms/step - loss: 246.6913 - mean_output_loss: 260.0903 - variance_output_loss: -13.3990 - val_loss: 217.0150 - val_mean_output_loss: 231.0690 - val_variance_output_loss: -14.0540\n",
            "Epoch 686/5000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 244.2598 - mean_output_loss: 259.2432 - variance_output_loss: -14.9834 - val_loss: 216.2123 - val_mean_output_loss: 230.2670 - val_variance_output_loss: -14.0547\n",
            "Epoch 687/5000\n",
            "2/2 [==============================] - 0s 78ms/step - loss: 243.3605 - mean_output_loss: 258.3944 - variance_output_loss: -15.0339 - val_loss: 215.4134 - val_mean_output_loss: 229.4688 - val_variance_output_loss: -14.0554\n",
            "Epoch 688/5000\n",
            "2/2 [==============================] - 0s 69ms/step - loss: 242.4081 - mean_output_loss: 257.5614 - variance_output_loss: -15.1532 - val_loss: 214.6164 - val_mean_output_loss: 228.6724 - val_variance_output_loss: -14.0561\n",
            "Epoch 689/5000\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 242.4280 - mean_output_loss: 256.7155 - variance_output_loss: -14.2875 - val_loss: 213.8237 - val_mean_output_loss: 227.8804 - val_variance_output_loss: -14.0567\n",
            "Epoch 690/5000\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 240.1345 - mean_output_loss: 255.8832 - variance_output_loss: -15.7487 - val_loss: 213.0333 - val_mean_output_loss: 227.0906 - val_variance_output_loss: -14.0574\n",
            "Epoch 691/5000\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 241.5316 - mean_output_loss: 255.0553 - variance_output_loss: -13.5237 - val_loss: 212.2449 - val_mean_output_loss: 226.3029 - val_variance_output_loss: -14.0580\n",
            "Epoch 692/5000\n",
            "2/2 [==============================] - 0s 71ms/step - loss: 239.0569 - mean_output_loss: 254.2201 - variance_output_loss: -15.1631 - val_loss: 211.4602 - val_mean_output_loss: 225.5188 - val_variance_output_loss: -14.0586\n",
            "Epoch 693/5000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 239.6046 - mean_output_loss: 253.4016 - variance_output_loss: -13.7969 - val_loss: 210.6768 - val_mean_output_loss: 224.7361 - val_variance_output_loss: -14.0592\n",
            "Epoch 694/5000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 237.3344 - mean_output_loss: 252.5816 - variance_output_loss: -15.2472 - val_loss: 209.8961 - val_mean_output_loss: 223.9559 - val_variance_output_loss: -14.0599\n",
            "Epoch 695/5000\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 237.7427 - mean_output_loss: 251.7512 - variance_output_loss: -14.0085 - val_loss: 209.1197 - val_mean_output_loss: 223.1801 - val_variance_output_loss: -14.0605\n",
            "Epoch 696/5000\n",
            "2/2 [==============================] - 0s 79ms/step - loss: 236.1998 - mean_output_loss: 250.9460 - variance_output_loss: -14.7462 - val_loss: 208.3441 - val_mean_output_loss: 222.4051 - val_variance_output_loss: -14.0611\n",
            "Epoch 697/5000\n",
            "2/2 [==============================] - 0s 101ms/step - loss: 235.9612 - mean_output_loss: 250.1282 - variance_output_loss: -14.1670 - val_loss: 207.5722 - val_mean_output_loss: 221.6339 - val_variance_output_loss: -14.0616\n",
            "Epoch 698/5000\n",
            "2/2 [==============================] - 0s 80ms/step - loss: 234.7759 - mean_output_loss: 249.3135 - variance_output_loss: -14.5376 - val_loss: 206.8038 - val_mean_output_loss: 220.8660 - val_variance_output_loss: -14.0622\n",
            "Epoch 699/5000\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 234.4162 - mean_output_loss: 248.5102 - variance_output_loss: -14.0940 - val_loss: 206.0374 - val_mean_output_loss: 220.1002 - val_variance_output_loss: -14.0628\n",
            "Epoch 700/5000\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 232.6840 - mean_output_loss: 247.7044 - variance_output_loss: -15.0204 - val_loss: 205.2742 - val_mean_output_loss: 219.3375 - val_variance_output_loss: -14.0634\n",
            "Epoch 701/5000\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 232.3504 - mean_output_loss: 246.9024 - variance_output_loss: -14.5520 - val_loss: 204.5139 - val_mean_output_loss: 218.5778 - val_variance_output_loss: -14.0639\n",
            "Epoch 702/5000\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 230.6958 - mean_output_loss: 246.1000 - variance_output_loss: -15.4042 - val_loss: 203.7570 - val_mean_output_loss: 217.8215 - val_variance_output_loss: -14.0645\n",
            "Epoch 703/5000\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 229.9375 - mean_output_loss: 245.3015 - variance_output_loss: -15.3640 - val_loss: 203.0031 - val_mean_output_loss: 217.0681 - val_variance_output_loss: -14.0651\n",
            "Epoch 704/5000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 230.3779 - mean_output_loss: 244.5121 - variance_output_loss: -14.1342 - val_loss: 202.2511 - val_mean_output_loss: 216.3167 - val_variance_output_loss: -14.0656\n",
            "Epoch 705/5000\n",
            "2/2 [==============================] - 0s 72ms/step - loss: 228.0795 - mean_output_loss: 243.7158 - variance_output_loss: -15.6363 - val_loss: 201.5026 - val_mean_output_loss: 215.5688 - val_variance_output_loss: -14.0661\n",
            "Epoch 706/5000\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 228.3671 - mean_output_loss: 242.9337 - variance_output_loss: -14.5666 - val_loss: 200.7558 - val_mean_output_loss: 214.8224 - val_variance_output_loss: -14.0667\n",
            "Epoch 707/5000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 226.3547 - mean_output_loss: 242.1373 - variance_output_loss: -15.7826 - val_loss: 200.0131 - val_mean_output_loss: 214.0803 - val_variance_output_loss: -14.0672\n",
            "Epoch 708/5000\n",
            "2/2 [==============================] - 0s 66ms/step - loss: 225.4003 - mean_output_loss: 241.3646 - variance_output_loss: -15.9643 - val_loss: 199.2710 - val_mean_output_loss: 213.3387 - val_variance_output_loss: -14.0677\n",
            "Epoch 709/5000\n",
            "2/2 [==============================] - 0s 67ms/step - loss: 225.0354 - mean_output_loss: 240.5794 - variance_output_loss: -15.5441 - val_loss: 198.5323 - val_mean_output_loss: 212.6005 - val_variance_output_loss: -14.0682\n",
            "Epoch 710/5000\n",
            "2/2 [==============================] - 0s 70ms/step - loss: 225.9314 - mean_output_loss: 239.8027 - variance_output_loss: -13.8714 - val_loss: 197.7958 - val_mean_output_loss: 211.8645 - val_variance_output_loss: -14.0687\n",
            "Epoch 711/5000\n",
            "2/2 [==============================] - 0s 92ms/step - loss: 224.7223 - mean_output_loss: 239.0230 - variance_output_loss: -14.3007 - val_loss: 197.0623 - val_mean_output_loss: 211.1316 - val_variance_output_loss: -14.0693\n",
            "Epoch 712/5000\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 222.6592 - mean_output_loss: 238.2653 - variance_output_loss: -15.6062 - val_loss: 196.3292 - val_mean_output_loss: 210.3989 - val_variance_output_loss: -14.0698\n",
            "Epoch 713/5000\n",
            "2/2 [==============================] - 0s 66ms/step - loss: 223.7696 - mean_output_loss: 237.4855 - variance_output_loss: -13.7158 - val_loss: 195.6006 - val_mean_output_loss: 209.6709 - val_variance_output_loss: -14.0702\n",
            "Epoch 714/5000\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 223.0500 - mean_output_loss: 236.7160 - variance_output_loss: -13.6660 - val_loss: 194.8750 - val_mean_output_loss: 208.9457 - val_variance_output_loss: -14.0707\n",
            "Epoch 715/5000\n",
            "2/2 [==============================] - 0s 73ms/step - loss: 220.5605 - mean_output_loss: 235.9474 - variance_output_loss: -15.3869 - val_loss: 194.1522 - val_mean_output_loss: 208.2234 - val_variance_output_loss: -14.0712\n",
            "Epoch 716/5000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 219.0482 - mean_output_loss: 235.1907 - variance_output_loss: -16.1425 - val_loss: 193.4306 - val_mean_output_loss: 207.5023 - val_variance_output_loss: -14.0717\n",
            "Epoch 717/5000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 219.8277 - mean_output_loss: 234.4318 - variance_output_loss: -14.6041 - val_loss: 192.7115 - val_mean_output_loss: 206.7837 - val_variance_output_loss: -14.0722\n",
            "Epoch 718/5000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 218.5625 - mean_output_loss: 233.6691 - variance_output_loss: -15.1065 - val_loss: 191.9955 - val_mean_output_loss: 206.0682 - val_variance_output_loss: -14.0726\n",
            "Epoch 719/5000\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 218.1990 - mean_output_loss: 232.9213 - variance_output_loss: -14.7223 - val_loss: 191.2808 - val_mean_output_loss: 205.3539 - val_variance_output_loss: -14.0731\n",
            "Epoch 720/5000\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 216.7615 - mean_output_loss: 232.1662 - variance_output_loss: -15.4047 - val_loss: 190.5691 - val_mean_output_loss: 204.6427 - val_variance_output_loss: -14.0736\n",
            "Epoch 721/5000\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 216.7376 - mean_output_loss: 231.4122 - variance_output_loss: -14.6746 - val_loss: 189.8605 - val_mean_output_loss: 203.9345 - val_variance_output_loss: -14.0740\n",
            "Epoch 722/5000\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 216.0983 - mean_output_loss: 230.6734 - variance_output_loss: -14.5750 - val_loss: 189.1528 - val_mean_output_loss: 203.2273 - val_variance_output_loss: -14.0745\n",
            "Epoch 723/5000\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 215.2194 - mean_output_loss: 229.9207 - variance_output_loss: -14.7013 - val_loss: 188.4491 - val_mean_output_loss: 202.5240 - val_variance_output_loss: -14.0749\n",
            "Epoch 724/5000\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 212.7576 - mean_output_loss: 229.1797 - variance_output_loss: -16.4221 - val_loss: 187.7473 - val_mean_output_loss: 201.8226 - val_variance_output_loss: -14.0754\n",
            "Epoch 725/5000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 212.7858 - mean_output_loss: 228.4445 - variance_output_loss: -15.6587 - val_loss: 187.0472 - val_mean_output_loss: 201.1230 - val_variance_output_loss: -14.0758\n",
            "Epoch 726/5000\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 213.4710 - mean_output_loss: 227.7071 - variance_output_loss: -14.2361 - val_loss: 186.3497 - val_mean_output_loss: 200.4259 - val_variance_output_loss: -14.0762\n",
            "Epoch 727/5000\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 211.4355 - mean_output_loss: 226.9645 - variance_output_loss: -15.5290 - val_loss: 185.6559 - val_mean_output_loss: 199.7326 - val_variance_output_loss: -14.0767\n",
            "Epoch 728/5000\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 212.8346 - mean_output_loss: 226.2295 - variance_output_loss: -13.3949 - val_loss: 184.9643 - val_mean_output_loss: 199.0414 - val_variance_output_loss: -14.0771\n",
            "Epoch 729/5000\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 212.1212 - mean_output_loss: 225.5040 - variance_output_loss: -13.3827 - val_loss: 184.2739 - val_mean_output_loss: 198.3514 - val_variance_output_loss: -14.0775\n",
            "Epoch 730/5000\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 208.6924 - mean_output_loss: 224.7764 - variance_output_loss: -16.0841 - val_loss: 183.5855 - val_mean_output_loss: 197.6635 - val_variance_output_loss: -14.0779\n",
            "Epoch 731/5000\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 208.9467 - mean_output_loss: 224.0506 - variance_output_loss: -15.1039 - val_loss: 182.8994 - val_mean_output_loss: 196.9778 - val_variance_output_loss: -14.0783\n",
            "Epoch 732/5000\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 208.2760 - mean_output_loss: 223.3209 - variance_output_loss: -15.0449 - val_loss: 182.2163 - val_mean_output_loss: 196.2950 - val_variance_output_loss: -14.0787\n",
            "Epoch 733/5000\n",
            "2/2 [==============================] - 0s 69ms/step - loss: 208.7675 - mean_output_loss: 222.6100 - variance_output_loss: -13.8425 - val_loss: 181.5336 - val_mean_output_loss: 195.6127 - val_variance_output_loss: -14.0791\n",
            "Epoch 734/5000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 206.9169 - mean_output_loss: 221.8862 - variance_output_loss: -14.9692 - val_loss: 180.8542 - val_mean_output_loss: 194.9337 - val_variance_output_loss: -14.0795\n",
            "Epoch 735/5000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 206.4890 - mean_output_loss: 221.1616 - variance_output_loss: -14.6725 - val_loss: 180.1780 - val_mean_output_loss: 194.2579 - val_variance_output_loss: -14.0799\n",
            "Epoch 736/5000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 204.6603 - mean_output_loss: 220.4567 - variance_output_loss: -15.7965 - val_loss: 179.5022 - val_mean_output_loss: 193.5826 - val_variance_output_loss: -14.0803\n",
            "Epoch 737/5000\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 204.5893 - mean_output_loss: 219.7480 - variance_output_loss: -15.1586 - val_loss: 178.8286 - val_mean_output_loss: 192.9093 - val_variance_output_loss: -14.0807\n",
            "Epoch 738/5000\n",
            "2/2 [==============================] - 0s 73ms/step - loss: 205.0318 - mean_output_loss: 219.0288 - variance_output_loss: -13.9971 - val_loss: 178.1588 - val_mean_output_loss: 192.2399 - val_variance_output_loss: -14.0811\n",
            "Epoch 739/5000\n",
            "2/2 [==============================] - 0s 70ms/step - loss: 203.4375 - mean_output_loss: 218.3273 - variance_output_loss: -14.8898 - val_loss: 177.4904 - val_mean_output_loss: 191.5719 - val_variance_output_loss: -14.0815\n",
            "Epoch 740/5000\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 202.1701 - mean_output_loss: 217.6166 - variance_output_loss: -15.4465 - val_loss: 176.8251 - val_mean_output_loss: 190.9070 - val_variance_output_loss: -14.0819\n",
            "Epoch 741/5000\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 202.0078 - mean_output_loss: 216.9184 - variance_output_loss: -14.9106 - val_loss: 176.1613 - val_mean_output_loss: 190.2435 - val_variance_output_loss: -14.0822\n",
            "Epoch 742/5000\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 200.8576 - mean_output_loss: 216.2118 - variance_output_loss: -15.3542 - val_loss: 175.5006 - val_mean_output_loss: 189.5833 - val_variance_output_loss: -14.0826\n",
            "Epoch 743/5000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 199.8474 - mean_output_loss: 215.5175 - variance_output_loss: -15.6700 - val_loss: 174.8414 - val_mean_output_loss: 188.9243 - val_variance_output_loss: -14.0830\n",
            "Epoch 744/5000\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 199.6579 - mean_output_loss: 214.8200 - variance_output_loss: -15.1621 - val_loss: 174.1844 - val_mean_output_loss: 188.2678 - val_variance_output_loss: -14.0834\n",
            "Epoch 745/5000\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 198.8398 - mean_output_loss: 214.1219 - variance_output_loss: -15.2821 - val_loss: 173.5301 - val_mean_output_loss: 187.6138 - val_variance_output_loss: -14.0837\n",
            "Epoch 746/5000\n",
            "2/2 [==============================] - 0s 77ms/step - loss: 198.3143 - mean_output_loss: 213.4380 - variance_output_loss: -15.1237 - val_loss: 172.8765 - val_mean_output_loss: 186.9605 - val_variance_output_loss: -14.0841\n",
            "Epoch 747/5000\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 198.0654 - mean_output_loss: 212.7447 - variance_output_loss: -14.6793 - val_loss: 172.2257 - val_mean_output_loss: 186.3102 - val_variance_output_loss: -14.0844\n",
            "Epoch 748/5000\n",
            "2/2 [==============================] - 0s 73ms/step - loss: 197.6138 - mean_output_loss: 212.0555 - variance_output_loss: -14.4417 - val_loss: 171.5773 - val_mean_output_loss: 185.6621 - val_variance_output_loss: -14.0848\n",
            "Epoch 749/5000\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 196.6251 - mean_output_loss: 211.3681 - variance_output_loss: -14.7430 - val_loss: 170.9312 - val_mean_output_loss: 185.0163 - val_variance_output_loss: -14.0851\n",
            "Epoch 750/5000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 196.1681 - mean_output_loss: 210.6859 - variance_output_loss: -14.5179 - val_loss: 170.2867 - val_mean_output_loss: 184.3721 - val_variance_output_loss: -14.0855\n",
            "Epoch 751/5000\n",
            "2/2 [==============================] - 0s 74ms/step - loss: 194.5659 - mean_output_loss: 210.0062 - variance_output_loss: -15.4403 - val_loss: 169.6438 - val_mean_output_loss: 183.7297 - val_variance_output_loss: -14.0858\n",
            "Epoch 752/5000\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 195.3302 - mean_output_loss: 209.3274 - variance_output_loss: -13.9972 - val_loss: 169.0031 - val_mean_output_loss: 183.0893 - val_variance_output_loss: -14.0862\n",
            "Epoch 753/5000\n",
            "2/2 [==============================] - 0s 66ms/step - loss: 192.4005 - mean_output_loss: 208.6465 - variance_output_loss: -16.2460 - val_loss: 168.3649 - val_mean_output_loss: 182.4514 - val_variance_output_loss: -14.0865\n",
            "Epoch 754/5000\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 193.5787 - mean_output_loss: 207.9696 - variance_output_loss: -14.3909 - val_loss: 167.7287 - val_mean_output_loss: 181.8155 - val_variance_output_loss: -14.0868\n",
            "Epoch 755/5000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 192.9123 - mean_output_loss: 207.2973 - variance_output_loss: -14.3850 - val_loss: 167.0939 - val_mean_output_loss: 181.1811 - val_variance_output_loss: -14.0872\n",
            "Epoch 756/5000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 192.3799 - mean_output_loss: 206.6256 - variance_output_loss: -14.2457 - val_loss: 166.4610 - val_mean_output_loss: 180.5485 - val_variance_output_loss: -14.0875\n",
            "Epoch 757/5000\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 192.4932 - mean_output_loss: 205.9603 - variance_output_loss: -13.4671 - val_loss: 165.8294 - val_mean_output_loss: 179.9172 - val_variance_output_loss: -14.0878\n",
            "Epoch 758/5000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 190.7198 - mean_output_loss: 205.2926 - variance_output_loss: -14.5728 - val_loss: 165.1999 - val_mean_output_loss: 179.2881 - val_variance_output_loss: -14.0882\n",
            "Epoch 759/5000\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 190.2012 - mean_output_loss: 204.6217 - variance_output_loss: -14.4205 - val_loss: 164.5732 - val_mean_output_loss: 178.6617 - val_variance_output_loss: -14.0885\n",
            "Epoch 760/5000\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 188.4255 - mean_output_loss: 203.9655 - variance_output_loss: -15.5401 - val_loss: 163.9475 - val_mean_output_loss: 178.0363 - val_variance_output_loss: -14.0888\n",
            "Epoch 761/5000\n",
            "2/2 [==============================] - 0s 66ms/step - loss: 188.4988 - mean_output_loss: 203.2976 - variance_output_loss: -14.7988 - val_loss: 163.3248 - val_mean_output_loss: 177.4140 - val_variance_output_loss: -14.0891\n",
            "Epoch 762/5000\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 187.2602 - mean_output_loss: 202.6435 - variance_output_loss: -15.3833 - val_loss: 162.7034 - val_mean_output_loss: 176.7928 - val_variance_output_loss: -14.0894\n",
            "Epoch 763/5000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 185.2095 - mean_output_loss: 201.9909 - variance_output_loss: -16.7814 - val_loss: 162.0836 - val_mean_output_loss: 176.1734 - val_variance_output_loss: -14.0897\n",
            "Epoch 764/5000\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 186.9013 - mean_output_loss: 201.3284 - variance_output_loss: -14.4270 - val_loss: 161.4674 - val_mean_output_loss: 175.5574 - val_variance_output_loss: -14.0900\n",
            "Epoch 765/5000\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 186.0355 - mean_output_loss: 200.6779 - variance_output_loss: -14.6424 - val_loss: 160.8528 - val_mean_output_loss: 174.9432 - val_variance_output_loss: -14.0903\n",
            "Epoch 766/5000\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 184.2044 - mean_output_loss: 200.0258 - variance_output_loss: -15.8215 - val_loss: 160.2405 - val_mean_output_loss: 174.3312 - val_variance_output_loss: -14.0906\n",
            "Epoch 767/5000\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 182.7755 - mean_output_loss: 199.3739 - variance_output_loss: -16.5984 - val_loss: 159.6306 - val_mean_output_loss: 173.7215 - val_variance_output_loss: -14.0909\n",
            "Epoch 768/5000\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 183.8484 - mean_output_loss: 198.7282 - variance_output_loss: -14.8799 - val_loss: 159.0221 - val_mean_output_loss: 173.1133 - val_variance_output_loss: -14.0912\n",
            "Epoch 769/5000\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 183.1322 - mean_output_loss: 198.0838 - variance_output_loss: -14.9516 - val_loss: 158.4152 - val_mean_output_loss: 172.5068 - val_variance_output_loss: -14.0915\n",
            "Epoch 770/5000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 181.6790 - mean_output_loss: 197.4403 - variance_output_loss: -15.7613 - val_loss: 157.8101 - val_mean_output_loss: 171.9019 - val_variance_output_loss: -14.0918\n",
            "Epoch 771/5000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 181.9609 - mean_output_loss: 196.8025 - variance_output_loss: -14.8416 - val_loss: 157.2062 - val_mean_output_loss: 171.2984 - val_variance_output_loss: -14.0921\n",
            "Epoch 772/5000\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 181.0679 - mean_output_loss: 196.1590 - variance_output_loss: -15.0911 - val_loss: 156.6049 - val_mean_output_loss: 170.6973 - val_variance_output_loss: -14.0924\n",
            "Epoch 773/5000\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 181.5204 - mean_output_loss: 195.5260 - variance_output_loss: -14.0056 - val_loss: 156.0047 - val_mean_output_loss: 170.0974 - val_variance_output_loss: -14.0927\n",
            "Epoch 774/5000\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 181.7702 - mean_output_loss: 194.8871 - variance_output_loss: -13.1168 - val_loss: 155.4068 - val_mean_output_loss: 169.4998 - val_variance_output_loss: -14.0930\n",
            "Epoch 775/5000\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 180.4948 - mean_output_loss: 194.2548 - variance_output_loss: -13.7600 - val_loss: 154.8107 - val_mean_output_loss: 168.9039 - val_variance_output_loss: -14.0933\n",
            "Epoch 776/5000\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 179.2839 - mean_output_loss: 193.6230 - variance_output_loss: -14.3392 - val_loss: 154.2163 - val_mean_output_loss: 168.3098 - val_variance_output_loss: -14.0935\n",
            "Epoch 777/5000\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 178.2121 - mean_output_loss: 192.9915 - variance_output_loss: -14.7794 - val_loss: 153.6241 - val_mean_output_loss: 167.7179 - val_variance_output_loss: -14.0938\n",
            "Epoch 778/5000\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 176.3609 - mean_output_loss: 192.3644 - variance_output_loss: -16.0036 - val_loss: 153.0334 - val_mean_output_loss: 167.1275 - val_variance_output_loss: -14.0941\n",
            "Epoch 779/5000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 177.1085 - mean_output_loss: 191.7432 - variance_output_loss: -14.6347 - val_loss: 152.4440 - val_mean_output_loss: 166.5384 - val_variance_output_loss: -14.0944\n",
            "Epoch 780/5000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 176.5567 - mean_output_loss: 191.1156 - variance_output_loss: -14.5589 - val_loss: 151.8573 - val_mean_output_loss: 165.9520 - val_variance_output_loss: -14.0946\n",
            "Epoch 781/5000\n",
            "2/2 [==============================] - 0s 68ms/step - loss: 174.9885 - mean_output_loss: 190.4885 - variance_output_loss: -15.5001 - val_loss: 151.2732 - val_mean_output_loss: 165.3681 - val_variance_output_loss: -14.0949\n",
            "Epoch 782/5000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 173.8621 - mean_output_loss: 189.8691 - variance_output_loss: -16.0070 - val_loss: 150.6904 - val_mean_output_loss: 164.7856 - val_variance_output_loss: -14.0952\n",
            "Epoch 783/5000\n",
            "2/2 [==============================] - 0s 76ms/step - loss: 172.8016 - mean_output_loss: 189.2542 - variance_output_loss: -16.4526 - val_loss: 150.1086 - val_mean_output_loss: 164.2041 - val_variance_output_loss: -14.0954\n",
            "Epoch 784/5000\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 172.4352 - mean_output_loss: 188.6391 - variance_output_loss: -16.2040 - val_loss: 149.5286 - val_mean_output_loss: 163.6243 - val_variance_output_loss: -14.0957\n",
            "Epoch 785/5000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 173.2444 - mean_output_loss: 188.0195 - variance_output_loss: -14.7752 - val_loss: 148.9512 - val_mean_output_loss: 163.0472 - val_variance_output_loss: -14.0960\n",
            "Epoch 786/5000\n",
            "2/2 [==============================] - 0s 70ms/step - loss: 170.9055 - mean_output_loss: 187.4079 - variance_output_loss: -16.5024 - val_loss: 148.3752 - val_mean_output_loss: 162.4715 - val_variance_output_loss: -14.0962\n",
            "Epoch 787/5000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 171.4210 - mean_output_loss: 186.7968 - variance_output_loss: -15.3758 - val_loss: 147.8009 - val_mean_output_loss: 161.8974 - val_variance_output_loss: -14.0965\n",
            "Epoch 788/5000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 171.0269 - mean_output_loss: 186.1886 - variance_output_loss: -15.1616 - val_loss: 147.2283 - val_mean_output_loss: 161.3250 - val_variance_output_loss: -14.0967\n",
            "Epoch 789/5000\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 170.6098 - mean_output_loss: 185.5779 - variance_output_loss: -14.9681 - val_loss: 146.6579 - val_mean_output_loss: 160.7549 - val_variance_output_loss: -14.0970\n",
            "Epoch 790/5000\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 169.9291 - mean_output_loss: 184.9737 - variance_output_loss: -15.0446 - val_loss: 146.0888 - val_mean_output_loss: 160.1860 - val_variance_output_loss: -14.0972\n",
            "Epoch 791/5000\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 170.5168 - mean_output_loss: 184.3757 - variance_output_loss: -13.8589 - val_loss: 145.5207 - val_mean_output_loss: 159.6182 - val_variance_output_loss: -14.0975\n",
            "Epoch 792/5000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 167.8355 - mean_output_loss: 183.7707 - variance_output_loss: -15.9352 - val_loss: 144.9553 - val_mean_output_loss: 159.0531 - val_variance_output_loss: -14.0977\n",
            "Epoch 793/5000\n",
            "2/2 [==============================] - 0s 71ms/step - loss: 166.5178 - mean_output_loss: 183.1653 - variance_output_loss: -16.6474 - val_loss: 144.3925 - val_mean_output_loss: 158.4905 - val_variance_output_loss: -14.0980\n",
            "Epoch 794/5000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 167.9119 - mean_output_loss: 182.5701 - variance_output_loss: -14.6582 - val_loss: 143.8309 - val_mean_output_loss: 157.9291 - val_variance_output_loss: -14.0982\n",
            "Epoch 795/5000\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 166.0124 - mean_output_loss: 181.9695 - variance_output_loss: -15.9572 - val_loss: 143.2715 - val_mean_output_loss: 157.3700 - val_variance_output_loss: -14.0985\n",
            "Epoch 796/5000\n",
            "2/2 [==============================] - 0s 80ms/step - loss: 166.3880 - mean_output_loss: 181.3748 - variance_output_loss: -14.9868 - val_loss: 142.7134 - val_mean_output_loss: 156.8121 - val_variance_output_loss: -14.0987\n",
            "Epoch 797/5000\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 166.6484 - mean_output_loss: 180.7867 - variance_output_loss: -14.1384 - val_loss: 142.1562 - val_mean_output_loss: 156.2551 - val_variance_output_loss: -14.0990\n",
            "Epoch 798/5000\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 166.6617 - mean_output_loss: 180.1943 - variance_output_loss: -13.5325 - val_loss: 141.6009 - val_mean_output_loss: 155.7001 - val_variance_output_loss: -14.0992\n",
            "Epoch 799/5000\n",
            "2/2 [==============================] - 0s 70ms/step - loss: 165.3460 - mean_output_loss: 179.6061 - variance_output_loss: -14.2601 - val_loss: 141.0472 - val_mean_output_loss: 155.1467 - val_variance_output_loss: -14.0994\n",
            "Epoch 800/5000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 164.5543 - mean_output_loss: 179.0139 - variance_output_loss: -14.4595 - val_loss: 140.4960 - val_mean_output_loss: 154.5957 - val_variance_output_loss: -14.0997\n",
            "Epoch 801/5000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 163.1715 - mean_output_loss: 178.4287 - variance_output_loss: -15.2572 - val_loss: 139.9463 - val_mean_output_loss: 154.0462 - val_variance_output_loss: -14.0999\n",
            "Epoch 802/5000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 162.5710 - mean_output_loss: 177.8528 - variance_output_loss: -15.2819 - val_loss: 139.3972 - val_mean_output_loss: 153.4973 - val_variance_output_loss: -14.1001\n",
            "Epoch 803/5000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 162.8704 - mean_output_loss: 177.2644 - variance_output_loss: -14.3940 - val_loss: 138.8512 - val_mean_output_loss: 152.9516 - val_variance_output_loss: -14.1004\n",
            "Epoch 804/5000\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 162.1297 - mean_output_loss: 176.6817 - variance_output_loss: -14.5520 - val_loss: 138.3073 - val_mean_output_loss: 152.4079 - val_variance_output_loss: -14.1006\n",
            "Epoch 805/5000\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 160.5449 - mean_output_loss: 176.1010 - variance_output_loss: -15.5561 - val_loss: 137.7653 - val_mean_output_loss: 151.8661 - val_variance_output_loss: -14.1008\n",
            "Epoch 806/5000\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 160.2092 - mean_output_loss: 175.5269 - variance_output_loss: -15.3177 - val_loss: 137.2243 - val_mean_output_loss: 151.3253 - val_variance_output_loss: -14.1010\n",
            "Epoch 807/5000\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 160.3149 - mean_output_loss: 174.9503 - variance_output_loss: -14.6354 - val_loss: 136.6851 - val_mean_output_loss: 150.7863 - val_variance_output_loss: -14.1013\n",
            "Epoch 808/5000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 159.9913 - mean_output_loss: 174.3721 - variance_output_loss: -14.3807 - val_loss: 136.1479 - val_mean_output_loss: 150.2494 - val_variance_output_loss: -14.1015\n",
            "Epoch 809/5000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 158.3970 - mean_output_loss: 173.8069 - variance_output_loss: -15.4099 - val_loss: 135.6110 - val_mean_output_loss: 149.7127 - val_variance_output_loss: -14.1017\n",
            "Epoch 810/5000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 158.5140 - mean_output_loss: 173.2328 - variance_output_loss: -14.7189 - val_loss: 135.0763 - val_mean_output_loss: 149.1782 - val_variance_output_loss: -14.1019\n",
            "Epoch 811/5000\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 156.6494 - mean_output_loss: 172.6611 - variance_output_loss: -16.0117 - val_loss: 134.5434 - val_mean_output_loss: 148.6456 - val_variance_output_loss: -14.1021\n",
            "Epoch 812/5000\n",
            "2/2 [==============================] - 0s 77ms/step - loss: 157.4394 - mean_output_loss: 172.1008 - variance_output_loss: -14.6614 - val_loss: 134.0110 - val_mean_output_loss: 148.1133 - val_variance_output_loss: -14.1024\n",
            "Epoch 813/5000\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 156.7648 - mean_output_loss: 171.5316 - variance_output_loss: -14.7668 - val_loss: 133.4808 - val_mean_output_loss: 147.5834 - val_variance_output_loss: -14.1026\n",
            "Epoch 814/5000\n",
            "2/2 [==============================] - 0s 76ms/step - loss: 156.0747 - mean_output_loss: 170.9678 - variance_output_loss: -14.8931 - val_loss: 132.9523 - val_mean_output_loss: 147.0551 - val_variance_output_loss: -14.1028\n",
            "Epoch 815/5000\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 155.1275 - mean_output_loss: 170.4001 - variance_output_loss: -15.2725 - val_loss: 132.4261 - val_mean_output_loss: 146.5291 - val_variance_output_loss: -14.1030\n",
            "Epoch 816/5000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 155.6523 - mean_output_loss: 169.8473 - variance_output_loss: -14.1950 - val_loss: 131.9001 - val_mean_output_loss: 146.0033 - val_variance_output_loss: -14.1032\n",
            "Epoch 817/5000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 153.8783 - mean_output_loss: 169.2867 - variance_output_loss: -15.4083 - val_loss: 131.3762 - val_mean_output_loss: 145.4796 - val_variance_output_loss: -14.1034\n",
            "Epoch 818/5000\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 153.6751 - mean_output_loss: 168.7280 - variance_output_loss: -15.0530 - val_loss: 130.8543 - val_mean_output_loss: 144.9579 - val_variance_output_loss: -14.1036\n",
            "Epoch 819/5000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 153.2521 - mean_output_loss: 168.1697 - variance_output_loss: -14.9176 - val_loss: 130.3345 - val_mean_output_loss: 144.4383 - val_variance_output_loss: -14.1038\n",
            "Epoch 820/5000\n",
            "2/2 [==============================] - 0s 70ms/step - loss: 152.0676 - mean_output_loss: 167.6269 - variance_output_loss: -15.5593 - val_loss: 129.8148 - val_mean_output_loss: 143.9188 - val_variance_output_loss: -14.1040\n",
            "Epoch 821/5000\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 152.2189 - mean_output_loss: 167.0626 - variance_output_loss: -14.8436 - val_loss: 129.2990 - val_mean_output_loss: 143.4032 - val_variance_output_loss: -14.1042\n",
            "Epoch 822/5000\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 152.0143 - mean_output_loss: 166.5192 - variance_output_loss: -14.5049 - val_loss: 128.7837 - val_mean_output_loss: 142.8882 - val_variance_output_loss: -14.1044\n",
            "Epoch 823/5000\n",
            "2/2 [==============================] - 0s 68ms/step - loss: 150.3862 - mean_output_loss: 165.9651 - variance_output_loss: -15.5789 - val_loss: 128.2711 - val_mean_output_loss: 142.3757 - val_variance_output_loss: -14.1046\n",
            "Epoch 824/5000\n",
            "2/2 [==============================] - 0s 71ms/step - loss: 150.1044 - mean_output_loss: 165.4204 - variance_output_loss: -15.3160 - val_loss: 127.7595 - val_mean_output_loss: 141.8643 - val_variance_output_loss: -14.1048\n",
            "Epoch 825/5000\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 149.9052 - mean_output_loss: 164.8746 - variance_output_loss: -14.9694 - val_loss: 127.2496 - val_mean_output_loss: 141.3546 - val_variance_output_loss: -14.1050\n",
            "Epoch 826/5000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 148.1931 - mean_output_loss: 164.3358 - variance_output_loss: -16.1428 - val_loss: 126.7406 - val_mean_output_loss: 140.8458 - val_variance_output_loss: -14.1052\n",
            "Epoch 827/5000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 148.5236 - mean_output_loss: 163.7830 - variance_output_loss: -15.2594 - val_loss: 126.2348 - val_mean_output_loss: 140.3402 - val_variance_output_loss: -14.1054\n",
            "Epoch 828/5000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 147.7457 - mean_output_loss: 163.2507 - variance_output_loss: -15.5050 - val_loss: 125.7290 - val_mean_output_loss: 139.8347 - val_variance_output_loss: -14.1056\n",
            "Epoch 829/5000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 148.7439 - mean_output_loss: 162.7125 - variance_output_loss: -13.9685 - val_loss: 125.2249 - val_mean_output_loss: 139.3307 - val_variance_output_loss: -14.1058\n",
            "Epoch 830/5000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 147.5423 - mean_output_loss: 162.1743 - variance_output_loss: -14.6319 - val_loss: 124.7225 - val_mean_output_loss: 138.8285 - val_variance_output_loss: -14.1060\n",
            "Epoch 831/5000\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 147.6415 - mean_output_loss: 161.6341 - variance_output_loss: -13.9926 - val_loss: 124.2224 - val_mean_output_loss: 138.3286 - val_variance_output_loss: -14.1062\n",
            "Epoch 832/5000\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 146.3028 - mean_output_loss: 161.1044 - variance_output_loss: -14.8016 - val_loss: 123.7229 - val_mean_output_loss: 137.8293 - val_variance_output_loss: -14.1064\n",
            "Epoch 833/5000\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 146.1082 - mean_output_loss: 160.5719 - variance_output_loss: -14.4638 - val_loss: 123.2251 - val_mean_output_loss: 137.3316 - val_variance_output_loss: -14.1066\n",
            "Epoch 834/5000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 145.4162 - mean_output_loss: 160.0400 - variance_output_loss: -14.6237 - val_loss: 122.7290 - val_mean_output_loss: 136.8358 - val_variance_output_loss: -14.1067\n",
            "Epoch 835/5000\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 143.6650 - mean_output_loss: 159.5082 - variance_output_loss: -15.8431 - val_loss: 122.2348 - val_mean_output_loss: 136.3417 - val_variance_output_loss: -14.1069\n",
            "Epoch 836/5000\n",
            "2/2 [==============================] - 0s 82ms/step - loss: 142.8586 - mean_output_loss: 158.9818 - variance_output_loss: -16.1232 - val_loss: 121.7417 - val_mean_output_loss: 135.8488 - val_variance_output_loss: -14.1071\n",
            "Epoch 837/5000\n",
            "2/2 [==============================] - 0s 82ms/step - loss: 143.6718 - mean_output_loss: 158.4515 - variance_output_loss: -14.7798 - val_loss: 121.2505 - val_mean_output_loss: 135.3578 - val_variance_output_loss: -14.1073\n",
            "Epoch 838/5000\n",
            "2/2 [==============================] - 0s 68ms/step - loss: 143.5577 - mean_output_loss: 157.9317 - variance_output_loss: -14.3740 - val_loss: 120.7597 - val_mean_output_loss: 134.8672 - val_variance_output_loss: -14.1075\n",
            "Epoch 839/5000\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 142.2924 - mean_output_loss: 157.4022 - variance_output_loss: -15.1098 - val_loss: 120.2711 - val_mean_output_loss: 134.3788 - val_variance_output_loss: -14.1077\n",
            "Epoch 840/5000\n",
            "2/2 [==============================] - 0s 76ms/step - loss: 141.6447 - mean_output_loss: 156.8820 - variance_output_loss: -15.2373 - val_loss: 119.7835 - val_mean_output_loss: 133.8913 - val_variance_output_loss: -14.1078\n",
            "Epoch 841/5000\n",
            "2/2 [==============================] - 0s 69ms/step - loss: 140.8948 - mean_output_loss: 156.3678 - variance_output_loss: -15.4730 - val_loss: 119.2962 - val_mean_output_loss: 133.4042 - val_variance_output_loss: -14.1080\n",
            "Epoch 842/5000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 141.6799 - mean_output_loss: 155.8423 - variance_output_loss: -14.1623 - val_loss: 118.8116 - val_mean_output_loss: 132.9198 - val_variance_output_loss: -14.1082\n",
            "Epoch 843/5000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 141.1854 - mean_output_loss: 155.3294 - variance_output_loss: -14.1439 - val_loss: 118.3277 - val_mean_output_loss: 132.4361 - val_variance_output_loss: -14.1084\n",
            "Epoch 844/5000\n",
            "2/2 [==============================] - 0s 97ms/step - loss: 139.4956 - mean_output_loss: 154.8113 - variance_output_loss: -15.3157 - val_loss: 117.8459 - val_mean_output_loss: 131.9544 - val_variance_output_loss: -14.1085\n",
            "Epoch 845/5000\n",
            "2/2 [==============================] - 0s 67ms/step - loss: 138.2374 - mean_output_loss: 154.2953 - variance_output_loss: -16.0579 - val_loss: 117.3659 - val_mean_output_loss: 131.4746 - val_variance_output_loss: -14.1087\n",
            "Epoch 846/5000\n",
            "2/2 [==============================] - 0s 74ms/step - loss: 138.9364 - mean_output_loss: 153.7871 - variance_output_loss: -14.8507 - val_loss: 116.8867 - val_mean_output_loss: 130.9956 - val_variance_output_loss: -14.1089\n",
            "Epoch 847/5000\n",
            "2/2 [==============================] - 0s 72ms/step - loss: 137.9053 - mean_output_loss: 153.2741 - variance_output_loss: -15.3688 - val_loss: 116.4097 - val_mean_output_loss: 130.5188 - val_variance_output_loss: -14.1091\n",
            "Epoch 848/5000\n",
            "2/2 [==============================] - 0s 77ms/step - loss: 138.3794 - mean_output_loss: 152.7602 - variance_output_loss: -14.3807 - val_loss: 115.9349 - val_mean_output_loss: 130.0442 - val_variance_output_loss: -14.1092\n",
            "Epoch 849/5000\n",
            "2/2 [==============================] - 0s 98ms/step - loss: 138.6801 - mean_output_loss: 152.2553 - variance_output_loss: -13.5752 - val_loss: 115.4611 - val_mean_output_loss: 129.5705 - val_variance_output_loss: -14.1094\n",
            "Epoch 850/5000\n",
            "2/2 [==============================] - 0s 79ms/step - loss: 136.4490 - mean_output_loss: 151.7473 - variance_output_loss: -15.2983 - val_loss: 114.9890 - val_mean_output_loss: 129.0986 - val_variance_output_loss: -14.1096\n",
            "Epoch 851/5000\n",
            "2/2 [==============================] - 0s 83ms/step - loss: 136.8973 - mean_output_loss: 151.2408 - variance_output_loss: -14.3435 - val_loss: 114.5185 - val_mean_output_loss: 128.6282 - val_variance_output_loss: -14.1097\n",
            "Epoch 852/5000\n",
            "2/2 [==============================] - 0s 68ms/step - loss: 135.9476 - mean_output_loss: 150.7355 - variance_output_loss: -14.7878 - val_loss: 114.0494 - val_mean_output_loss: 128.1593 - val_variance_output_loss: -14.1099\n",
            "Epoch 853/5000\n",
            "2/2 [==============================] - 0s 67ms/step - loss: 134.9041 - mean_output_loss: 150.2376 - variance_output_loss: -15.3335 - val_loss: 113.5809 - val_mean_output_loss: 127.6910 - val_variance_output_loss: -14.1101\n",
            "Epoch 854/5000\n",
            "2/2 [==============================] - 0s 77ms/step - loss: 135.0980 - mean_output_loss: 149.7377 - variance_output_loss: -14.6397 - val_loss: 113.1138 - val_mean_output_loss: 127.2240 - val_variance_output_loss: -14.1102\n",
            "Epoch 855/5000\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 133.5824 - mean_output_loss: 149.2386 - variance_output_loss: -15.6562 - val_loss: 112.6482 - val_mean_output_loss: 126.7586 - val_variance_output_loss: -14.1104\n",
            "Epoch 856/5000\n",
            "2/2 [==============================] - 0s 66ms/step - loss: 133.4387 - mean_output_loss: 148.7365 - variance_output_loss: -15.2977 - val_loss: 112.1847 - val_mean_output_loss: 126.2953 - val_variance_output_loss: -14.1106\n",
            "Epoch 857/5000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 131.9058 - mean_output_loss: 148.2431 - variance_output_loss: -16.3373 - val_loss: 111.7221 - val_mean_output_loss: 125.8328 - val_variance_output_loss: -14.1107\n",
            "Epoch 858/5000\n",
            "2/2 [==============================] - 0s 71ms/step - loss: 132.2475 - mean_output_loss: 147.7473 - variance_output_loss: -15.4998 - val_loss: 111.2611 - val_mean_output_loss: 125.3720 - val_variance_output_loss: -14.1109\n",
            "Epoch 859/5000\n",
            "2/2 [==============================] - 0s 74ms/step - loss: 132.4665 - mean_output_loss: 147.2536 - variance_output_loss: -14.7871 - val_loss: 110.8014 - val_mean_output_loss: 124.9125 - val_variance_output_loss: -14.1110\n",
            "Epoch 860/5000\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 131.5354 - mean_output_loss: 146.7604 - variance_output_loss: -15.2250 - val_loss: 110.3433 - val_mean_output_loss: 124.4545 - val_variance_output_loss: -14.1112\n",
            "Epoch 861/5000\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 131.4650 - mean_output_loss: 146.2733 - variance_output_loss: -14.8083 - val_loss: 109.8860 - val_mean_output_loss: 123.9974 - val_variance_output_loss: -14.1114\n",
            "Epoch 862/5000\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 131.6271 - mean_output_loss: 145.7835 - variance_output_loss: -14.1565 - val_loss: 109.4304 - val_mean_output_loss: 123.5419 - val_variance_output_loss: -14.1115\n",
            "Epoch 863/5000\n",
            "2/2 [==============================] - 0s 66ms/step - loss: 129.7387 - mean_output_loss: 145.2910 - variance_output_loss: -15.5523 - val_loss: 108.9768 - val_mean_output_loss: 123.0885 - val_variance_output_loss: -14.1117\n",
            "Epoch 864/5000\n",
            "2/2 [==============================] - 0s 70ms/step - loss: 129.8484 - mean_output_loss: 144.8067 - variance_output_loss: -14.9584 - val_loss: 108.5241 - val_mean_output_loss: 122.6359 - val_variance_output_loss: -14.1118\n",
            "Epoch 865/5000\n",
            "2/2 [==============================] - 0s 68ms/step - loss: 129.7897 - mean_output_loss: 144.3220 - variance_output_loss: -14.5323 - val_loss: 108.0726 - val_mean_output_loss: 122.1846 - val_variance_output_loss: -14.1120\n",
            "Epoch 866/5000\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 129.9111 - mean_output_loss: 143.8389 - variance_output_loss: -13.9278 - val_loss: 107.6224 - val_mean_output_loss: 121.7346 - val_variance_output_loss: -14.1121\n",
            "Epoch 867/5000\n",
            "2/2 [==============================] - 0s 80ms/step - loss: 128.7211 - mean_output_loss: 143.3563 - variance_output_loss: -14.6353 - val_loss: 107.1736 - val_mean_output_loss: 121.2859 - val_variance_output_loss: -14.1123\n",
            "Epoch 868/5000\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 127.1870 - mean_output_loss: 142.8727 - variance_output_loss: -15.6857 - val_loss: 106.7264 - val_mean_output_loss: 120.8388 - val_variance_output_loss: -14.1124\n",
            "Epoch 869/5000\n",
            "2/2 [==============================] - 0s 75ms/step - loss: 126.4219 - mean_output_loss: 142.3956 - variance_output_loss: -15.9737 - val_loss: 106.2800 - val_mean_output_loss: 120.3926 - val_variance_output_loss: -14.1126\n",
            "Epoch 870/5000\n",
            "2/2 [==============================] - 0s 68ms/step - loss: 127.6236 - mean_output_loss: 141.9132 - variance_output_loss: -14.2896 - val_loss: 105.8355 - val_mean_output_loss: 119.9483 - val_variance_output_loss: -14.1127\n",
            "Epoch 871/5000\n",
            "2/2 [==============================] - 0s 69ms/step - loss: 125.6202 - mean_output_loss: 141.4459 - variance_output_loss: -15.8257 - val_loss: 105.3908 - val_mean_output_loss: 119.5037 - val_variance_output_loss: -14.1129\n",
            "Epoch 872/5000\n",
            "2/2 [==============================] - 0s 82ms/step - loss: 125.8244 - mean_output_loss: 140.9653 - variance_output_loss: -15.1408 - val_loss: 104.9486 - val_mean_output_loss: 119.0616 - val_variance_output_loss: -14.1130\n",
            "Epoch 873/5000\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 125.3595 - mean_output_loss: 140.4905 - variance_output_loss: -15.1310 - val_loss: 104.5079 - val_mean_output_loss: 118.6210 - val_variance_output_loss: -14.1132\n",
            "Epoch 874/5000\n",
            "2/2 [==============================] - 0s 79ms/step - loss: 125.3128 - mean_output_loss: 140.0206 - variance_output_loss: -14.7078 - val_loss: 104.0682 - val_mean_output_loss: 118.1815 - val_variance_output_loss: -14.1133\n",
            "Epoch 875/5000\n",
            "2/2 [==============================] - 0s 69ms/step - loss: 125.1742 - mean_output_loss: 139.5525 - variance_output_loss: -14.3783 - val_loss: 103.6298 - val_mean_output_loss: 117.7433 - val_variance_output_loss: -14.1135\n",
            "Epoch 876/5000\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 124.2987 - mean_output_loss: 139.0793 - variance_output_loss: -14.7806 - val_loss: 103.1937 - val_mean_output_loss: 117.3073 - val_variance_output_loss: -14.1136\n",
            "Epoch 877/5000\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 123.5806 - mean_output_loss: 138.6103 - variance_output_loss: -15.0297 - val_loss: 102.7592 - val_mean_output_loss: 116.8729 - val_variance_output_loss: -14.1138\n",
            "Epoch 878/5000\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 122.1978 - mean_output_loss: 138.1420 - variance_output_loss: -15.9442 - val_loss: 102.3263 - val_mean_output_loss: 116.4402 - val_variance_output_loss: -14.1139\n",
            "Epoch 879/5000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 122.7177 - mean_output_loss: 137.6768 - variance_output_loss: -14.9590 - val_loss: 101.8946 - val_mean_output_loss: 116.0086 - val_variance_output_loss: -14.1140\n",
            "Epoch 880/5000\n",
            "2/2 [==============================] - 0s 75ms/step - loss: 122.8988 - mean_output_loss: 137.2163 - variance_output_loss: -14.3175 - val_loss: 101.4636 - val_mean_output_loss: 115.5778 - val_variance_output_loss: -14.1142\n",
            "Epoch 881/5000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 121.7873 - mean_output_loss: 136.7566 - variance_output_loss: -14.9693 - val_loss: 101.0337 - val_mean_output_loss: 115.1480 - val_variance_output_loss: -14.1143\n",
            "Epoch 882/5000\n",
            "2/2 [==============================] - 0s 69ms/step - loss: 121.0015 - mean_output_loss: 136.2891 - variance_output_loss: -15.2876 - val_loss: 100.6063 - val_mean_output_loss: 114.7207 - val_variance_output_loss: -14.1145\n",
            "Epoch 883/5000\n",
            "2/2 [==============================] - 0s 96ms/step - loss: 121.4901 - mean_output_loss: 135.8307 - variance_output_loss: -14.3407 - val_loss: 100.1797 - val_mean_output_loss: 114.2943 - val_variance_output_loss: -14.1146\n",
            "Epoch 884/5000\n",
            "2/2 [==============================] - 0s 75ms/step - loss: 121.1459 - mean_output_loss: 135.3744 - variance_output_loss: -14.2285 - val_loss: 99.7541 - val_mean_output_loss: 113.8688 - val_variance_output_loss: -14.1147\n",
            "Epoch 885/5000\n",
            "2/2 [==============================] - 0s 76ms/step - loss: 119.5566 - mean_output_loss: 134.9160 - variance_output_loss: -15.3595 - val_loss: 99.3299 - val_mean_output_loss: 113.4448 - val_variance_output_loss: -14.1149\n",
            "Epoch 886/5000\n",
            "2/2 [==============================] - 0s 68ms/step - loss: 119.6617 - mean_output_loss: 134.4611 - variance_output_loss: -14.7994 - val_loss: 98.9069 - val_mean_output_loss: 113.0219 - val_variance_output_loss: -14.1150\n",
            "Epoch 887/5000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 119.3819 - mean_output_loss: 134.0087 - variance_output_loss: -14.6268 - val_loss: 98.4849 - val_mean_output_loss: 112.6001 - val_variance_output_loss: -14.1152\n",
            "Epoch 888/5000\n",
            "2/2 [==============================] - 0s 72ms/step - loss: 119.7414 - mean_output_loss: 133.5522 - variance_output_loss: -13.8108 - val_loss: 98.0648 - val_mean_output_loss: 112.1801 - val_variance_output_loss: -14.1153\n",
            "Epoch 889/5000\n",
            "2/2 [==============================] - 0s 74ms/step - loss: 119.2416 - mean_output_loss: 133.1042 - variance_output_loss: -13.8626 - val_loss: 97.6454 - val_mean_output_loss: 111.7608 - val_variance_output_loss: -14.1154\n",
            "Epoch 890/5000\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 117.5814 - mean_output_loss: 132.6522 - variance_output_loss: -15.0709 - val_loss: 97.2277 - val_mean_output_loss: 111.3433 - val_variance_output_loss: -14.1156\n",
            "Epoch 891/5000\n",
            "2/2 [==============================] - 0s 71ms/step - loss: 116.6846 - mean_output_loss: 132.2054 - variance_output_loss: -15.5209 - val_loss: 96.8111 - val_mean_output_loss: 110.9268 - val_variance_output_loss: -14.1157\n",
            "Epoch 892/5000\n",
            "2/2 [==============================] - 0s 90ms/step - loss: 118.0833 - mean_output_loss: 131.7520 - variance_output_loss: -13.6687 - val_loss: 96.3967 - val_mean_output_loss: 110.5125 - val_variance_output_loss: -14.1158\n",
            "Epoch 893/5000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 116.9043 - mean_output_loss: 131.3123 - variance_output_loss: -14.4081 - val_loss: 95.9825 - val_mean_output_loss: 110.0984 - val_variance_output_loss: -14.1160\n",
            "Epoch 894/5000\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 115.4638 - mean_output_loss: 130.8652 - variance_output_loss: -15.4015 - val_loss: 95.5701 - val_mean_output_loss: 109.6862 - val_variance_output_loss: -14.1161\n",
            "Epoch 895/5000\n",
            "2/2 [==============================] - 0s 74ms/step - loss: 116.9662 - mean_output_loss: 130.4206 - variance_output_loss: -13.4544 - val_loss: 95.1592 - val_mean_output_loss: 109.2754 - val_variance_output_loss: -14.1162\n",
            "Epoch 896/5000\n",
            "2/2 [==============================] - 0s 84ms/step - loss: 115.3309 - mean_output_loss: 129.9801 - variance_output_loss: -14.6492 - val_loss: 94.7493 - val_mean_output_loss: 108.8656 - val_variance_output_loss: -14.1163\n",
            "Epoch 897/5000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 115.0788 - mean_output_loss: 129.5424 - variance_output_loss: -14.4636 - val_loss: 94.3404 - val_mean_output_loss: 108.4569 - val_variance_output_loss: -14.1165\n",
            "Epoch 898/5000\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 114.9087 - mean_output_loss: 129.1031 - variance_output_loss: -14.1944 - val_loss: 93.9332 - val_mean_output_loss: 108.0498 - val_variance_output_loss: -14.1166\n",
            "Epoch 899/5000\n",
            "2/2 [==============================] - 0s 72ms/step - loss: 113.3500 - mean_output_loss: 128.6561 - variance_output_loss: -15.3061 - val_loss: 93.5286 - val_mean_output_loss: 107.6454 - val_variance_output_loss: -14.1167\n",
            "Epoch 900/5000\n",
            "2/2 [==============================] - 0s 83ms/step - loss: 111.7987 - mean_output_loss: 128.2284 - variance_output_loss: -16.4297 - val_loss: 93.1238 - val_mean_output_loss: 107.2407 - val_variance_output_loss: -14.1169\n",
            "Epoch 901/5000\n",
            "2/2 [==============================] - 0s 78ms/step - loss: 112.8985 - mean_output_loss: 127.7908 - variance_output_loss: -14.8923 - val_loss: 92.7208 - val_mean_output_loss: 106.8378 - val_variance_output_loss: -14.1170\n",
            "Epoch 902/5000\n",
            "2/2 [==============================] - 0s 86ms/step - loss: 113.2326 - mean_output_loss: 127.3497 - variance_output_loss: -14.1171 - val_loss: 92.3200 - val_mean_output_loss: 106.4371 - val_variance_output_loss: -14.1171\n",
            "Epoch 903/5000\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 112.6710 - mean_output_loss: 126.9197 - variance_output_loss: -14.2488 - val_loss: 91.9194 - val_mean_output_loss: 106.0367 - val_variance_output_loss: -14.1172\n",
            "Epoch 904/5000\n",
            "2/2 [==============================] - 0s 68ms/step - loss: 110.3860 - mean_output_loss: 126.4925 - variance_output_loss: -16.1065 - val_loss: 91.5192 - val_mean_output_loss: 105.6366 - val_variance_output_loss: -14.1174\n",
            "Epoch 905/5000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 111.2821 - mean_output_loss: 126.0675 - variance_output_loss: -14.7853 - val_loss: 91.1197 - val_mean_output_loss: 105.2372 - val_variance_output_loss: -14.1175\n",
            "Epoch 906/5000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 109.4017 - mean_output_loss: 125.6315 - variance_output_loss: -16.2298 - val_loss: 90.7229 - val_mean_output_loss: 104.8405 - val_variance_output_loss: -14.1176\n",
            "Epoch 907/5000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 111.1944 - mean_output_loss: 125.2018 - variance_output_loss: -14.0074 - val_loss: 90.3275 - val_mean_output_loss: 104.4452 - val_variance_output_loss: -14.1177\n",
            "Epoch 908/5000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 110.4276 - mean_output_loss: 124.7742 - variance_output_loss: -14.3465 - val_loss: 89.9332 - val_mean_output_loss: 104.0511 - val_variance_output_loss: -14.1178\n",
            "Epoch 909/5000\n",
            "2/2 [==============================] - 0s 69ms/step - loss: 109.0888 - mean_output_loss: 124.3538 - variance_output_loss: -15.2650 - val_loss: 89.5393 - val_mean_output_loss: 103.6573 - val_variance_output_loss: -14.1180\n",
            "Epoch 910/5000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 108.5840 - mean_output_loss: 123.9315 - variance_output_loss: -15.3475 - val_loss: 89.1466 - val_mean_output_loss: 103.2646 - val_variance_output_loss: -14.1181\n",
            "Epoch 911/5000\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 108.3687 - mean_output_loss: 123.5057 - variance_output_loss: -15.1370 - val_loss: 88.7557 - val_mean_output_loss: 102.8739 - val_variance_output_loss: -14.1182\n",
            "Epoch 912/5000\n",
            "2/2 [==============================] - 0s 84ms/step - loss: 108.3380 - mean_output_loss: 123.0844 - variance_output_loss: -14.7464 - val_loss: 88.3661 - val_mean_output_loss: 102.4844 - val_variance_output_loss: -14.1183\n",
            "Epoch 913/5000\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 107.2312 - mean_output_loss: 122.6651 - variance_output_loss: -15.4339 - val_loss: 87.9776 - val_mean_output_loss: 102.0961 - val_variance_output_loss: -14.1184\n",
            "Epoch 914/5000\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 108.1645 - mean_output_loss: 122.2417 - variance_output_loss: -14.0772 - val_loss: 87.5910 - val_mean_output_loss: 101.7096 - val_variance_output_loss: -14.1186\n",
            "Epoch 915/5000\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 106.2474 - mean_output_loss: 121.8233 - variance_output_loss: -15.5759 - val_loss: 87.2054 - val_mean_output_loss: 101.3241 - val_variance_output_loss: -14.1187\n",
            "Epoch 916/5000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 106.5806 - mean_output_loss: 121.4111 - variance_output_loss: -14.8305 - val_loss: 86.8201 - val_mean_output_loss: 100.9389 - val_variance_output_loss: -14.1188\n",
            "Epoch 917/5000\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 106.1596 - mean_output_loss: 120.9966 - variance_output_loss: -14.8370 - val_loss: 86.4359 - val_mean_output_loss: 100.5548 - val_variance_output_loss: -14.1189\n",
            "Epoch 918/5000\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 104.6341 - mean_output_loss: 120.5802 - variance_output_loss: -15.9461 - val_loss: 86.0533 - val_mean_output_loss: 100.1723 - val_variance_output_loss: -14.1190\n",
            "Epoch 919/5000\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 106.1062 - mean_output_loss: 120.1713 - variance_output_loss: -14.0651 - val_loss: 85.6713 - val_mean_output_loss: 99.7905 - val_variance_output_loss: -14.1191\n",
            "Epoch 920/5000\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 105.0102 - mean_output_loss: 119.7549 - variance_output_loss: -14.7448 - val_loss: 85.2914 - val_mean_output_loss: 99.4107 - val_variance_output_loss: -14.1193\n",
            "Epoch 921/5000\n",
            "2/2 [==============================] - 0s 67ms/step - loss: 104.9869 - mean_output_loss: 119.3449 - variance_output_loss: -14.3580 - val_loss: 84.9125 - val_mean_output_loss: 99.0319 - val_variance_output_loss: -14.1194\n",
            "Epoch 922/5000\n",
            "2/2 [==============================] - 0s 67ms/step - loss: 104.4536 - mean_output_loss: 118.9357 - variance_output_loss: -14.4820 - val_loss: 84.5348 - val_mean_output_loss: 98.6543 - val_variance_output_loss: -14.1195\n",
            "Epoch 923/5000\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 104.7254 - mean_output_loss: 118.5263 - variance_output_loss: -13.8009 - val_loss: 84.1582 - val_mean_output_loss: 98.2778 - val_variance_output_loss: -14.1196\n",
            "Epoch 924/5000\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 102.2117 - mean_output_loss: 118.1231 - variance_output_loss: -15.9114 - val_loss: 83.7823 - val_mean_output_loss: 97.9020 - val_variance_output_loss: -14.1197\n",
            "Epoch 925/5000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 102.2369 - mean_output_loss: 117.7204 - variance_output_loss: -15.4835 - val_loss: 83.4072 - val_mean_output_loss: 97.5270 - val_variance_output_loss: -14.1198\n",
            "Epoch 926/5000\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 101.9552 - mean_output_loss: 117.3111 - variance_output_loss: -15.3558 - val_loss: 83.0344 - val_mean_output_loss: 97.1544 - val_variance_output_loss: -14.1199\n",
            "Epoch 927/5000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 101.5791 - mean_output_loss: 116.9104 - variance_output_loss: -15.3313 - val_loss: 82.6625 - val_mean_output_loss: 96.7825 - val_variance_output_loss: -14.1200\n",
            "Epoch 928/5000\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 100.8528 - mean_output_loss: 116.5100 - variance_output_loss: -15.6573 - val_loss: 82.2917 - val_mean_output_loss: 96.4119 - val_variance_output_loss: -14.1202\n",
            "Epoch 929/5000\n",
            "2/2 [==============================] - 0s 86ms/step - loss: 100.9206 - mean_output_loss: 116.1073 - variance_output_loss: -15.1868 - val_loss: 81.9227 - val_mean_output_loss: 96.0429 - val_variance_output_loss: -14.1203\n",
            "Epoch 930/5000\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 100.9361 - mean_output_loss: 115.7134 - variance_output_loss: -14.7774 - val_loss: 81.5542 - val_mean_output_loss: 95.6746 - val_variance_output_loss: -14.1204\n",
            "Epoch 931/5000\n",
            "2/2 [==============================] - 0s 69ms/step - loss: 101.1105 - mean_output_loss: 115.3073 - variance_output_loss: -14.1968 - val_loss: 81.1884 - val_mean_output_loss: 95.3089 - val_variance_output_loss: -14.1205\n",
            "Epoch 932/5000\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 100.6928 - mean_output_loss: 114.9149 - variance_output_loss: -14.2221 - val_loss: 80.8230 - val_mean_output_loss: 94.9436 - val_variance_output_loss: -14.1206\n",
            "Epoch 933/5000\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 99.8107 - mean_output_loss: 114.5174 - variance_output_loss: -14.7067 - val_loss: 80.4591 - val_mean_output_loss: 94.5798 - val_variance_output_loss: -14.1207\n",
            "Epoch 934/5000\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 99.1190 - mean_output_loss: 114.1245 - variance_output_loss: -15.0055 - val_loss: 80.0960 - val_mean_output_loss: 94.2168 - val_variance_output_loss: -14.1208\n",
            "Epoch 935/5000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 98.1295 - mean_output_loss: 113.7352 - variance_output_loss: -15.6057 - val_loss: 79.7335 - val_mean_output_loss: 93.8544 - val_variance_output_loss: -14.1209\n",
            "Epoch 936/5000\n",
            "2/2 [==============================] - 0s 66ms/step - loss: 98.8102 - mean_output_loss: 113.3445 - variance_output_loss: -14.5344 - val_loss: 79.3723 - val_mean_output_loss: 93.4933 - val_variance_output_loss: -14.1210\n",
            "Epoch 937/5000\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 98.4074 - mean_output_loss: 112.9492 - variance_output_loss: -14.5418 - val_loss: 79.0132 - val_mean_output_loss: 93.1343 - val_variance_output_loss: -14.1211\n",
            "Epoch 938/5000\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 98.3122 - mean_output_loss: 112.5696 - variance_output_loss: -14.2574 - val_loss: 78.6540 - val_mean_output_loss: 92.7752 - val_variance_output_loss: -14.1212\n",
            "Epoch 939/5000\n",
            "2/2 [==============================] - 0s 67ms/step - loss: 96.9649 - mean_output_loss: 112.1722 - variance_output_loss: -15.2073 - val_loss: 78.2977 - val_mean_output_loss: 92.4191 - val_variance_output_loss: -14.1213\n",
            "Epoch 940/5000\n",
            "2/2 [==============================] - 0s 66ms/step - loss: 96.3582 - mean_output_loss: 111.7837 - variance_output_loss: -15.4255 - val_loss: 77.9427 - val_mean_output_loss: 92.0641 - val_variance_output_loss: -14.1214\n",
            "Epoch 941/5000\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 96.7407 - mean_output_loss: 111.4008 - variance_output_loss: -14.6601 - val_loss: 77.5881 - val_mean_output_loss: 91.7096 - val_variance_output_loss: -14.1215\n",
            "Epoch 942/5000\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 96.0461 - mean_output_loss: 111.0173 - variance_output_loss: -14.9712 - val_loss: 77.2343 - val_mean_output_loss: 91.3559 - val_variance_output_loss: -14.1216\n",
            "Epoch 943/5000\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 95.7830 - mean_output_loss: 110.6346 - variance_output_loss: -14.8517 - val_loss: 76.8814 - val_mean_output_loss: 91.0032 - val_variance_output_loss: -14.1217\n",
            "Epoch 944/5000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 94.7663 - mean_output_loss: 110.2557 - variance_output_loss: -15.4894 - val_loss: 76.5293 - val_mean_output_loss: 90.6511 - val_variance_output_loss: -14.1218\n",
            "Epoch 945/5000\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 94.6416 - mean_output_loss: 109.8713 - variance_output_loss: -15.2297 - val_loss: 76.1789 - val_mean_output_loss: 90.3008 - val_variance_output_loss: -14.1219\n",
            "Epoch 946/5000\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 93.0009 - mean_output_loss: 109.4872 - variance_output_loss: -16.4863 - val_loss: 75.8301 - val_mean_output_loss: 89.9522 - val_variance_output_loss: -14.1220\n",
            "Epoch 947/5000\n",
            "2/2 [==============================] - 0s 67ms/step - loss: 94.6237 - mean_output_loss: 109.1137 - variance_output_loss: -14.4900 - val_loss: 75.4814 - val_mean_output_loss: 89.6036 - val_variance_output_loss: -14.1221\n",
            "Epoch 948/5000\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 94.1139 - mean_output_loss: 108.7370 - variance_output_loss: -14.6231 - val_loss: 75.1337 - val_mean_output_loss: 89.2560 - val_variance_output_loss: -14.1222\n",
            "Epoch 949/5000\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 93.2527 - mean_output_loss: 108.3602 - variance_output_loss: -15.1075 - val_loss: 74.7873 - val_mean_output_loss: 88.9097 - val_variance_output_loss: -14.1223\n",
            "Epoch 950/5000\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 92.5238 - mean_output_loss: 107.9824 - variance_output_loss: -15.4587 - val_loss: 74.4425 - val_mean_output_loss: 88.5649 - val_variance_output_loss: -14.1224\n",
            "Epoch 951/5000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 93.3491 - mean_output_loss: 107.6102 - variance_output_loss: -14.2611 - val_loss: 74.0984 - val_mean_output_loss: 88.2210 - val_variance_output_loss: -14.1225\n",
            "Epoch 952/5000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 92.5431 - mean_output_loss: 107.2371 - variance_output_loss: -14.6940 - val_loss: 73.7556 - val_mean_output_loss: 87.8782 - val_variance_output_loss: -14.1226\n",
            "Epoch 953/5000\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 91.0723 - mean_output_loss: 106.8628 - variance_output_loss: -15.7905 - val_loss: 73.4142 - val_mean_output_loss: 87.5369 - val_variance_output_loss: -14.1227\n",
            "Epoch 954/5000\n",
            "2/2 [==============================] - 0s 70ms/step - loss: 90.9424 - mean_output_loss: 106.4954 - variance_output_loss: -15.5530 - val_loss: 73.0734 - val_mean_output_loss: 87.1963 - val_variance_output_loss: -14.1228\n",
            "Epoch 955/5000\n",
            "2/2 [==============================] - 0s 71ms/step - loss: 89.7290 - mean_output_loss: 106.1204 - variance_output_loss: -16.3913 - val_loss: 72.7345 - val_mean_output_loss: 86.8575 - val_variance_output_loss: -14.1229\n",
            "Epoch 956/5000\n",
            "2/2 [==============================] - 0s 66ms/step - loss: 90.8091 - mean_output_loss: 105.7588 - variance_output_loss: -14.9497 - val_loss: 72.3956 - val_mean_output_loss: 86.5186 - val_variance_output_loss: -14.1230\n",
            "Epoch 957/5000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 91.0147 - mean_output_loss: 105.3885 - variance_output_loss: -14.3738 - val_loss: 72.0583 - val_mean_output_loss: 86.1814 - val_variance_output_loss: -14.1231\n",
            "Epoch 958/5000\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 88.6176 - mean_output_loss: 105.0201 - variance_output_loss: -16.4025 - val_loss: 71.7224 - val_mean_output_loss: 85.8456 - val_variance_output_loss: -14.1232\n",
            "Epoch 959/5000\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 88.8991 - mean_output_loss: 104.6618 - variance_output_loss: -15.7627 - val_loss: 71.3866 - val_mean_output_loss: 85.5099 - val_variance_output_loss: -14.1233\n",
            "Epoch 960/5000\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 89.1397 - mean_output_loss: 104.2967 - variance_output_loss: -15.1570 - val_loss: 71.0525 - val_mean_output_loss: 85.1759 - val_variance_output_loss: -14.1234\n",
            "Epoch 961/5000\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 89.1873 - mean_output_loss: 103.9310 - variance_output_loss: -14.7437 - val_loss: 70.7201 - val_mean_output_loss: 84.8436 - val_variance_output_loss: -14.1235\n",
            "Epoch 962/5000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 88.7241 - mean_output_loss: 103.5640 - variance_output_loss: -14.8399 - val_loss: 70.3895 - val_mean_output_loss: 84.5131 - val_variance_output_loss: -14.1236\n",
            "Epoch 963/5000\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 87.0788 - mean_output_loss: 103.2092 - variance_output_loss: -16.1303 - val_loss: 70.0588 - val_mean_output_loss: 84.1825 - val_variance_output_loss: -14.1237\n",
            "Epoch 964/5000\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 88.1442 - mean_output_loss: 102.8490 - variance_output_loss: -14.7047 - val_loss: 69.7292 - val_mean_output_loss: 83.8530 - val_variance_output_loss: -14.1238\n",
            "Epoch 965/5000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 87.9163 - mean_output_loss: 102.4940 - variance_output_loss: -14.5778 - val_loss: 69.4002 - val_mean_output_loss: 83.5241 - val_variance_output_loss: -14.1239\n",
            "Epoch 966/5000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 87.4685 - mean_output_loss: 102.1331 - variance_output_loss: -14.6646 - val_loss: 69.0729 - val_mean_output_loss: 83.1969 - val_variance_output_loss: -14.1240\n",
            "Epoch 967/5000\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 87.1234 - mean_output_loss: 101.7808 - variance_output_loss: -14.6575 - val_loss: 68.7461 - val_mean_output_loss: 82.8702 - val_variance_output_loss: -14.1240\n",
            "Epoch 968/5000\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 84.4688 - mean_output_loss: 101.4244 - variance_output_loss: -16.9556 - val_loss: 68.4208 - val_mean_output_loss: 82.5450 - val_variance_output_loss: -14.1241\n",
            "Epoch 969/5000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 85.8250 - mean_output_loss: 101.0703 - variance_output_loss: -15.2452 - val_loss: 68.0967 - val_mean_output_loss: 82.2210 - val_variance_output_loss: -14.1242\n",
            "Epoch 970/5000\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 86.3842 - mean_output_loss: 100.7209 - variance_output_loss: -14.3367 - val_loss: 67.7734 - val_mean_output_loss: 81.8977 - val_variance_output_loss: -14.1243\n",
            "Epoch 971/5000\n",
            "2/2 [==============================] - 0s 69ms/step - loss: 85.9705 - mean_output_loss: 100.3640 - variance_output_loss: -14.3936 - val_loss: 67.4521 - val_mean_output_loss: 81.5765 - val_variance_output_loss: -14.1244\n",
            "Epoch 972/5000\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 84.8464 - mean_output_loss: 100.0175 - variance_output_loss: -15.1711 - val_loss: 67.1312 - val_mean_output_loss: 81.2557 - val_variance_output_loss: -14.1245\n",
            "Epoch 973/5000\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 84.7355 - mean_output_loss: 99.6631 - variance_output_loss: -14.9276 - val_loss: 66.8121 - val_mean_output_loss: 80.9367 - val_variance_output_loss: -14.1246\n",
            "Epoch 974/5000\n",
            "2/2 [==============================] - 0s 68ms/step - loss: 83.6258 - mean_output_loss: 99.3128 - variance_output_loss: -15.6869 - val_loss: 66.4939 - val_mean_output_loss: 80.6186 - val_variance_output_loss: -14.1247\n",
            "Epoch 975/5000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 84.8500 - mean_output_loss: 98.9710 - variance_output_loss: -14.1210 - val_loss: 66.1756 - val_mean_output_loss: 80.3004 - val_variance_output_loss: -14.1248\n",
            "Epoch 976/5000\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 83.2491 - mean_output_loss: 98.6244 - variance_output_loss: -15.3754 - val_loss: 65.8583 - val_mean_output_loss: 79.9832 - val_variance_output_loss: -14.1248\n",
            "Epoch 977/5000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 82.8455 - mean_output_loss: 98.2802 - variance_output_loss: -15.4348 - val_loss: 65.5419 - val_mean_output_loss: 79.6669 - val_variance_output_loss: -14.1249\n",
            "Epoch 978/5000\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 82.6376 - mean_output_loss: 97.9330 - variance_output_loss: -15.2954 - val_loss: 65.2270 - val_mean_output_loss: 79.3520 - val_variance_output_loss: -14.1250\n",
            "Epoch 979/5000\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 84.0399 - mean_output_loss: 97.5881 - variance_output_loss: -13.5482 - val_loss: 64.9131 - val_mean_output_loss: 79.0382 - val_variance_output_loss: -14.1251\n",
            "Epoch 980/5000\n",
            "2/2 [==============================] - 0s 67ms/step - loss: 82.1029 - mean_output_loss: 97.2505 - variance_output_loss: -15.1476 - val_loss: 64.5995 - val_mean_output_loss: 78.7247 - val_variance_output_loss: -14.1252\n",
            "Epoch 981/5000\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 81.8803 - mean_output_loss: 96.9095 - variance_output_loss: -15.0293 - val_loss: 64.2870 - val_mean_output_loss: 78.4123 - val_variance_output_loss: -14.1253\n",
            "Epoch 982/5000\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 82.1026 - mean_output_loss: 96.5684 - variance_output_loss: -14.4657 - val_loss: 63.9759 - val_mean_output_loss: 78.1012 - val_variance_output_loss: -14.1254\n",
            "Epoch 983/5000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 81.9252 - mean_output_loss: 96.2277 - variance_output_loss: -14.3025 - val_loss: 63.6661 - val_mean_output_loss: 77.7916 - val_variance_output_loss: -14.1254\n",
            "Epoch 984/5000\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 81.0137 - mean_output_loss: 95.8894 - variance_output_loss: -14.8757 - val_loss: 63.3574 - val_mean_output_loss: 77.4829 - val_variance_output_loss: -14.1255\n",
            "Epoch 985/5000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 80.3683 - mean_output_loss: 95.5508 - variance_output_loss: -15.1825 - val_loss: 63.0499 - val_mean_output_loss: 77.1755 - val_variance_output_loss: -14.1256\n",
            "Epoch 986/5000\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 80.3259 - mean_output_loss: 95.2167 - variance_output_loss: -14.8908 - val_loss: 62.7429 - val_mean_output_loss: 76.8686 - val_variance_output_loss: -14.1257\n",
            "Epoch 987/5000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 80.4921 - mean_output_loss: 94.8798 - variance_output_loss: -14.3877 - val_loss: 62.4371 - val_mean_output_loss: 76.5629 - val_variance_output_loss: -14.1258\n",
            "Epoch 988/5000\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 80.4009 - mean_output_loss: 94.5507 - variance_output_loss: -14.1498 - val_loss: 62.1316 - val_mean_output_loss: 76.2574 - val_variance_output_loss: -14.1259\n",
            "Epoch 989/5000\n",
            "2/2 [==============================] - 0s 67ms/step - loss: 79.1633 - mean_output_loss: 94.2141 - variance_output_loss: -15.0508 - val_loss: 61.8277 - val_mean_output_loss: 75.9537 - val_variance_output_loss: -14.1259\n",
            "Epoch 990/5000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 78.6210 - mean_output_loss: 93.8849 - variance_output_loss: -15.2639 - val_loss: 61.5245 - val_mean_output_loss: 75.6505 - val_variance_output_loss: -14.1260\n",
            "Epoch 991/5000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 78.4220 - mean_output_loss: 93.5544 - variance_output_loss: -15.1324 - val_loss: 61.2223 - val_mean_output_loss: 75.3484 - val_variance_output_loss: -14.1261\n",
            "Epoch 992/5000\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 77.3447 - mean_output_loss: 93.2220 - variance_output_loss: -15.8773 - val_loss: 60.9217 - val_mean_output_loss: 75.0479 - val_variance_output_loss: -14.1262\n",
            "Epoch 993/5000\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 76.1876 - mean_output_loss: 92.8959 - variance_output_loss: -16.7082 - val_loss: 60.6218 - val_mean_output_loss: 74.7480 - val_variance_output_loss: -14.1263\n",
            "Epoch 994/5000\n",
            "2/2 [==============================] - 0s 74ms/step - loss: 75.8312 - mean_output_loss: 92.5639 - variance_output_loss: -16.7327 - val_loss: 60.3234 - val_mean_output_loss: 74.4498 - val_variance_output_loss: -14.1264\n",
            "Epoch 995/5000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 78.1812 - mean_output_loss: 92.2366 - variance_output_loss: -14.0554 - val_loss: 60.0259 - val_mean_output_loss: 74.1524 - val_variance_output_loss: -14.1264\n",
            "Epoch 996/5000\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 77.3895 - mean_output_loss: 91.9161 - variance_output_loss: -14.5266 - val_loss: 59.7285 - val_mean_output_loss: 73.8550 - val_variance_output_loss: -14.1265\n",
            "Epoch 997/5000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 76.6309 - mean_output_loss: 91.5891 - variance_output_loss: -14.9582 - val_loss: 59.4324 - val_mean_output_loss: 73.5590 - val_variance_output_loss: -14.1266\n",
            "Epoch 998/5000\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 76.8935 - mean_output_loss: 91.2632 - variance_output_loss: -14.3697 - val_loss: 59.1376 - val_mean_output_loss: 73.2643 - val_variance_output_loss: -14.1267\n",
            "Epoch 999/5000\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 76.8020 - mean_output_loss: 90.9424 - variance_output_loss: -14.1404 - val_loss: 58.8432 - val_mean_output_loss: 72.9700 - val_variance_output_loss: -14.1268\n",
            "Epoch 1000/5000\n",
            "2/2 [==============================] - 0s 67ms/step - loss: 75.6791 - mean_output_loss: 90.6172 - variance_output_loss: -14.9381 - val_loss: 58.5502 - val_mean_output_loss: 72.6770 - val_variance_output_loss: -14.1268\n",
            "Epoch 1001/5000\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 74.8747 - mean_output_loss: 90.3016 - variance_output_loss: -15.4269 - val_loss: 58.2572 - val_mean_output_loss: 72.3841 - val_variance_output_loss: -14.1269\n",
            "Epoch 1002/5000\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 74.0566 - mean_output_loss: 89.9769 - variance_output_loss: -15.9203 - val_loss: 57.9659 - val_mean_output_loss: 72.0929 - val_variance_output_loss: -14.1270\n",
            "Epoch 1003/5000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 75.3036 - mean_output_loss: 89.6618 - variance_output_loss: -14.3581 - val_loss: 57.6749 - val_mean_output_loss: 71.8019 - val_variance_output_loss: -14.1271\n",
            "Epoch 1004/5000\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 73.2516 - mean_output_loss: 89.3428 - variance_output_loss: -16.0912 - val_loss: 57.3850 - val_mean_output_loss: 71.5122 - val_variance_output_loss: -14.1271\n",
            "Epoch 1005/5000\n",
            "2/2 [==============================] - 0s 67ms/step - loss: 74.5926 - mean_output_loss: 89.0221 - variance_output_loss: -14.4295 - val_loss: 57.0967 - val_mean_output_loss: 71.2239 - val_variance_output_loss: -14.1272\n",
            "Epoch 1006/5000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 72.8116 - mean_output_loss: 88.7108 - variance_output_loss: -15.8992 - val_loss: 56.8085 - val_mean_output_loss: 70.9358 - val_variance_output_loss: -14.1273\n",
            "Epoch 1007/5000\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 73.6718 - mean_output_loss: 88.3940 - variance_output_loss: -14.7223 - val_loss: 56.5217 - val_mean_output_loss: 70.6491 - val_variance_output_loss: -14.1274\n",
            "Epoch 1008/5000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 73.7610 - mean_output_loss: 88.0811 - variance_output_loss: -14.3201 - val_loss: 56.2358 - val_mean_output_loss: 70.3632 - val_variance_output_loss: -14.1275\n",
            "Epoch 1009/5000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 72.9430 - mean_output_loss: 87.7674 - variance_output_loss: -14.8244 - val_loss: 55.9511 - val_mean_output_loss: 70.0786 - val_variance_output_loss: -14.1275\n",
            "Epoch 1010/5000\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 72.3213 - mean_output_loss: 87.4565 - variance_output_loss: -15.1352 - val_loss: 55.6673 - val_mean_output_loss: 69.7949 - val_variance_output_loss: -14.1276\n",
            "Epoch 1011/5000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 71.2324 - mean_output_loss: 87.1425 - variance_output_loss: -15.9102 - val_loss: 55.3850 - val_mean_output_loss: 69.5127 - val_variance_output_loss: -14.1277\n",
            "Epoch 1012/5000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 70.4904 - mean_output_loss: 86.8348 - variance_output_loss: -16.3444 - val_loss: 55.1033 - val_mean_output_loss: 69.2310 - val_variance_output_loss: -14.1278\n",
            "Epoch 1013/5000\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 72.0294 - mean_output_loss: 86.5266 - variance_output_loss: -14.4971 - val_loss: 54.8225 - val_mean_output_loss: 68.9503 - val_variance_output_loss: -14.1278\n",
            "Epoch 1014/5000\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 71.1068 - mean_output_loss: 86.2170 - variance_output_loss: -15.1103 - val_loss: 54.5430 - val_mean_output_loss: 68.6709 - val_variance_output_loss: -14.1279\n",
            "Epoch 1015/5000\n",
            "2/2 [==============================] - 0s 71ms/step - loss: 70.5043 - mean_output_loss: 85.9141 - variance_output_loss: -15.4097 - val_loss: 54.2639 - val_mean_output_loss: 68.3919 - val_variance_output_loss: -14.1280\n",
            "Epoch 1016/5000\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 70.0675 - mean_output_loss: 85.6066 - variance_output_loss: -15.5391 - val_loss: 53.9863 - val_mean_output_loss: 68.1143 - val_variance_output_loss: -14.1280\n",
            "Epoch 1017/5000\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 70.3593 - mean_output_loss: 85.2999 - variance_output_loss: -14.9406 - val_loss: 53.7099 - val_mean_output_loss: 67.8380 - val_variance_output_loss: -14.1281\n",
            "Epoch 1018/5000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 69.6346 - mean_output_loss: 84.9970 - variance_output_loss: -15.3623 - val_loss: 53.4342 - val_mean_output_loss: 67.5624 - val_variance_output_loss: -14.1282\n",
            "Epoch 1019/5000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 68.9091 - mean_output_loss: 84.6946 - variance_output_loss: -15.7856 - val_loss: 53.1595 - val_mean_output_loss: 67.2878 - val_variance_output_loss: -14.1283\n",
            "Epoch 1020/5000\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 67.8052 - mean_output_loss: 84.3910 - variance_output_loss: -16.5857 - val_loss: 52.8858 - val_mean_output_loss: 67.0142 - val_variance_output_loss: -14.1283\n",
            "Epoch 1021/5000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 69.6928 - mean_output_loss: 84.0942 - variance_output_loss: -14.4014 - val_loss: 52.6125 - val_mean_output_loss: 66.7409 - val_variance_output_loss: -14.1284\n",
            "Epoch 1022/5000\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 69.1636 - mean_output_loss: 83.7900 - variance_output_loss: -14.6264 - val_loss: 52.3407 - val_mean_output_loss: 66.4692 - val_variance_output_loss: -14.1285\n",
            "Epoch 1023/5000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 68.5533 - mean_output_loss: 83.4906 - variance_output_loss: -14.9373 - val_loss: 52.0697 - val_mean_output_loss: 66.1983 - val_variance_output_loss: -14.1286\n",
            "Epoch 1024/5000\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 68.3274 - mean_output_loss: 83.1928 - variance_output_loss: -14.8653 - val_loss: 51.7993 - val_mean_output_loss: 65.9280 - val_variance_output_loss: -14.1286\n",
            "Epoch 1025/5000\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 68.2849 - mean_output_loss: 82.8987 - variance_output_loss: -14.6137 - val_loss: 51.5293 - val_mean_output_loss: 65.6580 - val_variance_output_loss: -14.1287\n",
            "Epoch 1026/5000\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 68.2586 - mean_output_loss: 82.6019 - variance_output_loss: -14.3433 - val_loss: 51.2603 - val_mean_output_loss: 65.3891 - val_variance_output_loss: -14.1288\n",
            "Epoch 1027/5000\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 67.4611 - mean_output_loss: 82.3082 - variance_output_loss: -14.8471 - val_loss: 50.9922 - val_mean_output_loss: 65.1211 - val_variance_output_loss: -14.1288\n",
            "Epoch 1028/5000\n",
            "2/2 [==============================] - 0s 69ms/step - loss: 66.9916 - mean_output_loss: 82.0095 - variance_output_loss: -15.0179 - val_loss: 50.7257 - val_mean_output_loss: 64.8546 - val_variance_output_loss: -14.1289\n",
            "Epoch 1029/5000\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 66.2928 - mean_output_loss: 81.7177 - variance_output_loss: -15.4250 - val_loss: 50.4598 - val_mean_output_loss: 64.5888 - val_variance_output_loss: -14.1290\n",
            "Epoch 1030/5000\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 66.3457 - mean_output_loss: 81.4295 - variance_output_loss: -15.0838 - val_loss: 50.1944 - val_mean_output_loss: 64.3234 - val_variance_output_loss: -14.1291\n",
            "Epoch 1031/5000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 67.2047 - mean_output_loss: 81.1306 - variance_output_loss: -13.9258 - val_loss: 49.9310 - val_mean_output_loss: 64.0602 - val_variance_output_loss: -14.1291\n",
            "Epoch 1032/5000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 64.9734 - mean_output_loss: 80.8419 - variance_output_loss: -15.8685 - val_loss: 49.6681 - val_mean_output_loss: 63.7973 - val_variance_output_loss: -14.1292\n",
            "Epoch 1033/5000\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 64.1310 - mean_output_loss: 80.5537 - variance_output_loss: -16.4227 - val_loss: 49.4058 - val_mean_output_loss: 63.5351 - val_variance_output_loss: -14.1293\n",
            "Epoch 1034/5000\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 65.7350 - mean_output_loss: 80.2701 - variance_output_loss: -14.5351 - val_loss: 49.1438 - val_mean_output_loss: 63.2732 - val_variance_output_loss: -14.1293\n",
            "Epoch 1035/5000\n",
            "2/2 [==============================] - 0s 67ms/step - loss: 65.8221 - mean_output_loss: 79.9761 - variance_output_loss: -14.1540 - val_loss: 48.8839 - val_mean_output_loss: 63.0133 - val_variance_output_loss: -14.1294\n",
            "Epoch 1036/5000\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 64.2499 - mean_output_loss: 79.6897 - variance_output_loss: -15.4398 - val_loss: 48.6248 - val_mean_output_loss: 62.7542 - val_variance_output_loss: -14.1295\n",
            "Epoch 1037/5000\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 64.3565 - mean_output_loss: 79.4073 - variance_output_loss: -15.0508 - val_loss: 48.3660 - val_mean_output_loss: 62.4956 - val_variance_output_loss: -14.1295\n",
            "Epoch 1038/5000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 63.8915 - mean_output_loss: 79.1179 - variance_output_loss: -15.2264 - val_loss: 48.1089 - val_mean_output_loss: 62.2385 - val_variance_output_loss: -14.1296\n",
            "Epoch 1039/5000\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 64.4543 - mean_output_loss: 78.8404 - variance_output_loss: -14.3861 - val_loss: 47.8517 - val_mean_output_loss: 61.9814 - val_variance_output_loss: -14.1297\n",
            "Epoch 1040/5000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 62.7900 - mean_output_loss: 78.5500 - variance_output_loss: -15.7599 - val_loss: 47.5966 - val_mean_output_loss: 61.7263 - val_variance_output_loss: -14.1297\n",
            "Epoch 1041/5000\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 62.6094 - mean_output_loss: 78.2696 - variance_output_loss: -15.6602 - val_loss: 47.3419 - val_mean_output_loss: 61.4717 - val_variance_output_loss: -14.1298\n",
            "Epoch 1042/5000\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 62.9313 - mean_output_loss: 77.9947 - variance_output_loss: -15.0634 - val_loss: 47.0871 - val_mean_output_loss: 61.2170 - val_variance_output_loss: -14.1299\n",
            "Epoch 1043/5000\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 63.8475 - mean_output_loss: 77.7091 - variance_output_loss: -13.8616 - val_loss: 46.8342 - val_mean_output_loss: 60.9641 - val_variance_output_loss: -14.1299\n",
            "Epoch 1044/5000\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 62.7987 - mean_output_loss: 77.4304 - variance_output_loss: -14.6316 - val_loss: 46.5820 - val_mean_output_loss: 60.7120 - val_variance_output_loss: -14.1300\n",
            "Epoch 1045/5000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 61.4995 - mean_output_loss: 77.1517 - variance_output_loss: -15.6522 - val_loss: 46.3307 - val_mean_output_loss: 60.4607 - val_variance_output_loss: -14.1301\n",
            "Epoch 1046/5000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 62.4342 - mean_output_loss: 76.8754 - variance_output_loss: -14.4411 - val_loss: 46.0800 - val_mean_output_loss: 60.2102 - val_variance_output_loss: -14.1301\n",
            "Epoch 1047/5000\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 62.5104 - mean_output_loss: 76.6004 - variance_output_loss: -14.0900 - val_loss: 45.8301 - val_mean_output_loss: 59.9603 - val_variance_output_loss: -14.1302\n",
            "Epoch 1048/5000\n",
            "2/2 [==============================] - 0s 67ms/step - loss: 61.2517 - mean_output_loss: 76.3221 - variance_output_loss: -15.0704 - val_loss: 45.5815 - val_mean_output_loss: 59.7117 - val_variance_output_loss: -14.1303\n",
            "Epoch 1049/5000\n",
            "2/2 [==============================] - 0s 100ms/step - loss: 61.6452 - mean_output_loss: 76.0520 - variance_output_loss: -14.4068 - val_loss: 45.3332 - val_mean_output_loss: 59.4635 - val_variance_output_loss: -14.1303\n",
            "Epoch 1050/5000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 61.9678 - mean_output_loss: 75.7729 - variance_output_loss: -13.8051 - val_loss: 45.0867 - val_mean_output_loss: 59.2171 - val_variance_output_loss: -14.1304\n",
            "Epoch 1051/5000\n",
            "2/2 [==============================] - 0s 83ms/step - loss: 60.0663 - mean_output_loss: 75.5040 - variance_output_loss: -15.4378 - val_loss: 44.8405 - val_mean_output_loss: 58.9710 - val_variance_output_loss: -14.1304\n",
            "Epoch 1052/5000\n",
            "2/2 [==============================] - 0s 72ms/step - loss: 61.5151 - mean_output_loss: 75.2310 - variance_output_loss: -13.7159 - val_loss: 44.5955 - val_mean_output_loss: 58.7260 - val_variance_output_loss: -14.1305\n",
            "Epoch 1053/5000\n",
            "2/2 [==============================] - 0s 77ms/step - loss: 58.5451 - mean_output_loss: 74.9562 - variance_output_loss: -16.4110 - val_loss: 44.3519 - val_mean_output_loss: 58.4825 - val_variance_output_loss: -14.1306\n",
            "Epoch 1054/5000\n",
            "2/2 [==============================] - 0s 71ms/step - loss: 60.4633 - mean_output_loss: 74.6941 - variance_output_loss: -14.2308 - val_loss: 44.1080 - val_mean_output_loss: 58.2386 - val_variance_output_loss: -14.1306\n",
            "Epoch 1055/5000\n",
            "2/2 [==============================] - 0s 69ms/step - loss: 58.7468 - mean_output_loss: 74.4175 - variance_output_loss: -15.6707 - val_loss: 43.8662 - val_mean_output_loss: 57.9969 - val_variance_output_loss: -14.1307\n",
            "Epoch 1056/5000\n",
            "2/2 [==============================] - 0s 103ms/step - loss: 60.3827 - mean_output_loss: 74.1507 - variance_output_loss: -13.7680 - val_loss: 43.6248 - val_mean_output_loss: 57.7556 - val_variance_output_loss: -14.1308\n",
            "Epoch 1057/5000\n",
            "2/2 [==============================] - 0s 71ms/step - loss: 59.2890 - mean_output_loss: 73.8827 - variance_output_loss: -14.5937 - val_loss: 43.3841 - val_mean_output_loss: 57.5150 - val_variance_output_loss: -14.1308\n",
            "Epoch 1058/5000\n",
            "2/2 [==============================] - 0s 73ms/step - loss: 58.5010 - mean_output_loss: 73.6194 - variance_output_loss: -15.1184 - val_loss: 43.1438 - val_mean_output_loss: 57.2747 - val_variance_output_loss: -14.1309\n",
            "Epoch 1059/5000\n",
            "2/2 [==============================] - 0s 68ms/step - loss: 57.5250 - mean_output_loss: 73.3540 - variance_output_loss: -15.8290 - val_loss: 42.9043 - val_mean_output_loss: 57.0352 - val_variance_output_loss: -14.1309\n",
            "Epoch 1060/5000\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 59.5535 - mean_output_loss: 73.0898 - variance_output_loss: -13.5362 - val_loss: 42.6657 - val_mean_output_loss: 56.7967 - val_variance_output_loss: -14.1310\n",
            "Epoch 1061/5000\n",
            "2/2 [==============================] - 0s 78ms/step - loss: 57.7256 - mean_output_loss: 72.8231 - variance_output_loss: -15.0975 - val_loss: 42.4285 - val_mean_output_loss: 56.5595 - val_variance_output_loss: -14.1311\n",
            "Epoch 1062/5000\n",
            "2/2 [==============================] - 0s 81ms/step - loss: 56.1031 - mean_output_loss: 72.5594 - variance_output_loss: -16.4564 - val_loss: 42.1921 - val_mean_output_loss: 56.3232 - val_variance_output_loss: -14.1311\n",
            "Epoch 1063/5000\n",
            "2/2 [==============================] - 0s 72ms/step - loss: 56.9829 - mean_output_loss: 72.2950 - variance_output_loss: -15.3121 - val_loss: 41.9567 - val_mean_output_loss: 56.0879 - val_variance_output_loss: -14.1312\n",
            "Epoch 1064/5000\n",
            "2/2 [==============================] - 0s 106ms/step - loss: 57.5520 - mean_output_loss: 72.0374 - variance_output_loss: -14.4854 - val_loss: 41.7213 - val_mean_output_loss: 55.8526 - val_variance_output_loss: -14.1313\n",
            "Epoch 1065/5000\n",
            "2/2 [==============================] - 0s 81ms/step - loss: 56.9680 - mean_output_loss: 71.7785 - variance_output_loss: -14.8104 - val_loss: 41.4867 - val_mean_output_loss: 55.6180 - val_variance_output_loss: -14.1313\n",
            "Epoch 1066/5000\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 56.7055 - mean_output_loss: 71.5144 - variance_output_loss: -14.8089 - val_loss: 41.2535 - val_mean_output_loss: 55.3848 - val_variance_output_loss: -14.1314\n",
            "Epoch 1067/5000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 57.4608 - mean_output_loss: 71.2570 - variance_output_loss: -13.7962 - val_loss: 41.0207 - val_mean_output_loss: 55.1522 - val_variance_output_loss: -14.1314\n",
            "Epoch 1068/5000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 54.2703 - mean_output_loss: 70.9992 - variance_output_loss: -16.7290 - val_loss: 40.7887 - val_mean_output_loss: 54.9202 - val_variance_output_loss: -14.1315\n",
            "Epoch 1069/5000\n",
            "2/2 [==============================] - 0s 67ms/step - loss: 57.3759 - mean_output_loss: 70.7436 - variance_output_loss: -13.3677 - val_loss: 40.5574 - val_mean_output_loss: 54.6889 - val_variance_output_loss: -14.1316\n",
            "Epoch 1070/5000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 54.2208 - mean_output_loss: 70.4816 - variance_output_loss: -16.2608 - val_loss: 40.3276 - val_mean_output_loss: 54.4592 - val_variance_output_loss: -14.1316\n",
            "Epoch 1071/5000\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 56.3043 - mean_output_loss: 70.2324 - variance_output_loss: -13.9281 - val_loss: 40.0975 - val_mean_output_loss: 54.2292 - val_variance_output_loss: -14.1317\n",
            "Epoch 1072/5000\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 56.2471 - mean_output_loss: 69.9780 - variance_output_loss: -13.7310 - val_loss: 39.8685 - val_mean_output_loss: 54.0002 - val_variance_output_loss: -14.1317\n",
            "Epoch 1073/5000\n",
            "2/2 [==============================] - 0s 71ms/step - loss: 54.9477 - mean_output_loss: 69.7205 - variance_output_loss: -14.7728 - val_loss: 39.6410 - val_mean_output_loss: 53.7728 - val_variance_output_loss: -14.1318\n",
            "Epoch 1074/5000\n",
            "2/2 [==============================] - 0s 74ms/step - loss: 54.3516 - mean_output_loss: 69.4660 - variance_output_loss: -15.1145 - val_loss: 39.4144 - val_mean_output_loss: 53.5462 - val_variance_output_loss: -14.1319\n",
            "Epoch 1075/5000\n",
            "2/2 [==============================] - 0s 69ms/step - loss: 54.5033 - mean_output_loss: 69.2173 - variance_output_loss: -14.7139 - val_loss: 39.1880 - val_mean_output_loss: 53.3199 - val_variance_output_loss: -14.1319\n",
            "Epoch 1076/5000\n",
            "2/2 [==============================] - 0s 74ms/step - loss: 54.2966 - mean_output_loss: 68.9643 - variance_output_loss: -14.6677 - val_loss: 38.9628 - val_mean_output_loss: 53.0947 - val_variance_output_loss: -14.1320\n",
            "Epoch 1077/5000\n",
            "2/2 [==============================] - 0s 74ms/step - loss: 54.2824 - mean_output_loss: 68.7143 - variance_output_loss: -14.4318 - val_loss: 38.7382 - val_mean_output_loss: 52.8702 - val_variance_output_loss: -14.1320\n",
            "Epoch 1078/5000\n",
            "2/2 [==============================] - 0s 72ms/step - loss: 53.9249 - mean_output_loss: 68.4656 - variance_output_loss: -14.5408 - val_loss: 38.5144 - val_mean_output_loss: 52.6464 - val_variance_output_loss: -14.1321\n",
            "Epoch 1079/5000\n",
            "2/2 [==============================] - 0s 70ms/step - loss: 51.9742 - mean_output_loss: 68.2148 - variance_output_loss: -16.2406 - val_loss: 38.2916 - val_mean_output_loss: 52.4237 - val_variance_output_loss: -14.1321\n",
            "Epoch 1080/5000\n",
            "2/2 [==============================] - 0s 70ms/step - loss: 54.1892 - mean_output_loss: 67.9682 - variance_output_loss: -13.7790 - val_loss: 38.0694 - val_mean_output_loss: 52.2016 - val_variance_output_loss: -14.1322\n",
            "Epoch 1081/5000\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 52.1330 - mean_output_loss: 67.7217 - variance_output_loss: -15.5887 - val_loss: 37.8479 - val_mean_output_loss: 51.9802 - val_variance_output_loss: -14.1323\n",
            "Epoch 1082/5000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 52.4984 - mean_output_loss: 67.4744 - variance_output_loss: -14.9760 - val_loss: 37.6274 - val_mean_output_loss: 51.7598 - val_variance_output_loss: -14.1323\n",
            "Epoch 1083/5000\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 52.0730 - mean_output_loss: 67.2288 - variance_output_loss: -15.1558 - val_loss: 37.4078 - val_mean_output_loss: 51.5401 - val_variance_output_loss: -14.1324\n",
            "Epoch 1084/5000\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 51.7306 - mean_output_loss: 66.9838 - variance_output_loss: -15.2532 - val_loss: 37.1889 - val_mean_output_loss: 51.3213 - val_variance_output_loss: -14.1324\n",
            "Epoch 1085/5000\n",
            "2/2 [==============================] - 0s 67ms/step - loss: 51.6917 - mean_output_loss: 66.7402 - variance_output_loss: -15.0485 - val_loss: 36.9707 - val_mean_output_loss: 51.1032 - val_variance_output_loss: -14.1325\n",
            "Epoch 1086/5000\n",
            "2/2 [==============================] - 0s 67ms/step - loss: 51.1138 - mean_output_loss: 66.4979 - variance_output_loss: -15.3841 - val_loss: 36.7533 - val_mean_output_loss: 50.8858 - val_variance_output_loss: -14.1325\n",
            "Epoch 1087/5000\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 50.7087 - mean_output_loss: 66.2536 - variance_output_loss: -15.5449 - val_loss: 36.5368 - val_mean_output_loss: 50.6694 - val_variance_output_loss: -14.1326\n",
            "Epoch 1088/5000\n",
            "2/2 [==============================] - 0s 66ms/step - loss: 52.2675 - mean_output_loss: 66.0128 - variance_output_loss: -13.7454 - val_loss: 36.3209 - val_mean_output_loss: 50.4536 - val_variance_output_loss: -14.1326\n",
            "Epoch 1089/5000\n",
            "2/2 [==============================] - 0s 84ms/step - loss: 50.4919 - mean_output_loss: 65.7738 - variance_output_loss: -15.2819 - val_loss: 36.1055 - val_mean_output_loss: 50.2382 - val_variance_output_loss: -14.1327\n",
            "Epoch 1090/5000\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 50.9774 - mean_output_loss: 65.5330 - variance_output_loss: -14.5556 - val_loss: 35.8911 - val_mean_output_loss: 50.0239 - val_variance_output_loss: -14.1328\n",
            "Epoch 1091/5000\n",
            "2/2 [==============================] - 0s 66ms/step - loss: 49.0178 - mean_output_loss: 65.2928 - variance_output_loss: -16.2750 - val_loss: 35.6776 - val_mean_output_loss: 49.8104 - val_variance_output_loss: -14.1328\n",
            "Epoch 1092/5000\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 49.6835 - mean_output_loss: 65.0539 - variance_output_loss: -15.3704 - val_loss: 35.4648 - val_mean_output_loss: 49.5977 - val_variance_output_loss: -14.1329\n",
            "Epoch 1093/5000\n",
            "2/2 [==============================] - 0s 82ms/step - loss: 50.6867 - mean_output_loss: 64.8202 - variance_output_loss: -14.1335 - val_loss: 35.2522 - val_mean_output_loss: 49.3851 - val_variance_output_loss: -14.1329\n",
            "Epoch 1094/5000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 50.6103 - mean_output_loss: 64.5811 - variance_output_loss: -13.9708 - val_loss: 35.0409 - val_mean_output_loss: 49.1738 - val_variance_output_loss: -14.1330\n",
            "Epoch 1095/5000\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 49.1128 - mean_output_loss: 64.3427 - variance_output_loss: -15.2299 - val_loss: 34.8306 - val_mean_output_loss: 48.9636 - val_variance_output_loss: -14.1330\n",
            "Epoch 1096/5000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 48.8645 - mean_output_loss: 64.1099 - variance_output_loss: -15.2454 - val_loss: 34.6206 - val_mean_output_loss: 48.7537 - val_variance_output_loss: -14.1331\n",
            "Epoch 1097/5000\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 48.6777 - mean_output_loss: 63.8723 - variance_output_loss: -15.1946 - val_loss: 34.4118 - val_mean_output_loss: 48.5449 - val_variance_output_loss: -14.1331\n",
            "Epoch 1098/5000\n",
            "2/2 [==============================] - 0s 70ms/step - loss: 47.8953 - mean_output_loss: 63.6386 - variance_output_loss: -15.7433 - val_loss: 34.2034 - val_mean_output_loss: 48.3366 - val_variance_output_loss: -14.1332\n",
            "Epoch 1099/5000\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 48.5760 - mean_output_loss: 63.4095 - variance_output_loss: -14.8335 - val_loss: 33.9951 - val_mean_output_loss: 48.1283 - val_variance_output_loss: -14.1332\n",
            "Epoch 1100/5000\n",
            "2/2 [==============================] - 0s 71ms/step - loss: 49.1205 - mean_output_loss: 63.1769 - variance_output_loss: -14.0564 - val_loss: 33.7877 - val_mean_output_loss: 47.9210 - val_variance_output_loss: -14.1333\n",
            "Epoch 1101/5000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 48.3930 - mean_output_loss: 62.9423 - variance_output_loss: -14.5493 - val_loss: 33.5815 - val_mean_output_loss: 47.7148 - val_variance_output_loss: -14.1334\n",
            "Epoch 1102/5000\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 47.7070 - mean_output_loss: 62.7096 - variance_output_loss: -15.0026 - val_loss: 33.3761 - val_mean_output_loss: 47.5095 - val_variance_output_loss: -14.1334\n",
            "Epoch 1103/5000\n",
            "2/2 [==============================] - 0s 67ms/step - loss: 48.1544 - mean_output_loss: 62.4839 - variance_output_loss: -14.3295 - val_loss: 33.1707 - val_mean_output_loss: 47.3042 - val_variance_output_loss: -14.1335\n",
            "Epoch 1104/5000\n",
            "2/2 [==============================] - 0s 70ms/step - loss: 47.4866 - mean_output_loss: 62.2567 - variance_output_loss: -14.7700 - val_loss: 32.9660 - val_mean_output_loss: 47.0995 - val_variance_output_loss: -14.1335\n",
            "Epoch 1105/5000\n",
            "2/2 [==============================] - 0s 111ms/step - loss: 48.9764 - mean_output_loss: 62.0262 - variance_output_loss: -13.0498 - val_loss: 32.7625 - val_mean_output_loss: 46.8960 - val_variance_output_loss: -14.1336\n",
            "Epoch 1106/5000\n",
            "2/2 [==============================] - 0s 76ms/step - loss: 47.0877 - mean_output_loss: 61.7977 - variance_output_loss: -14.7100 - val_loss: 32.5599 - val_mean_output_loss: 46.6936 - val_variance_output_loss: -14.1336\n",
            "Epoch 1107/5000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 46.7173 - mean_output_loss: 61.5694 - variance_output_loss: -14.8521 - val_loss: 32.3584 - val_mean_output_loss: 46.4921 - val_variance_output_loss: -14.1337\n",
            "Epoch 1108/5000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 47.0778 - mean_output_loss: 61.3456 - variance_output_loss: -14.2678 - val_loss: 32.1573 - val_mean_output_loss: 46.2910 - val_variance_output_loss: -14.1337\n",
            "Epoch 1109/5000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 47.8881 - mean_output_loss: 61.1230 - variance_output_loss: -13.2348 - val_loss: 31.9568 - val_mean_output_loss: 46.0905 - val_variance_output_loss: -14.1338\n",
            "Epoch 1110/5000\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 44.4293 - mean_output_loss: 60.8925 - variance_output_loss: -16.4631 - val_loss: 31.7579 - val_mean_output_loss: 45.8918 - val_variance_output_loss: -14.1338\n",
            "Epoch 1111/5000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 45.3210 - mean_output_loss: 60.6729 - variance_output_loss: -15.3519 - val_loss: 31.5592 - val_mean_output_loss: 45.6931 - val_variance_output_loss: -14.1339\n",
            "Epoch 1112/5000\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 45.0082 - mean_output_loss: 60.4505 - variance_output_loss: -15.4423 - val_loss: 31.3612 - val_mean_output_loss: 45.4951 - val_variance_output_loss: -14.1339\n",
            "Epoch 1113/5000\n",
            "2/2 [==============================] - 0s 69ms/step - loss: 44.6003 - mean_output_loss: 60.2285 - variance_output_loss: -15.6282 - val_loss: 31.1641 - val_mean_output_loss: 45.2980 - val_variance_output_loss: -14.1340\n",
            "Epoch 1114/5000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 45.0168 - mean_output_loss: 60.0078 - variance_output_loss: -14.9910 - val_loss: 30.9677 - val_mean_output_loss: 45.1018 - val_variance_output_loss: -14.1340\n",
            "Epoch 1115/5000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 45.5147 - mean_output_loss: 59.7845 - variance_output_loss: -14.2698 - val_loss: 30.7726 - val_mean_output_loss: 44.9067 - val_variance_output_loss: -14.1341\n",
            "Epoch 1116/5000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 44.7328 - mean_output_loss: 59.5667 - variance_output_loss: -14.8339 - val_loss: 30.5778 - val_mean_output_loss: 44.7119 - val_variance_output_loss: -14.1341\n",
            "Epoch 1117/5000\n",
            "2/2 [==============================] - 0s 71ms/step - loss: 44.4236 - mean_output_loss: 59.3460 - variance_output_loss: -14.9224 - val_loss: 30.3839 - val_mean_output_loss: 44.5181 - val_variance_output_loss: -14.1342\n",
            "Epoch 1118/5000\n",
            "2/2 [==============================] - 0s 75ms/step - loss: 44.6466 - mean_output_loss: 59.1314 - variance_output_loss: -14.4848 - val_loss: 30.1902 - val_mean_output_loss: 44.3244 - val_variance_output_loss: -14.1342\n",
            "Epoch 1119/5000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 44.9836 - mean_output_loss: 58.9118 - variance_output_loss: -13.9282 - val_loss: 29.9975 - val_mean_output_loss: 44.1317 - val_variance_output_loss: -14.1343\n",
            "Epoch 1120/5000\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 43.9226 - mean_output_loss: 58.6918 - variance_output_loss: -14.7692 - val_loss: 29.8058 - val_mean_output_loss: 43.9401 - val_variance_output_loss: -14.1343\n",
            "Epoch 1121/5000\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 42.9276 - mean_output_loss: 58.4847 - variance_output_loss: -15.5571 - val_loss: 29.6135 - val_mean_output_loss: 43.7479 - val_variance_output_loss: -14.1344\n",
            "Epoch 1122/5000\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 44.3343 - mean_output_loss: 58.2664 - variance_output_loss: -13.9321 - val_loss: 29.4227 - val_mean_output_loss: 43.5571 - val_variance_output_loss: -14.1344\n",
            "Epoch 1123/5000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 42.6154 - mean_output_loss: 58.0531 - variance_output_loss: -15.4377 - val_loss: 29.2326 - val_mean_output_loss: 43.3670 - val_variance_output_loss: -14.1345\n",
            "Epoch 1124/5000\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 42.7135 - mean_output_loss: 57.8362 - variance_output_loss: -15.1227 - val_loss: 29.0438 - val_mean_output_loss: 43.1783 - val_variance_output_loss: -14.1345\n",
            "Epoch 1125/5000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 41.9216 - mean_output_loss: 57.6223 - variance_output_loss: -15.7008 - val_loss: 28.8559 - val_mean_output_loss: 42.9904 - val_variance_output_loss: -14.1346\n",
            "Epoch 1126/5000\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 42.3365 - mean_output_loss: 57.4140 - variance_output_loss: -15.0775 - val_loss: 28.6680 - val_mean_output_loss: 42.8026 - val_variance_output_loss: -14.1346\n",
            "Epoch 1127/5000\n",
            "2/2 [==============================] - 0s 67ms/step - loss: 42.0879 - mean_output_loss: 57.1985 - variance_output_loss: -15.1105 - val_loss: 28.4815 - val_mean_output_loss: 42.6161 - val_variance_output_loss: -14.1347\n",
            "Epoch 1128/5000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 40.9774 - mean_output_loss: 56.9932 - variance_output_loss: -16.0158 - val_loss: 28.2948 - val_mean_output_loss: 42.4295 - val_variance_output_loss: -14.1347\n",
            "Epoch 1129/5000\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 41.9617 - mean_output_loss: 56.7799 - variance_output_loss: -14.8183 - val_loss: 28.1094 - val_mean_output_loss: 42.2441 - val_variance_output_loss: -14.1348\n",
            "Epoch 1130/5000\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 41.3774 - mean_output_loss: 56.5738 - variance_output_loss: -15.1964 - val_loss: 27.9243 - val_mean_output_loss: 42.0591 - val_variance_output_loss: -14.1348\n",
            "Epoch 1131/5000\n",
            "2/2 [==============================] - 0s 67ms/step - loss: 41.0404 - mean_output_loss: 56.3629 - variance_output_loss: -15.3226 - val_loss: 27.7403 - val_mean_output_loss: 41.8752 - val_variance_output_loss: -14.1349\n",
            "Epoch 1132/5000\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 42.0719 - mean_output_loss: 56.1564 - variance_output_loss: -14.0846 - val_loss: 27.5569 - val_mean_output_loss: 41.6918 - val_variance_output_loss: -14.1349\n",
            "Epoch 1133/5000\n",
            "2/2 [==============================] - 0s 80ms/step - loss: 40.4095 - mean_output_loss: 55.9475 - variance_output_loss: -15.5380 - val_loss: 27.3744 - val_mean_output_loss: 41.5094 - val_variance_output_loss: -14.1350\n",
            "Epoch 1134/5000\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 39.7808 - mean_output_loss: 55.7411 - variance_output_loss: -15.9604 - val_loss: 27.1925 - val_mean_output_loss: 41.3275 - val_variance_output_loss: -14.1350\n",
            "Epoch 1135/5000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 41.1887 - mean_output_loss: 55.5388 - variance_output_loss: -14.3501 - val_loss: 27.0107 - val_mean_output_loss: 41.1458 - val_variance_output_loss: -14.1350\n",
            "Epoch 1136/5000\n",
            "2/2 [==============================] - 0s 74ms/step - loss: 40.7969 - mean_output_loss: 55.3341 - variance_output_loss: -14.5372 - val_loss: 26.8298 - val_mean_output_loss: 40.9648 - val_variance_output_loss: -14.1351\n",
            "Epoch 1137/5000\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 39.1996 - mean_output_loss: 55.1293 - variance_output_loss: -15.9298 - val_loss: 26.6497 - val_mean_output_loss: 40.7848 - val_variance_output_loss: -14.1351\n",
            "Epoch 1138/5000\n",
            "2/2 [==============================] - 0s 71ms/step - loss: 40.3572 - mean_output_loss: 54.9287 - variance_output_loss: -14.5715 - val_loss: 26.4701 - val_mean_output_loss: 40.6052 - val_variance_output_loss: -14.1352\n",
            "Epoch 1139/5000\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 38.8357 - mean_output_loss: 54.7267 - variance_output_loss: -15.8910 - val_loss: 26.2913 - val_mean_output_loss: 40.4266 - val_variance_output_loss: -14.1352\n",
            "Epoch 1140/5000\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 39.6402 - mean_output_loss: 54.5215 - variance_output_loss: -14.8813 - val_loss: 26.1140 - val_mean_output_loss: 40.2493 - val_variance_output_loss: -14.1353\n",
            "Epoch 1141/5000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 40.4254 - mean_output_loss: 54.3200 - variance_output_loss: -13.8947 - val_loss: 25.9375 - val_mean_output_loss: 40.0728 - val_variance_output_loss: -14.1353\n",
            "Epoch 1142/5000\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 38.9523 - mean_output_loss: 54.1229 - variance_output_loss: -15.1705 - val_loss: 25.7612 - val_mean_output_loss: 39.8965 - val_variance_output_loss: -14.1354\n",
            "Epoch 1143/5000\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 38.4393 - mean_output_loss: 53.9228 - variance_output_loss: -15.4835 - val_loss: 25.5857 - val_mean_output_loss: 39.7211 - val_variance_output_loss: -14.1354\n",
            "Epoch 1144/5000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 38.7995 - mean_output_loss: 53.7216 - variance_output_loss: -14.9221 - val_loss: 25.4113 - val_mean_output_loss: 39.5467 - val_variance_output_loss: -14.1355\n",
            "Epoch 1145/5000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 39.1119 - mean_output_loss: 53.5248 - variance_output_loss: -14.4129 - val_loss: 25.2372 - val_mean_output_loss: 39.3727 - val_variance_output_loss: -14.1355\n",
            "Epoch 1146/5000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 38.4001 - mean_output_loss: 53.3328 - variance_output_loss: -14.9327 - val_loss: 25.0631 - val_mean_output_loss: 39.1986 - val_variance_output_loss: -14.1356\n",
            "Epoch 1147/5000\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 36.0150 - mean_output_loss: 53.1309 - variance_output_loss: -17.1159 - val_loss: 24.8905 - val_mean_output_loss: 39.0261 - val_variance_output_loss: -14.1356\n",
            "Epoch 1148/5000\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 37.3981 - mean_output_loss: 52.9381 - variance_output_loss: -15.5401 - val_loss: 24.7182 - val_mean_output_loss: 38.8538 - val_variance_output_loss: -14.1356\n",
            "Epoch 1149/5000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 37.4204 - mean_output_loss: 52.7393 - variance_output_loss: -15.3189 - val_loss: 24.5471 - val_mean_output_loss: 38.6828 - val_variance_output_loss: -14.1357\n",
            "Epoch 1150/5000\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 36.6640 - mean_output_loss: 52.5509 - variance_output_loss: -15.8869 - val_loss: 24.3757 - val_mean_output_loss: 38.5114 - val_variance_output_loss: -14.1357\n",
            "Epoch 1151/5000\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 37.9179 - mean_output_loss: 52.3532 - variance_output_loss: -14.4353 - val_loss: 24.2058 - val_mean_output_loss: 38.3416 - val_variance_output_loss: -14.1358\n",
            "Epoch 1152/5000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 37.0578 - mean_output_loss: 52.1580 - variance_output_loss: -15.1002 - val_loss: 24.0367 - val_mean_output_loss: 38.1725 - val_variance_output_loss: -14.1358\n",
            "Epoch 1153/5000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 36.7123 - mean_output_loss: 51.9704 - variance_output_loss: -15.2581 - val_loss: 23.8675 - val_mean_output_loss: 38.0033 - val_variance_output_loss: -14.1359\n",
            "Epoch 1154/5000\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 37.5404 - mean_output_loss: 51.7779 - variance_output_loss: -14.2375 - val_loss: 23.6992 - val_mean_output_loss: 37.8351 - val_variance_output_loss: -14.1359\n",
            "Epoch 1155/5000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 35.6556 - mean_output_loss: 51.5861 - variance_output_loss: -15.9306 - val_loss: 23.5317 - val_mean_output_loss: 37.6676 - val_variance_output_loss: -14.1360\n",
            "Epoch 1156/5000\n",
            "2/2 [==============================] - 0s 73ms/step - loss: 37.3171 - mean_output_loss: 51.3969 - variance_output_loss: -14.0798 - val_loss: 23.3647 - val_mean_output_loss: 37.5007 - val_variance_output_loss: -14.1360\n",
            "Epoch 1157/5000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 36.0890 - mean_output_loss: 51.2059 - variance_output_loss: -15.1168 - val_loss: 23.1987 - val_mean_output_loss: 37.3347 - val_variance_output_loss: -14.1360\n",
            "Epoch 1158/5000\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 37.7499 - mean_output_loss: 51.0190 - variance_output_loss: -13.2691 - val_loss: 23.0330 - val_mean_output_loss: 37.1691 - val_variance_output_loss: -14.1361\n",
            "Epoch 1159/5000\n",
            "2/2 [==============================] - 0s 69ms/step - loss: 35.3729 - mean_output_loss: 50.8285 - variance_output_loss: -15.4556 - val_loss: 22.8683 - val_mean_output_loss: 37.0044 - val_variance_output_loss: -14.1361\n",
            "Epoch 1160/5000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 34.7958 - mean_output_loss: 50.6401 - variance_output_loss: -15.8443 - val_loss: 22.7043 - val_mean_output_loss: 36.8404 - val_variance_output_loss: -14.1362\n",
            "Epoch 1161/5000\n",
            "2/2 [==============================] - 0s 66ms/step - loss: 34.1912 - mean_output_loss: 50.4544 - variance_output_loss: -16.2632 - val_loss: 22.5405 - val_mean_output_loss: 36.6767 - val_variance_output_loss: -14.1362\n",
            "Epoch 1162/5000\n",
            "2/2 [==============================] - 0s 73ms/step - loss: 36.2548 - mean_output_loss: 50.2698 - variance_output_loss: -14.0150 - val_loss: 22.3772 - val_mean_output_loss: 36.5134 - val_variance_output_loss: -14.1363\n",
            "Epoch 1163/5000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 33.8558 - mean_output_loss: 50.0832 - variance_output_loss: -16.2274 - val_loss: 22.2146 - val_mean_output_loss: 36.3509 - val_variance_output_loss: -14.1363\n",
            "Epoch 1164/5000\n",
            "2/2 [==============================] - 0s 70ms/step - loss: 36.0929 - mean_output_loss: 49.9006 - variance_output_loss: -13.8076 - val_loss: 22.0524 - val_mean_output_loss: 36.1888 - val_variance_output_loss: -14.1363\n",
            "Epoch 1165/5000\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 34.3210 - mean_output_loss: 49.7126 - variance_output_loss: -15.3916 - val_loss: 21.8915 - val_mean_output_loss: 36.0278 - val_variance_output_loss: -14.1364\n",
            "Epoch 1166/5000\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 33.9253 - mean_output_loss: 49.5291 - variance_output_loss: -15.6038 - val_loss: 21.7310 - val_mean_output_loss: 35.8674 - val_variance_output_loss: -14.1364\n",
            "Epoch 1167/5000\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 34.1443 - mean_output_loss: 49.3472 - variance_output_loss: -15.2029 - val_loss: 21.5709 - val_mean_output_loss: 35.7074 - val_variance_output_loss: -14.1365\n",
            "Epoch 1168/5000\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 34.7133 - mean_output_loss: 49.1660 - variance_output_loss: -14.4528 - val_loss: 21.4113 - val_mean_output_loss: 35.5478 - val_variance_output_loss: -14.1365\n",
            "Epoch 1169/5000\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 34.3170 - mean_output_loss: 48.9831 - variance_output_loss: -14.6661 - val_loss: 21.2526 - val_mean_output_loss: 35.3891 - val_variance_output_loss: -14.1366\n",
            "Epoch 1170/5000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 34.5279 - mean_output_loss: 48.8022 - variance_output_loss: -14.2743 - val_loss: 21.0944 - val_mean_output_loss: 35.2310 - val_variance_output_loss: -14.1366\n",
            "Epoch 1171/5000\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 33.2779 - mean_output_loss: 48.6219 - variance_output_loss: -15.3440 - val_loss: 20.9369 - val_mean_output_loss: 35.0735 - val_variance_output_loss: -14.1366\n",
            "Epoch 1172/5000\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 33.1758 - mean_output_loss: 48.4424 - variance_output_loss: -15.2666 - val_loss: 20.7799 - val_mean_output_loss: 34.9166 - val_variance_output_loss: -14.1367\n",
            "Epoch 1173/5000\n",
            "2/2 [==============================] - 0s 66ms/step - loss: 33.2477 - mean_output_loss: 48.2624 - variance_output_loss: -15.0148 - val_loss: 20.6237 - val_mean_output_loss: 34.7604 - val_variance_output_loss: -14.1367\n",
            "Epoch 1174/5000\n",
            "2/2 [==============================] - 0s 76ms/step - loss: 34.0901 - mean_output_loss: 48.0855 - variance_output_loss: -13.9954 - val_loss: 20.4679 - val_mean_output_loss: 34.6047 - val_variance_output_loss: -14.1368\n",
            "Epoch 1175/5000\n",
            "2/2 [==============================] - 0s 69ms/step - loss: 32.6015 - mean_output_loss: 47.9067 - variance_output_loss: -15.3052 - val_loss: 20.3129 - val_mean_output_loss: 34.4497 - val_variance_output_loss: -14.1368\n",
            "Epoch 1176/5000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 33.2551 - mean_output_loss: 47.7291 - variance_output_loss: -14.4741 - val_loss: 20.1586 - val_mean_output_loss: 34.2954 - val_variance_output_loss: -14.1368\n",
            "Epoch 1177/5000\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 33.8678 - mean_output_loss: 47.5547 - variance_output_loss: -13.6869 - val_loss: 20.0045 - val_mean_output_loss: 34.1414 - val_variance_output_loss: -14.1369\n",
            "Epoch 1178/5000\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 33.4769 - mean_output_loss: 47.3737 - variance_output_loss: -13.8969 - val_loss: 19.8518 - val_mean_output_loss: 33.9888 - val_variance_output_loss: -14.1369\n",
            "Epoch 1179/5000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 32.3249 - mean_output_loss: 47.2025 - variance_output_loss: -14.8777 - val_loss: 19.6990 - val_mean_output_loss: 33.8359 - val_variance_output_loss: -14.1370\n",
            "Epoch 1180/5000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 31.9531 - mean_output_loss: 47.0295 - variance_output_loss: -15.0765 - val_loss: 19.5466 - val_mean_output_loss: 33.6836 - val_variance_output_loss: -14.1370\n",
            "Epoch 1181/5000\n",
            "2/2 [==============================] - 0s 67ms/step - loss: 32.1055 - mean_output_loss: 46.8525 - variance_output_loss: -14.7470 - val_loss: 19.3953 - val_mean_output_loss: 33.5323 - val_variance_output_loss: -14.1370\n",
            "Epoch 1182/5000\n",
            "2/2 [==============================] - 0s 68ms/step - loss: 30.9241 - mean_output_loss: 46.6792 - variance_output_loss: -15.7551 - val_loss: 19.2445 - val_mean_output_loss: 33.3816 - val_variance_output_loss: -14.1371\n",
            "Epoch 1183/5000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 31.6217 - mean_output_loss: 46.5053 - variance_output_loss: -14.8835 - val_loss: 19.0944 - val_mean_output_loss: 33.2316 - val_variance_output_loss: -14.1371\n",
            "Epoch 1184/5000\n",
            "2/2 [==============================] - 0s 69ms/step - loss: 31.8224 - mean_output_loss: 46.3358 - variance_output_loss: -14.5134 - val_loss: 18.9445 - val_mean_output_loss: 33.0816 - val_variance_output_loss: -14.1372\n",
            "Epoch 1185/5000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 30.8489 - mean_output_loss: 46.1638 - variance_output_loss: -15.3149 - val_loss: 18.7952 - val_mean_output_loss: 32.9324 - val_variance_output_loss: -14.1372\n",
            "Epoch 1186/5000\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 30.9842 - mean_output_loss: 45.9896 - variance_output_loss: -15.0054 - val_loss: 18.6469 - val_mean_output_loss: 32.7842 - val_variance_output_loss: -14.1372\n",
            "Epoch 1187/5000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 30.1614 - mean_output_loss: 45.8220 - variance_output_loss: -15.6606 - val_loss: 18.4988 - val_mean_output_loss: 32.6360 - val_variance_output_loss: -14.1373\n",
            "Epoch 1188/5000\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 30.5497 - mean_output_loss: 45.6553 - variance_output_loss: -15.1056 - val_loss: 18.3508 - val_mean_output_loss: 32.4882 - val_variance_output_loss: -14.1373\n",
            "Epoch 1189/5000\n",
            "2/2 [==============================] - 0s 75ms/step - loss: 29.0909 - mean_output_loss: 45.4821 - variance_output_loss: -16.3913 - val_loss: 18.2042 - val_mean_output_loss: 32.3416 - val_variance_output_loss: -14.1374\n",
            "Epoch 1190/5000\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 30.8503 - mean_output_loss: 45.3189 - variance_output_loss: -14.4686 - val_loss: 18.0576 - val_mean_output_loss: 32.1950 - val_variance_output_loss: -14.1374\n",
            "Epoch 1191/5000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 29.0806 - mean_output_loss: 45.1452 - variance_output_loss: -16.0646 - val_loss: 17.9126 - val_mean_output_loss: 32.0501 - val_variance_output_loss: -14.1374\n",
            "Epoch 1192/5000\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 30.1775 - mean_output_loss: 44.9786 - variance_output_loss: -14.8011 - val_loss: 17.7680 - val_mean_output_loss: 31.9055 - val_variance_output_loss: -14.1375\n",
            "Epoch 1193/5000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 29.4300 - mean_output_loss: 44.8113 - variance_output_loss: -15.3813 - val_loss: 17.6240 - val_mean_output_loss: 31.7615 - val_variance_output_loss: -14.1375\n",
            "Epoch 1194/5000\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 30.7714 - mean_output_loss: 44.6501 - variance_output_loss: -13.8788 - val_loss: 17.4798 - val_mean_output_loss: 31.6174 - val_variance_output_loss: -14.1376\n",
            "Epoch 1195/5000\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 29.2851 - mean_output_loss: 44.4804 - variance_output_loss: -15.1953 - val_loss: 17.3369 - val_mean_output_loss: 31.4745 - val_variance_output_loss: -14.1376\n",
            "Epoch 1196/5000\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 29.8724 - mean_output_loss: 44.3190 - variance_output_loss: -14.4465 - val_loss: 17.1941 - val_mean_output_loss: 31.3317 - val_variance_output_loss: -14.1376\n",
            "Epoch 1197/5000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 29.0322 - mean_output_loss: 44.1524 - variance_output_loss: -15.1202 - val_loss: 17.0522 - val_mean_output_loss: 31.1899 - val_variance_output_loss: -14.1377\n",
            "Epoch 1198/5000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 29.4537 - mean_output_loss: 43.9911 - variance_output_loss: -14.5374 - val_loss: 16.9106 - val_mean_output_loss: 31.0483 - val_variance_output_loss: -14.1377\n",
            "Epoch 1199/5000\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 28.1702 - mean_output_loss: 43.8281 - variance_output_loss: -15.6578 - val_loss: 16.7696 - val_mean_output_loss: 30.9074 - val_variance_output_loss: -14.1378\n",
            "Epoch 1200/5000\n",
            "2/2 [==============================] - 0s 79ms/step - loss: 28.8337 - mean_output_loss: 43.6618 - variance_output_loss: -14.8282 - val_loss: 16.6297 - val_mean_output_loss: 30.7675 - val_variance_output_loss: -14.1378\n",
            "Epoch 1201/5000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 27.1417 - mean_output_loss: 43.5045 - variance_output_loss: -16.3628 - val_loss: 16.4897 - val_mean_output_loss: 30.6275 - val_variance_output_loss: -14.1378\n",
            "Epoch 1202/5000\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 28.6714 - mean_output_loss: 43.3407 - variance_output_loss: -14.6693 - val_loss: 16.3506 - val_mean_output_loss: 30.4885 - val_variance_output_loss: -14.1379\n",
            "Epoch 1203/5000\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 29.1104 - mean_output_loss: 43.1785 - variance_output_loss: -14.0681 - val_loss: 16.2122 - val_mean_output_loss: 30.3501 - val_variance_output_loss: -14.1379\n",
            "Epoch 1204/5000\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 27.9408 - mean_output_loss: 43.0196 - variance_output_loss: -15.0787 - val_loss: 16.0739 - val_mean_output_loss: 30.2118 - val_variance_output_loss: -14.1379\n",
            "Epoch 1205/5000\n",
            "2/2 [==============================] - 0s 66ms/step - loss: 27.7165 - mean_output_loss: 42.8638 - variance_output_loss: -15.1472 - val_loss: 15.9356 - val_mean_output_loss: 30.0736 - val_variance_output_loss: -14.1380\n",
            "Epoch 1206/5000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 28.0219 - mean_output_loss: 42.7012 - variance_output_loss: -14.6793 - val_loss: 15.7985 - val_mean_output_loss: 29.9366 - val_variance_output_loss: -14.1380\n",
            "Epoch 1207/5000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 27.0230 - mean_output_loss: 42.5487 - variance_output_loss: -15.5257 - val_loss: 15.6613 - val_mean_output_loss: 29.7993 - val_variance_output_loss: -14.1381\n",
            "Epoch 1208/5000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 27.0788 - mean_output_loss: 42.3866 - variance_output_loss: -15.3078 - val_loss: 15.5255 - val_mean_output_loss: 29.6636 - val_variance_output_loss: -14.1381\n",
            "Epoch 1209/5000\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 26.4526 - mean_output_loss: 42.2268 - variance_output_loss: -15.7742 - val_loss: 15.3906 - val_mean_output_loss: 29.5287 - val_variance_output_loss: -14.1381\n",
            "Epoch 1210/5000\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 27.8325 - mean_output_loss: 42.0737 - variance_output_loss: -14.2412 - val_loss: 15.2557 - val_mean_output_loss: 29.3938 - val_variance_output_loss: -14.1382\n",
            "Epoch 1211/5000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 27.6694 - mean_output_loss: 41.9175 - variance_output_loss: -14.2482 - val_loss: 15.1214 - val_mean_output_loss: 29.2596 - val_variance_output_loss: -14.1382\n",
            "Epoch 1212/5000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 27.1907 - mean_output_loss: 41.7706 - variance_output_loss: -14.5798 - val_loss: 14.9869 - val_mean_output_loss: 29.1251 - val_variance_output_loss: -14.1382\n",
            "Epoch 1213/5000\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 25.9713 - mean_output_loss: 41.6037 - variance_output_loss: -15.6324 - val_loss: 14.8550 - val_mean_output_loss: 28.9933 - val_variance_output_loss: -14.1383\n",
            "Epoch 1214/5000\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 25.2285 - mean_output_loss: 41.4560 - variance_output_loss: -16.2274 - val_loss: 14.7227 - val_mean_output_loss: 28.8610 - val_variance_output_loss: -14.1383\n",
            "Epoch 1215/5000\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 27.3996 - mean_output_loss: 41.2990 - variance_output_loss: -13.8994 - val_loss: 14.5914 - val_mean_output_loss: 28.7298 - val_variance_output_loss: -14.1383\n",
            "Epoch 1216/5000\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 25.7121 - mean_output_loss: 41.1470 - variance_output_loss: -15.4349 - val_loss: 14.4605 - val_mean_output_loss: 28.5989 - val_variance_output_loss: -14.1384\n",
            "Epoch 1217/5000\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 25.6413 - mean_output_loss: 40.9954 - variance_output_loss: -15.3542 - val_loss: 14.3299 - val_mean_output_loss: 28.4683 - val_variance_output_loss: -14.1384\n",
            "Epoch 1218/5000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 25.7059 - mean_output_loss: 40.8457 - variance_output_loss: -15.1398 - val_loss: 14.1995 - val_mean_output_loss: 28.3379 - val_variance_output_loss: -14.1385\n",
            "Epoch 1219/5000\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 26.0752 - mean_output_loss: 40.6946 - variance_output_loss: -14.6194 - val_loss: 14.0697 - val_mean_output_loss: 28.2082 - val_variance_output_loss: -14.1385\n",
            "Epoch 1220/5000\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 25.9741 - mean_output_loss: 40.5418 - variance_output_loss: -14.5677 - val_loss: 13.9407 - val_mean_output_loss: 28.0793 - val_variance_output_loss: -14.1385\n",
            "Epoch 1221/5000\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 25.5393 - mean_output_loss: 40.3954 - variance_output_loss: -14.8561 - val_loss: 13.8118 - val_mean_output_loss: 27.9504 - val_variance_output_loss: -14.1386\n",
            "Epoch 1222/5000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 24.9536 - mean_output_loss: 40.2439 - variance_output_loss: -15.2903 - val_loss: 13.6838 - val_mean_output_loss: 27.8224 - val_variance_output_loss: -14.1386\n",
            "Epoch 1223/5000\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 24.5320 - mean_output_loss: 40.0968 - variance_output_loss: -15.5648 - val_loss: 13.5562 - val_mean_output_loss: 27.6948 - val_variance_output_loss: -14.1386\n",
            "Epoch 1224/5000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 26.1435 - mean_output_loss: 39.9473 - variance_output_loss: -13.8038 - val_loss: 13.4293 - val_mean_output_loss: 27.5680 - val_variance_output_loss: -14.1387\n",
            "Epoch 1225/5000\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 23.7756 - mean_output_loss: 39.8005 - variance_output_loss: -16.0250 - val_loss: 13.3029 - val_mean_output_loss: 27.4416 - val_variance_output_loss: -14.1387\n",
            "Epoch 1226/5000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 24.6913 - mean_output_loss: 39.6540 - variance_output_loss: -14.9627 - val_loss: 13.1770 - val_mean_output_loss: 27.3158 - val_variance_output_loss: -14.1387\n",
            "Epoch 1227/5000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 25.5725 - mean_output_loss: 39.5071 - variance_output_loss: -13.9346 - val_loss: 13.0518 - val_mean_output_loss: 27.1906 - val_variance_output_loss: -14.1388\n",
            "Epoch 1228/5000\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 24.2446 - mean_output_loss: 39.3593 - variance_output_loss: -15.1147 - val_loss: 12.9275 - val_mean_output_loss: 27.0663 - val_variance_output_loss: -14.1388\n",
            "Epoch 1229/5000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 23.8276 - mean_output_loss: 39.2191 - variance_output_loss: -15.3915 - val_loss: 12.8029 - val_mean_output_loss: 26.9418 - val_variance_output_loss: -14.1388\n",
            "Epoch 1230/5000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 23.5261 - mean_output_loss: 39.0718 - variance_output_loss: -15.5457 - val_loss: 12.6794 - val_mean_output_loss: 26.8183 - val_variance_output_loss: -14.1389\n",
            "Epoch 1231/5000\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 24.8954 - mean_output_loss: 38.9261 - variance_output_loss: -14.0307 - val_loss: 12.5567 - val_mean_output_loss: 26.6956 - val_variance_output_loss: -14.1389\n",
            "Epoch 1232/5000\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 24.0393 - mean_output_loss: 38.7834 - variance_output_loss: -14.7441 - val_loss: 12.4343 - val_mean_output_loss: 26.5732 - val_variance_output_loss: -14.1390\n",
            "Epoch 1233/5000\n",
            "2/2 [==============================] - 0s 70ms/step - loss: 23.3528 - mean_output_loss: 38.6398 - variance_output_loss: -15.2871 - val_loss: 12.3124 - val_mean_output_loss: 26.4514 - val_variance_output_loss: -14.1390\n",
            "Epoch 1234/5000\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 22.6317 - mean_output_loss: 38.5000 - variance_output_loss: -15.8682 - val_loss: 12.1906 - val_mean_output_loss: 26.3296 - val_variance_output_loss: -14.1390\n",
            "Epoch 1235/5000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 23.3965 - mean_output_loss: 38.3563 - variance_output_loss: -14.9598 - val_loss: 12.0696 - val_mean_output_loss: 26.2086 - val_variance_output_loss: -14.1391\n",
            "Epoch 1236/5000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 22.4811 - mean_output_loss: 38.2121 - variance_output_loss: -15.7310 - val_loss: 11.9494 - val_mean_output_loss: 26.0885 - val_variance_output_loss: -14.1391\n",
            "Epoch 1237/5000\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 23.2928 - mean_output_loss: 38.0764 - variance_output_loss: -14.7835 - val_loss: 11.8288 - val_mean_output_loss: 25.9679 - val_variance_output_loss: -14.1391\n",
            "Epoch 1238/5000\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 22.3789 - mean_output_loss: 37.9331 - variance_output_loss: -15.5542 - val_loss: 11.7092 - val_mean_output_loss: 25.8484 - val_variance_output_loss: -14.1392\n",
            "Epoch 1239/5000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 23.2674 - mean_output_loss: 37.7942 - variance_output_loss: -14.5268 - val_loss: 11.5900 - val_mean_output_loss: 25.7292 - val_variance_output_loss: -14.1392\n",
            "Epoch 1240/5000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 21.6510 - mean_output_loss: 37.6542 - variance_output_loss: -16.0032 - val_loss: 11.4713 - val_mean_output_loss: 25.6106 - val_variance_output_loss: -14.1392\n",
            "Epoch 1241/5000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 22.4397 - mean_output_loss: 37.5137 - variance_output_loss: -15.0740 - val_loss: 11.3534 - val_mean_output_loss: 25.4926 - val_variance_output_loss: -14.1393\n",
            "Epoch 1242/5000\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 21.3118 - mean_output_loss: 37.3795 - variance_output_loss: -16.0677 - val_loss: 11.2353 - val_mean_output_loss: 25.3745 - val_variance_output_loss: -14.1393\n",
            "Epoch 1243/5000\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 21.9563 - mean_output_loss: 37.2400 - variance_output_loss: -15.2837 - val_loss: 11.1180 - val_mean_output_loss: 25.2574 - val_variance_output_loss: -14.1393\n",
            "Epoch 1244/5000\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 22.6072 - mean_output_loss: 37.1025 - variance_output_loss: -14.4953 - val_loss: 11.0014 - val_mean_output_loss: 25.1407 - val_variance_output_loss: -14.1394\n",
            "Epoch 1245/5000\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 21.5680 - mean_output_loss: 36.9637 - variance_output_loss: -15.3957 - val_loss: 10.8855 - val_mean_output_loss: 25.0249 - val_variance_output_loss: -14.1394\n",
            "Epoch 1246/5000\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 22.3653 - mean_output_loss: 36.8305 - variance_output_loss: -14.4652 - val_loss: 10.7697 - val_mean_output_loss: 24.9091 - val_variance_output_loss: -14.1394\n",
            "Epoch 1247/5000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 21.8663 - mean_output_loss: 36.6945 - variance_output_loss: -14.8282 - val_loss: 10.6545 - val_mean_output_loss: 24.7939 - val_variance_output_loss: -14.1395\n",
            "Epoch 1248/5000\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 21.8158 - mean_output_loss: 36.5580 - variance_output_loss: -14.7422 - val_loss: 10.5400 - val_mean_output_loss: 24.6795 - val_variance_output_loss: -14.1395\n",
            "Epoch 1249/5000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 20.8051 - mean_output_loss: 36.4223 - variance_output_loss: -15.6172 - val_loss: 10.4261 - val_mean_output_loss: 24.5656 - val_variance_output_loss: -14.1395\n",
            "Epoch 1250/5000\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 21.7422 - mean_output_loss: 36.2904 - variance_output_loss: -14.5482 - val_loss: 10.3122 - val_mean_output_loss: 24.4518 - val_variance_output_loss: -14.1396\n",
            "Epoch 1251/5000\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 20.5001 - mean_output_loss: 36.1560 - variance_output_loss: -15.6559 - val_loss: 10.1990 - val_mean_output_loss: 24.3386 - val_variance_output_loss: -14.1396\n",
            "Epoch 1252/5000\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 19.9712 - mean_output_loss: 36.0228 - variance_output_loss: -16.0516 - val_loss: 10.0863 - val_mean_output_loss: 24.2259 - val_variance_output_loss: -14.1396\n",
            "Epoch 1253/5000\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 21.1369 - mean_output_loss: 35.8913 - variance_output_loss: -14.7543 - val_loss: 9.9739 - val_mean_output_loss: 24.1136 - val_variance_output_loss: -14.1397\n",
            "Epoch 1254/5000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 20.3124 - mean_output_loss: 35.7588 - variance_output_loss: -15.4464 - val_loss: 9.8621 - val_mean_output_loss: 24.0018 - val_variance_output_loss: -14.1397\n",
            "Epoch 1255/5000\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 20.5840 - mean_output_loss: 35.6265 - variance_output_loss: -15.0425 - val_loss: 9.7509 - val_mean_output_loss: 23.8907 - val_variance_output_loss: -14.1397\n",
            "Epoch 1256/5000\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 20.3350 - mean_output_loss: 35.4940 - variance_output_loss: -15.1589 - val_loss: 9.6403 - val_mean_output_loss: 23.7801 - val_variance_output_loss: -14.1397\n",
            "Epoch 1257/5000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 20.0939 - mean_output_loss: 35.3657 - variance_output_loss: -15.2718 - val_loss: 9.5298 - val_mean_output_loss: 23.6696 - val_variance_output_loss: -14.1398\n",
            "Epoch 1258/5000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 18.5465 - mean_output_loss: 35.2371 - variance_output_loss: -16.6906 - val_loss: 9.4197 - val_mean_output_loss: 23.5595 - val_variance_output_loss: -14.1398\n",
            "Epoch 1259/5000\n",
            "2/2 [==============================] - 0s 75ms/step - loss: 20.6993 - mean_output_loss: 35.1024 - variance_output_loss: -14.4031 - val_loss: 9.3107 - val_mean_output_loss: 23.4505 - val_variance_output_loss: -14.1398\n",
            "Epoch 1260/5000\n",
            "2/2 [==============================] - 0s 79ms/step - loss: 18.9371 - mean_output_loss: 34.9778 - variance_output_loss: -16.0407 - val_loss: 9.2014 - val_mean_output_loss: 23.3413 - val_variance_output_loss: -14.1399\n",
            "Epoch 1261/5000\n",
            "2/2 [==============================] - 0s 81ms/step - loss: 21.8349 - mean_output_loss: 34.8486 - variance_output_loss: -13.0137 - val_loss: 9.0928 - val_mean_output_loss: 23.2328 - val_variance_output_loss: -14.1399\n",
            "Epoch 1262/5000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 19.4889 - mean_output_loss: 34.7184 - variance_output_loss: -15.2295 - val_loss: 8.9850 - val_mean_output_loss: 23.1250 - val_variance_output_loss: -14.1399\n",
            "Epoch 1263/5000\n",
            "2/2 [==============================] - 0s 72ms/step - loss: 19.6406 - mean_output_loss: 34.5945 - variance_output_loss: -14.9539 - val_loss: 8.8772 - val_mean_output_loss: 23.0171 - val_variance_output_loss: -14.1400\n",
            "Epoch 1264/5000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 18.7375 - mean_output_loss: 34.4623 - variance_output_loss: -15.7248 - val_loss: 8.7705 - val_mean_output_loss: 22.9105 - val_variance_output_loss: -14.1400\n",
            "Epoch 1265/5000\n",
            "2/2 [==============================] - 0s 89ms/step - loss: 20.2178 - mean_output_loss: 34.3387 - variance_output_loss: -14.1209 - val_loss: 8.6638 - val_mean_output_loss: 22.8039 - val_variance_output_loss: -14.1400\n",
            "Epoch 1266/5000\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 19.7175 - mean_output_loss: 34.2131 - variance_output_loss: -14.4955 - val_loss: 8.5576 - val_mean_output_loss: 22.6976 - val_variance_output_loss: -14.1401\n",
            "Epoch 1267/5000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 19.4834 - mean_output_loss: 34.0878 - variance_output_loss: -14.6044 - val_loss: 8.4518 - val_mean_output_loss: 22.5919 - val_variance_output_loss: -14.1401\n",
            "Epoch 1268/5000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 20.0073 - mean_output_loss: 33.9659 - variance_output_loss: -13.9586 - val_loss: 8.3463 - val_mean_output_loss: 22.4864 - val_variance_output_loss: -14.1401\n",
            "Epoch 1269/5000\n",
            "2/2 [==============================] - 0s 102ms/step - loss: 18.8879 - mean_output_loss: 33.8356 - variance_output_loss: -14.9477 - val_loss: 8.2421 - val_mean_output_loss: 22.3823 - val_variance_output_loss: -14.1402\n",
            "Epoch 1270/5000\n",
            "2/2 [==============================] - 0s 76ms/step - loss: 17.6436 - mean_output_loss: 33.7171 - variance_output_loss: -16.0735 - val_loss: 8.1378 - val_mean_output_loss: 22.2780 - val_variance_output_loss: -14.1402\n",
            "Epoch 1271/5000\n",
            "2/2 [==============================] - 0s 66ms/step - loss: 17.7733 - mean_output_loss: 33.5921 - variance_output_loss: -15.8188 - val_loss: 8.0343 - val_mean_output_loss: 22.1745 - val_variance_output_loss: -14.1402\n",
            "Epoch 1272/5000\n",
            "2/2 [==============================] - 0s 81ms/step - loss: 17.4364 - mean_output_loss: 33.4693 - variance_output_loss: -16.0329 - val_loss: 7.9315 - val_mean_output_loss: 22.0717 - val_variance_output_loss: -14.1403\n",
            "Epoch 1273/5000\n",
            "2/2 [==============================] - 0s 68ms/step - loss: 19.0015 - mean_output_loss: 33.3434 - variance_output_loss: -14.3420 - val_loss: 7.8296 - val_mean_output_loss: 21.9699 - val_variance_output_loss: -14.1403\n",
            "Epoch 1274/5000\n",
            "2/2 [==============================] - 0s 82ms/step - loss: 17.2182 - mean_output_loss: 33.2229 - variance_output_loss: -16.0047 - val_loss: 7.7278 - val_mean_output_loss: 21.8681 - val_variance_output_loss: -14.1403\n",
            "Epoch 1275/5000\n",
            "2/2 [==============================] - 0s 81ms/step - loss: 17.7112 - mean_output_loss: 33.1038 - variance_output_loss: -15.3926 - val_loss: 7.6260 - val_mean_output_loss: 21.7664 - val_variance_output_loss: -14.1403\n",
            "Epoch 1276/5000\n",
            "2/2 [==============================] - 0s 79ms/step - loss: 18.2090 - mean_output_loss: 32.9827 - variance_output_loss: -14.7737 - val_loss: 7.5248 - val_mean_output_loss: 21.6652 - val_variance_output_loss: -14.1404\n",
            "Epoch 1277/5000\n",
            "2/2 [==============================] - 0s 77ms/step - loss: 17.4211 - mean_output_loss: 32.8612 - variance_output_loss: -15.4400 - val_loss: 7.4241 - val_mean_output_loss: 21.5645 - val_variance_output_loss: -14.1404\n",
            "Epoch 1278/5000\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 18.4512 - mean_output_loss: 32.7403 - variance_output_loss: -14.2891 - val_loss: 7.3239 - val_mean_output_loss: 21.4644 - val_variance_output_loss: -14.1404\n",
            "Epoch 1279/5000\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 18.2347 - mean_output_loss: 32.6260 - variance_output_loss: -14.3912 - val_loss: 7.2235 - val_mean_output_loss: 21.3639 - val_variance_output_loss: -14.1405\n",
            "Epoch 1280/5000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 17.2006 - mean_output_loss: 32.5042 - variance_output_loss: -15.3036 - val_loss: 7.1240 - val_mean_output_loss: 21.2645 - val_variance_output_loss: -14.1405\n",
            "Epoch 1281/5000\n",
            "2/2 [==============================] - 0s 66ms/step - loss: 16.5178 - mean_output_loss: 32.3873 - variance_output_loss: -15.8695 - val_loss: 7.0248 - val_mean_output_loss: 21.1653 - val_variance_output_loss: -14.1405\n",
            "Epoch 1282/5000\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 16.6407 - mean_output_loss: 32.2657 - variance_output_loss: -15.6250 - val_loss: 6.9267 - val_mean_output_loss: 21.0672 - val_variance_output_loss: -14.1406\n",
            "Epoch 1283/5000\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 16.5272 - mean_output_loss: 32.1500 - variance_output_loss: -15.6228 - val_loss: 6.8286 - val_mean_output_loss: 20.9692 - val_variance_output_loss: -14.1406\n",
            "Epoch 1284/5000\n",
            "2/2 [==============================] - 0s 71ms/step - loss: 16.9298 - mean_output_loss: 32.0339 - variance_output_loss: -15.1042 - val_loss: 6.7309 - val_mean_output_loss: 20.8715 - val_variance_output_loss: -14.1406\n",
            "Epoch 1285/5000\n",
            "2/2 [==============================] - 0s 115ms/step - loss: 17.8309 - mean_output_loss: 31.9167 - variance_output_loss: -14.0858 - val_loss: 6.6338 - val_mean_output_loss: 20.7744 - val_variance_output_loss: -14.1406\n",
            "Epoch 1286/5000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 17.3733 - mean_output_loss: 31.7990 - variance_output_loss: -14.4257 - val_loss: 6.5373 - val_mean_output_loss: 20.6779 - val_variance_output_loss: -14.1407\n",
            "Epoch 1287/5000\n",
            "2/2 [==============================] - 0s 107ms/step - loss: 16.4894 - mean_output_loss: 31.6872 - variance_output_loss: -15.1978 - val_loss: 6.4407 - val_mean_output_loss: 20.5814 - val_variance_output_loss: -14.1407\n",
            "Epoch 1288/5000\n",
            "2/2 [==============================] - 0s 83ms/step - loss: 16.6907 - mean_output_loss: 31.5718 - variance_output_loss: -14.8811 - val_loss: 6.3447 - val_mean_output_loss: 20.4854 - val_variance_output_loss: -14.1407\n",
            "Epoch 1289/5000\n",
            "2/2 [==============================] - 0s 79ms/step - loss: 16.5071 - mean_output_loss: 31.4542 - variance_output_loss: -14.9470 - val_loss: 6.2496 - val_mean_output_loss: 20.3904 - val_variance_output_loss: -14.1408\n",
            "Epoch 1290/5000\n",
            "2/2 [==============================] - 0s 80ms/step - loss: 17.3420 - mean_output_loss: 31.3409 - variance_output_loss: -13.9990 - val_loss: 6.1548 - val_mean_output_loss: 20.2956 - val_variance_output_loss: -14.1408\n",
            "Epoch 1291/5000\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 15.7810 - mean_output_loss: 31.2290 - variance_output_loss: -15.4480 - val_loss: 6.0601 - val_mean_output_loss: 20.2009 - val_variance_output_loss: -14.1408\n",
            "Epoch 1292/5000\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 16.3909 - mean_output_loss: 31.1182 - variance_output_loss: -14.7273 - val_loss: 5.9657 - val_mean_output_loss: 20.1066 - val_variance_output_loss: -14.1408\n",
            "Epoch 1293/5000\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 16.4434 - mean_output_loss: 31.0035 - variance_output_loss: -14.5602 - val_loss: 5.8723 - val_mean_output_loss: 20.0132 - val_variance_output_loss: -14.1409\n",
            "Epoch 1294/5000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 15.5466 - mean_output_loss: 30.8890 - variance_output_loss: -15.3424 - val_loss: 5.7796 - val_mean_output_loss: 19.9205 - val_variance_output_loss: -14.1409\n",
            "Epoch 1295/5000\n",
            "2/2 [==============================] - 0s 69ms/step - loss: 16.5330 - mean_output_loss: 30.7808 - variance_output_loss: -14.2478 - val_loss: 5.6869 - val_mean_output_loss: 19.8278 - val_variance_output_loss: -14.1409\n",
            "Epoch 1296/5000\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 14.3843 - mean_output_loss: 30.6657 - variance_output_loss: -16.2814 - val_loss: 5.5952 - val_mean_output_loss: 19.7362 - val_variance_output_loss: -14.1410\n",
            "Epoch 1297/5000\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 15.5626 - mean_output_loss: 30.5564 - variance_output_loss: -14.9937 - val_loss: 5.5036 - val_mean_output_loss: 19.6445 - val_variance_output_loss: -14.1410\n",
            "Epoch 1298/5000\n",
            "2/2 [==============================] - 0s 86ms/step - loss: 14.7063 - mean_output_loss: 30.4448 - variance_output_loss: -15.7385 - val_loss: 5.4124 - val_mean_output_loss: 19.5534 - val_variance_output_loss: -14.1410\n",
            "Epoch 1299/5000\n",
            "2/2 [==============================] - 0s 96ms/step - loss: 15.3488 - mean_output_loss: 30.3384 - variance_output_loss: -14.9896 - val_loss: 5.3210 - val_mean_output_loss: 19.4621 - val_variance_output_loss: -14.1410\n",
            "Epoch 1300/5000\n",
            "2/2 [==============================] - 0s 85ms/step - loss: 15.1142 - mean_output_loss: 30.2277 - variance_output_loss: -15.1135 - val_loss: 5.2303 - val_mean_output_loss: 19.3714 - val_variance_output_loss: -14.1411\n",
            "Epoch 1301/5000\n",
            "2/2 [==============================] - 0s 100ms/step - loss: 14.6138 - mean_output_loss: 30.1184 - variance_output_loss: -15.5046 - val_loss: 5.1401 - val_mean_output_loss: 19.2812 - val_variance_output_loss: -14.1411\n",
            "Epoch 1302/5000\n",
            "2/2 [==============================] - 0s 82ms/step - loss: 14.7506 - mean_output_loss: 30.0137 - variance_output_loss: -15.2631 - val_loss: 5.0499 - val_mean_output_loss: 19.1910 - val_variance_output_loss: -14.1411\n",
            "Epoch 1303/5000\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 14.1507 - mean_output_loss: 29.9014 - variance_output_loss: -15.7507 - val_loss: 4.9608 - val_mean_output_loss: 19.1020 - val_variance_output_loss: -14.1412\n",
            "Epoch 1304/5000\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 14.2946 - mean_output_loss: 29.7952 - variance_output_loss: -15.5007 - val_loss: 4.8720 - val_mean_output_loss: 19.0131 - val_variance_output_loss: -14.1412\n",
            "Epoch 1305/5000\n",
            "2/2 [==============================] - 0s 66ms/step - loss: 14.2357 - mean_output_loss: 29.6874 - variance_output_loss: -15.4518 - val_loss: 4.7837 - val_mean_output_loss: 18.9249 - val_variance_output_loss: -14.1412\n",
            "Epoch 1306/5000\n",
            "2/2 [==============================] - 0s 81ms/step - loss: 13.2424 - mean_output_loss: 29.5803 - variance_output_loss: -16.3379 - val_loss: 4.6958 - val_mean_output_loss: 18.8371 - val_variance_output_loss: -14.1412\n",
            "Epoch 1307/5000\n",
            "2/2 [==============================] - 0s 78ms/step - loss: 12.8768 - mean_output_loss: 29.4755 - variance_output_loss: -16.5987 - val_loss: 4.6082 - val_mean_output_loss: 18.7495 - val_variance_output_loss: -14.1413\n",
            "Epoch 1308/5000\n",
            "2/2 [==============================] - 0s 69ms/step - loss: 14.4228 - mean_output_loss: 29.3704 - variance_output_loss: -14.9477 - val_loss: 4.5210 - val_mean_output_loss: 18.6623 - val_variance_output_loss: -14.1413\n",
            "Epoch 1309/5000\n",
            "2/2 [==============================] - 0s 66ms/step - loss: 14.0071 - mean_output_loss: 29.2608 - variance_output_loss: -15.2537 - val_loss: 4.4348 - val_mean_output_loss: 18.5761 - val_variance_output_loss: -14.1413\n",
            "Epoch 1310/5000\n",
            "2/2 [==============================] - 0s 103ms/step - loss: 14.9159 - mean_output_loss: 29.1593 - variance_output_loss: -14.2435 - val_loss: 4.3483 - val_mean_output_loss: 18.4897 - val_variance_output_loss: -14.1414\n",
            "Epoch 1311/5000\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 14.4359 - mean_output_loss: 29.0542 - variance_output_loss: -14.6183 - val_loss: 4.2623 - val_mean_output_loss: 18.4037 - val_variance_output_loss: -14.1414\n",
            "Epoch 1312/5000\n",
            "2/2 [==============================] - 0s 85ms/step - loss: 14.3260 - mean_output_loss: 28.9524 - variance_output_loss: -14.6265 - val_loss: 4.1765 - val_mean_output_loss: 18.3179 - val_variance_output_loss: -14.1414\n",
            "Epoch 1313/5000\n",
            "2/2 [==============================] - 0s 66ms/step - loss: 14.3678 - mean_output_loss: 28.8484 - variance_output_loss: -14.4806 - val_loss: 4.0912 - val_mean_output_loss: 18.2327 - val_variance_output_loss: -14.1414\n",
            "Epoch 1314/5000\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 13.6296 - mean_output_loss: 28.7465 - variance_output_loss: -15.1168 - val_loss: 4.0064 - val_mean_output_loss: 18.1478 - val_variance_output_loss: -14.1415\n",
            "Epoch 1315/5000\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 13.2413 - mean_output_loss: 28.6384 - variance_output_loss: -15.3971 - val_loss: 3.9227 - val_mean_output_loss: 18.0642 - val_variance_output_loss: -14.1415\n",
            "Epoch 1316/5000\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 13.1307 - mean_output_loss: 28.5379 - variance_output_loss: -15.4072 - val_loss: 3.8390 - val_mean_output_loss: 17.9805 - val_variance_output_loss: -14.1415\n",
            "Epoch 1317/5000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 13.2780 - mean_output_loss: 28.4342 - variance_output_loss: -15.1562 - val_loss: 3.7558 - val_mean_output_loss: 17.8973 - val_variance_output_loss: -14.1415\n",
            "Epoch 1318/5000\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 14.4248 - mean_output_loss: 28.3361 - variance_output_loss: -13.9113 - val_loss: 3.6723 - val_mean_output_loss: 17.8139 - val_variance_output_loss: -14.1416\n",
            "Epoch 1319/5000\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 13.7902 - mean_output_loss: 28.2340 - variance_output_loss: -14.4438 - val_loss: 3.5893 - val_mean_output_loss: 17.7309 - val_variance_output_loss: -14.1416\n",
            "Epoch 1320/5000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 12.9327 - mean_output_loss: 28.1336 - variance_output_loss: -15.2008 - val_loss: 3.5067 - val_mean_output_loss: 17.6483 - val_variance_output_loss: -14.1416\n",
            "Epoch 1321/5000\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 14.1289 - mean_output_loss: 28.0332 - variance_output_loss: -13.9043 - val_loss: 3.4244 - val_mean_output_loss: 17.5660 - val_variance_output_loss: -14.1417\n",
            "Epoch 1322/5000\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 13.9039 - mean_output_loss: 27.9346 - variance_output_loss: -14.0307 - val_loss: 3.3424 - val_mean_output_loss: 17.4840 - val_variance_output_loss: -14.1417\n",
            "Epoch 1323/5000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 12.5239 - mean_output_loss: 27.8353 - variance_output_loss: -15.3114 - val_loss: 3.2609 - val_mean_output_loss: 17.4026 - val_variance_output_loss: -14.1417\n",
            "Epoch 1324/5000\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 12.3296 - mean_output_loss: 27.7338 - variance_output_loss: -15.4042 - val_loss: 3.1801 - val_mean_output_loss: 17.3219 - val_variance_output_loss: -14.1417\n",
            "Epoch 1325/5000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 10.9192 - mean_output_loss: 27.6361 - variance_output_loss: -16.7169 - val_loss: 3.0996 - val_mean_output_loss: 17.2414 - val_variance_output_loss: -14.1418\n",
            "Epoch 1326/5000\n",
            "2/2 [==============================] - 0s 77ms/step - loss: 13.2414 - mean_output_loss: 27.5386 - variance_output_loss: -14.2971 - val_loss: 3.0195 - val_mean_output_loss: 17.1613 - val_variance_output_loss: -14.1418\n",
            "Epoch 1327/5000\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 11.9646 - mean_output_loss: 27.4406 - variance_output_loss: -15.4759 - val_loss: 2.9399 - val_mean_output_loss: 17.0817 - val_variance_output_loss: -14.1418\n",
            "Epoch 1328/5000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 11.6911 - mean_output_loss: 27.3425 - variance_output_loss: -15.6514 - val_loss: 2.8607 - val_mean_output_loss: 17.0025 - val_variance_output_loss: -14.1418\n",
            "Epoch 1329/5000\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 12.0846 - mean_output_loss: 27.2460 - variance_output_loss: -15.1614 - val_loss: 2.7818 - val_mean_output_loss: 16.9237 - val_variance_output_loss: -14.1419\n",
            "Epoch 1330/5000\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 11.7272 - mean_output_loss: 27.1499 - variance_output_loss: -15.4227 - val_loss: 2.7033 - val_mean_output_loss: 16.8452 - val_variance_output_loss: -14.1419\n",
            "Epoch 1331/5000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 11.8313 - mean_output_loss: 27.0522 - variance_output_loss: -15.2209 - val_loss: 2.6254 - val_mean_output_loss: 16.7673 - val_variance_output_loss: -14.1419\n",
            "Epoch 1332/5000\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 12.8957 - mean_output_loss: 26.9572 - variance_output_loss: -14.0615 - val_loss: 2.5476 - val_mean_output_loss: 16.6896 - val_variance_output_loss: -14.1419\n",
            "Epoch 1333/5000\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 11.4859 - mean_output_loss: 26.8621 - variance_output_loss: -15.3761 - val_loss: 2.4702 - val_mean_output_loss: 16.6121 - val_variance_output_loss: -14.1420\n",
            "Epoch 1334/5000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 12.4012 - mean_output_loss: 26.7676 - variance_output_loss: -14.3664 - val_loss: 2.3930 - val_mean_output_loss: 16.5350 - val_variance_output_loss: -14.1420\n",
            "Epoch 1335/5000\n",
            "2/2 [==============================] - 0s 69ms/step - loss: 10.3179 - mean_output_loss: 26.6756 - variance_output_loss: -16.3577 - val_loss: 2.3159 - val_mean_output_loss: 16.4579 - val_variance_output_loss: -14.1420\n",
            "Epoch 1336/5000\n",
            "2/2 [==============================] - 0s 70ms/step - loss: 11.7928 - mean_output_loss: 26.5789 - variance_output_loss: -14.7861 - val_loss: 2.2397 - val_mean_output_loss: 16.3817 - val_variance_output_loss: -14.1420\n",
            "Epoch 1337/5000\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 11.3691 - mean_output_loss: 26.4863 - variance_output_loss: -15.1172 - val_loss: 2.1637 - val_mean_output_loss: 16.3058 - val_variance_output_loss: -14.1421\n",
            "Epoch 1338/5000\n",
            "2/2 [==============================] - 0s 67ms/step - loss: 11.5641 - mean_output_loss: 26.3918 - variance_output_loss: -14.8277 - val_loss: 2.0883 - val_mean_output_loss: 16.2304 - val_variance_output_loss: -14.1421\n",
            "Epoch 1339/5000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 11.5019 - mean_output_loss: 26.3002 - variance_output_loss: -14.7983 - val_loss: 2.0132 - val_mean_output_loss: 16.1553 - val_variance_output_loss: -14.1421\n",
            "Epoch 1340/5000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 10.9000 - mean_output_loss: 26.2059 - variance_output_loss: -15.3059 - val_loss: 1.9386 - val_mean_output_loss: 16.0808 - val_variance_output_loss: -14.1421\n",
            "Epoch 1341/5000\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 10.4348 - mean_output_loss: 26.1156 - variance_output_loss: -15.6808 - val_loss: 1.8642 - val_mean_output_loss: 16.0063 - val_variance_output_loss: -14.1422\n",
            "Epoch 1342/5000\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 11.9220 - mean_output_loss: 26.0238 - variance_output_loss: -14.1018 - val_loss: 1.7901 - val_mean_output_loss: 15.9323 - val_variance_output_loss: -14.1422\n",
            "Epoch 1343/5000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 11.0507 - mean_output_loss: 25.9363 - variance_output_loss: -14.8856 - val_loss: 1.7161 - val_mean_output_loss: 15.8583 - val_variance_output_loss: -14.1422\n",
            "Epoch 1344/5000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 11.0896 - mean_output_loss: 25.8422 - variance_output_loss: -14.7526 - val_loss: 1.6431 - val_mean_output_loss: 15.7854 - val_variance_output_loss: -14.1423\n",
            "Epoch 1345/5000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 11.5181 - mean_output_loss: 25.7523 - variance_output_loss: -14.2342 - val_loss: 1.5705 - val_mean_output_loss: 15.7127 - val_variance_output_loss: -14.1423\n",
            "Epoch 1346/5000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 11.1052 - mean_output_loss: 25.6595 - variance_output_loss: -14.5542 - val_loss: 1.4985 - val_mean_output_loss: 15.6409 - val_variance_output_loss: -14.1423\n",
            "Epoch 1347/5000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 11.2631 - mean_output_loss: 25.5737 - variance_output_loss: -14.3105 - val_loss: 1.4264 - val_mean_output_loss: 15.5687 - val_variance_output_loss: -14.1423\n",
            "Epoch 1348/5000\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 11.0083 - mean_output_loss: 25.4821 - variance_output_loss: -14.4737 - val_loss: 1.3549 - val_mean_output_loss: 15.4972 - val_variance_output_loss: -14.1424\n",
            "Epoch 1349/5000\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 9.7605 - mean_output_loss: 25.3947 - variance_output_loss: -15.6342 - val_loss: 1.2835 - val_mean_output_loss: 15.4259 - val_variance_output_loss: -14.1424\n",
            "Epoch 1350/5000\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 10.9832 - mean_output_loss: 25.3090 - variance_output_loss: -14.3258 - val_loss: 1.2121 - val_mean_output_loss: 15.3545 - val_variance_output_loss: -14.1424\n",
            "Epoch 1351/5000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 9.3218 - mean_output_loss: 25.2223 - variance_output_loss: -15.9005 - val_loss: 1.1412 - val_mean_output_loss: 15.2836 - val_variance_output_loss: -14.1424\n",
            "Epoch 1352/5000\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 11.2771 - mean_output_loss: 25.1298 - variance_output_loss: -13.8527 - val_loss: 1.0714 - val_mean_output_loss: 15.2139 - val_variance_output_loss: -14.1425\n",
            "Epoch 1353/5000\n",
            "2/2 [==============================] - 0s 68ms/step - loss: 8.7369 - mean_output_loss: 25.0432 - variance_output_loss: -16.3064 - val_loss: 1.0018 - val_mean_output_loss: 15.1442 - val_variance_output_loss: -14.1425\n",
            "Epoch 1354/5000\n",
            "2/2 [==============================] - 0s 87ms/step - loss: 10.5434 - mean_output_loss: 24.9577 - variance_output_loss: -14.4143 - val_loss: 0.9323 - val_mean_output_loss: 15.0748 - val_variance_output_loss: -14.1425\n",
            "Epoch 1355/5000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 8.7237 - mean_output_loss: 24.8720 - variance_output_loss: -16.1483 - val_loss: 0.8631 - val_mean_output_loss: 15.0056 - val_variance_output_loss: -14.1425\n",
            "Epoch 1356/5000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 9.6873 - mean_output_loss: 24.7858 - variance_output_loss: -15.0985 - val_loss: 0.7942 - val_mean_output_loss: 14.9368 - val_variance_output_loss: -14.1425\n",
            "Epoch 1357/5000\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 9.4316 - mean_output_loss: 24.6974 - variance_output_loss: -15.2659 - val_loss: 0.7261 - val_mean_output_loss: 14.8686 - val_variance_output_loss: -14.1426\n",
            "Epoch 1358/5000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 10.2590 - mean_output_loss: 24.6136 - variance_output_loss: -14.3546 - val_loss: 0.6579 - val_mean_output_loss: 14.8005 - val_variance_output_loss: -14.1426\n",
            "Epoch 1359/5000\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 8.9355 - mean_output_loss: 24.5289 - variance_output_loss: -15.5934 - val_loss: 0.5898 - val_mean_output_loss: 14.7325 - val_variance_output_loss: -14.1426\n",
            "Epoch 1360/5000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 10.4220 - mean_output_loss: 24.4444 - variance_output_loss: -14.0223 - val_loss: 0.5221 - val_mean_output_loss: 14.6648 - val_variance_output_loss: -14.1426\n",
            "Epoch 1361/5000\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 7.7809 - mean_output_loss: 24.3611 - variance_output_loss: -16.5802 - val_loss: 0.4546 - val_mean_output_loss: 14.5972 - val_variance_output_loss: -14.1427\n",
            "Epoch 1362/5000\n",
            "2/2 [==============================] - 0s 67ms/step - loss: 8.6490 - mean_output_loss: 24.2780 - variance_output_loss: -15.6290 - val_loss: 0.3874 - val_mean_output_loss: 14.5300 - val_variance_output_loss: -14.1427\n",
            "Epoch 1363/5000\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 8.8659 - mean_output_loss: 24.1947 - variance_output_loss: -15.3288 - val_loss: 0.3206 - val_mean_output_loss: 14.4633 - val_variance_output_loss: -14.1427\n",
            "Epoch 1364/5000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 9.2044 - mean_output_loss: 24.1097 - variance_output_loss: -14.9053 - val_loss: 0.2545 - val_mean_output_loss: 14.3972 - val_variance_output_loss: -14.1427\n",
            "Epoch 1365/5000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 8.0084 - mean_output_loss: 24.0253 - variance_output_loss: -16.0170 - val_loss: 0.1889 - val_mean_output_loss: 14.3317 - val_variance_output_loss: -14.1428\n",
            "Epoch 1366/5000\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 9.2663 - mean_output_loss: 23.9457 - variance_output_loss: -14.6794 - val_loss: 0.1233 - val_mean_output_loss: 14.2660 - val_variance_output_loss: -14.1428\n",
            "Epoch 1367/5000\n",
            "2/2 [==============================] - 0s 78ms/step - loss: 8.0444 - mean_output_loss: 23.8625 - variance_output_loss: -15.8181 - val_loss: 0.0582 - val_mean_output_loss: 14.2010 - val_variance_output_loss: -14.1428\n",
            "Epoch 1368/5000\n",
            "2/2 [==============================] - 0s 72ms/step - loss: 7.1157 - mean_output_loss: 23.7836 - variance_output_loss: -16.6679 - val_loss: -0.0069 - val_mean_output_loss: 14.1359 - val_variance_output_loss: -14.1428\n",
            "Epoch 1369/5000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 8.2588 - mean_output_loss: 23.6995 - variance_output_loss: -15.4406 - val_loss: -0.0712 - val_mean_output_loss: 14.0717 - val_variance_output_loss: -14.1429\n",
            "Epoch 1370/5000\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 8.9760 - mean_output_loss: 23.6188 - variance_output_loss: -14.6428 - val_loss: -0.1351 - val_mean_output_loss: 14.0077 - val_variance_output_loss: -14.1429\n",
            "Epoch 1371/5000\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 8.7502 - mean_output_loss: 23.5410 - variance_output_loss: -14.7908 - val_loss: -0.1991 - val_mean_output_loss: 13.9438 - val_variance_output_loss: -14.1429\n",
            "Epoch 1372/5000\n",
            "2/2 [==============================] - 0s 78ms/step - loss: 7.9109 - mean_output_loss: 23.4582 - variance_output_loss: -15.5473 - val_loss: -0.2623 - val_mean_output_loss: 13.8807 - val_variance_output_loss: -14.1429\n",
            "Epoch 1373/5000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 8.6841 - mean_output_loss: 23.3801 - variance_output_loss: -14.6960 - val_loss: -0.3253 - val_mean_output_loss: 13.8176 - val_variance_output_loss: -14.1430\n",
            "Epoch 1374/5000\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 7.4592 - mean_output_loss: 23.3003 - variance_output_loss: -15.8411 - val_loss: -0.3880 - val_mean_output_loss: 13.7550 - val_variance_output_loss: -14.1430\n",
            "Epoch 1375/5000\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 8.9240 - mean_output_loss: 23.2206 - variance_output_loss: -14.2966 - val_loss: -0.4502 - val_mean_output_loss: 13.6928 - val_variance_output_loss: -14.1430\n",
            "Epoch 1376/5000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 7.6501 - mean_output_loss: 23.1440 - variance_output_loss: -15.4939 - val_loss: -0.5124 - val_mean_output_loss: 13.6306 - val_variance_output_loss: -14.1430\n",
            "Epoch 1377/5000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 7.7743 - mean_output_loss: 23.0640 - variance_output_loss: -15.2897 - val_loss: -0.5740 - val_mean_output_loss: 13.5691 - val_variance_output_loss: -14.1430\n",
            "Epoch 1378/5000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 8.4215 - mean_output_loss: 22.9880 - variance_output_loss: -14.5665 - val_loss: -0.6354 - val_mean_output_loss: 13.5076 - val_variance_output_loss: -14.1431\n",
            "Epoch 1379/5000\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 6.8169 - mean_output_loss: 22.9085 - variance_output_loss: -16.0916 - val_loss: -0.6964 - val_mean_output_loss: 13.4467 - val_variance_output_loss: -14.1431\n",
            "Epoch 1380/5000\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 7.4115 - mean_output_loss: 22.8316 - variance_output_loss: -15.4202 - val_loss: -0.7570 - val_mean_output_loss: 13.3861 - val_variance_output_loss: -14.1431\n",
            "Epoch 1381/5000\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 6.5445 - mean_output_loss: 22.7566 - variance_output_loss: -16.2121 - val_loss: -0.8176 - val_mean_output_loss: 13.3255 - val_variance_output_loss: -14.1431\n",
            "Epoch 1382/5000\n",
            "2/2 [==============================] - 0s 81ms/step - loss: 9.0840 - mean_output_loss: 22.6804 - variance_output_loss: -13.5964 - val_loss: -0.8779 - val_mean_output_loss: 13.2653 - val_variance_output_loss: -14.1432\n",
            "Epoch 1383/5000\n",
            "2/2 [==============================] - 0s 66ms/step - loss: 8.3639 - mean_output_loss: 22.6012 - variance_output_loss: -14.2373 - val_loss: -0.9373 - val_mean_output_loss: 13.2058 - val_variance_output_loss: -14.1432\n",
            "Epoch 1384/5000\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 6.8901 - mean_output_loss: 22.5266 - variance_output_loss: -15.6365 - val_loss: -0.9968 - val_mean_output_loss: 13.1464 - val_variance_output_loss: -14.1432\n",
            "Epoch 1385/5000\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 7.7747 - mean_output_loss: 22.4521 - variance_output_loss: -14.6774 - val_loss: -1.0561 - val_mean_output_loss: 13.0871 - val_variance_output_loss: -14.1432\n",
            "Epoch 1386/5000\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 6.3325 - mean_output_loss: 22.3793 - variance_output_loss: -16.0468 - val_loss: -1.1153 - val_mean_output_loss: 13.0280 - val_variance_output_loss: -14.1433\n",
            "Epoch 1387/5000\n",
            "2/2 [==============================] - 0s 88ms/step - loss: 9.0274 - mean_output_loss: 22.3013 - variance_output_loss: -13.2738 - val_loss: -1.1736 - val_mean_output_loss: 12.9696 - val_variance_output_loss: -14.1433\n",
            "Epoch 1388/5000\n",
            "2/2 [==============================] - 0s 68ms/step - loss: 7.3975 - mean_output_loss: 22.2268 - variance_output_loss: -14.8294 - val_loss: -1.2317 - val_mean_output_loss: 12.9116 - val_variance_output_loss: -14.1433\n",
            "Epoch 1389/5000\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 7.9467 - mean_output_loss: 22.1528 - variance_output_loss: -14.2062 - val_loss: -1.2896 - val_mean_output_loss: 12.8537 - val_variance_output_loss: -14.1433\n",
            "Epoch 1390/5000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 6.3908 - mean_output_loss: 22.0799 - variance_output_loss: -15.6891 - val_loss: -1.3473 - val_mean_output_loss: 12.7961 - val_variance_output_loss: -14.1433\n",
            "Epoch 1391/5000\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 6.3665 - mean_output_loss: 22.0071 - variance_output_loss: -15.6405 - val_loss: -1.4047 - val_mean_output_loss: 12.7386 - val_variance_output_loss: -14.1434\n",
            "Epoch 1392/5000\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 7.3245 - mean_output_loss: 21.9351 - variance_output_loss: -14.6106 - val_loss: -1.4619 - val_mean_output_loss: 12.6815 - val_variance_output_loss: -14.1434\n",
            "Epoch 1393/5000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 6.4678 - mean_output_loss: 21.8614 - variance_output_loss: -15.3935 - val_loss: -1.5186 - val_mean_output_loss: 12.6248 - val_variance_output_loss: -14.1434\n",
            "Epoch 1394/5000\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 4.8993 - mean_output_loss: 21.7877 - variance_output_loss: -16.8885 - val_loss: -1.5748 - val_mean_output_loss: 12.5687 - val_variance_output_loss: -14.1434\n",
            "Epoch 1395/5000\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 7.3250 - mean_output_loss: 21.7148 - variance_output_loss: -14.3898 - val_loss: -1.6306 - val_mean_output_loss: 12.5128 - val_variance_output_loss: -14.1435\n",
            "Epoch 1396/5000\n",
            "2/2 [==============================] - 0s 70ms/step - loss: 6.6429 - mean_output_loss: 21.6442 - variance_output_loss: -15.0014 - val_loss: -1.6864 - val_mean_output_loss: 12.4571 - val_variance_output_loss: -14.1435\n",
            "Epoch 1397/5000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 6.4368 - mean_output_loss: 21.5746 - variance_output_loss: -15.1377 - val_loss: -1.7421 - val_mean_output_loss: 12.4014 - val_variance_output_loss: -14.1435\n",
            "Epoch 1398/5000\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 7.4005 - mean_output_loss: 21.5013 - variance_output_loss: -14.1008 - val_loss: -1.7973 - val_mean_output_loss: 12.3463 - val_variance_output_loss: -14.1435\n",
            "Epoch 1399/5000\n",
            "2/2 [==============================] - 0s 74ms/step - loss: 6.2391 - mean_output_loss: 21.4296 - variance_output_loss: -15.1906 - val_loss: -1.8521 - val_mean_output_loss: 12.2915 - val_variance_output_loss: -14.1435\n",
            "Epoch 1400/5000\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 5.3178 - mean_output_loss: 21.3612 - variance_output_loss: -16.0433 - val_loss: -1.9069 - val_mean_output_loss: 12.2367 - val_variance_output_loss: -14.1436\n",
            "Epoch 1401/5000\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 5.6936 - mean_output_loss: 21.2895 - variance_output_loss: -15.5959 - val_loss: -1.9613 - val_mean_output_loss: 12.1823 - val_variance_output_loss: -14.1436\n",
            "Epoch 1402/5000\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 5.3114 - mean_output_loss: 21.2216 - variance_output_loss: -15.9102 - val_loss: -2.0157 - val_mean_output_loss: 12.1279 - val_variance_output_loss: -14.1436\n",
            "Epoch 1403/5000\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 6.5686 - mean_output_loss: 21.1487 - variance_output_loss: -14.5802 - val_loss: -2.0693 - val_mean_output_loss: 12.0743 - val_variance_output_loss: -14.1436\n",
            "Epoch 1404/5000\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 5.6770 - mean_output_loss: 21.0829 - variance_output_loss: -15.4060 - val_loss: -2.1232 - val_mean_output_loss: 12.0204 - val_variance_output_loss: -14.1437\n",
            "Epoch 1405/5000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 6.0139 - mean_output_loss: 21.0126 - variance_output_loss: -14.9987 - val_loss: -2.1766 - val_mean_output_loss: 11.9671 - val_variance_output_loss: -14.1437\n",
            "Epoch 1406/5000\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 5.7160 - mean_output_loss: 20.9423 - variance_output_loss: -15.2264 - val_loss: -2.2294 - val_mean_output_loss: 11.9142 - val_variance_output_loss: -14.1437\n",
            "Epoch 1407/5000\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 6.3935 - mean_output_loss: 20.8771 - variance_output_loss: -14.4837 - val_loss: -2.2824 - val_mean_output_loss: 11.8613 - val_variance_output_loss: -14.1437\n",
            "Epoch 1408/5000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 5.9397 - mean_output_loss: 20.8070 - variance_output_loss: -14.8673 - val_loss: -2.3348 - val_mean_output_loss: 11.8089 - val_variance_output_loss: -14.1437\n",
            "Epoch 1409/5000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 6.6419 - mean_output_loss: 20.7398 - variance_output_loss: -14.0979 - val_loss: -2.3869 - val_mean_output_loss: 11.7569 - val_variance_output_loss: -14.1438\n",
            "Epoch 1410/5000\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 5.1004 - mean_output_loss: 20.6730 - variance_output_loss: -15.5726 - val_loss: -2.4387 - val_mean_output_loss: 11.7050 - val_variance_output_loss: -14.1438\n",
            "Epoch 1411/5000\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 5.4861 - mean_output_loss: 20.6061 - variance_output_loss: -15.1201 - val_loss: -2.4903 - val_mean_output_loss: 11.6535 - val_variance_output_loss: -14.1438\n",
            "Epoch 1412/5000\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 4.7769 - mean_output_loss: 20.5380 - variance_output_loss: -15.7611 - val_loss: -2.5413 - val_mean_output_loss: 11.6025 - val_variance_output_loss: -14.1438\n",
            "Epoch 1413/5000\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 4.8474 - mean_output_loss: 20.4745 - variance_output_loss: -15.6271 - val_loss: -2.5923 - val_mean_output_loss: 11.5515 - val_variance_output_loss: -14.1438\n",
            "Epoch 1414/5000\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 5.9243 - mean_output_loss: 20.4060 - variance_output_loss: -14.4816 - val_loss: -2.6427 - val_mean_output_loss: 11.5012 - val_variance_output_loss: -14.1439\n",
            "Epoch 1415/5000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 5.3974 - mean_output_loss: 20.3391 - variance_output_loss: -14.9417 - val_loss: -2.6927 - val_mean_output_loss: 11.4512 - val_variance_output_loss: -14.1439\n",
            "Epoch 1416/5000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 5.1155 - mean_output_loss: 20.2748 - variance_output_loss: -15.1593 - val_loss: -2.7427 - val_mean_output_loss: 11.4012 - val_variance_output_loss: -14.1439\n",
            "Epoch 1417/5000\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 3.9692 - mean_output_loss: 20.2118 - variance_output_loss: -16.2426 - val_loss: -2.7927 - val_mean_output_loss: 11.3513 - val_variance_output_loss: -14.1439\n",
            "Epoch 1418/5000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 4.4653 - mean_output_loss: 20.1431 - variance_output_loss: -15.6778 - val_loss: -2.8419 - val_mean_output_loss: 11.3021 - val_variance_output_loss: -14.1439\n",
            "Epoch 1419/5000\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 5.6941 - mean_output_loss: 20.0812 - variance_output_loss: -14.3870 - val_loss: -2.8913 - val_mean_output_loss: 11.2527 - val_variance_output_loss: -14.1440\n",
            "Epoch 1420/5000\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 3.8044 - mean_output_loss: 20.0174 - variance_output_loss: -16.2129 - val_loss: -2.9405 - val_mean_output_loss: 11.2035 - val_variance_output_loss: -14.1440\n",
            "Epoch 1421/5000\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 5.6050 - mean_output_loss: 19.9508 - variance_output_loss: -14.3458 - val_loss: -2.9890 - val_mean_output_loss: 11.1550 - val_variance_output_loss: -14.1440\n",
            "Epoch 1422/5000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 4.9806 - mean_output_loss: 19.8893 - variance_output_loss: -14.9087 - val_loss: -3.0377 - val_mean_output_loss: 11.1063 - val_variance_output_loss: -14.1440\n",
            "Epoch 1423/5000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 6.0611 - mean_output_loss: 19.8232 - variance_output_loss: -13.7621 - val_loss: -3.0859 - val_mean_output_loss: 11.0582 - val_variance_output_loss: -14.1441\n",
            "Epoch 1424/5000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 3.8832 - mean_output_loss: 19.7622 - variance_output_loss: -15.8790 - val_loss: -3.1341 - val_mean_output_loss: 11.0100 - val_variance_output_loss: -14.1441\n",
            "Epoch 1425/5000\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 4.9937 - mean_output_loss: 19.6986 - variance_output_loss: -14.7049 - val_loss: -3.1820 - val_mean_output_loss: 10.9621 - val_variance_output_loss: -14.1441\n",
            "Epoch 1426/5000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 3.7560 - mean_output_loss: 19.6339 - variance_output_loss: -15.8779 - val_loss: -3.2294 - val_mean_output_loss: 10.9147 - val_variance_output_loss: -14.1441\n",
            "Epoch 1427/5000\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 4.0391 - mean_output_loss: 19.5730 - variance_output_loss: -15.5339 - val_loss: -3.2768 - val_mean_output_loss: 10.8673 - val_variance_output_loss: -14.1441\n",
            "Epoch 1428/5000\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 4.0737 - mean_output_loss: 19.5130 - variance_output_loss: -15.4393 - val_loss: -3.3243 - val_mean_output_loss: 10.8199 - val_variance_output_loss: -14.1442\n",
            "Epoch 1429/5000\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 4.5153 - mean_output_loss: 19.4507 - variance_output_loss: -14.9354 - val_loss: -3.3713 - val_mean_output_loss: 10.7729 - val_variance_output_loss: -14.1442\n",
            "Epoch 1430/5000\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 5.5638 - mean_output_loss: 19.3876 - variance_output_loss: -13.8238 - val_loss: -3.4177 - val_mean_output_loss: 10.7265 - val_variance_output_loss: -14.1442\n",
            "Epoch 1431/5000\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 3.8055 - mean_output_loss: 19.3256 - variance_output_loss: -15.5201 - val_loss: -3.4638 - val_mean_output_loss: 10.6804 - val_variance_output_loss: -14.1442\n",
            "Epoch 1432/5000\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 3.9199 - mean_output_loss: 19.2656 - variance_output_loss: -15.3458 - val_loss: -3.5098 - val_mean_output_loss: 10.6344 - val_variance_output_loss: -14.1442\n",
            "Epoch 1433/5000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 4.0676 - mean_output_loss: 19.2026 - variance_output_loss: -15.1351 - val_loss: -3.5553 - val_mean_output_loss: 10.5890 - val_variance_output_loss: -14.1443\n",
            "Epoch 1434/5000\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 4.1867 - mean_output_loss: 19.1448 - variance_output_loss: -14.9581 - val_loss: -3.6009 - val_mean_output_loss: 10.5434 - val_variance_output_loss: -14.1443\n",
            "Epoch 1435/5000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 4.4253 - mean_output_loss: 19.0865 - variance_output_loss: -14.6612 - val_loss: -3.6464 - val_mean_output_loss: 10.4979 - val_variance_output_loss: -14.1443\n",
            "Epoch 1436/5000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 3.6986 - mean_output_loss: 19.0241 - variance_output_loss: -15.3255 - val_loss: -3.6912 - val_mean_output_loss: 10.4531 - val_variance_output_loss: -14.1443\n",
            "Epoch 1437/5000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 4.5555 - mean_output_loss: 18.9645 - variance_output_loss: -14.4090 - val_loss: -3.7358 - val_mean_output_loss: 10.4086 - val_variance_output_loss: -14.1443\n",
            "Epoch 1438/5000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 3.4286 - mean_output_loss: 18.9056 - variance_output_loss: -15.4770 - val_loss: -3.7801 - val_mean_output_loss: 10.3642 - val_variance_output_loss: -14.1444\n",
            "Epoch 1439/5000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 4.1312 - mean_output_loss: 18.8479 - variance_output_loss: -14.7167 - val_loss: -3.8244 - val_mean_output_loss: 10.3200 - val_variance_output_loss: -14.1444\n",
            "Epoch 1440/5000\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 3.7057 - mean_output_loss: 18.7871 - variance_output_loss: -15.0814 - val_loss: -3.8680 - val_mean_output_loss: 10.2764 - val_variance_output_loss: -14.1444\n",
            "Epoch 1441/5000\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 3.0611 - mean_output_loss: 18.7281 - variance_output_loss: -15.6670 - val_loss: -3.9115 - val_mean_output_loss: 10.2329 - val_variance_output_loss: -14.1444\n",
            "Epoch 1442/5000\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 4.3454 - mean_output_loss: 18.6719 - variance_output_loss: -14.3264 - val_loss: -3.9550 - val_mean_output_loss: 10.1894 - val_variance_output_loss: -14.1444\n",
            "Epoch 1443/5000\n",
            "2/2 [==============================] - 0s 67ms/step - loss: 3.7152 - mean_output_loss: 18.6140 - variance_output_loss: -14.8989 - val_loss: -3.9983 - val_mean_output_loss: 10.1461 - val_variance_output_loss: -14.1445\n",
            "Epoch 1444/5000\n",
            "2/2 [==============================] - 0s 69ms/step - loss: 3.6214 - mean_output_loss: 18.5562 - variance_output_loss: -14.9347 - val_loss: -4.0413 - val_mean_output_loss: 10.1032 - val_variance_output_loss: -14.1445\n",
            "Epoch 1445/5000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 3.9410 - mean_output_loss: 18.4977 - variance_output_loss: -14.5567 - val_loss: -4.0840 - val_mean_output_loss: 10.0605 - val_variance_output_loss: -14.1445\n",
            "Epoch 1446/5000\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 3.6456 - mean_output_loss: 18.4423 - variance_output_loss: -14.7967 - val_loss: -4.1266 - val_mean_output_loss: 10.0179 - val_variance_output_loss: -14.1445\n",
            "Epoch 1447/5000\n",
            "2/2 [==============================] - 0s 73ms/step - loss: 3.3693 - mean_output_loss: 18.3861 - variance_output_loss: -15.0169 - val_loss: -4.1690 - val_mean_output_loss: 9.9756 - val_variance_output_loss: -14.1445\n",
            "Epoch 1448/5000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 3.6577 - mean_output_loss: 18.3282 - variance_output_loss: -14.6705 - val_loss: -4.2108 - val_mean_output_loss: 9.9337 - val_variance_output_loss: -14.1446\n",
            "Epoch 1449/5000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 3.1130 - mean_output_loss: 18.2724 - variance_output_loss: -15.1594 - val_loss: -4.2525 - val_mean_output_loss: 9.8920 - val_variance_output_loss: -14.1446\n",
            "Epoch 1450/5000\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 2.8748 - mean_output_loss: 18.2170 - variance_output_loss: -15.3422 - val_loss: -4.2940 - val_mean_output_loss: 9.8506 - val_variance_output_loss: -14.1446\n",
            "Epoch 1451/5000\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 1.7339 - mean_output_loss: 18.1590 - variance_output_loss: -16.4251 - val_loss: -4.3349 - val_mean_output_loss: 9.8097 - val_variance_output_loss: -14.1446\n",
            "Epoch 1452/5000\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 3.6227 - mean_output_loss: 18.1022 - variance_output_loss: -14.4794 - val_loss: -4.3756 - val_mean_output_loss: 9.7690 - val_variance_output_loss: -14.1446\n",
            "Epoch 1453/5000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 3.3453 - mean_output_loss: 18.0495 - variance_output_loss: -14.7042 - val_loss: -4.4165 - val_mean_output_loss: 9.7281 - val_variance_output_loss: -14.1447\n",
            "Epoch 1454/5000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 3.3616 - mean_output_loss: 17.9956 - variance_output_loss: -14.6340 - val_loss: -4.4573 - val_mean_output_loss: 9.6873 - val_variance_output_loss: -14.1447\n",
            "Epoch 1455/5000\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 3.4744 - mean_output_loss: 17.9404 - variance_output_loss: -14.4660 - val_loss: -4.4978 - val_mean_output_loss: 9.6469 - val_variance_output_loss: -14.1447\n",
            "Epoch 1456/5000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 1.8999 - mean_output_loss: 17.8838 - variance_output_loss: -15.9840 - val_loss: -4.5378 - val_mean_output_loss: 9.6069 - val_variance_output_loss: -14.1447\n",
            "Epoch 1457/5000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 3.1482 - mean_output_loss: 17.8325 - variance_output_loss: -14.6842 - val_loss: -4.5780 - val_mean_output_loss: 9.5668 - val_variance_output_loss: -14.1447\n",
            "Epoch 1458/5000\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 2.5031 - mean_output_loss: 17.7787 - variance_output_loss: -15.2756 - val_loss: -4.6178 - val_mean_output_loss: 9.5270 - val_variance_output_loss: -14.1447\n",
            "Epoch 1459/5000\n",
            "2/2 [==============================] - 0s 66ms/step - loss: 3.2316 - mean_output_loss: 17.7218 - variance_output_loss: -14.4901 - val_loss: -4.6569 - val_mean_output_loss: 9.4878 - val_variance_output_loss: -14.1448\n",
            "Epoch 1460/5000\n",
            "2/2 [==============================] - 0s 79ms/step - loss: 3.0612 - mean_output_loss: 17.6716 - variance_output_loss: -14.6104 - val_loss: -4.6963 - val_mean_output_loss: 9.4485 - val_variance_output_loss: -14.1448\n",
            "Epoch 1461/5000\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 3.4928 - mean_output_loss: 17.6181 - variance_output_loss: -14.1252 - val_loss: -4.7352 - val_mean_output_loss: 9.4096 - val_variance_output_loss: -14.1448\n",
            "Epoch 1462/5000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 3.6315 - mean_output_loss: 17.5647 - variance_output_loss: -13.9332 - val_loss: -4.7738 - val_mean_output_loss: 9.3710 - val_variance_output_loss: -14.1448\n",
            "Epoch 1463/5000\n",
            "2/2 [==============================] - 0s 71ms/step - loss: 1.7572 - mean_output_loss: 17.5122 - variance_output_loss: -15.7550 - val_loss: -4.8121 - val_mean_output_loss: 9.3328 - val_variance_output_loss: -14.1448\n",
            "Epoch 1464/5000\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 3.4000 - mean_output_loss: 17.4590 - variance_output_loss: -14.0590 - val_loss: -4.8500 - val_mean_output_loss: 9.2948 - val_variance_output_loss: -14.1449\n",
            "Epoch 1465/5000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 2.6049 - mean_output_loss: 17.4096 - variance_output_loss: -14.8047 - val_loss: -4.8880 - val_mean_output_loss: 9.2569 - val_variance_output_loss: -14.1449\n",
            "Epoch 1466/5000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 2.5839 - mean_output_loss: 17.3547 - variance_output_loss: -14.7708 - val_loss: -4.9253 - val_mean_output_loss: 9.2196 - val_variance_output_loss: -14.1449\n",
            "Epoch 1467/5000\n",
            "2/2 [==============================] - 0s 66ms/step - loss: 2.3349 - mean_output_loss: 17.3061 - variance_output_loss: -14.9712 - val_loss: -4.9628 - val_mean_output_loss: 9.1821 - val_variance_output_loss: -14.1449\n",
            "Epoch 1468/5000\n",
            "2/2 [==============================] - 0s 92ms/step - loss: 2.3519 - mean_output_loss: 17.2533 - variance_output_loss: -14.9013 - val_loss: -4.9998 - val_mean_output_loss: 9.1451 - val_variance_output_loss: -14.1449\n",
            "Epoch 1469/5000\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 1.9236 - mean_output_loss: 17.2017 - variance_output_loss: -15.2781 - val_loss: -5.0366 - val_mean_output_loss: 9.1083 - val_variance_output_loss: -14.1450\n",
            "Epoch 1470/5000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 1.4982 - mean_output_loss: 17.1503 - variance_output_loss: -15.6520 - val_loss: -5.0732 - val_mean_output_loss: 9.0718 - val_variance_output_loss: -14.1450\n",
            "Epoch 1471/5000\n",
            "2/2 [==============================] - 0s 87ms/step - loss: 2.8669 - mean_output_loss: 17.1021 - variance_output_loss: -14.2351 - val_loss: -5.1099 - val_mean_output_loss: 9.0351 - val_variance_output_loss: -14.1450\n",
            "Epoch 1472/5000\n",
            "2/2 [==============================] - 0s 76ms/step - loss: 1.7003 - mean_output_loss: 17.0517 - variance_output_loss: -15.3514 - val_loss: -5.1464 - val_mean_output_loss: 8.9986 - val_variance_output_loss: -14.1450\n",
            "Epoch 1473/5000\n",
            "2/2 [==============================] - 0s 98ms/step - loss: 2.1635 - mean_output_loss: 17.0023 - variance_output_loss: -14.8388 - val_loss: -5.1827 - val_mean_output_loss: 8.9623 - val_variance_output_loss: -14.1450\n",
            "Epoch 1474/5000\n",
            "2/2 [==============================] - 0s 75ms/step - loss: 2.5920 - mean_output_loss: 16.9530 - variance_output_loss: -14.3611 - val_loss: -5.2188 - val_mean_output_loss: 8.9263 - val_variance_output_loss: -14.1450\n",
            "Epoch 1475/5000\n",
            "2/2 [==============================] - 0s 75ms/step - loss: -0.0432 - mean_output_loss: 16.9024 - variance_output_loss: -16.9456 - val_loss: -5.2544 - val_mean_output_loss: 8.8907 - val_variance_output_loss: -14.1451\n",
            "Epoch 1476/5000\n",
            "2/2 [==============================] - 0s 70ms/step - loss: 2.8872 - mean_output_loss: 16.8533 - variance_output_loss: -13.9660 - val_loss: -5.2898 - val_mean_output_loss: 8.8553 - val_variance_output_loss: -14.1451\n",
            "Epoch 1477/5000\n",
            "2/2 [==============================] - 0s 72ms/step - loss: 2.4154 - mean_output_loss: 16.8027 - variance_output_loss: -14.3874 - val_loss: -5.3248 - val_mean_output_loss: 8.8203 - val_variance_output_loss: -14.1451\n",
            "Epoch 1478/5000\n",
            "2/2 [==============================] - 0s 69ms/step - loss: 0.5375 - mean_output_loss: 16.7555 - variance_output_loss: -16.2180 - val_loss: -5.3598 - val_mean_output_loss: 8.7854 - val_variance_output_loss: -14.1451\n",
            "Epoch 1479/5000\n",
            "2/2 [==============================] - 0s 67ms/step - loss: 0.7846 - mean_output_loss: 16.7066 - variance_output_loss: -15.9221 - val_loss: -5.3945 - val_mean_output_loss: 8.7506 - val_variance_output_loss: -14.1451\n",
            "Epoch 1480/5000\n",
            "2/2 [==============================] - 0s 93ms/step - loss: 1.6232 - mean_output_loss: 16.6593 - variance_output_loss: -15.0361 - val_loss: -5.4291 - val_mean_output_loss: 8.7160 - val_variance_output_loss: -14.1452\n",
            "Epoch 1481/5000\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 2.5357 - mean_output_loss: 16.6109 - variance_output_loss: -14.0752 - val_loss: -5.4635 - val_mean_output_loss: 8.6817 - val_variance_output_loss: -14.1452\n",
            "Epoch 1482/5000\n",
            "2/2 [==============================] - 0s 71ms/step - loss: 2.0939 - mean_output_loss: 16.5643 - variance_output_loss: -14.4704 - val_loss: -5.4977 - val_mean_output_loss: 8.6475 - val_variance_output_loss: -14.1452\n",
            "Epoch 1483/5000\n",
            "2/2 [==============================] - 0s 76ms/step - loss: 2.1669 - mean_output_loss: 16.5150 - variance_output_loss: -14.3480 - val_loss: -5.5314 - val_mean_output_loss: 8.6138 - val_variance_output_loss: -14.1452\n",
            "Epoch 1484/5000\n",
            "2/2 [==============================] - 0s 67ms/step - loss: 1.3390 - mean_output_loss: 16.4692 - variance_output_loss: -15.1302 - val_loss: -5.5651 - val_mean_output_loss: 8.5801 - val_variance_output_loss: -14.1452\n",
            "Epoch 1485/5000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 1.3377 - mean_output_loss: 16.4217 - variance_output_loss: -15.0841 - val_loss: -5.5985 - val_mean_output_loss: 8.5468 - val_variance_output_loss: -14.1452\n",
            "Epoch 1486/5000\n",
            "2/2 [==============================] - 0s 81ms/step - loss: 1.3044 - mean_output_loss: 16.3746 - variance_output_loss: -15.0702 - val_loss: -5.6316 - val_mean_output_loss: 8.5136 - val_variance_output_loss: -14.1453\n",
            "Epoch 1487/5000\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 1.3206 - mean_output_loss: 16.3273 - variance_output_loss: -15.0067 - val_loss: -5.6645 - val_mean_output_loss: 8.4808 - val_variance_output_loss: -14.1453\n",
            "Epoch 1488/5000\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 1.4283 - mean_output_loss: 16.2817 - variance_output_loss: -14.8534 - val_loss: -5.6973 - val_mean_output_loss: 8.4480 - val_variance_output_loss: -14.1453\n",
            "Epoch 1489/5000\n",
            "2/2 [==============================] - 0s 68ms/step - loss: 0.9113 - mean_output_loss: 16.2365 - variance_output_loss: -15.3252 - val_loss: -5.7301 - val_mean_output_loss: 8.4152 - val_variance_output_loss: -14.1453\n",
            "Epoch 1490/5000\n",
            "2/2 [==============================] - 0s 72ms/step - loss: 0.4725 - mean_output_loss: 16.1902 - variance_output_loss: -15.7177 - val_loss: -5.7625 - val_mean_output_loss: 8.3828 - val_variance_output_loss: -14.1453\n",
            "Epoch 1491/5000\n",
            "2/2 [==============================] - 0s 68ms/step - loss: 0.9975 - mean_output_loss: 16.1434 - variance_output_loss: -15.1460 - val_loss: -5.7947 - val_mean_output_loss: 8.3507 - val_variance_output_loss: -14.1454\n",
            "Epoch 1492/5000\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 0.7808 - mean_output_loss: 16.0979 - variance_output_loss: -15.3171 - val_loss: -5.8267 - val_mean_output_loss: 8.3186 - val_variance_output_loss: -14.1454\n",
            "Epoch 1493/5000\n",
            "2/2 [==============================] - 0s 72ms/step - loss: 1.3060 - mean_output_loss: 16.0544 - variance_output_loss: -14.7484 - val_loss: -5.8588 - val_mean_output_loss: 8.2866 - val_variance_output_loss: -14.1454\n",
            "Epoch 1494/5000\n",
            "2/2 [==============================] - 0s 71ms/step - loss: 1.5817 - mean_output_loss: 16.0074 - variance_output_loss: -14.4257 - val_loss: -5.8904 - val_mean_output_loss: 8.2550 - val_variance_output_loss: -14.1454\n",
            "Epoch 1495/5000\n",
            "2/2 [==============================] - 0s 70ms/step - loss: 1.1017 - mean_output_loss: 15.9622 - variance_output_loss: -14.8605 - val_loss: -5.9219 - val_mean_output_loss: 8.2235 - val_variance_output_loss: -14.1454\n",
            "Epoch 1496/5000\n",
            "2/2 [==============================] - 0s 70ms/step - loss: 0.7269 - mean_output_loss: 15.9201 - variance_output_loss: -15.1932 - val_loss: -5.9536 - val_mean_output_loss: 8.1919 - val_variance_output_loss: -14.1454\n",
            "Epoch 1497/5000\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 1.0012 - mean_output_loss: 15.8748 - variance_output_loss: -14.8736 - val_loss: -5.9848 - val_mean_output_loss: 8.1606 - val_variance_output_loss: -14.1455\n",
            "Epoch 1498/5000\n",
            "2/2 [==============================] - 0s 80ms/step - loss: -0.0424 - mean_output_loss: 15.8306 - variance_output_loss: -15.8730 - val_loss: -6.0159 - val_mean_output_loss: 8.1296 - val_variance_output_loss: -14.1455\n",
            "Epoch 1499/5000\n",
            "2/2 [==============================] - 0s 81ms/step - loss: -0.3124 - mean_output_loss: 15.7855 - variance_output_loss: -16.0980 - val_loss: -6.0466 - val_mean_output_loss: 8.0989 - val_variance_output_loss: -14.1455\n",
            "Epoch 1500/5000\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 1.8091 - mean_output_loss: 15.7426 - variance_output_loss: -13.9335 - val_loss: -6.0772 - val_mean_output_loss: 8.0683 - val_variance_output_loss: -14.1455\n",
            "Epoch 1501/5000\n",
            "2/2 [==============================] - 0s 70ms/step - loss: -0.4736 - mean_output_loss: 15.6991 - variance_output_loss: -16.1727 - val_loss: -6.1076 - val_mean_output_loss: 8.0380 - val_variance_output_loss: -14.1455\n",
            "Epoch 1502/5000\n",
            "2/2 [==============================] - 0s 67ms/step - loss: 1.1981 - mean_output_loss: 15.6546 - variance_output_loss: -14.4565 - val_loss: -6.1376 - val_mean_output_loss: 8.0079 - val_variance_output_loss: -14.1455\n",
            "Epoch 1503/5000\n",
            "2/2 [==============================] - 0s 68ms/step - loss: 0.8324 - mean_output_loss: 15.6131 - variance_output_loss: -14.7808 - val_loss: -6.1677 - val_mean_output_loss: 7.9779 - val_variance_output_loss: -14.1456\n",
            "Epoch 1504/5000\n",
            "2/2 [==============================] - 0s 85ms/step - loss: 0.7310 - mean_output_loss: 15.5703 - variance_output_loss: -14.8393 - val_loss: -6.1975 - val_mean_output_loss: 7.9481 - val_variance_output_loss: -14.1456\n",
            "Epoch 1505/5000\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 0.3984 - mean_output_loss: 15.5274 - variance_output_loss: -15.1290 - val_loss: -6.2270 - val_mean_output_loss: 7.9185 - val_variance_output_loss: -14.1456\n",
            "Epoch 1506/5000\n",
            "2/2 [==============================] - 0s 70ms/step - loss: 0.8418 - mean_output_loss: 15.4840 - variance_output_loss: -14.6422 - val_loss: -6.2563 - val_mean_output_loss: 7.8893 - val_variance_output_loss: -14.1456\n",
            "Epoch 1507/5000\n",
            "2/2 [==============================] - 0s 79ms/step - loss: 2.3554 - mean_output_loss: 15.4433 - variance_output_loss: -13.0879 - val_loss: -6.2855 - val_mean_output_loss: 7.8602 - val_variance_output_loss: -14.1456\n",
            "Epoch 1508/5000\n",
            "2/2 [==============================] - 0s 116ms/step - loss: 2.3357 - mean_output_loss: 15.3993 - variance_output_loss: -13.0636 - val_loss: -6.3142 - val_mean_output_loss: 7.8314 - val_variance_output_loss: -14.1456\n",
            "Epoch 1509/5000\n",
            "2/2 [==============================] - 0s 84ms/step - loss: 0.2485 - mean_output_loss: 15.3565 - variance_output_loss: -15.1081 - val_loss: -6.3428 - val_mean_output_loss: 7.8028 - val_variance_output_loss: -14.1457\n",
            "Epoch 1510/5000\n",
            "2/2 [==============================] - 0s 61ms/step - loss: -0.3075 - mean_output_loss: 15.3170 - variance_output_loss: -15.6245 - val_loss: -6.3716 - val_mean_output_loss: 7.7741 - val_variance_output_loss: -14.1457\n",
            "Epoch 1511/5000\n",
            "2/2 [==============================] - 0s 66ms/step - loss: 0.8699 - mean_output_loss: 15.2779 - variance_output_loss: -14.4079 - val_loss: -6.4004 - val_mean_output_loss: 7.7453 - val_variance_output_loss: -14.1457\n",
            "Epoch 1512/5000\n",
            "2/2 [==============================] - 0s 67ms/step - loss: -0.2913 - mean_output_loss: 15.2343 - variance_output_loss: -15.5256 - val_loss: -6.4286 - val_mean_output_loss: 7.7171 - val_variance_output_loss: -14.1457\n",
            "Epoch 1513/5000\n",
            "2/2 [==============================] - 0s 63ms/step - loss: -0.9890 - mean_output_loss: 15.1944 - variance_output_loss: -16.1834 - val_loss: -6.4568 - val_mean_output_loss: 7.6889 - val_variance_output_loss: -14.1457\n",
            "Epoch 1514/5000\n",
            "2/2 [==============================] - 0s 72ms/step - loss: 2.0986 - mean_output_loss: 15.1531 - variance_output_loss: -13.0545 - val_loss: -6.4847 - val_mean_output_loss: 7.6611 - val_variance_output_loss: -14.1458\n",
            "Epoch 1515/5000\n",
            "2/2 [==============================] - 0s 69ms/step - loss: 1.4962 - mean_output_loss: 15.1128 - variance_output_loss: -13.6166 - val_loss: -6.5124 - val_mean_output_loss: 7.6334 - val_variance_output_loss: -14.1458\n",
            "Epoch 1516/5000\n",
            "2/2 [==============================] - 0s 64ms/step - loss: -0.1290 - mean_output_loss: 15.0704 - variance_output_loss: -15.1994 - val_loss: -6.5396 - val_mean_output_loss: 7.6061 - val_variance_output_loss: -14.1458\n",
            "Epoch 1517/5000\n",
            "2/2 [==============================] - 0s 74ms/step - loss: -0.2187 - mean_output_loss: 15.0342 - variance_output_loss: -15.2529 - val_loss: -6.5672 - val_mean_output_loss: 7.5786 - val_variance_output_loss: -14.1458\n",
            "Epoch 1518/5000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 0.9272 - mean_output_loss: 14.9904 - variance_output_loss: -14.0631 - val_loss: -6.5941 - val_mean_output_loss: 7.5517 - val_variance_output_loss: -14.1458\n",
            "Epoch 1519/5000\n",
            "2/2 [==============================] - 0s 67ms/step - loss: 1.2881 - mean_output_loss: 14.9533 - variance_output_loss: -13.6651 - val_loss: -6.6211 - val_mean_output_loss: 7.5247 - val_variance_output_loss: -14.1458\n",
            "Epoch 1520/5000\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 0.5788 - mean_output_loss: 14.9118 - variance_output_loss: -14.3330 - val_loss: -6.6478 - val_mean_output_loss: 7.4981 - val_variance_output_loss: -14.1459\n",
            "Epoch 1521/5000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: -0.1368 - mean_output_loss: 14.8727 - variance_output_loss: -15.0095 - val_loss: -6.6744 - val_mean_output_loss: 7.4715 - val_variance_output_loss: -14.1459\n",
            "Epoch 1522/5000\n",
            "2/2 [==============================] - 0s 40ms/step - loss: -0.7663 - mean_output_loss: 14.8335 - variance_output_loss: -15.5997 - val_loss: -6.7009 - val_mean_output_loss: 7.4450 - val_variance_output_loss: -14.1459\n",
            "Epoch 1523/5000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.0833 - mean_output_loss: 14.7952 - variance_output_loss: -14.7119 - val_loss: -6.7273 - val_mean_output_loss: 7.4186 - val_variance_output_loss: -14.1459\n",
            "Epoch 1524/5000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: -0.4802 - mean_output_loss: 14.7563 - variance_output_loss: -15.2365 - val_loss: -6.7536 - val_mean_output_loss: 7.3924 - val_variance_output_loss: -14.1459\n",
            "Epoch 1525/5000\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.2318 - mean_output_loss: 14.7172 - variance_output_loss: -14.4855 - val_loss: -6.7797 - val_mean_output_loss: 7.3663 - val_variance_output_loss: -14.1459\n",
            "Epoch 1526/5000\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 0.4238 - mean_output_loss: 14.6789 - variance_output_loss: -14.2551 - val_loss: -6.8056 - val_mean_output_loss: 7.3404 - val_variance_output_loss: -14.1460\n",
            "Epoch 1527/5000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: -0.4599 - mean_output_loss: 14.6405 - variance_output_loss: -15.1004 - val_loss: -6.8314 - val_mean_output_loss: 7.3146 - val_variance_output_loss: -14.1460\n",
            "Epoch 1528/5000\n",
            "2/2 [==============================] - 0s 40ms/step - loss: -0.3632 - mean_output_loss: 14.6035 - variance_output_loss: -14.9667 - val_loss: -6.8571 - val_mean_output_loss: 7.2889 - val_variance_output_loss: -14.1460\n",
            "Epoch 1529/5000\n",
            "2/2 [==============================] - 0s 47ms/step - loss: -0.5530 - mean_output_loss: 14.5652 - variance_output_loss: -15.1182 - val_loss: -6.8825 - val_mean_output_loss: 7.2635 - val_variance_output_loss: -14.1460\n",
            "Epoch 1530/5000\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 1.0864 - mean_output_loss: 14.5265 - variance_output_loss: -13.4400 - val_loss: -6.9076 - val_mean_output_loss: 7.2384 - val_variance_output_loss: -14.1460\n",
            "Epoch 1531/5000\n",
            "2/2 [==============================] - 0s 52ms/step - loss: -0.3756 - mean_output_loss: 14.4880 - variance_output_loss: -14.8636 - val_loss: -6.9325 - val_mean_output_loss: 7.2135 - val_variance_output_loss: -14.1460\n",
            "Epoch 1532/5000\n",
            "2/2 [==============================] - 0s 66ms/step - loss: -1.0095 - mean_output_loss: 14.4520 - variance_output_loss: -15.4615 - val_loss: -6.9574 - val_mean_output_loss: 7.1886 - val_variance_output_loss: -14.1460\n",
            "Epoch 1533/5000\n",
            "2/2 [==============================] - 0s 60ms/step - loss: -1.8069 - mean_output_loss: 14.4128 - variance_output_loss: -16.2197 - val_loss: -6.9820 - val_mean_output_loss: 7.1641 - val_variance_output_loss: -14.1461\n",
            "Epoch 1534/5000\n",
            "2/2 [==============================] - 0s 65ms/step - loss: -0.7462 - mean_output_loss: 14.3780 - variance_output_loss: -15.1243 - val_loss: -7.0067 - val_mean_output_loss: 7.1394 - val_variance_output_loss: -14.1461\n",
            "Epoch 1535/5000\n",
            "2/2 [==============================] - 0s 44ms/step - loss: -1.1135 - mean_output_loss: 14.3410 - variance_output_loss: -15.4545 - val_loss: -7.0312 - val_mean_output_loss: 7.1149 - val_variance_output_loss: -14.1461\n",
            "Epoch 1536/5000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: -0.6426 - mean_output_loss: 14.3039 - variance_output_loss: -14.9465 - val_loss: -7.0555 - val_mean_output_loss: 7.0906 - val_variance_output_loss: -14.1461\n",
            "Epoch 1537/5000\n",
            "2/2 [==============================] - 0s 61ms/step - loss: -1.7366 - mean_output_loss: 14.2654 - variance_output_loss: -16.0020 - val_loss: -7.0794 - val_mean_output_loss: 7.0667 - val_variance_output_loss: -14.1461\n",
            "Epoch 1538/5000\n",
            "2/2 [==============================] - 0s 46ms/step - loss: -1.3752 - mean_output_loss: 14.2320 - variance_output_loss: -15.6071 - val_loss: -7.1036 - val_mean_output_loss: 7.0425 - val_variance_output_loss: -14.1461\n",
            "Epoch 1539/5000\n",
            "2/2 [==============================] - 0s 50ms/step - loss: -1.4214 - mean_output_loss: 14.1930 - variance_output_loss: -15.6143 - val_loss: -7.1273 - val_mean_output_loss: 7.0189 - val_variance_output_loss: -14.1462\n",
            "Epoch 1540/5000\n",
            "2/2 [==============================] - 0s 65ms/step - loss: -1.3160 - mean_output_loss: 14.1594 - variance_output_loss: -15.4754 - val_loss: -7.1511 - val_mean_output_loss: 6.9950 - val_variance_output_loss: -14.1462\n",
            "Epoch 1541/5000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: -0.9655 - mean_output_loss: 14.1242 - variance_output_loss: -15.0897 - val_loss: -7.1748 - val_mean_output_loss: 6.9714 - val_variance_output_loss: -14.1462\n",
            "Epoch 1542/5000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: -0.4303 - mean_output_loss: 14.0872 - variance_output_loss: -14.5176 - val_loss: -7.1981 - val_mean_output_loss: 6.9481 - val_variance_output_loss: -14.1462\n",
            "Epoch 1543/5000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: -0.4944 - mean_output_loss: 14.0493 - variance_output_loss: -14.5436 - val_loss: -7.2210 - val_mean_output_loss: 6.9252 - val_variance_output_loss: -14.1462\n",
            "Epoch 1544/5000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: -1.1315 - mean_output_loss: 14.0187 - variance_output_loss: -15.1502 - val_loss: -7.2443 - val_mean_output_loss: 6.9020 - val_variance_output_loss: -14.1462\n",
            "Epoch 1545/5000\n",
            "2/2 [==============================] - 0s 63ms/step - loss: -0.7357 - mean_output_loss: 13.9816 - variance_output_loss: -14.7173 - val_loss: -7.2671 - val_mean_output_loss: 6.8792 - val_variance_output_loss: -14.1463\n",
            "Epoch 1546/5000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: -1.7431 - mean_output_loss: 13.9462 - variance_output_loss: -15.6893 - val_loss: -7.2896 - val_mean_output_loss: 6.8566 - val_variance_output_loss: -14.1463\n",
            "Epoch 1547/5000\n",
            "2/2 [==============================] - 0s 67ms/step - loss: -1.1599 - mean_output_loss: 13.9130 - variance_output_loss: -15.0729 - val_loss: -7.3122 - val_mean_output_loss: 6.8341 - val_variance_output_loss: -14.1463\n",
            "Epoch 1548/5000\n",
            "2/2 [==============================] - 0s 64ms/step - loss: -0.0641 - mean_output_loss: 13.8761 - variance_output_loss: -13.9403 - val_loss: -7.3343 - val_mean_output_loss: 6.8120 - val_variance_output_loss: -14.1463\n",
            "Epoch 1549/5000\n",
            "2/2 [==============================] - 0s 60ms/step - loss: -1.4253 - mean_output_loss: 13.8435 - variance_output_loss: -15.2688 - val_loss: -7.3564 - val_mean_output_loss: 6.7899 - val_variance_output_loss: -14.1463\n",
            "Epoch 1550/5000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: -1.9404 - mean_output_loss: 13.8104 - variance_output_loss: -15.7507 - val_loss: -7.3785 - val_mean_output_loss: 6.7678 - val_variance_output_loss: -14.1463\n",
            "Epoch 1551/5000\n",
            "2/2 [==============================] - 0s 48ms/step - loss: -2.0915 - mean_output_loss: 13.7735 - variance_output_loss: -15.8650 - val_loss: -7.4001 - val_mean_output_loss: 6.7463 - val_variance_output_loss: -14.1464\n",
            "Epoch 1552/5000\n",
            "2/2 [==============================] - 0s 40ms/step - loss: -1.2597 - mean_output_loss: 13.7417 - variance_output_loss: -15.0014 - val_loss: -7.4218 - val_mean_output_loss: 6.7246 - val_variance_output_loss: -14.1464\n",
            "Epoch 1553/5000\n",
            "2/2 [==============================] - 0s 44ms/step - loss: -1.7973 - mean_output_loss: 13.7065 - variance_output_loss: -15.5038 - val_loss: -7.4432 - val_mean_output_loss: 6.7031 - val_variance_output_loss: -14.1464\n",
            "Epoch 1554/5000\n",
            "2/2 [==============================] - 0s 45ms/step - loss: -1.7354 - mean_output_loss: 13.6750 - variance_output_loss: -15.4104 - val_loss: -7.4648 - val_mean_output_loss: 6.6816 - val_variance_output_loss: -14.1464\n",
            "Epoch 1555/5000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: -1.0250 - mean_output_loss: 13.6407 - variance_output_loss: -14.6657 - val_loss: -7.4860 - val_mean_output_loss: 6.6604 - val_variance_output_loss: -14.1464\n",
            "Epoch 1556/5000\n",
            "2/2 [==============================] - 0s 64ms/step - loss: -1.5148 - mean_output_loss: 13.6075 - variance_output_loss: -15.1223 - val_loss: -7.5072 - val_mean_output_loss: 6.6393 - val_variance_output_loss: -14.1464\n",
            "Epoch 1557/5000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: -2.3618 - mean_output_loss: 13.5760 - variance_output_loss: -15.9378 - val_loss: -7.5283 - val_mean_output_loss: 6.6182 - val_variance_output_loss: -14.1464\n",
            "Epoch 1558/5000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: -1.6609 - mean_output_loss: 13.5426 - variance_output_loss: -15.2035 - val_loss: -7.5491 - val_mean_output_loss: 6.5973 - val_variance_output_loss: -14.1465\n",
            "Epoch 1559/5000\n",
            "2/2 [==============================] - 0s 61ms/step - loss: -1.2336 - mean_output_loss: 13.5087 - variance_output_loss: -14.7423 - val_loss: -7.5697 - val_mean_output_loss: 6.5768 - val_variance_output_loss: -14.1465\n",
            "Epoch 1560/5000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: -1.6487 - mean_output_loss: 13.4774 - variance_output_loss: -15.1262 - val_loss: -7.5903 - val_mean_output_loss: 6.5562 - val_variance_output_loss: -14.1465\n",
            "Epoch 1561/5000\n",
            "2/2 [==============================] - 0s 62ms/step - loss: -1.7591 - mean_output_loss: 13.4443 - variance_output_loss: -15.2034 - val_loss: -7.6106 - val_mean_output_loss: 6.5359 - val_variance_output_loss: -14.1465\n",
            "Epoch 1562/5000\n",
            "2/2 [==============================] - 0s 52ms/step - loss: -1.6321 - mean_output_loss: 13.4133 - variance_output_loss: -15.0454 - val_loss: -7.6309 - val_mean_output_loss: 6.5156 - val_variance_output_loss: -14.1465\n",
            "Epoch 1563/5000\n",
            "2/2 [==============================] - 0s 73ms/step - loss: -3.1288 - mean_output_loss: 13.3821 - variance_output_loss: -16.5109 - val_loss: -7.6511 - val_mean_output_loss: 6.4955 - val_variance_output_loss: -14.1465\n",
            "Epoch 1564/5000\n",
            "2/2 [==============================] - 0s 50ms/step - loss: -0.3848 - mean_output_loss: 13.3507 - variance_output_loss: -13.7356 - val_loss: -7.6710 - val_mean_output_loss: 6.4755 - val_variance_output_loss: -14.1466\n",
            "Epoch 1565/5000\n",
            "2/2 [==============================] - 0s 69ms/step - loss: -0.7303 - mean_output_loss: 13.3174 - variance_output_loss: -14.0477 - val_loss: -7.6906 - val_mean_output_loss: 6.4560 - val_variance_output_loss: -14.1466\n",
            "Epoch 1566/5000\n",
            "2/2 [==============================] - 0s 67ms/step - loss: -1.7843 - mean_output_loss: 13.2872 - variance_output_loss: -15.0715 - val_loss: -7.7101 - val_mean_output_loss: 6.4365 - val_variance_output_loss: -14.1466\n",
            "Epoch 1567/5000\n",
            "2/2 [==============================] - 0s 69ms/step - loss: -1.2229 - mean_output_loss: 13.2551 - variance_output_loss: -14.4781 - val_loss: -7.7294 - val_mean_output_loss: 6.4172 - val_variance_output_loss: -14.1466\n",
            "Epoch 1568/5000\n",
            "2/2 [==============================] - 0s 64ms/step - loss: -2.6458 - mean_output_loss: 13.2234 - variance_output_loss: -15.8692 - val_loss: -7.7484 - val_mean_output_loss: 6.3982 - val_variance_output_loss: -14.1466\n",
            "Epoch 1569/5000\n",
            "2/2 [==============================] - 0s 44ms/step - loss: -1.3584 - mean_output_loss: 13.1938 - variance_output_loss: -14.5522 - val_loss: -7.7676 - val_mean_output_loss: 6.3791 - val_variance_output_loss: -14.1466\n",
            "Epoch 1570/5000\n",
            "2/2 [==============================] - 0s 46ms/step - loss: -1.9516 - mean_output_loss: 13.1615 - variance_output_loss: -15.1131 - val_loss: -7.7864 - val_mean_output_loss: 6.3602 - val_variance_output_loss: -14.1466\n",
            "Epoch 1571/5000\n",
            "2/2 [==============================] - 0s 52ms/step - loss: -1.2562 - mean_output_loss: 13.1343 - variance_output_loss: -14.3904 - val_loss: -7.8055 - val_mean_output_loss: 6.3411 - val_variance_output_loss: -14.1467\n",
            "Epoch 1572/5000\n",
            "2/2 [==============================] - 0s 64ms/step - loss: -3.5637 - mean_output_loss: 13.1027 - variance_output_loss: -16.6664 - val_loss: -7.8243 - val_mean_output_loss: 6.3224 - val_variance_output_loss: -14.1467\n",
            "Epoch 1573/5000\n",
            "2/2 [==============================] - 0s 61ms/step - loss: -2.2195 - mean_output_loss: 13.0716 - variance_output_loss: -15.2911 - val_loss: -7.8428 - val_mean_output_loss: 6.3039 - val_variance_output_loss: -14.1467\n",
            "Epoch 1574/5000\n",
            "2/2 [==============================] - 0s 48ms/step - loss: -1.7723 - mean_output_loss: 13.0406 - variance_output_loss: -14.8129 - val_loss: -7.8612 - val_mean_output_loss: 6.2855 - val_variance_output_loss: -14.1467\n",
            "Epoch 1575/5000\n",
            "2/2 [==============================] - 0s 37ms/step - loss: -2.1525 - mean_output_loss: 13.0104 - variance_output_loss: -15.1629 - val_loss: -7.8794 - val_mean_output_loss: 6.2673 - val_variance_output_loss: -14.1467\n",
            "Epoch 1576/5000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: -2.2165 - mean_output_loss: 12.9825 - variance_output_loss: -15.1990 - val_loss: -7.8978 - val_mean_output_loss: 6.2489 - val_variance_output_loss: -14.1467\n",
            "Epoch 1577/5000\n",
            "2/2 [==============================] - 0s 39ms/step - loss: -2.0120 - mean_output_loss: 12.9519 - variance_output_loss: -14.9639 - val_loss: -7.9160 - val_mean_output_loss: 6.2307 - val_variance_output_loss: -14.1468\n",
            "Epoch 1578/5000\n",
            "2/2 [==============================] - 0s 62ms/step - loss: -2.9982 - mean_output_loss: 12.9236 - variance_output_loss: -15.9218 - val_loss: -7.9342 - val_mean_output_loss: 6.2126 - val_variance_output_loss: -14.1468\n",
            "Epoch 1579/5000\n",
            "2/2 [==============================] - 0s 76ms/step - loss: -2.8064 - mean_output_loss: 12.8933 - variance_output_loss: -15.6996 - val_loss: -7.9520 - val_mean_output_loss: 6.1948 - val_variance_output_loss: -14.1468\n",
            "Epoch 1580/5000\n",
            "2/2 [==============================] - 0s 49ms/step - loss: -2.6976 - mean_output_loss: 12.8616 - variance_output_loss: -15.5592 - val_loss: -7.9696 - val_mean_output_loss: 6.1772 - val_variance_output_loss: -14.1468\n",
            "Epoch 1581/5000\n",
            "2/2 [==============================] - 0s 61ms/step - loss: -2.3499 - mean_output_loss: 12.8350 - variance_output_loss: -15.1849 - val_loss: -7.9873 - val_mean_output_loss: 6.1595 - val_variance_output_loss: -14.1468\n",
            "Epoch 1582/5000\n",
            "2/2 [==============================] - 0s 51ms/step - loss: -2.4213 - mean_output_loss: 12.8089 - variance_output_loss: -15.2302 - val_loss: -8.0051 - val_mean_output_loss: 6.1417 - val_variance_output_loss: -14.1468\n",
            "Epoch 1583/5000\n",
            "2/2 [==============================] - 0s 60ms/step - loss: -0.8091 - mean_output_loss: 12.7755 - variance_output_loss: -13.5846 - val_loss: -8.0222 - val_mean_output_loss: 6.1246 - val_variance_output_loss: -14.1468\n",
            "Epoch 1584/5000\n",
            "2/2 [==============================] - 0s 53ms/step - loss: -3.1385 - mean_output_loss: 12.7478 - variance_output_loss: -15.8863 - val_loss: -8.0393 - val_mean_output_loss: 6.1075 - val_variance_output_loss: -14.1469\n",
            "Epoch 1585/5000\n",
            "2/2 [==============================] - 0s 67ms/step - loss: -2.7500 - mean_output_loss: 12.7198 - variance_output_loss: -15.4698 - val_loss: -8.0564 - val_mean_output_loss: 6.0905 - val_variance_output_loss: -14.1469\n",
            "Epoch 1586/5000\n",
            "2/2 [==============================] - 0s 60ms/step - loss: -1.2173 - mean_output_loss: 12.6901 - variance_output_loss: -13.9075 - val_loss: -8.0732 - val_mean_output_loss: 6.0737 - val_variance_output_loss: -14.1469\n",
            "Epoch 1587/5000\n",
            "2/2 [==============================] - 0s 53ms/step - loss: -1.7155 - mean_output_loss: 12.6639 - variance_output_loss: -14.3794 - val_loss: -8.0901 - val_mean_output_loss: 6.0568 - val_variance_output_loss: -14.1469\n",
            "Epoch 1588/5000\n",
            "2/2 [==============================] - 0s 60ms/step - loss: -2.4633 - mean_output_loss: 12.6337 - variance_output_loss: -15.0970 - val_loss: -8.1067 - val_mean_output_loss: 6.0402 - val_variance_output_loss: -14.1469\n",
            "Epoch 1589/5000\n",
            "2/2 [==============================] - 0s 45ms/step - loss: -1.1760 - mean_output_loss: 12.6061 - variance_output_loss: -13.7821 - val_loss: -8.1232 - val_mean_output_loss: 6.0237 - val_variance_output_loss: -14.1469\n",
            "Epoch 1590/5000\n",
            "2/2 [==============================] - 0s 45ms/step - loss: -1.9254 - mean_output_loss: 12.5786 - variance_output_loss: -14.5041 - val_loss: -8.1397 - val_mean_output_loss: 6.0072 - val_variance_output_loss: -14.1469\n",
            "Epoch 1591/5000\n",
            "2/2 [==============================] - 0s 60ms/step - loss: -2.2212 - mean_output_loss: 12.5542 - variance_output_loss: -14.7754 - val_loss: -8.1563 - val_mean_output_loss: 5.9906 - val_variance_output_loss: -14.1470\n",
            "Epoch 1592/5000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: -2.1791 - mean_output_loss: 12.5230 - variance_output_loss: -14.7021 - val_loss: -8.1724 - val_mean_output_loss: 5.9746 - val_variance_output_loss: -14.1470\n",
            "Epoch 1593/5000\n",
            "2/2 [==============================] - 0s 41ms/step - loss: -2.8669 - mean_output_loss: 12.4963 - variance_output_loss: -15.3632 - val_loss: -8.1884 - val_mean_output_loss: 5.9586 - val_variance_output_loss: -14.1470\n",
            "Epoch 1594/5000\n",
            "2/2 [==============================] - 0s 85ms/step - loss: -2.6711 - mean_output_loss: 12.4693 - variance_output_loss: -15.1404 - val_loss: -8.2044 - val_mean_output_loss: 5.9426 - val_variance_output_loss: -14.1470\n",
            "Epoch 1595/5000\n",
            "2/2 [==============================] - 0s 71ms/step - loss: -1.7411 - mean_output_loss: 12.4416 - variance_output_loss: -14.1827 - val_loss: -8.2201 - val_mean_output_loss: 5.9269 - val_variance_output_loss: -14.1470\n",
            "Epoch 1596/5000\n",
            "2/2 [==============================] - 0s 79ms/step - loss: -3.4429 - mean_output_loss: 12.4144 - variance_output_loss: -15.8573 - val_loss: -8.2357 - val_mean_output_loss: 5.9113 - val_variance_output_loss: -14.1470\n",
            "Epoch 1597/5000\n",
            "2/2 [==============================] - 0s 70ms/step - loss: -1.6845 - mean_output_loss: 12.3886 - variance_output_loss: -14.0731 - val_loss: -8.2513 - val_mean_output_loss: 5.8957 - val_variance_output_loss: -14.1471\n",
            "Epoch 1598/5000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: -3.0768 - mean_output_loss: 12.3601 - variance_output_loss: -15.4369 - val_loss: -8.2667 - val_mean_output_loss: 5.8804 - val_variance_output_loss: -14.1471\n",
            "Epoch 1599/5000\n",
            "2/2 [==============================] - 0s 67ms/step - loss: -2.8843 - mean_output_loss: 12.3348 - variance_output_loss: -15.2191 - val_loss: -8.2821 - val_mean_output_loss: 5.8650 - val_variance_output_loss: -14.1471\n",
            "Epoch 1600/5000\n",
            "2/2 [==============================] - 0s 48ms/step - loss: -1.8984 - mean_output_loss: 12.3081 - variance_output_loss: -14.2065 - val_loss: -8.2974 - val_mean_output_loss: 5.8497 - val_variance_output_loss: -14.1471\n",
            "Epoch 1601/5000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: -2.0593 - mean_output_loss: 12.2821 - variance_output_loss: -14.3414 - val_loss: -8.3125 - val_mean_output_loss: 5.8346 - val_variance_output_loss: -14.1471\n",
            "Epoch 1602/5000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: -2.7523 - mean_output_loss: 12.2551 - variance_output_loss: -15.0074 - val_loss: -8.3275 - val_mean_output_loss: 5.8196 - val_variance_output_loss: -14.1471\n",
            "Epoch 1603/5000\n",
            "2/2 [==============================] - 0s 62ms/step - loss: -4.7600 - mean_output_loss: 12.2291 - variance_output_loss: -16.9891 - val_loss: -8.3424 - val_mean_output_loss: 5.8047 - val_variance_output_loss: -14.1471\n",
            "Epoch 1604/5000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: -2.4976 - mean_output_loss: 12.2042 - variance_output_loss: -14.7017 - val_loss: -8.3573 - val_mean_output_loss: 5.7898 - val_variance_output_loss: -14.1472\n",
            "Epoch 1605/5000\n",
            "2/2 [==============================] - 0s 47ms/step - loss: -1.6792 - mean_output_loss: 12.1773 - variance_output_loss: -13.8565 - val_loss: -8.3719 - val_mean_output_loss: 5.7752 - val_variance_output_loss: -14.1472\n",
            "Epoch 1606/5000\n",
            "2/2 [==============================] - 0s 44ms/step - loss: -3.8841 - mean_output_loss: 12.1514 - variance_output_loss: -16.0355 - val_loss: -8.3865 - val_mean_output_loss: 5.7607 - val_variance_output_loss: -14.1472\n",
            "Epoch 1607/5000\n",
            "2/2 [==============================] - 0s 47ms/step - loss: -3.1360 - mean_output_loss: 12.1245 - variance_output_loss: -15.2605 - val_loss: -8.4008 - val_mean_output_loss: 5.7464 - val_variance_output_loss: -14.1472\n",
            "Epoch 1608/5000\n",
            "2/2 [==============================] - 0s 69ms/step - loss: -2.0253 - mean_output_loss: 12.1023 - variance_output_loss: -14.1276 - val_loss: -8.4153 - val_mean_output_loss: 5.7319 - val_variance_output_loss: -14.1472\n",
            "Epoch 1609/5000\n",
            "2/2 [==============================] - 0s 70ms/step - loss: -1.9521 - mean_output_loss: 12.0747 - variance_output_loss: -14.0267 - val_loss: -8.4295 - val_mean_output_loss: 5.7177 - val_variance_output_loss: -14.1472\n",
            "Epoch 1610/5000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: -4.0012 - mean_output_loss: 12.0504 - variance_output_loss: -16.0516 - val_loss: -8.4436 - val_mean_output_loss: 5.7036 - val_variance_output_loss: -14.1472\n",
            "Epoch 1611/5000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: -2.1020 - mean_output_loss: 12.0239 - variance_output_loss: -14.1259 - val_loss: -8.4575 - val_mean_output_loss: 5.6898 - val_variance_output_loss: -14.1473\n",
            "Epoch 1612/5000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: -3.1249 - mean_output_loss: 12.0012 - variance_output_loss: -15.1261 - val_loss: -8.4715 - val_mean_output_loss: 5.6758 - val_variance_output_loss: -14.1473\n",
            "Epoch 1613/5000\n",
            "2/2 [==============================] - 0s 40ms/step - loss: -2.6534 - mean_output_loss: 11.9746 - variance_output_loss: -14.6280 - val_loss: -8.4851 - val_mean_output_loss: 5.6621 - val_variance_output_loss: -14.1473\n",
            "Epoch 1614/5000\n",
            "2/2 [==============================] - 0s 71ms/step - loss: -3.1605 - mean_output_loss: 11.9494 - variance_output_loss: -15.1099 - val_loss: -8.4987 - val_mean_output_loss: 5.6486 - val_variance_output_loss: -14.1473\n",
            "Epoch 1615/5000\n",
            "2/2 [==============================] - 0s 60ms/step - loss: -5.0451 - mean_output_loss: 11.9267 - variance_output_loss: -16.9717 - val_loss: -8.5123 - val_mean_output_loss: 5.6351 - val_variance_output_loss: -14.1473\n",
            "Epoch 1616/5000\n",
            "2/2 [==============================] - 0s 60ms/step - loss: -2.3626 - mean_output_loss: 11.9005 - variance_output_loss: -14.2631 - val_loss: -8.5256 - val_mean_output_loss: 5.6218 - val_variance_output_loss: -14.1473\n",
            "Epoch 1617/5000\n",
            "2/2 [==============================] - 0s 50ms/step - loss: -3.0364 - mean_output_loss: 11.8767 - variance_output_loss: -14.9132 - val_loss: -8.5388 - val_mean_output_loss: 5.6085 - val_variance_output_loss: -14.1473\n",
            "Epoch 1618/5000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: -4.0173 - mean_output_loss: 11.8528 - variance_output_loss: -15.8701 - val_loss: -8.5520 - val_mean_output_loss: 5.5953 - val_variance_output_loss: -14.1474\n",
            "Epoch 1619/5000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: -3.4220 - mean_output_loss: 11.8290 - variance_output_loss: -15.2509 - val_loss: -8.5651 - val_mean_output_loss: 5.5822 - val_variance_output_loss: -14.1474\n",
            "Epoch 1620/5000\n",
            "2/2 [==============================] - 0s 45ms/step - loss: -3.8200 - mean_output_loss: 11.8048 - variance_output_loss: -15.6249 - val_loss: -8.5781 - val_mean_output_loss: 5.5693 - val_variance_output_loss: -14.1474\n",
            "Epoch 1621/5000\n",
            "2/2 [==============================] - 0s 40ms/step - loss: -1.4939 - mean_output_loss: 11.7815 - variance_output_loss: -13.2753 - val_loss: -8.5909 - val_mean_output_loss: 5.5565 - val_variance_output_loss: -14.1474\n",
            "Epoch 1622/5000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: -4.0633 - mean_output_loss: 11.7582 - variance_output_loss: -15.8215 - val_loss: -8.6037 - val_mean_output_loss: 5.5437 - val_variance_output_loss: -14.1474\n",
            "Epoch 1623/5000\n",
            "2/2 [==============================] - 0s 67ms/step - loss: -3.0803 - mean_output_loss: 11.7333 - variance_output_loss: -14.8137 - val_loss: -8.6162 - val_mean_output_loss: 5.5313 - val_variance_output_loss: -14.1474\n",
            "Epoch 1624/5000\n",
            "2/2 [==============================] - 0s 76ms/step - loss: -2.9891 - mean_output_loss: 11.7106 - variance_output_loss: -14.6997 - val_loss: -8.6286 - val_mean_output_loss: 5.5188 - val_variance_output_loss: -14.1474\n",
            "Epoch 1625/5000\n",
            "2/2 [==============================] - 0s 61ms/step - loss: -1.9751 - mean_output_loss: 11.6865 - variance_output_loss: -13.6617 - val_loss: -8.6409 - val_mean_output_loss: 5.5066 - val_variance_output_loss: -14.1475\n",
            "Epoch 1626/5000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: -2.7467 - mean_output_loss: 11.6643 - variance_output_loss: -14.4110 - val_loss: -8.6531 - val_mean_output_loss: 5.4944 - val_variance_output_loss: -14.1475\n",
            "Epoch 1627/5000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: -3.2913 - mean_output_loss: 11.6400 - variance_output_loss: -14.9312 - val_loss: -8.6651 - val_mean_output_loss: 5.4823 - val_variance_output_loss: -14.1475\n",
            "Epoch 1628/5000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: -2.9389 - mean_output_loss: 11.6184 - variance_output_loss: -14.5573 - val_loss: -8.6772 - val_mean_output_loss: 5.4703 - val_variance_output_loss: -14.1475\n",
            "Epoch 1629/5000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: -3.4525 - mean_output_loss: 11.5949 - variance_output_loss: -15.0474 - val_loss: -8.6892 - val_mean_output_loss: 5.4584 - val_variance_output_loss: -14.1475\n",
            "Epoch 1630/5000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: -3.7029 - mean_output_loss: 11.5715 - variance_output_loss: -15.2743 - val_loss: -8.7009 - val_mean_output_loss: 5.4466 - val_variance_output_loss: -14.1475\n",
            "Epoch 1631/5000\n",
            "2/2 [==============================] - 0s 38ms/step - loss: -3.7005 - mean_output_loss: 11.5501 - variance_output_loss: -15.2505 - val_loss: -8.7127 - val_mean_output_loss: 5.4348 - val_variance_output_loss: -14.1475\n",
            "Epoch 1632/5000\n",
            "2/2 [==============================] - 0s 43ms/step - loss: -2.2175 - mean_output_loss: 11.5285 - variance_output_loss: -13.7460 - val_loss: -8.7245 - val_mean_output_loss: 5.4230 - val_variance_output_loss: -14.1476\n",
            "Epoch 1633/5000\n",
            "2/2 [==============================] - 0s 60ms/step - loss: -3.1834 - mean_output_loss: 11.5044 - variance_output_loss: -14.6878 - val_loss: -8.7360 - val_mean_output_loss: 5.4116 - val_variance_output_loss: -14.1476\n",
            "Epoch 1634/5000\n",
            "2/2 [==============================] - 0s 45ms/step - loss: -4.0539 - mean_output_loss: 11.4829 - variance_output_loss: -15.5368 - val_loss: -8.7474 - val_mean_output_loss: 5.4002 - val_variance_output_loss: -14.1476\n",
            "Epoch 1635/5000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: -3.6975 - mean_output_loss: 11.4594 - variance_output_loss: -15.1569 - val_loss: -8.7586 - val_mean_output_loss: 5.3889 - val_variance_output_loss: -14.1476\n",
            "Epoch 1636/5000\n",
            "2/2 [==============================] - 0s 52ms/step - loss: -3.1602 - mean_output_loss: 11.4386 - variance_output_loss: -14.5988 - val_loss: -8.7699 - val_mean_output_loss: 5.3777 - val_variance_output_loss: -14.1476\n",
            "Epoch 1637/5000\n",
            "2/2 [==============================] - 0s 38ms/step - loss: -1.9744 - mean_output_loss: 11.4170 - variance_output_loss: -13.3914 - val_loss: -8.7811 - val_mean_output_loss: 5.3665 - val_variance_output_loss: -14.1476\n",
            "Epoch 1638/5000\n",
            "2/2 [==============================] - 0s 51ms/step - loss: -2.6639 - mean_output_loss: 11.3941 - variance_output_loss: -14.0580 - val_loss: -8.7920 - val_mean_output_loss: 5.3556 - val_variance_output_loss: -14.1476\n",
            "Epoch 1639/5000\n",
            "2/2 [==============================] - 0s 83ms/step - loss: -4.4443 - mean_output_loss: 11.3731 - variance_output_loss: -15.8174 - val_loss: -8.8030 - val_mean_output_loss: 5.3447 - val_variance_output_loss: -14.1477\n",
            "Epoch 1640/5000\n",
            "2/2 [==============================] - 0s 64ms/step - loss: -3.7357 - mean_output_loss: 11.3509 - variance_output_loss: -15.0865 - val_loss: -8.8137 - val_mean_output_loss: 5.3339 - val_variance_output_loss: -14.1477\n",
            "Epoch 1641/5000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: -4.2578 - mean_output_loss: 11.3323 - variance_output_loss: -15.5901 - val_loss: -8.8246 - val_mean_output_loss: 5.3231 - val_variance_output_loss: -14.1477\n",
            "Epoch 1642/5000\n",
            "2/2 [==============================] - 0s 46ms/step - loss: -3.8099 - mean_output_loss: 11.3075 - variance_output_loss: -15.1174 - val_loss: -8.8350 - val_mean_output_loss: 5.3127 - val_variance_output_loss: -14.1477\n",
            "Epoch 1643/5000\n",
            "2/2 [==============================] - 0s 40ms/step - loss: -4.2834 - mean_output_loss: 11.2867 - variance_output_loss: -15.5701 - val_loss: -8.8454 - val_mean_output_loss: 5.3023 - val_variance_output_loss: -14.1477\n",
            "Epoch 1644/5000\n",
            "2/2 [==============================] - 0s 70ms/step - loss: -2.8312 - mean_output_loss: 11.2652 - variance_output_loss: -14.0963 - val_loss: -8.8557 - val_mean_output_loss: 5.2920 - val_variance_output_loss: -14.1477\n",
            "Epoch 1645/5000\n",
            "2/2 [==============================] - 0s 49ms/step - loss: -4.4549 - mean_output_loss: 11.2457 - variance_output_loss: -15.7006 - val_loss: -8.8660 - val_mean_output_loss: 5.2817 - val_variance_output_loss: -14.1477\n",
            "Epoch 1646/5000\n",
            "2/2 [==============================] - 0s 39ms/step - loss: -5.4312 - mean_output_loss: 11.2235 - variance_output_loss: -16.6548 - val_loss: -8.8762 - val_mean_output_loss: 5.2716 - val_variance_output_loss: -14.1477\n",
            "Epoch 1647/5000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: -4.1477 - mean_output_loss: 11.2019 - variance_output_loss: -15.3496 - val_loss: -8.8862 - val_mean_output_loss: 5.2616 - val_variance_output_loss: -14.1478\n",
            "Epoch 1648/5000\n",
            "2/2 [==============================] - 0s 62ms/step - loss: -4.0118 - mean_output_loss: 11.1819 - variance_output_loss: -15.1937 - val_loss: -8.8962 - val_mean_output_loss: 5.2515 - val_variance_output_loss: -14.1478\n",
            "Epoch 1649/5000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: -4.0991 - mean_output_loss: 11.1642 - variance_output_loss: -15.2632 - val_loss: -8.9064 - val_mean_output_loss: 5.2414 - val_variance_output_loss: -14.1478\n",
            "Epoch 1650/5000\n",
            "2/2 [==============================] - 0s 46ms/step - loss: -3.8071 - mean_output_loss: 11.1406 - variance_output_loss: -14.9477 - val_loss: -8.9162 - val_mean_output_loss: 5.2316 - val_variance_output_loss: -14.1478\n",
            "Epoch 1651/5000\n",
            "2/2 [==============================] - 0s 39ms/step - loss: -4.1819 - mean_output_loss: 11.1209 - variance_output_loss: -15.3028 - val_loss: -8.9259 - val_mean_output_loss: 5.2219 - val_variance_output_loss: -14.1478\n",
            "Epoch 1652/5000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: -3.3374 - mean_output_loss: 11.1002 - variance_output_loss: -14.4376 - val_loss: -8.9355 - val_mean_output_loss: 5.2123 - val_variance_output_loss: -14.1478\n",
            "Epoch 1653/5000\n",
            "2/2 [==============================] - 0s 53ms/step - loss: -3.0264 - mean_output_loss: 11.0802 - variance_output_loss: -14.1066 - val_loss: -8.9450 - val_mean_output_loss: 5.2028 - val_variance_output_loss: -14.1478\n",
            "Epoch 1654/5000\n",
            "2/2 [==============================] - 0s 66ms/step - loss: -3.8026 - mean_output_loss: 11.0606 - variance_output_loss: -14.8631 - val_loss: -8.9544 - val_mean_output_loss: 5.1934 - val_variance_output_loss: -14.1479\n",
            "Epoch 1655/5000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: -4.1918 - mean_output_loss: 11.0407 - variance_output_loss: -15.2325 - val_loss: -8.9638 - val_mean_output_loss: 5.1841 - val_variance_output_loss: -14.1479\n",
            "Epoch 1656/5000\n",
            "2/2 [==============================] - 0s 69ms/step - loss: -4.7505 - mean_output_loss: 11.0217 - variance_output_loss: -15.7721 - val_loss: -8.9730 - val_mean_output_loss: 5.1749 - val_variance_output_loss: -14.1479\n",
            "Epoch 1657/5000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: -5.1578 - mean_output_loss: 11.0003 - variance_output_loss: -16.1580 - val_loss: -8.9819 - val_mean_output_loss: 5.1660 - val_variance_output_loss: -14.1479\n",
            "Epoch 1658/5000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: -3.9124 - mean_output_loss: 10.9820 - variance_output_loss: -14.8944 - val_loss: -8.9909 - val_mean_output_loss: 5.1570 - val_variance_output_loss: -14.1479\n",
            "Epoch 1659/5000\n",
            "2/2 [==============================] - 0s 38ms/step - loss: -3.0940 - mean_output_loss: 10.9616 - variance_output_loss: -14.0556 - val_loss: -8.9996 - val_mean_output_loss: 5.1483 - val_variance_output_loss: -14.1479\n",
            "Epoch 1660/5000\n",
            "2/2 [==============================] - 0s 37ms/step - loss: -4.0189 - mean_output_loss: 10.9417 - variance_output_loss: -14.9606 - val_loss: -9.0083 - val_mean_output_loss: 5.1397 - val_variance_output_loss: -14.1479\n",
            "Epoch 1661/5000\n",
            "2/2 [==============================] - 0s 44ms/step - loss: -5.9125 - mean_output_loss: 10.9219 - variance_output_loss: -16.8344 - val_loss: -9.0168 - val_mean_output_loss: 5.1311 - val_variance_output_loss: -14.1480\n",
            "Epoch 1662/5000\n",
            "2/2 [==============================] - 0s 62ms/step - loss: -4.1564 - mean_output_loss: 10.9052 - variance_output_loss: -15.0616 - val_loss: -9.0255 - val_mean_output_loss: 5.1225 - val_variance_output_loss: -14.1480\n",
            "Epoch 1663/5000\n",
            "2/2 [==============================] - 0s 65ms/step - loss: -3.5364 - mean_output_loss: 10.8871 - variance_output_loss: -14.4236 - val_loss: -9.0341 - val_mean_output_loss: 5.1139 - val_variance_output_loss: -14.1480\n",
            "Epoch 1664/5000\n",
            "2/2 [==============================] - 0s 61ms/step - loss: -4.0943 - mean_output_loss: 10.8662 - variance_output_loss: -14.9605 - val_loss: -9.0424 - val_mean_output_loss: 5.1056 - val_variance_output_loss: -14.1480\n",
            "Epoch 1665/5000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: -4.9059 - mean_output_loss: 10.8468 - variance_output_loss: -15.7527 - val_loss: -9.0506 - val_mean_output_loss: 5.0975 - val_variance_output_loss: -14.1480\n",
            "Epoch 1666/5000\n",
            "2/2 [==============================] - 0s 52ms/step - loss: -4.2977 - mean_output_loss: 10.8278 - variance_output_loss: -15.1255 - val_loss: -9.0587 - val_mean_output_loss: 5.0894 - val_variance_output_loss: -14.1480\n",
            "Epoch 1667/5000\n",
            "2/2 [==============================] - 0s 46ms/step - loss: -2.7947 - mean_output_loss: 10.8101 - variance_output_loss: -13.6047 - val_loss: -9.0668 - val_mean_output_loss: 5.0813 - val_variance_output_loss: -14.1480\n",
            "Epoch 1668/5000\n",
            "2/2 [==============================] - 0s 63ms/step - loss: -4.0471 - mean_output_loss: 10.7924 - variance_output_loss: -14.8395 - val_loss: -9.0748 - val_mean_output_loss: 5.0732 - val_variance_output_loss: -14.1481\n",
            "Epoch 1669/5000\n",
            "2/2 [==============================] - 0s 61ms/step - loss: -3.8083 - mean_output_loss: 10.7737 - variance_output_loss: -14.5821 - val_loss: -9.0828 - val_mean_output_loss: 5.0653 - val_variance_output_loss: -14.1481\n",
            "Epoch 1670/5000\n",
            "2/2 [==============================] - 0s 63ms/step - loss: -4.9374 - mean_output_loss: 10.7555 - variance_output_loss: -15.6929 - val_loss: -9.0906 - val_mean_output_loss: 5.0575 - val_variance_output_loss: -14.1481\n",
            "Epoch 1671/5000\n",
            "2/2 [==============================] - 0s 72ms/step - loss: -4.9909 - mean_output_loss: 10.7378 - variance_output_loss: -15.7288 - val_loss: -9.0983 - val_mean_output_loss: 5.0498 - val_variance_output_loss: -14.1481\n",
            "Epoch 1672/5000\n",
            "2/2 [==============================] - 0s 64ms/step - loss: -4.3509 - mean_output_loss: 10.7188 - variance_output_loss: -15.0698 - val_loss: -9.1059 - val_mean_output_loss: 5.0422 - val_variance_output_loss: -14.1481\n",
            "Epoch 1673/5000\n",
            "2/2 [==============================] - 0s 60ms/step - loss: -4.3525 - mean_output_loss: 10.7020 - variance_output_loss: -15.0545 - val_loss: -9.1134 - val_mean_output_loss: 5.0348 - val_variance_output_loss: -14.1481\n",
            "Epoch 1674/5000\n",
            "2/2 [==============================] - 0s 52ms/step - loss: -4.0290 - mean_output_loss: 10.6852 - variance_output_loss: -14.7142 - val_loss: -9.1208 - val_mean_output_loss: 5.0274 - val_variance_output_loss: -14.1481\n",
            "Epoch 1675/5000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: -4.8211 - mean_output_loss: 10.6658 - variance_output_loss: -15.4868 - val_loss: -9.1279 - val_mean_output_loss: 5.0202 - val_variance_output_loss: -14.1482\n",
            "Epoch 1676/5000\n",
            "2/2 [==============================] - 0s 66ms/step - loss: -5.6687 - mean_output_loss: 10.6477 - variance_output_loss: -16.3164 - val_loss: -9.1349 - val_mean_output_loss: 5.0132 - val_variance_output_loss: -14.1482\n",
            "Epoch 1677/5000\n",
            "2/2 [==============================] - 0s 66ms/step - loss: -5.0796 - mean_output_loss: 10.6309 - variance_output_loss: -15.7106 - val_loss: -9.1420 - val_mean_output_loss: 5.0062 - val_variance_output_loss: -14.1482\n",
            "Epoch 1678/5000\n",
            "2/2 [==============================] - 0s 97ms/step - loss: -4.8311 - mean_output_loss: 10.6150 - variance_output_loss: -15.4461 - val_loss: -9.1490 - val_mean_output_loss: 4.9992 - val_variance_output_loss: -14.1482\n",
            "Epoch 1679/5000\n",
            "2/2 [==============================] - 0s 67ms/step - loss: -3.2535 - mean_output_loss: 10.5987 - variance_output_loss: -13.8523 - val_loss: -9.1559 - val_mean_output_loss: 4.9923 - val_variance_output_loss: -14.1482\n",
            "Epoch 1680/5000\n",
            "2/2 [==============================] - 0s 97ms/step - loss: -4.5539 - mean_output_loss: 10.5822 - variance_output_loss: -15.1361 - val_loss: -9.1626 - val_mean_output_loss: 4.9856 - val_variance_output_loss: -14.1482\n",
            "Epoch 1681/5000\n",
            "2/2 [==============================] - 0s 61ms/step - loss: -4.8747 - mean_output_loss: 10.5635 - variance_output_loss: -15.4383 - val_loss: -9.1691 - val_mean_output_loss: 4.9791 - val_variance_output_loss: -14.1482\n",
            "Epoch 1682/5000\n",
            "2/2 [==============================] - 0s 90ms/step - loss: -3.8116 - mean_output_loss: 10.5469 - variance_output_loss: -14.3585 - val_loss: -9.1756 - val_mean_output_loss: 4.9727 - val_variance_output_loss: -14.1482\n",
            "Epoch 1683/5000\n",
            "2/2 [==============================] - 0s 95ms/step - loss: -4.8049 - mean_output_loss: 10.5300 - variance_output_loss: -15.3349 - val_loss: -9.1819 - val_mean_output_loss: 4.9664 - val_variance_output_loss: -14.1483\n",
            "Epoch 1684/5000\n",
            "2/2 [==============================] - 0s 77ms/step - loss: -5.4417 - mean_output_loss: 10.5142 - variance_output_loss: -15.9559 - val_loss: -9.1882 - val_mean_output_loss: 4.9601 - val_variance_output_loss: -14.1483\n",
            "Epoch 1685/5000\n",
            "2/2 [==============================] - 0s 84ms/step - loss: -3.6260 - mean_output_loss: 10.4983 - variance_output_loss: -14.1244 - val_loss: -9.1944 - val_mean_output_loss: 4.9538 - val_variance_output_loss: -14.1483\n",
            "Epoch 1686/5000\n",
            "2/2 [==============================] - 0s 74ms/step - loss: -5.7645 - mean_output_loss: 10.4825 - variance_output_loss: -16.2470 - val_loss: -9.2006 - val_mean_output_loss: 4.9477 - val_variance_output_loss: -14.1483\n",
            "Epoch 1687/5000\n",
            "2/2 [==============================] - 0s 97ms/step - loss: -4.1876 - mean_output_loss: 10.4657 - variance_output_loss: -14.6532 - val_loss: -9.2066 - val_mean_output_loss: 4.9417 - val_variance_output_loss: -14.1483\n",
            "Epoch 1688/5000\n",
            "2/2 [==============================] - 0s 64ms/step - loss: -4.1382 - mean_output_loss: 10.4485 - variance_output_loss: -14.5868 - val_loss: -9.2125 - val_mean_output_loss: 4.9358 - val_variance_output_loss: -14.1483\n",
            "Epoch 1689/5000\n",
            "2/2 [==============================] - 0s 69ms/step - loss: -5.5482 - mean_output_loss: 10.4345 - variance_output_loss: -15.9827 - val_loss: -9.2185 - val_mean_output_loss: 4.9299 - val_variance_output_loss: -14.1483\n",
            "Epoch 1690/5000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: -3.6086 - mean_output_loss: 10.4185 - variance_output_loss: -14.0271 - val_loss: -9.2243 - val_mean_output_loss: 4.9240 - val_variance_output_loss: -14.1484\n",
            "Epoch 1691/5000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: -5.1119 - mean_output_loss: 10.4031 - variance_output_loss: -15.5150 - val_loss: -9.2301 - val_mean_output_loss: 4.9183 - val_variance_output_loss: -14.1484\n",
            "Epoch 1692/5000\n",
            "2/2 [==============================] - 0s 67ms/step - loss: -4.6667 - mean_output_loss: 10.3869 - variance_output_loss: -15.0535 - val_loss: -9.2357 - val_mean_output_loss: 4.9127 - val_variance_output_loss: -14.1484\n",
            "Epoch 1693/5000\n",
            "2/2 [==============================] - 0s 74ms/step - loss: -5.7903 - mean_output_loss: 10.3705 - variance_output_loss: -16.1608 - val_loss: -9.2412 - val_mean_output_loss: 4.9072 - val_variance_output_loss: -14.1484\n",
            "Epoch 1694/5000\n",
            "2/2 [==============================] - 0s 102ms/step - loss: -4.1382 - mean_output_loss: 10.3574 - variance_output_loss: -14.4956 - val_loss: -9.2467 - val_mean_output_loss: 4.9017 - val_variance_output_loss: -14.1484\n",
            "Epoch 1695/5000\n",
            "2/2 [==============================] - 0s 53ms/step - loss: -3.7091 - mean_output_loss: 10.3421 - variance_output_loss: -14.0512 - val_loss: -9.2521 - val_mean_output_loss: 4.8964 - val_variance_output_loss: -14.1484\n",
            "Epoch 1696/5000\n",
            "2/2 [==============================] - 0s 50ms/step - loss: -4.9213 - mean_output_loss: 10.3251 - variance_output_loss: -15.2463 - val_loss: -9.2572 - val_mean_output_loss: 4.8912 - val_variance_output_loss: -14.1484\n",
            "Epoch 1697/5000\n",
            "2/2 [==============================] - 0s 64ms/step - loss: -4.9455 - mean_output_loss: 10.3112 - variance_output_loss: -15.2567 - val_loss: -9.2624 - val_mean_output_loss: 4.8861 - val_variance_output_loss: -14.1484\n",
            "Epoch 1698/5000\n",
            "2/2 [==============================] - 0s 72ms/step - loss: -5.2007 - mean_output_loss: 10.2958 - variance_output_loss: -15.4965 - val_loss: -9.2674 - val_mean_output_loss: 4.8810 - val_variance_output_loss: -14.1485\n",
            "Epoch 1699/5000\n",
            "2/2 [==============================] - 0s 65ms/step - loss: -4.1257 - mean_output_loss: 10.2810 - variance_output_loss: -14.4068 - val_loss: -9.2724 - val_mean_output_loss: 4.8761 - val_variance_output_loss: -14.1485\n",
            "Epoch 1700/5000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: -4.4653 - mean_output_loss: 10.2664 - variance_output_loss: -14.7317 - val_loss: -9.2772 - val_mean_output_loss: 4.8712 - val_variance_output_loss: -14.1485\n",
            "Epoch 1701/5000\n",
            "2/2 [==============================] - 0s 65ms/step - loss: -4.0998 - mean_output_loss: 10.2515 - variance_output_loss: -14.3513 - val_loss: -9.2820 - val_mean_output_loss: 4.8665 - val_variance_output_loss: -14.1485\n",
            "Epoch 1702/5000\n",
            "2/2 [==============================] - 0s 80ms/step - loss: -5.2784 - mean_output_loss: 10.2378 - variance_output_loss: -15.5161 - val_loss: -9.2868 - val_mean_output_loss: 4.8617 - val_variance_output_loss: -14.1485\n",
            "Epoch 1703/5000\n",
            "2/2 [==============================] - 0s 61ms/step - loss: -5.6851 - mean_output_loss: 10.2238 - variance_output_loss: -15.9090 - val_loss: -9.2915 - val_mean_output_loss: 4.8571 - val_variance_output_loss: -14.1485\n",
            "Epoch 1704/5000\n",
            "2/2 [==============================] - 0s 60ms/step - loss: -4.1249 - mean_output_loss: 10.2082 - variance_output_loss: -14.3330 - val_loss: -9.2960 - val_mean_output_loss: 4.8526 - val_variance_output_loss: -14.1485\n",
            "Epoch 1705/5000\n",
            "2/2 [==============================] - 0s 91ms/step - loss: -5.0197 - mean_output_loss: 10.1954 - variance_output_loss: -15.2151 - val_loss: -9.3005 - val_mean_output_loss: 4.8481 - val_variance_output_loss: -14.1486\n",
            "Epoch 1706/5000\n",
            "2/2 [==============================] - 0s 71ms/step - loss: -5.7975 - mean_output_loss: 10.1813 - variance_output_loss: -15.9788 - val_loss: -9.3049 - val_mean_output_loss: 4.8437 - val_variance_output_loss: -14.1486\n",
            "Epoch 1707/5000\n",
            "2/2 [==============================] - 0s 99ms/step - loss: -4.9978 - mean_output_loss: 10.1665 - variance_output_loss: -15.1643 - val_loss: -9.3092 - val_mean_output_loss: 4.8394 - val_variance_output_loss: -14.1486\n",
            "Epoch 1708/5000\n",
            "2/2 [==============================] - 0s 60ms/step - loss: -4.0091 - mean_output_loss: 10.1537 - variance_output_loss: -14.1628 - val_loss: -9.3134 - val_mean_output_loss: 4.8352 - val_variance_output_loss: -14.1486\n",
            "Epoch 1709/5000\n",
            "2/2 [==============================] - 0s 77ms/step - loss: -4.9880 - mean_output_loss: 10.1391 - variance_output_loss: -15.1271 - val_loss: -9.3175 - val_mean_output_loss: 4.8311 - val_variance_output_loss: -14.1486\n",
            "Epoch 1710/5000\n",
            "2/2 [==============================] - 0s 80ms/step - loss: -4.9223 - mean_output_loss: 10.1258 - variance_output_loss: -15.0481 - val_loss: -9.3216 - val_mean_output_loss: 4.8271 - val_variance_output_loss: -14.1486\n",
            "Epoch 1711/5000\n",
            "2/2 [==============================] - 0s 66ms/step - loss: -5.8381 - mean_output_loss: 10.1138 - variance_output_loss: -15.9519 - val_loss: -9.3256 - val_mean_output_loss: 4.8231 - val_variance_output_loss: -14.1486\n",
            "Epoch 1712/5000\n",
            "2/2 [==============================] - 0s 71ms/step - loss: -5.3336 - mean_output_loss: 10.0992 - variance_output_loss: -15.4328 - val_loss: -9.3294 - val_mean_output_loss: 4.8192 - val_variance_output_loss: -14.1486\n",
            "Epoch 1713/5000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: -6.3158 - mean_output_loss: 10.0851 - variance_output_loss: -16.4009 - val_loss: -9.3331 - val_mean_output_loss: 4.8155 - val_variance_output_loss: -14.1487\n",
            "Epoch 1714/5000\n",
            "2/2 [==============================] - 0s 82ms/step - loss: -4.9538 - mean_output_loss: 10.0731 - variance_output_loss: -15.0270 - val_loss: -9.3368 - val_mean_output_loss: 4.8118 - val_variance_output_loss: -14.1487\n",
            "Epoch 1715/5000\n",
            "2/2 [==============================] - 0s 87ms/step - loss: -4.6532 - mean_output_loss: 10.0604 - variance_output_loss: -14.7137 - val_loss: -9.3405 - val_mean_output_loss: 4.8082 - val_variance_output_loss: -14.1487\n",
            "Epoch 1716/5000\n",
            "2/2 [==============================] - 0s 61ms/step - loss: -5.5153 - mean_output_loss: 10.0464 - variance_output_loss: -15.5617 - val_loss: -9.3440 - val_mean_output_loss: 4.8047 - val_variance_output_loss: -14.1487\n",
            "Epoch 1717/5000\n",
            "2/2 [==============================] - 0s 73ms/step - loss: -4.2444 - mean_output_loss: 10.0344 - variance_output_loss: -14.2788 - val_loss: -9.3474 - val_mean_output_loss: 4.8013 - val_variance_output_loss: -14.1487\n",
            "Epoch 1718/5000\n",
            "2/2 [==============================] - 0s 80ms/step - loss: -6.0048 - mean_output_loss: 10.0218 - variance_output_loss: -16.0266 - val_loss: -9.3508 - val_mean_output_loss: 4.7979 - val_variance_output_loss: -14.1487\n",
            "Epoch 1719/5000\n",
            "2/2 [==============================] - 0s 88ms/step - loss: -5.5243 - mean_output_loss: 10.0106 - variance_output_loss: -15.5349 - val_loss: -9.3542 - val_mean_output_loss: 4.7945 - val_variance_output_loss: -14.1487\n",
            "Epoch 1720/5000\n",
            "2/2 [==============================] - 0s 74ms/step - loss: -5.3264 - mean_output_loss: 9.9960 - variance_output_loss: -15.3223 - val_loss: -9.3573 - val_mean_output_loss: 4.7914 - val_variance_output_loss: -14.1487\n",
            "Epoch 1721/5000\n",
            "2/2 [==============================] - 0s 77ms/step - loss: -5.0323 - mean_output_loss: 9.9849 - variance_output_loss: -15.0172 - val_loss: -9.3605 - val_mean_output_loss: 4.7883 - val_variance_output_loss: -14.1488\n",
            "Epoch 1722/5000\n",
            "2/2 [==============================] - 0s 64ms/step - loss: -3.5445 - mean_output_loss: 9.9724 - variance_output_loss: -13.5168 - val_loss: -9.3635 - val_mean_output_loss: 4.7852 - val_variance_output_loss: -14.1488\n",
            "Epoch 1723/5000\n",
            "2/2 [==============================] - 0s 47ms/step - loss: -5.4198 - mean_output_loss: 9.9598 - variance_output_loss: -15.3796 - val_loss: -9.3665 - val_mean_output_loss: 4.7823 - val_variance_output_loss: -14.1488\n",
            "Epoch 1724/5000\n",
            "2/2 [==============================] - 0s 43ms/step - loss: -5.4290 - mean_output_loss: 9.9484 - variance_output_loss: -15.3774 - val_loss: -9.3694 - val_mean_output_loss: 4.7794 - val_variance_output_loss: -14.1488\n",
            "Epoch 1725/5000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: -4.0114 - mean_output_loss: 9.9364 - variance_output_loss: -13.9478 - val_loss: -9.3722 - val_mean_output_loss: 4.7766 - val_variance_output_loss: -14.1488\n",
            "Epoch 1726/5000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: -5.2613 - mean_output_loss: 9.9252 - variance_output_loss: -15.1865 - val_loss: -9.3750 - val_mean_output_loss: 4.7738 - val_variance_output_loss: -14.1488\n",
            "Epoch 1727/5000\n",
            "2/2 [==============================] - 0s 60ms/step - loss: -5.5752 - mean_output_loss: 9.9138 - variance_output_loss: -15.4890 - val_loss: -9.3777 - val_mean_output_loss: 4.7711 - val_variance_output_loss: -14.1488\n",
            "Epoch 1728/5000\n",
            "2/2 [==============================] - 0s 60ms/step - loss: -4.0062 - mean_output_loss: 9.9020 - variance_output_loss: -13.9082 - val_loss: -9.3803 - val_mean_output_loss: 4.7685 - val_variance_output_loss: -14.1488\n",
            "Epoch 1729/5000\n",
            "2/2 [==============================] - 0s 45ms/step - loss: -5.1676 - mean_output_loss: 9.8904 - variance_output_loss: -15.0579 - val_loss: -9.3828 - val_mean_output_loss: 4.7660 - val_variance_output_loss: -14.1489\n",
            "Epoch 1730/5000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: -5.0007 - mean_output_loss: 9.8787 - variance_output_loss: -14.8794 - val_loss: -9.3852 - val_mean_output_loss: 4.7636 - val_variance_output_loss: -14.1489\n",
            "Epoch 1731/5000\n",
            "2/2 [==============================] - 0s 78ms/step - loss: -6.4212 - mean_output_loss: 9.8669 - variance_output_loss: -16.2881 - val_loss: -9.3876 - val_mean_output_loss: 4.7613 - val_variance_output_loss: -14.1489\n",
            "Epoch 1732/5000\n",
            "2/2 [==============================] - 0s 60ms/step - loss: -4.7252 - mean_output_loss: 9.8554 - variance_output_loss: -14.5806 - val_loss: -9.3899 - val_mean_output_loss: 4.7590 - val_variance_output_loss: -14.1489\n",
            "Epoch 1733/5000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: -5.0912 - mean_output_loss: 9.8468 - variance_output_loss: -14.9380 - val_loss: -9.3922 - val_mean_output_loss: 4.7567 - val_variance_output_loss: -14.1489\n",
            "Epoch 1734/5000\n",
            "2/2 [==============================] - 0s 62ms/step - loss: -5.5019 - mean_output_loss: 9.8343 - variance_output_loss: -15.3363 - val_loss: -9.3944 - val_mean_output_loss: 4.7546 - val_variance_output_loss: -14.1489\n",
            "Epoch 1735/5000\n",
            "2/2 [==============================] - 0s 61ms/step - loss: -4.5199 - mean_output_loss: 9.8239 - variance_output_loss: -14.3437 - val_loss: -9.3965 - val_mean_output_loss: 4.7525 - val_variance_output_loss: -14.1489\n",
            "Epoch 1736/5000\n",
            "2/2 [==============================] - 0s 41ms/step - loss: -6.2139 - mean_output_loss: 9.8129 - variance_output_loss: -16.0268 - val_loss: -9.3985 - val_mean_output_loss: 4.7504 - val_variance_output_loss: -14.1489\n",
            "Epoch 1737/5000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: -5.6328 - mean_output_loss: 9.8024 - variance_output_loss: -15.4352 - val_loss: -9.4005 - val_mean_output_loss: 4.7484 - val_variance_output_loss: -14.1490\n",
            "Epoch 1738/5000\n",
            "2/2 [==============================] - 0s 50ms/step - loss: -6.3202 - mean_output_loss: 9.7930 - variance_output_loss: -16.1132 - val_loss: -9.4025 - val_mean_output_loss: 4.7465 - val_variance_output_loss: -14.1490\n",
            "Epoch 1739/5000\n",
            "2/2 [==============================] - 0s 53ms/step - loss: -4.3789 - mean_output_loss: 9.7822 - variance_output_loss: -14.1611 - val_loss: -9.4043 - val_mean_output_loss: 4.7447 - val_variance_output_loss: -14.1490\n",
            "Epoch 1740/5000\n",
            "2/2 [==============================] - 0s 47ms/step - loss: -4.6078 - mean_output_loss: 9.7722 - variance_output_loss: -14.3801 - val_loss: -9.4061 - val_mean_output_loss: 4.7429 - val_variance_output_loss: -14.1490\n",
            "Epoch 1741/5000\n",
            "2/2 [==============================] - 0s 46ms/step - loss: -4.6235 - mean_output_loss: 9.7615 - variance_output_loss: -14.3850 - val_loss: -9.4078 - val_mean_output_loss: 4.7412 - val_variance_output_loss: -14.1490\n",
            "Epoch 1742/5000\n",
            "2/2 [==============================] - 0s 48ms/step - loss: -6.4058 - mean_output_loss: 9.7518 - variance_output_loss: -16.1577 - val_loss: -9.4094 - val_mean_output_loss: 4.7396 - val_variance_output_loss: -14.1490\n",
            "Epoch 1743/5000\n",
            "2/2 [==============================] - 0s 39ms/step - loss: -5.6579 - mean_output_loss: 9.7414 - variance_output_loss: -15.3993 - val_loss: -9.4109 - val_mean_output_loss: 4.7381 - val_variance_output_loss: -14.1490\n",
            "Epoch 1744/5000\n",
            "2/2 [==============================] - 0s 41ms/step - loss: -6.2740 - mean_output_loss: 9.7321 - variance_output_loss: -16.0061 - val_loss: -9.4124 - val_mean_output_loss: 4.7366 - val_variance_output_loss: -14.1490\n",
            "Epoch 1745/5000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: -5.2996 - mean_output_loss: 9.7218 - variance_output_loss: -15.0214 - val_loss: -9.4138 - val_mean_output_loss: 4.7352 - val_variance_output_loss: -14.1491\n",
            "Epoch 1746/5000\n",
            "2/2 [==============================] - 0s 68ms/step - loss: -7.0680 - mean_output_loss: 9.7129 - variance_output_loss: -16.7809 - val_loss: -9.4152 - val_mean_output_loss: 4.7339 - val_variance_output_loss: -14.1491\n",
            "Epoch 1747/5000\n",
            "2/2 [==============================] - 0s 61ms/step - loss: -5.4480 - mean_output_loss: 9.7019 - variance_output_loss: -15.1499 - val_loss: -9.4165 - val_mean_output_loss: 4.7326 - val_variance_output_loss: -14.1491\n",
            "Epoch 1748/5000\n",
            "2/2 [==============================] - 0s 60ms/step - loss: -4.4258 - mean_output_loss: 9.6934 - variance_output_loss: -14.1193 - val_loss: -9.4178 - val_mean_output_loss: 4.7313 - val_variance_output_loss: -14.1491\n",
            "Epoch 1749/5000\n",
            "2/2 [==============================] - 0s 39ms/step - loss: -4.7285 - mean_output_loss: 9.6847 - variance_output_loss: -14.4132 - val_loss: -9.4190 - val_mean_output_loss: 4.7301 - val_variance_output_loss: -14.1491\n",
            "Epoch 1750/5000\n",
            "2/2 [==============================] - 0s 51ms/step - loss: -5.0258 - mean_output_loss: 9.6755 - variance_output_loss: -14.7013 - val_loss: -9.4201 - val_mean_output_loss: 4.7290 - val_variance_output_loss: -14.1491\n",
            "Epoch 1751/5000\n",
            "2/2 [==============================] - 0s 47ms/step - loss: -4.7608 - mean_output_loss: 9.6668 - variance_output_loss: -14.4276 - val_loss: -9.4212 - val_mean_output_loss: 4.7279 - val_variance_output_loss: -14.1491\n",
            "Epoch 1752/5000\n",
            "2/2 [==============================] - 0s 64ms/step - loss: -5.6057 - mean_output_loss: 9.6563 - variance_output_loss: -15.2621 - val_loss: -9.4223 - val_mean_output_loss: 4.7269 - val_variance_output_loss: -14.1491\n",
            "Epoch 1753/5000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: -6.1568 - mean_output_loss: 9.6481 - variance_output_loss: -15.8049 - val_loss: -9.4233 - val_mean_output_loss: 4.7259 - val_variance_output_loss: -14.1491\n",
            "Epoch 1754/5000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: -5.3444 - mean_output_loss: 9.6386 - variance_output_loss: -14.9830 - val_loss: -9.4242 - val_mean_output_loss: 4.7250 - val_variance_output_loss: -14.1492\n",
            "Epoch 1755/5000\n",
            "2/2 [==============================] - 0s 47ms/step - loss: -5.0351 - mean_output_loss: 9.6298 - variance_output_loss: -14.6650 - val_loss: -9.4251 - val_mean_output_loss: 4.7241 - val_variance_output_loss: -14.1492\n",
            "Epoch 1756/5000\n",
            "2/2 [==============================] - 0s 62ms/step - loss: -6.1508 - mean_output_loss: 9.6227 - variance_output_loss: -15.7734 - val_loss: -9.4259 - val_mean_output_loss: 4.7233 - val_variance_output_loss: -14.1492\n",
            "Epoch 1757/5000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: -5.7527 - mean_output_loss: 9.6128 - variance_output_loss: -15.3654 - val_loss: -9.4267 - val_mean_output_loss: 4.7225 - val_variance_output_loss: -14.1492\n",
            "Epoch 1758/5000\n",
            "2/2 [==============================] - 0s 61ms/step - loss: -4.9500 - mean_output_loss: 9.6040 - variance_output_loss: -14.5540 - val_loss: -9.4274 - val_mean_output_loss: 4.7218 - val_variance_output_loss: -14.1492\n",
            "Epoch 1759/5000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: -6.8297 - mean_output_loss: 9.5951 - variance_output_loss: -16.4248 - val_loss: -9.4280 - val_mean_output_loss: 4.7212 - val_variance_output_loss: -14.1492\n",
            "Epoch 1760/5000\n",
            "2/2 [==============================] - 0s 60ms/step - loss: -4.9444 - mean_output_loss: 9.5871 - variance_output_loss: -14.5314 - val_loss: -9.4286 - val_mean_output_loss: 4.7206 - val_variance_output_loss: -14.1492\n",
            "Epoch 1761/5000\n",
            "2/2 [==============================] - 0s 49ms/step - loss: -6.6564 - mean_output_loss: 9.5797 - variance_output_loss: -16.2362 - val_loss: -9.4292 - val_mean_output_loss: 4.7200 - val_variance_output_loss: -14.1492\n",
            "Epoch 1762/5000\n",
            "2/2 [==============================] - 0s 74ms/step - loss: -4.4708 - mean_output_loss: 9.5712 - variance_output_loss: -14.0420 - val_loss: -9.4297 - val_mean_output_loss: 4.7195 - val_variance_output_loss: -14.1493\n",
            "Epoch 1763/5000\n",
            "2/2 [==============================] - 0s 64ms/step - loss: -6.1602 - mean_output_loss: 9.5624 - variance_output_loss: -15.7226 - val_loss: -9.4302 - val_mean_output_loss: 4.7191 - val_variance_output_loss: -14.1493\n",
            "Epoch 1764/5000\n",
            "2/2 [==============================] - 0s 46ms/step - loss: -6.4593 - mean_output_loss: 9.5555 - variance_output_loss: -16.0149 - val_loss: -9.4306 - val_mean_output_loss: 4.7187 - val_variance_output_loss: -14.1493\n",
            "Epoch 1765/5000\n",
            "2/2 [==============================] - 0s 61ms/step - loss: -5.7408 - mean_output_loss: 9.5464 - variance_output_loss: -15.2872 - val_loss: -9.4310 - val_mean_output_loss: 4.7183 - val_variance_output_loss: -14.1493\n",
            "Epoch 1766/5000\n",
            "2/2 [==============================] - 0s 49ms/step - loss: -6.6869 - mean_output_loss: 9.5389 - variance_output_loss: -16.2258 - val_loss: -9.4313 - val_mean_output_loss: 4.7180 - val_variance_output_loss: -14.1493\n",
            "Epoch 1767/5000\n",
            "2/2 [==============================] - 0s 60ms/step - loss: -5.8584 - mean_output_loss: 9.5318 - variance_output_loss: -15.3902 - val_loss: -9.4315 - val_mean_output_loss: 4.7178 - val_variance_output_loss: -14.1493\n",
            "Epoch 1768/5000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: -7.0086 - mean_output_loss: 9.5234 - variance_output_loss: -16.5320 - val_loss: -9.4318 - val_mean_output_loss: 4.7176 - val_variance_output_loss: -14.1493\n",
            "Epoch 1769/5000\n",
            "2/2 [==============================] - 0s 61ms/step - loss: -5.3909 - mean_output_loss: 9.5161 - variance_output_loss: -14.9071 - val_loss: -9.4319 - val_mean_output_loss: 4.7174 - val_variance_output_loss: -14.1493\n",
            "Epoch 1770/5000\n",
            "2/2 [==============================] - 0s 52ms/step - loss: -6.0440 - mean_output_loss: 9.5084 - variance_output_loss: -15.5524 - val_loss: -9.4321 - val_mean_output_loss: 4.7173 - val_variance_output_loss: -14.1493\n",
            "Epoch 1771/5000\n",
            "2/2 [==============================] - 0s 46ms/step - loss: -5.5815 - mean_output_loss: 9.5021 - variance_output_loss: -15.0836 - val_loss: -9.4322 - val_mean_output_loss: 4.7172 - val_variance_output_loss: -14.1494\n",
            "Epoch 1772/5000\n",
            "2/2 [==============================] - 0s 39ms/step - loss: -4.5369 - mean_output_loss: 9.4945 - variance_output_loss: -14.0314 - val_loss: -9.4322 - val_mean_output_loss: 4.7172 - val_variance_output_loss: -14.1494\n",
            "Epoch 1773/5000\n",
            "2/2 [==============================] - 0s 60ms/step - loss: -5.1731 - mean_output_loss: 9.4864 - variance_output_loss: -14.6594 - val_loss: -9.4322 - val_mean_output_loss: 4.7172 - val_variance_output_loss: -14.1494\n",
            "Epoch 1774/5000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: -5.4595 - mean_output_loss: 9.4799 - variance_output_loss: -14.9394 - val_loss: -9.4322 - val_mean_output_loss: 4.7172 - val_variance_output_loss: -14.1494\n",
            "Epoch 1775/5000\n",
            "2/2 [==============================] - 0s 44ms/step - loss: -4.0572 - mean_output_loss: 9.4726 - variance_output_loss: -13.5298 - val_loss: -9.4321 - val_mean_output_loss: 4.7173 - val_variance_output_loss: -14.1494\n",
            "Epoch 1776/5000\n",
            "2/2 [==============================] - 0s 48ms/step - loss: -5.0205 - mean_output_loss: 9.4657 - variance_output_loss: -14.4861 - val_loss: -9.4320 - val_mean_output_loss: 4.7175 - val_variance_output_loss: -14.1494\n",
            "Epoch 1777/5000\n",
            "2/2 [==============================] - 0s 75ms/step - loss: -5.2504 - mean_output_loss: 9.4594 - variance_output_loss: -14.7098 - val_loss: -9.4318 - val_mean_output_loss: 4.7176 - val_variance_output_loss: -14.1494\n",
            "Epoch 1778/5000\n",
            "2/2 [==============================] - 0s 69ms/step - loss: -5.7162 - mean_output_loss: 9.4530 - variance_output_loss: -15.1693 - val_loss: -9.4316 - val_mean_output_loss: 4.7178 - val_variance_output_loss: -14.1494\n",
            "Epoch 1779/5000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: -5.9293 - mean_output_loss: 9.4461 - variance_output_loss: -15.3753 - val_loss: -9.4314 - val_mean_output_loss: 4.7181 - val_variance_output_loss: -14.1495\n",
            "Epoch 1780/5000\n",
            "2/2 [==============================] - 0s 66ms/step - loss: -4.4492 - mean_output_loss: 9.4383 - variance_output_loss: -13.8875 - val_loss: -9.4311 - val_mean_output_loss: 4.7183 - val_variance_output_loss: -14.1495\n",
            "Epoch 1781/5000\n",
            "2/2 [==============================] - 0s 65ms/step - loss: -5.2474 - mean_output_loss: 9.4323 - variance_output_loss: -14.6797 - val_loss: -9.4308 - val_mean_output_loss: 4.7187 - val_variance_output_loss: -14.1495\n",
            "Epoch 1782/5000\n",
            "2/2 [==============================] - 0s 48ms/step - loss: -5.2548 - mean_output_loss: 9.4258 - variance_output_loss: -14.6807 - val_loss: -9.4305 - val_mean_output_loss: 4.7190 - val_variance_output_loss: -14.1495\n",
            "Epoch 1783/5000\n",
            "2/2 [==============================] - 0s 61ms/step - loss: -5.7274 - mean_output_loss: 9.4191 - variance_output_loss: -15.1464 - val_loss: -9.4301 - val_mean_output_loss: 4.7194 - val_variance_output_loss: -14.1495\n",
            "Epoch 1784/5000\n",
            "2/2 [==============================] - 0s 64ms/step - loss: -4.7655 - mean_output_loss: 9.4121 - variance_output_loss: -14.1776 - val_loss: -9.4297 - val_mean_output_loss: 4.7198 - val_variance_output_loss: -14.1495\n",
            "Epoch 1785/5000\n",
            "2/2 [==============================] - 0s 62ms/step - loss: -5.2662 - mean_output_loss: 9.4074 - variance_output_loss: -14.6736 - val_loss: -9.4292 - val_mean_output_loss: 4.7203 - val_variance_output_loss: -14.1495\n",
            "Epoch 1786/5000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: -5.6734 - mean_output_loss: 9.4003 - variance_output_loss: -15.0737 - val_loss: -9.4287 - val_mean_output_loss: 4.7208 - val_variance_output_loss: -14.1495\n",
            "Epoch 1787/5000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: -5.5242 - mean_output_loss: 9.3948 - variance_output_loss: -14.9190 - val_loss: -9.4282 - val_mean_output_loss: 4.7213 - val_variance_output_loss: -14.1495\n",
            "Epoch 1788/5000\n",
            "2/2 [==============================] - 0s 39ms/step - loss: -5.7740 - mean_output_loss: 9.3871 - variance_output_loss: -15.1611 - val_loss: -9.4277 - val_mean_output_loss: 4.7219 - val_variance_output_loss: -14.1496\n",
            "Epoch 1789/5000\n",
            "2/2 [==============================] - 0s 63ms/step - loss: -6.0843 - mean_output_loss: 9.3813 - variance_output_loss: -15.4656 - val_loss: -9.4271 - val_mean_output_loss: 4.7225 - val_variance_output_loss: -14.1496\n",
            "Epoch 1790/5000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: -4.1458 - mean_output_loss: 9.3765 - variance_output_loss: -13.5224 - val_loss: -9.4264 - val_mean_output_loss: 4.7231 - val_variance_output_loss: -14.1496\n",
            "Epoch 1791/5000\n",
            "2/2 [==============================] - 0s 62ms/step - loss: -6.0053 - mean_output_loss: 9.3696 - variance_output_loss: -15.3749 - val_loss: -9.4258 - val_mean_output_loss: 4.7238 - val_variance_output_loss: -14.1496\n",
            "Epoch 1792/5000\n",
            "2/2 [==============================] - 0s 61ms/step - loss: -4.9852 - mean_output_loss: 9.3637 - variance_output_loss: -14.3489 - val_loss: -9.4251 - val_mean_output_loss: 4.7245 - val_variance_output_loss: -14.1496\n",
            "Epoch 1793/5000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: -7.3127 - mean_output_loss: 9.3574 - variance_output_loss: -16.6702 - val_loss: -9.4244 - val_mean_output_loss: 4.7252 - val_variance_output_loss: -14.1496\n",
            "Epoch 1794/5000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: -6.1088 - mean_output_loss: 9.3518 - variance_output_loss: -15.4606 - val_loss: -9.4236 - val_mean_output_loss: 4.7260 - val_variance_output_loss: -14.1496\n",
            "Epoch 1795/5000\n",
            "2/2 [==============================] - 0s 61ms/step - loss: -7.3004 - mean_output_loss: 9.3464 - variance_output_loss: -16.6468 - val_loss: -9.4228 - val_mean_output_loss: 4.7268 - val_variance_output_loss: -14.1496\n",
            "Epoch 1796/5000\n",
            "2/2 [==============================] - 0s 46ms/step - loss: -7.0499 - mean_output_loss: 9.3405 - variance_output_loss: -16.3904 - val_loss: -9.4220 - val_mean_output_loss: 4.7277 - val_variance_output_loss: -14.1496\n",
            "Epoch 1797/5000\n",
            "2/2 [==============================] - 0s 48ms/step - loss: -6.0175 - mean_output_loss: 9.3353 - variance_output_loss: -15.3528 - val_loss: -9.4211 - val_mean_output_loss: 4.7285 - val_variance_output_loss: -14.1496\n",
            "Epoch 1798/5000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: -5.1849 - mean_output_loss: 9.3301 - variance_output_loss: -14.5150 - val_loss: -9.4202 - val_mean_output_loss: 4.7294 - val_variance_output_loss: -14.1497\n",
            "Epoch 1799/5000\n",
            "2/2 [==============================] - 0s 60ms/step - loss: -5.8910 - mean_output_loss: 9.3227 - variance_output_loss: -15.2138 - val_loss: -9.4194 - val_mean_output_loss: 4.7303 - val_variance_output_loss: -14.1497\n",
            "Epoch 1800/5000\n",
            "2/2 [==============================] - 0s 40ms/step - loss: -6.0257 - mean_output_loss: 9.3174 - variance_output_loss: -15.3430 - val_loss: -9.4184 - val_mean_output_loss: 4.7312 - val_variance_output_loss: -14.1497\n",
            "Epoch 1801/5000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: -5.6677 - mean_output_loss: 9.3136 - variance_output_loss: -14.9813 - val_loss: -9.4174 - val_mean_output_loss: 4.7322 - val_variance_output_loss: -14.1497\n",
            "Epoch 1802/5000\n",
            "2/2 [==============================] - 0s 41ms/step - loss: -5.8873 - mean_output_loss: 9.3072 - variance_output_loss: -15.1945 - val_loss: -9.4165 - val_mean_output_loss: 4.7332 - val_variance_output_loss: -14.1497\n",
            "Epoch 1803/5000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: -5.5768 - mean_output_loss: 9.3029 - variance_output_loss: -14.8796 - val_loss: -9.4154 - val_mean_output_loss: 4.7343 - val_variance_output_loss: -14.1497\n",
            "Epoch 1804/5000\n",
            "2/2 [==============================] - 0s 60ms/step - loss: -5.7304 - mean_output_loss: 9.2977 - variance_output_loss: -15.0280 - val_loss: -9.4144 - val_mean_output_loss: 4.7354 - val_variance_output_loss: -14.1497\n",
            "Epoch 1805/5000\n",
            "2/2 [==============================] - 0s 51ms/step - loss: -6.2621 - mean_output_loss: 9.2914 - variance_output_loss: -15.5535 - val_loss: -9.4133 - val_mean_output_loss: 4.7364 - val_variance_output_loss: -14.1497\n",
            "Epoch 1806/5000\n",
            "2/2 [==============================] - 0s 77ms/step - loss: -5.6766 - mean_output_loss: 9.2873 - variance_output_loss: -14.9638 - val_loss: -9.4122 - val_mean_output_loss: 4.7375 - val_variance_output_loss: -14.1497\n",
            "Epoch 1807/5000\n",
            "2/2 [==============================] - 0s 81ms/step - loss: -5.2057 - mean_output_loss: 9.2832 - variance_output_loss: -14.4889 - val_loss: -9.4111 - val_mean_output_loss: 4.7387 - val_variance_output_loss: -14.1498\n",
            "Epoch 1808/5000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: -6.0031 - mean_output_loss: 9.2775 - variance_output_loss: -15.2806 - val_loss: -9.4100 - val_mean_output_loss: 4.7398 - val_variance_output_loss: -14.1498\n",
            "Epoch 1809/5000\n",
            "2/2 [==============================] - 0s 50ms/step - loss: -5.9293 - mean_output_loss: 9.2724 - variance_output_loss: -15.2017 - val_loss: -9.4089 - val_mean_output_loss: 4.7409 - val_variance_output_loss: -14.1498\n",
            "Epoch 1810/5000\n",
            "2/2 [==============================] - 0s 43ms/step - loss: -6.0973 - mean_output_loss: 9.2672 - variance_output_loss: -15.3645 - val_loss: -9.4077 - val_mean_output_loss: 4.7420 - val_variance_output_loss: -14.1498\n",
            "Epoch 1811/5000\n",
            "2/2 [==============================] - 0s 61ms/step - loss: -6.1028 - mean_output_loss: 9.2637 - variance_output_loss: -15.3665 - val_loss: -9.4066 - val_mean_output_loss: 4.7432 - val_variance_output_loss: -14.1498\n",
            "Epoch 1812/5000\n",
            "2/2 [==============================] - 0s 64ms/step - loss: -4.9625 - mean_output_loss: 9.2579 - variance_output_loss: -14.2204 - val_loss: -9.4054 - val_mean_output_loss: 4.7444 - val_variance_output_loss: -14.1498\n",
            "Epoch 1813/5000\n",
            "2/2 [==============================] - 0s 48ms/step - loss: -6.0135 - mean_output_loss: 9.2536 - variance_output_loss: -15.2672 - val_loss: -9.4042 - val_mean_output_loss: 4.7456 - val_variance_output_loss: -14.1498\n",
            "Epoch 1814/5000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: -5.9000 - mean_output_loss: 9.2486 - variance_output_loss: -15.1486 - val_loss: -9.4030 - val_mean_output_loss: 4.7468 - val_variance_output_loss: -14.1498\n",
            "Epoch 1815/5000\n",
            "2/2 [==============================] - 0s 53ms/step - loss: -6.3569 - mean_output_loss: 9.2448 - variance_output_loss: -15.6017 - val_loss: -9.4017 - val_mean_output_loss: 4.7481 - val_variance_output_loss: -14.1498\n",
            "Epoch 1816/5000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: -5.2780 - mean_output_loss: 9.2410 - variance_output_loss: -14.5190 - val_loss: -9.4004 - val_mean_output_loss: 4.7495 - val_variance_output_loss: -14.1498\n",
            "Epoch 1817/5000\n",
            "2/2 [==============================] - 0s 50ms/step - loss: -5.9354 - mean_output_loss: 9.2360 - variance_output_loss: -15.1714 - val_loss: -9.3991 - val_mean_output_loss: 4.7508 - val_variance_output_loss: -14.1499\n",
            "Epoch 1818/5000\n",
            "2/2 [==============================] - 0s 46ms/step - loss: -6.2232 - mean_output_loss: 9.2318 - variance_output_loss: -15.4550 - val_loss: -9.3978 - val_mean_output_loss: 4.7521 - val_variance_output_loss: -14.1499\n",
            "Epoch 1819/5000\n",
            "2/2 [==============================] - 0s 39ms/step - loss: -6.2121 - mean_output_loss: 9.2272 - variance_output_loss: -15.4393 - val_loss: -9.3964 - val_mean_output_loss: 4.7535 - val_variance_output_loss: -14.1499\n",
            "Epoch 1820/5000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: -5.7097 - mean_output_loss: 9.2226 - variance_output_loss: -14.9323 - val_loss: -9.3951 - val_mean_output_loss: 4.7548 - val_variance_output_loss: -14.1499\n",
            "Epoch 1821/5000\n",
            "2/2 [==============================] - 0s 62ms/step - loss: -6.0398 - mean_output_loss: 9.2185 - variance_output_loss: -15.2583 - val_loss: -9.3937 - val_mean_output_loss: 4.7562 - val_variance_output_loss: -14.1499\n",
            "Epoch 1822/5000\n",
            "2/2 [==============================] - 0s 62ms/step - loss: -5.9745 - mean_output_loss: 9.2138 - variance_output_loss: -15.1883 - val_loss: -9.3923 - val_mean_output_loss: 4.7576 - val_variance_output_loss: -14.1499\n",
            "Epoch 1823/5000\n",
            "2/2 [==============================] - 0s 64ms/step - loss: -6.8497 - mean_output_loss: 9.2099 - variance_output_loss: -16.0596 - val_loss: -9.3909 - val_mean_output_loss: 4.7590 - val_variance_output_loss: -14.1499\n",
            "Epoch 1824/5000\n",
            "2/2 [==============================] - 0s 52ms/step - loss: -5.3965 - mean_output_loss: 9.2064 - variance_output_loss: -14.6028 - val_loss: -9.3894 - val_mean_output_loss: 4.7606 - val_variance_output_loss: -14.1499\n",
            "Epoch 1825/5000\n",
            "2/2 [==============================] - 0s 53ms/step - loss: -3.8204 - mean_output_loss: 9.2015 - variance_output_loss: -13.0219 - val_loss: -9.3879 - val_mean_output_loss: 4.7620 - val_variance_output_loss: -14.1499\n",
            "Epoch 1826/5000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: -5.3327 - mean_output_loss: 9.1983 - variance_output_loss: -14.5310 - val_loss: -9.3863 - val_mean_output_loss: 4.7636 - val_variance_output_loss: -14.1500\n",
            "Epoch 1827/5000\n",
            "2/2 [==============================] - 0s 69ms/step - loss: -5.2400 - mean_output_loss: 9.1948 - variance_output_loss: -14.4349 - val_loss: -9.3847 - val_mean_output_loss: 4.7652 - val_variance_output_loss: -14.1500\n",
            "Epoch 1828/5000\n",
            "2/2 [==============================] - 0s 45ms/step - loss: -5.8593 - mean_output_loss: 9.1897 - variance_output_loss: -15.0490 - val_loss: -9.3832 - val_mean_output_loss: 4.7668 - val_variance_output_loss: -14.1500\n",
            "Epoch 1829/5000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: -5.2166 - mean_output_loss: 9.1859 - variance_output_loss: -14.4025 - val_loss: -9.3817 - val_mean_output_loss: 4.7683 - val_variance_output_loss: -14.1500\n",
            "Epoch 1830/5000\n",
            "2/2 [==============================] - 0s 52ms/step - loss: -5.7507 - mean_output_loss: 9.1820 - variance_output_loss: -14.9327 - val_loss: -9.3801 - val_mean_output_loss: 4.7699 - val_variance_output_loss: -14.1500\n",
            "Epoch 1831/5000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: -5.3301 - mean_output_loss: 9.1773 - variance_output_loss: -14.5074 - val_loss: -9.3786 - val_mean_output_loss: 4.7714 - val_variance_output_loss: -14.1500\n",
            "Epoch 1832/5000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: -6.4234 - mean_output_loss: 9.1736 - variance_output_loss: -15.5970 - val_loss: -9.3770 - val_mean_output_loss: 4.7730 - val_variance_output_loss: -14.1500\n",
            "Epoch 1833/5000\n",
            "2/2 [==============================] - 0s 61ms/step - loss: -5.6684 - mean_output_loss: 9.1706 - variance_output_loss: -14.8389 - val_loss: -9.3753 - val_mean_output_loss: 4.7747 - val_variance_output_loss: -14.1500\n",
            "Epoch 1834/5000\n",
            "2/2 [==============================] - 0s 46ms/step - loss: -6.5149 - mean_output_loss: 9.1670 - variance_output_loss: -15.6818 - val_loss: -9.3737 - val_mean_output_loss: 4.7764 - val_variance_output_loss: -14.1500\n",
            "Epoch 1835/5000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: -7.2813 - mean_output_loss: 9.1638 - variance_output_loss: -16.4451 - val_loss: -9.3719 - val_mean_output_loss: 4.7781 - val_variance_output_loss: -14.1500\n",
            "Epoch 1836/5000\n",
            "2/2 [==============================] - 0s 68ms/step - loss: -6.1289 - mean_output_loss: 9.1598 - variance_output_loss: -15.2887 - val_loss: -9.3702 - val_mean_output_loss: 4.7798 - val_variance_output_loss: -14.1501\n",
            "Epoch 1837/5000\n",
            "2/2 [==============================] - 0s 83ms/step - loss: -6.1722 - mean_output_loss: 9.1548 - variance_output_loss: -15.3269 - val_loss: -9.3687 - val_mean_output_loss: 4.7814 - val_variance_output_loss: -14.1501\n",
            "Epoch 1838/5000\n",
            "2/2 [==============================] - 0s 41ms/step - loss: -5.3836 - mean_output_loss: 9.1527 - variance_output_loss: -14.5363 - val_loss: -9.3669 - val_mean_output_loss: 4.7831 - val_variance_output_loss: -14.1501\n",
            "Epoch 1839/5000\n",
            "2/2 [==============================] - 0s 62ms/step - loss: -5.8104 - mean_output_loss: 9.1485 - variance_output_loss: -14.9589 - val_loss: -9.3652 - val_mean_output_loss: 4.7848 - val_variance_output_loss: -14.1501\n",
            "Epoch 1840/5000\n",
            "2/2 [==============================] - 0s 64ms/step - loss: -5.8677 - mean_output_loss: 9.1456 - variance_output_loss: -15.0133 - val_loss: -9.3635 - val_mean_output_loss: 4.7866 - val_variance_output_loss: -14.1501\n",
            "Epoch 1841/5000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: -5.6889 - mean_output_loss: 9.3637 - variance_output_loss: -15.0526"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-149-5ee63712f32d>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mhistory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_nn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_layers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mrender_plot_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-148-1f9e58d91878>\u001b[0m in \u001b[0;36mtrain_nn\u001b[0;34m(X, Y, hidden_layers, epochs, batch_size)\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'mean_output'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'mse'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'variance_output'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mkl_divergence_loss\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m     \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1727\u001b[0m                             \u001b[0msteps_per_execution\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_steps_per_execution\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1728\u001b[0m                         )\n\u001b[0;32m-> 1729\u001b[0;31m                     val_logs = self.evaluate(\n\u001b[0m\u001b[1;32m   1730\u001b[0m                         \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1731\u001b[0m                         \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m   2062\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_test_counter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2063\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2064\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menumerate_epochs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Single epoch.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2065\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2066\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_stop_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36menumerate_epochs\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1303\u001b[0m         \u001b[0;34m\"\"\"Yields `(epoch, tf.data.Iterator)`.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_truncate_execution_to_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1305\u001b[0;31m             \u001b[0mdata_iterator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1306\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initial_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1307\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_insufficient_data\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Set by `catch_stop_iteration`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    503\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minside_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolocate_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variant_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 505\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0miterator_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOwnedIterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    506\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    507\u001b[0m       raise RuntimeError(\"`tf.data.Dataset` only supports Python-style \"\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dataset, components, element_spec)\u001b[0m\n\u001b[1;32m    711\u001b[0m             \u001b[0;34m\"When `dataset` is provided, `element_spec` and `components` must \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    712\u001b[0m             \"not be specified.\")\n\u001b[0;32m--> 713\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_next_call_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m_create_iterator\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    750\u001b[0m             self._flat_output_types)\n\u001b[1;32m    751\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator_resource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_set_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfulltype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 752\u001b[0;31m       \u001b[0mgen_dataset_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_variant\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator_resource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    753\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    754\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/gen_dataset_ops.py\u001b[0m in \u001b[0;36mmake_iterator\u001b[0;34m(dataset, iterator, name)\u001b[0m\n\u001b[1;32m   3406\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mtld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3407\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3408\u001b[0;31m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0m\u001b[1;32m   3409\u001b[0m         _ctx, \"MakeIterator\", name, dataset, iterator)\n\u001b[1;32m   3410\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(x=X_test, y=Y_test)\n",
        "print(X_test)\n",
        "print(Y_test)\n",
        "predictions = model.predict(X_test)\n",
        "print(predictions)"
      ],
      "metadata": {
        "id": "oLCwyNCPMkVr",
        "outputId": "5d19705e-805a-442b-fb8e-1223df08e2ab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 8ms/step - loss: -6.4923 - mean_output_loss: 9.3560 - variance_output_loss: -15.8484\n",
            "     month_of_year        rh       temp       vpd  atmosphere_oxygen_ratio  \\\n",
            "85               1  0.827577  26.186667  0.602667                -4.758965   \n",
            "42               6  0.727107  24.515000  0.911667                -2.424168   \n",
            "43               7  0.698422  25.745000  1.082000                -1.333719   \n",
            "40               4  0.814435  25.093333  0.617333                -5.834663   \n",
            "75               3  0.838914  24.296667  0.515333                -7.677537   \n",
            "93               9  0.759181  27.686667  0.927667                -2.068940   \n",
            "21               9  0.810539  26.473333  0.681333                -2.441832   \n",
            "133              1  0.852663  25.540000  0.498333                -4.644259   \n",
            "103              7  0.752574  26.878333  0.913333                -0.682668   \n",
            "141              9  0.758108  27.191667  0.916667                -1.753848   \n",
            "125              5  0.769429  26.861667  0.850333                -3.380640   \n",
            "112              4  0.830732  26.568333  0.607000                -6.134641   \n",
            "26               2  0.850127  26.595000  0.539000                -6.334692   \n",
            "121              1  0.820702  26.455000  0.636667                -4.905178   \n",
            "105              9  0.694944  28.060000  1.211667                -2.032881   \n",
            "99               3  0.769637  26.913333  0.847000                -6.613016   \n",
            "161              5  0.625833  22.835000  1.168000                -2.644745   \n",
            "30               6  0.819814  26.020000  0.630000                -2.648644   \n",
            "80               8  0.666968  24.613333  1.123667                -0.518511   \n",
            "65               5  0.797164  26.661667  0.738333                -4.105834   \n",
            "149              5  0.826857  25.041667  0.569667                -2.936041   \n",
            "145              1  0.841374  24.670000  0.509000                -4.232430   \n",
            "6                6  0.796810  25.356667  0.690333                -2.751603   \n",
            "31               7  0.790010  26.791667  0.772667                -0.863672   \n",
            "163              7  0.529665  24.635000  1.663667                -1.190379   \n",
            "34              10  0.840399  26.850000  0.586000                -3.463705   \n",
            "114              6  0.780549  26.553333  0.792667                -2.115060   \n",
            "41               5  0.787177  24.531667  0.698333                -4.104644   \n",
            "174              6  0.791283  26.225000  0.744667                -1.360722   \n",
            "70              10  0.795810  27.551667  0.781667                -3.544452   \n",
            "7                7  0.769625  26.126667  0.820667                -0.875347   \n",
            "97               1  0.746646  26.925000  0.936667                -4.274483   \n",
            "78               6  0.633419  22.421667  1.112333                -2.424748   \n",
            "69               9  0.791118  27.663333  0.807000                -2.512503   \n",
            "77               5  0.741922  22.328333  0.757667                -3.690761   \n",
            "94              10  0.776026  27.300000  0.840667                -3.202030   \n",
            "10              10  0.794421  26.785000  0.757667                -3.578487   \n",
            "177              9  0.753228  27.093333  0.928667                -1.228098   \n",
            "49               1  0.864052  25.578333  0.460333                -7.483854   \n",
            "8                8  0.767621  26.583333  0.849000                -1.542072   \n",
            "123              3  0.814920  26.890000  0.674667                -6.555357   \n",
            "82              10  0.789205  24.828333  0.698333                -4.718137   \n",
            "54               6  0.748647  24.561667  0.838000                -2.414974   \n",
            "120              0  0.806711  26.705000  0.696333                -3.958005   \n",
            "107             11  0.734711  27.221667  1.000667                -2.798178   \n",
            "\n",
            "           lon        lat  \n",
            "85  -59.995140  -2.547137  \n",
            "42  -63.025632  -9.436920  \n",
            "43  -63.018074  -9.505025  \n",
            "40  -62.934779  -9.598616  \n",
            "75  -59.966899 -12.468335  \n",
            "93  -60.027490  -2.524020  \n",
            "21  -67.592372  -0.027301  \n",
            "133 -55.043354  -3.525768  \n",
            "103 -59.966063   0.995775  \n",
            "141 -54.980800  -3.556273  \n",
            "125 -57.523347  -4.085968  \n",
            "112 -59.012702  -2.549761  \n",
            "26  -66.059611  -4.549419  \n",
            "121 -57.473998  -4.020216  \n",
            "105 -60.074334   0.971600  \n",
            "99  -60.031094   1.021257  \n",
            "161 -52.524792 -13.062139  \n",
            "30  -65.973084  -4.394504  \n",
            "80  -59.945452 -12.556665  \n",
            "65  -62.058384  -5.932647  \n",
            "149 -54.010771  -0.874067  \n",
            "145 -54.101554  -0.952342  \n",
            "6   -70.017592  -5.074882  \n",
            "31  -65.940548  -4.464582  \n",
            "163 -52.481110 -13.026080  \n",
            "34  -65.919635  -4.491852  \n",
            "114 -59.016821  -2.533317  \n",
            "41  -63.094090  -9.481545  \n",
            "174 -51.490304  -2.472995  \n",
            "70  -62.018920  -5.993962  \n",
            "7   -69.941013  -4.974513  \n",
            "97  -59.995978   0.978041  \n",
            "78  -59.986168 -12.530924  \n",
            "69  -61.943942  -5.968439  \n",
            "77  -60.028974 -12.512967  \n",
            "94  -60.053079  -2.472211  \n",
            "10  -69.998987  -4.987620  \n",
            "177 -51.482649  -2.542973  \n",
            "49  -62.987849  -9.108469  \n",
            "8   -69.959494  -5.057864  \n",
            "123 -57.569598  -3.959208  \n",
            "82  -59.988404 -12.483041  \n",
            "54  -63.034702  -8.936042  \n",
            "120 -57.441254  -4.043666  \n",
            "107 -59.996245   0.944263  \n",
            "(array([36.32258867, 40.7952952 , 42.44920177, 35.54795707, 33.17328283,\n",
            "       40.42068967, 38.99447263, 35.9123499 , 41.96313577, 40.76868643,\n",
            "       38.9116596 , 34.876199  , 34.25798153, 36.3190911 , 41.73504463,\n",
            "       35.68019797, 42.69945517, 38.60038817, 43.93325943, 37.61372613,\n",
            "       38.19111357, 36.5643681 , 38.99234923, 40.99868043, 45.87947013,\n",
            "       37.33362937, 39.9602944 , 37.85613507, 40.48990127, 38.186331  ,\n",
            "       41.426369  , 38.48803687, 42.7894115 , 39.31669647, 39.27226093,\n",
            "       38.9498037 , 38.19946593, 41.39638427, 32.83303453, 40.79385507,\n",
            "       34.78866117, 37.1861013 , 40.35766153, 37.55605523, 40.19941603]), array([0.014559  , 0.07172296, 0.22858119, 0.0184792 , 0.03962006,\n",
            "       0.03291305, 0.00265304, 0.01640927, 0.00522156, 0.02022111,\n",
            "       0.02895331, 0.03323808, 0.00503375, 0.0045559 , 0.01661229,\n",
            "       0.04727275, 0.0192214 , 0.00509048, 0.06681183, 0.04306306,\n",
            "       0.01158416, 0.04764672, 0.00134131, 0.00207393, 0.01086676,\n",
            "       0.01058084, 0.01839097, 0.02962355, 0.053403  , 0.02284583,\n",
            "       0.00118247, 0.02847794, 0.00528039, 0.01598556, 0.01258249,\n",
            "       0.02662847, 0.02849809, 0.03654166, 0.01285939, 0.00277783,\n",
            "       0.003483  , 0.0675025 , 0.04161284, 0.00755532, 0.01385543]))\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "[array([[37.66986 ],\n",
            "       [37.669865],\n",
            "       [37.669865],\n",
            "       [37.669876],\n",
            "       [37.669857],\n",
            "       [37.66988 ],\n",
            "       [37.669827],\n",
            "       [37.669865],\n",
            "       [37.66981 ],\n",
            "       [37.66988 ],\n",
            "       [37.669888],\n",
            "       [37.669888],\n",
            "       [37.66987 ],\n",
            "       [37.669872],\n",
            "       [37.66987 ],\n",
            "       [37.669884],\n",
            "       [37.66988 ],\n",
            "       [37.669865],\n",
            "       [37.66986 ],\n",
            "       [37.669888],\n",
            "       [37.66986 ],\n",
            "       [37.669834],\n",
            "       [37.669834],\n",
            "       [37.66984 ],\n",
            "       [37.669884],\n",
            "       [37.669876],\n",
            "       [37.669865],\n",
            "       [37.669876],\n",
            "       [37.669857],\n",
            "       [37.669888],\n",
            "       [37.669785],\n",
            "       [37.669838],\n",
            "       [37.669846],\n",
            "       [37.669888],\n",
            "       [37.66986 ],\n",
            "       [37.669884],\n",
            "       [37.669865],\n",
            "       [37.669876],\n",
            "       [37.669846],\n",
            "       [37.66983 ],\n",
            "       [37.669888],\n",
            "       [37.669888],\n",
            "       [37.669865],\n",
            "       [37.669857],\n",
            "       [37.66987 ]], dtype=float32), array([[3.7107418e-11],\n",
            "       [3.7107348e-11],\n",
            "       [3.7107348e-11],\n",
            "       [3.7107133e-11],\n",
            "       [3.7107772e-11],\n",
            "       [3.7107133e-11],\n",
            "       [3.7107702e-11],\n",
            "       [3.7107487e-11],\n",
            "       [3.7107914e-11],\n",
            "       [3.7107133e-11],\n",
            "       [3.7107133e-11],\n",
            "       [3.7107064e-11],\n",
            "       [3.7107206e-11],\n",
            "       [3.7107418e-11],\n",
            "       [3.7107348e-11],\n",
            "       [3.7107276e-11],\n",
            "       [3.7107276e-11],\n",
            "       [3.7107348e-11],\n",
            "       [3.7107348e-11],\n",
            "       [3.7107064e-11],\n",
            "       [3.7107348e-11],\n",
            "       [3.7107772e-11],\n",
            "       [3.7107629e-11],\n",
            "       [3.7107560e-11],\n",
            "       [3.7107206e-11],\n",
            "       [3.7107206e-11],\n",
            "       [3.7107348e-11],\n",
            "       [3.7107206e-11],\n",
            "       [3.7107418e-11],\n",
            "       [3.7107064e-11],\n",
            "       [3.7108053e-11],\n",
            "       [3.7107702e-11],\n",
            "       [3.7107487e-11],\n",
            "       [3.7107064e-11],\n",
            "       [3.7107348e-11],\n",
            "       [3.7107133e-11],\n",
            "       [3.7107348e-11],\n",
            "       [3.7107276e-11],\n",
            "       [3.7107841e-11],\n",
            "       [3.7107702e-11],\n",
            "       [3.7107276e-11],\n",
            "       [3.7107060e-11],\n",
            "       [3.7107345e-11],\n",
            "       [3.7107557e-11],\n",
            "       [3.7107345e-11]], dtype=float32)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(get_model_save_location(), save_format=\"h5\")"
      ],
      "metadata": {
        "id": "4v8KfwFPorQk"
      },
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generating GeoTIFFs from the DNN\n",
        "\n",
        "All of the code from the following block is (temporarily) copy and pasted from the library files."
      ],
      "metadata": {
        "id": "POFF4TG1pIZd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "from dataclasses import dataclass\n",
        "from osgeo import gdal, gdal_array\n",
        "from tqdm import tqdm\n",
        "import math\n",
        "\n",
        "@dataclass\n",
        "class AmazonGeoTiff:\n",
        "  \"\"\"Represents a geotiff from our dataset.\"\"\"\n",
        "  gdal_dataset: gdal.Dataset\n",
        "  image_value_array: np.ndarray # ndarray of floats\n",
        "  image_mask_array: np.ndarray # ndarray of uint8\n",
        "  masked_image: np.ma.masked_array\n",
        "  yearly_masked_image: np.ma.masked_array\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class Bounds:\n",
        "  \"\"\"Represents geographic bounds and size information.\"\"\"\n",
        "  minx: float\n",
        "  maxx: float\n",
        "  miny: float\n",
        "  maxy: float\n",
        "  pixel_size_x: float\n",
        "  pixel_size_y: float\n",
        "  raster_size_x: float\n",
        "  raster_size_y: float\n",
        "\n",
        "def to_matplotlib(self) -> List[float]:\n",
        "    return [self.minx, self.maxx, self.miny, self.maxy]\n",
        "\n",
        "def load_raster(path: str, use_only_band_index: int = -1) -> AmazonGeoTiff:\n",
        "  \"\"\"\n",
        "  TODO: Refactor (is_single_band, etc., should be a better design)\n",
        "  --> Find a way to simplify this logic. Maybe it needs to be more abstract.\n",
        "  \"\"\"\n",
        "  dataset = gdal.Open(path, gdal.GA_ReadOnly)\n",
        "  image_datatype = dataset.GetRasterBand(1).DataType\n",
        "  mask_datatype = dataset.GetRasterBand(1).GetMaskBand().DataType\n",
        "  image = np.zeros((dataset.RasterYSize, dataset.RasterXSize, 12),\n",
        "                   dtype=gdal_array.GDALTypeCodeToNumericTypeCode(image_datatype))\n",
        "  mask = np.zeros((dataset.RasterYSize, dataset.RasterXSize, 12),\n",
        "                  dtype=gdal_array.GDALTypeCodeToNumericTypeCode(image_datatype))\n",
        "\n",
        "  if use_only_band_index == -1:\n",
        "    if dataset.RasterCount != 12 and dataset.RasterCount != 1:\n",
        "      raise ValueError(f\"Expected 12 raster bands (one for each month) or one annual average, but found {dataset.RasterCount}\")\n",
        "    if dataset.RasterCount == 1:\n",
        "      use_only_band_index = 0\n",
        "\n",
        "  is_single_band = use_only_band_index != -1\n",
        "\n",
        "  if is_single_band and use_only_band_index >= dataset.RasterCount:\n",
        "    raise IndexError(f\"Specified raster band index {use_only_band_index}\"\n",
        "                     f\" but there are only {dataset.RasterCount} rasters\")\n",
        "\n",
        "  for band_index in range(12):\n",
        "    band = dataset.GetRasterBand(use_only_band_index+1 if is_single_band else band_index+1)\n",
        "    image[:, :, band_index] = band.ReadAsArray()\n",
        "    mask[:, :, band_index] = band.GetMaskBand().ReadAsArray()\n",
        "  masked_image = np.ma.masked_where(mask == 0, image)\n",
        "  yearly_masked_image = masked_image.mean(axis=2)\n",
        "\n",
        "  return AmazonGeoTiff(dataset, image, mask, masked_image, yearly_masked_image)\n",
        "\n",
        "def get_extent(dataset):\n",
        "  geoTransform = dataset.GetGeoTransform()\n",
        "  minx = geoTransform[0]\n",
        "  maxy = geoTransform[3]\n",
        "  maxx = minx + geoTransform[1] * dataset.RasterXSize\n",
        "  miny = maxy + geoTransform[5] * dataset.RasterYSize\n",
        "  return Bounds(minx, maxx, miny, maxy, geoTransform[1], geoTransform[5], dataset.RasterXSize, dataset.RasterYSize)\n",
        "\n",
        "def coords_to_indices(bounds: Bounds, x: float, y: float):\n",
        "  if x < bounds.minx or x > bounds.maxx or y < bounds.miny or y > bounds.maxy:\n",
        "    raise ValueError(\"Coordinates out of bounds\")\n",
        "\n",
        "  # X => lat, Y => lon\n",
        "  x_idx = bounds.raster_size_y - int(math.ceil((y - bounds.miny) / abs(bounds.pixel_size_y)))\n",
        "  y_idx = int((x - bounds.minx) / abs(bounds.pixel_size_x))\n",
        "\n",
        "  return x_idx, y_idx\n",
        "\n",
        "def get_data_at_coords(dataset: AmazonGeoTiff, x: float, y: float, month: int) -> float:\n",
        "  # x = longitude\n",
        "  # y = latitude\n",
        "  bounds = get_extent(dataset.gdal_dataset)\n",
        "  x_idx, y_idx = coords_to_indices(bounds, x, y)\n",
        "  if month == -1:\n",
        "    value = dataset.yearly_masked_image[x_idx, y_idx]\n",
        "  else:\n",
        "    value = dataset.masked_image[x_idx, y_idx, month]\n",
        "  if np.ma.is_masked(value):\n",
        "    raise ValueError(\"Coordinates are masked\")\n",
        "  else:\n",
        "    return value\n"
      ],
      "metadata": {
        "id": "88AuYoy9pP3v"
      },
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following code is new stuff, and used to generate a 12 GeoTIFFs (one for each month) from the model."
      ],
      "metadata": {
        "id": "PMEBK97Bxv2z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_predictions_at_each_pixel(\n",
        "    monthly: bool,\n",
        "    geotiffs: dict[str, AmazonGeoTiff],\n",
        "    bounds: Bounds,\n",
        "    model: keras.Model):\n",
        "  feature_names = [\"lat\", \"lon\", \"month_of_year\"] + list(geotiffs.keys())\n",
        "  predicted_means_isoscape = np.ma.array(\n",
        "      np.zeros([bounds.raster_size_x, bounds.raster_size_y, 1], dtype=float),\n",
        "      mask=np.ones([bounds.raster_size_x, bounds.raster_size_y, 1], dtype=bool))\n",
        "  predicted_vars_isoscape = np.ma.array(\n",
        "      np.zeros([bounds.raster_size_x, bounds.raster_size_y, 1], dtype=float),\n",
        "      mask=np.ones([bounds.raster_size_x, bounds.raster_size_y, 1], dtype=bool))\n",
        "\n",
        "  for month in range (0, 12 if monthly else 1):\n",
        "    for x_idx, x in enumerate(tqdm(np.arange(bounds.minx, bounds.maxx, bounds.pixel_size_x, dtype=float))):\n",
        "      rows = []\n",
        "      row_indexes = []\n",
        "      for y_idx, y in enumerate(np.arange(bounds.miny, bounds.maxy, -bounds.pixel_size_y, dtype=float)):\n",
        "        row = {}\n",
        "        try:\n",
        "          for geotiff_label, geotiff in geotiffs.items():\n",
        "            row[geotiff_label] = get_data_at_coords(geotiff, x, y, month)\n",
        "          row[\"month_of_year\"] = month\n",
        "          row[\"lon\"] = x\n",
        "          row[\"lat\"] = y\n",
        "        except ValueError:\n",
        "          continue # masked and out-of-bounds coordinates\n",
        "        except IndexError:\n",
        "          continue\n",
        "        rows.append(row)\n",
        "        row_indexes.append((y_idx,month,))\n",
        "      if (len(rows) > 0):\n",
        "        X = pd.DataFrame.from_dict(rows)\n",
        "        predictions = model.predict(X)\n",
        "        print(predictions)\n",
        "        means_np = predictions[0]\n",
        "        for prediction, (y_idx, month_idx) in zip(means_np, row_indexes):\n",
        "          predicted_means_isoscape.mask[x_idx,y_idx,month_idx] = False # unmask since we have data\n",
        "          predicted_means_isoscape.data[x_idx,y_idx,month_idx] = prediction\n",
        "        vars_np = predictions[1]\n",
        "        for prediction, (y_idx, month_idx) in zip (vars_np, row_indexes):\n",
        "          predicted_vars_isoscape.mask[x_idx, y_idx, month_idx] = False\n",
        "          predicted_vars_isoscape.data[x_idx, y_idx, month_idx] = prediction\n",
        "\n",
        "\n",
        "\n",
        "  return predicted_isoscape"
      ],
      "metadata": {
        "id": "9vwqAMX0yCEI"
      },
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.models.load_model(get_model_save_location(), custom_objects={\"kl_divergence_loss\": kl_divergence_loss})\n",
        "\n",
        "relative_humidity_geotiff = load_raster(get_raster_path_from_params(\"R.rh_Stack.tif\"))\n",
        "temperature_geotiff = load_raster(get_raster_path_from_params(\"Temperatura_Stack.tif\"))\n",
        "vapor_pressure_deficit_geotiff = load_raster(get_raster_path_from_params(\"R.vpd_Stack.tif\"))\n",
        "atmosphere_isoscape_geotiff = load_raster(get_raster_path_from_params(\"Iso_Oxi_Stack.tif\"))\n",
        "\n",
        "name_to_geotiff = {\n",
        "    \"rh\": relative_humidity_geotiff,\n",
        "    \"temp\" : temperature_geotiff,\n",
        "    \"vpd\" : vapor_pressure_deficit_geotiff,\n",
        "    \"atmosphere_oxygen_ratio\" : atmosphere_isoscape_geotiff,\n",
        "}\n",
        "\n",
        "# We need the borders of the map. Pick one geotiff at random and use that as the extent.\n",
        "bounds =  get_extent(atmosphere_isoscape_geotiff.gdal_dataset)\n",
        "\n",
        "isoscape_np = get_predictions_at_each_pixel(\n",
        "    monthly=True,\n",
        "    geotiffs=name_to_geotiff,\n",
        "    bounds=bounds,\n",
        "    model=model)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "su_oKXUpxvQO",
        "outputId": "15231cd8-08a2-4626-cdb6-bd2aacc6662e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/940 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 68ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 1/940 [00:00<02:03,  7.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[array([[38.533215]], dtype=float32), array([[0.]], dtype=float32)]\n",
            "1/1 [==============================] - 0s 19ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 2/940 [00:00<01:46,  8.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[array([[38.507195],\n",
            "       [38.49244 ],\n",
            "       [38.45522 ]], dtype=float32), array([[0.],\n",
            "       [0.],\n",
            "       [0.]], dtype=float32)]\n",
            "1/1 [==============================] - 0s 19ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 3/940 [00:00<01:40,  9.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[array([[38.506588],\n",
            "       [38.484592],\n",
            "       [38.486336],\n",
            "       [38.468964],\n",
            "       [38.448246],\n",
            "       [38.436882]], dtype=float32), array([[0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.]], dtype=float32)]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "[array([[38.488644],\n",
            "       [38.485718],\n",
            "       [38.470535],\n",
            "       [38.458225],\n",
            "       [38.4448  ],\n",
            "       [38.433033],\n",
            "       [38.427162],\n",
            "       [38.42447 ]], dtype=float32), array([[0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.]], dtype=float32)]\n",
            "1/1 [==============================] - 0s 21ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  1%|          | 5/940 [00:00<01:27, 10.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[array([[38.488827],\n",
            "       [38.47389 ],\n",
            "       [38.46597 ],\n",
            "       [38.439545],\n",
            "       [38.44052 ],\n",
            "       [38.423157],\n",
            "       [38.41794 ],\n",
            "       [38.426872]], dtype=float32), array([[0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.]], dtype=float32)]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "[array([[38.47824 ],\n",
            "       [38.454166],\n",
            "       [38.438305],\n",
            "       [38.429756],\n",
            "       [38.409058],\n",
            "       [38.403816],\n",
            "       [38.405945],\n",
            "       [38.39555 ],\n",
            "       [38.24015 ],\n",
            "       [38.25869 ]], dtype=float32), array([[0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.]], dtype=float32)]\n",
            "1/1 [==============================] - 0s 18ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  1%|          | 7/940 [00:00<01:24, 11.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[array([[38.517254],\n",
            "       [38.50502 ],\n",
            "       [38.46154 ],\n",
            "       [38.44299 ],\n",
            "       [38.459217],\n",
            "       [38.436398],\n",
            "       [38.405827],\n",
            "       [38.40359 ],\n",
            "       [38.39105 ],\n",
            "       [38.38398 ],\n",
            "       [38.368774],\n",
            "       [38.367344],\n",
            "       [38.262787],\n",
            "       [38.267643],\n",
            "       [38.268307],\n",
            "       [38.252815],\n",
            "       [38.23978 ],\n",
            "       [38.223812]], dtype=float32), array([[0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.]], dtype=float32)]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "[array([[38.4998  ],\n",
            "       [38.48997 ],\n",
            "       [38.413662],\n",
            "       [38.39636 ],\n",
            "       [38.40119 ],\n",
            "       [38.379402],\n",
            "       [38.362427],\n",
            "       [38.382385],\n",
            "       [38.37925 ],\n",
            "       [38.352543],\n",
            "       [38.34331 ],\n",
            "       [38.299316],\n",
            "       [38.289444],\n",
            "       [38.255222],\n",
            "       [38.260063],\n",
            "       [38.26708 ],\n",
            "       [38.272293],\n",
            "       [38.25993 ],\n",
            "       [38.245224],\n",
            "       [38.232025],\n",
            "       [38.220825],\n",
            "       [38.21302 ],\n",
            "       [38.200657],\n",
            "       [38.19097 ],\n",
            "       [38.177742]], dtype=float32), array([[0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.]], dtype=float32)]\n",
            "1/1 [==============================] - 0s 18ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  1%|          | 9/940 [00:00<01:23, 11.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[array([[38.4872  ],\n",
            "       [38.4777  ],\n",
            "       [38.49271 ],\n",
            "       [38.450375],\n",
            "       [38.400723],\n",
            "       [38.418617],\n",
            "       [38.40642 ],\n",
            "       [38.396786],\n",
            "       [38.38345 ],\n",
            "       [38.370655],\n",
            "       [38.357903],\n",
            "       [38.3402  ],\n",
            "       [38.333183],\n",
            "       [38.327545],\n",
            "       [38.315052],\n",
            "       [38.308884],\n",
            "       [38.28995 ],\n",
            "       [38.274498],\n",
            "       [38.259678],\n",
            "       [38.250248],\n",
            "       [38.24374 ],\n",
            "       [38.226006],\n",
            "       [38.217182],\n",
            "       [38.201225],\n",
            "       [38.188087],\n",
            "       [38.177544],\n",
            "       [38.166107],\n",
            "       [38.152016],\n",
            "       [38.14752 ]], dtype=float32), array([[0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.]], dtype=float32)]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "[array([[38.476498],\n",
            "       [38.457123],\n",
            "       [38.46308 ],\n",
            "       [38.45433 ],\n",
            "       [38.431595],\n",
            "       [38.39798 ],\n",
            "       [38.42079 ],\n",
            "       [38.403667],\n",
            "       [38.391712],\n",
            "       [38.379715],\n",
            "       [38.363285],\n",
            "       [38.354576],\n",
            "       [38.340145],\n",
            "       [38.33045 ],\n",
            "       [38.319244],\n",
            "       [38.314323],\n",
            "       [38.300945],\n",
            "       [38.282005],\n",
            "       [38.265274],\n",
            "       [38.25185 ],\n",
            "       [38.239597],\n",
            "       [38.232952],\n",
            "       [38.219437],\n",
            "       [38.19581 ],\n",
            "       [38.195107],\n",
            "       [38.183823],\n",
            "       [38.174297],\n",
            "       [38.152477],\n",
            "       [38.142036],\n",
            "       [38.13255 ],\n",
            "       [38.122086],\n",
            "       [38.110188]], dtype=float32), array([[0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.]], dtype=float32)]\n",
            "2/2 [==============================] - 0s 9ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  1%|          | 11/940 [00:01<01:49,  8.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[array([[38.533844],\n",
            "       [38.516037],\n",
            "       [38.49209 ],\n",
            "       [38.479187],\n",
            "       [38.474422],\n",
            "       [38.45848 ],\n",
            "       [38.44505 ],\n",
            "       [38.430496],\n",
            "       [38.4245  ],\n",
            "       [38.416428],\n",
            "       [38.396133],\n",
            "       [38.38178 ],\n",
            "       [38.37103 ],\n",
            "       [38.355534],\n",
            "       [38.351147],\n",
            "       [38.336292],\n",
            "       [38.323578],\n",
            "       [38.30752 ],\n",
            "       [38.300167],\n",
            "       [38.29389 ],\n",
            "       [38.272247],\n",
            "       [38.2609  ],\n",
            "       [38.24938 ],\n",
            "       [38.236614],\n",
            "       [38.22304 ],\n",
            "       [38.212387],\n",
            "       [38.199234],\n",
            "       [38.177273],\n",
            "       [38.175014],\n",
            "       [38.163647],\n",
            "       [38.15226 ],\n",
            "       [38.133095],\n",
            "       [38.126427],\n",
            "       [38.108242],\n",
            "       [38.095547],\n",
            "       [38.088837],\n",
            "       [38.08226 ]], dtype=float32), array([[0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.]], dtype=float32)]\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "[array([[38.549118],\n",
            "       [38.532803],\n",
            "       [38.534485],\n",
            "       [38.51086 ],\n",
            "       [38.49205 ],\n",
            "       [38.482944],\n",
            "       [38.47118 ],\n",
            "       [38.454113],\n",
            "       [38.438114],\n",
            "       [38.435505],\n",
            "       [38.411266],\n",
            "       [38.402912],\n",
            "       [38.39525 ],\n",
            "       [38.3735  ],\n",
            "       [38.362007],\n",
            "       [38.35126 ],\n",
            "       [38.33713 ],\n",
            "       [38.328186],\n",
            "       [38.317066],\n",
            "       [38.30144 ],\n",
            "       [38.286922],\n",
            "       [38.27445 ],\n",
            "       [38.269176],\n",
            "       [38.253014],\n",
            "       [38.239353],\n",
            "       [38.228043],\n",
            "       [38.216232],\n",
            "       [38.201992],\n",
            "       [38.18377 ],\n",
            "       [38.185303],\n",
            "       [38.15698 ],\n",
            "       [38.147537],\n",
            "       [38.13584 ],\n",
            "       [38.13287 ],\n",
            "       [38.11315 ],\n",
            "       [38.09852 ],\n",
            "       [38.09781 ],\n",
            "       [38.080048],\n",
            "       [38.067535],\n",
            "       [38.055344]], dtype=float32), array([[0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.]], dtype=float32)]\n",
            "2/2 [==============================] - 0s 5ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  1%|▏         | 13/940 [00:01<01:41,  9.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[array([[38.532467],\n",
            "       [38.51852 ],\n",
            "       [38.504463],\n",
            "       [38.486862],\n",
            "       [38.47853 ],\n",
            "       [38.4652  ],\n",
            "       [38.448696],\n",
            "       [38.435516],\n",
            "       [38.413635],\n",
            "       [38.40445 ],\n",
            "       [38.39576 ],\n",
            "       [38.377407],\n",
            "       [38.368374],\n",
            "       [38.355362],\n",
            "       [38.341637],\n",
            "       [38.33318 ],\n",
            "       [38.321957],\n",
            "       [38.309666],\n",
            "       [38.295116],\n",
            "       [38.27706 ],\n",
            "       [38.269825],\n",
            "       [38.253525],\n",
            "       [38.244595],\n",
            "       [38.227005],\n",
            "       [38.213505],\n",
            "       [38.20528 ],\n",
            "       [38.196144],\n",
            "       [38.177605],\n",
            "       [38.164936],\n",
            "       [38.151436],\n",
            "       [38.13633 ],\n",
            "       [38.127003],\n",
            "       [38.117214],\n",
            "       [38.104324],\n",
            "       [38.087204],\n",
            "       [38.08092 ],\n",
            "       [38.07213 ],\n",
            "       [38.059544],\n",
            "       [38.0454  ],\n",
            "       [38.035164],\n",
            "       [38.02232 ]], dtype=float32), array([[0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.]], dtype=float32)]\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "[array([[38.529194],\n",
            "       [38.50822 ],\n",
            "       [38.49906 ],\n",
            "       [38.482033],\n",
            "       [38.47506 ],\n",
            "       [38.458054],\n",
            "       [38.447742],\n",
            "       [38.42602 ],\n",
            "       [38.414795],\n",
            "       [38.398674],\n",
            "       [38.387146],\n",
            "       [38.37087 ],\n",
            "       [38.360386],\n",
            "       [38.35024 ],\n",
            "       [38.33956 ],\n",
            "       [38.32137 ],\n",
            "       [38.30827 ],\n",
            "       [38.296757],\n",
            "       [38.284836],\n",
            "       [38.270645],\n",
            "       [38.2511  ],\n",
            "       [38.2436  ],\n",
            "       [38.226418],\n",
            "       [38.223675],\n",
            "       [38.20826 ],\n",
            "       [38.18826 ],\n",
            "       [38.180878],\n",
            "       [38.170887],\n",
            "       [38.157692],\n",
            "       [38.141434],\n",
            "       [38.13571 ],\n",
            "       [38.113415],\n",
            "       [38.11479 ],\n",
            "       [38.09524 ],\n",
            "       [38.0865  ],\n",
            "       [38.068516],\n",
            "       [38.066967],\n",
            "       [38.050808],\n",
            "       [38.044613],\n",
            "       [38.031044],\n",
            "       [38.01614 ],\n",
            "       [38.01171 ]], dtype=float32), array([[0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.]], dtype=float32)]\n",
            "2/2 [==============================] - 0s 5ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  2%|▏         | 15/940 [00:01<01:37,  9.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[array([[38.517815],\n",
            "       [38.500454],\n",
            "       [38.488373],\n",
            "       [38.479507],\n",
            "       [38.46122 ],\n",
            "       [38.451138],\n",
            "       [38.436123],\n",
            "       [38.42599 ],\n",
            "       [38.40807 ],\n",
            "       [38.39053 ],\n",
            "       [38.376656],\n",
            "       [38.359753],\n",
            "       [38.349533],\n",
            "       [38.33703 ],\n",
            "       [38.32381 ],\n",
            "       [38.317577],\n",
            "       [38.302883],\n",
            "       [38.28671 ],\n",
            "       [38.268677],\n",
            "       [38.2549  ],\n",
            "       [38.244408],\n",
            "       [38.226284],\n",
            "       [38.211716],\n",
            "       [38.208466],\n",
            "       [38.198807],\n",
            "       [38.18374 ],\n",
            "       [38.17519 ],\n",
            "       [38.161453],\n",
            "       [38.15269 ],\n",
            "       [38.133865],\n",
            "       [38.119083],\n",
            "       [38.11298 ],\n",
            "       [38.105354],\n",
            "       [38.09883 ],\n",
            "       [38.079082],\n",
            "       [38.067715],\n",
            "       [38.046875],\n",
            "       [38.041946],\n",
            "       [38.02954 ],\n",
            "       [38.01151 ],\n",
            "       [38.009705],\n",
            "       [37.995083],\n",
            "       [37.987637],\n",
            "       [37.97027 ]], dtype=float32), array([[0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.]], dtype=float32)]\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "[array([[38.51048 ],\n",
            "       [38.48314 ],\n",
            "       [38.46778 ],\n",
            "       [38.45578 ],\n",
            "       [38.447094],\n",
            "       [38.436153],\n",
            "       [38.417072],\n",
            "       [38.399815],\n",
            "       [38.388386],\n",
            "       [38.368637],\n",
            "       [38.350536],\n",
            "       [38.34287 ],\n",
            "       [38.326824],\n",
            "       [38.31492 ],\n",
            "       [38.301   ],\n",
            "       [38.29157 ],\n",
            "       [38.275803],\n",
            "       [38.263355],\n",
            "       [38.246956],\n",
            "       [38.236935],\n",
            "       [38.22063 ],\n",
            "       [38.20914 ],\n",
            "       [38.199768],\n",
            "       [38.189995],\n",
            "       [38.18266 ],\n",
            "       [38.16649 ],\n",
            "       [38.15643 ],\n",
            "       [38.14693 ],\n",
            "       [38.12372 ],\n",
            "       [38.107353],\n",
            "       [38.101757],\n",
            "       [38.085102],\n",
            "       [38.078865],\n",
            "       [38.069466],\n",
            "       [38.05862 ],\n",
            "       [38.042732],\n",
            "       [38.02635 ],\n",
            "       [38.01823 ],\n",
            "       [38.017227],\n",
            "       [37.998867],\n",
            "       [37.982758],\n",
            "       [37.971455],\n",
            "       [37.96497 ],\n",
            "       [37.953556]], dtype=float32), array([[0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.]], dtype=float32)]\n",
            "2/2 [==============================] - 0s 5ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  2%|▏         | 17/940 [00:01<01:32,  9.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[array([[38.537243],\n",
            "       [38.525253],\n",
            "       [38.502617],\n",
            "       [38.47307 ],\n",
            "       [38.458244],\n",
            "       [38.458256],\n",
            "       [38.446648],\n",
            "       [38.43368 ],\n",
            "       [38.4289  ],\n",
            "       [38.412823],\n",
            "       [38.393234],\n",
            "       [38.378788],\n",
            "       [38.37159 ],\n",
            "       [38.349674],\n",
            "       [38.331005],\n",
            "       [38.320824],\n",
            "       [38.305706],\n",
            "       [38.295494],\n",
            "       [38.27291 ],\n",
            "       [38.264683],\n",
            "       [38.253445],\n",
            "       [38.238358],\n",
            "       [38.228374],\n",
            "       [38.219383],\n",
            "       [38.201294],\n",
            "       [38.190327],\n",
            "       [38.177315],\n",
            "       [38.16324 ],\n",
            "       [38.16125 ],\n",
            "       [38.140766],\n",
            "       [38.129635],\n",
            "       [38.114685],\n",
            "       [38.105503],\n",
            "       [38.089626],\n",
            "       [38.081   ],\n",
            "       [38.071968],\n",
            "       [38.0508  ],\n",
            "       [38.042683],\n",
            "       [38.034542],\n",
            "       [38.02502 ],\n",
            "       [38.011314],\n",
            "       [38.006207],\n",
            "       [37.992428],\n",
            "       [37.968903],\n",
            "       [37.95457 ],\n",
            "       [37.948334],\n",
            "       [37.93887 ],\n",
            "       [37.926464],\n",
            "       [37.91956 ]], dtype=float32), array([[0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.]], dtype=float32)]\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "[array([[38.53047 ],\n",
            "       [38.516636],\n",
            "       [38.506905],\n",
            "       [38.48945 ],\n",
            "       [38.47674 ],\n",
            "       [38.456425],\n",
            "       [38.44912 ],\n",
            "       [38.43334 ],\n",
            "       [38.42566 ],\n",
            "       [38.39666 ],\n",
            "       [38.38865 ],\n",
            "       [38.37274 ],\n",
            "       [38.355133],\n",
            "       [38.35069 ],\n",
            "       [38.32675 ],\n",
            "       [38.31912 ],\n",
            "       [38.302906],\n",
            "       [38.28942 ],\n",
            "       [38.273586],\n",
            "       [38.25254 ],\n",
            "       [38.242985],\n",
            "       [38.23743 ],\n",
            "       [38.21616 ],\n",
            "       [38.207825],\n",
            "       [38.193073],\n",
            "       [38.18506 ],\n",
            "       [38.175213],\n",
            "       [38.154007],\n",
            "       [38.145535],\n",
            "       [38.131035],\n",
            "       [38.12015 ],\n",
            "       [38.112232],\n",
            "       [38.09179 ],\n",
            "       [38.076454],\n",
            "       [38.06163 ],\n",
            "       [38.0625  ],\n",
            "       [38.05578 ],\n",
            "       [38.03511 ],\n",
            "       [38.032887],\n",
            "       [38.019478],\n",
            "       [38.00086 ],\n",
            "       [37.980816],\n",
            "       [37.975468],\n",
            "       [37.958633],\n",
            "       [37.95241 ],\n",
            "       [37.937363],\n",
            "       [37.93242 ],\n",
            "       [37.931126],\n",
            "       [37.90923 ],\n",
            "       [37.897648]], dtype=float32), array([[0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.]], dtype=float32)]\n",
            "2/2 [==============================] - 0s 7ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  2%|▏         | 19/940 [00:01<01:35,  9.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[array([[38.514675],\n",
            "       [38.49854 ],\n",
            "       [38.485744],\n",
            "       [38.464493],\n",
            "       [38.449017],\n",
            "       [38.438488],\n",
            "       [38.418736],\n",
            "       [38.415123],\n",
            "       [38.404163],\n",
            "       [38.385845],\n",
            "       [38.368164],\n",
            "       [38.352825],\n",
            "       [38.33837 ],\n",
            "       [38.330414],\n",
            "       [38.308002],\n",
            "       [38.305058],\n",
            "       [38.28022 ],\n",
            "       [38.273952],\n",
            "       [38.25072 ],\n",
            "       [38.240406],\n",
            "       [38.22972 ],\n",
            "       [38.221107],\n",
            "       [38.20279 ],\n",
            "       [38.18715 ],\n",
            "       [38.171997],\n",
            "       [38.156326],\n",
            "       [38.15383 ],\n",
            "       [38.135567],\n",
            "       [38.125397],\n",
            "       [38.106636],\n",
            "       [38.104385],\n",
            "       [38.087456],\n",
            "       [38.072575],\n",
            "       [38.058113],\n",
            "       [38.046955],\n",
            "       [38.036606],\n",
            "       [38.027943],\n",
            "       [38.01294 ],\n",
            "       [38.003967],\n",
            "       [37.985287],\n",
            "       [37.97158 ],\n",
            "       [37.954544],\n",
            "       [37.954933],\n",
            "       [37.94595 ],\n",
            "       [37.93153 ],\n",
            "       [37.925743],\n",
            "       [37.913567],\n",
            "       [37.896072],\n",
            "       [37.893204],\n",
            "       [37.875046],\n",
            "       [37.76141 ],\n",
            "       [37.748695],\n",
            "       [37.732136]], dtype=float32), array([[0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.]], dtype=float32)]\n",
            "2/2 [==============================] - 0s 10ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  2%|▏         | 20/940 [00:02<01:38,  9.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[array([[38.759098],\n",
            "       [38.512756],\n",
            "       [38.496075],\n",
            "       [38.477715],\n",
            "       [38.47002 ],\n",
            "       [38.45317 ],\n",
            "       [38.439713],\n",
            "       [38.4192  ],\n",
            "       [38.40563 ],\n",
            "       [38.38889 ],\n",
            "       [38.378277],\n",
            "       [38.364605],\n",
            "       [38.35721 ],\n",
            "       [38.339966],\n",
            "       [38.312393],\n",
            "       [38.306515],\n",
            "       [38.28887 ],\n",
            "       [38.272594],\n",
            "       [38.268578],\n",
            "       [38.242958],\n",
            "       [38.229332],\n",
            "       [38.221676],\n",
            "       [38.201218],\n",
            "       [38.193817],\n",
            "       [38.17332 ],\n",
            "       [38.16021 ],\n",
            "       [38.152298],\n",
            "       [38.136356],\n",
            "       [38.118523],\n",
            "       [38.106503],\n",
            "       [38.094097],\n",
            "       [38.088943],\n",
            "       [38.086052],\n",
            "       [38.06729 ],\n",
            "       [38.05767 ],\n",
            "       [38.039925],\n",
            "       [38.022724],\n",
            "       [38.018295],\n",
            "       [38.0067  ],\n",
            "       [38.004047],\n",
            "       [37.982067],\n",
            "       [37.970432],\n",
            "       [37.95768 ],\n",
            "       [37.93942 ],\n",
            "       [37.931034],\n",
            "       [37.928627],\n",
            "       [37.92202 ],\n",
            "       [37.91827 ],\n",
            "       [37.89694 ],\n",
            "       [37.882282],\n",
            "       [37.863853],\n",
            "       [37.862274],\n",
            "       [37.854614],\n",
            "       [37.76343 ],\n",
            "       [37.749813],\n",
            "       [37.737175],\n",
            "       [37.724453],\n",
            "       [37.70833 ],\n",
            "       [37.693657],\n",
            "       [37.68906 ]], dtype=float32), array([[0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.]], dtype=float32)]\n",
            "3/3 [==============================] - 0s 3ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  2%|▏         | 21/940 [00:02<01:46,  8.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[array([[38.739174],\n",
            "       [38.726048],\n",
            "       [38.490562],\n",
            "       [38.472492],\n",
            "       [38.466454],\n",
            "       [38.44779 ],\n",
            "       [38.4246  ],\n",
            "       [38.419865],\n",
            "       [38.4044  ],\n",
            "       [38.38857 ],\n",
            "       [38.36812 ],\n",
            "       [38.359962],\n",
            "       [38.345455],\n",
            "       [38.33827 ],\n",
            "       [38.317593],\n",
            "       [38.301632],\n",
            "       [38.28885 ],\n",
            "       [38.268986],\n",
            "       [38.251095],\n",
            "       [38.242023],\n",
            "       [38.219482],\n",
            "       [38.219395],\n",
            "       [38.195183],\n",
            "       [38.185986],\n",
            "       [38.175304],\n",
            "       [38.15718 ],\n",
            "       [38.144043],\n",
            "       [38.129143],\n",
            "       [38.115288],\n",
            "       [38.10696 ],\n",
            "       [38.0904  ],\n",
            "       [38.07818 ],\n",
            "       [38.0613  ],\n",
            "       [38.05814 ],\n",
            "       [38.048656],\n",
            "       [38.04153 ],\n",
            "       [38.01303 ],\n",
            "       [38.006573],\n",
            "       [37.991337],\n",
            "       [37.983685],\n",
            "       [37.970264],\n",
            "       [37.964546],\n",
            "       [37.94711 ],\n",
            "       [37.94285 ],\n",
            "       [37.935253],\n",
            "       [37.922493],\n",
            "       [37.908215],\n",
            "       [37.895252],\n",
            "       [37.881874],\n",
            "       [37.86469 ],\n",
            "       [37.86237 ],\n",
            "       [37.84881 ],\n",
            "       [37.837692],\n",
            "       [37.830315],\n",
            "       [37.813446],\n",
            "       [37.769276],\n",
            "       [37.763176],\n",
            "       [37.751583],\n",
            "       [37.729263],\n",
            "       [37.72768 ],\n",
            "       [37.706844],\n",
            "       [37.691845],\n",
            "       [37.68454 ],\n",
            "       [37.67119 ],\n",
            "       [37.663853],\n",
            "       [37.649315],\n",
            "       [37.640793]], dtype=float32), array([[0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.]], dtype=float32)]\n",
            "3/3 [==============================] - 0s 4ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  2%|▏         | 22/940 [00:02<01:43,  8.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[array([[38.72046 ],\n",
            "       [38.702705],\n",
            "       [38.693947],\n",
            "       [38.51464 ],\n",
            "       [38.498024],\n",
            "       [38.48597 ],\n",
            "       [38.466743],\n",
            "       [38.453094],\n",
            "       [38.44413 ],\n",
            "       [38.416286],\n",
            "       [38.403492],\n",
            "       [38.394905],\n",
            "       [38.384567],\n",
            "       [38.37179 ],\n",
            "       [38.35734 ],\n",
            "       [38.34736 ],\n",
            "       [38.321373],\n",
            "       [38.309753],\n",
            "       [38.29643 ],\n",
            "       [38.283203],\n",
            "       [38.273125],\n",
            "       [38.251663],\n",
            "       [38.232044],\n",
            "       [38.216427],\n",
            "       [38.204407],\n",
            "       [38.193142],\n",
            "       [38.184307],\n",
            "       [38.17032 ],\n",
            "       [38.150097],\n",
            "       [38.13463 ],\n",
            "       [38.120388],\n",
            "       [38.112427],\n",
            "       [38.098705],\n",
            "       [38.080677],\n",
            "       [38.0777  ],\n",
            "       [38.056763],\n",
            "       [38.05248 ],\n",
            "       [38.0461  ],\n",
            "       [38.029938],\n",
            "       [38.01245 ],\n",
            "       [38.0018  ],\n",
            "       [37.99353 ],\n",
            "       [37.97601 ],\n",
            "       [37.96439 ],\n",
            "       [37.95628 ],\n",
            "       [37.950947],\n",
            "       [37.930027],\n",
            "       [37.912262],\n",
            "       [37.90362 ],\n",
            "       [37.894726],\n",
            "       [37.87921 ],\n",
            "       [37.87669 ],\n",
            "       [37.85739 ],\n",
            "       [37.842712],\n",
            "       [37.836197],\n",
            "       [37.837685],\n",
            "       [37.821693],\n",
            "       [37.80473 ],\n",
            "       [37.79826 ],\n",
            "       [37.788143],\n",
            "       [37.772457],\n",
            "       [37.763077],\n",
            "       [37.754936],\n",
            "       [37.73631 ],\n",
            "       [37.72757 ],\n",
            "       [37.720963],\n",
            "       [37.704037],\n",
            "       [37.685497],\n",
            "       [37.669346],\n",
            "       [37.65425 ],\n",
            "       [37.647404],\n",
            "       [37.636513],\n",
            "       [37.622654],\n",
            "       [37.61668 ],\n",
            "       [37.609734]], dtype=float32), array([[0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.]], dtype=float32)]\n",
            "3/3 [==============================] - 0s 2ms/step\n",
            "[array([[38.69877 ],\n",
            "       [38.685326],\n",
            "       [38.67216 ],\n",
            "       [38.657246],\n",
            "       [38.527668],\n",
            "       [38.50932 ],\n",
            "       [38.497635],\n",
            "       [38.48312 ],\n",
            "       [38.46436 ],\n",
            "       [38.442394],\n",
            "       [38.434025],\n",
            "       [38.416855],\n",
            "       [38.4013  ],\n",
            "       [38.39334 ],\n",
            "       [38.37172 ],\n",
            "       [38.36298 ],\n",
            "       [38.342346],\n",
            "       [38.32815 ],\n",
            "       [38.319958],\n",
            "       [38.307667],\n",
            "       [38.294872],\n",
            "       [38.273563],\n",
            "       [38.264534],\n",
            "       [38.23677 ],\n",
            "       [38.227634],\n",
            "       [38.213142],\n",
            "       [38.20272 ],\n",
            "       [38.190582],\n",
            "       [38.170685],\n",
            "       [38.1633  ],\n",
            "       [38.139347],\n",
            "       [38.13161 ],\n",
            "       [38.104164],\n",
            "       [38.08969 ],\n",
            "       [38.09455 ],\n",
            "       [38.067295],\n",
            "       [38.049385],\n",
            "       [38.0417  ],\n",
            "       [38.03257 ],\n",
            "       [38.0287  ],\n",
            "       [38.014046],\n",
            "       [38.008057],\n",
            "       [37.999603],\n",
            "       [37.984108],\n",
            "       [37.97073 ],\n",
            "       [37.951157],\n",
            "       [37.94572 ],\n",
            "       [37.928997],\n",
            "       [37.915394],\n",
            "       [37.907856],\n",
            "       [37.88985 ],\n",
            "       [37.883053],\n",
            "       [37.86707 ],\n",
            "       [37.861874],\n",
            "       [37.8535  ],\n",
            "       [37.840206],\n",
            "       [37.821896],\n",
            "       [37.825283],\n",
            "       [37.805275],\n",
            "       [37.792614],\n",
            "       [37.78624 ],\n",
            "       [37.768627],\n",
            "       [37.768547],\n",
            "       [37.757153],\n",
            "       [37.745136],\n",
            "       [37.733917],\n",
            "       [37.716118],\n",
            "       [37.702812],\n",
            "       [37.686283],\n",
            "       [37.67503 ],\n",
            "       [37.663128],\n",
            "       [37.650555],\n",
            "       [37.638172],\n",
            "       [37.63045 ],\n",
            "       [37.625248],\n",
            "       [37.611492],\n",
            "       [37.590088],\n",
            "       [37.581947],\n",
            "       [37.57374 ]], dtype=float32), array([[0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.]], dtype=float32)]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  2%|▏         | 23/940 [00:02<01:40,  9.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "3/3 [==============================] - 0s 5ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  3%|▎         | 24/940 [00:02<01:45,  8.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[array([[38.677567],\n",
            "       [38.66332 ],\n",
            "       [38.646347],\n",
            "       [38.6356  ],\n",
            "       [38.612423],\n",
            "       [38.504326],\n",
            "       [38.491432],\n",
            "       [38.479046],\n",
            "       [38.459682],\n",
            "       [38.44137 ],\n",
            "       [38.425823],\n",
            "       [38.412487],\n",
            "       [38.395794],\n",
            "       [38.38844 ],\n",
            "       [38.3691  ],\n",
            "       [38.35431 ],\n",
            "       [38.342163],\n",
            "       [38.3326  ],\n",
            "       [38.304688],\n",
            "       [38.29232 ],\n",
            "       [38.29129 ],\n",
            "       [38.27464 ],\n",
            "       [38.256035],\n",
            "       [38.236855],\n",
            "       [38.222088],\n",
            "       [38.199364],\n",
            "       [38.19182 ],\n",
            "       [38.168835],\n",
            "       [38.1692  ],\n",
            "       [38.143097],\n",
            "       [38.136497],\n",
            "       [38.132442],\n",
            "       [38.10302 ],\n",
            "       [38.095524],\n",
            "       [38.08636 ],\n",
            "       [38.073544],\n",
            "       [38.05473 ],\n",
            "       [38.036076],\n",
            "       [38.03139 ],\n",
            "       [38.01993 ],\n",
            "       [38.01045 ],\n",
            "       [37.99655 ],\n",
            "       [37.98367 ],\n",
            "       [37.97193 ],\n",
            "       [37.959583],\n",
            "       [37.94627 ],\n",
            "       [37.928493],\n",
            "       [37.927242],\n",
            "       [37.918007],\n",
            "       [37.904057],\n",
            "       [37.885036],\n",
            "       [37.87282 ],\n",
            "       [37.8635  ],\n",
            "       [37.849037],\n",
            "       [37.839363],\n",
            "       [37.826866],\n",
            "       [37.813072],\n",
            "       [37.804604],\n",
            "       [37.802708],\n",
            "       [37.783443],\n",
            "       [37.768665],\n",
            "       [37.76488 ],\n",
            "       [37.751408],\n",
            "       [37.741543],\n",
            "       [37.734085],\n",
            "       [37.721138],\n",
            "       [37.717514],\n",
            "       [37.691986],\n",
            "       [37.674126],\n",
            "       [37.66046 ],\n",
            "       [37.65098 ],\n",
            "       [37.64063 ],\n",
            "       [37.626507],\n",
            "       [37.62889 ],\n",
            "       [37.614212],\n",
            "       [37.597683],\n",
            "       [37.585827],\n",
            "       [37.579487],\n",
            "       [37.56633 ],\n",
            "       [37.553684],\n",
            "       [37.548687]], dtype=float32), array([[0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.]], dtype=float32)]\n",
            "3/3 [==============================] - 0s 5ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  3%|▎         | 25/940 [00:02<01:39,  9.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[array([[38.663406],\n",
            "       [38.65576 ],\n",
            "       [38.646908],\n",
            "       [38.62298 ],\n",
            "       [38.60189 ],\n",
            "       [38.58276 ],\n",
            "       [38.500664],\n",
            "       [38.4855  ],\n",
            "       [38.466957],\n",
            "       [38.45594 ],\n",
            "       [38.436623],\n",
            "       [38.422382],\n",
            "       [38.404438],\n",
            "       [38.400425],\n",
            "       [38.37347 ],\n",
            "       [38.365643],\n",
            "       [38.35435 ],\n",
            "       [38.342228],\n",
            "       [38.326164],\n",
            "       [38.311474],\n",
            "       [38.28719 ],\n",
            "       [38.280888],\n",
            "       [38.259304],\n",
            "       [38.254257],\n",
            "       [38.235588],\n",
            "       [38.219646],\n",
            "       [38.20394 ],\n",
            "       [38.185463],\n",
            "       [38.167267],\n",
            "       [38.14841 ],\n",
            "       [38.14953 ],\n",
            "       [38.121346],\n",
            "       [38.11383 ],\n",
            "       [38.107567],\n",
            "       [38.092052],\n",
            "       [38.071846],\n",
            "       [38.06338 ],\n",
            "       [38.047737],\n",
            "       [38.02891 ],\n",
            "       [38.01872 ],\n",
            "       [38.005898],\n",
            "       [38.000965],\n",
            "       [37.98035 ],\n",
            "       [37.96843 ],\n",
            "       [37.95562 ],\n",
            "       [37.943306],\n",
            "       [37.930893],\n",
            "       [37.9176  ],\n",
            "       [37.907196],\n",
            "       [37.911797],\n",
            "       [37.898888],\n",
            "       [37.872936],\n",
            "       [37.868954],\n",
            "       [37.851147],\n",
            "       [37.8494  ],\n",
            "       [37.834557],\n",
            "       [37.818   ],\n",
            "       [37.80512 ],\n",
            "       [37.797188],\n",
            "       [37.78932 ],\n",
            "       [37.778446],\n",
            "       [37.769527],\n",
            "       [37.746284],\n",
            "       [37.743755],\n",
            "       [37.732655],\n",
            "       [37.72206 ],\n",
            "       [37.710793],\n",
            "       [37.702885],\n",
            "       [37.687393],\n",
            "       [37.671   ],\n",
            "       [37.652992],\n",
            "       [37.64891 ],\n",
            "       [37.640736],\n",
            "       [37.629444],\n",
            "       [37.61676 ],\n",
            "       [37.59682 ],\n",
            "       [37.58267 ],\n",
            "       [37.567097],\n",
            "       [37.570324],\n",
            "       [37.560726],\n",
            "       [37.551067],\n",
            "       [37.53343 ],\n",
            "       [37.527843],\n",
            "       [37.521156],\n",
            "       [37.503075]], dtype=float32), array([[0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.]], dtype=float32)]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-126-387dd32be4db>\u001b[0m in \u001b[0;36m<cell line: 18>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mbounds\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mget_extent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0matmosphere_isoscape_geotiff\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgdal_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m isoscape_np = get_predictions_at_each_pixel(\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0mmonthly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mgeotiffs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname_to_geotiff\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-125-18ca8ec83aa9>\u001b[0m in \u001b[0;36mget_predictions_at_each_pixel\u001b[0;34m(monthly, geotiffs, bounds, model)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m           \u001b[0;32mfor\u001b[0m \u001b[0mgeotiff_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgeotiff\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgeotiffs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m             \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgeotiff_label\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_data_at_coords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgeotiff\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmonth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m           \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"month_of_year\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmonth\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m           \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"lon\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-118-2b7cd67a6a3c>\u001b[0m in \u001b[0;36mget_data_at_coords\u001b[0;34m(dataset, x, y, month)\u001b[0m\n\u001b[1;32m     85\u001b[0m   \u001b[0;31m# x = longitude\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m   \u001b[0;31m# y = latitude\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m   \u001b[0mbounds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_extent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgdal_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m   \u001b[0mx_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcoords_to_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbounds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mmonth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-118-2b7cd67a6a3c>\u001b[0m in \u001b[0;36mget_extent\u001b[0;34m(dataset)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_extent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m   \u001b[0mgeoTransform\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGetGeoTransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m   \u001b[0mminx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgeoTransform\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m   \u001b[0mmaxy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgeoTransform\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/osgeo/gdal.py\u001b[0m in \u001b[0;36mGetGeoTransform\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2295\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mGetGeoTransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2296\u001b[0m         \u001b[0;34m\"\"\"GetGeoTransform(Dataset self, int * can_return_null=None)\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2297\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_gdal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset_GetGeoTransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2299\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}