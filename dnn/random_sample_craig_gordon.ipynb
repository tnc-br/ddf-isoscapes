{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from dataclasses import dataclass\n",
    "import math\n",
    "import numpy as np\n",
    "from numpy.random import MT19937, RandomState, SeedSequence\n",
    "from osgeo import gdal, gdal_array\n",
    "import pandas as pd\n",
    "from typing import List\n",
    "from tqdm import tqdm\n",
    "\n",
    "#@title Debugging\n",
    "# See https://zohaib.me/debugging-in-google-collab-notebook/ for tips,\n",
    "# as well as docs for pdb and ipdb.\n",
    "DEBUG = True #@param {type:\"boolean\"}\n",
    "\n",
    "RASTER_BASE = \"/MyDrive/amazon_rainforest_files/amazon_rasters/\" #@param\n",
    "OUTPUT_DIR = \"/MyDrive/amazon_rainforest_files/dataframes/\" #@param\n",
    "GDRIVE_BASE = \"/content/drive\" #@param\n",
    "\n",
    "def get_raster_path(filename: str) -> str:\n",
    "  root = GDRIVE_BASE if GDRIVE_BASE else \"\"\n",
    "  return f\"{root}{RASTER_BASE}{filename}\"\n",
    "\n",
    "def get_output_dir(filename: str) -> str:\n",
    "  root = GDRIVE_BASE if GDRIVE_BASE else \"\"\n",
    "  return f\"{root}{OUTPUT_DIR}{filename}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access data stored on Google Drive\n",
    "if GDRIVE_BASE:\n",
    "    from google.colab import drive\n",
    "    drive.mount(GDRIVE_BASE)\n",
    "\n",
    "if DEBUG:\n",
    "    %pip install -Uqq ipdb\n",
    "    import ipdb\n",
    "    %pdb on"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Dependencies from xgboost.ipynb\n",
    "\n",
    "TODO: Move these to a shared module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class AmazonGeoTiff:\n",
    "  \"\"\"Represents a geotiff from our dataset.\"\"\"\n",
    "  gdal_dataset: gdal.Dataset\n",
    "  image_value_array: np.ndarray # ndarray of floats\n",
    "  image_mask_array: np.ndarray # ndarray of uint8\n",
    "  masked_image: np.ma.masked_array\n",
    "  yearly_masked_image: np.ma.masked_array\n",
    "\n",
    "@dataclass\n",
    "class Bounds:\n",
    "  \"\"\"Represents geographic bounds and size information.\"\"\"\n",
    "  minx: float\n",
    "  maxx: float\n",
    "  miny: float\n",
    "  maxy: float\n",
    "  pixel_size_x: float\n",
    "  pixel_size_y: float\n",
    "  raster_size_x: float\n",
    "  raster_size_y: float\n",
    "\n",
    "  def to_matplotlib(self) -> List[float]:\n",
    "    return [self.minx, self.maxx, self.miny, self.maxy]\n",
    "\n",
    "def print_raster_info(raster):\n",
    "  dataset = raster\n",
    "  print(\"Driver: {}/{}\".format(dataset.GetDriver().ShortName,\n",
    "                              dataset.GetDriver().LongName))\n",
    "  print(\"Size is {} x {} x {}\".format(dataset.RasterXSize,\n",
    "                                      dataset.RasterYSize,\n",
    "                                      dataset.RasterCount))\n",
    "  print(\"Projection is {}\".format(dataset.GetProjection()))\n",
    "  geotransform = dataset.GetGeoTransform()\n",
    "  if geotransform:\n",
    "      print(\"Origin = ({}, {})\".format(geotransform[0], geotransform[3]))\n",
    "      print(\"Pixel Size = ({}, {})\".format(geotransform[1], geotransform[5]))\n",
    "\n",
    "  for band in range(dataset.RasterCount):\n",
    "    band = dataset.GetRasterBand(band+1)\n",
    "    #print(\"Band Type={}\".format(gdal.GetDataTypeName(band.DataType)))\n",
    "\n",
    "    min = band.GetMinimum()\n",
    "    max = band.GetMaximum()\n",
    "    if not min or not max:\n",
    "        (min,max) = band.ComputeRasterMinMax(False)\n",
    "    #print(\"Min={:.3f}, Max={:.3f}\".format(min,max))\n",
    "\n",
    "    if band.GetOverviewCount() > 0:\n",
    "        print(\"Band has {} overviews\".format(band.GetOverviewCount()))\n",
    "\n",
    "    if band.GetRasterColorTable():\n",
    "        print(\"Band has a color table with {} entries\".format(band.GetRasterColorTable().GetCount()))\n",
    "\n",
    "def load_raster(path: str, use_only_band_index: int = -1) -> AmazonGeoTiff:\n",
    "  \"\"\"\n",
    "  TODO: Refactor (is_single_band, etc., should be a better design)\n",
    "  --> Find a way to simplify this logic. Maybe it needs to be more abstract.\n",
    "  \"\"\"\n",
    "  dataset = gdal.Open(path, gdal.GA_ReadOnly)\n",
    "  try:\n",
    "    print_raster_info(dataset)\n",
    "  except AttributeError as e:\n",
    "    raise OSError(\"Failed to print raster. This likely means it did not load properly from \"+ path)\n",
    "  image_datatype = dataset.GetRasterBand(1).DataType\n",
    "  mask_datatype = dataset.GetRasterBand(1).GetMaskBand().DataType\n",
    "  image = np.zeros((dataset.RasterYSize, dataset.RasterXSize, 12),\n",
    "                  dtype=gdal_array.GDALTypeCodeToNumericTypeCode(image_datatype))\n",
    "  mask = np.zeros((dataset.RasterYSize, dataset.RasterXSize, 12),\n",
    "                  dtype=gdal_array.GDALTypeCodeToNumericTypeCode(image_datatype))\n",
    "\n",
    "  if use_only_band_index == -1:\n",
    "    if dataset.RasterCount != 12 and dataset.RasterCount != 1:\n",
    "      raise ValueError(f\"Expected 12 raster bands (one for each month) or one annual average, but found {dataset.RasterCount}\")\n",
    "    if dataset.RasterCount == 1:\n",
    "      use_only_band_index = 0\n",
    "\n",
    "  is_single_band = use_only_band_index != -1\n",
    "\n",
    "  if is_single_band and use_only_band_index >= dataset.RasterCount:\n",
    "    raise IndexError(f\"Specified raster band index {use_only_band_index}\"\n",
    "    f\" but there are only {dataset.RasterCount} rasters\")\n",
    "\n",
    "  for band_index in range(12):\n",
    "    band = dataset.GetRasterBand(use_only_band_index+1 if is_single_band else band_index+1)\n",
    "    image[:, :, band_index] = band.ReadAsArray()\n",
    "    mask[:, :, band_index] = band.GetMaskBand().ReadAsArray()\n",
    "  masked_image = np.ma.masked_where(mask == 0, image)\n",
    "  yearly_masked_image = masked_image.mean(axis=2)\n",
    "\n",
    "  return AmazonGeoTiff(dataset, image, mask, masked_image, yearly_masked_image)\n",
    "\n",
    "def get_extent(dataset):\n",
    "  geoTransform = dataset.GetGeoTransform()\n",
    "  minx = geoTransform[0]\n",
    "  maxy = geoTransform[3]\n",
    "  maxx = minx + geoTransform[1] * dataset.RasterXSize\n",
    "  miny = maxy + geoTransform[5] * dataset.RasterYSize\n",
    "  return Bounds(minx, maxx, miny, maxy, geoTransform[1], geoTransform[5], dataset.RasterXSize, dataset.RasterYSize)\n",
    "\n",
    "def coords_to_indices(bounds: Bounds, x: float, y: float):\n",
    "  if x < bounds.minx or x > bounds.maxx or y < bounds.miny or y > bounds.maxy:\n",
    "    raise ValueError(\"Coordinates out of bounds\")\n",
    "\n",
    "  # X => lat, Y => lon\n",
    "  x_idx = bounds.raster_size_y - int(math.ceil((y - bounds.miny) / abs(bounds.pixel_size_y)))\n",
    "  y_idx = int((x - bounds.minx) / abs(bounds.pixel_size_x))\n",
    "\n",
    "  return x_idx, y_idx\n",
    "\n",
    "def get_data_at_coords(dataset: AmazonGeoTiff, x: float, y: float, month: int) -> float:\n",
    "  # x = longitude\n",
    "  # y = latitude\n",
    "  bounds = get_extent(dataset.gdal_dataset)\n",
    "  x_idx, y_idx = coords_to_indices(bounds, x, y)\n",
    "  if month == -1:\n",
    "    value = dataset.yearly_masked_image[x_idx, y_idx]\n",
    "  else:\n",
    "    value = dataset.masked_image[x_idx, y_idx, month]\n",
    "  if np.ma.is_masked(value):\n",
    "    raise ValueError(\"Coordinates are masked\")\n",
    "  else:\n",
    "    return value\n",
    "\n",
    "# Randomly sample from geotiffs image files to generate DataFrames.\n",
    "def generate_tabular_dataset(\n",
    "    monthly: bool,\n",
    "    geotiff_features: dict[str, AmazonGeoTiff],\n",
    "    sample_site_coordinates: List[tuple[float, float]],\n",
    "    sample_radius: float,\n",
    "    random_samples_per_site: int) -> pd.DataFrame:\n",
    "  feature_names = [\"lat\", \"lon\", \"month_of_year\"] + list(geotiff_features.keys())\n",
    "  feature_values = defaultdict(list)\n",
    "\n",
    "  rs = RandomState(MT19937(SeedSequence(42)))\n",
    "  for x, y in tqdm(sample_site_coordinates):\n",
    "    for month in range(0, 12 if monthly else 1):\n",
    "      random_samples_collected = 0\n",
    "      while random_samples_collected < random_samples_per_site:\n",
    "        row = {}\n",
    "        sample_x, sample_y = 2*(rs.rand(2) - 0.5) * sample_radius\n",
    "        sample_x += x\n",
    "        sample_y += y\n",
    "        try:\n",
    "          for geotiff_label, geotiff in geotiff_features.items():\n",
    "            row[geotiff_label] = get_data_at_coords(\n",
    "                geotiff, sample_x, sample_y, month)\n",
    "          row[\"month_of_year\"] = month\n",
    "          row[\"lon\"] = sample_x\n",
    "          row[\"lat\"] = sample_y\n",
    "          random_samples_collected += 1\n",
    "        except ValueError:\n",
    "          continue # masked and out-of-bounds coordinates\n",
    "        for feature_name, value in row.items():\n",
    "          feature_values[feature_name].append(value)\n",
    "\n",
    "  samples = pd.DataFrame(feature_values)\n",
    "\n",
    "  if not monthly:\n",
    "    samples.drop(\"month_of_year\", axis=1, inplace=True)\n",
    "\n",
    "  return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relative_humidity_geotiff = load_raster(get_raster_path(\"R.rh_Stack.tif\"))\n",
    "temperature_geotiff = load_raster(get_raster_path(\"Temperatura_Stack.tif\"))\n",
    "vapor_pressure_deficit_geotiff = load_raster(get_raster_path(\"R.vpd_Stack.tif\"))\n",
    "atmosphere_isoscape_geotiff = load_raster(get_raster_path(\"Iso_Oxi_Stack.tif\"))\n",
    "cellulose_isoscape_geotiff = load_raster(get_raster_path(\"iso_O_cellulose.tif\"))\n",
    "\n",
    "name_to_geotiff = {\n",
    "    \"rh\": relative_humidity_geotiff,\n",
    "    \"temp\" : temperature_geotiff,\n",
    "    \"vpd\" : vapor_pressure_deficit_geotiff,\n",
    "    \"atmosphere_oxygen_ratio\" : atmosphere_isoscape_geotiff,\n",
    "    \"cellulose_oxygen_ratio\" : cellulose_isoscape_geotiff\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate and save the dataframes to CSVs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_site_coordinates = [(-70,-5,),(-67.5,0,),(-66,-4.5,),(-63,-9.5,),(-63,-9,),(-62,-6,),(-60,-2.5,),(-60,1,),(-60,-12.5,),(-59,-2.5,),(-57.5,-4,),(-55,-3.5,),(-54,-1,),(-52.5,-13,),(-51.5,-2.5,)]\n",
    "\n",
    "monthly_large_df = generate_tabular_dataset(\n",
    "    monthly=True,\n",
    "    geotiff_features=name_to_geotiff,\n",
    "    sample_site_coordinates=sample_site_coordinates,\n",
    "    sample_radius=0.5,\n",
    "    random_samples_per_site=30)\n",
    "monthly_large_df.to_csv(get_output_dir(\"monthly_large.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_sparse_df = generate_tabular_dataset(\n",
    "    monthly=True,\n",
    "    geotiff_features=name_to_geotiff,\n",
    "    sample_site_coordinates=sample_site_coordinates,\n",
    "    sample_radius=0.5,\n",
    "    random_samples_per_site=17)\n",
    "monthly_sparse_df.to_csv(get_output_dir(\"monthly_sparse.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yearly_large_df = generate_tabular_dataset(\n",
    "    monthly=False,\n",
    "    geotiff_features=name_to_geotiff,\n",
    "    sample_site_coordinates=sample_site_coordinates,\n",
    "    sample_radius=0.5,\n",
    "    random_samples_per_site=30*12)\n",
    "yearly_large_df.to_csv(get_output_dir(\"yearly_large.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yearly_small_df = generate_tabular_dataset(\n",
    "    monthly=False,\n",
    "    geotiff_features=name_to_geotiff,\n",
    "    sample_site_coordinates=sample_site_coordinates,\n",
    "    sample_radius=0.5,\n",
    "    random_samples_per_site=30*12)\n",
    "yearly_small_df.to_csv(get_output_dir(\"yearly_small.csv\"))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
