{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tnc-br/ddf-isoscapes/blob/split_experiments/dnn/variational_split_experiments.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Variational model\n",
        "\n",
        "Find the mean/variance of O18 ratios (as well as N15 and C13 in the future) at a particular lat/lon across Brazil. At the bottom of the colab, train and evaluate 4 different versions of the model with different data partitioning strategies."
      ],
      "metadata": {
        "id": "-0IfT3kGwgK6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "henIPlAPCb4i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1dfa3d9d-7b03-4fb1-8c34-553ab568a28d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from collections import defaultdict\n",
        "import math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import datetime\n",
        "import os\n",
        "from typing import List, Tuple, Dict\n",
        "from dataclasses import dataclass\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, regularizers\n",
        "from matplotlib import pyplot as plt\n",
        "from tensorflow.python.ops import math_ops\n",
        "from sklearn.preprocessing import StandardScaler, Normalizer\n",
        "from sklearn.compose import ColumnTransformer\n",
        "\n",
        "#@title Debugging\n",
        "# See https://zohaib.me/debugging-in-google-collab-notebook/ for tips,\n",
        "# as well as docs for pdb and ipdb.\n",
        "DEBUG = False #@param {type:\"boolean\"}\n",
        "USE_LOCAL_DRIVE = False #@param {type:\"boolean\"}\n",
        "LOCAL_DIR = \"/usr/local/google/home/ruru/Downloads/variational/variational/model/\" #@param\n",
        "GDRIVE_DIR = \"MyDrive/amazon_rainforest_files/\" #@param\n",
        "FP_ROOT = LOCAL_DIR\n",
        "\n",
        "def get_model_save_location(filename) -> str:\n",
        "  root = '' if USE_LOCAL_DRIVE else '/content/drive'\n",
        "  return os.path.join(root, GDRIVE_DIR,'variational/model', filename)\n",
        "\n",
        "# Access data stored on Google Drive if not reading data locally.\n",
        "if not USE_LOCAL_DRIVE:\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive')\n",
        "  global FP_ROOT\n",
        "  FP_ROOT = os.path.join('/content/drive', GDRIVE_DIR)\n",
        "\n",
        "if DEBUG:\n",
        "    %pip install -Uqq ipdb\n",
        "    import ipdb\n",
        "    %pdb on"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GQrEv57zCb4q"
      },
      "source": [
        "# Data preparation\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_dataset(path: str):\n",
        "  df = pd.read_csv(path, encoding=\"ISO-8859-1\", sep=',')\n",
        "  df = df[df['d18O_cel_variance'].notna()]\n",
        "\n",
        "  # Family is too sparse. Too many families exist in validation/test that won't\n",
        "  # exist in train, so drop it.\n",
        "  X = df.drop([\"d18O_cel_mean\", \"d18O_cel_variance\", \"Code\", \"Family\", \"Unnamed: 0\"], axis=1)\n",
        "  Y = df[[\"d18O_cel_mean\", \"d18O_cel_variance\"]]\n",
        "  return X, Y"
      ],
      "metadata": {
        "id": "6XMee1aHfcik"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Standardization"
      ],
      "metadata": {
        "id": "DtkKhMOtb6cS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@dataclass\n",
        "class FeaturesToLabels():\n",
        "  def __init__(self, X: pd.DataFrame, Y: pd.DataFrame):\n",
        "    self.X = X\n",
        "    self.Y = Y\n",
        "\n",
        "  def as_tuple():\n",
        "    return (self.X, self.Y)\n",
        "\n",
        "\n",
        "def create_feature_scaler(X: pd.DataFrame) -> ColumnTransformer:\n",
        "  columns_to_normalize = ['lat', 'long', 'VPD', 'RH', 'PET', 'DEM', 'PA',\n",
        "       'Mean Annual Temperature', 'Mean Annual Precipitation',\n",
        "       'Iso_Oxi_Stack_mean_TERZER', 'predkrig_br_lat_ISORG',\n",
        "       'isoscape_fullmodel_d18O_prec_REGRESSION']\n",
        "  feature_scaler = ColumnTransformer([\n",
        "      ('feature_normalizer', Normalizer(), columns_to_normalize)],\n",
        "      remainder='passthrough')\n",
        "  feature_scaler.fit(X)\n",
        "  return feature_scaler\n",
        "\n",
        "def create_label_scaler(Y: pd.DataFrame) -> ColumnTransformer:\n",
        "  # CODE REVIEW QUESTION: Standardization of variances will produce negative\n",
        "  # variances. Any workarounds or should I just not try it?\n",
        "  label_scaler = ColumnTransformer([\n",
        "      ('label_std_scaler', StandardScaler(), ['d18O_cel_mean'])],\n",
        "      remainder='passthrough')\n",
        "  label_scaler.fit(Y)\n",
        "  return label_scaler\n",
        "\n",
        "def scale(X: pd.DataFrame, Y: pd.DataFrame, feature_scaler, label_scaler):\n",
        "  # transform() outputs numpy arrays :(  need to convert back to DataFrame.\n",
        "  X_standardized = pd.DataFrame(feature_scaler.transform(X),\n",
        "                        index=X.index, columns=X.columns)\n",
        "  Y_standardized = pd.DataFrame(label_scaler.transform(Y),\n",
        "                                      index=Y.index, columns=Y.columns)\n",
        "  return FeaturesToLabels(X_standardized, Y_standardized)"
      ],
      "metadata": {
        "id": "XSDwdvMkb7w8"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Just a class organization, holds each scaled dataset and the scaler used.\n",
        "# Useful for unscaling predictions.\n",
        "@dataclass\n",
        "class ScaledPartitions():\n",
        "  def __init__(self,\n",
        "               feature_scaler: ColumnTransformer,\n",
        "               label_scaler: ColumnTransformer,\n",
        "               train: FeaturesToLabels, val: FeaturesToLabels,\n",
        "               test: FeaturesToLabels):\n",
        "    self.feature_scaler = feature_scaler\n",
        "    self.label_scaler = label_scaler\n",
        "    self.train = train\n",
        "    self.val = val\n",
        "    self.test = test\n",
        "\n",
        "\n",
        "def load_and_scale(config: Dict) -> ScaledPartitions:\n",
        "  X_train, Y_train = load_dataset(config['TRAIN'])\n",
        "  X_val, Y_val = load_dataset(config['VALIDATION'])\n",
        "  X_test, Y_test = load_dataset(config['TEST'])\n",
        "\n",
        "  feature_scaler = create_feature_scaler(X_train)\n",
        "  label_scaler = create_label_scaler(Y_train)\n",
        "  train = scale(X_train, Y_train, feature_scaler, label_scaler)\n",
        "  val = scale(X_val, Y_val, feature_scaler, label_scaler)\n",
        "  test = scale(X_test, Y_test, feature_scaler, label_scaler)\n",
        "  return ScaledPartitions(feature_scaler, label_scaler, train, val, test)\n"
      ],
      "metadata": {
        "id": "_kf2e_fKon2P"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Definition\n",
        "\n"
      ],
      "metadata": {
        "id": "usGznR593LZc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The KL Loss function:"
      ],
      "metadata": {
        "id": "khK7C8WvU8ZR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# log(σ2/σ1) + ( σ1^2+(μ1−μ2)^2 ) / 2* σ^2   − 1/2\n",
        "def kl_divergence(real, predicted):\n",
        "    real_value = tf.gather(real, [0], axis=1)\n",
        "    real_std = tf.math.sqrt(tf.gather(real, [1], axis=1))\n",
        "\n",
        "    predicted_value = tf.gather(predicted, [0], axis=1)\n",
        "    predicted_std = tf.math.sqrt(tf.gather(predicted, [1], axis=1))\n",
        "\n",
        "    kl_loss = -0.5 + tf.math.log(predicted_std/real_std) + \\\n",
        "     (tf.square(real_std) + tf.square(real_value - predicted_value))/ \\\n",
        "     (2*tf.square(predicted_std))\n",
        "\n",
        "    return tf.math.reduce_mean(kl_loss)"
      ],
      "metadata": {
        "id": "urGjYNNnemX6"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test the loss function:"
      ],
      "metadata": {
        "id": "fJzBFWQVeqNE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pytest\n",
        "\n",
        "test_real = tf.convert_to_tensor(np.array([[1, 0.02]]))\n",
        "test_pred = tf.convert_to_tensor(np.array([[0.98, 0.021]]))\n",
        "\n",
        "# https://screenshot.googleplex.com/5WM9dinAbhR26ZS\n",
        "assert float(kl_divergence(test_real, test_pred)) == pytest.approx(0.0101094, 1e-5)\n",
        "\n",
        "test_neg_real = tf.convert_to_tensor(np.array([[32.32, 0.0344]]))\n",
        "test_neg_pred = tf.convert_to_tensor(np.array([[32.01, -0.322]]))\n",
        "\n",
        "# Negative variance causes NaN\n",
        "assert tf.math.is_nan(kl_divergence(test_neg_real, test_neg_pred))\n",
        "\n",
        "# Calculated manually by computing the result of this equation in wolfram alpha:\n",
        "# log(σ2/σ1) + ( σ1^2+(μ1−μ2)^2 ) / 2* σ^2   − 1/2\n",
        "test_real_2d = tf.convert_to_tensor(np.array(\n",
        "    [[1.00, 0.020],\n",
        "     [1.01, 0.042]]))\n",
        "test_pred_2d = tf.convert_to_tensor(np.array(\n",
        "    [[0.98, 0.021],\n",
        "     [0.99, 0.012]]))\n",
        "\n",
        "# Should reduce to the average loss of all rows.\n",
        "assert float(kl_divergence(test_real_2d, test_pred_2d)) == pytest.approx(\n",
        "    sum([0.0101094, 0.6402851])/2, 1e-5)"
      ],
      "metadata": {
        "id": "48TaPd70erSk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model definition"
      ],
      "metadata": {
        "id": "8rI6qPRh7oO7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "\n",
        "def get_early_stopping_callback():\n",
        "  return EarlyStopping(monitor='val_loss', patience=1000, min_delta=0.001,\n",
        "                       verbose=0, restore_best_weights=True, start_from_epoch=0)\n",
        "\n",
        "tf.keras.utils.set_random_seed(18731)\n",
        "\n",
        "# I was experimenting with models that took longer to train, and used this\n",
        "# checkpointing callback to periodically save the model. It's optional.\n",
        "def get_checkpoint_callback(model_file):\n",
        "  return ModelCheckpoint(\n",
        "      get_model_save_location(model_file),\n",
        "      monitor='val_loss', verbose=0, save_best_only=True, mode='min')\n",
        "\n",
        "def train_or_update_variational_model(\n",
        "        X: pd.DataFrame,\n",
        "        Y: pd.DataFrame,\n",
        "        hidden_layers: List[int],\n",
        "        epochs: int,\n",
        "        batch_size: int,\n",
        "        lr: float,\n",
        "        validation_data: FeaturesToLabels,\n",
        "        model_file=None,\n",
        "        use_checkpoint=False):\n",
        "  callbacks_list = [get_early_stopping_callback(),\n",
        "                    get_checkpoint_callback(model_file)]\n",
        "  if not use_checkpoint:\n",
        "    inputs = keras.Input(shape=(X.shape[1],))\n",
        "    x = inputs\n",
        "    for layer_size in hidden_layers:\n",
        "      x = keras.layers.Dense(\n",
        "          layer_size, activation='relu')(x)\n",
        "    mean_output = keras.layers.Dense(1, name='mean_output')(x)\n",
        "\n",
        "    # We can not have negative variance. Apply very little variance.\n",
        "    var_output = keras.layers.Dense(1, name='var_output')(x)\n",
        "    abs_var = keras.layers.Lambda(lambda t: tf.abs(t))(var_output)\n",
        "\n",
        "    # Output mean, |variance| tuples.\n",
        "    outputs = keras.layers.concatenate([mean_output, abs_var])\n",
        "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "    # Later epochs seem to benefit from lower learning rate... but it takes\n",
        "    # a while to get there.\n",
        "    decay = keras.optimizers.schedules.ExponentialDecay(\n",
        "       lr, decay_steps=100, decay_rate=0.5, staircase=True)\n",
        "\n",
        "    optimizer = keras.optimizers.Adam(learning_rate=lr)\n",
        "    model.compile(optimizer=optimizer, loss=kl_divergence)\n",
        "    model.summary()\n",
        "  else:\n",
        "    model = keras.models.load_model(\n",
        "        get_model_save_location(model_file),\n",
        "        custom_objects={\"kl_divergence\": kl_divergence})\n",
        "  history = model.fit(X, Y, verbose=1, epochs=epochs, batch_size=batch_size,\n",
        "                      validation_data=validation_data.as_tuple(),\n",
        "                      shuffle=True, callbacks=callbacks_list)\n",
        "  return history, model"
      ],
      "metadata": {
        "id": "HCkGSPUo3KqY"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "def render_plot_loss(history, name):\n",
        "  plt.plot(history.history['loss'])\n",
        "  plt.plot(history.history['val_loss'])\n",
        "  plt.title(name + ' model loss')\n",
        "  plt.ylabel('loss')\n",
        "  plt.yscale(\"log\")\n",
        "  plt.xlabel('epoch')\n",
        "  plt.legend(['loss', 'val_loss'], loc='upper left')\n",
        "  plt.show()\n",
        "\n",
        "def destandardize(sd: ScaledPartitions, df: pd.DataFrame):\n",
        "  means = pd.DataFrame(\n",
        "      sd.label_scaler.named_transformers_['label_std_scaler'].inverse_transform(df[['d18O_cel_mean']]),\n",
        "      index=df.index, columns=['d18O_cel_mean'])\n",
        "  vars = df['d18O_cel_variance']\n",
        "  return means.join(vars)\n",
        "\n",
        "def train_and_evaluate(sp: ScaledPartitions, run_id: str, training_batch_size=5):\n",
        "  print(\"==================\")\n",
        "  print(run_id)\n",
        "  history, model = train_or_update_variational_model(\n",
        "      sp.train.X, sp.train.Y, hidden_layers=[20, 20],\n",
        "      epochs=5000, batch_size=training_batch_size,\n",
        "      lr=0.0001, validation_data=sp.val,\n",
        "      model_file=run_id+\".h5\", use_checkpoint=False)\n",
        "  render_plot_loss(history, run_id+\" kl_loss\")\n",
        "  model.save(get_model_save_location(run_id+\".h5\"), save_format=\"h5\")\n",
        "\n",
        "  model.evaluate(x=sp.test.X, y=sp.test.Y)\n",
        "  predictions = model.predict_on_batch(sp.test.X)\n",
        "  print(\"EXPECTED:\")\n",
        "  Y_destandardized = destandardize(sp, sp.test.Y)\n",
        "  print(Y_destandardized.to_string())\n",
        "  print()\n",
        "  print(\"PREDICTED:\")\n",
        "  predictions =  destandardize(sp, pd.DataFrame(predictions, columns=['d18O_cel_mean', 'd18O_cel_variance']))\n",
        "  print(predictions.to_string())\n",
        "\n",
        "  rmse = np.sqrt(mean_squared_error(Y_destandardized['d18O_cel_mean'], predictions['d18O_cel_mean']))\n",
        "  print(\"RMSE: \"+ str(rmse))"
      ],
      "metadata": {
        "id": "DALuUm8UOgNu"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load and evaluate the model with each set of data.\n",
        "\n",
        "Use the same model configured the same way for every run, with the exception of the training batch size setting, which is 1 for grouped and 5 for ungrouped."
      ],
      "metadata": {
        "id": "WF_1T_zZtK0T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1) Ungrouped, random"
      ],
      "metadata": {
        "id": "q6vAjessuMSM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ungrouped_random = {\n",
        "    'TRAIN' : os.path.join(FP_ROOT, \"amazon_sample_data/uc_davis_2023_08_12_train_random_ungrouped.csv\"),\n",
        "    'TEST' : os.path.join(FP_ROOT, \"amazon_sample_data/uc_davis_2023_08_12_test_random_ungrouped.csv\"),\n",
        "    'VALIDATION' : os.path.join(FP_ROOT, \"amazon_sample_data/uc_davis_2023_08_12_validation_random_ungrouped.csv\"),\n",
        "}\n",
        "\n",
        "ungrouped_random_scaled = load_and_scale(ungrouped_random)\n",
        "train_and_evaluate(ungrouped_random_scaled, \"ungrouped_random\", training_batch_size=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "qM5zP9M9tQqE",
        "outputId": "1865ce7e-2084-47de-aee3-4b372066da6c"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================\n",
            "ungrouped_random\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 12)]         0           []                               \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 20)           260         ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 20)           420         ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            " var_output (Dense)             (None, 1)            21          ['dense_1[0][0]']                \n",
            "                                                                                                  \n",
            " mean_output (Dense)            (None, 1)            21          ['dense_1[0][0]']                \n",
            "                                                                                                  \n",
            " lambda (Lambda)                (None, 1)            0           ['var_output[0][0]']             \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 2)            0           ['mean_output[0][0]',            \n",
            "                                                                  'lambda[0][0]']                 \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 722\n",
            "Trainable params: 722\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/5000\n",
            "99/99 [==============================] - 3s 11ms/step - loss: 4.8927 - val_loss: 2.9635\n",
            "Epoch 2/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 3.1866 - val_loss: 2.2133\n",
            "Epoch 3/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 2.5828 - val_loss: 1.8458\n",
            "Epoch 4/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 2.2117 - val_loss: 1.6021\n",
            "Epoch 5/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 1.9386 - val_loss: 1.4165\n",
            "Epoch 6/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 1.6400 - val_loss: 1.1720\n",
            "Epoch 7/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 1.3661 - val_loss: 1.0573\n",
            "Epoch 8/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 1.2040 - val_loss: 0.9806\n",
            "Epoch 9/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 1.0886 - val_loss: 0.9258\n",
            "Epoch 10/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 1.0005 - val_loss: 0.8836\n",
            "Epoch 11/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.9302 - val_loss: 0.8514\n",
            "Epoch 12/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.8720 - val_loss: 0.8245\n",
            "Epoch 13/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.8243 - val_loss: 0.8048\n",
            "Epoch 14/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.7833 - val_loss: 0.7855\n",
            "Epoch 15/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.7484 - val_loss: 0.7703\n",
            "Epoch 16/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.7182 - val_loss: 0.7548\n",
            "Epoch 17/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.6919 - val_loss: 0.7429\n",
            "Epoch 18/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.6687 - val_loss: 0.7293\n",
            "Epoch 19/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.6484 - val_loss: 0.7199\n",
            "Epoch 20/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.6304 - val_loss: 0.7112\n",
            "Epoch 21/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.6145 - val_loss: 0.7049\n",
            "Epoch 22/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.6005 - val_loss: 0.6959\n",
            "Epoch 23/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.5876 - val_loss: 0.6892\n",
            "Epoch 24/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.5763 - val_loss: 0.6874\n",
            "Epoch 25/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.5663 - val_loss: 0.6781\n",
            "Epoch 26/5000\n",
            "99/99 [==============================] - 0s 4ms/step - loss: 0.5573 - val_loss: 0.6759\n",
            "Epoch 27/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.5492 - val_loss: 0.6714\n",
            "Epoch 28/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.5419 - val_loss: 0.6646\n",
            "Epoch 29/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.5354 - val_loss: 0.6639\n",
            "Epoch 30/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.5295 - val_loss: 0.6570\n",
            "Epoch 31/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.5241 - val_loss: 0.6573\n",
            "Epoch 32/5000\n",
            "99/99 [==============================] - 0s 4ms/step - loss: 0.5193 - val_loss: 0.6513\n",
            "Epoch 33/5000\n",
            "99/99 [==============================] - 0s 4ms/step - loss: 0.5150 - val_loss: 0.6480\n",
            "Epoch 34/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.5112 - val_loss: 0.6453\n",
            "Epoch 35/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.5077 - val_loss: 0.6451\n",
            "Epoch 36/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.5046 - val_loss: 0.6415\n",
            "Epoch 37/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.5019 - val_loss: 0.6389\n",
            "Epoch 38/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4995 - val_loss: 0.6392\n",
            "Epoch 39/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4974 - val_loss: 0.6384\n",
            "Epoch 40/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4955 - val_loss: 0.6354\n",
            "Epoch 41/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4938 - val_loss: 0.6331\n",
            "Epoch 42/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4923 - val_loss: 0.6355\n",
            "Epoch 43/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4909 - val_loss: 0.6321\n",
            "Epoch 44/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4898 - val_loss: 0.6324\n",
            "Epoch 45/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4888 - val_loss: 0.6327\n",
            "Epoch 46/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4879 - val_loss: 0.6284\n",
            "Epoch 47/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4871 - val_loss: 0.6291\n",
            "Epoch 48/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4865 - val_loss: 0.6279\n",
            "Epoch 49/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4861 - val_loss: 0.6295\n",
            "Epoch 50/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4854 - val_loss: 0.6254\n",
            "Epoch 51/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4849 - val_loss: 0.6280\n",
            "Epoch 52/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4846 - val_loss: 0.6273\n",
            "Epoch 53/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4845 - val_loss: 0.6289\n",
            "Epoch 54/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4841 - val_loss: 0.6252\n",
            "Epoch 55/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4838 - val_loss: 0.6301\n",
            "Epoch 56/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4835 - val_loss: 0.6273\n",
            "Epoch 57/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4834 - val_loss: 0.6277\n",
            "Epoch 58/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4832 - val_loss: 0.6294\n",
            "Epoch 59/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4831 - val_loss: 0.6259\n",
            "Epoch 60/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4830 - val_loss: 0.6263\n",
            "Epoch 61/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4828 - val_loss: 0.6284\n",
            "Epoch 62/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4827 - val_loss: 0.6273\n",
            "Epoch 63/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4826 - val_loss: 0.6284\n",
            "Epoch 64/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4826 - val_loss: 0.6296\n",
            "Epoch 65/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4825 - val_loss: 0.6291\n",
            "Epoch 66/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4825 - val_loss: 0.6289\n",
            "Epoch 67/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4824 - val_loss: 0.6283\n",
            "Epoch 68/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4823 - val_loss: 0.6266\n",
            "Epoch 69/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4822 - val_loss: 0.6279\n",
            "Epoch 70/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4822 - val_loss: 0.6291\n",
            "Epoch 71/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4822 - val_loss: 0.6290\n",
            "Epoch 72/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4822 - val_loss: 0.6280\n",
            "Epoch 73/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4821 - val_loss: 0.6244\n",
            "Epoch 74/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4821 - val_loss: 0.6300\n",
            "Epoch 75/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4820 - val_loss: 0.6258\n",
            "Epoch 76/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4819 - val_loss: 0.6273\n",
            "Epoch 77/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4819 - val_loss: 0.6263\n",
            "Epoch 78/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4820 - val_loss: 0.6255\n",
            "Epoch 79/5000\n",
            "99/99 [==============================] - 0s 4ms/step - loss: 0.4819 - val_loss: 0.6250\n",
            "Epoch 80/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4820 - val_loss: 0.6238\n",
            "Epoch 81/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4820 - val_loss: 0.6250\n",
            "Epoch 82/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4817 - val_loss: 0.6243\n",
            "Epoch 83/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4817 - val_loss: 0.6201\n",
            "Epoch 84/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4816 - val_loss: 0.6262\n",
            "Epoch 85/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4817 - val_loss: 0.6250\n",
            "Epoch 86/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4816 - val_loss: 0.6291\n",
            "Epoch 87/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4816 - val_loss: 0.6206\n",
            "Epoch 88/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4813 - val_loss: 0.6191\n",
            "Epoch 89/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4812 - val_loss: 0.6211\n",
            "Epoch 90/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4812 - val_loss: 0.6238\n",
            "Epoch 91/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4812 - val_loss: 0.6208\n",
            "Epoch 92/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4811 - val_loss: 0.6214\n",
            "Epoch 93/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4812 - val_loss: 0.6212\n",
            "Epoch 94/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4811 - val_loss: 0.6213\n",
            "Epoch 95/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4810 - val_loss: 0.6179\n",
            "Epoch 96/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4810 - val_loss: 0.6219\n",
            "Epoch 97/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4808 - val_loss: 0.6194\n",
            "Epoch 98/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4808 - val_loss: 0.6213\n",
            "Epoch 99/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4807 - val_loss: 0.6191\n",
            "Epoch 100/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4808 - val_loss: 0.6213\n",
            "Epoch 101/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4806 - val_loss: 0.6167\n",
            "Epoch 102/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4805 - val_loss: 0.6183\n",
            "Epoch 103/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4805 - val_loss: 0.6191\n",
            "Epoch 104/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4804 - val_loss: 0.6192\n",
            "Epoch 105/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4806 - val_loss: 0.6167\n",
            "Epoch 106/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4803 - val_loss: 0.6192\n",
            "Epoch 107/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4804 - val_loss: 0.6210\n",
            "Epoch 108/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4803 - val_loss: 0.6155\n",
            "Epoch 109/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4801 - val_loss: 0.6188\n",
            "Epoch 110/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4801 - val_loss: 0.6114\n",
            "Epoch 111/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4799 - val_loss: 0.6133\n",
            "Epoch 112/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4799 - val_loss: 0.6148\n",
            "Epoch 113/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4797 - val_loss: 0.6172\n",
            "Epoch 114/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4799 - val_loss: 0.6166\n",
            "Epoch 115/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4797 - val_loss: 0.6157\n",
            "Epoch 116/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4797 - val_loss: 0.6097\n",
            "Epoch 117/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4796 - val_loss: 0.6143\n",
            "Epoch 118/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4794 - val_loss: 0.6085\n",
            "Epoch 119/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4793 - val_loss: 0.6097\n",
            "Epoch 120/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4794 - val_loss: 0.6104\n",
            "Epoch 121/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4789 - val_loss: 0.6058\n",
            "Epoch 122/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4787 - val_loss: 0.6033\n",
            "Epoch 123/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4783 - val_loss: 0.6055\n",
            "Epoch 124/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4781 - val_loss: 0.6033\n",
            "Epoch 125/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4779 - val_loss: 0.6069\n",
            "Epoch 126/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4779 - val_loss: 0.6089\n",
            "Epoch 127/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4780 - val_loss: 0.5995\n",
            "Epoch 128/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4777 - val_loss: 0.6030\n",
            "Epoch 129/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4774 - val_loss: 0.5975\n",
            "Epoch 130/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4776 - val_loss: 0.6028\n",
            "Epoch 131/5000\n",
            "99/99 [==============================] - 0s 4ms/step - loss: 0.4771 - val_loss: 0.5913\n",
            "Epoch 132/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4769 - val_loss: 0.5957\n",
            "Epoch 133/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4769 - val_loss: 0.5941\n",
            "Epoch 134/5000\n",
            "99/99 [==============================] - 0s 4ms/step - loss: 0.4767 - val_loss: 0.5948\n",
            "Epoch 135/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4765 - val_loss: 0.5945\n",
            "Epoch 136/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4765 - val_loss: 0.5928\n",
            "Epoch 137/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4763 - val_loss: 0.5898\n",
            "Epoch 138/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4761 - val_loss: 0.5961\n",
            "Epoch 139/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4759 - val_loss: 0.5945\n",
            "Epoch 140/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4759 - val_loss: 0.5954\n",
            "Epoch 141/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4756 - val_loss: 0.5928\n",
            "Epoch 142/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4750 - val_loss: 0.5859\n",
            "Epoch 143/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4746 - val_loss: 0.5900\n",
            "Epoch 144/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4740 - val_loss: 0.5869\n",
            "Epoch 145/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4737 - val_loss: 0.5881\n",
            "Epoch 146/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4736 - val_loss: 0.5855\n",
            "Epoch 147/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4735 - val_loss: 0.5878\n",
            "Epoch 148/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4732 - val_loss: 0.5885\n",
            "Epoch 149/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4727 - val_loss: 0.5866\n",
            "Epoch 150/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4725 - val_loss: 0.5828\n",
            "Epoch 151/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4722 - val_loss: 0.5845\n",
            "Epoch 152/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4720 - val_loss: 0.5820\n",
            "Epoch 153/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4716 - val_loss: 0.5794\n",
            "Epoch 154/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4717 - val_loss: 0.5787\n",
            "Epoch 155/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4716 - val_loss: 0.5772\n",
            "Epoch 156/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4711 - val_loss: 0.5772\n",
            "Epoch 157/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4707 - val_loss: 0.5765\n",
            "Epoch 158/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4706 - val_loss: 0.5742\n",
            "Epoch 159/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4704 - val_loss: 0.5749\n",
            "Epoch 160/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4701 - val_loss: 0.5720\n",
            "Epoch 161/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4699 - val_loss: 0.5677\n",
            "Epoch 162/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4695 - val_loss: 0.5686\n",
            "Epoch 163/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4697 - val_loss: 0.5700\n",
            "Epoch 164/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4693 - val_loss: 0.5644\n",
            "Epoch 165/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4687 - val_loss: 0.5669\n",
            "Epoch 166/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4685 - val_loss: 0.5642\n",
            "Epoch 167/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4684 - val_loss: 0.5626\n",
            "Epoch 168/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4683 - val_loss: 0.5601\n",
            "Epoch 169/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4678 - val_loss: 0.5599\n",
            "Epoch 170/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4678 - val_loss: 0.5606\n",
            "Epoch 171/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4673 - val_loss: 0.5624\n",
            "Epoch 172/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4673 - val_loss: 0.5580\n",
            "Epoch 173/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4668 - val_loss: 0.5564\n",
            "Epoch 174/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4666 - val_loss: 0.5574\n",
            "Epoch 175/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4664 - val_loss: 0.5569\n",
            "Epoch 176/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4660 - val_loss: 0.5536\n",
            "Epoch 177/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4658 - val_loss: 0.5548\n",
            "Epoch 178/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4656 - val_loss: 0.5482\n",
            "Epoch 179/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4651 - val_loss: 0.5506\n",
            "Epoch 180/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4650 - val_loss: 0.5489\n",
            "Epoch 181/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4647 - val_loss: 0.5473\n",
            "Epoch 182/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4644 - val_loss: 0.5463\n",
            "Epoch 183/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4644 - val_loss: 0.5481\n",
            "Epoch 184/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4640 - val_loss: 0.5458\n",
            "Epoch 185/5000\n",
            "99/99 [==============================] - 0s 4ms/step - loss: 0.4639 - val_loss: 0.5439\n",
            "Epoch 186/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4636 - val_loss: 0.5392\n",
            "Epoch 187/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4633 - val_loss: 0.5393\n",
            "Epoch 188/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4629 - val_loss: 0.5378\n",
            "Epoch 189/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4629 - val_loss: 0.5327\n",
            "Epoch 190/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4622 - val_loss: 0.5348\n",
            "Epoch 191/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4622 - val_loss: 0.5394\n",
            "Epoch 192/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4619 - val_loss: 0.5339\n",
            "Epoch 193/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4617 - val_loss: 0.5337\n",
            "Epoch 194/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4613 - val_loss: 0.5284\n",
            "Epoch 195/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4613 - val_loss: 0.5249\n",
            "Epoch 196/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4610 - val_loss: 0.5270\n",
            "Epoch 197/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4606 - val_loss: 0.5283\n",
            "Epoch 198/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4605 - val_loss: 0.5212\n",
            "Epoch 199/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4601 - val_loss: 0.5229\n",
            "Epoch 200/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4598 - val_loss: 0.5226\n",
            "Epoch 201/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4594 - val_loss: 0.5220\n",
            "Epoch 202/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4594 - val_loss: 0.5198\n",
            "Epoch 203/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4591 - val_loss: 0.5179\n",
            "Epoch 204/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4591 - val_loss: 0.5114\n",
            "Epoch 205/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4586 - val_loss: 0.5115\n",
            "Epoch 206/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4583 - val_loss: 0.5156\n",
            "Epoch 207/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4586 - val_loss: 0.5163\n",
            "Epoch 208/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4576 - val_loss: 0.5098\n",
            "Epoch 209/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4575 - val_loss: 0.5100\n",
            "Epoch 210/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4573 - val_loss: 0.5071\n",
            "Epoch 211/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4574 - val_loss: 0.5064\n",
            "Epoch 212/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4570 - val_loss: 0.5060\n",
            "Epoch 213/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4567 - val_loss: 0.4996\n",
            "Epoch 214/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4564 - val_loss: 0.5036\n",
            "Epoch 215/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4561 - val_loss: 0.5047\n",
            "Epoch 216/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4562 - val_loss: 0.4975\n",
            "Epoch 217/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4558 - val_loss: 0.4975\n",
            "Epoch 218/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4553 - val_loss: 0.4976\n",
            "Epoch 219/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4552 - val_loss: 0.4978\n",
            "Epoch 220/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4549 - val_loss: 0.4994\n",
            "Epoch 221/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4547 - val_loss: 0.4961\n",
            "Epoch 222/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4547 - val_loss: 0.4999\n",
            "Epoch 223/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4543 - val_loss: 0.4897\n",
            "Epoch 224/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4542 - val_loss: 0.4950\n",
            "Epoch 225/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4540 - val_loss: 0.4887\n",
            "Epoch 226/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4534 - val_loss: 0.4887\n",
            "Epoch 227/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4535 - val_loss: 0.4877\n",
            "Epoch 228/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4531 - val_loss: 0.4871\n",
            "Epoch 229/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4528 - val_loss: 0.4824\n",
            "Epoch 230/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4526 - val_loss: 0.4831\n",
            "Epoch 231/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4527 - val_loss: 0.4791\n",
            "Epoch 232/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4520 - val_loss: 0.4822\n",
            "Epoch 233/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4522 - val_loss: 0.4814\n",
            "Epoch 234/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4519 - val_loss: 0.4808\n",
            "Epoch 235/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4515 - val_loss: 0.4772\n",
            "Epoch 236/5000\n",
            "99/99 [==============================] - 0s 4ms/step - loss: 0.4514 - val_loss: 0.4751\n",
            "Epoch 237/5000\n",
            "99/99 [==============================] - 0s 4ms/step - loss: 0.4510 - val_loss: 0.4730\n",
            "Epoch 238/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4508 - val_loss: 0.4736\n",
            "Epoch 239/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4507 - val_loss: 0.4737\n",
            "Epoch 240/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4505 - val_loss: 0.4716\n",
            "Epoch 241/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4504 - val_loss: 0.4681\n",
            "Epoch 242/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4502 - val_loss: 0.4652\n",
            "Epoch 243/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4503 - val_loss: 0.4657\n",
            "Epoch 244/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4497 - val_loss: 0.4673\n",
            "Epoch 245/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4494 - val_loss: 0.4649\n",
            "Epoch 246/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4498 - val_loss: 0.4671\n",
            "Epoch 247/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4494 - val_loss: 0.4646\n",
            "Epoch 248/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4490 - val_loss: 0.4668\n",
            "Epoch 249/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4486 - val_loss: 0.4627\n",
            "Epoch 250/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4486 - val_loss: 0.4612\n",
            "Epoch 251/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4487 - val_loss: 0.4615\n",
            "Epoch 252/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4482 - val_loss: 0.4606\n",
            "Epoch 253/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4481 - val_loss: 0.4621\n",
            "Epoch 254/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4477 - val_loss: 0.4542\n",
            "Epoch 255/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4474 - val_loss: 0.4573\n",
            "Epoch 256/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4475 - val_loss: 0.4545\n",
            "Epoch 257/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4472 - val_loss: 0.4555\n",
            "Epoch 258/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4469 - val_loss: 0.4530\n",
            "Epoch 259/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4471 - val_loss: 0.4526\n",
            "Epoch 260/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4465 - val_loss: 0.4496\n",
            "Epoch 261/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4465 - val_loss: 0.4490\n",
            "Epoch 262/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4464 - val_loss: 0.4443\n",
            "Epoch 263/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4461 - val_loss: 0.4403\n",
            "Epoch 264/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4464 - val_loss: 0.4441\n",
            "Epoch 265/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4460 - val_loss: 0.4404\n",
            "Epoch 266/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4456 - val_loss: 0.4374\n",
            "Epoch 267/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4455 - val_loss: 0.4418\n",
            "Epoch 268/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4450 - val_loss: 0.4411\n",
            "Epoch 269/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4454 - val_loss: 0.4369\n",
            "Epoch 270/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4455 - val_loss: 0.4407\n",
            "Epoch 271/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4449 - val_loss: 0.4402\n",
            "Epoch 272/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4448 - val_loss: 0.4382\n",
            "Epoch 273/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4446 - val_loss: 0.4367\n",
            "Epoch 274/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4440 - val_loss: 0.4360\n",
            "Epoch 275/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4442 - val_loss: 0.4353\n",
            "Epoch 276/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4440 - val_loss: 0.4316\n",
            "Epoch 277/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4439 - val_loss: 0.4326\n",
            "Epoch 278/5000\n",
            "99/99 [==============================] - 0s 4ms/step - loss: 0.4434 - val_loss: 0.4295\n",
            "Epoch 279/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4432 - val_loss: 0.4336\n",
            "Epoch 280/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4432 - val_loss: 0.4290\n",
            "Epoch 281/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4430 - val_loss: 0.4285\n",
            "Epoch 282/5000\n",
            "99/99 [==============================] - 0s 4ms/step - loss: 0.4430 - val_loss: 0.4267\n",
            "Epoch 283/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4430 - val_loss: 0.4293\n",
            "Epoch 284/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4427 - val_loss: 0.4306\n",
            "Epoch 285/5000\n",
            "99/99 [==============================] - 0s 4ms/step - loss: 0.4429 - val_loss: 0.4241\n",
            "Epoch 286/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4425 - val_loss: 0.4223\n",
            "Epoch 287/5000\n",
            "99/99 [==============================] - 0s 4ms/step - loss: 0.4430 - val_loss: 0.4129\n",
            "Epoch 288/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4420 - val_loss: 0.4215\n",
            "Epoch 289/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4422 - val_loss: 0.4199\n",
            "Epoch 290/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4420 - val_loss: 0.4192\n",
            "Epoch 291/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4419 - val_loss: 0.4199\n",
            "Epoch 292/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4416 - val_loss: 0.4194\n",
            "Epoch 293/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4416 - val_loss: 0.4199\n",
            "Epoch 294/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4415 - val_loss: 0.4222\n",
            "Epoch 295/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4416 - val_loss: 0.4126\n",
            "Epoch 296/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4410 - val_loss: 0.4142\n",
            "Epoch 297/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4412 - val_loss: 0.4164\n",
            "Epoch 298/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4410 - val_loss: 0.4157\n",
            "Epoch 299/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4407 - val_loss: 0.4113\n",
            "Epoch 300/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4408 - val_loss: 0.4183\n",
            "Epoch 301/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4408 - val_loss: 0.4160\n",
            "Epoch 302/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4408 - val_loss: 0.4158\n",
            "Epoch 303/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4401 - val_loss: 0.4117\n",
            "Epoch 304/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4400 - val_loss: 0.4070\n",
            "Epoch 305/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4399 - val_loss: 0.4066\n",
            "Epoch 306/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4404 - val_loss: 0.4044\n",
            "Epoch 307/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4398 - val_loss: 0.4034\n",
            "Epoch 308/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4401 - val_loss: 0.4026\n",
            "Epoch 309/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4396 - val_loss: 0.4047\n",
            "Epoch 310/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4393 - val_loss: 0.4059\n",
            "Epoch 311/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4392 - val_loss: 0.4057\n",
            "Epoch 312/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4388 - val_loss: 0.4030\n",
            "Epoch 313/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4391 - val_loss: 0.3988\n",
            "Epoch 314/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4390 - val_loss: 0.4024\n",
            "Epoch 315/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4387 - val_loss: 0.4020\n",
            "Epoch 316/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4384 - val_loss: 0.4015\n",
            "Epoch 317/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4386 - val_loss: 0.3991\n",
            "Epoch 318/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4389 - val_loss: 0.3926\n",
            "Epoch 319/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4384 - val_loss: 0.3974\n",
            "Epoch 320/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4386 - val_loss: 0.3963\n",
            "Epoch 321/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4379 - val_loss: 0.4002\n",
            "Epoch 322/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4385 - val_loss: 0.3960\n",
            "Epoch 323/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4380 - val_loss: 0.3932\n",
            "Epoch 324/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4381 - val_loss: 0.3946\n",
            "Epoch 325/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4381 - val_loss: 0.3964\n",
            "Epoch 326/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4376 - val_loss: 0.3899\n",
            "Epoch 327/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4382 - val_loss: 0.3911\n",
            "Epoch 328/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4374 - val_loss: 0.3926\n",
            "Epoch 329/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4371 - val_loss: 0.3915\n",
            "Epoch 330/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4373 - val_loss: 0.3951\n",
            "Epoch 331/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4371 - val_loss: 0.3878\n",
            "Epoch 332/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4370 - val_loss: 0.3877\n",
            "Epoch 333/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4373 - val_loss: 0.3895\n",
            "Epoch 334/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4369 - val_loss: 0.3932\n",
            "Epoch 335/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4372 - val_loss: 0.3899\n",
            "Epoch 336/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4366 - val_loss: 0.3893\n",
            "Epoch 337/5000\n",
            "99/99 [==============================] - 0s 4ms/step - loss: 0.4369 - val_loss: 0.3873\n",
            "Epoch 338/5000\n",
            "99/99 [==============================] - 0s 4ms/step - loss: 0.4368 - val_loss: 0.3797\n",
            "Epoch 339/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4362 - val_loss: 0.3838\n",
            "Epoch 340/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4362 - val_loss: 0.3830\n",
            "Epoch 341/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4366 - val_loss: 0.3815\n",
            "Epoch 342/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4358 - val_loss: 0.3862\n",
            "Epoch 343/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4365 - val_loss: 0.3865\n",
            "Epoch 344/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4360 - val_loss: 0.3855\n",
            "Epoch 345/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4359 - val_loss: 0.3849\n",
            "Epoch 346/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4361 - val_loss: 0.3861\n",
            "Epoch 347/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4357 - val_loss: 0.3819\n",
            "Epoch 348/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4355 - val_loss: 0.3799\n",
            "Epoch 349/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4355 - val_loss: 0.3791\n",
            "Epoch 350/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4357 - val_loss: 0.3809\n",
            "Epoch 351/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4356 - val_loss: 0.3794\n",
            "Epoch 352/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4351 - val_loss: 0.3768\n",
            "Epoch 353/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4353 - val_loss: 0.3757\n",
            "Epoch 354/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4352 - val_loss: 0.3782\n",
            "Epoch 355/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4355 - val_loss: 0.3760\n",
            "Epoch 356/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4349 - val_loss: 0.3756\n",
            "Epoch 357/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4347 - val_loss: 0.3756\n",
            "Epoch 358/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4349 - val_loss: 0.3790\n",
            "Epoch 359/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4347 - val_loss: 0.3760\n",
            "Epoch 360/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4352 - val_loss: 0.3766\n",
            "Epoch 361/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4347 - val_loss: 0.3762\n",
            "Epoch 362/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4345 - val_loss: 0.3737\n",
            "Epoch 363/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4345 - val_loss: 0.3723\n",
            "Epoch 364/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4343 - val_loss: 0.3734\n",
            "Epoch 365/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4343 - val_loss: 0.3720\n",
            "Epoch 366/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4344 - val_loss: 0.3682\n",
            "Epoch 367/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4340 - val_loss: 0.3720\n",
            "Epoch 368/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4342 - val_loss: 0.3696\n",
            "Epoch 369/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4348 - val_loss: 0.3725\n",
            "Epoch 370/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4351 - val_loss: 0.3733\n",
            "Epoch 371/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4341 - val_loss: 0.3721\n",
            "Epoch 372/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4338 - val_loss: 0.3702\n",
            "Epoch 373/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4340 - val_loss: 0.3679\n",
            "Epoch 374/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4338 - val_loss: 0.3667\n",
            "Epoch 375/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4336 - val_loss: 0.3686\n",
            "Epoch 376/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4333 - val_loss: 0.3676\n",
            "Epoch 377/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4334 - val_loss: 0.3683\n",
            "Epoch 378/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4341 - val_loss: 0.3675\n",
            "Epoch 379/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4332 - val_loss: 0.3676\n",
            "Epoch 380/5000\n",
            "99/99 [==============================] - 0s 4ms/step - loss: 0.4333 - val_loss: 0.3655\n",
            "Epoch 381/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4336 - val_loss: 0.3675\n",
            "Epoch 382/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4331 - val_loss: 0.3669\n",
            "Epoch 383/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4329 - val_loss: 0.3674\n",
            "Epoch 384/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4330 - val_loss: 0.3672\n",
            "Epoch 385/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4330 - val_loss: 0.3615\n",
            "Epoch 386/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4327 - val_loss: 0.3649\n",
            "Epoch 387/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4329 - val_loss: 0.3656\n",
            "Epoch 388/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4326 - val_loss: 0.3633\n",
            "Epoch 389/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4328 - val_loss: 0.3635\n",
            "Epoch 390/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4329 - val_loss: 0.3637\n",
            "Epoch 391/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4327 - val_loss: 0.3615\n",
            "Epoch 392/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4325 - val_loss: 0.3619\n",
            "Epoch 393/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4323 - val_loss: 0.3601\n",
            "Epoch 394/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4324 - val_loss: 0.3626\n",
            "Epoch 395/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4324 - val_loss: 0.3610\n",
            "Epoch 396/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4322 - val_loss: 0.3602\n",
            "Epoch 397/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4323 - val_loss: 0.3597\n",
            "Epoch 398/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4321 - val_loss: 0.3602\n",
            "Epoch 399/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4324 - val_loss: 0.3654\n",
            "Epoch 400/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4321 - val_loss: 0.3628\n",
            "Epoch 401/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4320 - val_loss: 0.3589\n",
            "Epoch 402/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4317 - val_loss: 0.3589\n",
            "Epoch 403/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4317 - val_loss: 0.3596\n",
            "Epoch 404/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4320 - val_loss: 0.3636\n",
            "Epoch 405/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4316 - val_loss: 0.3580\n",
            "Epoch 406/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4316 - val_loss: 0.3633\n",
            "Epoch 407/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4321 - val_loss: 0.3556\n",
            "Epoch 408/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4318 - val_loss: 0.3553\n",
            "Epoch 409/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4314 - val_loss: 0.3580\n",
            "Epoch 410/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4317 - val_loss: 0.3589\n",
            "Epoch 411/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4311 - val_loss: 0.3620\n",
            "Epoch 412/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4317 - val_loss: 0.3551\n",
            "Epoch 413/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4313 - val_loss: 0.3552\n",
            "Epoch 414/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4311 - val_loss: 0.3554\n",
            "Epoch 415/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4312 - val_loss: 0.3571\n",
            "Epoch 416/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4310 - val_loss: 0.3557\n",
            "Epoch 417/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4314 - val_loss: 0.3601\n",
            "Epoch 418/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4310 - val_loss: 0.3561\n",
            "Epoch 419/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4309 - val_loss: 0.3531\n",
            "Epoch 420/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4309 - val_loss: 0.3568\n",
            "Epoch 421/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4310 - val_loss: 0.3526\n",
            "Epoch 422/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4308 - val_loss: 0.3491\n",
            "Epoch 423/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4305 - val_loss: 0.3556\n",
            "Epoch 424/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4308 - val_loss: 0.3537\n",
            "Epoch 425/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4306 - val_loss: 0.3510\n",
            "Epoch 426/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4304 - val_loss: 0.3524\n",
            "Epoch 427/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4304 - val_loss: 0.3531\n",
            "Epoch 428/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4302 - val_loss: 0.3498\n",
            "Epoch 429/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4300 - val_loss: 0.3532\n",
            "Epoch 430/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4302 - val_loss: 0.3490\n",
            "Epoch 431/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4302 - val_loss: 0.3516\n",
            "Epoch 432/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4300 - val_loss: 0.3526\n",
            "Epoch 433/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4301 - val_loss: 0.3491\n",
            "Epoch 434/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4308 - val_loss: 0.3553\n",
            "Epoch 435/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4299 - val_loss: 0.3495\n",
            "Epoch 436/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4301 - val_loss: 0.3511\n",
            "Epoch 437/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4300 - val_loss: 0.3482\n",
            "Epoch 438/5000\n",
            "99/99 [==============================] - 0s 4ms/step - loss: 0.4302 - val_loss: 0.3521\n",
            "Epoch 439/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4306 - val_loss: 0.3491\n",
            "Epoch 440/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4297 - val_loss: 0.3538\n",
            "Epoch 441/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4296 - val_loss: 0.3461\n",
            "Epoch 442/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4296 - val_loss: 0.3496\n",
            "Epoch 443/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4298 - val_loss: 0.3480\n",
            "Epoch 444/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4294 - val_loss: 0.3482\n",
            "Epoch 445/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4294 - val_loss: 0.3494\n",
            "Epoch 446/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4296 - val_loss: 0.3463\n",
            "Epoch 447/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4292 - val_loss: 0.3481\n",
            "Epoch 448/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4291 - val_loss: 0.3471\n",
            "Epoch 449/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4295 - val_loss: 0.3484\n",
            "Epoch 450/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4293 - val_loss: 0.3483\n",
            "Epoch 451/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4293 - val_loss: 0.3487\n",
            "Epoch 452/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4295 - val_loss: 0.3458\n",
            "Epoch 453/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4292 - val_loss: 0.3488\n",
            "Epoch 454/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4289 - val_loss: 0.3472\n",
            "Epoch 455/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4292 - val_loss: 0.3493\n",
            "Epoch 456/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4291 - val_loss: 0.3458\n",
            "Epoch 457/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4287 - val_loss: 0.3487\n",
            "Epoch 458/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4290 - val_loss: 0.3522\n",
            "Epoch 459/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4289 - val_loss: 0.3457\n",
            "Epoch 460/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4285 - val_loss: 0.3420\n",
            "Epoch 461/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4294 - val_loss: 0.3516\n",
            "Epoch 462/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4290 - val_loss: 0.3540\n",
            "Epoch 463/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4286 - val_loss: 0.3466\n",
            "Epoch 464/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4285 - val_loss: 0.3451\n",
            "Epoch 465/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4287 - val_loss: 0.3524\n",
            "Epoch 466/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4286 - val_loss: 0.3512\n",
            "Epoch 467/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4286 - val_loss: 0.3478\n",
            "Epoch 468/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4284 - val_loss: 0.3471\n",
            "Epoch 469/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4281 - val_loss: 0.3478\n",
            "Epoch 470/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4282 - val_loss: 0.3475\n",
            "Epoch 471/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4281 - val_loss: 0.3433\n",
            "Epoch 472/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4281 - val_loss: 0.3418\n",
            "Epoch 473/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4279 - val_loss: 0.3453\n",
            "Epoch 474/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4280 - val_loss: 0.3455\n",
            "Epoch 475/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4281 - val_loss: 0.3461\n",
            "Epoch 476/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4279 - val_loss: 0.3466\n",
            "Epoch 477/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4276 - val_loss: 0.3450\n",
            "Epoch 478/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4279 - val_loss: 0.3456\n",
            "Epoch 479/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4278 - val_loss: 0.3441\n",
            "Epoch 480/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4274 - val_loss: 0.3412\n",
            "Epoch 481/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4278 - val_loss: 0.3433\n",
            "Epoch 482/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4285 - val_loss: 0.3418\n",
            "Epoch 483/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4281 - val_loss: 0.3460\n",
            "Epoch 484/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4275 - val_loss: 0.3439\n",
            "Epoch 485/5000\n",
            "99/99 [==============================] - 0s 4ms/step - loss: 0.4279 - val_loss: 0.3430\n",
            "Epoch 486/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4274 - val_loss: 0.3446\n",
            "Epoch 487/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4270 - val_loss: 0.3429\n",
            "Epoch 488/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4278 - val_loss: 0.3420\n",
            "Epoch 489/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4272 - val_loss: 0.3446\n",
            "Epoch 490/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4271 - val_loss: 0.3443\n",
            "Epoch 491/5000\n",
            "99/99 [==============================] - 0s 4ms/step - loss: 0.4278 - val_loss: 0.3459\n",
            "Epoch 492/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4273 - val_loss: 0.3424\n",
            "Epoch 493/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4271 - val_loss: 0.3451\n",
            "Epoch 494/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4273 - val_loss: 0.3452\n",
            "Epoch 495/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4270 - val_loss: 0.3437\n",
            "Epoch 496/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4270 - val_loss: 0.3461\n",
            "Epoch 497/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4272 - val_loss: 0.3426\n",
            "Epoch 498/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4269 - val_loss: 0.3424\n",
            "Epoch 499/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4273 - val_loss: 0.3418\n",
            "Epoch 500/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4268 - val_loss: 0.3464\n",
            "Epoch 501/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4278 - val_loss: 0.3453\n",
            "Epoch 502/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4268 - val_loss: 0.3437\n",
            "Epoch 503/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4266 - val_loss: 0.3417\n",
            "Epoch 504/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4267 - val_loss: 0.3480\n",
            "Epoch 505/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4269 - val_loss: 0.3490\n",
            "Epoch 506/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4268 - val_loss: 0.3481\n",
            "Epoch 507/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4265 - val_loss: 0.3435\n",
            "Epoch 508/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4266 - val_loss: 0.3455\n",
            "Epoch 509/5000\n",
            "99/99 [==============================] - 1s 5ms/step - loss: 0.4267 - val_loss: 0.3410\n",
            "Epoch 510/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4266 - val_loss: 0.3465\n",
            "Epoch 511/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4265 - val_loss: 0.3456\n",
            "Epoch 512/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4268 - val_loss: 0.3406\n",
            "Epoch 513/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4264 - val_loss: 0.3429\n",
            "Epoch 514/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4262 - val_loss: 0.3432\n",
            "Epoch 515/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4265 - val_loss: 0.3433\n",
            "Epoch 516/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4263 - val_loss: 0.3420\n",
            "Epoch 517/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4259 - val_loss: 0.3406\n",
            "Epoch 518/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4271 - val_loss: 0.3419\n",
            "Epoch 519/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4261 - val_loss: 0.3467\n",
            "Epoch 520/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4260 - val_loss: 0.3448\n",
            "Epoch 521/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4257 - val_loss: 0.3448\n",
            "Epoch 522/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4257 - val_loss: 0.3430\n",
            "Epoch 523/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4266 - val_loss: 0.3389\n",
            "Epoch 524/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4259 - val_loss: 0.3439\n",
            "Epoch 525/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4256 - val_loss: 0.3437\n",
            "Epoch 526/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4258 - val_loss: 0.3414\n",
            "Epoch 527/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4255 - val_loss: 0.3416\n",
            "Epoch 528/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4256 - val_loss: 0.3420\n",
            "Epoch 529/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4264 - val_loss: 0.3407\n",
            "Epoch 530/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4262 - val_loss: 0.3437\n",
            "Epoch 531/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4256 - val_loss: 0.3470\n",
            "Epoch 532/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4261 - val_loss: 0.3443\n",
            "Epoch 533/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4254 - val_loss: 0.3412\n",
            "Epoch 534/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4256 - val_loss: 0.3402\n",
            "Epoch 535/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4260 - val_loss: 0.3445\n",
            "Epoch 536/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4259 - val_loss: 0.3455\n",
            "Epoch 537/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4252 - val_loss: 0.3417\n",
            "Epoch 538/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4252 - val_loss: 0.3472\n",
            "Epoch 539/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4251 - val_loss: 0.3436\n",
            "Epoch 540/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4250 - val_loss: 0.3406\n",
            "Epoch 541/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4256 - val_loss: 0.3419\n",
            "Epoch 542/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4251 - val_loss: 0.3443\n",
            "Epoch 543/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4253 - val_loss: 0.3419\n",
            "Epoch 544/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4254 - val_loss: 0.3412\n",
            "Epoch 545/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4248 - val_loss: 0.3422\n",
            "Epoch 546/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4248 - val_loss: 0.3399\n",
            "Epoch 547/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4245 - val_loss: 0.3429\n",
            "Epoch 548/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4246 - val_loss: 0.3417\n",
            "Epoch 549/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4252 - val_loss: 0.3461\n",
            "Epoch 550/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4247 - val_loss: 0.3423\n",
            "Epoch 551/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4246 - val_loss: 0.3412\n",
            "Epoch 552/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4246 - val_loss: 0.3394\n",
            "Epoch 553/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4249 - val_loss: 0.3436\n",
            "Epoch 554/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4246 - val_loss: 0.3437\n",
            "Epoch 555/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4250 - val_loss: 0.3462\n",
            "Epoch 556/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4248 - val_loss: 0.3438\n",
            "Epoch 557/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4245 - val_loss: 0.3464\n",
            "Epoch 558/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4242 - val_loss: 0.3426\n",
            "Epoch 559/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4246 - val_loss: 0.3439\n",
            "Epoch 560/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4243 - val_loss: 0.3453\n",
            "Epoch 561/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4241 - val_loss: 0.3432\n",
            "Epoch 562/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4244 - val_loss: 0.3423\n",
            "Epoch 563/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4246 - val_loss: 0.3479\n",
            "Epoch 564/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4244 - val_loss: 0.3413\n",
            "Epoch 565/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4252 - val_loss: 0.3440\n",
            "Epoch 566/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4243 - val_loss: 0.3464\n",
            "Epoch 567/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4240 - val_loss: 0.3397\n",
            "Epoch 568/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4240 - val_loss: 0.3425\n",
            "Epoch 569/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4237 - val_loss: 0.3412\n",
            "Epoch 570/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4239 - val_loss: 0.3412\n",
            "Epoch 571/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4239 - val_loss: 0.3446\n",
            "Epoch 572/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4238 - val_loss: 0.3421\n",
            "Epoch 573/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4238 - val_loss: 0.3399\n",
            "Epoch 574/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4242 - val_loss: 0.3427\n",
            "Epoch 575/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4236 - val_loss: 0.3430\n",
            "Epoch 576/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4243 - val_loss: 0.3426\n",
            "Epoch 577/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4239 - val_loss: 0.3420\n",
            "Epoch 578/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4236 - val_loss: 0.3422\n",
            "Epoch 579/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4237 - val_loss: 0.3454\n",
            "Epoch 580/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4250 - val_loss: 0.3438\n",
            "Epoch 581/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4234 - val_loss: 0.3422\n",
            "Epoch 582/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4237 - val_loss: 0.3434\n",
            "Epoch 583/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4233 - val_loss: 0.3398\n",
            "Epoch 584/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4232 - val_loss: 0.3419\n",
            "Epoch 585/5000\n",
            "99/99 [==============================] - 0s 4ms/step - loss: 0.4232 - val_loss: 0.3441\n",
            "Epoch 586/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4235 - val_loss: 0.3441\n",
            "Epoch 587/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4234 - val_loss: 0.3441\n",
            "Epoch 588/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4233 - val_loss: 0.3430\n",
            "Epoch 589/5000\n",
            "99/99 [==============================] - 0s 4ms/step - loss: 0.4231 - val_loss: 0.3444\n",
            "Epoch 590/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4239 - val_loss: 0.3487\n",
            "Epoch 591/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4232 - val_loss: 0.3465\n",
            "Epoch 592/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4229 - val_loss: 0.3448\n",
            "Epoch 593/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4228 - val_loss: 0.3422\n",
            "Epoch 594/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4230 - val_loss: 0.3392\n",
            "Epoch 595/5000\n",
            "99/99 [==============================] - 0s 4ms/step - loss: 0.4233 - val_loss: 0.3416\n",
            "Epoch 596/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4228 - val_loss: 0.3436\n",
            "Epoch 597/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4232 - val_loss: 0.3436\n",
            "Epoch 598/5000\n",
            "99/99 [==============================] - 1s 5ms/step - loss: 0.4226 - val_loss: 0.3386\n",
            "Epoch 599/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4232 - val_loss: 0.3419\n",
            "Epoch 600/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4233 - val_loss: 0.3402\n",
            "Epoch 601/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4225 - val_loss: 0.3412\n",
            "Epoch 602/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4224 - val_loss: 0.3414\n",
            "Epoch 603/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4227 - val_loss: 0.3385\n",
            "Epoch 604/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4227 - val_loss: 0.3441\n",
            "Epoch 605/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4227 - val_loss: 0.3427\n",
            "Epoch 606/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4228 - val_loss: 0.3469\n",
            "Epoch 607/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4222 - val_loss: 0.3426\n",
            "Epoch 608/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4231 - val_loss: 0.3454\n",
            "Epoch 609/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4226 - val_loss: 0.3456\n",
            "Epoch 610/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4227 - val_loss: 0.3427\n",
            "Epoch 611/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4222 - val_loss: 0.3415\n",
            "Epoch 612/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4226 - val_loss: 0.3382\n",
            "Epoch 613/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4222 - val_loss: 0.3453\n",
            "Epoch 614/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4223 - val_loss: 0.3486\n",
            "Epoch 615/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4224 - val_loss: 0.3488\n",
            "Epoch 616/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4220 - val_loss: 0.3450\n",
            "Epoch 617/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4224 - val_loss: 0.3426\n",
            "Epoch 618/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4226 - val_loss: 0.3474\n",
            "Epoch 619/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4220 - val_loss: 0.3430\n",
            "Epoch 620/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4230 - val_loss: 0.3438\n",
            "Epoch 621/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4216 - val_loss: 0.3449\n",
            "Epoch 622/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4216 - val_loss: 0.3455\n",
            "Epoch 623/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4219 - val_loss: 0.3447\n",
            "Epoch 624/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4217 - val_loss: 0.3479\n",
            "Epoch 625/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4218 - val_loss: 0.3444\n",
            "Epoch 626/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4219 - val_loss: 0.3436\n",
            "Epoch 627/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4220 - val_loss: 0.3441\n",
            "Epoch 628/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4222 - val_loss: 0.3445\n",
            "Epoch 629/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4213 - val_loss: 0.3441\n",
            "Epoch 630/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4218 - val_loss: 0.3430\n",
            "Epoch 631/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4220 - val_loss: 0.3442\n",
            "Epoch 632/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4215 - val_loss: 0.3408\n",
            "Epoch 633/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4217 - val_loss: 0.3442\n",
            "Epoch 634/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4216 - val_loss: 0.3473\n",
            "Epoch 635/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4216 - val_loss: 0.3460\n",
            "Epoch 636/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4219 - val_loss: 0.3434\n",
            "Epoch 637/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4213 - val_loss: 0.3437\n",
            "Epoch 638/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4222 - val_loss: 0.3470\n",
            "Epoch 639/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4211 - val_loss: 0.3463\n",
            "Epoch 640/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4219 - val_loss: 0.3480\n",
            "Epoch 641/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4211 - val_loss: 0.3431\n",
            "Epoch 642/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4211 - val_loss: 0.3450\n",
            "Epoch 643/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4210 - val_loss: 0.3439\n",
            "Epoch 644/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4209 - val_loss: 0.3429\n",
            "Epoch 645/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4210 - val_loss: 0.3410\n",
            "Epoch 646/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4211 - val_loss: 0.3398\n",
            "Epoch 647/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4209 - val_loss: 0.3428\n",
            "Epoch 648/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4207 - val_loss: 0.3423\n",
            "Epoch 649/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4213 - val_loss: 0.3470\n",
            "Epoch 650/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4209 - val_loss: 0.3455\n",
            "Epoch 651/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4214 - val_loss: 0.3459\n",
            "Epoch 652/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4209 - val_loss: 0.3484\n",
            "Epoch 653/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4207 - val_loss: 0.3444\n",
            "Epoch 654/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4207 - val_loss: 0.3465\n",
            "Epoch 655/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4208 - val_loss: 0.3442\n",
            "Epoch 656/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4216 - val_loss: 0.3471\n",
            "Epoch 657/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4209 - val_loss: 0.3445\n",
            "Epoch 658/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4208 - val_loss: 0.3455\n",
            "Epoch 659/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4204 - val_loss: 0.3437\n",
            "Epoch 660/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4204 - val_loss: 0.3466\n",
            "Epoch 661/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4204 - val_loss: 0.3451\n",
            "Epoch 662/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4204 - val_loss: 0.3475\n",
            "Epoch 663/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4207 - val_loss: 0.3455\n",
            "Epoch 664/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4205 - val_loss: 0.3448\n",
            "Epoch 665/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4201 - val_loss: 0.3448\n",
            "Epoch 666/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4204 - val_loss: 0.3440\n",
            "Epoch 667/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4199 - val_loss: 0.3430\n",
            "Epoch 668/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4200 - val_loss: 0.3433\n",
            "Epoch 669/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4202 - val_loss: 0.3422\n",
            "Epoch 670/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4197 - val_loss: 0.3450\n",
            "Epoch 671/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4201 - val_loss: 0.3455\n",
            "Epoch 672/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4201 - val_loss: 0.3457\n",
            "Epoch 673/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4197 - val_loss: 0.3454\n",
            "Epoch 674/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4199 - val_loss: 0.3471\n",
            "Epoch 675/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4201 - val_loss: 0.3435\n",
            "Epoch 676/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4198 - val_loss: 0.3477\n",
            "Epoch 677/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4198 - val_loss: 0.3485\n",
            "Epoch 678/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4201 - val_loss: 0.3428\n",
            "Epoch 679/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4204 - val_loss: 0.3438\n",
            "Epoch 680/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4195 - val_loss: 0.3440\n",
            "Epoch 681/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4194 - val_loss: 0.3458\n",
            "Epoch 682/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4200 - val_loss: 0.3436\n",
            "Epoch 683/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4200 - val_loss: 0.3439\n",
            "Epoch 684/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4197 - val_loss: 0.3410\n",
            "Epoch 685/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4195 - val_loss: 0.3457\n",
            "Epoch 686/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4198 - val_loss: 0.3452\n",
            "Epoch 687/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4192 - val_loss: 0.3439\n",
            "Epoch 688/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4193 - val_loss: 0.3439\n",
            "Epoch 689/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4195 - val_loss: 0.3461\n",
            "Epoch 690/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4192 - val_loss: 0.3446\n",
            "Epoch 691/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4193 - val_loss: 0.3472\n",
            "Epoch 692/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4193 - val_loss: 0.3474\n",
            "Epoch 693/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4190 - val_loss: 0.3458\n",
            "Epoch 694/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4194 - val_loss: 0.3475\n",
            "Epoch 695/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4192 - val_loss: 0.3447\n",
            "Epoch 696/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4190 - val_loss: 0.3478\n",
            "Epoch 697/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4190 - val_loss: 0.3474\n",
            "Epoch 698/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4188 - val_loss: 0.3448\n",
            "Epoch 699/5000\n",
            "99/99 [==============================] - 1s 6ms/step - loss: 0.4189 - val_loss: 0.3446\n",
            "Epoch 700/5000\n",
            "99/99 [==============================] - 0s 4ms/step - loss: 0.4189 - val_loss: 0.3457\n",
            "Epoch 701/5000\n",
            "99/99 [==============================] - 0s 5ms/step - loss: 0.4192 - val_loss: 0.3459\n",
            "Epoch 702/5000\n",
            "99/99 [==============================] - 0s 4ms/step - loss: 0.4188 - val_loss: 0.3472\n",
            "Epoch 703/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4191 - val_loss: 0.3463\n",
            "Epoch 704/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4192 - val_loss: 0.3447\n",
            "Epoch 705/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4190 - val_loss: 0.3460\n",
            "Epoch 706/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4189 - val_loss: 0.3475\n",
            "Epoch 707/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4189 - val_loss: 0.3432\n",
            "Epoch 708/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4188 - val_loss: 0.3470\n",
            "Epoch 709/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4185 - val_loss: 0.3492\n",
            "Epoch 710/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4185 - val_loss: 0.3457\n",
            "Epoch 711/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4183 - val_loss: 0.3445\n",
            "Epoch 712/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4186 - val_loss: 0.3444\n",
            "Epoch 713/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4186 - val_loss: 0.3454\n",
            "Epoch 714/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4186 - val_loss: 0.3464\n",
            "Epoch 715/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4190 - val_loss: 0.3440\n",
            "Epoch 716/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4186 - val_loss: 0.3482\n",
            "Epoch 717/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4184 - val_loss: 0.3482\n",
            "Epoch 718/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4181 - val_loss: 0.3485\n",
            "Epoch 719/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4183 - val_loss: 0.3471\n",
            "Epoch 720/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4189 - val_loss: 0.3448\n",
            "Epoch 721/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4186 - val_loss: 0.3489\n",
            "Epoch 722/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4183 - val_loss: 0.3468\n",
            "Epoch 723/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4183 - val_loss: 0.3486\n",
            "Epoch 724/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4189 - val_loss: 0.3490\n",
            "Epoch 725/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4180 - val_loss: 0.3515\n",
            "Epoch 726/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4184 - val_loss: 0.3513\n",
            "Epoch 727/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4183 - val_loss: 0.3516\n",
            "Epoch 728/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4178 - val_loss: 0.3510\n",
            "Epoch 729/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4174 - val_loss: 0.3459\n",
            "Epoch 730/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4189 - val_loss: 0.3468\n",
            "Epoch 731/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4177 - val_loss: 0.3498\n",
            "Epoch 732/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4178 - val_loss: 0.3473\n",
            "Epoch 733/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4176 - val_loss: 0.3463\n",
            "Epoch 734/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4184 - val_loss: 0.3519\n",
            "Epoch 735/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4179 - val_loss: 0.3511\n",
            "Epoch 736/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4176 - val_loss: 0.3482\n",
            "Epoch 737/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4178 - val_loss: 0.3495\n",
            "Epoch 738/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4178 - val_loss: 0.3494\n",
            "Epoch 739/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4173 - val_loss: 0.3475\n",
            "Epoch 740/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4174 - val_loss: 0.3503\n",
            "Epoch 741/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4173 - val_loss: 0.3481\n",
            "Epoch 742/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4176 - val_loss: 0.3483\n",
            "Epoch 743/5000\n",
            "99/99 [==============================] - 0s 4ms/step - loss: 0.4174 - val_loss: 0.3463\n",
            "Epoch 744/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4170 - val_loss: 0.3476\n",
            "Epoch 745/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4171 - val_loss: 0.3472\n",
            "Epoch 746/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4171 - val_loss: 0.3474\n",
            "Epoch 747/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4174 - val_loss: 0.3492\n",
            "Epoch 748/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4174 - val_loss: 0.3504\n",
            "Epoch 749/5000\n",
            "99/99 [==============================] - 0s 4ms/step - loss: 0.4172 - val_loss: 0.3488\n",
            "Epoch 750/5000\n",
            "99/99 [==============================] - 0s 4ms/step - loss: 0.4174 - val_loss: 0.3478\n",
            "Epoch 751/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4165 - val_loss: 0.3480\n",
            "Epoch 752/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4174 - val_loss: 0.3494\n",
            "Epoch 753/5000\n",
            "99/99 [==============================] - 0s 4ms/step - loss: 0.4173 - val_loss: 0.3549\n",
            "Epoch 754/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4175 - val_loss: 0.3510\n",
            "Epoch 755/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4170 - val_loss: 0.3502\n",
            "Epoch 756/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4173 - val_loss: 0.3513\n",
            "Epoch 757/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4169 - val_loss: 0.3528\n",
            "Epoch 758/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4167 - val_loss: 0.3491\n",
            "Epoch 759/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4166 - val_loss: 0.3502\n",
            "Epoch 760/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4172 - val_loss: 0.3514\n",
            "Epoch 761/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4170 - val_loss: 0.3507\n",
            "Epoch 762/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4170 - val_loss: 0.3476\n",
            "Epoch 763/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4166 - val_loss: 0.3493\n",
            "Epoch 764/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4164 - val_loss: 0.3529\n",
            "Epoch 765/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4167 - val_loss: 0.3526\n",
            "Epoch 766/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4169 - val_loss: 0.3538\n",
            "Epoch 767/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4168 - val_loss: 0.3529\n",
            "Epoch 768/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4166 - val_loss: 0.3508\n",
            "Epoch 769/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4165 - val_loss: 0.3506\n",
            "Epoch 770/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4167 - val_loss: 0.3481\n",
            "Epoch 771/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4170 - val_loss: 0.3512\n",
            "Epoch 772/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4169 - val_loss: 0.3511\n",
            "Epoch 773/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4164 - val_loss: 0.3519\n",
            "Epoch 774/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4162 - val_loss: 0.3518\n",
            "Epoch 775/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4160 - val_loss: 0.3498\n",
            "Epoch 776/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4166 - val_loss: 0.3539\n",
            "Epoch 777/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4161 - val_loss: 0.3515\n",
            "Epoch 778/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4162 - val_loss: 0.3505\n",
            "Epoch 779/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4163 - val_loss: 0.3505\n",
            "Epoch 780/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4156 - val_loss: 0.3506\n",
            "Epoch 781/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4163 - val_loss: 0.3529\n",
            "Epoch 782/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4163 - val_loss: 0.3530\n",
            "Epoch 783/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4166 - val_loss: 0.3560\n",
            "Epoch 784/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4157 - val_loss: 0.3526\n",
            "Epoch 785/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4167 - val_loss: 0.3554\n",
            "Epoch 786/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4158 - val_loss: 0.3571\n",
            "Epoch 787/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4159 - val_loss: 0.3585\n",
            "Epoch 788/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4159 - val_loss: 0.3534\n",
            "Epoch 789/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4155 - val_loss: 0.3537\n",
            "Epoch 790/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4158 - val_loss: 0.3545\n",
            "Epoch 791/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4158 - val_loss: 0.3564\n",
            "Epoch 792/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4155 - val_loss: 0.3567\n",
            "Epoch 793/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4157 - val_loss: 0.3554\n",
            "Epoch 794/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4159 - val_loss: 0.3545\n",
            "Epoch 795/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4160 - val_loss: 0.3548\n",
            "Epoch 796/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4154 - val_loss: 0.3565\n",
            "Epoch 797/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4158 - val_loss: 0.3545\n",
            "Epoch 798/5000\n",
            "99/99 [==============================] - 0s 4ms/step - loss: 0.4162 - val_loss: 0.3558\n",
            "Epoch 799/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4155 - val_loss: 0.3579\n",
            "Epoch 800/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4153 - val_loss: 0.3558\n",
            "Epoch 801/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4156 - val_loss: 0.3537\n",
            "Epoch 802/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4154 - val_loss: 0.3565\n",
            "Epoch 803/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4157 - val_loss: 0.3560\n",
            "Epoch 804/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4149 - val_loss: 0.3564\n",
            "Epoch 805/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4148 - val_loss: 0.3556\n",
            "Epoch 806/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4156 - val_loss: 0.3555\n",
            "Epoch 807/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4151 - val_loss: 0.3536\n",
            "Epoch 808/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4152 - val_loss: 0.3553\n",
            "Epoch 809/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4158 - val_loss: 0.3580\n",
            "Epoch 810/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4152 - val_loss: 0.3561\n",
            "Epoch 811/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4149 - val_loss: 0.3557\n",
            "Epoch 812/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4151 - val_loss: 0.3557\n",
            "Epoch 813/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4153 - val_loss: 0.3538\n",
            "Epoch 814/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4148 - val_loss: 0.3566\n",
            "Epoch 815/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4148 - val_loss: 0.3557\n",
            "Epoch 816/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4151 - val_loss: 0.3545\n",
            "Epoch 817/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4150 - val_loss: 0.3582\n",
            "Epoch 818/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4147 - val_loss: 0.3559\n",
            "Epoch 819/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4146 - val_loss: 0.3568\n",
            "Epoch 820/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4150 - val_loss: 0.3550\n",
            "Epoch 821/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4149 - val_loss: 0.3556\n",
            "Epoch 822/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4145 - val_loss: 0.3572\n",
            "Epoch 823/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4147 - val_loss: 0.3518\n",
            "Epoch 824/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4144 - val_loss: 0.3566\n",
            "Epoch 825/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4142 - val_loss: 0.3568\n",
            "Epoch 826/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4144 - val_loss: 0.3593\n",
            "Epoch 827/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4148 - val_loss: 0.3570\n",
            "Epoch 828/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4146 - val_loss: 0.3600\n",
            "Epoch 829/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4149 - val_loss: 0.3581\n",
            "Epoch 830/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4148 - val_loss: 0.3575\n",
            "Epoch 831/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4147 - val_loss: 0.3583\n",
            "Epoch 832/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4144 - val_loss: 0.3600\n",
            "Epoch 833/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4142 - val_loss: 0.3595\n",
            "Epoch 834/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4144 - val_loss: 0.3586\n",
            "Epoch 835/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4141 - val_loss: 0.3578\n",
            "Epoch 836/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4140 - val_loss: 0.3573\n",
            "Epoch 837/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4140 - val_loss: 0.3558\n",
            "Epoch 838/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4141 - val_loss: 0.3576\n",
            "Epoch 839/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4141 - val_loss: 0.3589\n",
            "Epoch 840/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4139 - val_loss: 0.3601\n",
            "Epoch 841/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4139 - val_loss: 0.3573\n",
            "Epoch 842/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4137 - val_loss: 0.3582\n",
            "Epoch 843/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4146 - val_loss: 0.3619\n",
            "Epoch 844/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4141 - val_loss: 0.3574\n",
            "Epoch 845/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4141 - val_loss: 0.3566\n",
            "Epoch 846/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4142 - val_loss: 0.3609\n",
            "Epoch 847/5000\n",
            "99/99 [==============================] - 0s 4ms/step - loss: 0.4137 - val_loss: 0.3609\n",
            "Epoch 848/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4136 - val_loss: 0.3574\n",
            "Epoch 849/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4138 - val_loss: 0.3579\n",
            "Epoch 850/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4138 - val_loss: 0.3564\n",
            "Epoch 851/5000\n",
            "99/99 [==============================] - 0s 4ms/step - loss: 0.4136 - val_loss: 0.3601\n",
            "Epoch 852/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4138 - val_loss: 0.3591\n",
            "Epoch 853/5000\n",
            "99/99 [==============================] - 0s 4ms/step - loss: 0.4132 - val_loss: 0.3616\n",
            "Epoch 854/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4133 - val_loss: 0.3592\n",
            "Epoch 855/5000\n",
            "99/99 [==============================] - 0s 4ms/step - loss: 0.4133 - val_loss: 0.3594\n",
            "Epoch 856/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4140 - val_loss: 0.3619\n",
            "Epoch 857/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4134 - val_loss: 0.3611\n",
            "Epoch 858/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4130 - val_loss: 0.3546\n",
            "Epoch 859/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4144 - val_loss: 0.3597\n",
            "Epoch 860/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4133 - val_loss: 0.3635\n",
            "Epoch 861/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4132 - val_loss: 0.3609\n",
            "Epoch 862/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4132 - val_loss: 0.3628\n",
            "Epoch 863/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4134 - val_loss: 0.3617\n",
            "Epoch 864/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4133 - val_loss: 0.3634\n",
            "Epoch 865/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4135 - val_loss: 0.3680\n",
            "Epoch 866/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4135 - val_loss: 0.3688\n",
            "Epoch 867/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4132 - val_loss: 0.3670\n",
            "Epoch 868/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4131 - val_loss: 0.3706\n",
            "Epoch 869/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4128 - val_loss: 0.3646\n",
            "Epoch 870/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4129 - val_loss: 0.3617\n",
            "Epoch 871/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4132 - val_loss: 0.3602\n",
            "Epoch 872/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4130 - val_loss: 0.3623\n",
            "Epoch 873/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4128 - val_loss: 0.3638\n",
            "Epoch 874/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4129 - val_loss: 0.3625\n",
            "Epoch 875/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4130 - val_loss: 0.3654\n",
            "Epoch 876/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4124 - val_loss: 0.3653\n",
            "Epoch 877/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4127 - val_loss: 0.3646\n",
            "Epoch 878/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4125 - val_loss: 0.3619\n",
            "Epoch 879/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4125 - val_loss: 0.3598\n",
            "Epoch 880/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4130 - val_loss: 0.3601\n",
            "Epoch 881/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4126 - val_loss: 0.3660\n",
            "Epoch 882/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4126 - val_loss: 0.3634\n",
            "Epoch 883/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4130 - val_loss: 0.3702\n",
            "Epoch 884/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4128 - val_loss: 0.3687\n",
            "Epoch 885/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4132 - val_loss: 0.3661\n",
            "Epoch 886/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4125 - val_loss: 0.3689\n",
            "Epoch 887/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4121 - val_loss: 0.3654\n",
            "Epoch 888/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4121 - val_loss: 0.3656\n",
            "Epoch 889/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4120 - val_loss: 0.3622\n",
            "Epoch 890/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4122 - val_loss: 0.3665\n",
            "Epoch 891/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4124 - val_loss: 0.3663\n",
            "Epoch 892/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4137 - val_loss: 0.3670\n",
            "Epoch 893/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4134 - val_loss: 0.3701\n",
            "Epoch 894/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4124 - val_loss: 0.3655\n",
            "Epoch 895/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4124 - val_loss: 0.3657\n",
            "Epoch 896/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4120 - val_loss: 0.3672\n",
            "Epoch 897/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4121 - val_loss: 0.3686\n",
            "Epoch 898/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4121 - val_loss: 0.3654\n",
            "Epoch 899/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4120 - val_loss: 0.3634\n",
            "Epoch 900/5000\n",
            "99/99 [==============================] - 0s 4ms/step - loss: 0.4121 - val_loss: 0.3663\n",
            "Epoch 901/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4118 - val_loss: 0.3686\n",
            "Epoch 902/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4118 - val_loss: 0.3651\n",
            "Epoch 903/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4122 - val_loss: 0.3700\n",
            "Epoch 904/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4115 - val_loss: 0.3664\n",
            "Epoch 905/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4113 - val_loss: 0.3660\n",
            "Epoch 906/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4118 - val_loss: 0.3663\n",
            "Epoch 907/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4119 - val_loss: 0.3703\n",
            "Epoch 908/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4114 - val_loss: 0.3688\n",
            "Epoch 909/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4116 - val_loss: 0.3669\n",
            "Epoch 910/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4118 - val_loss: 0.3715\n",
            "Epoch 911/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4113 - val_loss: 0.3664\n",
            "Epoch 912/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4118 - val_loss: 0.3698\n",
            "Epoch 913/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4111 - val_loss: 0.3716\n",
            "Epoch 914/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4120 - val_loss: 0.3721\n",
            "Epoch 915/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4114 - val_loss: 0.3694\n",
            "Epoch 916/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4122 - val_loss: 0.3737\n",
            "Epoch 917/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4116 - val_loss: 0.3694\n",
            "Epoch 918/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4112 - val_loss: 0.3678\n",
            "Epoch 919/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4114 - val_loss: 0.3670\n",
            "Epoch 920/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4115 - val_loss: 0.3701\n",
            "Epoch 921/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4114 - val_loss: 0.3760\n",
            "Epoch 922/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4110 - val_loss: 0.3700\n",
            "Epoch 923/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4110 - val_loss: 0.3714\n",
            "Epoch 924/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4111 - val_loss: 0.3696\n",
            "Epoch 925/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4109 - val_loss: 0.3731\n",
            "Epoch 926/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4114 - val_loss: 0.3726\n",
            "Epoch 927/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4110 - val_loss: 0.3715\n",
            "Epoch 928/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4116 - val_loss: 0.3730\n",
            "Epoch 929/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4111 - val_loss: 0.3745\n",
            "Epoch 930/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4110 - val_loss: 0.3738\n",
            "Epoch 931/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4107 - val_loss: 0.3680\n",
            "Epoch 932/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4113 - val_loss: 0.3728\n",
            "Epoch 933/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4119 - val_loss: 0.3750\n",
            "Epoch 934/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4111 - val_loss: 0.3735\n",
            "Epoch 935/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4108 - val_loss: 0.3769\n",
            "Epoch 936/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4103 - val_loss: 0.3757\n",
            "Epoch 937/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4105 - val_loss: 0.3724\n",
            "Epoch 938/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4112 - val_loss: 0.3721\n",
            "Epoch 939/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4104 - val_loss: 0.3737\n",
            "Epoch 940/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4108 - val_loss: 0.3761\n",
            "Epoch 941/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4111 - val_loss: 0.3766\n",
            "Epoch 942/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4109 - val_loss: 0.3732\n",
            "Epoch 943/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4108 - val_loss: 0.3775\n",
            "Epoch 944/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4106 - val_loss: 0.3756\n",
            "Epoch 945/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4101 - val_loss: 0.3761\n",
            "Epoch 946/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4103 - val_loss: 0.3724\n",
            "Epoch 947/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4105 - val_loss: 0.3698\n",
            "Epoch 948/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4105 - val_loss: 0.3732\n",
            "Epoch 949/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4099 - val_loss: 0.3763\n",
            "Epoch 950/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4101 - val_loss: 0.3714\n",
            "Epoch 951/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4100 - val_loss: 0.3676\n",
            "Epoch 952/5000\n",
            "99/99 [==============================] - 0s 4ms/step - loss: 0.4103 - val_loss: 0.3711\n",
            "Epoch 953/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4101 - val_loss: 0.3721\n",
            "Epoch 954/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4103 - val_loss: 0.3755\n",
            "Epoch 955/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4110 - val_loss: 0.3761\n",
            "Epoch 956/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4108 - val_loss: 0.3777\n",
            "Epoch 957/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4097 - val_loss: 0.3778\n",
            "Epoch 958/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4105 - val_loss: 0.3797\n",
            "Epoch 959/5000\n",
            "99/99 [==============================] - 0s 4ms/step - loss: 0.4097 - val_loss: 0.3813\n",
            "Epoch 960/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4097 - val_loss: 0.3765\n",
            "Epoch 961/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4095 - val_loss: 0.3735\n",
            "Epoch 962/5000\n",
            "99/99 [==============================] - 0s 4ms/step - loss: 0.4098 - val_loss: 0.3729\n",
            "Epoch 963/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4107 - val_loss: 0.3761\n",
            "Epoch 964/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4098 - val_loss: 0.3753\n",
            "Epoch 965/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4098 - val_loss: 0.3748\n",
            "Epoch 966/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4100 - val_loss: 0.3788\n",
            "Epoch 967/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4094 - val_loss: 0.3779\n",
            "Epoch 968/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4095 - val_loss: 0.3771\n",
            "Epoch 969/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4097 - val_loss: 0.3789\n",
            "Epoch 970/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4096 - val_loss: 0.3794\n",
            "Epoch 971/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4094 - val_loss: 0.3768\n",
            "Epoch 972/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4094 - val_loss: 0.3782\n",
            "Epoch 973/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4095 - val_loss: 0.3759\n",
            "Epoch 974/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4096 - val_loss: 0.3816\n",
            "Epoch 975/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4089 - val_loss: 0.3802\n",
            "Epoch 976/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4100 - val_loss: 0.3817\n",
            "Epoch 977/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4089 - val_loss: 0.3835\n",
            "Epoch 978/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4095 - val_loss: 0.3802\n",
            "Epoch 979/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4087 - val_loss: 0.3867\n",
            "Epoch 980/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4096 - val_loss: 0.3823\n",
            "Epoch 981/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4092 - val_loss: 0.3809\n",
            "Epoch 982/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4091 - val_loss: 0.3887\n",
            "Epoch 983/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4087 - val_loss: 0.3853\n",
            "Epoch 984/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4092 - val_loss: 0.3824\n",
            "Epoch 985/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4088 - val_loss: 0.3814\n",
            "Epoch 986/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4092 - val_loss: 0.3832\n",
            "Epoch 987/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4091 - val_loss: 0.3841\n",
            "Epoch 988/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4090 - val_loss: 0.3836\n",
            "Epoch 989/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4087 - val_loss: 0.3841\n",
            "Epoch 990/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4094 - val_loss: 0.3859\n",
            "Epoch 991/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4087 - val_loss: 0.3818\n",
            "Epoch 992/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4088 - val_loss: 0.3855\n",
            "Epoch 993/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4085 - val_loss: 0.3836\n",
            "Epoch 994/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4086 - val_loss: 0.3829\n",
            "Epoch 995/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4082 - val_loss: 0.3834\n",
            "Epoch 996/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4087 - val_loss: 0.3796\n",
            "Epoch 997/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4088 - val_loss: 0.3782\n",
            "Epoch 998/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4084 - val_loss: 0.3828\n",
            "Epoch 999/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4083 - val_loss: 0.3819\n",
            "Epoch 1000/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4081 - val_loss: 0.3820\n",
            "Epoch 1001/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4087 - val_loss: 0.3812\n",
            "Epoch 1002/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4082 - val_loss: 0.3811\n",
            "Epoch 1003/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4088 - val_loss: 0.3832\n",
            "Epoch 1004/5000\n",
            "99/99 [==============================] - 0s 4ms/step - loss: 0.4081 - val_loss: 0.3857\n",
            "Epoch 1005/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4080 - val_loss: 0.3880\n",
            "Epoch 1006/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4084 - val_loss: 0.3860\n",
            "Epoch 1007/5000\n",
            "99/99 [==============================] - 0s 4ms/step - loss: 0.4086 - val_loss: 0.3860\n",
            "Epoch 1008/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4079 - val_loss: 0.3877\n",
            "Epoch 1009/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4079 - val_loss: 0.3864\n",
            "Epoch 1010/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4079 - val_loss: 0.3844\n",
            "Epoch 1011/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4082 - val_loss: 0.3868\n",
            "Epoch 1012/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4083 - val_loss: 0.3883\n",
            "Epoch 1013/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4077 - val_loss: 0.3846\n",
            "Epoch 1014/5000\n",
            "99/99 [==============================] - 0s 4ms/step - loss: 0.4076 - val_loss: 0.3898\n",
            "Epoch 1015/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4085 - val_loss: 0.3912\n",
            "Epoch 1016/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4076 - val_loss: 0.3863\n",
            "Epoch 1017/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4083 - val_loss: 0.3937\n",
            "Epoch 1018/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4077 - val_loss: 0.3931\n",
            "Epoch 1019/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4078 - val_loss: 0.3909\n",
            "Epoch 1020/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4075 - val_loss: 0.3937\n",
            "Epoch 1021/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4074 - val_loss: 0.3913\n",
            "Epoch 1022/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4077 - val_loss: 0.3933\n",
            "Epoch 1023/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4080 - val_loss: 0.3941\n",
            "Epoch 1024/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4073 - val_loss: 0.3893\n",
            "Epoch 1025/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4077 - val_loss: 0.3900\n",
            "Epoch 1026/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4085 - val_loss: 0.3886\n",
            "Epoch 1027/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4073 - val_loss: 0.3910\n",
            "Epoch 1028/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4082 - val_loss: 0.3884\n",
            "Epoch 1029/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4077 - val_loss: 0.3892\n",
            "Epoch 1030/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4071 - val_loss: 0.3897\n",
            "Epoch 1031/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4070 - val_loss: 0.3917\n",
            "Epoch 1032/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4073 - val_loss: 0.3892\n",
            "Epoch 1033/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4069 - val_loss: 0.3892\n",
            "Epoch 1034/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4070 - val_loss: 0.3903\n",
            "Epoch 1035/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4075 - val_loss: 0.3879\n",
            "Epoch 1036/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4074 - val_loss: 0.3948\n",
            "Epoch 1037/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4069 - val_loss: 0.3900\n",
            "Epoch 1038/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4074 - val_loss: 0.3837\n",
            "Epoch 1039/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4068 - val_loss: 0.3882\n",
            "Epoch 1040/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4070 - val_loss: 0.3915\n",
            "Epoch 1041/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4070 - val_loss: 0.3898\n",
            "Epoch 1042/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4072 - val_loss: 0.3879\n",
            "Epoch 1043/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4068 - val_loss: 0.3930\n",
            "Epoch 1044/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4067 - val_loss: 0.3942\n",
            "Epoch 1045/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4067 - val_loss: 0.3946\n",
            "Epoch 1046/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4066 - val_loss: 0.3985\n",
            "Epoch 1047/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4069 - val_loss: 0.3970\n",
            "Epoch 1048/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4071 - val_loss: 0.3965\n",
            "Epoch 1049/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4067 - val_loss: 0.3928\n",
            "Epoch 1050/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4064 - val_loss: 0.3998\n",
            "Epoch 1051/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4075 - val_loss: 0.3933\n",
            "Epoch 1052/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4071 - val_loss: 0.3975\n",
            "Epoch 1053/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4072 - val_loss: 0.3952\n",
            "Epoch 1054/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4065 - val_loss: 0.3971\n",
            "Epoch 1055/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4062 - val_loss: 0.3950\n",
            "Epoch 1056/5000\n",
            "99/99 [==============================] - 0s 4ms/step - loss: 0.4071 - val_loss: 0.3934\n",
            "Epoch 1057/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4066 - val_loss: 0.3906\n",
            "Epoch 1058/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4068 - val_loss: 0.3966\n",
            "Epoch 1059/5000\n",
            "99/99 [==============================] - 0s 4ms/step - loss: 0.4065 - val_loss: 0.4010\n",
            "Epoch 1060/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4063 - val_loss: 0.4059\n",
            "Epoch 1061/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4062 - val_loss: 0.3996\n",
            "Epoch 1062/5000\n",
            "99/99 [==============================] - 0s 4ms/step - loss: 0.4059 - val_loss: 0.4031\n",
            "Epoch 1063/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4066 - val_loss: 0.3977\n",
            "Epoch 1064/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4066 - val_loss: 0.3965\n",
            "Epoch 1065/5000\n",
            "99/99 [==============================] - 0s 4ms/step - loss: 0.4065 - val_loss: 0.4018\n",
            "Epoch 1066/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4060 - val_loss: 0.4040\n",
            "Epoch 1067/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4068 - val_loss: 0.3984\n",
            "Epoch 1068/5000\n",
            "99/99 [==============================] - 0s 4ms/step - loss: 0.4059 - val_loss: 0.4048\n",
            "Epoch 1069/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4058 - val_loss: 0.4033\n",
            "Epoch 1070/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4062 - val_loss: 0.4019\n",
            "Epoch 1071/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4057 - val_loss: 0.4067\n",
            "Epoch 1072/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4058 - val_loss: 0.3987\n",
            "Epoch 1073/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4057 - val_loss: 0.4027\n",
            "Epoch 1074/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4061 - val_loss: 0.4063\n",
            "Epoch 1075/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4055 - val_loss: 0.4027\n",
            "Epoch 1076/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4054 - val_loss: 0.4021\n",
            "Epoch 1077/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4056 - val_loss: 0.3953\n",
            "Epoch 1078/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4062 - val_loss: 0.3973\n",
            "Epoch 1079/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4057 - val_loss: 0.4012\n",
            "Epoch 1080/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4056 - val_loss: 0.4087\n",
            "Epoch 1081/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4054 - val_loss: 0.4062\n",
            "Epoch 1082/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4059 - val_loss: 0.3953\n",
            "Epoch 1083/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4059 - val_loss: 0.4014\n",
            "Epoch 1084/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4057 - val_loss: 0.4061\n",
            "Epoch 1085/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4063 - val_loss: 0.4024\n",
            "Epoch 1086/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4058 - val_loss: 0.4088\n",
            "Epoch 1087/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4051 - val_loss: 0.4104\n",
            "Epoch 1088/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4052 - val_loss: 0.4072\n",
            "Epoch 1089/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4059 - val_loss: 0.4051\n",
            "Epoch 1090/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4049 - val_loss: 0.4059\n",
            "Epoch 1091/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4054 - val_loss: 0.4093\n",
            "Epoch 1092/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4047 - val_loss: 0.4055\n",
            "Epoch 1093/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4048 - val_loss: 0.4039\n",
            "Epoch 1094/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4051 - val_loss: 0.4079\n",
            "Epoch 1095/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4055 - val_loss: 0.4049\n",
            "Epoch 1096/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4049 - val_loss: 0.3997\n",
            "Epoch 1097/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4050 - val_loss: 0.4049\n",
            "Epoch 1098/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4054 - val_loss: 0.4123\n",
            "Epoch 1099/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4058 - val_loss: 0.4092\n",
            "Epoch 1100/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4053 - val_loss: 0.4076\n",
            "Epoch 1101/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4060 - val_loss: 0.4122\n",
            "Epoch 1102/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4050 - val_loss: 0.4154\n",
            "Epoch 1103/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4047 - val_loss: 0.4129\n",
            "Epoch 1104/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4047 - val_loss: 0.4167\n",
            "Epoch 1105/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4043 - val_loss: 0.4161\n",
            "Epoch 1106/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4051 - val_loss: 0.4142\n",
            "Epoch 1107/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4046 - val_loss: 0.4181\n",
            "Epoch 1108/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4041 - val_loss: 0.4174\n",
            "Epoch 1109/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4047 - val_loss: 0.4178\n",
            "Epoch 1110/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4043 - val_loss: 0.4137\n",
            "Epoch 1111/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4043 - val_loss: 0.4103\n",
            "Epoch 1112/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4044 - val_loss: 0.4195\n",
            "Epoch 1113/5000\n",
            "99/99 [==============================] - 0s 4ms/step - loss: 0.4040 - val_loss: 0.4169\n",
            "Epoch 1114/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4045 - val_loss: 0.4124\n",
            "Epoch 1115/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4042 - val_loss: 0.4116\n",
            "Epoch 1116/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4038 - val_loss: 0.4160\n",
            "Epoch 1117/5000\n",
            "99/99 [==============================] - 0s 4ms/step - loss: 0.4042 - val_loss: 0.4096\n",
            "Epoch 1118/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4044 - val_loss: 0.4082\n",
            "Epoch 1119/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4039 - val_loss: 0.4178\n",
            "Epoch 1120/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4042 - val_loss: 0.4087\n",
            "Epoch 1121/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4037 - val_loss: 0.4113\n",
            "Epoch 1122/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4039 - val_loss: 0.4064\n",
            "Epoch 1123/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4037 - val_loss: 0.4156\n",
            "Epoch 1124/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4038 - val_loss: 0.4097\n",
            "Epoch 1125/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4038 - val_loss: 0.4095\n",
            "Epoch 1126/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4035 - val_loss: 0.4113\n",
            "Epoch 1127/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4035 - val_loss: 0.4111\n",
            "Epoch 1128/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4036 - val_loss: 0.4157\n",
            "Epoch 1129/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4037 - val_loss: 0.4187\n",
            "Epoch 1130/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4044 - val_loss: 0.4108\n",
            "Epoch 1131/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4045 - val_loss: 0.4111\n",
            "Epoch 1132/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4034 - val_loss: 0.4172\n",
            "Epoch 1133/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4029 - val_loss: 0.4217\n",
            "Epoch 1134/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4040 - val_loss: 0.4196\n",
            "Epoch 1135/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4034 - val_loss: 0.4176\n",
            "Epoch 1136/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4037 - val_loss: 0.4184\n",
            "Epoch 1137/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4032 - val_loss: 0.4199\n",
            "Epoch 1138/5000\n",
            "99/99 [==============================] - 0s 4ms/step - loss: 0.4037 - val_loss: 0.4229\n",
            "Epoch 1139/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4040 - val_loss: 0.4186\n",
            "Epoch 1140/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4029 - val_loss: 0.4185\n",
            "Epoch 1141/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4030 - val_loss: 0.4185\n",
            "Epoch 1142/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4033 - val_loss: 0.4221\n",
            "Epoch 1143/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4025 - val_loss: 0.4273\n",
            "Epoch 1144/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4029 - val_loss: 0.4263\n",
            "Epoch 1145/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4033 - val_loss: 0.4226\n",
            "Epoch 1146/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4034 - val_loss: 0.4210\n",
            "Epoch 1147/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4030 - val_loss: 0.4156\n",
            "Epoch 1148/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4028 - val_loss: 0.4182\n",
            "Epoch 1149/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4029 - val_loss: 0.4261\n",
            "Epoch 1150/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4029 - val_loss: 0.4229\n",
            "Epoch 1151/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4032 - val_loss: 0.4191\n",
            "Epoch 1152/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4025 - val_loss: 0.4228\n",
            "Epoch 1153/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4029 - val_loss: 0.4218\n",
            "Epoch 1154/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4030 - val_loss: 0.4244\n",
            "Epoch 1155/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4025 - val_loss: 0.4209\n",
            "Epoch 1156/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4027 - val_loss: 0.4243\n",
            "Epoch 1157/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4025 - val_loss: 0.4204\n",
            "Epoch 1158/5000\n",
            "99/99 [==============================] - 0s 4ms/step - loss: 0.4026 - val_loss: 0.4198\n",
            "Epoch 1159/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4023 - val_loss: 0.4223\n",
            "Epoch 1160/5000\n",
            "99/99 [==============================] - 0s 4ms/step - loss: 0.4025 - val_loss: 0.4280\n",
            "Epoch 1161/5000\n",
            "99/99 [==============================] - 0s 4ms/step - loss: 0.4024 - val_loss: 0.4239\n",
            "Epoch 1162/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4024 - val_loss: 0.4240\n",
            "Epoch 1163/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4025 - val_loss: 0.4235\n",
            "Epoch 1164/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4023 - val_loss: 0.4199\n",
            "Epoch 1165/5000\n",
            "99/99 [==============================] - 0s 4ms/step - loss: 0.4022 - val_loss: 0.4248\n",
            "Epoch 1166/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4027 - val_loss: 0.4221\n",
            "Epoch 1167/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4023 - val_loss: 0.4261\n",
            "Epoch 1168/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4020 - val_loss: 0.4269\n",
            "Epoch 1169/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4025 - val_loss: 0.4272\n",
            "Epoch 1170/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4020 - val_loss: 0.4318\n",
            "Epoch 1171/5000\n",
            "99/99 [==============================] - 0s 4ms/step - loss: 0.4021 - val_loss: 0.4291\n",
            "Epoch 1172/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4026 - val_loss: 0.4291\n",
            "Epoch 1173/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4024 - val_loss: 0.4256\n",
            "Epoch 1174/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4021 - val_loss: 0.4239\n",
            "Epoch 1175/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4019 - val_loss: 0.4247\n",
            "Epoch 1176/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4027 - val_loss: 0.4375\n",
            "Epoch 1177/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4018 - val_loss: 0.4278\n",
            "Epoch 1178/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4025 - val_loss: 0.4317\n",
            "Epoch 1179/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4018 - val_loss: 0.4346\n",
            "Epoch 1180/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4017 - val_loss: 0.4302\n",
            "Epoch 1181/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4020 - val_loss: 0.4377\n",
            "Epoch 1182/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4017 - val_loss: 0.4375\n",
            "Epoch 1183/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4020 - val_loss: 0.4367\n",
            "Epoch 1184/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4019 - val_loss: 0.4327\n",
            "Epoch 1185/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4018 - val_loss: 0.4301\n",
            "Epoch 1186/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4018 - val_loss: 0.4294\n",
            "Epoch 1187/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4017 - val_loss: 0.4331\n",
            "Epoch 1188/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4015 - val_loss: 0.4339\n",
            "Epoch 1189/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4015 - val_loss: 0.4347\n",
            "Epoch 1190/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4016 - val_loss: 0.4364\n",
            "Epoch 1191/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4022 - val_loss: 0.4290\n",
            "Epoch 1192/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4012 - val_loss: 0.4432\n",
            "Epoch 1193/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4016 - val_loss: 0.4282\n",
            "Epoch 1194/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4016 - val_loss: 0.4328\n",
            "Epoch 1195/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4012 - val_loss: 0.4313\n",
            "Epoch 1196/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4018 - val_loss: 0.4373\n",
            "Epoch 1197/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4014 - val_loss: 0.4389\n",
            "Epoch 1198/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4010 - val_loss: 0.4414\n",
            "Epoch 1199/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4009 - val_loss: 0.4394\n",
            "Epoch 1200/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4010 - val_loss: 0.4350\n",
            "Epoch 1201/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4013 - val_loss: 0.4392\n",
            "Epoch 1202/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4020 - val_loss: 0.4335\n",
            "Epoch 1203/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4018 - val_loss: 0.4409\n",
            "Epoch 1204/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4006 - val_loss: 0.4408\n",
            "Epoch 1205/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4006 - val_loss: 0.4449\n",
            "Epoch 1206/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4007 - val_loss: 0.4417\n",
            "Epoch 1207/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4009 - val_loss: 0.4358\n",
            "Epoch 1208/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4007 - val_loss: 0.4467\n",
            "Epoch 1209/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4005 - val_loss: 0.4408\n",
            "Epoch 1210/5000\n",
            "99/99 [==============================] - 0s 4ms/step - loss: 0.4010 - val_loss: 0.4392\n",
            "Epoch 1211/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4006 - val_loss: 0.4389\n",
            "Epoch 1212/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4005 - val_loss: 0.4406\n",
            "Epoch 1213/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4003 - val_loss: 0.4415\n",
            "Epoch 1214/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4003 - val_loss: 0.4391\n",
            "Epoch 1215/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4003 - val_loss: 0.4412\n",
            "Epoch 1216/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4009 - val_loss: 0.4415\n",
            "Epoch 1217/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4006 - val_loss: 0.4376\n",
            "Epoch 1218/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4008 - val_loss: 0.4397\n",
            "Epoch 1219/5000\n",
            "99/99 [==============================] - 0s 4ms/step - loss: 0.4001 - val_loss: 0.4442\n",
            "Epoch 1220/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4008 - val_loss: 0.4454\n",
            "Epoch 1221/5000\n",
            "99/99 [==============================] - 0s 4ms/step - loss: 0.4002 - val_loss: 0.4489\n",
            "Epoch 1222/5000\n",
            "99/99 [==============================] - 0s 4ms/step - loss: 0.4004 - val_loss: 0.4426\n",
            "Epoch 1223/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4005 - val_loss: 0.4413\n",
            "Epoch 1224/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.3997 - val_loss: 0.4424\n",
            "Epoch 1225/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4005 - val_loss: 0.4411\n",
            "Epoch 1226/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.3997 - val_loss: 0.4382\n",
            "Epoch 1227/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.3997 - val_loss: 0.4425\n",
            "Epoch 1228/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4001 - val_loss: 0.4381\n",
            "Epoch 1229/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.3998 - val_loss: 0.4395\n",
            "Epoch 1230/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.3997 - val_loss: 0.4477\n",
            "Epoch 1231/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.3999 - val_loss: 0.4437\n",
            "Epoch 1232/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4000 - val_loss: 0.4424\n",
            "Epoch 1233/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.3998 - val_loss: 0.4366\n",
            "Epoch 1234/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4004 - val_loss: 0.4428\n",
            "Epoch 1235/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4005 - val_loss: 0.4463\n",
            "Epoch 1236/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.3996 - val_loss: 0.4410\n",
            "Epoch 1237/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.3994 - val_loss: 0.4430\n",
            "Epoch 1238/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.3992 - val_loss: 0.4520\n",
            "Epoch 1239/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.3993 - val_loss: 0.4493\n",
            "Epoch 1240/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.3993 - val_loss: 0.4480\n",
            "Epoch 1241/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.3994 - val_loss: 0.4472\n",
            "Epoch 1242/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.3986 - val_loss: 0.4491\n",
            "Epoch 1243/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4002 - val_loss: 0.4405\n",
            "Epoch 1244/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4002 - val_loss: 0.4396\n",
            "Epoch 1245/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.3989 - val_loss: 0.4497\n",
            "Epoch 1246/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.3988 - val_loss: 0.4483\n",
            "Epoch 1247/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.3990 - val_loss: 0.4492\n",
            "Epoch 1248/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4002 - val_loss: 0.4444\n",
            "Epoch 1249/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.3988 - val_loss: 0.4465\n",
            "Epoch 1250/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.3991 - val_loss: 0.4463\n",
            "Epoch 1251/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.3988 - val_loss: 0.4425\n",
            "Epoch 1252/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.3988 - val_loss: 0.4437\n",
            "Epoch 1253/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.3994 - val_loss: 0.4478\n",
            "Epoch 1254/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.3988 - val_loss: 0.4390\n",
            "Epoch 1255/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.3988 - val_loss: 0.4487\n",
            "Epoch 1256/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.3991 - val_loss: 0.4477\n",
            "Epoch 1257/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.3989 - val_loss: 0.4485\n",
            "Epoch 1258/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.3992 - val_loss: 0.4469\n",
            "Epoch 1259/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.3991 - val_loss: 0.4456\n",
            "Epoch 1260/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.3985 - val_loss: 0.4521\n",
            "Epoch 1261/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.3984 - val_loss: 0.4404\n",
            "Epoch 1262/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.3995 - val_loss: 0.4447\n",
            "Epoch 1263/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.3983 - val_loss: 0.4482\n",
            "Epoch 1264/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.3982 - val_loss: 0.4386\n",
            "Epoch 1265/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.3983 - val_loss: 0.4438\n",
            "Epoch 1266/5000\n",
            "99/99 [==============================] - 0s 4ms/step - loss: 0.3987 - val_loss: 0.4532\n",
            "Epoch 1267/5000\n",
            "99/99 [==============================] - 0s 4ms/step - loss: 0.3983 - val_loss: 0.4457\n",
            "Epoch 1268/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.3983 - val_loss: 0.4467\n",
            "Epoch 1269/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.3982 - val_loss: 0.4526\n",
            "Epoch 1270/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.3979 - val_loss: 0.4543\n",
            "Epoch 1271/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.3997 - val_loss: 0.4430\n",
            "Epoch 1272/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.3993 - val_loss: 0.4478\n",
            "Epoch 1273/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.3978 - val_loss: 0.4520\n",
            "Epoch 1274/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.3977 - val_loss: 0.4483\n",
            "Epoch 1275/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.3986 - val_loss: 0.4501\n",
            "Epoch 1276/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.3978 - val_loss: 0.4537\n",
            "Epoch 1277/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.3980 - val_loss: 0.4537\n",
            "Epoch 1278/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.3980 - val_loss: 0.4483\n",
            "Epoch 1279/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.3978 - val_loss: 0.4573\n",
            "Epoch 1280/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.3975 - val_loss: 0.4461\n",
            "Epoch 1281/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.3978 - val_loss: 0.4439\n",
            "Epoch 1282/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.3981 - val_loss: 0.4536\n",
            "Epoch 1283/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.3973 - val_loss: 0.4484\n",
            "Epoch 1284/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.3975 - val_loss: 0.4548\n",
            "Epoch 1285/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.3974 - val_loss: 0.4488\n",
            "Epoch 1286/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.3977 - val_loss: 0.4474\n",
            "Epoch 1287/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.3975 - val_loss: 0.4575\n",
            "Epoch 1288/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.3973 - val_loss: 0.4549\n",
            "Epoch 1289/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.3974 - val_loss: 0.4597\n",
            "Epoch 1290/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.3978 - val_loss: 0.4570\n",
            "Epoch 1291/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.3985 - val_loss: 0.4594\n",
            "Epoch 1292/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.3979 - val_loss: 0.4713\n",
            "Epoch 1293/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.3976 - val_loss: 0.4544\n",
            "Epoch 1294/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.3964 - val_loss: 0.4583\n",
            "Epoch 1295/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.3977 - val_loss: 0.4634\n",
            "Epoch 1296/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.3972 - val_loss: 0.4657\n",
            "Epoch 1297/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.3969 - val_loss: 0.4623\n",
            "Epoch 1298/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.3970 - val_loss: 0.4595\n",
            "Epoch 1299/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.3987 - val_loss: 0.4554\n",
            "Epoch 1300/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.3973 - val_loss: 0.4654\n",
            "Epoch 1301/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.3968 - val_loss: 0.4695\n",
            "Epoch 1302/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.3969 - val_loss: 0.4690\n",
            "Epoch 1303/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.3975 - val_loss: 0.4629\n",
            "Epoch 1304/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.3967 - val_loss: 0.4664\n",
            "Epoch 1305/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.3980 - val_loss: 0.4721\n",
            "Epoch 1306/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.3975 - val_loss: 0.4464\n",
            "Epoch 1307/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.3970 - val_loss: 0.4523\n",
            "Epoch 1308/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.3965 - val_loss: 0.4635\n",
            "Epoch 1309/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.3961 - val_loss: 0.4599\n",
            "Epoch 1310/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.3972 - val_loss: 0.4605\n",
            "Epoch 1311/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.3966 - val_loss: 0.4584\n",
            "Epoch 1312/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.3968 - val_loss: 0.4621\n",
            "Epoch 1313/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.3964 - val_loss: 0.4695\n",
            "Epoch 1314/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.3976 - val_loss: 0.4641\n",
            "Epoch 1315/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.3964 - val_loss: 0.4639\n",
            "Epoch 1316/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.3962 - val_loss: 0.4596\n",
            "Epoch 1317/5000\n",
            "99/99 [==============================] - 0s 4ms/step - loss: 0.3961 - val_loss: 0.4541\n",
            "Epoch 1318/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.3963 - val_loss: 0.4703\n",
            "Epoch 1319/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.3977 - val_loss: 0.4611\n",
            "Epoch 1320/5000\n",
            "99/99 [==============================] - 0s 4ms/step - loss: 0.3960 - val_loss: 0.4634\n",
            "Epoch 1321/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.3962 - val_loss: 0.4583\n",
            "Epoch 1322/5000\n",
            "99/99 [==============================] - 0s 4ms/step - loss: 0.3957 - val_loss: 0.4631\n",
            "Epoch 1323/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.3957 - val_loss: 0.4569\n",
            "Epoch 1324/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.3962 - val_loss: 0.4637\n",
            "Epoch 1325/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.3958 - val_loss: 0.4682\n",
            "Epoch 1326/5000\n",
            "99/99 [==============================] - 0s 4ms/step - loss: 0.3964 - val_loss: 0.4730\n",
            "Epoch 1327/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.3965 - val_loss: 0.4644\n",
            "Epoch 1328/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.3964 - val_loss: 0.4629\n",
            "Epoch 1329/5000\n",
            "99/99 [==============================] - 0s 4ms/step - loss: 0.3956 - val_loss: 0.4635\n",
            "Epoch 1330/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.3958 - val_loss: 0.4685\n",
            "Epoch 1331/5000\n",
            "99/99 [==============================] - 0s 4ms/step - loss: 0.3956 - val_loss: 0.4750\n",
            "Epoch 1332/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.3959 - val_loss: 0.4701\n",
            "Epoch 1333/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.3957 - val_loss: 0.4676\n",
            "Epoch 1334/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.3956 - val_loss: 0.4784\n",
            "Epoch 1335/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.3948 - val_loss: 0.4683\n",
            "Epoch 1336/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.3955 - val_loss: 0.4777\n",
            "Epoch 1337/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.3955 - val_loss: 0.4648\n",
            "Epoch 1338/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.3956 - val_loss: 0.4683\n",
            "Epoch 1339/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.3956 - val_loss: 0.4612\n",
            "Epoch 1340/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.3948 - val_loss: 0.4769\n",
            "Epoch 1341/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.3953 - val_loss: 0.4704\n",
            "Epoch 1342/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.3953 - val_loss: 0.4722\n",
            "Epoch 1343/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.3951 - val_loss: 0.4878\n",
            "Epoch 1344/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.3956 - val_loss: 0.4695\n",
            "Epoch 1345/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.3956 - val_loss: 0.4709\n",
            "Epoch 1346/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.3948 - val_loss: 0.4749\n",
            "Epoch 1347/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.3951 - val_loss: 0.4680\n",
            "Epoch 1348/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.3955 - val_loss: 0.4809\n",
            "Epoch 1349/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.3954 - val_loss: 0.4696\n",
            "Epoch 1350/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.3952 - val_loss: 0.4712\n",
            "Epoch 1351/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.3949 - val_loss: 0.4656\n",
            "Epoch 1352/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.3954 - val_loss: 0.4775\n",
            "Epoch 1353/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.3950 - val_loss: 0.4700\n",
            "Epoch 1354/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.3942 - val_loss: 0.4726\n",
            "Epoch 1355/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.3951 - val_loss: 0.4772\n",
            "Epoch 1356/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.3950 - val_loss: 0.4845\n",
            "Epoch 1357/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.3941 - val_loss: 0.4746\n",
            "Epoch 1358/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.3946 - val_loss: 0.4787\n",
            "Epoch 1359/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.3942 - val_loss: 0.4858\n",
            "Epoch 1360/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.3943 - val_loss: 0.4745\n",
            "Epoch 1361/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.3942 - val_loss: 0.4853\n",
            "Epoch 1362/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.3942 - val_loss: 0.4830\n",
            "Epoch 1363/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.3950 - val_loss: 0.4779\n",
            "Epoch 1364/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.3941 - val_loss: 0.4839\n",
            "Epoch 1365/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.3944 - val_loss: 0.4792\n",
            "Epoch 1366/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.3937 - val_loss: 0.4754\n",
            "Epoch 1367/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.3944 - val_loss: 0.4863\n",
            "Epoch 1368/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.3945 - val_loss: 0.4847\n",
            "Epoch 1369/5000\n",
            "99/99 [==============================] - 0s 4ms/step - loss: 0.3947 - val_loss: 0.4908\n",
            "Epoch 1370/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.3937 - val_loss: 0.4831\n",
            "Epoch 1371/5000\n",
            "99/99 [==============================] - 0s 4ms/step - loss: 0.3937 - val_loss: 0.4807\n",
            "Epoch 1372/5000\n",
            "99/99 [==============================] - 0s 4ms/step - loss: 0.3953 - val_loss: 0.4802\n",
            "Epoch 1373/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.3944 - val_loss: 0.4898\n",
            "Epoch 1374/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.3940 - val_loss: 0.4778\n",
            "Epoch 1375/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.3944 - val_loss: 0.4818\n",
            "Epoch 1376/5000\n",
            "99/99 [==============================] - 0s 4ms/step - loss: 0.3941 - val_loss: 0.4872\n",
            "Epoch 1377/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.3937 - val_loss: 0.4870\n",
            "Epoch 1378/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.3944 - val_loss: 0.4903\n",
            "Epoch 1379/5000\n",
            "99/99 [==============================] - 0s 4ms/step - loss: 0.3940 - val_loss: 0.4874\n",
            "Epoch 1380/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.3937 - val_loss: 0.4975\n",
            "Epoch 1381/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.3940 - val_loss: 0.4924\n",
            "Epoch 1382/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.3938 - val_loss: 0.4818\n",
            "Epoch 1383/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.3938 - val_loss: 0.4865\n",
            "Epoch 1384/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.3939 - val_loss: 0.4926\n",
            "Epoch 1385/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.3944 - val_loss: 0.4898\n",
            "Epoch 1386/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.3933 - val_loss: 0.4921\n",
            "Epoch 1387/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.3933 - val_loss: 0.4896\n",
            "Epoch 1388/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.3937 - val_loss: 0.4930\n",
            "Epoch 1389/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.3932 - val_loss: 0.4952\n",
            "Epoch 1390/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.3938 - val_loss: 0.4919\n",
            "Epoch 1391/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.3934 - val_loss: 0.4949\n",
            "Epoch 1392/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.3932 - val_loss: 0.4905\n",
            "Epoch 1393/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.3934 - val_loss: 0.4998\n",
            "Epoch 1394/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.3938 - val_loss: 0.4900\n",
            "Epoch 1395/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.3936 - val_loss: 0.4986\n",
            "Epoch 1396/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.3929 - val_loss: 0.4977\n",
            "Epoch 1397/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.3937 - val_loss: 0.4994\n",
            "Epoch 1398/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.3929 - val_loss: 0.4906\n",
            "Epoch 1399/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.3926 - val_loss: 0.4906\n",
            "Epoch 1400/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.3933 - val_loss: 0.4947\n",
            "Epoch 1401/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.3939 - val_loss: 0.4890\n",
            "Epoch 1402/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.3926 - val_loss: 0.4961\n",
            "Epoch 1403/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.3935 - val_loss: 0.4905\n",
            "Epoch 1404/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.3929 - val_loss: 0.4959\n",
            "Epoch 1405/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.3926 - val_loss: 0.4896\n",
            "Epoch 1406/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.3931 - val_loss: 0.5009\n",
            "Epoch 1407/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.3924 - val_loss: 0.4972\n",
            "Epoch 1408/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.3927 - val_loss: 0.5122\n",
            "Epoch 1409/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.3927 - val_loss: 0.5098\n",
            "Epoch 1410/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.3921 - val_loss: 0.5032\n",
            "Epoch 1411/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.3924 - val_loss: 0.5019\n",
            "Epoch 1412/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.3928 - val_loss: 0.4936\n",
            "Epoch 1413/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.3926 - val_loss: 0.5019\n",
            "Epoch 1414/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.3926 - val_loss: 0.5023\n",
            "Epoch 1415/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.3924 - val_loss: 0.5110\n",
            "Epoch 1416/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.3928 - val_loss: 0.5049\n",
            "Epoch 1417/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.3927 - val_loss: 0.4975\n",
            "Epoch 1418/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.3919 - val_loss: 0.5022\n",
            "Epoch 1419/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.3923 - val_loss: 0.5020\n",
            "Epoch 1420/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.3923 - val_loss: 0.4980\n",
            "Epoch 1421/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.3921 - val_loss: 0.5126\n",
            "Epoch 1422/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.3917 - val_loss: 0.5013\n",
            "Epoch 1423/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.3918 - val_loss: 0.5017\n",
            "Epoch 1424/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.3919 - val_loss: 0.5030\n",
            "Epoch 1425/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.3921 - val_loss: 0.5033\n",
            "Epoch 1426/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.3923 - val_loss: 0.5020\n",
            "Epoch 1427/5000\n",
            "99/99 [==============================] - 0s 4ms/step - loss: 0.3916 - val_loss: 0.5030\n",
            "Epoch 1428/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.3917 - val_loss: 0.5028\n",
            "Epoch 1429/5000\n",
            "99/99 [==============================] - 0s 4ms/step - loss: 0.3915 - val_loss: 0.5007\n",
            "Epoch 1430/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.3927 - val_loss: 0.4910\n",
            "Epoch 1431/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.3916 - val_loss: 0.5033\n",
            "Epoch 1432/5000\n",
            "99/99 [==============================] - 0s 4ms/step - loss: 0.3921 - val_loss: 0.4958\n",
            "Epoch 1433/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.3912 - val_loss: 0.5067\n",
            "Epoch 1434/5000\n",
            "99/99 [==============================] - 0s 4ms/step - loss: 0.3911 - val_loss: 0.5106\n",
            "Epoch 1435/5000\n",
            "99/99 [==============================] - 0s 4ms/step - loss: 0.3912 - val_loss: 0.5199\n",
            "Epoch 1436/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.3919 - val_loss: 0.5065\n",
            "Epoch 1437/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.3914 - val_loss: 0.5091\n",
            "Epoch 1438/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.3911 - val_loss: 0.5175\n",
            "Epoch 1439/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.3917 - val_loss: 0.5141\n",
            "Epoch 1440/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.3915 - val_loss: 0.5056\n",
            "Epoch 1441/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.3917 - val_loss: 0.5134\n",
            "Epoch 1442/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.3914 - val_loss: 0.5052\n",
            "Epoch 1443/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.3924 - val_loss: 0.5070\n",
            "Epoch 1444/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.3913 - val_loss: 0.5099\n",
            "Epoch 1445/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.3915 - val_loss: 0.5108\n",
            "Epoch 1446/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.3908 - val_loss: 0.5076\n",
            "Epoch 1447/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.3909 - val_loss: 0.5210\n",
            "Epoch 1448/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.3910 - val_loss: 0.5137\n",
            "Epoch 1449/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.3913 - val_loss: 0.5149\n",
            "Epoch 1450/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.3907 - val_loss: 0.5110\n",
            "Epoch 1451/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.3913 - val_loss: 0.5088\n",
            "Epoch 1452/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.3904 - val_loss: 0.5050\n",
            "Epoch 1453/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.3912 - val_loss: 0.5070\n",
            "Epoch 1454/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.3923 - val_loss: 0.5143\n",
            "Epoch 1455/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.3906 - val_loss: 0.5287\n",
            "Epoch 1456/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.3907 - val_loss: 0.5169\n",
            "Epoch 1457/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.3908 - val_loss: 0.5091\n",
            "Epoch 1458/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.3903 - val_loss: 0.5075\n",
            "Epoch 1459/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.3906 - val_loss: 0.5135\n",
            "Epoch 1460/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.3903 - val_loss: 0.5164\n",
            "Epoch 1461/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.3912 - val_loss: 0.5157\n",
            "Epoch 1462/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.3903 - val_loss: 0.5235\n",
            "Epoch 1463/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.3903 - val_loss: 0.5222\n",
            "Epoch 1464/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.3901 - val_loss: 0.5203\n",
            "Epoch 1465/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.3911 - val_loss: 0.5297\n",
            "Epoch 1466/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.3902 - val_loss: 0.5275\n",
            "Epoch 1467/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.3910 - val_loss: 0.5242\n",
            "Epoch 1468/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.3902 - val_loss: 0.5211\n",
            "Epoch 1469/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.3908 - val_loss: 0.5256\n",
            "Epoch 1470/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.3898 - val_loss: 0.5056\n",
            "Epoch 1471/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.3905 - val_loss: 0.5256\n",
            "Epoch 1472/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.3897 - val_loss: 0.5309\n",
            "Epoch 1473/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.3900 - val_loss: 0.5338\n",
            "Epoch 1474/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.3906 - val_loss: 0.5185\n",
            "Epoch 1475/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.3905 - val_loss: 0.5269\n",
            "Epoch 1476/5000\n",
            "99/99 [==============================] - 0s 4ms/step - loss: 0.3896 - val_loss: 0.5242\n",
            "Epoch 1477/5000\n",
            "99/99 [==============================] - 0s 4ms/step - loss: 0.3905 - val_loss: 0.5183\n",
            "Epoch 1478/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.3894 - val_loss: 0.5249\n",
            "Epoch 1479/5000\n",
            "99/99 [==============================] - 0s 4ms/step - loss: 0.3899 - val_loss: 0.5207\n",
            "Epoch 1480/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.3894 - val_loss: 0.5262\n",
            "Epoch 1481/5000\n",
            "99/99 [==============================] - 0s 4ms/step - loss: 0.3893 - val_loss: 0.5287\n",
            "Epoch 1482/5000\n",
            "99/99 [==============================] - 0s 4ms/step - loss: 0.3897 - val_loss: 0.5375\n",
            "Epoch 1483/5000\n",
            "99/99 [==============================] - 0s 4ms/step - loss: 0.3897 - val_loss: 0.5337\n",
            "Epoch 1484/5000\n",
            "99/99 [==============================] - 0s 4ms/step - loss: 0.3895 - val_loss: 0.5247\n",
            "Epoch 1485/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.3895 - val_loss: 0.5233\n",
            "Epoch 1486/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.3892 - val_loss: 0.5279\n",
            "Epoch 1487/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.3899 - val_loss: 0.5261\n",
            "Epoch 1488/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.3887 - val_loss: 0.5218\n",
            "Epoch 1489/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.3889 - val_loss: 0.5179\n",
            "Epoch 1490/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.3895 - val_loss: 0.5386\n",
            "Epoch 1491/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.3900 - val_loss: 0.5245\n",
            "Epoch 1492/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.3897 - val_loss: 0.5199\n",
            "Epoch 1493/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.3899 - val_loss: 0.5413\n",
            "Epoch 1494/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.3891 - val_loss: 0.5235\n",
            "Epoch 1495/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.3888 - val_loss: 0.5255\n",
            "Epoch 1496/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.3889 - val_loss: 0.5422\n",
            "Epoch 1497/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.3893 - val_loss: 0.5231\n",
            "Epoch 1498/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.3882 - val_loss: 0.5405\n",
            "Epoch 1499/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.3896 - val_loss: 0.5298\n",
            "Epoch 1500/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.3883 - val_loss: 0.5281\n",
            "Epoch 1501/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.3902 - val_loss: 0.5427\n",
            "Epoch 1502/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.3887 - val_loss: 0.5372\n",
            "Epoch 1503/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.3891 - val_loss: 0.5448\n",
            "Epoch 1504/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.3886 - val_loss: 0.5343\n",
            "Epoch 1505/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.3885 - val_loss: 0.5397\n",
            "Epoch 1506/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.3886 - val_loss: 0.5404\n",
            "Epoch 1507/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.3881 - val_loss: 0.5403\n",
            "Epoch 1508/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.3885 - val_loss: 0.5317\n",
            "Epoch 1509/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.3887 - val_loss: 0.5525\n",
            "Epoch 1510/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.3885 - val_loss: 0.5305\n",
            "Epoch 1511/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.3887 - val_loss: 0.5306\n",
            "Epoch 1512/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.3886 - val_loss: 0.5279\n",
            "Epoch 1513/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.3888 - val_loss: 0.5413\n",
            "Epoch 1514/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.3882 - val_loss: 0.5454\n",
            "Epoch 1515/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.3882 - val_loss: 0.5322\n",
            "Epoch 1516/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.3885 - val_loss: 0.5325\n",
            "Epoch 1517/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.3881 - val_loss: 0.5515\n",
            "Epoch 1518/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.3885 - val_loss: 0.5448\n",
            "Epoch 1519/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.3888 - val_loss: 0.5456\n",
            "Epoch 1520/5000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.3884 - val_loss: 0.5450\n",
            "Epoch 1521/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.3884 - val_loss: 0.5367\n",
            "Epoch 1522/5000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.3880 - val_loss: 0.5487\n",
            "Epoch 1523/5000\n",
            "95/99 [===========================>..] - ETA: 0s - loss: 0.3846Restoring model weights from the end of the best epoch: 523.\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.3877 - val_loss: 0.5467\n",
            "Epoch 1523: early stopping\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 6ms/step - loss: 1.4080\n",
            "EXPECTED:\n",
            "    d18O_cel_mean  d18O_cel_variance\n",
            "0       26.663818           0.574594\n",
            "1       26.663818           0.574594\n",
            "2       26.663818           0.574594\n",
            "3       27.559140           0.780698\n",
            "4       27.559140           0.780698\n",
            "5       27.559140           0.780698\n",
            "6       27.559140           0.780698\n",
            "7       27.559140           0.780698\n",
            "8       27.559140           0.780698\n",
            "9       27.559140           0.780698\n",
            "10      27.559140           0.780698\n",
            "11      27.559140           0.780698\n",
            "12      27.559140           0.780698\n",
            "13      27.260748           0.830341\n",
            "14      27.260748           0.830341\n",
            "15      27.260748           0.830341\n",
            "16      27.260748           0.830341\n",
            "17      27.260748           0.830341\n",
            "18      27.260748           0.830341\n",
            "19      27.260748           0.830341\n",
            "20      27.260748           0.830341\n",
            "21      27.260748           0.830341\n",
            "22      27.260748           0.830341\n",
            "23      27.260748           0.830341\n",
            "24      27.260748           0.830341\n",
            "25      27.260748           0.830341\n",
            "26      27.260748           0.830341\n",
            "27      27.260748           0.830341\n",
            "28      27.260748           0.830341\n",
            "29      27.260748           0.830341\n",
            "30      27.260748           0.830341\n",
            "31      27.260748           0.830341\n",
            "32      27.260748           0.830341\n",
            "33      27.260748           0.830341\n",
            "34      27.260748           0.830341\n",
            "35      27.260748           0.830341\n",
            "36      27.260748           0.830341\n",
            "37      27.260748           0.830341\n",
            "38      27.260748           0.830341\n",
            "39      27.260748           0.830341\n",
            "40      27.260748           0.830341\n",
            "41      27.260748           0.830341\n",
            "42      27.260748           0.830341\n",
            "43      27.260748           0.830341\n",
            "44      27.260748           0.830341\n",
            "45      27.260748           0.830341\n",
            "46      27.260748           0.830341\n",
            "47      27.260748           0.830341\n",
            "48      24.964000           0.108138\n",
            "49      24.964000           0.108138\n",
            "50      24.964000           0.108138\n",
            "51      24.964000           0.108138\n",
            "52      24.964000           0.108138\n",
            "53      24.964000           0.108138\n",
            "54      24.964000           0.108138\n",
            "55      24.964000           0.108138\n",
            "56      24.964000           0.108138\n",
            "57      24.964000           0.108138\n",
            "58      23.752000           0.524370\n",
            "59      23.752000           0.524370\n",
            "60      23.752000           0.524370\n",
            "61      23.752000           0.524370\n",
            "62      23.752000           0.524370\n",
            "\n",
            "PREDICTED:\n",
            "    d18O_cel_mean  d18O_cel_variance\n",
            "0       25.908567           1.532691\n",
            "1       25.908567           1.532691\n",
            "2       25.908567           1.532691\n",
            "3       25.143929           1.768347\n",
            "4       25.143929           1.768347\n",
            "5       25.143929           1.768347\n",
            "6       25.143929           1.768347\n",
            "7       25.143929           1.768347\n",
            "8       25.143929           1.768347\n",
            "9       25.143929           1.768347\n",
            "10      25.143929           1.768347\n",
            "11      25.143929           1.768347\n",
            "12      25.143929           1.768347\n",
            "13      25.207232           1.732938\n",
            "14      25.207232           1.732938\n",
            "15      25.207232           1.732938\n",
            "16      25.207232           1.732938\n",
            "17      25.207232           1.732938\n",
            "18      25.207232           1.732938\n",
            "19      25.207232           1.732938\n",
            "20      25.207232           1.732938\n",
            "21      25.207232           1.732938\n",
            "22      25.207232           1.732938\n",
            "23      25.207232           1.732938\n",
            "24      25.207232           1.732938\n",
            "25      25.207232           1.732938\n",
            "26      25.207232           1.732938\n",
            "27      25.207232           1.732938\n",
            "28      25.207232           1.732938\n",
            "29      25.207232           1.732938\n",
            "30      25.207232           1.732938\n",
            "31      25.207232           1.732938\n",
            "32      25.207232           1.732938\n",
            "33      25.207232           1.732938\n",
            "34      25.207232           1.732938\n",
            "35      25.207232           1.732938\n",
            "36      25.207232           1.732938\n",
            "37      25.207232           1.732938\n",
            "38      25.207232           1.732938\n",
            "39      25.207232           1.732938\n",
            "40      25.207232           1.732938\n",
            "41      25.207232           1.732938\n",
            "42      25.207232           1.732938\n",
            "43      25.207232           1.732938\n",
            "44      25.207232           1.732938\n",
            "45      25.207232           1.732938\n",
            "46      25.207232           1.732938\n",
            "47      25.207232           1.732938\n",
            "48      24.893894           2.695183\n",
            "49      24.893894           2.695183\n",
            "50      24.893894           2.695183\n",
            "51      24.893894           2.695183\n",
            "52      24.893894           2.695183\n",
            "53      24.893894           2.695183\n",
            "54      24.893894           2.695183\n",
            "55      24.893894           2.695183\n",
            "56      24.893894           2.695183\n",
            "57      24.893894           2.695183\n",
            "58      24.888424           2.701507\n",
            "59      24.888424           2.701507\n",
            "60      24.888424           2.701507\n",
            "61      24.888424           2.701507\n",
            "62      24.888424           2.701507\n",
            "RMSE: 1.8436620193867626\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2) Ungrouped, fixed"
      ],
      "metadata": {
        "id": "yIQGGzsIup_d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ungrouped_fixed = {\n",
        "    'TRAIN' : os.path.join(FP_ROOT, \"amazon_sample_data/uc_davis_2023_08_12_train_fixed_ungrouped.csv\"),\n",
        "    'TEST' : os.path.join(FP_ROOT, \"amazon_sample_data/uc_davis_2023_08_12_test_fixed_ungrouped.csv\"),\n",
        "    'VALIDATION' : os.path.join(FP_ROOT, \"amazon_sample_data/uc_davis_2023_08_12_validation_fixed_ungrouped.csv\"),\n",
        "}\n",
        "\n",
        "ungrouped_fixed_scaled = load_and_scale(ungrouped_fixed)\n",
        "train_and_evaluate(ungrouped_fixed_scaled, \"ungrouped_fixed\", training_batch_size=1)"
      ],
      "metadata": {
        "id": "-TkJGJ9Xux24",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5d09697c-b9ef-4bb4-de80-dfcb171b9b13"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================\n",
            "ungrouped_fixed\n",
            "Model: \"model_10\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_11 (InputLayer)          [(None, 12)]         0           []                               \n",
            "                                                                                                  \n",
            " dense_20 (Dense)               (None, 20)           260         ['input_11[0][0]']               \n",
            "                                                                                                  \n",
            " dense_21 (Dense)               (None, 20)           420         ['dense_20[0][0]']               \n",
            "                                                                                                  \n",
            " var_output (Dense)             (None, 1)            21          ['dense_21[0][0]']               \n",
            "                                                                                                  \n",
            " mean_output (Dense)            (None, 1)            21          ['dense_21[0][0]']               \n",
            "                                                                                                  \n",
            " lambda_10 (Lambda)             (None, 1)            0           ['var_output[0][0]']             \n",
            "                                                                                                  \n",
            " concatenate_10 (Concatenate)   (None, 2)            0           ['mean_output[0][0]',            \n",
            "                                                                  'lambda_10[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 722\n",
            "Trainable params: 722\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Restoring model weights from the end of the best epoch: 1031.\n",
            "Epoch 1531: early stopping\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 0s 2ms/step - loss: 2.8060\n",
            "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f83fb36d3a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "EXPECTED:\n",
            "     d18O_cel_mean  d18O_cel_variance\n",
            "0        25.120750           0.844007\n",
            "1        25.120750           0.844007\n",
            "2        25.120750           0.844007\n",
            "3        25.120750           0.844007\n",
            "4        25.120750           0.844007\n",
            "5        25.120750           0.844007\n",
            "6        25.120750           0.844007\n",
            "7        25.120750           0.844007\n",
            "8        25.120750           0.844007\n",
            "9        25.120750           0.844007\n",
            "10       25.120750           0.844007\n",
            "11       25.120750           0.844007\n",
            "12       25.120750           0.844007\n",
            "13       25.120750           0.844007\n",
            "14       25.120750           0.844007\n",
            "15       25.120750           0.844007\n",
            "16       25.120750           0.844007\n",
            "17       25.120750           0.844007\n",
            "18       25.120750           0.844007\n",
            "19       25.120750           0.844007\n",
            "20       25.120750           0.844007\n",
            "21       25.120750           0.844007\n",
            "22       25.120750           0.844007\n",
            "23       25.120750           0.844007\n",
            "24       25.120750           0.844007\n",
            "25       25.120750           0.844007\n",
            "26       25.120750           0.844007\n",
            "27       25.120750           0.844007\n",
            "28       25.120750           0.844007\n",
            "29       25.120750           0.844007\n",
            "30       25.120750           0.844007\n",
            "31       25.120750           0.844007\n",
            "32       25.120750           0.844007\n",
            "33       25.120750           0.844007\n",
            "34       25.120750           0.844007\n",
            "35       25.120750           0.844007\n",
            "36       25.120750           0.844007\n",
            "37       25.120750           0.844007\n",
            "38       25.120750           0.844007\n",
            "39       25.120750           0.844007\n",
            "40       24.777670           0.736571\n",
            "41       24.777670           0.736571\n",
            "42       24.777670           0.736571\n",
            "43       24.777670           0.736571\n",
            "44       24.777670           0.736571\n",
            "45       25.551850           0.312355\n",
            "46       25.551850           0.312355\n",
            "47       25.551850           0.312355\n",
            "48       25.551850           0.312355\n",
            "49       25.551850           0.312355\n",
            "50       25.115885           0.033519\n",
            "51       25.115885           0.033519\n",
            "52       25.115885           0.033519\n",
            "53       25.115885           0.033519\n",
            "54       25.115885           0.033519\n",
            "55       25.987815           5.280825\n",
            "56       25.987815           5.280825\n",
            "57       25.987815           5.280825\n",
            "58       25.987815           5.280825\n",
            "59       25.987815           5.280825\n",
            "60       24.132031           0.389042\n",
            "61       24.132031           0.389042\n",
            "62       24.132031           0.389042\n",
            "63       24.132031           0.389042\n",
            "64       27.559140           0.780698\n",
            "65       27.559140           0.780698\n",
            "66       27.559140           0.780698\n",
            "67       27.559140           0.780698\n",
            "68       27.559140           0.780698\n",
            "69       27.559140           0.780698\n",
            "70       27.559140           0.780698\n",
            "71       27.559140           0.780698\n",
            "72       27.559140           0.780698\n",
            "73       27.559140           0.780698\n",
            "74       27.260748           0.830341\n",
            "75       27.260748           0.830341\n",
            "76       27.260748           0.830341\n",
            "77       27.260748           0.830341\n",
            "78       27.260748           0.830341\n",
            "79       27.260748           0.830341\n",
            "80       27.260748           0.830341\n",
            "81       27.260748           0.830341\n",
            "82       27.260748           0.830341\n",
            "83       27.260748           0.830341\n",
            "84       27.260748           0.830341\n",
            "85       27.260748           0.830341\n",
            "86       27.260748           0.830341\n",
            "87       27.260748           0.830341\n",
            "88       27.260748           0.830341\n",
            "89       27.260748           0.830341\n",
            "90       27.260748           0.830341\n",
            "91       27.260748           0.830341\n",
            "92       27.260748           0.830341\n",
            "93       27.260748           0.830341\n",
            "94       27.260748           0.830341\n",
            "95       27.260748           0.830341\n",
            "96       27.260748           0.830341\n",
            "97       27.260748           0.830341\n",
            "98       27.260748           0.830341\n",
            "99       27.260748           0.830341\n",
            "100      27.260748           0.830341\n",
            "101      27.260748           0.830341\n",
            "102      27.260748           0.830341\n",
            "103      27.260748           0.830341\n",
            "104      27.260748           0.830341\n",
            "105      27.260748           0.830341\n",
            "106      27.260748           0.830341\n",
            "107      27.260748           0.830341\n",
            "108      27.260748           0.830341\n",
            "\n",
            "PREDICTED:\n",
            "     d18O_cel_mean  d18O_cel_variance\n",
            "0        26.905420           0.536932\n",
            "1        26.905420           0.536932\n",
            "2        26.905420           0.536932\n",
            "3        26.905420           0.536932\n",
            "4        26.905420           0.536932\n",
            "5        26.905420           0.536932\n",
            "6        26.905420           0.536932\n",
            "7        26.905420           0.536932\n",
            "8        26.905420           0.536932\n",
            "9        26.905420           0.536932\n",
            "10       26.905420           0.536932\n",
            "11       26.905420           0.536932\n",
            "12       26.905420           0.536932\n",
            "13       26.905420           0.536932\n",
            "14       26.905420           0.536932\n",
            "15       26.905420           0.536932\n",
            "16       26.905420           0.536932\n",
            "17       26.905420           0.536932\n",
            "18       26.905420           0.536932\n",
            "19       26.905420           0.536932\n",
            "20       26.905420           0.536932\n",
            "21       26.905420           0.536932\n",
            "22       26.905420           0.536932\n",
            "23       26.905420           0.536932\n",
            "24       26.905420           0.536932\n",
            "25       26.905420           0.536932\n",
            "26       26.905420           0.536932\n",
            "27       26.905420           0.536932\n",
            "28       26.905420           0.536932\n",
            "29       26.905420           0.536932\n",
            "30       26.905420           0.536932\n",
            "31       26.905420           0.536932\n",
            "32       26.905420           0.536932\n",
            "33       26.905420           0.536932\n",
            "34       26.905420           0.536932\n",
            "35       26.905420           0.536932\n",
            "36       26.905420           0.536932\n",
            "37       26.905420           0.536932\n",
            "38       26.905420           0.536932\n",
            "39       26.905420           0.536932\n",
            "40       25.050524           2.297126\n",
            "41       25.050524           2.297126\n",
            "42       25.050524           2.297126\n",
            "43       25.050524           2.297126\n",
            "44       25.050524           2.297126\n",
            "45       25.106853           2.422469\n",
            "46       25.106853           2.422469\n",
            "47       25.106853           2.422469\n",
            "48       25.106853           2.422469\n",
            "49       25.106853           2.422469\n",
            "50       25.156002           2.385101\n",
            "51       25.156002           2.385101\n",
            "52       25.156002           2.385101\n",
            "53       25.156002           2.385101\n",
            "54       25.156002           2.385101\n",
            "55       25.018280           2.489763\n",
            "56       25.018280           2.489763\n",
            "57       25.018280           2.489763\n",
            "58       25.018280           2.489763\n",
            "59       25.018280           2.489763\n",
            "60       25.126596           2.407570\n",
            "61       25.126596           2.407570\n",
            "62       25.126596           2.407570\n",
            "63       25.126596           2.407570\n",
            "64       23.200083           3.390790\n",
            "65       23.200083           3.390790\n",
            "66       23.200083           3.390790\n",
            "67       23.200083           3.390790\n",
            "68       23.200083           3.390790\n",
            "69       23.200083           3.390790\n",
            "70       23.200083           3.390790\n",
            "71       23.200083           3.390790\n",
            "72       23.200083           3.390790\n",
            "73       23.200083           3.390790\n",
            "74       23.285538           3.304089\n",
            "75       23.285538           3.304089\n",
            "76       23.285538           3.304089\n",
            "77       23.285538           3.304089\n",
            "78       23.285538           3.304089\n",
            "79       23.285538           3.304089\n",
            "80       23.285538           3.304089\n",
            "81       23.285538           3.304089\n",
            "82       23.285538           3.304089\n",
            "83       23.285538           3.304089\n",
            "84       23.285538           3.304089\n",
            "85       23.285538           3.304089\n",
            "86       23.285538           3.304089\n",
            "87       23.285538           3.304089\n",
            "88       23.285538           3.304089\n",
            "89       23.285538           3.304089\n",
            "90       23.285538           3.304089\n",
            "91       23.285538           3.304089\n",
            "92       23.285538           3.304089\n",
            "93       23.285538           3.304089\n",
            "94       23.285538           3.304089\n",
            "95       23.285538           3.304089\n",
            "96       23.285538           3.304089\n",
            "97       23.285538           3.304089\n",
            "98       23.285538           3.304089\n",
            "99       23.285538           3.304089\n",
            "100      23.285538           3.304089\n",
            "101      23.285538           3.304089\n",
            "102      23.285538           3.304089\n",
            "103      23.285538           3.304089\n",
            "104      23.285538           3.304089\n",
            "105      23.285538           3.304089\n",
            "106      23.285538           3.304089\n",
            "107      23.285538           3.304089\n",
            "108      23.285536           3.304089\n",
            "RMSE: 2.8422163418172057\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2023-07-12 21:21:56.328651: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype double and shape [109,12]\n",
            "\t [[{{node Placeholder/_0}}]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3) Grouped, random"
      ],
      "metadata": {
        "id": "n8pNR1CrvF2a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "grouped_random = {\n",
        "    'TRAIN' : os.path.join(FP_ROOT, 'amazon_sample_data/uc_davis_2023_08_12_train_random_grouped.csv'),\n",
        "    'TEST' : os.path.join(FP_ROOT, 'amazon_sample_data/uc_davis_2023_08_12_test_random_grouped.csv'),\n",
        "    'VALIDATION' : os.path.join(FP_ROOT, 'amazon_sample_data/uc_davis_2023_08_12_validation_random_grouped.csv'),\n",
        "}\n",
        "\n",
        "grouped_random_scaled = load_and_scale(grouped_random)\n",
        "train_and_evaluate(grouped_random_scaled, \"grouped_random\", training_batch_size=1)"
      ],
      "metadata": {
        "id": "rPONfgkjvJWz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "de827a16-7308-40c6-f868-c7235d5dabdb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Epoch 225/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6166 - val_loss: 1.0536\n",
            "Epoch 226/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6164 - val_loss: 1.0535\n",
            "Epoch 227/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6167 - val_loss: 1.0531\n",
            "Epoch 228/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6164 - val_loss: 1.0543\n",
            "Epoch 229/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6165 - val_loss: 1.0552\n",
            "Epoch 230/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6163 - val_loss: 1.0543\n",
            "Epoch 231/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6164 - val_loss: 1.0528\n",
            "Epoch 232/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6165 - val_loss: 1.0540\n",
            "Epoch 233/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6160 - val_loss: 1.0539\n",
            "Epoch 234/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6164 - val_loss: 1.0526\n",
            "Epoch 235/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6163 - val_loss: 1.0555\n",
            "Epoch 236/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6160 - val_loss: 1.0534\n",
            "Epoch 237/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6160 - val_loss: 1.0545\n",
            "Epoch 238/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6158 - val_loss: 1.0537\n",
            "Epoch 239/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6159 - val_loss: 1.0554\n",
            "Epoch 240/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6157 - val_loss: 1.0534\n",
            "Epoch 241/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6160 - val_loss: 1.0546\n",
            "Epoch 242/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6157 - val_loss: 1.0552\n",
            "Epoch 243/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6161 - val_loss: 1.0555\n",
            "Epoch 244/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6158 - val_loss: 1.0530\n",
            "Epoch 245/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6157 - val_loss: 1.0553\n",
            "Epoch 246/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6156 - val_loss: 1.0536\n",
            "Epoch 247/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6155 - val_loss: 1.0535\n",
            "Epoch 248/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6161 - val_loss: 1.0516\n",
            "Epoch 249/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 1.0538\n",
            "Epoch 250/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6154 - val_loss: 1.0540\n",
            "Epoch 251/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6155 - val_loss: 1.0528\n",
            "Epoch 252/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6154 - val_loss: 1.0533\n",
            "Epoch 253/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6153 - val_loss: 1.0532\n",
            "Epoch 254/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6150 - val_loss: 1.0530\n",
            "Epoch 255/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 1.0538\n",
            "Epoch 256/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 1.0526\n",
            "Epoch 257/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6148 - val_loss: 1.0541\n",
            "Epoch 258/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6147 - val_loss: 1.0542\n",
            "Epoch 259/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6147 - val_loss: 1.0532\n",
            "Epoch 260/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6147 - val_loss: 1.0529\n",
            "Epoch 261/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6147 - val_loss: 1.0544\n",
            "Epoch 262/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6150 - val_loss: 1.0531\n",
            "Epoch 263/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6147 - val_loss: 1.0543\n",
            "Epoch 264/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6145 - val_loss: 1.0543\n",
            "Epoch 265/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6147 - val_loss: 1.0518\n",
            "Epoch 266/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6143 - val_loss: 1.0533\n",
            "Epoch 267/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6143 - val_loss: 1.0540\n",
            "Epoch 268/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6143 - val_loss: 1.0543\n",
            "Epoch 269/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6145 - val_loss: 1.0532\n",
            "Epoch 270/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6145 - val_loss: 1.0558\n",
            "Epoch 271/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6144 - val_loss: 1.0538\n",
            "Epoch 272/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6140 - val_loss: 1.0544\n",
            "Epoch 273/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6140 - val_loss: 1.0546\n",
            "Epoch 274/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6140 - val_loss: 1.0542\n",
            "Epoch 275/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6138 - val_loss: 1.0537\n",
            "Epoch 276/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6139 - val_loss: 1.0543\n",
            "Epoch 277/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6135 - val_loss: 1.0539\n",
            "Epoch 278/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6135 - val_loss: 1.0533\n",
            "Epoch 279/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6135 - val_loss: 1.0533\n",
            "Epoch 280/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6136 - val_loss: 1.0524\n",
            "Epoch 281/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6136 - val_loss: 1.0540\n",
            "Epoch 282/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6137 - val_loss: 1.0517\n",
            "Epoch 283/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6134 - val_loss: 1.0541\n",
            "Epoch 284/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6132 - val_loss: 1.0528\n",
            "Epoch 285/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6132 - val_loss: 1.0534\n",
            "Epoch 286/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6131 - val_loss: 1.0530\n",
            "Epoch 287/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6131 - val_loss: 1.0537\n",
            "Epoch 288/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6133 - val_loss: 1.0544\n",
            "Epoch 289/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6137 - val_loss: 1.0544\n",
            "Epoch 290/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6130 - val_loss: 1.0548\n",
            "Epoch 291/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6130 - val_loss: 1.0524\n",
            "Epoch 292/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6132 - val_loss: 1.0545\n",
            "Epoch 293/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6131 - val_loss: 1.0535\n",
            "Epoch 294/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6126 - val_loss: 1.0530\n",
            "Epoch 295/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6126 - val_loss: 1.0524\n",
            "Epoch 296/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6127 - val_loss: 1.0522\n",
            "Epoch 297/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6126 - val_loss: 1.0518\n",
            "Epoch 298/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6125 - val_loss: 1.0514\n",
            "Epoch 299/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6127 - val_loss: 1.0538\n",
            "Epoch 300/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6124 - val_loss: 1.0533\n",
            "Epoch 301/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6123 - val_loss: 1.0533\n",
            "Epoch 302/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6122 - val_loss: 1.0539\n",
            "Epoch 303/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6125 - val_loss: 1.0528\n",
            "Epoch 304/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6121 - val_loss: 1.0534\n",
            "Epoch 305/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6123 - val_loss: 1.0530\n",
            "Epoch 306/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6121 - val_loss: 1.0524\n",
            "Epoch 307/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6120 - val_loss: 1.0542\n",
            "Epoch 308/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6120 - val_loss: 1.0516\n",
            "Epoch 309/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6120 - val_loss: 1.0543\n",
            "Epoch 310/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6115 - val_loss: 1.0535\n",
            "Epoch 311/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6118 - val_loss: 1.0515\n",
            "Epoch 312/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6116 - val_loss: 1.0540\n",
            "Epoch 313/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6116 - val_loss: 1.0519\n",
            "Epoch 314/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6116 - val_loss: 1.0534\n",
            "Epoch 315/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6113 - val_loss: 1.0531\n",
            "Epoch 316/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6115 - val_loss: 1.0540\n",
            "Epoch 317/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6117 - val_loss: 1.0518\n",
            "Epoch 318/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6119 - val_loss: 1.0537\n",
            "Epoch 319/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6113 - val_loss: 1.0528\n",
            "Epoch 320/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6114 - val_loss: 1.0517\n",
            "Epoch 321/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6110 - val_loss: 1.0534\n",
            "Epoch 322/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6112 - val_loss: 1.0541\n",
            "Epoch 323/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6110 - val_loss: 1.0520\n",
            "Epoch 324/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6112 - val_loss: 1.0513\n",
            "Epoch 325/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6107 - val_loss: 1.0528\n",
            "Epoch 326/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6109 - val_loss: 1.0511\n",
            "Epoch 327/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6106 - val_loss: 1.0534\n",
            "Epoch 328/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6105 - val_loss: 1.0527\n",
            "Epoch 329/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6105 - val_loss: 1.0543\n",
            "Epoch 330/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6106 - val_loss: 1.0539\n",
            "Epoch 331/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6106 - val_loss: 1.0546\n",
            "Epoch 332/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6105 - val_loss: 1.0519\n",
            "Epoch 333/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6105 - val_loss: 1.0530\n",
            "Epoch 334/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6103 - val_loss: 1.0523\n",
            "Epoch 335/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6100 - val_loss: 1.0533\n",
            "Epoch 336/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6100 - val_loss: 1.0533\n",
            "Epoch 337/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6099 - val_loss: 1.0536\n",
            "Epoch 338/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6100 - val_loss: 1.0524\n",
            "Epoch 339/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6099 - val_loss: 1.0531\n",
            "Epoch 340/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6099 - val_loss: 1.0530\n",
            "Epoch 341/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6101 - val_loss: 1.0518\n",
            "Epoch 342/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6101 - val_loss: 1.0544\n",
            "Epoch 343/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6097 - val_loss: 1.0524\n",
            "Epoch 344/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6096 - val_loss: 1.0513\n",
            "Epoch 345/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6095 - val_loss: 1.0532\n",
            "Epoch 346/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6095 - val_loss: 1.0535\n",
            "Epoch 347/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6094 - val_loss: 1.0527\n",
            "Epoch 348/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6093 - val_loss: 1.0534\n",
            "Epoch 349/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6098 - val_loss: 1.0552\n",
            "Epoch 350/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6093 - val_loss: 1.0518\n",
            "Epoch 351/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6092 - val_loss: 1.0531\n",
            "Epoch 352/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6089 - val_loss: 1.0526\n",
            "Epoch 353/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6092 - val_loss: 1.0543\n",
            "Epoch 354/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6093 - val_loss: 1.0511\n",
            "Epoch 355/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6089 - val_loss: 1.0527\n",
            "Epoch 356/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6088 - val_loss: 1.0528\n",
            "Epoch 357/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6087 - val_loss: 1.0544\n",
            "Epoch 358/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6084 - val_loss: 1.0527\n",
            "Epoch 359/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6088 - val_loss: 1.0533\n",
            "Epoch 360/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6087 - val_loss: 1.0528\n",
            "Epoch 361/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6085 - val_loss: 1.0531\n",
            "Epoch 362/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6086 - val_loss: 1.0523\n",
            "Epoch 363/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6084 - val_loss: 1.0533\n",
            "Epoch 364/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6084 - val_loss: 1.0542\n",
            "Epoch 365/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6082 - val_loss: 1.0537\n",
            "Epoch 366/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6084 - val_loss: 1.0548\n",
            "Epoch 367/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6080 - val_loss: 1.0541\n",
            "Epoch 368/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6080 - val_loss: 1.0523\n",
            "Epoch 369/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6078 - val_loss: 1.0524\n",
            "Epoch 370/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6081 - val_loss: 1.0537\n",
            "Epoch 371/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.6079 - val_loss: 1.0540\n",
            "Epoch 372/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6078 - val_loss: 1.0534\n",
            "Epoch 373/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.6075 - val_loss: 1.0528\n",
            "Epoch 374/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6077 - val_loss: 1.0546\n",
            "Epoch 375/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6074 - val_loss: 1.0519\n",
            "Epoch 376/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6076 - val_loss: 1.0523\n",
            "Epoch 377/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6077 - val_loss: 1.0526\n",
            "Epoch 378/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6074 - val_loss: 1.0507\n",
            "Epoch 379/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6074 - val_loss: 1.0512\n",
            "Epoch 380/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6078 - val_loss: 1.0526\n",
            "Epoch 381/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6069 - val_loss: 1.0529\n",
            "Epoch 382/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6072 - val_loss: 1.0538\n",
            "Epoch 383/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6072 - val_loss: 1.0507\n",
            "Epoch 384/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6069 - val_loss: 1.0518\n",
            "Epoch 385/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6067 - val_loss: 1.0534\n",
            "Epoch 386/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6067 - val_loss: 1.0536\n",
            "Epoch 387/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6065 - val_loss: 1.0528\n",
            "Epoch 388/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6066 - val_loss: 1.0528\n",
            "Epoch 389/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6064 - val_loss: 1.0536\n",
            "Epoch 390/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6065 - val_loss: 1.0546\n",
            "Epoch 391/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.6064 - val_loss: 1.0536\n",
            "Epoch 392/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6064 - val_loss: 1.0539\n",
            "Epoch 393/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6064 - val_loss: 1.0521\n",
            "Epoch 394/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6063 - val_loss: 1.0524\n",
            "Epoch 395/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6062 - val_loss: 1.0530\n",
            "Epoch 396/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6063 - val_loss: 1.0514\n",
            "Epoch 397/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6061 - val_loss: 1.0534\n",
            "Epoch 398/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6060 - val_loss: 1.0533\n",
            "Epoch 399/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6059 - val_loss: 1.0522\n",
            "Epoch 400/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6060 - val_loss: 1.0514\n",
            "Epoch 401/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6058 - val_loss: 1.0511\n",
            "Epoch 402/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6054 - val_loss: 1.0525\n",
            "Epoch 403/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6058 - val_loss: 1.0544\n",
            "Epoch 404/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6055 - val_loss: 1.0521\n",
            "Epoch 405/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6056 - val_loss: 1.0526\n",
            "Epoch 406/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6053 - val_loss: 1.0539\n",
            "Epoch 407/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6054 - val_loss: 1.0541\n",
            "Epoch 408/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6060 - val_loss: 1.0508\n",
            "Epoch 409/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6050 - val_loss: 1.0532\n",
            "Epoch 410/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6050 - val_loss: 1.0538\n",
            "Epoch 411/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6049 - val_loss: 1.0542\n",
            "Epoch 412/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6053 - val_loss: 1.0513\n",
            "Epoch 413/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6046 - val_loss: 1.0535\n",
            "Epoch 414/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6049 - val_loss: 1.0548\n",
            "Epoch 415/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.6048 - val_loss: 1.0524\n",
            "Epoch 416/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.6045 - val_loss: 1.0518\n",
            "Epoch 417/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.6047 - val_loss: 1.0533\n",
            "Epoch 418/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6047 - val_loss: 1.0548\n",
            "Epoch 419/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6045 - val_loss: 1.0534\n",
            "Epoch 420/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6043 - val_loss: 1.0517\n",
            "Epoch 421/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6043 - val_loss: 1.0530\n",
            "Epoch 422/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6043 - val_loss: 1.0517\n",
            "Epoch 423/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6042 - val_loss: 1.0541\n",
            "Epoch 424/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6040 - val_loss: 1.0524\n",
            "Epoch 425/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6041 - val_loss: 1.0531\n",
            "Epoch 426/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6038 - val_loss: 1.0531\n",
            "Epoch 427/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6045 - val_loss: 1.0536\n",
            "Epoch 428/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6039 - val_loss: 1.0541\n",
            "Epoch 429/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6036 - val_loss: 1.0522\n",
            "Epoch 430/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6039 - val_loss: 1.0525\n",
            "Epoch 431/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6036 - val_loss: 1.0534\n",
            "Epoch 432/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6036 - val_loss: 1.0533\n",
            "Epoch 433/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6031 - val_loss: 1.0522\n",
            "Epoch 434/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6034 - val_loss: 1.0518\n",
            "Epoch 435/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6034 - val_loss: 1.0527\n",
            "Epoch 436/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6034 - val_loss: 1.0544\n",
            "Epoch 437/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6034 - val_loss: 1.0525\n",
            "Epoch 438/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6032 - val_loss: 1.0515\n",
            "Epoch 439/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6030 - val_loss: 1.0542\n",
            "Epoch 440/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6031 - val_loss: 1.0520\n",
            "Epoch 441/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6027 - val_loss: 1.0520\n",
            "Epoch 442/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6027 - val_loss: 1.0521\n",
            "Epoch 443/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6027 - val_loss: 1.0529\n",
            "Epoch 444/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6029 - val_loss: 1.0541\n",
            "Epoch 445/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.6025 - val_loss: 1.0517\n",
            "Epoch 446/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6024 - val_loss: 1.0527\n",
            "Epoch 447/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6026 - val_loss: 1.0514\n",
            "Epoch 448/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6023 - val_loss: 1.0547\n",
            "Epoch 449/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6023 - val_loss: 1.0521\n",
            "Epoch 450/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6021 - val_loss: 1.0515\n",
            "Epoch 451/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6021 - val_loss: 1.0526\n",
            "Epoch 452/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6019 - val_loss: 1.0535\n",
            "Epoch 453/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6023 - val_loss: 1.0515\n",
            "Epoch 454/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6016 - val_loss: 1.0525\n",
            "Epoch 455/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6017 - val_loss: 1.0533\n",
            "Epoch 456/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6017 - val_loss: 1.0526\n",
            "Epoch 457/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6015 - val_loss: 1.0523\n",
            "Epoch 458/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6018 - val_loss: 1.0509\n",
            "Epoch 459/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6015 - val_loss: 1.0528\n",
            "Epoch 460/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6014 - val_loss: 1.0530\n",
            "Epoch 461/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6014 - val_loss: 1.0535\n",
            "Epoch 462/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6012 - val_loss: 1.0526\n",
            "Epoch 463/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6011 - val_loss: 1.0524\n",
            "Epoch 464/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6012 - val_loss: 1.0526\n",
            "Epoch 465/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6010 - val_loss: 1.0541\n",
            "Epoch 466/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6010 - val_loss: 1.0532\n",
            "Epoch 467/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6008 - val_loss: 1.0539\n",
            "Epoch 468/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6012 - val_loss: 1.0539\n",
            "Epoch 469/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6007 - val_loss: 1.0513\n",
            "Epoch 470/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6007 - val_loss: 1.0522\n",
            "Epoch 471/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6005 - val_loss: 1.0532\n",
            "Epoch 472/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6005 - val_loss: 1.0521\n",
            "Epoch 473/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6004 - val_loss: 1.0528\n",
            "Epoch 474/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6004 - val_loss: 1.0525\n",
            "Epoch 475/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6003 - val_loss: 1.0524\n",
            "Epoch 476/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5999 - val_loss: 1.0530\n",
            "Epoch 477/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6004 - val_loss: 1.0543\n",
            "Epoch 478/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6008 - val_loss: 1.0531\n",
            "Epoch 479/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6002 - val_loss: 1.0515\n",
            "Epoch 480/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5997 - val_loss: 1.0521\n",
            "Epoch 481/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5997 - val_loss: 1.0520\n",
            "Epoch 482/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6000 - val_loss: 1.0511\n",
            "Epoch 483/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.6005 - val_loss: 1.0554\n",
            "Epoch 484/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5995 - val_loss: 1.0524\n",
            "Epoch 485/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5995 - val_loss: 1.0515\n",
            "Epoch 486/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5992 - val_loss: 1.0533\n",
            "Epoch 487/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5993 - val_loss: 1.0523\n",
            "Epoch 488/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5992 - val_loss: 1.0520\n",
            "Epoch 489/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5992 - val_loss: 1.0537\n",
            "Epoch 490/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5992 - val_loss: 1.0520\n",
            "Epoch 491/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5990 - val_loss: 1.0517\n",
            "Epoch 492/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5993 - val_loss: 1.0512\n",
            "Epoch 493/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5989 - val_loss: 1.0511\n",
            "Epoch 494/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5989 - val_loss: 1.0531\n",
            "Epoch 495/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5990 - val_loss: 1.0523\n",
            "Epoch 496/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5987 - val_loss: 1.0522\n",
            "Epoch 497/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5986 - val_loss: 1.0530\n",
            "Epoch 498/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5986 - val_loss: 1.0526\n",
            "Epoch 499/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5989 - val_loss: 1.0503\n",
            "Epoch 500/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5984 - val_loss: 1.0540\n",
            "Epoch 501/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5980 - val_loss: 1.0522\n",
            "Epoch 502/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5980 - val_loss: 1.0535\n",
            "Epoch 503/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5986 - val_loss: 1.0545\n",
            "Epoch 504/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5990 - val_loss: 1.0499\n",
            "Epoch 505/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5980 - val_loss: 1.0530\n",
            "Epoch 506/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5981 - val_loss: 1.0515\n",
            "Epoch 507/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5979 - val_loss: 1.0531\n",
            "Epoch 508/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5979 - val_loss: 1.0515\n",
            "Epoch 509/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5977 - val_loss: 1.0533\n",
            "Epoch 510/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5975 - val_loss: 1.0518\n",
            "Epoch 511/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5983 - val_loss: 1.0554\n",
            "Epoch 512/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5972 - val_loss: 1.0531\n",
            "Epoch 513/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5974 - val_loss: 1.0514\n",
            "Epoch 514/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5970 - val_loss: 1.0523\n",
            "Epoch 515/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5970 - val_loss: 1.0516\n",
            "Epoch 516/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5970 - val_loss: 1.0511\n",
            "Epoch 517/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5970 - val_loss: 1.0540\n",
            "Epoch 518/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5976 - val_loss: 1.0514\n",
            "Epoch 519/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5971 - val_loss: 1.0529\n",
            "Epoch 520/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5967 - val_loss: 1.0531\n",
            "Epoch 521/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5966 - val_loss: 1.0527\n",
            "Epoch 522/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5970 - val_loss: 1.0516\n",
            "Epoch 523/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5968 - val_loss: 1.0542\n",
            "Epoch 524/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5966 - val_loss: 1.0523\n",
            "Epoch 525/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5969 - val_loss: 1.0497\n",
            "Epoch 526/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5962 - val_loss: 1.0536\n",
            "Epoch 527/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5963 - val_loss: 1.0544\n",
            "Epoch 528/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5961 - val_loss: 1.0521\n",
            "Epoch 529/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5958 - val_loss: 1.0518\n",
            "Epoch 530/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5962 - val_loss: 1.0530\n",
            "Epoch 531/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5961 - val_loss: 1.0541\n",
            "Epoch 532/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5955 - val_loss: 1.0529\n",
            "Epoch 533/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5955 - val_loss: 1.0532\n",
            "Epoch 534/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5956 - val_loss: 1.0533\n",
            "Epoch 535/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5957 - val_loss: 1.0526\n",
            "Epoch 536/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5953 - val_loss: 1.0518\n",
            "Epoch 537/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5954 - val_loss: 1.0513\n",
            "Epoch 538/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5951 - val_loss: 1.0532\n",
            "Epoch 539/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5959 - val_loss: 1.0510\n",
            "Epoch 540/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5953 - val_loss: 1.0531\n",
            "Epoch 541/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5948 - val_loss: 1.0532\n",
            "Epoch 542/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5952 - val_loss: 1.0545\n",
            "Epoch 543/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5955 - val_loss: 1.0522\n",
            "Epoch 544/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5952 - val_loss: 1.0537\n",
            "Epoch 545/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5945 - val_loss: 1.0521\n",
            "Epoch 546/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5946 - val_loss: 1.0513\n",
            "Epoch 547/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5944 - val_loss: 1.0517\n",
            "Epoch 548/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5943 - val_loss: 1.0521\n",
            "Epoch 549/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5944 - val_loss: 1.0520\n",
            "Epoch 550/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5941 - val_loss: 1.0527\n",
            "Epoch 551/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5941 - val_loss: 1.0534\n",
            "Epoch 552/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5941 - val_loss: 1.0512\n",
            "Epoch 553/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5941 - val_loss: 1.0531\n",
            "Epoch 554/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5942 - val_loss: 1.0507\n",
            "Epoch 555/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5938 - val_loss: 1.0525\n",
            "Epoch 556/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5938 - val_loss: 1.0530\n",
            "Epoch 557/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5934 - val_loss: 1.0532\n",
            "Epoch 558/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5939 - val_loss: 1.0512\n",
            "Epoch 559/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5934 - val_loss: 1.0514\n",
            "Epoch 560/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5936 - val_loss: 1.0536\n",
            "Epoch 561/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5933 - val_loss: 1.0524\n",
            "Epoch 562/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5934 - val_loss: 1.0527\n",
            "Epoch 563/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5930 - val_loss: 1.0541\n",
            "Epoch 564/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5935 - val_loss: 1.0544\n",
            "Epoch 565/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5933 - val_loss: 1.0507\n",
            "Epoch 566/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5931 - val_loss: 1.0523\n",
            "Epoch 567/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5932 - val_loss: 1.0522\n",
            "Epoch 568/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5928 - val_loss: 1.0508\n",
            "Epoch 569/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5927 - val_loss: 1.0537\n",
            "Epoch 570/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5924 - val_loss: 1.0515\n",
            "Epoch 571/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5924 - val_loss: 1.0508\n",
            "Epoch 572/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5925 - val_loss: 1.0534\n",
            "Epoch 573/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5921 - val_loss: 1.0524\n",
            "Epoch 574/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5927 - val_loss: 1.0503\n",
            "Epoch 575/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5920 - val_loss: 1.0536\n",
            "Epoch 576/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5920 - val_loss: 1.0546\n",
            "Epoch 577/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5920 - val_loss: 1.0543\n",
            "Epoch 578/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5917 - val_loss: 1.0515\n",
            "Epoch 579/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5917 - val_loss: 1.0520\n",
            "Epoch 580/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5917 - val_loss: 1.0528\n",
            "Epoch 581/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5915 - val_loss: 1.0532\n",
            "Epoch 582/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5914 - val_loss: 1.0515\n",
            "Epoch 583/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5913 - val_loss: 1.0541\n",
            "Epoch 584/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5912 - val_loss: 1.0525\n",
            "Epoch 585/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5914 - val_loss: 1.0512\n",
            "Epoch 586/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5910 - val_loss: 1.0518\n",
            "Epoch 587/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5912 - val_loss: 1.0534\n",
            "Epoch 588/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5908 - val_loss: 1.0530\n",
            "Epoch 589/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5907 - val_loss: 1.0534\n",
            "Epoch 590/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5910 - val_loss: 1.0503\n",
            "Epoch 591/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5906 - val_loss: 1.0516\n",
            "Epoch 592/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5906 - val_loss: 1.0519\n",
            "Epoch 593/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5906 - val_loss: 1.0530\n",
            "Epoch 594/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5904 - val_loss: 1.0534\n",
            "Epoch 595/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5909 - val_loss: 1.0526\n",
            "Epoch 596/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5909 - val_loss: 1.0510\n",
            "Epoch 597/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5899 - val_loss: 1.0524\n",
            "Epoch 598/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5900 - val_loss: 1.0532\n",
            "Epoch 599/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5899 - val_loss: 1.0518\n",
            "Epoch 600/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5902 - val_loss: 1.0541\n",
            "Epoch 601/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5908 - val_loss: 1.0564\n",
            "Epoch 602/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5903 - val_loss: 1.0502\n",
            "Epoch 603/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5897 - val_loss: 1.0503\n",
            "Epoch 604/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5904 - val_loss: 1.0510\n",
            "Epoch 605/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5895 - val_loss: 1.0532\n",
            "Epoch 606/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5892 - val_loss: 1.0530\n",
            "Epoch 607/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5893 - val_loss: 1.0526\n",
            "Epoch 608/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5895 - val_loss: 1.0542\n",
            "Epoch 609/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5896 - val_loss: 1.0517\n",
            "Epoch 610/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5893 - val_loss: 1.0544\n",
            "Epoch 611/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5888 - val_loss: 1.0535\n",
            "Epoch 612/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5890 - val_loss: 1.0534\n",
            "Epoch 613/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5886 - val_loss: 1.0521\n",
            "Epoch 614/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5884 - val_loss: 1.0525\n",
            "Epoch 615/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5886 - val_loss: 1.0537\n",
            "Epoch 616/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5883 - val_loss: 1.0523\n",
            "Epoch 617/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5883 - val_loss: 1.0516\n",
            "Epoch 618/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5881 - val_loss: 1.0508\n",
            "Epoch 619/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5888 - val_loss: 1.0553\n",
            "Epoch 620/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5883 - val_loss: 1.0511\n",
            "Epoch 621/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5884 - val_loss: 1.0511\n",
            "Epoch 622/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5879 - val_loss: 1.0523\n",
            "Epoch 623/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5880 - val_loss: 1.0532\n",
            "Epoch 624/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5878 - val_loss: 1.0542\n",
            "Epoch 625/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5875 - val_loss: 1.0525\n",
            "Epoch 626/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5874 - val_loss: 1.0522\n",
            "Epoch 627/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5875 - val_loss: 1.0537\n",
            "Epoch 628/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5872 - val_loss: 1.0511\n",
            "Epoch 629/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5872 - val_loss: 1.0525\n",
            "Epoch 630/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5873 - val_loss: 1.0528\n",
            "Epoch 631/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5872 - val_loss: 1.0514\n",
            "Epoch 632/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5871 - val_loss: 1.0496\n",
            "Epoch 633/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5866 - val_loss: 1.0517\n",
            "Epoch 634/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5869 - val_loss: 1.0542\n",
            "Epoch 635/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5868 - val_loss: 1.0540\n",
            "Epoch 636/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5871 - val_loss: 1.0540\n",
            "Epoch 637/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5865 - val_loss: 1.0516\n",
            "Epoch 638/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5865 - val_loss: 1.0514\n",
            "Epoch 639/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5866 - val_loss: 1.0510\n",
            "Epoch 640/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5863 - val_loss: 1.0501\n",
            "Epoch 641/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5861 - val_loss: 1.0507\n",
            "Epoch 642/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5861 - val_loss: 1.0509\n",
            "Epoch 643/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5862 - val_loss: 1.0543\n",
            "Epoch 644/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5861 - val_loss: 1.0514\n",
            "Epoch 645/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5859 - val_loss: 1.0540\n",
            "Epoch 646/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5858 - val_loss: 1.0497\n",
            "Epoch 647/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5854 - val_loss: 1.0518\n",
            "Epoch 648/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5856 - val_loss: 1.0528\n",
            "Epoch 649/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5853 - val_loss: 1.0518\n",
            "Epoch 650/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5856 - val_loss: 1.0520\n",
            "Epoch 651/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5854 - val_loss: 1.0515\n",
            "Epoch 652/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5854 - val_loss: 1.0499\n",
            "Epoch 653/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5856 - val_loss: 1.0534\n",
            "Epoch 654/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5850 - val_loss: 1.0538\n",
            "Epoch 655/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5849 - val_loss: 1.0518\n",
            "Epoch 656/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5849 - val_loss: 1.0524\n",
            "Epoch 657/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5851 - val_loss: 1.0530\n",
            "Epoch 658/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5848 - val_loss: 1.0535\n",
            "Epoch 659/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5851 - val_loss: 1.0494\n",
            "Epoch 660/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5847 - val_loss: 1.0506\n",
            "Epoch 661/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5849 - val_loss: 1.0548\n",
            "Epoch 662/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5842 - val_loss: 1.0520\n",
            "Epoch 663/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5841 - val_loss: 1.0524\n",
            "Epoch 664/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5841 - val_loss: 1.0506\n",
            "Epoch 665/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5841 - val_loss: 1.0527\n",
            "Epoch 666/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5842 - val_loss: 1.0528\n",
            "Epoch 667/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5842 - val_loss: 1.0504\n",
            "Epoch 668/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5839 - val_loss: 1.0545\n",
            "Epoch 669/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5835 - val_loss: 1.0519\n",
            "Epoch 670/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5838 - val_loss: 1.0508\n",
            "Epoch 671/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5837 - val_loss: 1.0514\n",
            "Epoch 672/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5838 - val_loss: 1.0555\n",
            "Epoch 673/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5835 - val_loss: 1.0525\n",
            "Epoch 674/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5833 - val_loss: 1.0516\n",
            "Epoch 675/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5830 - val_loss: 1.0512\n",
            "Epoch 676/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5828 - val_loss: 1.0534\n",
            "Epoch 677/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5831 - val_loss: 1.0517\n",
            "Epoch 678/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5828 - val_loss: 1.0535\n",
            "Epoch 679/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5829 - val_loss: 1.0509\n",
            "Epoch 680/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5828 - val_loss: 1.0540\n",
            "Epoch 681/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5825 - val_loss: 1.0505\n",
            "Epoch 682/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5822 - val_loss: 1.0515\n",
            "Epoch 683/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5823 - val_loss: 1.0513\n",
            "Epoch 684/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5826 - val_loss: 1.0525\n",
            "Epoch 685/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5823 - val_loss: 1.0513\n",
            "Epoch 686/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5821 - val_loss: 1.0509\n",
            "Epoch 687/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5823 - val_loss: 1.0509\n",
            "Epoch 688/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5822 - val_loss: 1.0523\n",
            "Epoch 689/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5818 - val_loss: 1.0527\n",
            "Epoch 690/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5817 - val_loss: 1.0518\n",
            "Epoch 691/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5814 - val_loss: 1.0510\n",
            "Epoch 692/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5813 - val_loss: 1.0520\n",
            "Epoch 693/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5811 - val_loss: 1.0526\n",
            "Epoch 694/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5811 - val_loss: 1.0515\n",
            "Epoch 695/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5813 - val_loss: 1.0535\n",
            "Epoch 696/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5823 - val_loss: 1.0546\n",
            "Epoch 697/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5810 - val_loss: 1.0526\n",
            "Epoch 698/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5807 - val_loss: 1.0526\n",
            "Epoch 699/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5807 - val_loss: 1.0515\n",
            "Epoch 700/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5808 - val_loss: 1.0530\n",
            "Epoch 701/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5808 - val_loss: 1.0499\n",
            "Epoch 702/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5809 - val_loss: 1.0511\n",
            "Epoch 703/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5803 - val_loss: 1.0525\n",
            "Epoch 704/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5811 - val_loss: 1.0521\n",
            "Epoch 705/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5808 - val_loss: 1.0526\n",
            "Epoch 706/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5799 - val_loss: 1.0510\n",
            "Epoch 707/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5800 - val_loss: 1.0543\n",
            "Epoch 708/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5802 - val_loss: 1.0502\n",
            "Epoch 709/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5797 - val_loss: 1.0514\n",
            "Epoch 710/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5804 - val_loss: 1.0547\n",
            "Epoch 711/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5797 - val_loss: 1.0502\n",
            "Epoch 712/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5793 - val_loss: 1.0510\n",
            "Epoch 713/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5791 - val_loss: 1.0525\n",
            "Epoch 714/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5794 - val_loss: 1.0517\n",
            "Epoch 715/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5795 - val_loss: 1.0547\n",
            "Epoch 716/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5793 - val_loss: 1.0514\n",
            "Epoch 717/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5788 - val_loss: 1.0516\n",
            "Epoch 718/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5792 - val_loss: 1.0527\n",
            "Epoch 719/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5790 - val_loss: 1.0498\n",
            "Epoch 720/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5791 - val_loss: 1.0534\n",
            "Epoch 721/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5784 - val_loss: 1.0521\n",
            "Epoch 722/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5792 - val_loss: 1.0500\n",
            "Epoch 723/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5790 - val_loss: 1.0521\n",
            "Epoch 724/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5782 - val_loss: 1.0529\n",
            "Epoch 725/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5784 - val_loss: 1.0545\n",
            "Epoch 726/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5785 - val_loss: 1.0497\n",
            "Epoch 727/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5780 - val_loss: 1.0527\n",
            "Epoch 728/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5785 - val_loss: 1.0525\n",
            "Epoch 729/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5778 - val_loss: 1.0537\n",
            "Epoch 730/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5782 - val_loss: 1.0537\n",
            "Epoch 731/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5775 - val_loss: 1.0528\n",
            "Epoch 732/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5778 - val_loss: 1.0518\n",
            "Epoch 733/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5773 - val_loss: 1.0513\n",
            "Epoch 734/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5773 - val_loss: 1.0533\n",
            "Epoch 735/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5774 - val_loss: 1.0522\n",
            "Epoch 736/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5770 - val_loss: 1.0517\n",
            "Epoch 737/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5776 - val_loss: 1.0538\n",
            "Epoch 738/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5768 - val_loss: 1.0516\n",
            "Epoch 739/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5771 - val_loss: 1.0504\n",
            "Epoch 740/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5765 - val_loss: 1.0520\n",
            "Epoch 741/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5771 - val_loss: 1.0528\n",
            "Epoch 742/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5771 - val_loss: 1.0502\n",
            "Epoch 743/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5764 - val_loss: 1.0537\n",
            "Epoch 744/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5765 - val_loss: 1.0512\n",
            "Epoch 745/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5770 - val_loss: 1.0532\n",
            "Epoch 746/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5761 - val_loss: 1.0521\n",
            "Epoch 747/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5761 - val_loss: 1.0531\n",
            "Epoch 748/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5759 - val_loss: 1.0517\n",
            "Epoch 749/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5759 - val_loss: 1.0509\n",
            "Epoch 750/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5757 - val_loss: 1.0520\n",
            "Epoch 751/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5758 - val_loss: 1.0540\n",
            "Epoch 752/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5756 - val_loss: 1.0527\n",
            "Epoch 753/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5754 - val_loss: 1.0505\n",
            "Epoch 754/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5755 - val_loss: 1.0523\n",
            "Epoch 755/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5754 - val_loss: 1.0516\n",
            "Epoch 756/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5751 - val_loss: 1.0525\n",
            "Epoch 757/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5754 - val_loss: 1.0530\n",
            "Epoch 758/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5749 - val_loss: 1.0508\n",
            "Epoch 759/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5748 - val_loss: 1.0530\n",
            "Epoch 760/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5750 - val_loss: 1.0514\n",
            "Epoch 761/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5748 - val_loss: 1.0518\n",
            "Epoch 762/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5746 - val_loss: 1.0529\n",
            "Epoch 763/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5744 - val_loss: 1.0515\n",
            "Epoch 764/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5746 - val_loss: 1.0531\n",
            "Epoch 765/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5745 - val_loss: 1.0510\n",
            "Epoch 766/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5740 - val_loss: 1.0526\n",
            "Epoch 767/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5742 - val_loss: 1.0515\n",
            "Epoch 768/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5739 - val_loss: 1.0518\n",
            "Epoch 769/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5744 - val_loss: 1.0535\n",
            "Epoch 770/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5746 - val_loss: 1.0543\n",
            "Epoch 771/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5741 - val_loss: 1.0514\n",
            "Epoch 772/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5741 - val_loss: 1.0486\n",
            "Epoch 773/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5737 - val_loss: 1.0520\n",
            "Epoch 774/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5735 - val_loss: 1.0529\n",
            "Epoch 775/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5733 - val_loss: 1.0517\n",
            "Epoch 776/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5734 - val_loss: 1.0530\n",
            "Epoch 777/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5736 - val_loss: 1.0533\n",
            "Epoch 778/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5731 - val_loss: 1.0540\n",
            "Epoch 779/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5741 - val_loss: 1.0477\n",
            "Epoch 780/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5725 - val_loss: 1.0502\n",
            "Epoch 781/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5724 - val_loss: 1.0521\n",
            "Epoch 782/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5725 - val_loss: 1.0523\n",
            "Epoch 783/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5730 - val_loss: 1.0493\n",
            "Epoch 784/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5723 - val_loss: 1.0536\n",
            "Epoch 785/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5728 - val_loss: 1.0497\n",
            "Epoch 786/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5721 - val_loss: 1.0526\n",
            "Epoch 787/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5725 - val_loss: 1.0507\n",
            "Epoch 788/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5722 - val_loss: 1.0549\n",
            "Epoch 789/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5726 - val_loss: 1.0527\n",
            "Epoch 790/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5724 - val_loss: 1.0559\n",
            "Epoch 791/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5715 - val_loss: 1.0539\n",
            "Epoch 792/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5714 - val_loss: 1.0541\n",
            "Epoch 793/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5719 - val_loss: 1.0501\n",
            "Epoch 794/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5714 - val_loss: 1.0540\n",
            "Epoch 795/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5717 - val_loss: 1.0506\n",
            "Epoch 796/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5717 - val_loss: 1.0521\n",
            "Epoch 797/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5712 - val_loss: 1.0522\n",
            "Epoch 798/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5708 - val_loss: 1.0532\n",
            "Epoch 799/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5712 - val_loss: 1.0502\n",
            "Epoch 800/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5701 - val_loss: 1.0529\n",
            "Epoch 801/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5707 - val_loss: 1.0548\n",
            "Epoch 802/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5704 - val_loss: 1.0511\n",
            "Epoch 803/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5705 - val_loss: 1.0541\n",
            "Epoch 804/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5702 - val_loss: 1.0529\n",
            "Epoch 805/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5699 - val_loss: 1.0522\n",
            "Epoch 806/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5701 - val_loss: 1.0525\n",
            "Epoch 807/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5700 - val_loss: 1.0504\n",
            "Epoch 808/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5698 - val_loss: 1.0512\n",
            "Epoch 809/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5695 - val_loss: 1.0515\n",
            "Epoch 810/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5699 - val_loss: 1.0504\n",
            "Epoch 811/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5693 - val_loss: 1.0532\n",
            "Epoch 812/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5696 - val_loss: 1.0553\n",
            "Epoch 813/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5700 - val_loss: 1.0504\n",
            "Epoch 814/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5693 - val_loss: 1.0546\n",
            "Epoch 815/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5687 - val_loss: 1.0516\n",
            "Epoch 816/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5689 - val_loss: 1.0535\n",
            "Epoch 817/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5686 - val_loss: 1.0518\n",
            "Epoch 818/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5689 - val_loss: 1.0496\n",
            "Epoch 819/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5685 - val_loss: 1.0516\n",
            "Epoch 820/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5684 - val_loss: 1.0519\n",
            "Epoch 821/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5691 - val_loss: 1.0527\n",
            "Epoch 822/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5679 - val_loss: 1.0519\n",
            "Epoch 823/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5683 - val_loss: 1.0510\n",
            "Epoch 824/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5680 - val_loss: 1.0535\n",
            "Epoch 825/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5679 - val_loss: 1.0505\n",
            "Epoch 826/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5677 - val_loss: 1.0518\n",
            "Epoch 827/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5676 - val_loss: 1.0518\n",
            "Epoch 828/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5676 - val_loss: 1.0544\n",
            "Epoch 829/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5675 - val_loss: 1.0539\n",
            "Epoch 830/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5676 - val_loss: 1.0509\n",
            "Epoch 831/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5672 - val_loss: 1.0507\n",
            "Epoch 832/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5672 - val_loss: 1.0544\n",
            "Epoch 833/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5670 - val_loss: 1.0508\n",
            "Epoch 834/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5673 - val_loss: 1.0503\n",
            "Epoch 835/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5665 - val_loss: 1.0513\n",
            "Epoch 836/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5663 - val_loss: 1.0529\n",
            "Epoch 837/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5666 - val_loss: 1.0517\n",
            "Epoch 838/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5666 - val_loss: 1.0516\n",
            "Epoch 839/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5664 - val_loss: 1.0537\n",
            "Epoch 840/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5663 - val_loss: 1.0507\n",
            "Epoch 841/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5662 - val_loss: 1.0535\n",
            "Epoch 842/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5661 - val_loss: 1.0545\n",
            "Epoch 843/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5661 - val_loss: 1.0515\n",
            "Epoch 844/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5661 - val_loss: 1.0511\n",
            "Epoch 845/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5663 - val_loss: 1.0528\n",
            "Epoch 846/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5654 - val_loss: 1.0528\n",
            "Epoch 847/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5653 - val_loss: 1.0508\n",
            "Epoch 848/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5652 - val_loss: 1.0519\n",
            "Epoch 849/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5654 - val_loss: 1.0520\n",
            "Epoch 850/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5650 - val_loss: 1.0507\n",
            "Epoch 851/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5648 - val_loss: 1.0516\n",
            "Epoch 852/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5650 - val_loss: 1.0536\n",
            "Epoch 853/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5647 - val_loss: 1.0510\n",
            "Epoch 854/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5647 - val_loss: 1.0524\n",
            "Epoch 855/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5646 - val_loss: 1.0505\n",
            "Epoch 856/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5643 - val_loss: 1.0521\n",
            "Epoch 857/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5646 - val_loss: 1.0525\n",
            "Epoch 858/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5647 - val_loss: 1.0547\n",
            "Epoch 859/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5640 - val_loss: 1.0515\n",
            "Epoch 860/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5638 - val_loss: 1.0524\n",
            "Epoch 861/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5646 - val_loss: 1.0533\n",
            "Epoch 862/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5642 - val_loss: 1.0538\n",
            "Epoch 863/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5635 - val_loss: 1.0517\n",
            "Epoch 864/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5637 - val_loss: 1.0507\n",
            "Epoch 865/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5637 - val_loss: 1.0517\n",
            "Epoch 866/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5639 - val_loss: 1.0487\n",
            "Epoch 867/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5637 - val_loss: 1.0512\n",
            "Epoch 868/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5633 - val_loss: 1.0548\n",
            "Epoch 869/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5629 - val_loss: 1.0522\n",
            "Epoch 870/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5627 - val_loss: 1.0515\n",
            "Epoch 871/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5632 - val_loss: 1.0542\n",
            "Epoch 872/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5630 - val_loss: 1.0488\n",
            "Epoch 873/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5624 - val_loss: 1.0510\n",
            "Epoch 874/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5626 - val_loss: 1.0506\n",
            "Epoch 875/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5624 - val_loss: 1.0544\n",
            "Epoch 876/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5623 - val_loss: 1.0536\n",
            "Epoch 877/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5620 - val_loss: 1.0533\n",
            "Epoch 878/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5622 - val_loss: 1.0509\n",
            "Epoch 879/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5618 - val_loss: 1.0534\n",
            "Epoch 880/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5618 - val_loss: 1.0517\n",
            "Epoch 881/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5620 - val_loss: 1.0494\n",
            "Epoch 882/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5620 - val_loss: 1.0509\n",
            "Epoch 883/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5621 - val_loss: 1.0499\n",
            "Epoch 884/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5622 - val_loss: 1.0558\n",
            "Epoch 885/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5614 - val_loss: 1.0533\n",
            "Epoch 886/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5615 - val_loss: 1.0497\n",
            "Epoch 887/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5615 - val_loss: 1.0542\n",
            "Epoch 888/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5620 - val_loss: 1.0495\n",
            "Epoch 889/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5621 - val_loss: 1.0551\n",
            "Epoch 890/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5605 - val_loss: 1.0510\n",
            "Epoch 891/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5611 - val_loss: 1.0504\n",
            "Epoch 892/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5605 - val_loss: 1.0509\n",
            "Epoch 893/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5607 - val_loss: 1.0501\n",
            "Epoch 894/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5607 - val_loss: 1.0513\n",
            "Epoch 895/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5605 - val_loss: 1.0524\n",
            "Epoch 896/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5602 - val_loss: 1.0508\n",
            "Epoch 897/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5603 - val_loss: 1.0536\n",
            "Epoch 898/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5598 - val_loss: 1.0528\n",
            "Epoch 899/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5599 - val_loss: 1.0532\n",
            "Epoch 900/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5609 - val_loss: 1.0513\n",
            "Epoch 901/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5594 - val_loss: 1.0512\n",
            "Epoch 902/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5601 - val_loss: 1.0552\n",
            "Epoch 903/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5596 - val_loss: 1.0518\n",
            "Epoch 904/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5595 - val_loss: 1.0509\n",
            "Epoch 905/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5590 - val_loss: 1.0510\n",
            "Epoch 906/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5593 - val_loss: 1.0522\n",
            "Epoch 907/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5593 - val_loss: 1.0505\n",
            "Epoch 908/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5592 - val_loss: 1.0560\n",
            "Epoch 909/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5589 - val_loss: 1.0548\n",
            "Epoch 910/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5592 - val_loss: 1.0514\n",
            "Epoch 911/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5588 - val_loss: 1.0544\n",
            "Epoch 912/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5596 - val_loss: 1.0513\n",
            "Epoch 913/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5589 - val_loss: 1.0529\n",
            "Epoch 914/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5584 - val_loss: 1.0546\n",
            "Epoch 915/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5583 - val_loss: 1.0526\n",
            "Epoch 916/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5581 - val_loss: 1.0525\n",
            "Epoch 917/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5579 - val_loss: 1.0521\n",
            "Epoch 918/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5578 - val_loss: 1.0518\n",
            "Epoch 919/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5578 - val_loss: 1.0519\n",
            "Epoch 920/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5577 - val_loss: 1.0507\n",
            "Epoch 921/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5575 - val_loss: 1.0531\n",
            "Epoch 922/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5573 - val_loss: 1.0530\n",
            "Epoch 923/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5573 - val_loss: 1.0533\n",
            "Epoch 924/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5575 - val_loss: 1.0514\n",
            "Epoch 925/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5574 - val_loss: 1.0542\n",
            "Epoch 926/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5570 - val_loss: 1.0536\n",
            "Epoch 927/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5573 - val_loss: 1.0515\n",
            "Epoch 928/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5572 - val_loss: 1.0501\n",
            "Epoch 929/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5574 - val_loss: 1.0503\n",
            "Epoch 930/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5570 - val_loss: 1.0560\n",
            "Epoch 931/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5566 - val_loss: 1.0530\n",
            "Epoch 932/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5565 - val_loss: 1.0534\n",
            "Epoch 933/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5565 - val_loss: 1.0539\n",
            "Epoch 934/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5569 - val_loss: 1.0502\n",
            "Epoch 935/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5558 - val_loss: 1.0541\n",
            "Epoch 936/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5565 - val_loss: 1.0549\n",
            "Epoch 937/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5557 - val_loss: 1.0527\n",
            "Epoch 938/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5554 - val_loss: 1.0530\n",
            "Epoch 939/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5555 - val_loss: 1.0501\n",
            "Epoch 940/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5556 - val_loss: 1.0532\n",
            "Epoch 941/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5553 - val_loss: 1.0531\n",
            "Epoch 942/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5552 - val_loss: 1.0539\n",
            "Epoch 943/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5553 - val_loss: 1.0559\n",
            "Epoch 944/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5552 - val_loss: 1.0514\n",
            "Epoch 945/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5548 - val_loss: 1.0498\n",
            "Epoch 946/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5552 - val_loss: 1.0549\n",
            "Epoch 947/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5554 - val_loss: 1.0498\n",
            "Epoch 948/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5546 - val_loss: 1.0542\n",
            "Epoch 949/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5543 - val_loss: 1.0538\n",
            "Epoch 950/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5543 - val_loss: 1.0542\n",
            "Epoch 951/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5541 - val_loss: 1.0543\n",
            "Epoch 952/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5548 - val_loss: 1.0499\n",
            "Epoch 953/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5547 - val_loss: 1.0506\n",
            "Epoch 954/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5542 - val_loss: 1.0511\n",
            "Epoch 955/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5540 - val_loss: 1.0531\n",
            "Epoch 956/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5548 - val_loss: 1.0549\n",
            "Epoch 957/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5539 - val_loss: 1.0507\n",
            "Epoch 958/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5535 - val_loss: 1.0534\n",
            "Epoch 959/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5535 - val_loss: 1.0536\n",
            "Epoch 960/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5537 - val_loss: 1.0535\n",
            "Epoch 961/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5535 - val_loss: 1.0545\n",
            "Epoch 962/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5537 - val_loss: 1.0528\n",
            "Epoch 963/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5535 - val_loss: 1.0554\n",
            "Epoch 964/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5529 - val_loss: 1.0503\n",
            "Epoch 965/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5531 - val_loss: 1.0505\n",
            "Epoch 966/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5528 - val_loss: 1.0534\n",
            "Epoch 967/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5524 - val_loss: 1.0530\n",
            "Epoch 968/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5525 - val_loss: 1.0525\n",
            "Epoch 969/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5527 - val_loss: 1.0516\n",
            "Epoch 970/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5534 - val_loss: 1.0547\n",
            "Epoch 971/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5535 - val_loss: 1.0511\n",
            "Epoch 972/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5520 - val_loss: 1.0514\n",
            "Epoch 973/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5522 - val_loss: 1.0543\n",
            "Epoch 974/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5519 - val_loss: 1.0532\n",
            "Epoch 975/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5521 - val_loss: 1.0524\n",
            "Epoch 976/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5519 - val_loss: 1.0501\n",
            "Epoch 977/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5530 - val_loss: 1.0546\n",
            "Epoch 978/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5513 - val_loss: 1.0545\n",
            "Epoch 979/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5515 - val_loss: 1.0512\n",
            "Epoch 980/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5514 - val_loss: 1.0524\n",
            "Epoch 981/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5519 - val_loss: 1.0512\n",
            "Epoch 982/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5513 - val_loss: 1.0520\n",
            "Epoch 983/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5509 - val_loss: 1.0516\n",
            "Epoch 984/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5510 - val_loss: 1.0524\n",
            "Epoch 985/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5515 - val_loss: 1.0511\n",
            "Epoch 986/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5512 - val_loss: 1.0576\n",
            "Epoch 987/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5508 - val_loss: 1.0572\n",
            "Epoch 988/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5503 - val_loss: 1.0553\n",
            "Epoch 989/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5514 - val_loss: 1.0591\n",
            "Epoch 990/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5509 - val_loss: 1.0504\n",
            "Epoch 991/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5500 - val_loss: 1.0536\n",
            "Epoch 992/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5503 - val_loss: 1.0501\n",
            "Epoch 993/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5499 - val_loss: 1.0540\n",
            "Epoch 994/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5501 - val_loss: 1.0554\n",
            "Epoch 995/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5502 - val_loss: 1.0566\n",
            "Epoch 996/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5496 - val_loss: 1.0524\n",
            "Epoch 997/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5495 - val_loss: 1.0514\n",
            "Epoch 998/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5500 - val_loss: 1.0532\n",
            "Epoch 999/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5493 - val_loss: 1.0529\n",
            "Epoch 1000/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5493 - val_loss: 1.0508\n",
            "Epoch 1001/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5495 - val_loss: 1.0527\n",
            "Epoch 1002/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5489 - val_loss: 1.0534\n",
            "Epoch 1003/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5498 - val_loss: 1.0489\n",
            "Epoch 1004/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5493 - val_loss: 1.0507\n",
            "Epoch 1005/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5488 - val_loss: 1.0537\n",
            "Epoch 1006/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5486 - val_loss: 1.0555\n",
            "Epoch 1007/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5486 - val_loss: 1.0521\n",
            "Epoch 1008/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5482 - val_loss: 1.0531\n",
            "Epoch 1009/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5497 - val_loss: 1.0485\n",
            "Epoch 1010/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5495 - val_loss: 1.0509\n",
            "Epoch 1011/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5485 - val_loss: 1.0532\n",
            "Epoch 1012/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5484 - val_loss: 1.0558\n",
            "Epoch 1013/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5483 - val_loss: 1.0566\n",
            "Epoch 1014/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5480 - val_loss: 1.0541\n",
            "Epoch 1015/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5478 - val_loss: 1.0515\n",
            "Epoch 1016/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5476 - val_loss: 1.0543\n",
            "Epoch 1017/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5475 - val_loss: 1.0528\n",
            "Epoch 1018/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5478 - val_loss: 1.0534\n",
            "Epoch 1019/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5480 - val_loss: 1.0499\n",
            "Epoch 1020/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5472 - val_loss: 1.0538\n",
            "Epoch 1021/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5475 - val_loss: 1.0527\n",
            "Epoch 1022/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5471 - val_loss: 1.0531\n",
            "Epoch 1023/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5480 - val_loss: 1.0567\n",
            "Epoch 1024/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5474 - val_loss: 1.0524\n",
            "Epoch 1025/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5469 - val_loss: 1.0519\n",
            "Epoch 1026/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5467 - val_loss: 1.0544\n",
            "Epoch 1027/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5468 - val_loss: 1.0512\n",
            "Epoch 1028/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5465 - val_loss: 1.0518\n",
            "Epoch 1029/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5469 - val_loss: 1.0536\n",
            "Epoch 1030/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5468 - val_loss: 1.0502\n",
            "Epoch 1031/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5460 - val_loss: 1.0540\n",
            "Epoch 1032/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5463 - val_loss: 1.0539\n",
            "Epoch 1033/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5463 - val_loss: 1.0526\n",
            "Epoch 1034/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5468 - val_loss: 1.0577\n",
            "Epoch 1035/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5457 - val_loss: 1.0535\n",
            "Epoch 1036/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5463 - val_loss: 1.0535\n",
            "Epoch 1037/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5456 - val_loss: 1.0537\n",
            "Epoch 1038/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5464 - val_loss: 1.0519\n",
            "Epoch 1039/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5456 - val_loss: 1.0516\n",
            "Epoch 1040/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5454 - val_loss: 1.0531\n",
            "Epoch 1041/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5452 - val_loss: 1.0531\n",
            "Epoch 1042/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5459 - val_loss: 1.0539\n",
            "Epoch 1043/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5459 - val_loss: 1.0520\n",
            "Epoch 1044/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5452 - val_loss: 1.0552\n",
            "Epoch 1045/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5453 - val_loss: 1.0526\n",
            "Epoch 1046/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5451 - val_loss: 1.0557\n",
            "Epoch 1047/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5448 - val_loss: 1.0542\n",
            "Epoch 1048/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5449 - val_loss: 1.0497\n",
            "Epoch 1049/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5451 - val_loss: 1.0527\n",
            "Epoch 1050/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5448 - val_loss: 1.0541\n",
            "Epoch 1051/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5447 - val_loss: 1.0536\n",
            "Epoch 1052/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5445 - val_loss: 1.0516\n",
            "Epoch 1053/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5444 - val_loss: 1.0540\n",
            "Epoch 1054/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5455 - val_loss: 1.0564\n",
            "Epoch 1055/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5446 - val_loss: 1.0557\n",
            "Epoch 1056/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5443 - val_loss: 1.0535\n",
            "Epoch 1057/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5448 - val_loss: 1.0516\n",
            "Epoch 1058/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5436 - val_loss: 1.0528\n",
            "Epoch 1059/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5438 - val_loss: 1.0551\n",
            "Epoch 1060/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5441 - val_loss: 1.0496\n",
            "Epoch 1061/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5436 - val_loss: 1.0525\n",
            "Epoch 1062/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5435 - val_loss: 1.0521\n",
            "Epoch 1063/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5439 - val_loss: 1.0499\n",
            "Epoch 1064/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5438 - val_loss: 1.0567\n",
            "Epoch 1065/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5432 - val_loss: 1.0547\n",
            "Epoch 1066/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5432 - val_loss: 1.0538\n",
            "Epoch 1067/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5433 - val_loss: 1.0544\n",
            "Epoch 1068/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5431 - val_loss: 1.0525\n",
            "Epoch 1069/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5428 - val_loss: 1.0530\n",
            "Epoch 1070/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5425 - val_loss: 1.0546\n",
            "Epoch 1071/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5427 - val_loss: 1.0520\n",
            "Epoch 1072/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5430 - val_loss: 1.0549\n",
            "Epoch 1073/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5426 - val_loss: 1.0535\n",
            "Epoch 1074/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5426 - val_loss: 1.0533\n",
            "Epoch 1075/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5426 - val_loss: 1.0513\n",
            "Epoch 1076/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5421 - val_loss: 1.0530\n",
            "Epoch 1077/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5420 - val_loss: 1.0552\n",
            "Epoch 1078/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5426 - val_loss: 1.0507\n",
            "Epoch 1079/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5423 - val_loss: 1.0510\n",
            "Epoch 1080/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5428 - val_loss: 1.0539\n",
            "Epoch 1081/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5419 - val_loss: 1.0515\n",
            "Epoch 1082/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5425 - val_loss: 1.0510\n",
            "Epoch 1083/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5419 - val_loss: 1.0552\n",
            "Epoch 1084/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5417 - val_loss: 1.0537\n",
            "Epoch 1085/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5418 - val_loss: 1.0544\n",
            "Epoch 1086/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5413 - val_loss: 1.0523\n",
            "Epoch 1087/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5417 - val_loss: 1.0565\n",
            "Epoch 1088/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5422 - val_loss: 1.0524\n",
            "Epoch 1089/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5415 - val_loss: 1.0523\n",
            "Epoch 1090/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5417 - val_loss: 1.0523\n",
            "Epoch 1091/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5419 - val_loss: 1.0491\n",
            "Epoch 1092/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5413 - val_loss: 1.0558\n",
            "Epoch 1093/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5406 - val_loss: 1.0550\n",
            "Epoch 1094/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5406 - val_loss: 1.0533\n",
            "Epoch 1095/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5408 - val_loss: 1.0544\n",
            "Epoch 1096/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5412 - val_loss: 1.0502\n",
            "Epoch 1097/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5408 - val_loss: 1.0529\n",
            "Epoch 1098/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5403 - val_loss: 1.0540\n",
            "Epoch 1099/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5405 - val_loss: 1.0502\n",
            "Epoch 1100/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5402 - val_loss: 1.0554\n",
            "Epoch 1101/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5403 - val_loss: 1.0515\n",
            "Epoch 1102/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5414 - val_loss: 1.0525\n",
            "Epoch 1103/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5400 - val_loss: 1.0499\n",
            "Epoch 1104/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5399 - val_loss: 1.0529\n",
            "Epoch 1105/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5401 - val_loss: 1.0504\n",
            "Epoch 1106/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5397 - val_loss: 1.0533\n",
            "Epoch 1107/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5406 - val_loss: 1.0506\n",
            "Epoch 1108/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5407 - val_loss: 1.0592\n",
            "Epoch 1109/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5393 - val_loss: 1.0514\n",
            "Epoch 1110/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5398 - val_loss: 1.0500\n",
            "Epoch 1111/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5396 - val_loss: 1.0535\n",
            "Epoch 1112/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5391 - val_loss: 1.0541\n",
            "Epoch 1113/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5391 - val_loss: 1.0512\n",
            "Epoch 1114/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5396 - val_loss: 1.0519\n",
            "Epoch 1115/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5389 - val_loss: 1.0517\n",
            "Epoch 1116/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5400 - val_loss: 1.0509\n",
            "Epoch 1117/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5391 - val_loss: 1.0500\n",
            "Epoch 1118/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5389 - val_loss: 1.0526\n",
            "Epoch 1119/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5394 - val_loss: 1.0563\n",
            "Epoch 1120/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5396 - val_loss: 1.0579\n",
            "Epoch 1121/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5391 - val_loss: 1.0538\n",
            "Epoch 1122/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5383 - val_loss: 1.0516\n",
            "Epoch 1123/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5385 - val_loss: 1.0528\n",
            "Epoch 1124/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5386 - val_loss: 1.0490\n",
            "Epoch 1125/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5385 - val_loss: 1.0549\n",
            "Epoch 1126/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5379 - val_loss: 1.0520\n",
            "Epoch 1127/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5386 - val_loss: 1.0501\n",
            "Epoch 1128/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5381 - val_loss: 1.0525\n",
            "Epoch 1129/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5378 - val_loss: 1.0551\n",
            "Epoch 1130/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5381 - val_loss: 1.0511\n",
            "Epoch 1131/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5377 - val_loss: 1.0529\n",
            "Epoch 1132/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5379 - val_loss: 1.0555\n",
            "Epoch 1133/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5374 - val_loss: 1.0532\n",
            "Epoch 1134/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5380 - val_loss: 1.0512\n",
            "Epoch 1135/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5380 - val_loss: 1.0554\n",
            "Epoch 1136/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5372 - val_loss: 1.0536\n",
            "Epoch 1137/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5373 - val_loss: 1.0521\n",
            "Epoch 1138/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5372 - val_loss: 1.0514\n",
            "Epoch 1139/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5371 - val_loss: 1.0511\n",
            "Epoch 1140/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5371 - val_loss: 1.0518\n",
            "Epoch 1141/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5374 - val_loss: 1.0530\n",
            "Epoch 1142/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5373 - val_loss: 1.0507\n",
            "Epoch 1143/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5372 - val_loss: 1.0568\n",
            "Epoch 1144/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5375 - val_loss: 1.0497\n",
            "Epoch 1145/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5368 - val_loss: 1.0509\n",
            "Epoch 1146/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5369 - val_loss: 1.0537\n",
            "Epoch 1147/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5367 - val_loss: 1.0515\n",
            "Epoch 1148/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5368 - val_loss: 1.0518\n",
            "Epoch 1149/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5369 - val_loss: 1.0515\n",
            "Epoch 1150/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5365 - val_loss: 1.0511\n",
            "Epoch 1151/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5369 - val_loss: 1.0576\n",
            "Epoch 1152/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5361 - val_loss: 1.0563\n",
            "Epoch 1153/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5362 - val_loss: 1.0523\n",
            "Epoch 1154/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5363 - val_loss: 1.0499\n",
            "Epoch 1155/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5366 - val_loss: 1.0538\n",
            "Epoch 1156/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5365 - val_loss: 1.0517\n",
            "Epoch 1157/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5361 - val_loss: 1.0532\n",
            "Epoch 1158/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5360 - val_loss: 1.0503\n",
            "Epoch 1159/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5367 - val_loss: 1.0488\n",
            "Epoch 1160/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5359 - val_loss: 1.0519\n",
            "Epoch 1161/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5360 - val_loss: 1.0549\n",
            "Epoch 1162/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5359 - val_loss: 1.0551\n",
            "Epoch 1163/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5363 - val_loss: 1.0510\n",
            "Epoch 1164/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5359 - val_loss: 1.0525\n",
            "Epoch 1165/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5355 - val_loss: 1.0554\n",
            "Epoch 1166/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5360 - val_loss: 1.0509\n",
            "Epoch 1167/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5355 - val_loss: 1.0499\n",
            "Epoch 1168/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5355 - val_loss: 1.0542\n",
            "Epoch 1169/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5359 - val_loss: 1.0525\n",
            "Epoch 1170/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5369 - val_loss: 1.0568\n",
            "Epoch 1171/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5360 - val_loss: 1.0510\n",
            "Epoch 1172/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5356 - val_loss: 1.0517\n",
            "Epoch 1173/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5359 - val_loss: 1.0518\n",
            "Epoch 1174/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5349 - val_loss: 1.0524\n",
            "Epoch 1175/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5355 - val_loss: 1.0506\n",
            "Epoch 1176/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5347 - val_loss: 1.0550\n",
            "Epoch 1177/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5360 - val_loss: 1.0483\n",
            "Epoch 1178/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5346 - val_loss: 1.0516\n",
            "Epoch 1179/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5345 - val_loss: 1.0522\n",
            "Epoch 1180/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5346 - val_loss: 1.0536\n",
            "Epoch 1181/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5344 - val_loss: 1.0504\n",
            "Epoch 1182/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5344 - val_loss: 1.0517\n",
            "Epoch 1183/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5347 - val_loss: 1.0515\n",
            "Epoch 1184/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5346 - val_loss: 1.0547\n",
            "Epoch 1185/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5344 - val_loss: 1.0548\n",
            "Epoch 1186/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5342 - val_loss: 1.0554\n",
            "Epoch 1187/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5342 - val_loss: 1.0527\n",
            "Epoch 1188/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5342 - val_loss: 1.0521\n",
            "Epoch 1189/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5352 - val_loss: 1.0482\n",
            "Epoch 1190/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5360 - val_loss: 1.0540\n",
            "Epoch 1191/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5346 - val_loss: 1.0497\n",
            "Epoch 1192/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5342 - val_loss: 1.0537\n",
            "Epoch 1193/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5352 - val_loss: 1.0468\n",
            "Epoch 1194/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5330 - val_loss: 1.0509\n",
            "Epoch 1195/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5336 - val_loss: 1.0523\n",
            "Epoch 1196/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5336 - val_loss: 1.0547\n",
            "Epoch 1197/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5334 - val_loss: 1.0523\n",
            "Epoch 1198/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5335 - val_loss: 1.0554\n",
            "Epoch 1199/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5334 - val_loss: 1.0513\n",
            "Epoch 1200/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5334 - val_loss: 1.0540\n",
            "Epoch 1201/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5336 - val_loss: 1.0554\n",
            "Epoch 1202/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5329 - val_loss: 1.0498\n",
            "Epoch 1203/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5332 - val_loss: 1.0495\n",
            "Epoch 1204/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5333 - val_loss: 1.0528\n",
            "Epoch 1205/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5334 - val_loss: 1.0513\n",
            "Epoch 1206/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5337 - val_loss: 1.0485\n",
            "Epoch 1207/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5331 - val_loss: 1.0493\n",
            "Epoch 1208/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5328 - val_loss: 1.0515\n",
            "Epoch 1209/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5334 - val_loss: 1.0524\n",
            "Epoch 1210/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5329 - val_loss: 1.0546\n",
            "Epoch 1211/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5329 - val_loss: 1.0513\n",
            "Epoch 1212/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5326 - val_loss: 1.0513\n",
            "Epoch 1213/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5331 - val_loss: 1.0540\n",
            "Epoch 1214/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5328 - val_loss: 1.0512\n",
            "Epoch 1215/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5326 - val_loss: 1.0503\n",
            "Epoch 1216/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5327 - val_loss: 1.0533\n",
            "Epoch 1217/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5326 - val_loss: 1.0509\n",
            "Epoch 1218/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5326 - val_loss: 1.0533\n",
            "Epoch 1219/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5322 - val_loss: 1.0502\n",
            "Epoch 1220/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5323 - val_loss: 1.0509\n",
            "Epoch 1221/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5325 - val_loss: 1.0495\n",
            "Epoch 1222/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5326 - val_loss: 1.0524\n",
            "Epoch 1223/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5324 - val_loss: 1.0520\n",
            "Epoch 1224/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5321 - val_loss: 1.0548\n",
            "Epoch 1225/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5325 - val_loss: 1.0478\n",
            "Epoch 1226/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5324 - val_loss: 1.0526\n",
            "Epoch 1227/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5321 - val_loss: 1.0541\n",
            "Epoch 1228/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5319 - val_loss: 1.0531\n",
            "Epoch 1229/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5321 - val_loss: 1.0485\n",
            "Epoch 1230/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5316 - val_loss: 1.0496\n",
            "Epoch 1231/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5315 - val_loss: 1.0519\n",
            "Epoch 1232/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5323 - val_loss: 1.0488\n",
            "Epoch 1233/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5318 - val_loss: 1.0534\n",
            "Epoch 1234/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5319 - val_loss: 1.0502\n",
            "Epoch 1235/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5324 - val_loss: 1.0473\n",
            "Epoch 1236/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5333 - val_loss: 1.0524\n",
            "Epoch 1237/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5322 - val_loss: 1.0489\n",
            "Epoch 1238/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5312 - val_loss: 1.0508\n",
            "Epoch 1239/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5317 - val_loss: 1.0504\n",
            "Epoch 1240/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5318 - val_loss: 1.0557\n",
            "Epoch 1241/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5317 - val_loss: 1.0495\n",
            "Epoch 1242/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5321 - val_loss: 1.0545\n",
            "Epoch 1243/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5319 - val_loss: 1.0483\n",
            "Epoch 1244/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5322 - val_loss: 1.0578\n",
            "Epoch 1245/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5310 - val_loss: 1.0501\n",
            "Epoch 1246/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5311 - val_loss: 1.0521\n",
            "Epoch 1247/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5314 - val_loss: 1.0535\n",
            "Epoch 1248/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5312 - val_loss: 1.0490\n",
            "Epoch 1249/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5315 - val_loss: 1.0521\n",
            "Epoch 1250/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5309 - val_loss: 1.0495\n",
            "Epoch 1251/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5312 - val_loss: 1.0525\n",
            "Epoch 1252/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5308 - val_loss: 1.0498\n",
            "Epoch 1253/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5311 - val_loss: 1.0533\n",
            "Epoch 1254/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5304 - val_loss: 1.0514\n",
            "Epoch 1255/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5307 - val_loss: 1.0488\n",
            "Epoch 1256/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5309 - val_loss: 1.0534\n",
            "Epoch 1257/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5314 - val_loss: 1.0545\n",
            "Epoch 1258/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5310 - val_loss: 1.0473\n",
            "Epoch 1259/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5313 - val_loss: 1.0458\n",
            "Epoch 1260/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5306 - val_loss: 1.0543\n",
            "Epoch 1261/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5314 - val_loss: 1.0500\n",
            "Epoch 1262/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5313 - val_loss: 1.0563\n",
            "Epoch 1263/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5307 - val_loss: 1.0494\n",
            "Epoch 1264/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5305 - val_loss: 1.0508\n",
            "Epoch 1265/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5303 - val_loss: 1.0503\n",
            "Epoch 1266/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5306 - val_loss: 1.0525\n",
            "Epoch 1267/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5313 - val_loss: 1.0475\n",
            "Epoch 1268/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5309 - val_loss: 1.0551\n",
            "Epoch 1269/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5305 - val_loss: 1.0523\n",
            "Epoch 1270/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5312 - val_loss: 1.0562\n",
            "Epoch 1271/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5308 - val_loss: 1.0545\n",
            "Epoch 1272/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5298 - val_loss: 1.0484\n",
            "Epoch 1273/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5303 - val_loss: 1.0476\n",
            "Epoch 1274/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5300 - val_loss: 1.0494\n",
            "Epoch 1275/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5317 - val_loss: 1.0461\n",
            "Epoch 1276/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5296 - val_loss: 1.0532\n",
            "Epoch 1277/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5298 - val_loss: 1.0541\n",
            "Epoch 1278/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5304 - val_loss: 1.0488\n",
            "Epoch 1279/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5300 - val_loss: 1.0497\n",
            "Epoch 1280/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5298 - val_loss: 1.0492\n",
            "Epoch 1281/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5302 - val_loss: 1.0576\n",
            "Epoch 1282/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5297 - val_loss: 1.0540\n",
            "Epoch 1283/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5295 - val_loss: 1.0527\n",
            "Epoch 1284/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5293 - val_loss: 1.0515\n",
            "Epoch 1285/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5293 - val_loss: 1.0495\n",
            "Epoch 1286/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5306 - val_loss: 1.0466\n",
            "Epoch 1287/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5295 - val_loss: 1.0488\n",
            "Epoch 1288/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5298 - val_loss: 1.0560\n",
            "Epoch 1289/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5301 - val_loss: 1.0505\n",
            "Epoch 1290/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5293 - val_loss: 1.0508\n",
            "Epoch 1291/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5292 - val_loss: 1.0536\n",
            "Epoch 1292/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5292 - val_loss: 1.0501\n",
            "Epoch 1293/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5294 - val_loss: 1.0494\n",
            "Epoch 1294/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5292 - val_loss: 1.0525\n",
            "Epoch 1295/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5294 - val_loss: 1.0539\n",
            "Epoch 1296/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5293 - val_loss: 1.0494\n",
            "Epoch 1297/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5295 - val_loss: 1.0505\n",
            "Epoch 1298/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5290 - val_loss: 1.0483\n",
            "Epoch 1299/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5289 - val_loss: 1.0482\n",
            "Epoch 1300/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5293 - val_loss: 1.0524\n",
            "Epoch 1301/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5287 - val_loss: 1.0510\n",
            "Epoch 1302/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5292 - val_loss: 1.0466\n",
            "Epoch 1303/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5289 - val_loss: 1.0470\n",
            "Epoch 1304/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5290 - val_loss: 1.0514\n",
            "Epoch 1305/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5292 - val_loss: 1.0544\n",
            "Epoch 1306/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5289 - val_loss: 1.0505\n",
            "Epoch 1307/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5287 - val_loss: 1.0498\n",
            "Epoch 1308/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5289 - val_loss: 1.0485\n",
            "Epoch 1309/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5292 - val_loss: 1.0462\n",
            "Epoch 1310/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5292 - val_loss: 1.0472\n",
            "Epoch 1311/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5291 - val_loss: 1.0508\n",
            "Epoch 1312/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5297 - val_loss: 1.0551\n",
            "Epoch 1313/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5290 - val_loss: 1.0532\n",
            "Epoch 1314/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5288 - val_loss: 1.0501\n",
            "Epoch 1315/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5292 - val_loss: 1.0517\n",
            "Epoch 1316/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5289 - val_loss: 1.0468\n",
            "Epoch 1317/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5291 - val_loss: 1.0482\n",
            "Epoch 1318/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5285 - val_loss: 1.0517\n",
            "Epoch 1319/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5287 - val_loss: 1.0486\n",
            "Epoch 1320/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5288 - val_loss: 1.0466\n",
            "Epoch 1321/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5282 - val_loss: 1.0517\n",
            "Epoch 1322/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5284 - val_loss: 1.0498\n",
            "Epoch 1323/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5285 - val_loss: 1.0491\n",
            "Epoch 1324/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5284 - val_loss: 1.0470\n",
            "Epoch 1325/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5284 - val_loss: 1.0485\n",
            "Epoch 1326/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5283 - val_loss: 1.0497\n",
            "Epoch 1327/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5288 - val_loss: 1.0527\n",
            "Epoch 1328/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5308 - val_loss: 1.0497\n",
            "Epoch 1329/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5293 - val_loss: 1.0557\n",
            "Epoch 1330/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5286 - val_loss: 1.0496\n",
            "Epoch 1331/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5279 - val_loss: 1.0479\n",
            "Epoch 1332/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5281 - val_loss: 1.0481\n",
            "Epoch 1333/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5283 - val_loss: 1.0501\n",
            "Epoch 1334/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5288 - val_loss: 1.0470\n",
            "Epoch 1335/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5288 - val_loss: 1.0512\n",
            "Epoch 1336/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5280 - val_loss: 1.0480\n",
            "Epoch 1337/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5281 - val_loss: 1.0530\n",
            "Epoch 1338/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5284 - val_loss: 1.0476\n",
            "Epoch 1339/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5281 - val_loss: 1.0495\n",
            "Epoch 1340/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5281 - val_loss: 1.0485\n",
            "Epoch 1341/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5280 - val_loss: 1.0489\n",
            "Epoch 1342/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5284 - val_loss: 1.0455\n",
            "Epoch 1343/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5281 - val_loss: 1.0517\n",
            "Epoch 1344/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5277 - val_loss: 1.0501\n",
            "Epoch 1345/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5279 - val_loss: 1.0492\n",
            "Epoch 1346/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5275 - val_loss: 1.0491\n",
            "Epoch 1347/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5279 - val_loss: 1.0476\n",
            "Epoch 1348/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5286 - val_loss: 1.0462\n",
            "Epoch 1349/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5285 - val_loss: 1.0510\n",
            "Epoch 1350/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5274 - val_loss: 1.0500\n",
            "Epoch 1351/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5278 - val_loss: 1.0479\n",
            "Epoch 1352/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5278 - val_loss: 1.0480\n",
            "Epoch 1353/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5278 - val_loss: 1.0494\n",
            "Epoch 1354/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5276 - val_loss: 1.0505\n",
            "Epoch 1355/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5280 - val_loss: 1.0489\n",
            "Epoch 1356/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5282 - val_loss: 1.0494\n",
            "Epoch 1357/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5280 - val_loss: 1.0492\n",
            "Epoch 1358/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5280 - val_loss: 1.0459\n",
            "Epoch 1359/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5280 - val_loss: 1.0514\n",
            "Epoch 1360/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5275 - val_loss: 1.0505\n",
            "Epoch 1361/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5272 - val_loss: 1.0482\n",
            "Epoch 1362/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5276 - val_loss: 1.0496\n",
            "Epoch 1363/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5275 - val_loss: 1.0496\n",
            "Epoch 1364/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5273 - val_loss: 1.0477\n",
            "Epoch 1365/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5279 - val_loss: 1.0467\n",
            "Epoch 1366/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5272 - val_loss: 1.0461\n",
            "Epoch 1367/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5273 - val_loss: 1.0474\n",
            "Epoch 1368/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5275 - val_loss: 1.0471\n",
            "Epoch 1369/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5273 - val_loss: 1.0478\n",
            "Epoch 1370/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5281 - val_loss: 1.0467\n",
            "Epoch 1371/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5277 - val_loss: 1.0460\n",
            "Epoch 1372/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5269 - val_loss: 1.0499\n",
            "Epoch 1373/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5269 - val_loss: 1.0509\n",
            "Epoch 1374/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5278 - val_loss: 1.0514\n",
            "Epoch 1375/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5272 - val_loss: 1.0459\n",
            "Epoch 1376/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5272 - val_loss: 1.0492\n",
            "Epoch 1377/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5279 - val_loss: 1.0461\n",
            "Epoch 1378/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5277 - val_loss: 1.0458\n",
            "Epoch 1379/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5272 - val_loss: 1.0488\n",
            "Epoch 1380/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5272 - val_loss: 1.0451\n",
            "Epoch 1381/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5276 - val_loss: 1.0451\n",
            "Epoch 1382/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5268 - val_loss: 1.0497\n",
            "Epoch 1383/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5271 - val_loss: 1.0474\n",
            "Epoch 1384/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5267 - val_loss: 1.0501\n",
            "Epoch 1385/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5268 - val_loss: 1.0481\n",
            "Epoch 1386/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5271 - val_loss: 1.0497\n",
            "Epoch 1387/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5280 - val_loss: 1.0468\n",
            "Epoch 1388/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5275 - val_loss: 1.0471\n",
            "Epoch 1389/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5273 - val_loss: 1.0512\n",
            "Epoch 1390/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5273 - val_loss: 1.0450\n",
            "Epoch 1391/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5274 - val_loss: 1.0456\n",
            "Epoch 1392/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5267 - val_loss: 1.0472\n",
            "Epoch 1393/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5273 - val_loss: 1.0521\n",
            "Epoch 1394/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5272 - val_loss: 1.0467\n",
            "Epoch 1395/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5271 - val_loss: 1.0513\n",
            "Epoch 1396/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5266 - val_loss: 1.0474\n",
            "Epoch 1397/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5267 - val_loss: 1.0497\n",
            "Epoch 1398/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5277 - val_loss: 1.0486\n",
            "Epoch 1399/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5271 - val_loss: 1.0453\n",
            "Epoch 1400/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5274 - val_loss: 1.0530\n",
            "Epoch 1401/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5270 - val_loss: 1.0489\n",
            "Epoch 1402/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5276 - val_loss: 1.0456\n",
            "Epoch 1403/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5267 - val_loss: 1.0490\n",
            "Epoch 1404/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5279 - val_loss: 1.0529\n",
            "Epoch 1405/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5278 - val_loss: 1.0454\n",
            "Epoch 1406/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5262 - val_loss: 1.0473\n",
            "Epoch 1407/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5267 - val_loss: 1.0447\n",
            "Epoch 1408/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5266 - val_loss: 1.0456\n",
            "Epoch 1409/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5278 - val_loss: 1.0479\n",
            "Epoch 1410/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5268 - val_loss: 1.0463\n",
            "Epoch 1411/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5268 - val_loss: 1.0491\n",
            "Epoch 1412/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5266 - val_loss: 1.0489\n",
            "Epoch 1413/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5271 - val_loss: 1.0493\n",
            "Epoch 1414/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5266 - val_loss: 1.0476\n",
            "Epoch 1415/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5273 - val_loss: 1.0452\n",
            "Epoch 1416/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5273 - val_loss: 1.0482\n",
            "Epoch 1417/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5264 - val_loss: 1.0471\n",
            "Epoch 1418/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5268 - val_loss: 1.0512\n",
            "Epoch 1419/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5262 - val_loss: 1.0483\n",
            "Epoch 1420/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5264 - val_loss: 1.0468\n",
            "Epoch 1421/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5262 - val_loss: 1.0444\n",
            "Epoch 1422/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5275 - val_loss: 1.0409\n",
            "Epoch 1423/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5265 - val_loss: 1.0495\n",
            "Epoch 1424/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5268 - val_loss: 1.0464\n",
            "Epoch 1425/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5265 - val_loss: 1.0469\n",
            "Epoch 1426/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5270 - val_loss: 1.0458\n",
            "Epoch 1427/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5276 - val_loss: 1.0508\n",
            "Epoch 1428/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5277 - val_loss: 1.0440\n",
            "Epoch 1429/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5263 - val_loss: 1.0451\n",
            "Epoch 1430/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5264 - val_loss: 1.0474\n",
            "Epoch 1431/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5272 - val_loss: 1.0444\n",
            "Epoch 1432/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5271 - val_loss: 1.0477\n",
            "Epoch 1433/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5276 - val_loss: 1.0549\n",
            "Epoch 1434/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5264 - val_loss: 1.0513\n",
            "Epoch 1435/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5272 - val_loss: 1.0526\n",
            "Epoch 1436/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5292 - val_loss: 1.0400\n",
            "Epoch 1437/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5261 - val_loss: 1.0489\n",
            "Epoch 1438/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5272 - val_loss: 1.0472\n",
            "Epoch 1439/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5263 - val_loss: 1.0471\n",
            "Epoch 1440/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5269 - val_loss: 1.0514\n",
            "Epoch 1441/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5259 - val_loss: 1.0469\n",
            "Epoch 1442/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5267 - val_loss: 1.0457\n",
            "Epoch 1443/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5282 - val_loss: 1.0417\n",
            "Epoch 1444/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5282 - val_loss: 1.0512\n",
            "Epoch 1445/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5265 - val_loss: 1.0431\n",
            "Epoch 1446/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5260 - val_loss: 1.0468\n",
            "Epoch 1447/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5264 - val_loss: 1.0436\n",
            "Epoch 1448/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5266 - val_loss: 1.0498\n",
            "Epoch 1449/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5264 - val_loss: 1.0455\n",
            "Epoch 1450/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5266 - val_loss: 1.0445\n",
            "Epoch 1451/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5279 - val_loss: 1.0412\n",
            "Epoch 1452/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5259 - val_loss: 1.0497\n",
            "Epoch 1453/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5261 - val_loss: 1.0477\n",
            "Epoch 1454/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5262 - val_loss: 1.0486\n",
            "Epoch 1455/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5264 - val_loss: 1.0468\n",
            "Epoch 1456/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5265 - val_loss: 1.0503\n",
            "Epoch 1457/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5273 - val_loss: 1.0446\n",
            "Epoch 1458/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5263 - val_loss: 1.0440\n",
            "Epoch 1459/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5264 - val_loss: 1.0437\n",
            "Epoch 1460/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5273 - val_loss: 1.0532\n",
            "Epoch 1461/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5263 - val_loss: 1.0448\n",
            "Epoch 1462/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5267 - val_loss: 1.0488\n",
            "Epoch 1463/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5263 - val_loss: 1.0461\n",
            "Epoch 1464/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5262 - val_loss: 1.0460\n",
            "Epoch 1465/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5266 - val_loss: 1.0448\n",
            "Epoch 1466/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5260 - val_loss: 1.0458\n",
            "Epoch 1467/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5268 - val_loss: 1.0515\n",
            "Epoch 1468/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5259 - val_loss: 1.0462\n",
            "Epoch 1469/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5257 - val_loss: 1.0441\n",
            "Epoch 1470/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5258 - val_loss: 1.0432\n",
            "Epoch 1471/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5265 - val_loss: 1.0444\n",
            "Epoch 1472/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5261 - val_loss: 1.0464\n",
            "Epoch 1473/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5260 - val_loss: 1.0449\n",
            "Epoch 1474/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5265 - val_loss: 1.0508\n",
            "Epoch 1475/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5270 - val_loss: 1.0424\n",
            "Epoch 1476/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5259 - val_loss: 1.0444\n",
            "Epoch 1477/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5265 - val_loss: 1.0462\n",
            "Epoch 1478/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5261 - val_loss: 1.0425\n",
            "Epoch 1479/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5268 - val_loss: 1.0438\n",
            "Epoch 1480/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5258 - val_loss: 1.0471\n",
            "Epoch 1481/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5257 - val_loss: 1.0455\n",
            "Epoch 1482/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5255 - val_loss: 1.0467\n",
            "Epoch 1483/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5261 - val_loss: 1.0505\n",
            "Epoch 1484/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5260 - val_loss: 1.0499\n",
            "Epoch 1485/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5258 - val_loss: 1.0476\n",
            "Epoch 1486/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5265 - val_loss: 1.0418\n",
            "Epoch 1487/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5256 - val_loss: 1.0461\n",
            "Epoch 1488/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5256 - val_loss: 1.0451\n",
            "Epoch 1489/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5261 - val_loss: 1.0474\n",
            "Epoch 1490/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5262 - val_loss: 1.0457\n",
            "Epoch 1491/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5269 - val_loss: 1.0483\n",
            "Epoch 1492/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5255 - val_loss: 1.0465\n",
            "Epoch 1493/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5263 - val_loss: 1.0440\n",
            "Epoch 1494/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5257 - val_loss: 1.0463\n",
            "Epoch 1495/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5260 - val_loss: 1.0447\n",
            "Epoch 1496/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5269 - val_loss: 1.0478\n",
            "Epoch 1497/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5254 - val_loss: 1.0431\n",
            "Epoch 1498/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5255 - val_loss: 1.0429\n",
            "Epoch 1499/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5256 - val_loss: 1.0428\n",
            "Epoch 1500/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5274 - val_loss: 1.0388\n",
            "Epoch 1501/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5258 - val_loss: 1.0439\n",
            "Epoch 1502/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5256 - val_loss: 1.0473\n",
            "Epoch 1503/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5260 - val_loss: 1.0463\n",
            "Epoch 1504/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5254 - val_loss: 1.0452\n",
            "Epoch 1505/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5254 - val_loss: 1.0462\n",
            "Epoch 1506/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5263 - val_loss: 1.0443\n",
            "Epoch 1507/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5256 - val_loss: 1.0439\n",
            "Epoch 1508/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5264 - val_loss: 1.0476\n",
            "Epoch 1509/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5256 - val_loss: 1.0468\n",
            "Epoch 1510/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5259 - val_loss: 1.0442\n",
            "Epoch 1511/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5260 - val_loss: 1.0437\n",
            "Epoch 1512/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5256 - val_loss: 1.0433\n",
            "Epoch 1513/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5263 - val_loss: 1.0465\n",
            "Epoch 1514/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5257 - val_loss: 1.0435\n",
            "Epoch 1515/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5256 - val_loss: 1.0460\n",
            "Epoch 1516/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5253 - val_loss: 1.0456\n",
            "Epoch 1517/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5255 - val_loss: 1.0463\n",
            "Epoch 1518/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5273 - val_loss: 1.0422\n",
            "Epoch 1519/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5267 - val_loss: 1.0461\n",
            "Epoch 1520/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5258 - val_loss: 1.0444\n",
            "Epoch 1521/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5259 - val_loss: 1.0456\n",
            "Epoch 1522/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5261 - val_loss: 1.0477\n",
            "Epoch 1523/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5259 - val_loss: 1.0424\n",
            "Epoch 1524/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5258 - val_loss: 1.0430\n",
            "Epoch 1525/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5255 - val_loss: 1.0436\n",
            "Epoch 1526/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5257 - val_loss: 1.0432\n",
            "Epoch 1527/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5260 - val_loss: 1.0457\n",
            "Epoch 1528/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5258 - val_loss: 1.0423\n",
            "Epoch 1529/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5255 - val_loss: 1.0433\n",
            "Epoch 1530/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5264 - val_loss: 1.0407\n",
            "Epoch 1531/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5257 - val_loss: 1.0429\n",
            "Epoch 1532/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5267 - val_loss: 1.0453\n",
            "Epoch 1533/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5258 - val_loss: 1.0451\n",
            "Epoch 1534/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5255 - val_loss: 1.0476\n",
            "Epoch 1535/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5256 - val_loss: 1.0445\n",
            "Epoch 1536/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5254 - val_loss: 1.0427\n",
            "Epoch 1537/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5257 - val_loss: 1.0439\n",
            "Epoch 1538/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5260 - val_loss: 1.0442\n",
            "Epoch 1539/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5256 - val_loss: 1.0472\n",
            "Epoch 1540/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5258 - val_loss: 1.0442\n",
            "Epoch 1541/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5261 - val_loss: 1.0480\n",
            "Epoch 1542/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5252 - val_loss: 1.0437\n",
            "Epoch 1543/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5254 - val_loss: 1.0453\n",
            "Epoch 1544/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5263 - val_loss: 1.0394\n",
            "Epoch 1545/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5260 - val_loss: 1.0418\n",
            "Epoch 1546/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5255 - val_loss: 1.0454\n",
            "Epoch 1547/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5260 - val_loss: 1.0430\n",
            "Epoch 1548/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5257 - val_loss: 1.0464\n",
            "Epoch 1549/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5251 - val_loss: 1.0455\n",
            "Epoch 1550/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5253 - val_loss: 1.0458\n",
            "Epoch 1551/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5255 - val_loss: 1.0459\n",
            "Epoch 1552/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5261 - val_loss: 1.0471\n",
            "Epoch 1553/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5254 - val_loss: 1.0445\n",
            "Epoch 1554/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5254 - val_loss: 1.0446\n",
            "Epoch 1555/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5253 - val_loss: 1.0415\n",
            "Epoch 1556/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5258 - val_loss: 1.0402\n",
            "Epoch 1557/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5260 - val_loss: 1.0447\n",
            "Epoch 1558/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5255 - val_loss: 1.0451\n",
            "Epoch 1559/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5264 - val_loss: 1.0491\n",
            "Epoch 1560/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5252 - val_loss: 1.0444\n",
            "Epoch 1561/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5258 - val_loss: 1.0441\n",
            "Epoch 1562/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5252 - val_loss: 1.0465\n",
            "Epoch 1563/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5276 - val_loss: 1.0417\n",
            "Epoch 1564/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5254 - val_loss: 1.0472\n",
            "Epoch 1565/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5254 - val_loss: 1.0473\n",
            "Epoch 1566/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5255 - val_loss: 1.0452\n",
            "Epoch 1567/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5260 - val_loss: 1.0437\n",
            "Epoch 1568/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5263 - val_loss: 1.0422\n",
            "Epoch 1569/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5255 - val_loss: 1.0461\n",
            "Epoch 1570/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5255 - val_loss: 1.0432\n",
            "Epoch 1571/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5257 - val_loss: 1.0394\n",
            "Epoch 1572/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5253 - val_loss: 1.0430\n",
            "Epoch 1573/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5253 - val_loss: 1.0419\n",
            "Epoch 1574/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5260 - val_loss: 1.0468\n",
            "Epoch 1575/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5254 - val_loss: 1.0416\n",
            "Epoch 1576/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5254 - val_loss: 1.0425\n",
            "Epoch 1577/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5253 - val_loss: 1.0469\n",
            "Epoch 1578/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5253 - val_loss: 1.0442\n",
            "Epoch 1579/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5254 - val_loss: 1.0460\n",
            "Epoch 1580/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5256 - val_loss: 1.0417\n",
            "Epoch 1581/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5255 - val_loss: 1.0446\n",
            "Epoch 1582/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5254 - val_loss: 1.0409\n",
            "Epoch 1583/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5254 - val_loss: 1.0462\n",
            "Epoch 1584/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5254 - val_loss: 1.0424\n",
            "Epoch 1585/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5253 - val_loss: 1.0437\n",
            "Epoch 1586/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5259 - val_loss: 1.0455\n",
            "Epoch 1587/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5251 - val_loss: 1.0463\n",
            "Epoch 1588/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5257 - val_loss: 1.0455\n",
            "Epoch 1589/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5253 - val_loss: 1.0430\n",
            "Epoch 1590/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5258 - val_loss: 1.0487\n",
            "Epoch 1591/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5253 - val_loss: 1.0467\n",
            "Epoch 1592/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5265 - val_loss: 1.0407\n",
            "Epoch 1593/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5251 - val_loss: 1.0425\n",
            "Epoch 1594/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5258 - val_loss: 1.0493\n",
            "Epoch 1595/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5255 - val_loss: 1.0469\n",
            "Epoch 1596/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5255 - val_loss: 1.0470\n",
            "Epoch 1597/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5249 - val_loss: 1.0433\n",
            "Epoch 1598/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5255 - val_loss: 1.0436\n",
            "Epoch 1599/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5254 - val_loss: 1.0433\n",
            "Epoch 1600/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5251 - val_loss: 1.0442\n",
            "Epoch 1601/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5251 - val_loss: 1.0422\n",
            "Epoch 1602/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5262 - val_loss: 1.0448\n",
            "Epoch 1603/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5253 - val_loss: 1.0448\n",
            "Epoch 1604/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5254 - val_loss: 1.0425\n",
            "Epoch 1605/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5252 - val_loss: 1.0418\n",
            "Epoch 1606/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5252 - val_loss: 1.0454\n",
            "Epoch 1607/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5259 - val_loss: 1.0473\n",
            "Epoch 1608/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5255 - val_loss: 1.0404\n",
            "Epoch 1609/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5250 - val_loss: 1.0439\n",
            "Epoch 1610/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5252 - val_loss: 1.0432\n",
            "Epoch 1611/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5252 - val_loss: 1.0421\n",
            "Epoch 1612/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5250 - val_loss: 1.0439\n",
            "Epoch 1613/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5260 - val_loss: 1.0486\n",
            "Epoch 1614/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5249 - val_loss: 1.0432\n",
            "Epoch 1615/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5258 - val_loss: 1.0403\n",
            "Epoch 1616/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5258 - val_loss: 1.0399\n",
            "Epoch 1617/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5254 - val_loss: 1.0436\n",
            "Epoch 1618/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5251 - val_loss: 1.0447\n",
            "Epoch 1619/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5256 - val_loss: 1.0421\n",
            "Epoch 1620/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5250 - val_loss: 1.0444\n",
            "Epoch 1621/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5260 - val_loss: 1.0468\n",
            "Epoch 1622/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5252 - val_loss: 1.0455\n",
            "Epoch 1623/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5251 - val_loss: 1.0417\n",
            "Epoch 1624/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5253 - val_loss: 1.0400\n",
            "Epoch 1625/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5250 - val_loss: 1.0435\n",
            "Epoch 1626/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5250 - val_loss: 1.0428\n",
            "Epoch 1627/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5253 - val_loss: 1.0457\n",
            "Epoch 1628/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5249 - val_loss: 1.0438\n",
            "Epoch 1629/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5252 - val_loss: 1.0455\n",
            "Epoch 1630/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5250 - val_loss: 1.0436\n",
            "Epoch 1631/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5253 - val_loss: 1.0459\n",
            "Epoch 1632/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5254 - val_loss: 1.0429\n",
            "Epoch 1633/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5253 - val_loss: 1.0428\n",
            "Epoch 1634/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5253 - val_loss: 1.0465\n",
            "Epoch 1635/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5255 - val_loss: 1.0464\n",
            "Epoch 1636/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5251 - val_loss: 1.0424\n",
            "Epoch 1637/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5255 - val_loss: 1.0420\n",
            "Epoch 1638/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5251 - val_loss: 1.0436\n",
            "Epoch 1639/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5252 - val_loss: 1.0443\n",
            "Epoch 1640/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5251 - val_loss: 1.0444\n",
            "Epoch 1641/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5249 - val_loss: 1.0431\n",
            "Epoch 1642/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5258 - val_loss: 1.0424\n",
            "Epoch 1643/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5250 - val_loss: 1.0445\n",
            "Epoch 1644/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5255 - val_loss: 1.0458\n",
            "Epoch 1645/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5252 - val_loss: 1.0430\n",
            "Epoch 1646/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5253 - val_loss: 1.0400\n",
            "Epoch 1647/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5249 - val_loss: 1.0416\n",
            "Epoch 1648/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5249 - val_loss: 1.0433\n",
            "Epoch 1649/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5251 - val_loss: 1.0448\n",
            "Epoch 1650/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5250 - val_loss: 1.0430\n",
            "Epoch 1651/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5268 - val_loss: 1.0468\n",
            "Epoch 1652/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5249 - val_loss: 1.0429\n",
            "Epoch 1653/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5254 - val_loss: 1.0409\n",
            "Epoch 1654/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5250 - val_loss: 1.0420\n",
            "Epoch 1655/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5255 - val_loss: 1.0462\n",
            "Epoch 1656/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5271 - val_loss: 1.0444\n",
            "Epoch 1657/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5250 - val_loss: 1.0435\n",
            "Epoch 1658/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5248 - val_loss: 1.0419\n",
            "Epoch 1659/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5255 - val_loss: 1.0446\n",
            "Epoch 1660/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5253 - val_loss: 1.0425\n",
            "Epoch 1661/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5250 - val_loss: 1.0408\n",
            "Epoch 1662/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5249 - val_loss: 1.0467\n",
            "Epoch 1663/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5256 - val_loss: 1.0427\n",
            "Epoch 1664/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5253 - val_loss: 1.0437\n",
            "Epoch 1665/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5255 - val_loss: 1.0462\n",
            "Epoch 1666/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5251 - val_loss: 1.0456\n",
            "Epoch 1667/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5251 - val_loss: 1.0474\n",
            "Epoch 1668/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5249 - val_loss: 1.0454\n",
            "Epoch 1669/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5259 - val_loss: 1.0405\n",
            "Epoch 1670/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5263 - val_loss: 1.0444\n",
            "Epoch 1671/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5250 - val_loss: 1.0397\n",
            "Epoch 1672/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5254 - val_loss: 1.0444\n",
            "Epoch 1673/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5250 - val_loss: 1.0445\n",
            "Epoch 1674/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5256 - val_loss: 1.0439\n",
            "Epoch 1675/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5256 - val_loss: 1.0451\n",
            "Epoch 1676/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5252 - val_loss: 1.0467\n",
            "Epoch 1677/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5248 - val_loss: 1.0425\n",
            "Epoch 1678/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5254 - val_loss: 1.0457\n",
            "Epoch 1679/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5248 - val_loss: 1.0421\n",
            "Epoch 1680/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5263 - val_loss: 1.0425\n",
            "Epoch 1681/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5247 - val_loss: 1.0417\n",
            "Epoch 1682/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5255 - val_loss: 1.0397\n",
            "Epoch 1683/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5254 - val_loss: 1.0448\n",
            "Epoch 1684/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5256 - val_loss: 1.0414\n",
            "Epoch 1685/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5248 - val_loss: 1.0442\n",
            "Epoch 1686/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5260 - val_loss: 1.0416\n",
            "Epoch 1687/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5249 - val_loss: 1.0436\n",
            "Epoch 1688/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5250 - val_loss: 1.0423\n",
            "Epoch 1689/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5250 - val_loss: 1.0440\n",
            "Epoch 1690/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5250 - val_loss: 1.0456\n",
            "Epoch 1691/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5253 - val_loss: 1.0451\n",
            "Epoch 1692/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5257 - val_loss: 1.0471\n",
            "Epoch 1693/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5249 - val_loss: 1.0444\n",
            "Epoch 1694/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5256 - val_loss: 1.0409\n",
            "Epoch 1695/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5249 - val_loss: 1.0405\n",
            "Epoch 1696/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5253 - val_loss: 1.0394\n",
            "Epoch 1697/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5249 - val_loss: 1.0400\n",
            "Epoch 1698/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5249 - val_loss: 1.0463\n",
            "Epoch 1699/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5245 - val_loss: 1.0441\n",
            "Epoch 1700/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5250 - val_loss: 1.0412\n",
            "Epoch 1701/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5248 - val_loss: 1.0433\n",
            "Epoch 1702/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5253 - val_loss: 1.0417\n",
            "Epoch 1703/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5252 - val_loss: 1.0460\n",
            "Epoch 1704/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5251 - val_loss: 1.0469\n",
            "Epoch 1705/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5253 - val_loss: 1.0426\n",
            "Epoch 1706/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5249 - val_loss: 1.0433\n",
            "Epoch 1707/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5250 - val_loss: 1.0428\n",
            "Epoch 1708/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5250 - val_loss: 1.0432\n",
            "Epoch 1709/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5253 - val_loss: 1.0441\n",
            "Epoch 1710/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5248 - val_loss: 1.0433\n",
            "Epoch 1711/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5252 - val_loss: 1.0447\n",
            "Epoch 1712/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5253 - val_loss: 1.0406\n",
            "Epoch 1713/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5249 - val_loss: 1.0399\n",
            "Epoch 1714/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5257 - val_loss: 1.0472\n",
            "Epoch 1715/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5247 - val_loss: 1.0447\n",
            "Epoch 1716/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5255 - val_loss: 1.0455\n",
            "Epoch 1717/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5247 - val_loss: 1.0431\n",
            "Epoch 1718/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5254 - val_loss: 1.0386\n",
            "Epoch 1719/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5253 - val_loss: 1.0446\n",
            "Epoch 1720/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5250 - val_loss: 1.0448\n",
            "Epoch 1721/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5256 - val_loss: 1.0447\n",
            "Epoch 1722/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5247 - val_loss: 1.0415\n",
            "Epoch 1723/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5259 - val_loss: 1.0377\n",
            "Epoch 1724/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5252 - val_loss: 1.0405\n",
            "Epoch 1725/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5254 - val_loss: 1.0406\n",
            "Epoch 1726/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5247 - val_loss: 1.0455\n",
            "Epoch 1727/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5254 - val_loss: 1.0478\n",
            "Epoch 1728/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5249 - val_loss: 1.0439\n",
            "Epoch 1729/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5250 - val_loss: 1.0408\n",
            "Epoch 1730/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5262 - val_loss: 1.0490\n",
            "Epoch 1731/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5250 - val_loss: 1.0412\n",
            "Epoch 1732/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5248 - val_loss: 1.0417\n",
            "Epoch 1733/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5257 - val_loss: 1.0449\n",
            "Epoch 1734/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5248 - val_loss: 1.0409\n",
            "Epoch 1735/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5250 - val_loss: 1.0444\n",
            "Epoch 1736/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5247 - val_loss: 1.0455\n",
            "Epoch 1737/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5248 - val_loss: 1.0428\n",
            "Epoch 1738/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5251 - val_loss: 1.0409\n",
            "Epoch 1739/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5254 - val_loss: 1.0409\n",
            "Epoch 1740/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5261 - val_loss: 1.0392\n",
            "Epoch 1741/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5252 - val_loss: 1.0472\n",
            "Epoch 1742/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5247 - val_loss: 1.0457\n",
            "Epoch 1743/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5251 - val_loss: 1.0456\n",
            "Epoch 1744/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5248 - val_loss: 1.0453\n",
            "Epoch 1745/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5249 - val_loss: 1.0408\n",
            "Epoch 1746/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5245 - val_loss: 1.0416\n",
            "Epoch 1747/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5260 - val_loss: 1.0422\n",
            "Epoch 1748/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5249 - val_loss: 1.0416\n",
            "Epoch 1749/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5249 - val_loss: 1.0442\n",
            "Epoch 1750/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5256 - val_loss: 1.0375\n",
            "Epoch 1751/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5253 - val_loss: 1.0431\n",
            "Epoch 1752/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5255 - val_loss: 1.0465\n",
            "Epoch 1753/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5246 - val_loss: 1.0444\n",
            "Epoch 1754/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5248 - val_loss: 1.0411\n",
            "Epoch 1755/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5245 - val_loss: 1.0424\n",
            "Epoch 1756/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5249 - val_loss: 1.0450\n",
            "Epoch 1757/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5255 - val_loss: 1.0440\n",
            "Epoch 1758/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5259 - val_loss: 1.0440\n",
            "Epoch 1759/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5248 - val_loss: 1.0468\n",
            "Epoch 1760/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5254 - val_loss: 1.0421\n",
            "Epoch 1761/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5246 - val_loss: 1.0407\n",
            "Epoch 1762/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5247 - val_loss: 1.0439\n",
            "Epoch 1763/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5259 - val_loss: 1.0407\n",
            "Epoch 1764/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5250 - val_loss: 1.0454\n",
            "Epoch 1765/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5260 - val_loss: 1.0407\n",
            "Epoch 1766/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5254 - val_loss: 1.0478\n",
            "Epoch 1767/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5250 - val_loss: 1.0429\n",
            "Epoch 1768/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5245 - val_loss: 1.0436\n",
            "Epoch 1769/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5252 - val_loss: 1.0444\n",
            "Epoch 1770/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5248 - val_loss: 1.0420\n",
            "Epoch 1771/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5248 - val_loss: 1.0403\n",
            "Epoch 1772/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5251 - val_loss: 1.0452\n",
            "Epoch 1773/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5252 - val_loss: 1.0458\n",
            "Epoch 1774/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5262 - val_loss: 1.0392\n",
            "Epoch 1775/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5245 - val_loss: 1.0452\n",
            "Epoch 1776/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5251 - val_loss: 1.0486\n",
            "Epoch 1777/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5254 - val_loss: 1.0445\n",
            "Epoch 1778/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5248 - val_loss: 1.0420\n",
            "Epoch 1779/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5245 - val_loss: 1.0438\n",
            "Epoch 1780/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5249 - val_loss: 1.0450\n",
            "Epoch 1781/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5252 - val_loss: 1.0403\n",
            "Epoch 1782/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5255 - val_loss: 1.0404\n",
            "Epoch 1783/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5246 - val_loss: 1.0429\n",
            "Epoch 1784/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5252 - val_loss: 1.0404\n",
            "Epoch 1785/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5248 - val_loss: 1.0457\n",
            "Epoch 1786/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5247 - val_loss: 1.0415\n",
            "Epoch 1787/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5247 - val_loss: 1.0431\n",
            "Epoch 1788/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5243 - val_loss: 1.0427\n",
            "Epoch 1789/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5247 - val_loss: 1.0430\n",
            "Epoch 1790/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5247 - val_loss: 1.0448\n",
            "Epoch 1791/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5249 - val_loss: 1.0478\n",
            "Epoch 1792/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5244 - val_loss: 1.0439\n",
            "Epoch 1793/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5245 - val_loss: 1.0444\n",
            "Epoch 1794/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5247 - val_loss: 1.0440\n",
            "Epoch 1795/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5250 - val_loss: 1.0459\n",
            "Epoch 1796/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5247 - val_loss: 1.0436\n",
            "Epoch 1797/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5244 - val_loss: 1.0423\n",
            "Epoch 1798/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5246 - val_loss: 1.0388\n",
            "Epoch 1799/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5248 - val_loss: 1.0431\n",
            "Epoch 1800/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5254 - val_loss: 1.0424\n",
            "Epoch 1801/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5256 - val_loss: 1.0407\n",
            "Epoch 1802/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5247 - val_loss: 1.0439\n",
            "Epoch 1803/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5246 - val_loss: 1.0442\n",
            "Epoch 1804/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5248 - val_loss: 1.0452\n",
            "Epoch 1805/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5247 - val_loss: 1.0455\n",
            "Epoch 1806/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5255 - val_loss: 1.0395\n",
            "Epoch 1807/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5247 - val_loss: 1.0458\n",
            "Epoch 1808/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5249 - val_loss: 1.0466\n",
            "Epoch 1809/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5252 - val_loss: 1.0404\n",
            "Epoch 1810/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5252 - val_loss: 1.0464\n",
            "Epoch 1811/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5244 - val_loss: 1.0455\n",
            "Epoch 1812/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5247 - val_loss: 1.0422\n",
            "Epoch 1813/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5244 - val_loss: 1.0434\n",
            "Epoch 1814/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5257 - val_loss: 1.0425\n",
            "Epoch 1815/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5248 - val_loss: 1.0447\n",
            "Epoch 1816/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5246 - val_loss: 1.0435\n",
            "Epoch 1817/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5243 - val_loss: 1.0440\n",
            "Epoch 1818/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5254 - val_loss: 1.0487\n",
            "Epoch 1819/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5251 - val_loss: 1.0422\n",
            "Epoch 1820/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5247 - val_loss: 1.0426\n",
            "Epoch 1821/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5243 - val_loss: 1.0441\n",
            "Epoch 1822/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5246 - val_loss: 1.0417\n",
            "Epoch 1823/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5247 - val_loss: 1.0447\n",
            "Epoch 1824/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5248 - val_loss: 1.0423\n",
            "Epoch 1825/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5252 - val_loss: 1.0481\n",
            "Epoch 1826/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5248 - val_loss: 1.0461\n",
            "Epoch 1827/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5245 - val_loss: 1.0453\n",
            "Epoch 1828/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5251 - val_loss: 1.0386\n",
            "Epoch 1829/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5244 - val_loss: 1.0408\n",
            "Epoch 1830/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5248 - val_loss: 1.0440\n",
            "Epoch 1831/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5246 - val_loss: 1.0453\n",
            "Epoch 1832/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5249 - val_loss: 1.0434\n",
            "Epoch 1833/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5244 - val_loss: 1.0434\n",
            "Epoch 1834/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5245 - val_loss: 1.0408\n",
            "Epoch 1835/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5253 - val_loss: 1.0439\n",
            "Epoch 1836/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5264 - val_loss: 1.0379\n",
            "Epoch 1837/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5259 - val_loss: 1.0479\n",
            "Epoch 1838/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5251 - val_loss: 1.0442\n",
            "Epoch 1839/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5245 - val_loss: 1.0440\n",
            "Epoch 1840/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5255 - val_loss: 1.0431\n",
            "Epoch 1841/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5245 - val_loss: 1.0428\n",
            "Epoch 1842/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5247 - val_loss: 1.0442\n",
            "Epoch 1843/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5254 - val_loss: 1.0383\n",
            "Epoch 1844/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5246 - val_loss: 1.0434\n",
            "Epoch 1845/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5247 - val_loss: 1.0430\n",
            "Epoch 1846/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5245 - val_loss: 1.0443\n",
            "Epoch 1847/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5245 - val_loss: 1.0451\n",
            "Epoch 1848/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5250 - val_loss: 1.0421\n",
            "Epoch 1849/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5250 - val_loss: 1.0477\n",
            "Epoch 1850/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5255 - val_loss: 1.0395\n",
            "Epoch 1851/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5249 - val_loss: 1.0437\n",
            "Epoch 1852/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5251 - val_loss: 1.0434\n",
            "Epoch 1853/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5257 - val_loss: 1.0430\n",
            "Epoch 1854/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5246 - val_loss: 1.0421\n",
            "Epoch 1855/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5246 - val_loss: 1.0454\n",
            "Epoch 1856/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5259 - val_loss: 1.0401\n",
            "Epoch 1857/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5251 - val_loss: 1.0414\n",
            "Epoch 1858/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5255 - val_loss: 1.0404\n",
            "Epoch 1859/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5246 - val_loss: 1.0454\n",
            "Epoch 1860/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5250 - val_loss: 1.0428\n",
            "Epoch 1861/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5249 - val_loss: 1.0440\n",
            "Epoch 1862/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5247 - val_loss: 1.0441\n",
            "Epoch 1863/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5244 - val_loss: 1.0450\n",
            "Epoch 1864/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5260 - val_loss: 1.0396\n",
            "Epoch 1865/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5247 - val_loss: 1.0457\n",
            "Epoch 1866/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5245 - val_loss: 1.0444\n",
            "Epoch 1867/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5245 - val_loss: 1.0457\n",
            "Epoch 1868/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5248 - val_loss: 1.0461\n",
            "Epoch 1869/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5248 - val_loss: 1.0411\n",
            "Epoch 1870/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5243 - val_loss: 1.0430\n",
            "Epoch 1871/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5243 - val_loss: 1.0429\n",
            "Epoch 1872/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5250 - val_loss: 1.0404\n",
            "Epoch 1873/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5249 - val_loss: 1.0454\n",
            "Epoch 1874/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5245 - val_loss: 1.0445\n",
            "Epoch 1875/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5245 - val_loss: 1.0440\n",
            "Epoch 1876/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5242 - val_loss: 1.0452\n",
            "Epoch 1877/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5247 - val_loss: 1.0446\n",
            "Epoch 1878/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5248 - val_loss: 1.0432\n",
            "Epoch 1879/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5245 - val_loss: 1.0410\n",
            "Epoch 1880/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5243 - val_loss: 1.0437\n",
            "Epoch 1881/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5244 - val_loss: 1.0433\n",
            "Epoch 1882/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5243 - val_loss: 1.0448\n",
            "Epoch 1883/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5243 - val_loss: 1.0425\n",
            "Epoch 1884/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5249 - val_loss: 1.0456\n",
            "Epoch 1885/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5259 - val_loss: 1.0419\n",
            "Epoch 1886/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5247 - val_loss: 1.0421\n",
            "Epoch 1887/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5249 - val_loss: 1.0402\n",
            "Epoch 1888/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5243 - val_loss: 1.0429\n",
            "Epoch 1889/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5253 - val_loss: 1.0473\n",
            "Epoch 1890/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5251 - val_loss: 1.0451\n",
            "Epoch 1891/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5243 - val_loss: 1.0462\n",
            "Epoch 1892/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5243 - val_loss: 1.0451\n",
            "Epoch 1893/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5251 - val_loss: 1.0429\n",
            "Epoch 1894/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5250 - val_loss: 1.0473\n",
            "Epoch 1895/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5243 - val_loss: 1.0425\n",
            "Epoch 1896/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5254 - val_loss: 1.0418\n",
            "Epoch 1897/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5244 - val_loss: 1.0480\n",
            "Epoch 1898/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5250 - val_loss: 1.0477\n",
            "Epoch 1899/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5257 - val_loss: 1.0468\n",
            "Epoch 1900/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5252 - val_loss: 1.0394\n",
            "Epoch 1901/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5267 - val_loss: 1.0472\n",
            "Epoch 1902/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5247 - val_loss: 1.0447\n",
            "Epoch 1903/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5246 - val_loss: 1.0399\n",
            "Epoch 1904/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5257 - val_loss: 1.0467\n",
            "Epoch 1905/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5249 - val_loss: 1.0418\n",
            "Epoch 1906/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5249 - val_loss: 1.0433\n",
            "Epoch 1907/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5244 - val_loss: 1.0428\n",
            "Epoch 1908/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5242 - val_loss: 1.0439\n",
            "Epoch 1909/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5244 - val_loss: 1.0425\n",
            "Epoch 1910/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5243 - val_loss: 1.0424\n",
            "Epoch 1911/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5245 - val_loss: 1.0414\n",
            "Epoch 1912/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5253 - val_loss: 1.0449\n",
            "Epoch 1913/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5242 - val_loss: 1.0439\n",
            "Epoch 1914/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5245 - val_loss: 1.0401\n",
            "Epoch 1915/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5250 - val_loss: 1.0448\n",
            "Epoch 1916/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5253 - val_loss: 1.0412\n",
            "Epoch 1917/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5246 - val_loss: 1.0460\n",
            "Epoch 1918/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5250 - val_loss: 1.0429\n",
            "Epoch 1919/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5252 - val_loss: 1.0439\n",
            "Epoch 1920/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5252 - val_loss: 1.0490\n",
            "Epoch 1921/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5243 - val_loss: 1.0446\n",
            "Epoch 1922/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5253 - val_loss: 1.0481\n",
            "Epoch 1923/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5263 - val_loss: 1.0373\n",
            "Epoch 1924/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5245 - val_loss: 1.0387\n",
            "Epoch 1925/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5248 - val_loss: 1.0482\n",
            "Epoch 1926/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5243 - val_loss: 1.0447\n",
            "Epoch 1927/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5243 - val_loss: 1.0460\n",
            "Epoch 1928/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5245 - val_loss: 1.0461\n",
            "Epoch 1929/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5244 - val_loss: 1.0446\n",
            "Epoch 1930/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5252 - val_loss: 1.0402\n",
            "Epoch 1931/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5245 - val_loss: 1.0412\n",
            "Epoch 1932/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5243 - val_loss: 1.0451\n",
            "Epoch 1933/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5245 - val_loss: 1.0427\n",
            "Epoch 1934/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5245 - val_loss: 1.0420\n",
            "Epoch 1935/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5257 - val_loss: 1.0485\n",
            "Epoch 1936/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5268 - val_loss: 1.0400\n",
            "Epoch 1937/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5248 - val_loss: 1.0454\n",
            "Epoch 1938/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5242 - val_loss: 1.0443\n",
            "Epoch 1939/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5244 - val_loss: 1.0424\n",
            "Epoch 1940/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5243 - val_loss: 1.0413\n",
            "Epoch 1941/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5250 - val_loss: 1.0443\n",
            "Epoch 1942/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5249 - val_loss: 1.0410\n",
            "Epoch 1943/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5242 - val_loss: 1.0464\n",
            "Epoch 1944/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5247 - val_loss: 1.0400\n",
            "Epoch 1945/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5240 - val_loss: 1.0448\n",
            "Epoch 1946/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5246 - val_loss: 1.0432\n",
            "Epoch 1947/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5251 - val_loss: 1.0486\n",
            "Epoch 1948/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5250 - val_loss: 1.0450\n",
            "Epoch 1949/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5244 - val_loss: 1.0455\n",
            "Epoch 1950/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5242 - val_loss: 1.0426\n",
            "Epoch 1951/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5242 - val_loss: 1.0399\n",
            "Epoch 1952/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5247 - val_loss: 1.0422\n",
            "Epoch 1953/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5241 - val_loss: 1.0447\n",
            "Epoch 1954/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5243 - val_loss: 1.0458\n",
            "Epoch 1955/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5243 - val_loss: 1.0464\n",
            "Epoch 1956/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5243 - val_loss: 1.0411\n",
            "Epoch 1957/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5244 - val_loss: 1.0415\n",
            "Epoch 1958/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5245 - val_loss: 1.0429\n",
            "Epoch 1959/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5263 - val_loss: 1.0404\n",
            "Epoch 1960/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5247 - val_loss: 1.0464\n",
            "Epoch 1961/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5258 - val_loss: 1.0429\n",
            "Epoch 1962/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5251 - val_loss: 1.0443\n",
            "Epoch 1963/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5247 - val_loss: 1.0462\n",
            "Epoch 1964/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5244 - val_loss: 1.0454\n",
            "Epoch 1965/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5243 - val_loss: 1.0400\n",
            "Epoch 1966/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5257 - val_loss: 1.0379\n",
            "Epoch 1967/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5243 - val_loss: 1.0470\n",
            "Epoch 1968/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5242 - val_loss: 1.0422\n",
            "Epoch 1969/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5244 - val_loss: 1.0446\n",
            "Epoch 1970/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5246 - val_loss: 1.0438\n",
            "Epoch 1971/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5241 - val_loss: 1.0442\n",
            "Epoch 1972/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5244 - val_loss: 1.0448\n",
            "Epoch 1973/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5245 - val_loss: 1.0469\n",
            "Epoch 1974/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5240 - val_loss: 1.0445\n",
            "Epoch 1975/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5245 - val_loss: 1.0439\n",
            "Epoch 1976/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5250 - val_loss: 1.0416\n",
            "Epoch 1977/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5248 - val_loss: 1.0463\n",
            "Epoch 1978/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5253 - val_loss: 1.0389\n",
            "Epoch 1979/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5243 - val_loss: 1.0466\n",
            "Epoch 1980/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5244 - val_loss: 1.0439\n",
            "Epoch 1981/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5255 - val_loss: 1.0438\n",
            "Epoch 1982/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5248 - val_loss: 1.0413\n",
            "Epoch 1983/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5246 - val_loss: 1.0432\n",
            "Epoch 1984/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5248 - val_loss: 1.0425\n",
            "Epoch 1985/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5258 - val_loss: 1.0402\n",
            "Epoch 1986/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5257 - val_loss: 1.0503\n",
            "Epoch 1987/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5240 - val_loss: 1.0455\n",
            "Epoch 1988/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5244 - val_loss: 1.0465\n",
            "Epoch 1989/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5243 - val_loss: 1.0417\n",
            "Epoch 1990/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5250 - val_loss: 1.0419\n",
            "Epoch 1991/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5257 - val_loss: 1.0399\n",
            "Epoch 1992/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5248 - val_loss: 1.0477\n",
            "Epoch 1993/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5252 - val_loss: 1.0395\n",
            "Epoch 1994/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5245 - val_loss: 1.0440\n",
            "Epoch 1995/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5254 - val_loss: 1.0517\n",
            "Epoch 1996/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5241 - val_loss: 1.0447\n",
            "Epoch 1997/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5249 - val_loss: 1.0484\n",
            "Epoch 1998/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5246 - val_loss: 1.0392\n",
            "Epoch 1999/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5246 - val_loss: 1.0462\n",
            "Epoch 2000/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5244 - val_loss: 1.0447\n",
            "Epoch 2001/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5241 - val_loss: 1.0436\n",
            "Epoch 2002/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5247 - val_loss: 1.0447\n",
            "Epoch 2003/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5241 - val_loss: 1.0423\n",
            "Epoch 2004/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5246 - val_loss: 1.0430\n",
            "Epoch 2005/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5248 - val_loss: 1.0393\n",
            "Epoch 2006/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5242 - val_loss: 1.0447\n",
            "Epoch 2007/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5242 - val_loss: 1.0446\n",
            "Epoch 2008/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5241 - val_loss: 1.0445\n",
            "Epoch 2009/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5241 - val_loss: 1.0462\n",
            "Epoch 2010/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5242 - val_loss: 1.0452\n",
            "Epoch 2011/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5243 - val_loss: 1.0415\n",
            "Epoch 2012/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5248 - val_loss: 1.0473\n",
            "Epoch 2013/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5247 - val_loss: 1.0404\n",
            "Epoch 2014/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5249 - val_loss: 1.0459\n",
            "Epoch 2015/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5240 - val_loss: 1.0418\n",
            "Epoch 2016/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5242 - val_loss: 1.0423\n",
            "Epoch 2017/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5253 - val_loss: 1.0459\n",
            "Epoch 2018/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5244 - val_loss: 1.0419\n",
            "Epoch 2019/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5240 - val_loss: 1.0419\n",
            "Epoch 2020/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5239 - val_loss: 1.0425\n",
            "Epoch 2021/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5242 - val_loss: 1.0405\n",
            "Epoch 2022/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5244 - val_loss: 1.0457\n",
            "Epoch 2023/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5242 - val_loss: 1.0450\n",
            "Epoch 2024/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5244 - val_loss: 1.0430\n",
            "Epoch 2025/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5242 - val_loss: 1.0449\n",
            "Epoch 2026/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5240 - val_loss: 1.0450\n",
            "Epoch 2027/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5249 - val_loss: 1.0438\n",
            "Epoch 2028/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5244 - val_loss: 1.0478\n",
            "Epoch 2029/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5242 - val_loss: 1.0454\n",
            "Epoch 2030/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5244 - val_loss: 1.0420\n",
            "Epoch 2031/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5245 - val_loss: 1.0443\n",
            "Epoch 2032/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5241 - val_loss: 1.0426\n",
            "Epoch 2033/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5241 - val_loss: 1.0414\n",
            "Epoch 2034/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5252 - val_loss: 1.0456\n",
            "Epoch 2035/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5248 - val_loss: 1.0381\n",
            "Epoch 2036/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5244 - val_loss: 1.0445\n",
            "Epoch 2037/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5248 - val_loss: 1.0406\n",
            "Epoch 2038/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5243 - val_loss: 1.0427\n",
            "Epoch 2039/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5241 - val_loss: 1.0437\n",
            "Epoch 2040/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5244 - val_loss: 1.0407\n",
            "Epoch 2041/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5249 - val_loss: 1.0442\n",
            "Epoch 2042/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5247 - val_loss: 1.0443\n",
            "Epoch 2043/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5243 - val_loss: 1.0426\n",
            "Epoch 2044/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5243 - val_loss: 1.0435\n",
            "Epoch 2045/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5243 - val_loss: 1.0434\n",
            "Epoch 2046/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5246 - val_loss: 1.0473\n",
            "Epoch 2047/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5246 - val_loss: 1.0446\n",
            "Epoch 2048/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5247 - val_loss: 1.0456\n",
            "Epoch 2049/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5250 - val_loss: 1.0392\n",
            "Epoch 2050/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5245 - val_loss: 1.0453\n",
            "Epoch 2051/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5245 - val_loss: 1.0442\n",
            "Epoch 2052/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5244 - val_loss: 1.0456\n",
            "Epoch 2053/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5247 - val_loss: 1.0483\n",
            "Epoch 2054/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5242 - val_loss: 1.0424\n",
            "Epoch 2055/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5246 - val_loss: 1.0430\n",
            "Epoch 2056/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5240 - val_loss: 1.0412\n",
            "Epoch 2057/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5243 - val_loss: 1.0401\n",
            "Epoch 2058/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5244 - val_loss: 1.0447\n",
            "Epoch 2059/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5251 - val_loss: 1.0401\n",
            "Epoch 2060/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5240 - val_loss: 1.0462\n",
            "Epoch 2061/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5252 - val_loss: 1.0466\n",
            "Epoch 2062/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5244 - val_loss: 1.0416\n",
            "Epoch 2063/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5243 - val_loss: 1.0429\n",
            "Epoch 2064/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5247 - val_loss: 1.0446\n",
            "Epoch 2065/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5248 - val_loss: 1.0396\n",
            "Epoch 2066/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5244 - val_loss: 1.0431\n",
            "Epoch 2067/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5246 - val_loss: 1.0471\n",
            "Epoch 2068/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5253 - val_loss: 1.0434\n",
            "Epoch 2069/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5242 - val_loss: 1.0461\n",
            "Epoch 2070/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5247 - val_loss: 1.0403\n",
            "Epoch 2071/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5248 - val_loss: 1.0481\n",
            "Epoch 2072/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5244 - val_loss: 1.0466\n",
            "Epoch 2073/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5244 - val_loss: 1.0417\n",
            "Epoch 2074/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5246 - val_loss: 1.0457\n",
            "Epoch 2075/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5243 - val_loss: 1.0423\n",
            "Epoch 2076/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5250 - val_loss: 1.0406\n",
            "Epoch 2077/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5239 - val_loss: 1.0448\n",
            "Epoch 2078/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5245 - val_loss: 1.0446\n",
            "Epoch 2079/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5242 - val_loss: 1.0458\n",
            "Epoch 2080/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5237 - val_loss: 1.0435\n",
            "Epoch 2081/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5241 - val_loss: 1.0419\n",
            "Epoch 2082/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5241 - val_loss: 1.0419\n",
            "Epoch 2083/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5246 - val_loss: 1.0420\n",
            "Epoch 2084/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5247 - val_loss: 1.0499\n",
            "Epoch 2085/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5254 - val_loss: 1.0425\n",
            "Epoch 2086/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5246 - val_loss: 1.0480\n",
            "Epoch 2087/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5240 - val_loss: 1.0427\n",
            "Epoch 2088/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5246 - val_loss: 1.0466\n",
            "Epoch 2089/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5241 - val_loss: 1.0445\n",
            "Epoch 2090/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5243 - val_loss: 1.0446\n",
            "Epoch 2091/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5239 - val_loss: 1.0435\n",
            "Epoch 2092/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5241 - val_loss: 1.0434\n",
            "Epoch 2093/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5250 - val_loss: 1.0408\n",
            "Epoch 2094/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5240 - val_loss: 1.0448\n",
            "Epoch 2095/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5243 - val_loss: 1.0468\n",
            "Epoch 2096/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5243 - val_loss: 1.0478\n",
            "Epoch 2097/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5245 - val_loss: 1.0393\n",
            "Epoch 2098/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5241 - val_loss: 1.0422\n",
            "Epoch 2099/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5244 - val_loss: 1.0478\n",
            "Epoch 2100/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5238 - val_loss: 1.0448\n",
            "Epoch 2101/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5243 - val_loss: 1.0404\n",
            "Epoch 2102/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5239 - val_loss: 1.0432\n",
            "Epoch 2103/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5239 - val_loss: 1.0447\n",
            "Epoch 2104/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5240 - val_loss: 1.0462\n",
            "Epoch 2105/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5241 - val_loss: 1.0452\n",
            "Epoch 2106/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5244 - val_loss: 1.0483\n",
            "Epoch 2107/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5241 - val_loss: 1.0438\n",
            "Epoch 2108/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5246 - val_loss: 1.0411\n",
            "Epoch 2109/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5236 - val_loss: 1.0443\n",
            "Epoch 2110/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5245 - val_loss: 1.0425\n",
            "Epoch 2111/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5240 - val_loss: 1.0479\n",
            "Epoch 2112/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5237 - val_loss: 1.0475\n",
            "Epoch 2113/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5239 - val_loss: 1.0459\n",
            "Epoch 2114/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5244 - val_loss: 1.0455\n",
            "Epoch 2115/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5257 - val_loss: 1.0419\n",
            "Epoch 2116/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5236 - val_loss: 1.0442\n",
            "Epoch 2117/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5251 - val_loss: 1.0411\n",
            "Epoch 2118/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5244 - val_loss: 1.0457\n",
            "Epoch 2119/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5244 - val_loss: 1.0431\n",
            "Epoch 2120/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5251 - val_loss: 1.0472\n",
            "Epoch 2121/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5248 - val_loss: 1.0434\n",
            "Epoch 2122/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5243 - val_loss: 1.0417\n",
            "Epoch 2123/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5239 - val_loss: 1.0413\n",
            "Epoch 2124/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5245 - val_loss: 1.0433\n",
            "Epoch 2125/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5244 - val_loss: 1.0470\n",
            "Epoch 2126/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5245 - val_loss: 1.0461\n",
            "Epoch 2127/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5238 - val_loss: 1.0452\n",
            "Epoch 2128/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5237 - val_loss: 1.0420\n",
            "Epoch 2129/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5237 - val_loss: 1.0454\n",
            "Epoch 2130/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5246 - val_loss: 1.0471\n",
            "Epoch 2131/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5246 - val_loss: 1.0425\n",
            "Epoch 2132/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5238 - val_loss: 1.0451\n",
            "Epoch 2133/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5236 - val_loss: 1.0442\n",
            "Epoch 2134/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5241 - val_loss: 1.0418\n",
            "Epoch 2135/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5243 - val_loss: 1.0426\n",
            "Epoch 2136/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5241 - val_loss: 1.0446\n",
            "Epoch 2137/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5238 - val_loss: 1.0448\n",
            "Epoch 2138/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5240 - val_loss: 1.0440\n",
            "Epoch 2139/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5244 - val_loss: 1.0421\n",
            "Epoch 2140/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5255 - val_loss: 1.0481\n",
            "Epoch 2141/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5243 - val_loss: 1.0431\n",
            "Epoch 2142/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5248 - val_loss: 1.0385\n",
            "Epoch 2143/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5241 - val_loss: 1.0471\n",
            "Epoch 2144/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5244 - val_loss: 1.0424\n",
            "Epoch 2145/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5239 - val_loss: 1.0423\n",
            "Epoch 2146/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5237 - val_loss: 1.0441\n",
            "Epoch 2147/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5240 - val_loss: 1.0446\n",
            "Epoch 2148/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5242 - val_loss: 1.0436\n",
            "Epoch 2149/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5238 - val_loss: 1.0447\n",
            "Epoch 2150/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5241 - val_loss: 1.0449\n",
            "Epoch 2151/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5241 - val_loss: 1.0478\n",
            "Epoch 2152/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5240 - val_loss: 1.0421\n",
            "Epoch 2153/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5241 - val_loss: 1.0458\n",
            "Epoch 2154/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5238 - val_loss: 1.0417\n",
            "Epoch 2155/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5241 - val_loss: 1.0428\n",
            "Epoch 2156/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5242 - val_loss: 1.0410\n",
            "Epoch 2157/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5245 - val_loss: 1.0430\n",
            "Epoch 2158/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5236 - val_loss: 1.0465\n",
            "Epoch 2159/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5236 - val_loss: 1.0454\n",
            "Epoch 2160/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5238 - val_loss: 1.0443\n",
            "Epoch 2161/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5248 - val_loss: 1.0404\n",
            "Epoch 2162/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5237 - val_loss: 1.0454\n",
            "Epoch 2163/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5239 - val_loss: 1.0449\n",
            "Epoch 2164/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5248 - val_loss: 1.0446\n",
            "Epoch 2165/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5235 - val_loss: 1.0467\n",
            "Epoch 2166/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5240 - val_loss: 1.0467\n",
            "Epoch 2167/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5241 - val_loss: 1.0442\n",
            "Epoch 2168/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5240 - val_loss: 1.0454\n",
            "Epoch 2169/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5246 - val_loss: 1.0413\n",
            "Epoch 2170/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5240 - val_loss: 1.0451\n",
            "Epoch 2171/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5238 - val_loss: 1.0444\n",
            "Epoch 2172/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5237 - val_loss: 1.0447\n",
            "Epoch 2173/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5239 - val_loss: 1.0459\n",
            "Epoch 2174/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5244 - val_loss: 1.0425\n",
            "Epoch 2175/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5246 - val_loss: 1.0439\n",
            "Epoch 2176/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5239 - val_loss: 1.0422\n",
            "Epoch 2177/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5250 - val_loss: 1.0462\n",
            "Epoch 2178/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5235 - val_loss: 1.0445\n",
            "Epoch 2179/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5241 - val_loss: 1.0436\n",
            "Epoch 2180/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5240 - val_loss: 1.0427\n",
            "Epoch 2181/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5237 - val_loss: 1.0412\n",
            "Epoch 2182/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5247 - val_loss: 1.0448\n",
            "Epoch 2183/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5239 - val_loss: 1.0468\n",
            "Epoch 2184/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5240 - val_loss: 1.0463\n",
            "Epoch 2185/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5237 - val_loss: 1.0434\n",
            "Epoch 2186/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5258 - val_loss: 1.0383\n",
            "Epoch 2187/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5240 - val_loss: 1.0413\n",
            "Epoch 2188/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5235 - val_loss: 1.0465\n",
            "Epoch 2189/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5241 - val_loss: 1.0423\n",
            "Epoch 2190/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5241 - val_loss: 1.0474\n",
            "Epoch 2191/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5235 - val_loss: 1.0428\n",
            "Epoch 2192/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5238 - val_loss: 1.0418\n",
            "Epoch 2193/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5243 - val_loss: 1.0479\n",
            "Epoch 2194/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5240 - val_loss: 1.0448\n",
            "Epoch 2195/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5242 - val_loss: 1.0418\n",
            "Epoch 2196/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5241 - val_loss: 1.0407\n",
            "Epoch 2197/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5240 - val_loss: 1.0419\n",
            "Epoch 2198/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5238 - val_loss: 1.0426\n",
            "Epoch 2199/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5242 - val_loss: 1.0438\n",
            "Epoch 2200/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5243 - val_loss: 1.0463\n",
            "Epoch 2201/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5238 - val_loss: 1.0445\n",
            "Epoch 2202/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5237 - val_loss: 1.0454\n",
            "Epoch 2203/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5240 - val_loss: 1.0457\n",
            "Epoch 2204/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5237 - val_loss: 1.0436\n",
            "Epoch 2205/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5237 - val_loss: 1.0431\n",
            "Epoch 2206/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5236 - val_loss: 1.0434\n",
            "Epoch 2207/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5241 - val_loss: 1.0448\n",
            "Epoch 2208/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5247 - val_loss: 1.0420\n",
            "Epoch 2209/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5238 - val_loss: 1.0471\n",
            "Epoch 2210/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5241 - val_loss: 1.0428\n",
            "Epoch 2211/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5236 - val_loss: 1.0447\n",
            "Epoch 2212/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5240 - val_loss: 1.0468\n",
            "Epoch 2213/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5239 - val_loss: 1.0452\n",
            "Epoch 2214/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5244 - val_loss: 1.0407\n",
            "Epoch 2215/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5251 - val_loss: 1.0453\n",
            "Epoch 2216/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5240 - val_loss: 1.0406\n",
            "Epoch 2217/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5238 - val_loss: 1.0458\n",
            "Epoch 2218/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5245 - val_loss: 1.0432\n",
            "Epoch 2219/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5238 - val_loss: 1.0458\n",
            "Epoch 2220/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5238 - val_loss: 1.0466\n",
            "Epoch 2221/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5242 - val_loss: 1.0497\n",
            "Epoch 2222/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5237 - val_loss: 1.0404\n",
            "Epoch 2223/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5241 - val_loss: 1.0418\n",
            "Epoch 2224/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5241 - val_loss: 1.0448\n",
            "Epoch 2225/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5240 - val_loss: 1.0423\n",
            "Epoch 2226/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5253 - val_loss: 1.0494\n",
            "Epoch 2227/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5249 - val_loss: 1.0415\n",
            "Epoch 2228/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5235 - val_loss: 1.0446\n",
            "Epoch 2229/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5238 - val_loss: 1.0456\n",
            "Epoch 2230/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5238 - val_loss: 1.0472\n",
            "Epoch 2231/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5251 - val_loss: 1.0419\n",
            "Epoch 2232/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5242 - val_loss: 1.0463\n",
            "Epoch 2233/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5244 - val_loss: 1.0431\n",
            "Epoch 2234/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5243 - val_loss: 1.0455\n",
            "Epoch 2235/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5235 - val_loss: 1.0431\n",
            "Epoch 2236/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5241 - val_loss: 1.0407\n",
            "Epoch 2237/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5241 - val_loss: 1.0421\n",
            "Epoch 2238/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5234 - val_loss: 1.0442\n",
            "Epoch 2239/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5235 - val_loss: 1.0466\n",
            "Epoch 2240/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5239 - val_loss: 1.0428\n",
            "Epoch 2241/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5243 - val_loss: 1.0481\n",
            "Epoch 2242/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5236 - val_loss: 1.0446\n",
            "Epoch 2243/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5236 - val_loss: 1.0455\n",
            "Epoch 2244/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5235 - val_loss: 1.0449\n",
            "Epoch 2245/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5236 - val_loss: 1.0427\n",
            "Epoch 2246/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5239 - val_loss: 1.0458\n",
            "Epoch 2247/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5238 - val_loss: 1.0451\n",
            "Epoch 2248/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5240 - val_loss: 1.0409\n",
            "Epoch 2249/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5237 - val_loss: 1.0454\n",
            "Epoch 2250/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5235 - val_loss: 1.0442\n",
            "Epoch 2251/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5239 - val_loss: 1.0434\n",
            "Epoch 2252/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5245 - val_loss: 1.0424\n",
            "Epoch 2253/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5250 - val_loss: 1.0441\n",
            "Epoch 2254/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5245 - val_loss: 1.0417\n",
            "Epoch 2255/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5254 - val_loss: 1.0480\n",
            "Epoch 2256/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5234 - val_loss: 1.0438\n",
            "Epoch 2257/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5235 - val_loss: 1.0428\n",
            "Epoch 2258/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5242 - val_loss: 1.0477\n",
            "Epoch 2259/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5237 - val_loss: 1.0454\n",
            "Epoch 2260/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5241 - val_loss: 1.0414\n",
            "Epoch 2261/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5249 - val_loss: 1.0478\n",
            "Epoch 2262/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5243 - val_loss: 1.0451\n",
            "Epoch 2263/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5238 - val_loss: 1.0422\n",
            "Epoch 2264/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5238 - val_loss: 1.0429\n",
            "Epoch 2265/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5237 - val_loss: 1.0427\n",
            "Epoch 2266/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5235 - val_loss: 1.0431\n",
            "Epoch 2267/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5235 - val_loss: 1.0466\n",
            "Epoch 2268/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5239 - val_loss: 1.0417\n",
            "Epoch 2269/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5233 - val_loss: 1.0424\n",
            "Epoch 2270/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5235 - val_loss: 1.0466\n",
            "Epoch 2271/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5236 - val_loss: 1.0440\n",
            "Epoch 2272/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5249 - val_loss: 1.0404\n",
            "Epoch 2273/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5238 - val_loss: 1.0448\n",
            "Epoch 2274/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5233 - val_loss: 1.0438\n",
            "Epoch 2275/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5241 - val_loss: 1.0466\n",
            "Epoch 2276/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5247 - val_loss: 1.0438\n",
            "Epoch 2277/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5237 - val_loss: 1.0445\n",
            "Epoch 2278/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5241 - val_loss: 1.0433\n",
            "Epoch 2279/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5239 - val_loss: 1.0483\n",
            "Epoch 2280/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5237 - val_loss: 1.0473\n",
            "Epoch 2281/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5238 - val_loss: 1.0452\n",
            "Epoch 2282/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5246 - val_loss: 1.0435\n",
            "Epoch 2283/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5238 - val_loss: 1.0457\n",
            "Epoch 2284/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5244 - val_loss: 1.0409\n",
            "Epoch 2285/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5234 - val_loss: 1.0434\n",
            "Epoch 2286/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5236 - val_loss: 1.0472\n",
            "Epoch 2287/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5241 - val_loss: 1.0438\n",
            "Epoch 2288/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5238 - val_loss: 1.0482\n",
            "Epoch 2289/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5243 - val_loss: 1.0488\n",
            "Epoch 2290/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5240 - val_loss: 1.0433\n",
            "Epoch 2291/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5245 - val_loss: 1.0392\n",
            "Epoch 2292/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5236 - val_loss: 1.0418\n",
            "Epoch 2293/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5239 - val_loss: 1.0460\n",
            "Epoch 2294/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5233 - val_loss: 1.0461\n",
            "Epoch 2295/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5243 - val_loss: 1.0432\n",
            "Epoch 2296/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5237 - val_loss: 1.0457\n",
            "Epoch 2297/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5238 - val_loss: 1.0427\n",
            "Epoch 2298/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5235 - val_loss: 1.0461\n",
            "Epoch 2299/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5259 - val_loss: 1.0417\n",
            "Epoch 2300/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5242 - val_loss: 1.0439\n",
            "Epoch 2301/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5241 - val_loss: 1.0437\n",
            "Epoch 2302/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5239 - val_loss: 1.0469\n",
            "Epoch 2303/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5242 - val_loss: 1.0474\n",
            "Epoch 2304/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5237 - val_loss: 1.0475\n",
            "Epoch 2305/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5237 - val_loss: 1.0440\n",
            "Epoch 2306/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5235 - val_loss: 1.0423\n",
            "Epoch 2307/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5239 - val_loss: 1.0403\n",
            "Epoch 2308/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5232 - val_loss: 1.0426\n",
            "Epoch 2309/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5234 - val_loss: 1.0441\n",
            "Epoch 2310/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5239 - val_loss: 1.0449\n",
            "Epoch 2311/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5237 - val_loss: 1.0466\n",
            "Epoch 2312/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5234 - val_loss: 1.0479\n",
            "Epoch 2313/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5235 - val_loss: 1.0441\n",
            "Epoch 2314/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5248 - val_loss: 1.0490\n",
            "Epoch 2315/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5238 - val_loss: 1.0430\n",
            "Epoch 2316/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5234 - val_loss: 1.0442\n",
            "Epoch 2317/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5240 - val_loss: 1.0467\n",
            "Epoch 2318/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5237 - val_loss: 1.0435\n",
            "Epoch 2319/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5240 - val_loss: 1.0400\n",
            "Epoch 2320/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5245 - val_loss: 1.0443\n",
            "Epoch 2321/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5239 - val_loss: 1.0407\n",
            "Epoch 2322/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5238 - val_loss: 1.0453\n",
            "Epoch 2323/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5242 - val_loss: 1.0417\n",
            "Epoch 2324/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5238 - val_loss: 1.0486\n",
            "Epoch 2325/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5238 - val_loss: 1.0442\n",
            "Epoch 2326/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5235 - val_loss: 1.0434\n",
            "Epoch 2327/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5237 - val_loss: 1.0450\n",
            "Epoch 2328/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5241 - val_loss: 1.0433\n",
            "Epoch 2329/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5243 - val_loss: 1.0448\n",
            "Epoch 2330/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5244 - val_loss: 1.0471\n",
            "Epoch 2331/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5239 - val_loss: 1.0441\n",
            "Epoch 2332/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5240 - val_loss: 1.0405\n",
            "Epoch 2333/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5239 - val_loss: 1.0458\n",
            "Epoch 2334/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5237 - val_loss: 1.0418\n",
            "Epoch 2335/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5241 - val_loss: 1.0403\n",
            "Epoch 2336/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5238 - val_loss: 1.0450\n",
            "Epoch 2337/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5247 - val_loss: 1.0431\n",
            "Epoch 2338/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5238 - val_loss: 1.0490\n",
            "Epoch 2339/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5247 - val_loss: 1.0411\n",
            "Epoch 2340/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5275 - val_loss: 1.0543\n",
            "Epoch 2341/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5235 - val_loss: 1.0439\n",
            "Epoch 2342/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5240 - val_loss: 1.0413\n",
            "Epoch 2343/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5239 - val_loss: 1.0478\n",
            "Epoch 2344/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5250 - val_loss: 1.0388\n",
            "Epoch 2345/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5239 - val_loss: 1.0412\n",
            "Epoch 2346/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5238 - val_loss: 1.0481\n",
            "Epoch 2347/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5232 - val_loss: 1.0468\n",
            "Epoch 2348/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5234 - val_loss: 1.0441\n",
            "Epoch 2349/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5243 - val_loss: 1.0472\n",
            "Epoch 2350/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5237 - val_loss: 1.0432\n",
            "Epoch 2351/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5233 - val_loss: 1.0437\n",
            "Epoch 2352/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5240 - val_loss: 1.0484\n",
            "Epoch 2353/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5249 - val_loss: 1.0421\n",
            "Epoch 2354/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5235 - val_loss: 1.0423\n",
            "Epoch 2355/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5236 - val_loss: 1.0433\n",
            "Epoch 2356/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5234 - val_loss: 1.0471\n",
            "Epoch 2357/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5234 - val_loss: 1.0456\n",
            "Epoch 2358/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5240 - val_loss: 1.0424\n",
            "Epoch 2359/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5239 - val_loss: 1.0404\n",
            "Epoch 2360/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5237 - val_loss: 1.0430\n",
            "Epoch 2361/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5231 - val_loss: 1.0451\n",
            "Epoch 2362/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5234 - val_loss: 1.0474\n",
            "Epoch 2363/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5237 - val_loss: 1.0449\n",
            "Epoch 2364/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5236 - val_loss: 1.0448\n",
            "Epoch 2365/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5236 - val_loss: 1.0478\n",
            "Epoch 2366/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5237 - val_loss: 1.0445\n",
            "Epoch 2367/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5235 - val_loss: 1.0470\n",
            "Epoch 2368/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5239 - val_loss: 1.0416\n",
            "Epoch 2369/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5240 - val_loss: 1.0434\n",
            "Epoch 2370/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5234 - val_loss: 1.0435\n",
            "Epoch 2371/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5240 - val_loss: 1.0452\n",
            "Epoch 2372/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5240 - val_loss: 1.0422\n",
            "Epoch 2373/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5240 - val_loss: 1.0433\n",
            "Epoch 2374/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5242 - val_loss: 1.0480\n",
            "Epoch 2375/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5241 - val_loss: 1.0423\n",
            "Epoch 2376/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5248 - val_loss: 1.0493\n",
            "Epoch 2377/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5234 - val_loss: 1.0447\n",
            "Epoch 2378/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5242 - val_loss: 1.0429\n",
            "Epoch 2379/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5236 - val_loss: 1.0446\n",
            "Epoch 2380/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5237 - val_loss: 1.0416\n",
            "Epoch 2381/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5234 - val_loss: 1.0431\n",
            "Epoch 2382/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5237 - val_loss: 1.0410\n",
            "Epoch 2383/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5233 - val_loss: 1.0439\n",
            "Epoch 2384/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5234 - val_loss: 1.0459\n",
            "Epoch 2385/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5232 - val_loss: 1.0437\n",
            "Epoch 2386/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5232 - val_loss: 1.0443\n",
            "Epoch 2387/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5234 - val_loss: 1.0450\n",
            "Epoch 2388/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5236 - val_loss: 1.0466\n",
            "Epoch 2389/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5233 - val_loss: 1.0454\n",
            "Epoch 2390/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5236 - val_loss: 1.0451\n",
            "Epoch 2391/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5232 - val_loss: 1.0459\n",
            "Epoch 2392/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5242 - val_loss: 1.0472\n",
            "Epoch 2393/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5236 - val_loss: 1.0446\n",
            "Epoch 2394/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5232 - val_loss: 1.0424\n",
            "Epoch 2395/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5233 - val_loss: 1.0458\n",
            "Epoch 2396/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5240 - val_loss: 1.0469\n",
            "Epoch 2397/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5238 - val_loss: 1.0424\n",
            "Epoch 2398/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5244 - val_loss: 1.0448\n",
            "Epoch 2399/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5240 - val_loss: 1.0442\n",
            "Epoch 2400/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5236 - val_loss: 1.0434\n",
            "Epoch 2401/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5233 - val_loss: 1.0421\n",
            "Epoch 2402/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5240 - val_loss: 1.0463\n",
            "Epoch 2403/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5235 - val_loss: 1.0408\n",
            "Epoch 2404/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5239 - val_loss: 1.0409\n",
            "Epoch 2405/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5239 - val_loss: 1.0473\n",
            "Epoch 2406/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5239 - val_loss: 1.0421\n",
            "Epoch 2407/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5232 - val_loss: 1.0462\n",
            "Epoch 2408/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5251 - val_loss: 1.0512\n",
            "Epoch 2409/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5235 - val_loss: 1.0426\n",
            "Epoch 2410/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5234 - val_loss: 1.0411\n",
            "Epoch 2411/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5234 - val_loss: 1.0425\n",
            "Epoch 2412/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5234 - val_loss: 1.0465\n",
            "Epoch 2413/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5244 - val_loss: 1.0400\n",
            "Epoch 2414/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5245 - val_loss: 1.0492\n",
            "Epoch 2415/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5240 - val_loss: 1.0454\n",
            "Epoch 2416/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5242 - val_loss: 1.0415\n",
            "Epoch 2417/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5234 - val_loss: 1.0450\n",
            "Epoch 2418/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5234 - val_loss: 1.0477\n",
            "Epoch 2419/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5236 - val_loss: 1.0450\n",
            "Epoch 2420/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5235 - val_loss: 1.0434\n",
            "Epoch 2421/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5241 - val_loss: 1.0465\n",
            "Epoch 2422/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5234 - val_loss: 1.0482\n",
            "Epoch 2423/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5243 - val_loss: 1.0398\n",
            "Epoch 2424/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5229 - val_loss: 1.0435\n",
            "Epoch 2425/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5233 - val_loss: 1.0456\n",
            "Epoch 2426/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5236 - val_loss: 1.0435\n",
            "Epoch 2427/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5231 - val_loss: 1.0471\n",
            "Epoch 2428/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5235 - val_loss: 1.0471\n",
            "Epoch 2429/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5233 - val_loss: 1.0459\n",
            "Epoch 2430/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5232 - val_loss: 1.0443\n",
            "Epoch 2431/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5234 - val_loss: 1.0417\n",
            "Epoch 2432/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5238 - val_loss: 1.0452\n",
            "Epoch 2433/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5231 - val_loss: 1.0449\n",
            "Epoch 2434/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5233 - val_loss: 1.0477\n",
            "Epoch 2435/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5243 - val_loss: 1.0420\n",
            "Epoch 2436/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5233 - val_loss: 1.0447\n",
            "Epoch 2437/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5245 - val_loss: 1.0495\n",
            "Epoch 2438/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5234 - val_loss: 1.0485\n",
            "Epoch 2439/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5230 - val_loss: 1.0428\n",
            "Epoch 2440/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5232 - val_loss: 1.0426\n",
            "Epoch 2441/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5242 - val_loss: 1.0492\n",
            "Epoch 2442/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5228 - val_loss: 1.0429\n",
            "Epoch 2443/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5242 - val_loss: 1.0459\n",
            "Epoch 2444/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5235 - val_loss: 1.0415\n",
            "Epoch 2445/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5233 - val_loss: 1.0426\n",
            "Epoch 2446/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5232 - val_loss: 1.0408\n",
            "Epoch 2447/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5230 - val_loss: 1.0430\n",
            "Epoch 2448/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5241 - val_loss: 1.0453\n",
            "Epoch 2449/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5234 - val_loss: 1.0458\n",
            "Epoch 2450/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5235 - val_loss: 1.0429\n",
            "Epoch 2451/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5241 - val_loss: 1.0409\n",
            "Epoch 2452/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5233 - val_loss: 1.0488\n",
            "Epoch 2453/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5232 - val_loss: 1.0473\n",
            "Epoch 2454/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5235 - val_loss: 1.0433\n",
            "Epoch 2455/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5232 - val_loss: 1.0459\n",
            "Epoch 2456/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5233 - val_loss: 1.0429\n",
            "Epoch 2457/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5232 - val_loss: 1.0477\n",
            "Epoch 2458/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5233 - val_loss: 1.0451\n",
            "Epoch 2459/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5235 - val_loss: 1.0435\n",
            "Epoch 2460/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5238 - val_loss: 1.0436\n",
            "Epoch 2461/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5232 - val_loss: 1.0431\n",
            "Epoch 2462/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5231 - val_loss: 1.0457\n",
            "Epoch 2463/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5235 - val_loss: 1.0422\n",
            "Epoch 2464/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5230 - val_loss: 1.0444\n",
            "Epoch 2465/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5232 - val_loss: 1.0461\n",
            "Epoch 2466/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5238 - val_loss: 1.0456\n",
            "Epoch 2467/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5241 - val_loss: 1.0441\n",
            "Epoch 2468/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5239 - val_loss: 1.0480\n",
            "Epoch 2469/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5241 - val_loss: 1.0448\n",
            "Epoch 2470/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5241 - val_loss: 1.0406\n",
            "Epoch 2471/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5231 - val_loss: 1.0450\n",
            "Epoch 2472/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5237 - val_loss: 1.0470\n",
            "Epoch 2473/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5240 - val_loss: 1.0406\n",
            "Epoch 2474/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5239 - val_loss: 1.0456\n",
            "Epoch 2475/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5232 - val_loss: 1.0482\n",
            "Epoch 2476/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5231 - val_loss: 1.0438\n",
            "Epoch 2477/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5233 - val_loss: 1.0416\n",
            "Epoch 2478/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5242 - val_loss: 1.0502\n",
            "Epoch 2479/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5234 - val_loss: 1.0443\n",
            "Epoch 2480/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5239 - val_loss: 1.0484\n",
            "Epoch 2481/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5237 - val_loss: 1.0437\n",
            "Epoch 2482/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5232 - val_loss: 1.0411\n",
            "Epoch 2483/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5234 - val_loss: 1.0460\n",
            "Epoch 2484/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5241 - val_loss: 1.0421\n",
            "Epoch 2485/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5237 - val_loss: 1.0458\n",
            "Epoch 2486/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5233 - val_loss: 1.0423\n",
            "Epoch 2487/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5234 - val_loss: 1.0420\n",
            "Epoch 2488/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5232 - val_loss: 1.0434\n",
            "Epoch 2489/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5233 - val_loss: 1.0431\n",
            "Epoch 2490/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5234 - val_loss: 1.0425\n",
            "Epoch 2491/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5236 - val_loss: 1.0429\n",
            "Epoch 2492/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5237 - val_loss: 1.0449\n",
            "Epoch 2493/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5234 - val_loss: 1.0481\n",
            "Epoch 2494/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5247 - val_loss: 1.0429\n",
            "Epoch 2495/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5230 - val_loss: 1.0442\n",
            "Epoch 2496/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5245 - val_loss: 1.0485\n",
            "Epoch 2497/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5236 - val_loss: 1.0504\n",
            "Epoch 2498/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5238 - val_loss: 1.0468\n",
            "Epoch 2499/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5238 - val_loss: 1.0427\n",
            "Epoch 2500/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5235 - val_loss: 1.0464\n",
            "Epoch 2501/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5236 - val_loss: 1.0448\n",
            "Epoch 2502/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5233 - val_loss: 1.0436\n",
            "Epoch 2503/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5238 - val_loss: 1.0449\n",
            "Epoch 2504/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5239 - val_loss: 1.0425\n",
            "Epoch 2505/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5233 - val_loss: 1.0416\n",
            "Epoch 2506/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5234 - val_loss: 1.0445\n",
            "Epoch 2507/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5235 - val_loss: 1.0446\n",
            "Epoch 2508/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5239 - val_loss: 1.0504\n",
            "Epoch 2509/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5245 - val_loss: 1.0437\n",
            "Epoch 2510/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5231 - val_loss: 1.0436\n",
            "Epoch 2511/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5230 - val_loss: 1.0434\n",
            "Epoch 2512/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5250 - val_loss: 1.0477\n",
            "Epoch 2513/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5234 - val_loss: 1.0469\n",
            "Epoch 2514/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5229 - val_loss: 1.0451\n",
            "Epoch 2515/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5232 - val_loss: 1.0417\n",
            "Epoch 2516/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5232 - val_loss: 1.0414\n",
            "Epoch 2517/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5234 - val_loss: 1.0467\n",
            "Epoch 2518/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5237 - val_loss: 1.0439\n",
            "Epoch 2519/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5234 - val_loss: 1.0426\n",
            "Epoch 2520/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5233 - val_loss: 1.0481\n",
            "Epoch 2521/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5235 - val_loss: 1.0501\n",
            "Epoch 2522/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5232 - val_loss: 1.0411\n",
            "Epoch 2523/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5233 - val_loss: 1.0434\n",
            "Epoch 2524/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5228 - val_loss: 1.0429\n",
            "Epoch 2525/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5239 - val_loss: 1.0462\n",
            "Epoch 2526/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5238 - val_loss: 1.0423\n",
            "Epoch 2527/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5230 - val_loss: 1.0426\n",
            "Epoch 2528/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5236 - val_loss: 1.0456\n",
            "Epoch 2529/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5234 - val_loss: 1.0479\n",
            "Epoch 2530/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5245 - val_loss: 1.0396\n",
            "Epoch 2531/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5241 - val_loss: 1.0472\n",
            "Epoch 2532/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5242 - val_loss: 1.0475\n",
            "Epoch 2533/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5232 - val_loss: 1.0426\n",
            "Epoch 2534/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5240 - val_loss: 1.0488\n",
            "Epoch 2535/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5234 - val_loss: 1.0424\n",
            "Epoch 2536/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5241 - val_loss: 1.0420\n",
            "Epoch 2537/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5238 - val_loss: 1.0394\n",
            "Epoch 2538/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5232 - val_loss: 1.0467\n",
            "Epoch 2539/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5230 - val_loss: 1.0467\n",
            "Epoch 2540/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5236 - val_loss: 1.0475\n",
            "Epoch 2541/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5235 - val_loss: 1.0442\n",
            "Epoch 2542/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5232 - val_loss: 1.0456\n",
            "Epoch 2543/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5231 - val_loss: 1.0425\n",
            "Epoch 2544/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5238 - val_loss: 1.0441\n",
            "Epoch 2545/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5234 - val_loss: 1.0428\n",
            "Epoch 2546/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5231 - val_loss: 1.0494\n",
            "Epoch 2547/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5239 - val_loss: 1.0435\n",
            "Epoch 2548/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5232 - val_loss: 1.0448\n",
            "Epoch 2549/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5232 - val_loss: 1.0470\n",
            "Epoch 2550/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5235 - val_loss: 1.0462\n",
            "Epoch 2551/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5228 - val_loss: 1.0455\n",
            "Epoch 2552/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5236 - val_loss: 1.0453\n",
            "Epoch 2553/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5244 - val_loss: 1.0464\n",
            "Epoch 2554/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5232 - val_loss: 1.0440\n",
            "Epoch 2555/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5239 - val_loss: 1.0405\n",
            "Epoch 2556/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5237 - val_loss: 1.0420\n",
            "Epoch 2557/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5230 - val_loss: 1.0452\n",
            "Epoch 2558/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5231 - val_loss: 1.0473\n",
            "Epoch 2559/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5234 - val_loss: 1.0465\n",
            "Epoch 2560/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5234 - val_loss: 1.0445\n",
            "Epoch 2561/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5230 - val_loss: 1.0449\n",
            "Epoch 2562/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5238 - val_loss: 1.0484\n",
            "Epoch 2563/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5245 - val_loss: 1.0392\n",
            "Epoch 2564/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5238 - val_loss: 1.0444\n",
            "Epoch 2565/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5237 - val_loss: 1.0408\n",
            "Epoch 2566/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5234 - val_loss: 1.0412\n",
            "Epoch 2567/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5231 - val_loss: 1.0445\n",
            "Epoch 2568/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5237 - val_loss: 1.0423\n",
            "Epoch 2569/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5233 - val_loss: 1.0445\n",
            "Epoch 2570/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5227 - val_loss: 1.0447\n",
            "Epoch 2571/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5229 - val_loss: 1.0443\n",
            "Epoch 2572/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5234 - val_loss: 1.0503\n",
            "Epoch 2573/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5228 - val_loss: 1.0466\n",
            "Epoch 2574/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5230 - val_loss: 1.0459\n",
            "Epoch 2575/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5232 - val_loss: 1.0428\n",
            "Epoch 2576/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5227 - val_loss: 1.0438\n",
            "Epoch 2577/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5231 - val_loss: 1.0478\n",
            "Epoch 2578/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5235 - val_loss: 1.0476\n",
            "Epoch 2579/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5246 - val_loss: 1.0500\n",
            "Epoch 2580/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5230 - val_loss: 1.0448\n",
            "Epoch 2581/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5236 - val_loss: 1.0410\n",
            "Epoch 2582/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5235 - val_loss: 1.0413\n",
            "Epoch 2583/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5243 - val_loss: 1.0513\n",
            "Epoch 2584/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5228 - val_loss: 1.0446\n",
            "Epoch 2585/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5239 - val_loss: 1.0402\n",
            "Epoch 2586/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5235 - val_loss: 1.0403\n",
            "Epoch 2587/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5231 - val_loss: 1.0444\n",
            "Epoch 2588/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5231 - val_loss: 1.0475\n",
            "Epoch 2589/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5232 - val_loss: 1.0450\n",
            "Epoch 2590/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5235 - val_loss: 1.0447\n",
            "Epoch 2591/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5232 - val_loss: 1.0447\n",
            "Epoch 2592/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5233 - val_loss: 1.0435\n",
            "Epoch 2593/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5229 - val_loss: 1.0451\n",
            "Epoch 2594/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5233 - val_loss: 1.0427\n",
            "Epoch 2595/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5237 - val_loss: 1.0466\n",
            "Epoch 2596/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5230 - val_loss: 1.0462\n",
            "Epoch 2597/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5229 - val_loss: 1.0446\n",
            "Epoch 2598/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5233 - val_loss: 1.0456\n",
            "Epoch 2599/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5234 - val_loss: 1.0493\n",
            "Epoch 2600/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5231 - val_loss: 1.0476\n",
            "Epoch 2601/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5229 - val_loss: 1.0440\n",
            "Epoch 2602/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5237 - val_loss: 1.0410\n",
            "Epoch 2603/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5231 - val_loss: 1.0449\n",
            "Epoch 2604/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5231 - val_loss: 1.0453\n",
            "Epoch 2605/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5233 - val_loss: 1.0449\n",
            "Epoch 2606/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5231 - val_loss: 1.0435\n",
            "Epoch 2607/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5239 - val_loss: 1.0457\n",
            "Epoch 2608/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5230 - val_loss: 1.0454\n",
            "Epoch 2609/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5236 - val_loss: 1.0496\n",
            "Epoch 2610/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5240 - val_loss: 1.0406\n",
            "Epoch 2611/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5234 - val_loss: 1.0407\n",
            "Epoch 2612/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5229 - val_loss: 1.0449\n",
            "Epoch 2613/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5231 - val_loss: 1.0442\n",
            "Epoch 2614/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5231 - val_loss: 1.0463\n",
            "Epoch 2615/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5233 - val_loss: 1.0423\n",
            "Epoch 2616/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5236 - val_loss: 1.0473\n",
            "Epoch 2617/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5234 - val_loss: 1.0438\n",
            "Epoch 2618/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5233 - val_loss: 1.0490\n",
            "Epoch 2619/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5244 - val_loss: 1.0401\n",
            "Epoch 2620/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5227 - val_loss: 1.0438\n",
            "Epoch 2621/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5243 - val_loss: 1.0443\n",
            "Epoch 2622/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5235 - val_loss: 1.0441\n",
            "Epoch 2623/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5232 - val_loss: 1.0475\n",
            "Epoch 2624/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5231 - val_loss: 1.0486\n",
            "Epoch 2625/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5232 - val_loss: 1.0446\n",
            "Epoch 2626/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5230 - val_loss: 1.0423\n",
            "Epoch 2627/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5230 - val_loss: 1.0460\n",
            "Epoch 2628/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5245 - val_loss: 1.0416\n",
            "Epoch 2629/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5234 - val_loss: 1.0489\n",
            "Epoch 2630/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5230 - val_loss: 1.0491\n",
            "Epoch 2631/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5227 - val_loss: 1.0463\n",
            "Epoch 2632/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5233 - val_loss: 1.0421\n",
            "Epoch 2633/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5229 - val_loss: 1.0460\n",
            "Epoch 2634/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5229 - val_loss: 1.0461\n",
            "Epoch 2635/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5228 - val_loss: 1.0455\n",
            "Epoch 2636/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5231 - val_loss: 1.0470\n",
            "Epoch 2637/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5234 - val_loss: 1.0407\n",
            "Epoch 2638/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5231 - val_loss: 1.0465\n",
            "Epoch 2639/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5228 - val_loss: 1.0467\n",
            "Epoch 2640/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5227 - val_loss: 1.0465\n",
            "Epoch 2641/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5231 - val_loss: 1.0460\n",
            "Epoch 2642/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5229 - val_loss: 1.0447\n",
            "Epoch 2643/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5230 - val_loss: 1.0409\n",
            "Epoch 2644/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5228 - val_loss: 1.0456\n",
            "Epoch 2645/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5233 - val_loss: 1.0407\n",
            "Epoch 2646/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5229 - val_loss: 1.0427\n",
            "Epoch 2647/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5229 - val_loss: 1.0461\n",
            "Epoch 2648/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5230 - val_loss: 1.0430\n",
            "Epoch 2649/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5249 - val_loss: 1.0500\n",
            "Epoch 2650/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5264 - val_loss: 1.0412\n",
            "Epoch 2651/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5231 - val_loss: 1.0466\n",
            "Epoch 2652/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5241 - val_loss: 1.0434\n",
            "Epoch 2653/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5232 - val_loss: 1.0460\n",
            "Epoch 2654/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5239 - val_loss: 1.0506\n",
            "Epoch 2655/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5233 - val_loss: 1.0457\n",
            "Epoch 2656/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5228 - val_loss: 1.0456\n",
            "Epoch 2657/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5234 - val_loss: 1.0454\n",
            "Epoch 2658/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5239 - val_loss: 1.0478\n",
            "Epoch 2659/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5229 - val_loss: 1.0466\n",
            "Epoch 2660/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5227 - val_loss: 1.0471\n",
            "Epoch 2661/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5227 - val_loss: 1.0422\n",
            "Epoch 2662/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5230 - val_loss: 1.0431\n",
            "Epoch 2663/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5230 - val_loss: 1.0446\n",
            "Epoch 2664/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5236 - val_loss: 1.0437\n",
            "Epoch 2665/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5234 - val_loss: 1.0417\n",
            "Epoch 2666/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5234 - val_loss: 1.0498\n",
            "Epoch 2667/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5230 - val_loss: 1.0482\n",
            "Epoch 2668/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5231 - val_loss: 1.0447\n",
            "Epoch 2669/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5233 - val_loss: 1.0434\n",
            "Epoch 2670/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5228 - val_loss: 1.0430\n",
            "Epoch 2671/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5229 - val_loss: 1.0463\n",
            "Epoch 2672/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5229 - val_loss: 1.0450\n",
            "Epoch 2673/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5232 - val_loss: 1.0455\n",
            "Epoch 2674/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5232 - val_loss: 1.0421\n",
            "Epoch 2675/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5231 - val_loss: 1.0470\n",
            "Epoch 2676/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5231 - val_loss: 1.0424\n",
            "Epoch 2677/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5238 - val_loss: 1.0465\n",
            "Epoch 2678/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5231 - val_loss: 1.0449\n",
            "Epoch 2679/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5229 - val_loss: 1.0430\n",
            "Epoch 2680/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5232 - val_loss: 1.0432\n",
            "Epoch 2681/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5234 - val_loss: 1.0423\n",
            "Epoch 2682/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5239 - val_loss: 1.0513\n",
            "Epoch 2683/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5230 - val_loss: 1.0452\n",
            "Epoch 2684/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5231 - val_loss: 1.0428\n",
            "Epoch 2685/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5231 - val_loss: 1.0466\n",
            "Epoch 2686/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5230 - val_loss: 1.0444\n",
            "Epoch 2687/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5238 - val_loss: 1.0470\n",
            "Epoch 2688/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5227 - val_loss: 1.0455\n",
            "Epoch 2689/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5234 - val_loss: 1.0429\n",
            "Epoch 2690/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5234 - val_loss: 1.0484\n",
            "Epoch 2691/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5229 - val_loss: 1.0412\n",
            "Epoch 2692/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5230 - val_loss: 1.0462\n",
            "Epoch 2693/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5231 - val_loss: 1.0437\n",
            "Epoch 2694/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5229 - val_loss: 1.0469\n",
            "Epoch 2695/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5236 - val_loss: 1.0407\n",
            "Epoch 2696/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5234 - val_loss: 1.0455\n",
            "Epoch 2697/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5233 - val_loss: 1.0497\n",
            "Epoch 2698/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5230 - val_loss: 1.0426\n",
            "Epoch 2699/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5228 - val_loss: 1.0430\n",
            "Epoch 2700/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5228 - val_loss: 1.0471\n",
            "Epoch 2701/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5237 - val_loss: 1.0423\n",
            "Epoch 2702/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5229 - val_loss: 1.0482\n",
            "Epoch 2703/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5235 - val_loss: 1.0422\n",
            "Epoch 2704/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5227 - val_loss: 1.0449\n",
            "Epoch 2705/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5230 - val_loss: 1.0470\n",
            "Epoch 2706/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5236 - val_loss: 1.0419\n",
            "Epoch 2707/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5226 - val_loss: 1.0451\n",
            "Epoch 2708/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5230 - val_loss: 1.0423\n",
            "Epoch 2709/5000\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5230 - val_loss: 1.0443\n",
            "Epoch 2710/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5231 - val_loss: 1.0487\n",
            "Epoch 2711/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5233 - val_loss: 1.0472\n",
            "Epoch 2712/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5229 - val_loss: 1.0484\n",
            "Epoch 2713/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5226 - val_loss: 1.0455\n",
            "Epoch 2714/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5233 - val_loss: 1.0454\n",
            "Epoch 2715/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5230 - val_loss: 1.0485\n",
            "Epoch 2716/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5226 - val_loss: 1.0448\n",
            "Epoch 2717/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5231 - val_loss: 1.0459\n",
            "Epoch 2718/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5228 - val_loss: 1.0437\n",
            "Epoch 2719/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5225 - val_loss: 1.0444\n",
            "Epoch 2720/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5232 - val_loss: 1.0456\n",
            "Epoch 2721/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5231 - val_loss: 1.0470\n",
            "Epoch 2722/5000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5232 - val_loss: 1.0460\n",
            "Epoch 2723/5000\n",
            " 1/36 [..............................] - ETA: 0s - loss: 1.5012Restoring model weights from the end of the best epoch: 1723.\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.5226 - val_loss: 1.0464\n",
            "Epoch 2723: early stopping\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 87ms/step - loss: 0.6941\n",
            "EXPECTED:\n",
            "   d18O_cel_mean  d18O_cel_variance\n",
            "0      25.882000           0.233670\n",
            "1      25.654000           0.334480\n",
            "2      27.207456           1.041823\n",
            "3      25.163333           0.807832\n",
            "4      24.030630           0.579233\n",
            "5      26.040923           0.222859\n",
            "\n",
            "PREDICTED:\n",
            "   d18O_cel_mean  d18O_cel_variance\n",
            "0      25.129105           1.809810\n",
            "1      25.098963           1.822455\n",
            "2      25.111458           1.816504\n",
            "3      24.711420           1.989376\n",
            "4      24.711418           1.989376\n",
            "5      24.726463           1.982928\n",
            "RMSE: 1.130164146106385\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2023-07-12 21:44:34.743611: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype double and shape [6,12]\n",
            "\t [[{{node Placeholder/_0}}]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4) Grouped, fixed"
      ],
      "metadata": {
        "id": "opmE3xc0vcY0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "grouped_fixed = {\n",
        "    'TRAIN': os.path.join(FP_ROOT, \"amazon_sample_data/uc_davis_2023_08_12_train_fixed_grouped.csv\"),\n",
        "    'TEST': os.path.join(FP_ROOT, \"amazon_sample_data/uc_davis_2023_08_12_test_fixed_grouped.csv\"),\n",
        "    'VALIDATION': os.path.join(FP_ROOT, \"amazon_sample_data/uc_davis_2023_08_12_validation_fixed_grouped.csv\"),\n",
        "}\n",
        "\n",
        "grouped_fixed_scaled = load_and_scale(grouped_fixed)\n",
        "train_and_evaluate(grouped_fixed_scaled, \"grouped_fixed\", training_batch_size=1)"
      ],
      "metadata": {
        "id": "KCebsA7XvfRH"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}