{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tnc-br/ddf-isoscapes/blob/split_experiments/dnn/variational_split_experiments.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Variational model\n",
        "\n",
        "Find the mean/variance of O18 ratios (as well as N15 and C13 in the future) at a particular lat/lon across Brazil. At the bottom of the colab, train and evaluate 4 different versions of the model with different data partitioning strategies."
      ],
      "metadata": {
        "id": "-0IfT3kGwgK6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "henIPlAPCb4i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04e584e1-177a-412a-8ae2-81820d9952ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2023-07-17 22:54:10.944498: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2023-07-17 22:54:10.978284: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2023-07-17 22:54:10.979019: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-07-17 22:54:11.675639: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        }
      ],
      "source": [
        "from collections import defaultdict\n",
        "import math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import datetime\n",
        "import os\n",
        "from typing import List, Tuple, Dict\n",
        "from dataclasses import dataclass\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, regularizers\n",
        "from matplotlib import pyplot as plt\n",
        "from tensorflow.python.ops import math_ops\n",
        "from sklearn.preprocessing import StandardScaler, Normalizer\n",
        "from sklearn.compose import ColumnTransformer\n",
        "\n",
        "#@title Debugging\n",
        "# See https://zohaib.me/debugging-in-google-collab-notebook/ for tips,\n",
        "# as well as docs for pdb and ipdb.\n",
        "DEBUG = False #@param {type:\"boolean\"}\n",
        "USE_LOCAL_DRIVE = True #@param {type:\"boolean\"}\n",
        "LOCAL_DIR = \"/usr/local/google/home/ruru/Downloads/amazon_sample_data-20230712T203059Z-001\" #@param\n",
        "GDRIVE_DIR = \"MyDrive/amazon_rainforest_files/\" #@param\n",
        "FP_ROOT = LOCAL_DIR\n",
        "\n",
        "def get_model_save_location(filename) -> str:\n",
        "  root = '' if USE_LOCAL_DRIVE else '/content/drive'\n",
        "  return os.path.join(root, GDRIVE_DIR,'variational/model', filename)\n",
        "\n",
        "# Access data stored on Google Drive if not reading data locally.\n",
        "if not USE_LOCAL_DRIVE:\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive')\n",
        "  global FP_ROOT\n",
        "  FP_ROOT = os.path.join('/content/drive', GDRIVE_DIR)\n",
        "\n",
        "if DEBUG:\n",
        "    %pip install -Uqq ipdb\n",
        "    import ipdb\n",
        "    %pdb on"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GQrEv57zCb4q"
      },
      "source": [
        "# Data preparation\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_dataset(path: str):\n",
        "  df = pd.read_csv(path, encoding=\"ISO-8859-1\", sep=',')\n",
        "  df = df[df['d18O_cel_variance'].notna()]\n",
        "\n",
        "  # Family is too sparse. Too many families exist in validation/test that won't\n",
        "  # exist in train, so drop it.\n",
        "  X = df.drop([\"d18O_cel_mean\", \"d18O_cel_variance\", \"Code\", \"Family\", \"Unnamed: 0\"], axis=1)\n",
        "  Y = df[[\"d18O_cel_mean\", \"d18O_cel_variance\"]]\n",
        "  return X, Y"
      ],
      "metadata": {
        "id": "6XMee1aHfcik"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Standardization"
      ],
      "metadata": {
        "id": "DtkKhMOtb6cS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@dataclass\n",
        "class FeaturesToLabels:\n",
        "  def __init__(self, X: pd.DataFrame, Y: pd.DataFrame):\n",
        "    self.X = X\n",
        "    self.Y = Y\n",
        "\n",
        "  def as_tuple(self):\n",
        "    return (self.X, self.Y)\n",
        "\n",
        "\n",
        "def create_feature_scaler(X: pd.DataFrame) -> ColumnTransformer:\n",
        "  columns_to_normalize = ['lat', 'long', 'VPD', 'RH', 'PET', 'DEM', 'PA',\n",
        "       'Mean Annual Temperature', 'Mean Annual Precipitation',\n",
        "       'Iso_Oxi_Stack_mean_TERZER', 'predkrig_br_lat_ISORG',\n",
        "       'isoscape_fullmodel_d18O_prec_REGRESSION']\n",
        "  feature_scaler = ColumnTransformer([\n",
        "      ('feature_normalizer', Normalizer(), columns_to_normalize)],\n",
        "      remainder='passthrough')\n",
        "  feature_scaler.fit(X)\n",
        "  return feature_scaler\n",
        "\n",
        "def create_label_scaler(Y: pd.DataFrame) -> ColumnTransformer:\n",
        "  label_scaler = ColumnTransformer([\n",
        "      ('mean_std_scaler', StandardScaler(), ['d18O_cel_mean']),\n",
        "      ('var_std_scaler', StandardScaler(), ['d18O_cel_variance'])],\n",
        "      remainder='passthrough')\n",
        "  label_scaler.fit(Y)\n",
        "  return label_scaler\n",
        "\n",
        "def scale(X: pd.DataFrame, Y: pd.DataFrame, feature_scaler, label_scaler):\n",
        "  # transform() outputs numpy arrays :(  need to convert back to DataFrame.\n",
        "  X_standardized = pd.DataFrame(feature_scaler.transform(X),\n",
        "                        index=X.index, columns=X.columns)\n",
        "  # Y_standardized = pd.DataFrame(label_scaler.transform(Y),\n",
        "  #                                     index=Y.index, columns=Y.columns)\n",
        "  # FOR NOW, DO NOT SCALE Y.\n",
        "  return FeaturesToLabels(X_standardized, Y)"
      ],
      "metadata": {
        "id": "XSDwdvMkb7w8"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Just a class organization, holds each scaled dataset and the scaler used.\n",
        "# Useful for unscaling predictions.\n",
        "@dataclass\n",
        "class ScaledPartitions():\n",
        "  def __init__(self,\n",
        "               feature_scaler: ColumnTransformer,\n",
        "               label_scaler: ColumnTransformer,\n",
        "               train: FeaturesToLabels, val: FeaturesToLabels,\n",
        "               test: FeaturesToLabels):\n",
        "    self.feature_scaler = feature_scaler\n",
        "    self.label_scaler = label_scaler\n",
        "    self.train = train\n",
        "    self.val = val\n",
        "    self.test = test\n",
        "\n",
        "\n",
        "def load_and_scale(config: Dict) -> ScaledPartitions:\n",
        "  X_train, Y_train = load_dataset(config['TRAIN'])\n",
        "  X_val, Y_val = load_dataset(config['VALIDATION'])\n",
        "  X_test, Y_test = load_dataset(config['TEST'])\n",
        "\n",
        "  feature_scaler = create_feature_scaler(X_train)\n",
        "  label_scaler = create_label_scaler(Y_train)\n",
        "  train = scale(X_train, Y_train, feature_scaler, label_scaler)\n",
        "  val = scale(X_val, Y_val, feature_scaler, label_scaler)\n",
        "  test = scale(X_test, Y_test, feature_scaler, label_scaler)\n",
        "  return ScaledPartitions(feature_scaler, label_scaler, train, val, test)\n"
      ],
      "metadata": {
        "id": "_kf2e_fKon2P"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Definition\n",
        "\n"
      ],
      "metadata": {
        "id": "usGznR593LZc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The KL Loss function:"
      ],
      "metadata": {
        "id": "khK7C8WvU8ZR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# log(σ2/σ1) + ( σ1^2+(μ1−μ2)^2 ) / 2* σ^2   − 1/2\n",
        "def kl_divergence(real, predicted):\n",
        "    real_value = tf.gather(real, [0], axis=1)\n",
        "    real_std = tf.math.sqrt(tf.gather(real, [1], axis=1))\n",
        "\n",
        "    predicted_value = tf.gather(predicted, [0], axis=1)\n",
        "    predicted_std = tf.math.sqrt(tf.gather(predicted, [1], axis=1))\n",
        "\n",
        "    kl_loss = -0.5 + tf.math.log(predicted_std/real_std) + \\\n",
        "     (tf.square(real_std) + tf.square(real_value - predicted_value))/ \\\n",
        "     (2*tf.square(predicted_std))\n",
        "\n",
        "    return tf.math.reduce_mean(kl_loss)"
      ],
      "metadata": {
        "id": "urGjYNNnemX6"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test the loss function:"
      ],
      "metadata": {
        "id": "fJzBFWQVeqNE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pytest\n",
        "\n",
        "test_real = tf.convert_to_tensor(np.array([[1, 0.02]]))\n",
        "test_pred = tf.convert_to_tensor(np.array([[0.98, 0.021]]))\n",
        "\n",
        "# https://screenshot.googleplex.com/5WM9dinAbhR26ZS\n",
        "assert float(kl_divergence(test_real, test_pred)) == pytest.approx(0.0101094, 1e-5)\n",
        "\n",
        "test_neg_real = tf.convert_to_tensor(np.array([[32.32, 0.0344]]))\n",
        "test_neg_pred = tf.convert_to_tensor(np.array([[32.01, -0.322]]))\n",
        "\n",
        "# Negative variance causes NaN\n",
        "assert tf.math.is_nan(kl_divergence(test_neg_real, test_neg_pred))\n",
        "\n",
        "# Calculated manually by computing the result of this equation in wolfram alpha:\n",
        "# log(σ2/σ1) + ( σ1^2+(μ1−μ2)^2 ) / 2* σ^2   − 1/2\n",
        "test_real_2d = tf.convert_to_tensor(np.array(\n",
        "    [[1.00, 0.020],\n",
        "     [1.01, 0.042]]))\n",
        "test_pred_2d = tf.convert_to_tensor(np.array(\n",
        "    [[0.98, 0.021],\n",
        "     [0.99, 0.012]]))\n",
        "\n",
        "# Should reduce to the average loss of all rows.\n",
        "assert float(kl_divergence(test_real_2d, test_pred_2d)) == pytest.approx(\n",
        "    sum([0.0101094, 0.6402851])/2, 1e-5)"
      ],
      "metadata": {
        "id": "48TaPd70erSk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model definition"
      ],
      "metadata": {
        "id": "8rI6qPRh7oO7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "\n",
        "def get_early_stopping_callback():\n",
        "  return EarlyStopping(monitor='val_loss', patience=100, min_delta=0.001,\n",
        "                       verbose=1, restore_best_weights=True, start_from_epoch=0)\n",
        "\n",
        "tf.keras.utils.set_random_seed(18731)\n",
        "\n",
        "# I was experimenting with models that took longer to train, and used this\n",
        "# checkpointing callback to periodically save the model. It's optional.\n",
        "def get_checkpoint_callback(model_file):\n",
        "  return ModelCheckpoint(\n",
        "      get_model_save_location(model_file),\n",
        "      monitor='val_loss', verbose=0, save_best_only=True, mode='min')\n",
        "\n",
        "def train_or_update_variational_model(\n",
        "        sp: ScaledPartitions,\n",
        "        hidden_layers: List[int],\n",
        "        epochs: int,\n",
        "        batch_size: int,\n",
        "        lr: float,\n",
        "        model_file=None,\n",
        "        use_checkpoint=False):\n",
        "  callbacks_list = [get_early_stopping_callback(),\n",
        "                    get_checkpoint_callback(model_file)]\n",
        "  if not use_checkpoint:\n",
        "    inputs = keras.Input(shape=(sp.train.X.shape[1],))\n",
        "    x = inputs\n",
        "    for layer_size in hidden_layers:\n",
        "      x = keras.layers.Dense(\n",
        "          layer_size, activation='relu')(x)\n",
        "    mean_output = keras.layers.Dense(1, name='mean_output')(x)\n",
        "\n",
        "    # We can not have negative variance. Apply very little variance.\n",
        "    var_output = keras.layers.Dense(1, name='var_output')(x)\n",
        "\n",
        "    # Invert the normalization on our outputs\n",
        "    mean_scaler = sp.label_scaler.named_transformers_['mean_std_scaler']\n",
        "    untransformed_mean = mean_output * mean_scaler.var_ + mean_scaler.mean_\n",
        "\n",
        "    var_scaler = sp.label_scaler.named_transformers_['var_std_scaler']\n",
        "    untransformed_var = var_output * var_scaler.var_ + var_scaler.mean_\n",
        "\n",
        "    untransformed_abs_var = keras.layers.Lambda(lambda t: tf.abs(t))(untransformed_var)\n",
        "\n",
        "    # Output mean, |variance| tuples.\n",
        "    outputs = keras.layers.concatenate([untransformed_mean, untransformed_abs_var])\n",
        "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "    # Later epochs seem to benefit from lower learning rate... but it takes\n",
        "    # a while to get there.\n",
        "    decay = keras.optimizers.schedules.ExponentialDecay(\n",
        "       lr, decay_steps=100, decay_rate=0.5, staircase=True)\n",
        "\n",
        "    optimizer = keras.optimizers.Adam(learning_rate=lr)\n",
        "    model.compile(optimizer=optimizer, loss=kl_divergence)\n",
        "    model.summary()\n",
        "  else:\n",
        "    model = keras.models.load_model(\n",
        "        get_model_save_location(model_file),\n",
        "        custom_objects={\"kl_divergence\": kl_divergence})\n",
        "  history = model.fit(sp.train.X, sp.train.Y, verbose=1, epochs=epochs, batch_size=batch_size,\n",
        "                      validation_data=sp.val.as_tuple(),\n",
        "                      shuffle=True, callbacks=callbacks_list)\n",
        "  return history, model"
      ],
      "metadata": {
        "id": "HCkGSPUo3KqY"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "def render_plot_loss(history, name):\n",
        "  plt.plot(history.history['loss'])\n",
        "  plt.plot(history.history['val_loss'])\n",
        "  plt.title(name + ' model loss')\n",
        "  plt.ylabel('loss')\n",
        "  plt.yscale(\"log\")\n",
        "  plt.xlabel('epoch')\n",
        "  plt.legend(['loss', 'val_loss'], loc='upper left')\n",
        "  plt.show()\n",
        "\n",
        "def destandardize(sd: ScaledPartitions, df: pd.DataFrame):\n",
        "  means = pd.DataFrame(\n",
        "      sd.label_scaler.named_transformers_['var_std_scaler'].inverse_transform(df[['d18O_cel_mean']]),\n",
        "      index=df.index, columns=['d18O_cel_mean'])\n",
        "  vars = df['d18O_cel_variance']\n",
        "  return means.join(vars)\n",
        "\n",
        "def train_and_evaluate(sp: ScaledPartitions, run_id: str, training_batch_size=5):\n",
        "  print(\"==================\")\n",
        "  print(run_id)\n",
        "  history, model = train_or_update_variational_model(\n",
        "      sp, hidden_layers=[20, 20], epochs=5000, batch_size=training_batch_size,\n",
        "      lr=0.0001, model_file=run_id+\".h5\", use_checkpoint=False)\n",
        "  render_plot_loss(history, run_id+\" kl_loss\")\n",
        "  model.save(get_model_save_location(run_id+\".h5\"), save_format=\"h5\")\n",
        "\n",
        "  model.evaluate(x=sp.test.X, y=sp.test.Y)\n",
        "  predictions = model.predict_on_batch(sp.test.X)\n",
        "  print(\"EXPECTED:\")\n",
        "  print(sp.test.Y.to_string())\n",
        "  print()\n",
        "  print(\"PREDICTED:\")\n",
        "  predictions = pd.DataFrame(predictions, columns=['d18O_cel_mean', 'd18O_cel_variance'])\n",
        "  print(predictions.to_string())\n",
        "\n",
        "  rmse = np.sqrt(mean_squared_error(sp.test.Y['d18O_cel_mean'], predictions['d18O_cel_mean']))\n",
        "  print(\"RMSE: \"+ str(rmse))"
      ],
      "metadata": {
        "id": "DALuUm8UOgNu"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load and evaluate the model with each set of data.\n",
        "\n",
        "Use the same model configured the same way for every run, with the exception of the training batch size setting, which is 1 for grouped and 5 for ungrouped."
      ],
      "metadata": {
        "id": "WF_1T_zZtK0T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1) Ungrouped, random"
      ],
      "metadata": {
        "id": "q6vAjessuMSM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ungrouped_random = {\n",
        "    'TRAIN' : os.path.join(FP_ROOT, \"amazon_sample_data/uc_davis_2023_08_12_train_random_ungrouped.csv\"),\n",
        "    'TEST' : os.path.join(FP_ROOT, \"amazon_sample_data/uc_davis_2023_08_12_test_random_ungrouped.csv\"),\n",
        "    'VALIDATION' : os.path.join(FP_ROOT, \"amazon_sample_data/uc_davis_2023_08_12_validation_random_ungrouped.csv\"),\n",
        "}\n",
        "\n",
        "ungrouped_random_scaled = load_and_scale(ungrouped_random)\n",
        "train_and_evaluate(ungrouped_random_scaled, \"ungrouped_random\", training_batch_size=3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "qM5zP9M9tQqE",
        "outputId": "497bef82-7ac7-4f33-8f18-62347630fd08"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================\n",
            "ungrouped_random\n",
            "Model: \"model_11\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_12 (InputLayer)          [(None, 12)]         0           []                               \n",
            "                                                                                                  \n",
            " dense_22 (Dense)               (None, 20)           260         ['input_12[0][0]']               \n",
            "                                                                                                  \n",
            " dense_23 (Dense)               (None, 20)           420         ['dense_22[0][0]']               \n",
            "                                                                                                  \n",
            " var_output (Dense)             (None, 1)            21          ['dense_23[0][0]']               \n",
            "                                                                                                  \n",
            " mean_output (Dense)            (None, 1)            21          ['dense_23[0][0]']               \n",
            "                                                                                                  \n",
            " tf.math.multiply_23 (TFOpLambd  (None, 1)           0           ['var_output[0][0]']             \n",
            " a)                                                                                               \n",
            "                                                                                                  \n",
            " tf.math.multiply_22 (TFOpLambd  (None, 1)           0           ['mean_output[0][0]']            \n",
            " a)                                                                                               \n",
            "                                                                                                  \n",
            " tf.__operators__.add_23 (TFOpL  (None, 1)           0           ['tf.math.multiply_23[0][0]']    \n",
            " ambda)                                                                                           \n",
            "                                                                                                  \n",
            " tf.__operators__.add_22 (TFOpL  (None, 1)           0           ['tf.math.multiply_22[0][0]']    \n",
            " ambda)                                                                                           \n",
            "                                                                                                  \n",
            " lambda_11 (Lambda)             (None, 1)            0           ['tf.__operators__.add_23[0][0]']\n",
            "                                                                                                  \n",
            " concatenate_11 (Concatenate)   (None, 2)            0           ['tf.__operators__.add_22[0][0]',\n",
            "                                                                  'lambda_11[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 722\n",
            "Trainable params: 722\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/5000\n",
            "165/165 [==============================] - 1s 2ms/step - loss: 0.4978 - val_loss: 0.6135\n",
            "Epoch 2/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4715 - val_loss: 0.6030\n",
            "Epoch 3/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4634 - val_loss: 0.5984\n",
            "Epoch 4/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4604 - val_loss: 0.5979\n",
            "Epoch 5/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4592 - val_loss: 0.5970\n",
            "Epoch 6/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4586 - val_loss: 0.5956\n",
            "Epoch 7/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4582 - val_loss: 0.5935\n",
            "Epoch 8/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4581 - val_loss: 0.5905\n",
            "Epoch 9/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4581 - val_loss: 0.5901\n",
            "Epoch 10/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4578 - val_loss: 0.5898\n",
            "Epoch 11/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4576 - val_loss: 0.5881\n",
            "Epoch 12/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4574 - val_loss: 0.5880\n",
            "Epoch 13/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4574 - val_loss: 0.5870\n",
            "Epoch 14/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4574 - val_loss: 0.5851\n",
            "Epoch 15/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4570 - val_loss: 0.5851\n",
            "Epoch 16/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4568 - val_loss: 0.5854\n",
            "Epoch 17/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4567 - val_loss: 0.5851\n",
            "Epoch 18/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4566 - val_loss: 0.5818\n",
            "Epoch 19/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4563 - val_loss: 0.5825\n",
            "Epoch 20/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4563 - val_loss: 0.5833\n",
            "Epoch 21/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4561 - val_loss: 0.5843\n",
            "Epoch 22/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4560 - val_loss: 0.5821\n",
            "Epoch 23/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4558 - val_loss: 0.5792\n",
            "Epoch 24/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4557 - val_loss: 0.5784\n",
            "Epoch 25/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4556 - val_loss: 0.5788\n",
            "Epoch 26/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4554 - val_loss: 0.5815\n",
            "Epoch 27/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4552 - val_loss: 0.5786\n",
            "Epoch 28/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4551 - val_loss: 0.5811\n",
            "Epoch 29/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4549 - val_loss: 0.5779\n",
            "Epoch 30/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4548 - val_loss: 0.5785\n",
            "Epoch 31/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4546 - val_loss: 0.5741\n",
            "Epoch 32/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4545 - val_loss: 0.5743\n",
            "Epoch 33/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4543 - val_loss: 0.5725\n",
            "Epoch 34/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4542 - val_loss: 0.5727\n",
            "Epoch 35/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4542 - val_loss: 0.5712\n",
            "Epoch 36/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4539 - val_loss: 0.5709\n",
            "Epoch 37/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4536 - val_loss: 0.5704\n",
            "Epoch 38/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4536 - val_loss: 0.5718\n",
            "Epoch 39/5000\n",
            "165/165 [==============================] - 0s 987us/step - loss: 0.4535 - val_loss: 0.5723\n",
            "Epoch 40/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4532 - val_loss: 0.5691\n",
            "Epoch 41/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4531 - val_loss: 0.5680\n",
            "Epoch 42/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4529 - val_loss: 0.5669\n",
            "Epoch 43/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4526 - val_loss: 0.5662\n",
            "Epoch 44/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4526 - val_loss: 0.5686\n",
            "Epoch 45/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4523 - val_loss: 0.5643\n",
            "Epoch 46/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4521 - val_loss: 0.5647\n",
            "Epoch 47/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4519 - val_loss: 0.5640\n",
            "Epoch 48/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4520 - val_loss: 0.5647\n",
            "Epoch 49/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4517 - val_loss: 0.5646\n",
            "Epoch 50/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4514 - val_loss: 0.5595\n",
            "Epoch 51/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4513 - val_loss: 0.5596\n",
            "Epoch 52/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4514 - val_loss: 0.5580\n",
            "Epoch 53/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4509 - val_loss: 0.5585\n",
            "Epoch 54/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4508 - val_loss: 0.5586\n",
            "Epoch 55/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4506 - val_loss: 0.5575\n",
            "Epoch 56/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4505 - val_loss: 0.5562\n",
            "Epoch 57/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4502 - val_loss: 0.5543\n",
            "Epoch 58/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4501 - val_loss: 0.5512\n",
            "Epoch 59/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4498 - val_loss: 0.5511\n",
            "Epoch 60/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4495 - val_loss: 0.5526\n",
            "Epoch 61/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4494 - val_loss: 0.5531\n",
            "Epoch 62/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4494 - val_loss: 0.5543\n",
            "Epoch 63/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4490 - val_loss: 0.5498\n",
            "Epoch 64/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4488 - val_loss: 0.5454\n",
            "Epoch 65/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4487 - val_loss: 0.5483\n",
            "Epoch 66/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4485 - val_loss: 0.5501\n",
            "Epoch 67/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4481 - val_loss: 0.5447\n",
            "Epoch 68/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4480 - val_loss: 0.5430\n",
            "Epoch 69/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4478 - val_loss: 0.5414\n",
            "Epoch 70/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4475 - val_loss: 0.5410\n",
            "Epoch 71/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4475 - val_loss: 0.5405\n",
            "Epoch 72/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4472 - val_loss: 0.5455\n",
            "Epoch 73/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4471 - val_loss: 0.5426\n",
            "Epoch 74/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4467 - val_loss: 0.5388\n",
            "Epoch 75/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4465 - val_loss: 0.5339\n",
            "Epoch 76/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4463 - val_loss: 0.5371\n",
            "Epoch 77/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4461 - val_loss: 0.5386\n",
            "Epoch 78/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4461 - val_loss: 0.5314\n",
            "Epoch 79/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4457 - val_loss: 0.5316\n",
            "Epoch 80/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4457 - val_loss: 0.5304\n",
            "Epoch 81/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4452 - val_loss: 0.5285\n",
            "Epoch 82/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4452 - val_loss: 0.5289\n",
            "Epoch 83/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4447 - val_loss: 0.5290\n",
            "Epoch 84/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4444 - val_loss: 0.5306\n",
            "Epoch 85/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4445 - val_loss: 0.5273\n",
            "Epoch 86/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4443 - val_loss: 0.5269\n",
            "Epoch 87/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4438 - val_loss: 0.5235\n",
            "Epoch 88/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4437 - val_loss: 0.5230\n",
            "Epoch 89/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4433 - val_loss: 0.5250\n",
            "Epoch 90/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4432 - val_loss: 0.5202\n",
            "Epoch 91/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4427 - val_loss: 0.5199\n",
            "Epoch 92/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4427 - val_loss: 0.5150\n",
            "Epoch 93/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4425 - val_loss: 0.5192\n",
            "Epoch 94/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4420 - val_loss: 0.5131\n",
            "Epoch 95/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4418 - val_loss: 0.5091\n",
            "Epoch 96/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4417 - val_loss: 0.5116\n",
            "Epoch 97/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4414 - val_loss: 0.5151\n",
            "Epoch 98/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4412 - val_loss: 0.5131\n",
            "Epoch 99/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4408 - val_loss: 0.5038\n",
            "Epoch 100/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4409 - val_loss: 0.5070\n",
            "Epoch 101/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4404 - val_loss: 0.5033\n",
            "Epoch 102/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4401 - val_loss: 0.5093\n",
            "Epoch 103/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4398 - val_loss: 0.5044\n",
            "Epoch 104/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4397 - val_loss: 0.5057\n",
            "Epoch 105/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4393 - val_loss: 0.4940\n",
            "Epoch 106/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4394 - val_loss: 0.4977\n",
            "Epoch 107/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4387 - val_loss: 0.4951\n",
            "Epoch 108/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4387 - val_loss: 0.4965\n",
            "Epoch 109/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4384 - val_loss: 0.4954\n",
            "Epoch 110/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4381 - val_loss: 0.4932\n",
            "Epoch 111/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4378 - val_loss: 0.4921\n",
            "Epoch 112/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4376 - val_loss: 0.4931\n",
            "Epoch 113/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4372 - val_loss: 0.4938\n",
            "Epoch 114/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4371 - val_loss: 0.4869\n",
            "Epoch 115/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4367 - val_loss: 0.4826\n",
            "Epoch 116/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4365 - val_loss: 0.4856\n",
            "Epoch 117/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4365 - val_loss: 0.4839\n",
            "Epoch 118/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4360 - val_loss: 0.4750\n",
            "Epoch 119/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4359 - val_loss: 0.4809\n",
            "Epoch 120/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4356 - val_loss: 0.4774\n",
            "Epoch 121/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4356 - val_loss: 0.4808\n",
            "Epoch 122/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4353 - val_loss: 0.4832\n",
            "Epoch 123/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4348 - val_loss: 0.4782\n",
            "Epoch 124/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4346 - val_loss: 0.4774\n",
            "Epoch 125/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4342 - val_loss: 0.4754\n",
            "Epoch 126/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4340 - val_loss: 0.4761\n",
            "Epoch 127/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4338 - val_loss: 0.4727\n",
            "Epoch 128/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4336 - val_loss: 0.4696\n",
            "Epoch 129/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4334 - val_loss: 0.4646\n",
            "Epoch 130/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4332 - val_loss: 0.4612\n",
            "Epoch 131/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4328 - val_loss: 0.4655\n",
            "Epoch 132/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4326 - val_loss: 0.4691\n",
            "Epoch 133/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4327 - val_loss: 0.4622\n",
            "Epoch 134/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4321 - val_loss: 0.4618\n",
            "Epoch 135/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4320 - val_loss: 0.4589\n",
            "Epoch 136/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4317 - val_loss: 0.4605\n",
            "Epoch 137/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4315 - val_loss: 0.4569\n",
            "Epoch 138/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4312 - val_loss: 0.4511\n",
            "Epoch 139/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4310 - val_loss: 0.4523\n",
            "Epoch 140/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4311 - val_loss: 0.4565\n",
            "Epoch 141/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4303 - val_loss: 0.4552\n",
            "Epoch 142/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4306 - val_loss: 0.4480\n",
            "Epoch 143/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4307 - val_loss: 0.4503\n",
            "Epoch 144/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4301 - val_loss: 0.4510\n",
            "Epoch 145/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4298 - val_loss: 0.4443\n",
            "Epoch 146/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4295 - val_loss: 0.4436\n",
            "Epoch 147/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4297 - val_loss: 0.4489\n",
            "Epoch 148/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4290 - val_loss: 0.4387\n",
            "Epoch 149/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4289 - val_loss: 0.4367\n",
            "Epoch 150/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4287 - val_loss: 0.4418\n",
            "Epoch 151/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4286 - val_loss: 0.4338\n",
            "Epoch 152/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4283 - val_loss: 0.4388\n",
            "Epoch 153/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4281 - val_loss: 0.4413\n",
            "Epoch 154/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4279 - val_loss: 0.4353\n",
            "Epoch 155/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4276 - val_loss: 0.4298\n",
            "Epoch 156/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4277 - val_loss: 0.4344\n",
            "Epoch 157/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4271 - val_loss: 0.4312\n",
            "Epoch 158/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4271 - val_loss: 0.4231\n",
            "Epoch 159/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4270 - val_loss: 0.4296\n",
            "Epoch 160/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4270 - val_loss: 0.4303\n",
            "Epoch 161/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4264 - val_loss: 0.4272\n",
            "Epoch 162/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4264 - val_loss: 0.4219\n",
            "Epoch 163/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4261 - val_loss: 0.4199\n",
            "Epoch 164/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4261 - val_loss: 0.4245\n",
            "Epoch 165/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4258 - val_loss: 0.4253\n",
            "Epoch 166/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4257 - val_loss: 0.4228\n",
            "Epoch 167/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4253 - val_loss: 0.4193\n",
            "Epoch 168/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4252 - val_loss: 0.4202\n",
            "Epoch 169/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4251 - val_loss: 0.4177\n",
            "Epoch 170/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4252 - val_loss: 0.4073\n",
            "Epoch 171/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4249 - val_loss: 0.4149\n",
            "Epoch 172/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4249 - val_loss: 0.4163\n",
            "Epoch 173/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4246 - val_loss: 0.4053\n",
            "Epoch 174/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4245 - val_loss: 0.4082\n",
            "Epoch 175/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4241 - val_loss: 0.4118\n",
            "Epoch 176/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4242 - val_loss: 0.4134\n",
            "Epoch 177/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4239 - val_loss: 0.4090\n",
            "Epoch 178/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4237 - val_loss: 0.4043\n",
            "Epoch 179/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4238 - val_loss: 0.4109\n",
            "Epoch 180/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4236 - val_loss: 0.4117\n",
            "Epoch 181/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4234 - val_loss: 0.4059\n",
            "Epoch 182/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4232 - val_loss: 0.4032\n",
            "Epoch 183/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4231 - val_loss: 0.4021\n",
            "Epoch 184/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4229 - val_loss: 0.3977\n",
            "Epoch 185/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4229 - val_loss: 0.3943\n",
            "Epoch 186/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4226 - val_loss: 0.4010\n",
            "Epoch 187/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4226 - val_loss: 0.3957\n",
            "Epoch 188/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4224 - val_loss: 0.3915\n",
            "Epoch 189/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4222 - val_loss: 0.3852\n",
            "Epoch 190/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4225 - val_loss: 0.3916\n",
            "Epoch 191/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4223 - val_loss: 0.3940\n",
            "Epoch 192/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4219 - val_loss: 0.3976\n",
            "Epoch 193/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4218 - val_loss: 0.3908\n",
            "Epoch 194/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4219 - val_loss: 0.3950\n",
            "Epoch 195/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4216 - val_loss: 0.3921\n",
            "Epoch 196/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4218 - val_loss: 0.3892\n",
            "Epoch 197/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4218 - val_loss: 0.3906\n",
            "Epoch 198/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4213 - val_loss: 0.3850\n",
            "Epoch 199/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4213 - val_loss: 0.3834\n",
            "Epoch 200/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4213 - val_loss: 0.3837\n",
            "Epoch 201/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4209 - val_loss: 0.3887\n",
            "Epoch 202/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4209 - val_loss: 0.3851\n",
            "Epoch 203/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4211 - val_loss: 0.3862\n",
            "Epoch 204/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4206 - val_loss: 0.3867\n",
            "Epoch 205/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4204 - val_loss: 0.3832\n",
            "Epoch 206/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4203 - val_loss: 0.3920\n",
            "Epoch 207/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4206 - val_loss: 0.3832\n",
            "Epoch 208/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4204 - val_loss: 0.3869\n",
            "Epoch 209/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4204 - val_loss: 0.3768\n",
            "Epoch 210/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4201 - val_loss: 0.3889\n",
            "Epoch 211/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4201 - val_loss: 0.3756\n",
            "Epoch 212/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4202 - val_loss: 0.3781\n",
            "Epoch 213/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4200 - val_loss: 0.3797\n",
            "Epoch 214/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4198 - val_loss: 0.3839\n",
            "Epoch 215/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4202 - val_loss: 0.3811\n",
            "Epoch 216/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4199 - val_loss: 0.3762\n",
            "Epoch 217/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4200 - val_loss: 0.3722\n",
            "Epoch 218/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4197 - val_loss: 0.3737\n",
            "Epoch 219/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4195 - val_loss: 0.3729\n",
            "Epoch 220/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4194 - val_loss: 0.3816\n",
            "Epoch 221/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4198 - val_loss: 0.3749\n",
            "Epoch 222/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4191 - val_loss: 0.3685\n",
            "Epoch 223/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4191 - val_loss: 0.3735\n",
            "Epoch 224/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4190 - val_loss: 0.3779\n",
            "Epoch 225/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4187 - val_loss: 0.3674\n",
            "Epoch 226/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4189 - val_loss: 0.3694\n",
            "Epoch 227/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4191 - val_loss: 0.3684\n",
            "Epoch 228/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4190 - val_loss: 0.3635\n",
            "Epoch 229/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4186 - val_loss: 0.3668\n",
            "Epoch 230/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4185 - val_loss: 0.3760\n",
            "Epoch 231/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4186 - val_loss: 0.3722\n",
            "Epoch 232/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4185 - val_loss: 0.3680\n",
            "Epoch 233/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4184 - val_loss: 0.3706\n",
            "Epoch 234/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4185 - val_loss: 0.3658\n",
            "Epoch 235/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4183 - val_loss: 0.3674\n",
            "Epoch 236/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4186 - val_loss: 0.3657\n",
            "Epoch 237/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4184 - val_loss: 0.3669\n",
            "Epoch 238/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4180 - val_loss: 0.3650\n",
            "Epoch 239/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4181 - val_loss: 0.3674\n",
            "Epoch 240/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4185 - val_loss: 0.3608\n",
            "Epoch 241/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4183 - val_loss: 0.3647\n",
            "Epoch 242/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4183 - val_loss: 0.3680\n",
            "Epoch 243/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4180 - val_loss: 0.3674\n",
            "Epoch 244/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4178 - val_loss: 0.3651\n",
            "Epoch 245/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4178 - val_loss: 0.3604\n",
            "Epoch 246/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4177 - val_loss: 0.3667\n",
            "Epoch 247/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4183 - val_loss: 0.3653\n",
            "Epoch 248/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4179 - val_loss: 0.3648\n",
            "Epoch 249/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4176 - val_loss: 0.3707\n",
            "Epoch 250/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4174 - val_loss: 0.3700\n",
            "Epoch 251/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4167 - val_loss: 0.3742\n",
            "Epoch 252/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4174 - val_loss: 0.3706\n",
            "Epoch 253/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4167 - val_loss: 0.3670\n",
            "Epoch 254/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4167 - val_loss: 0.3643\n",
            "Epoch 255/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4174 - val_loss: 0.3661\n",
            "Epoch 256/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4166 - val_loss: 0.3678\n",
            "Epoch 257/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4167 - val_loss: 0.3659\n",
            "Epoch 258/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4165 - val_loss: 0.3673\n",
            "Epoch 259/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4162 - val_loss: 0.3684\n",
            "Epoch 260/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4163 - val_loss: 0.3666\n",
            "Epoch 261/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4163 - val_loss: 0.3702\n",
            "Epoch 262/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4160 - val_loss: 0.3709\n",
            "Epoch 263/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4159 - val_loss: 0.3628\n",
            "Epoch 264/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4157 - val_loss: 0.3682\n",
            "Epoch 265/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4162 - val_loss: 0.3688\n",
            "Epoch 266/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4154 - val_loss: 0.3677\n",
            "Epoch 267/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4154 - val_loss: 0.3710\n",
            "Epoch 268/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4153 - val_loss: 0.3685\n",
            "Epoch 269/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4152 - val_loss: 0.3671\n",
            "Epoch 270/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4153 - val_loss: 0.3654\n",
            "Epoch 271/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4154 - val_loss: 0.3674\n",
            "Epoch 272/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4151 - val_loss: 0.3732\n",
            "Epoch 273/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4150 - val_loss: 0.3686\n",
            "Epoch 274/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4148 - val_loss: 0.3670\n",
            "Epoch 275/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4147 - val_loss: 0.3676\n",
            "Epoch 276/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4146 - val_loss: 0.3637\n",
            "Epoch 277/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4147 - val_loss: 0.3676\n",
            "Epoch 278/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4147 - val_loss: 0.3691\n",
            "Epoch 279/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4148 - val_loss: 0.3651\n",
            "Epoch 280/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4145 - val_loss: 0.3658\n",
            "Epoch 281/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4140 - val_loss: 0.3700\n",
            "Epoch 282/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4140 - val_loss: 0.3676\n",
            "Epoch 283/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4140 - val_loss: 0.3699\n",
            "Epoch 284/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4144 - val_loss: 0.3689\n",
            "Epoch 285/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4139 - val_loss: 0.3645\n",
            "Epoch 286/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4139 - val_loss: 0.3654\n",
            "Epoch 287/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4139 - val_loss: 0.3613\n",
            "Epoch 288/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4138 - val_loss: 0.3612\n",
            "Epoch 289/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4138 - val_loss: 0.3659\n",
            "Epoch 290/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4134 - val_loss: 0.3596\n",
            "Epoch 291/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4138 - val_loss: 0.3641\n",
            "Epoch 292/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4133 - val_loss: 0.3706\n",
            "Epoch 293/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4131 - val_loss: 0.3589\n",
            "Epoch 294/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4135 - val_loss: 0.3592\n",
            "Epoch 295/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4133 - val_loss: 0.3645\n",
            "Epoch 296/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4133 - val_loss: 0.3632\n",
            "Epoch 297/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4131 - val_loss: 0.3623\n",
            "Epoch 298/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4130 - val_loss: 0.3629\n",
            "Epoch 299/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4133 - val_loss: 0.3598\n",
            "Epoch 300/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4129 - val_loss: 0.3556\n",
            "Epoch 301/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4125 - val_loss: 0.3669\n",
            "Epoch 302/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4131 - val_loss: 0.3589\n",
            "Epoch 303/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4132 - val_loss: 0.3603\n",
            "Epoch 304/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4134 - val_loss: 0.3617\n",
            "Epoch 305/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4121 - val_loss: 0.3547\n",
            "Epoch 306/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4125 - val_loss: 0.3574\n",
            "Epoch 307/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4124 - val_loss: 0.3605\n",
            "Epoch 308/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4121 - val_loss: 0.3585\n",
            "Epoch 309/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4119 - val_loss: 0.3643\n",
            "Epoch 310/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4115 - val_loss: 0.3616\n",
            "Epoch 311/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4114 - val_loss: 0.3588\n",
            "Epoch 312/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4113 - val_loss: 0.3615\n",
            "Epoch 313/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4118 - val_loss: 0.3666\n",
            "Epoch 314/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4108 - val_loss: 0.3639\n",
            "Epoch 315/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4105 - val_loss: 0.3724\n",
            "Epoch 316/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4109 - val_loss: 0.3663\n",
            "Epoch 317/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4109 - val_loss: 0.3626\n",
            "Epoch 318/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4102 - val_loss: 0.3760\n",
            "Epoch 319/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4115 - val_loss: 0.3640\n",
            "Epoch 320/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4112 - val_loss: 0.3657\n",
            "Epoch 321/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4106 - val_loss: 0.3694\n",
            "Epoch 322/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4102 - val_loss: 0.3658\n",
            "Epoch 323/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4105 - val_loss: 0.3647\n",
            "Epoch 324/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4105 - val_loss: 0.3623\n",
            "Epoch 325/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4102 - val_loss: 0.3603\n",
            "Epoch 326/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4105 - val_loss: 0.3634\n",
            "Epoch 327/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4099 - val_loss: 0.3626\n",
            "Epoch 328/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4105 - val_loss: 0.3609\n",
            "Epoch 329/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4102 - val_loss: 0.3604\n",
            "Epoch 330/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4100 - val_loss: 0.3637\n",
            "Epoch 331/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4102 - val_loss: 0.3584\n",
            "Epoch 332/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4096 - val_loss: 0.3641\n",
            "Epoch 333/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4097 - val_loss: 0.3623\n",
            "Epoch 334/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4097 - val_loss: 0.3648\n",
            "Epoch 335/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4095 - val_loss: 0.3598\n",
            "Epoch 336/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4095 - val_loss: 0.3593\n",
            "Epoch 337/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4096 - val_loss: 0.3628\n",
            "Epoch 338/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4094 - val_loss: 0.3640\n",
            "Epoch 339/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4096 - val_loss: 0.3611\n",
            "Epoch 340/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4093 - val_loss: 0.3566\n",
            "Epoch 341/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4091 - val_loss: 0.3558\n",
            "Epoch 342/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4091 - val_loss: 0.3606\n",
            "Epoch 343/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4090 - val_loss: 0.3532\n",
            "Epoch 344/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4088 - val_loss: 0.3510\n",
            "Epoch 345/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4090 - val_loss: 0.3582\n",
            "Epoch 346/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4092 - val_loss: 0.3529\n",
            "Epoch 347/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4089 - val_loss: 0.3520\n",
            "Epoch 348/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4087 - val_loss: 0.3561\n",
            "Epoch 349/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4088 - val_loss: 0.3544\n",
            "Epoch 350/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4087 - val_loss: 0.3536\n",
            "Epoch 351/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4088 - val_loss: 0.3524\n",
            "Epoch 352/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4087 - val_loss: 0.3541\n",
            "Epoch 353/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4084 - val_loss: 0.3533\n",
            "Epoch 354/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4084 - val_loss: 0.3533\n",
            "Epoch 355/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4083 - val_loss: 0.3460\n",
            "Epoch 356/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4080 - val_loss: 0.3534\n",
            "Epoch 357/5000\n",
            "165/165 [==============================] - 0s 988us/step - loss: 0.4085 - val_loss: 0.3521\n",
            "Epoch 358/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4082 - val_loss: 0.3516\n",
            "Epoch 359/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4082 - val_loss: 0.3524\n",
            "Epoch 360/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4081 - val_loss: 0.3573\n",
            "Epoch 361/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4085 - val_loss: 0.3500\n",
            "Epoch 362/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4078 - val_loss: 0.3506\n",
            "Epoch 363/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4082 - val_loss: 0.3512\n",
            "Epoch 364/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4080 - val_loss: 0.3512\n",
            "Epoch 365/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4077 - val_loss: 0.3533\n",
            "Epoch 366/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4081 - val_loss: 0.3525\n",
            "Epoch 367/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4078 - val_loss: 0.3488\n",
            "Epoch 368/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4075 - val_loss: 0.3497\n",
            "Epoch 369/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4075 - val_loss: 0.3486\n",
            "Epoch 370/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4080 - val_loss: 0.3518\n",
            "Epoch 371/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4078 - val_loss: 0.3492\n",
            "Epoch 372/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4076 - val_loss: 0.3393\n",
            "Epoch 373/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4084 - val_loss: 0.3429\n",
            "Epoch 374/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4072 - val_loss: 0.3427\n",
            "Epoch 375/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4072 - val_loss: 0.3482\n",
            "Epoch 376/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4078 - val_loss: 0.3449\n",
            "Epoch 377/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4070 - val_loss: 0.3502\n",
            "Epoch 378/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4075 - val_loss: 0.3399\n",
            "Epoch 379/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4077 - val_loss: 0.3447\n",
            "Epoch 380/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4074 - val_loss: 0.3480\n",
            "Epoch 381/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4070 - val_loss: 0.3451\n",
            "Epoch 382/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4073 - val_loss: 0.3453\n",
            "Epoch 383/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4067 - val_loss: 0.3433\n",
            "Epoch 384/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4070 - val_loss: 0.3395\n",
            "Epoch 385/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4071 - val_loss: 0.3450\n",
            "Epoch 386/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4068 - val_loss: 0.3418\n",
            "Epoch 387/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4067 - val_loss: 0.3413\n",
            "Epoch 388/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4064 - val_loss: 0.3465\n",
            "Epoch 389/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4063 - val_loss: 0.3387\n",
            "Epoch 390/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4062 - val_loss: 0.3319\n",
            "Epoch 391/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4063 - val_loss: 0.3453\n",
            "Epoch 392/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4067 - val_loss: 0.3441\n",
            "Epoch 393/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4068 - val_loss: 0.3439\n",
            "Epoch 394/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4064 - val_loss: 0.3413\n",
            "Epoch 395/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4064 - val_loss: 0.3362\n",
            "Epoch 396/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4068 - val_loss: 0.3447\n",
            "Epoch 397/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4063 - val_loss: 0.3407\n",
            "Epoch 398/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4060 - val_loss: 0.3400\n",
            "Epoch 399/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4062 - val_loss: 0.3383\n",
            "Epoch 400/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4060 - val_loss: 0.3377\n",
            "Epoch 401/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4060 - val_loss: 0.3387\n",
            "Epoch 402/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4060 - val_loss: 0.3412\n",
            "Epoch 403/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4059 - val_loss: 0.3429\n",
            "Epoch 404/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4060 - val_loss: 0.3438\n",
            "Epoch 405/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4060 - val_loss: 0.3385\n",
            "Epoch 406/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4058 - val_loss: 0.3401\n",
            "Epoch 407/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4057 - val_loss: 0.3354\n",
            "Epoch 408/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4060 - val_loss: 0.3357\n",
            "Epoch 409/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4060 - val_loss: 0.3368\n",
            "Epoch 410/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4061 - val_loss: 0.3364\n",
            "Epoch 411/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4056 - val_loss: 0.3369\n",
            "Epoch 412/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4055 - val_loss: 0.3397\n",
            "Epoch 413/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4055 - val_loss: 0.3409\n",
            "Epoch 414/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4055 - val_loss: 0.3358\n",
            "Epoch 415/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4059 - val_loss: 0.3362\n",
            "Epoch 416/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4055 - val_loss: 0.3377\n",
            "Epoch 417/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4053 - val_loss: 0.3345\n",
            "Epoch 418/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4052 - val_loss: 0.3345\n",
            "Epoch 419/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4050 - val_loss: 0.3396\n",
            "Epoch 420/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4053 - val_loss: 0.3360\n",
            "Epoch 421/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4054 - val_loss: 0.3372\n",
            "Epoch 422/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4052 - val_loss: 0.3350\n",
            "Epoch 423/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4049 - val_loss: 0.3367\n",
            "Epoch 424/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4049 - val_loss: 0.3316\n",
            "Epoch 425/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4049 - val_loss: 0.3318\n",
            "Epoch 426/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4049 - val_loss: 0.3320\n",
            "Epoch 427/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4052 - val_loss: 0.3301\n",
            "Epoch 428/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4045 - val_loss: 0.3374\n",
            "Epoch 429/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4048 - val_loss: 0.3368\n",
            "Epoch 430/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4044 - val_loss: 0.3276\n",
            "Epoch 431/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4050 - val_loss: 0.3329\n",
            "Epoch 432/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4045 - val_loss: 0.3371\n",
            "Epoch 433/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4050 - val_loss: 0.3345\n",
            "Epoch 434/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4047 - val_loss: 0.3362\n",
            "Epoch 435/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4046 - val_loss: 0.3362\n",
            "Epoch 436/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4046 - val_loss: 0.3337\n",
            "Epoch 437/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4044 - val_loss: 0.3325\n",
            "Epoch 438/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4046 - val_loss: 0.3340\n",
            "Epoch 439/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4039 - val_loss: 0.3405\n",
            "Epoch 440/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4046 - val_loss: 0.3400\n",
            "Epoch 441/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4045 - val_loss: 0.3305\n",
            "Epoch 442/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4044 - val_loss: 0.3300\n",
            "Epoch 443/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4043 - val_loss: 0.3292\n",
            "Epoch 444/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4043 - val_loss: 0.3300\n",
            "Epoch 445/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4041 - val_loss: 0.3289\n",
            "Epoch 446/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4041 - val_loss: 0.3318\n",
            "Epoch 447/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4043 - val_loss: 0.3286\n",
            "Epoch 448/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4039 - val_loss: 0.3302\n",
            "Epoch 449/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4039 - val_loss: 0.3271\n",
            "Epoch 450/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4043 - val_loss: 0.3267\n",
            "Epoch 451/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4047 - val_loss: 0.3270\n",
            "Epoch 452/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4034 - val_loss: 0.3323\n",
            "Epoch 453/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4037 - val_loss: 0.3271\n",
            "Epoch 454/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4040 - val_loss: 0.3328\n",
            "Epoch 455/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4036 - val_loss: 0.3255\n",
            "Epoch 456/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4044 - val_loss: 0.3343\n",
            "Epoch 457/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4041 - val_loss: 0.3277\n",
            "Epoch 458/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4038 - val_loss: 0.3314\n",
            "Epoch 459/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4035 - val_loss: 0.3290\n",
            "Epoch 460/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4035 - val_loss: 0.3301\n",
            "Epoch 461/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4037 - val_loss: 0.3327\n",
            "Epoch 462/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4036 - val_loss: 0.3326\n",
            "Epoch 463/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4035 - val_loss: 0.3304\n",
            "Epoch 464/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4034 - val_loss: 0.3314\n",
            "Epoch 465/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4035 - val_loss: 0.3358\n",
            "Epoch 466/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4039 - val_loss: 0.3311\n",
            "Epoch 467/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4033 - val_loss: 0.3286\n",
            "Epoch 468/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4039 - val_loss: 0.3283\n",
            "Epoch 469/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4032 - val_loss: 0.3268\n",
            "Epoch 470/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4032 - val_loss: 0.3201\n",
            "Epoch 471/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4032 - val_loss: 0.3248\n",
            "Epoch 472/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4027 - val_loss: 0.3317\n",
            "Epoch 473/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4033 - val_loss: 0.3248\n",
            "Epoch 474/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4030 - val_loss: 0.3313\n",
            "Epoch 475/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4030 - val_loss: 0.3245\n",
            "Epoch 476/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4026 - val_loss: 0.3330\n",
            "Epoch 477/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4030 - val_loss: 0.3248\n",
            "Epoch 478/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4034 - val_loss: 0.3241\n",
            "Epoch 479/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4026 - val_loss: 0.3227\n",
            "Epoch 480/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4028 - val_loss: 0.3276\n",
            "Epoch 481/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4031 - val_loss: 0.3284\n",
            "Epoch 482/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4031 - val_loss: 0.3300\n",
            "Epoch 483/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4027 - val_loss: 0.3234\n",
            "Epoch 484/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4028 - val_loss: 0.3257\n",
            "Epoch 485/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4025 - val_loss: 0.3267\n",
            "Epoch 486/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4025 - val_loss: 0.3226\n",
            "Epoch 487/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4029 - val_loss: 0.3249\n",
            "Epoch 488/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4026 - val_loss: 0.3234\n",
            "Epoch 489/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4028 - val_loss: 0.3252\n",
            "Epoch 490/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4024 - val_loss: 0.3231\n",
            "Epoch 491/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4021 - val_loss: 0.3302\n",
            "Epoch 492/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4022 - val_loss: 0.3236\n",
            "Epoch 493/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4028 - val_loss: 0.3245\n",
            "Epoch 494/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4026 - val_loss: 0.3214\n",
            "Epoch 495/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4023 - val_loss: 0.3227\n",
            "Epoch 496/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4028 - val_loss: 0.3298\n",
            "Epoch 497/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4023 - val_loss: 0.3276\n",
            "Epoch 498/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4023 - val_loss: 0.3227\n",
            "Epoch 499/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4020 - val_loss: 0.3286\n",
            "Epoch 500/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4021 - val_loss: 0.3272\n",
            "Epoch 501/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4019 - val_loss: 0.3279\n",
            "Epoch 502/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4022 - val_loss: 0.3229\n",
            "Epoch 503/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4020 - val_loss: 0.3177\n",
            "Epoch 504/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4022 - val_loss: 0.3187\n",
            "Epoch 505/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4019 - val_loss: 0.3179\n",
            "Epoch 506/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4016 - val_loss: 0.3268\n",
            "Epoch 507/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4023 - val_loss: 0.3250\n",
            "Epoch 508/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4015 - val_loss: 0.3207\n",
            "Epoch 509/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4019 - val_loss: 0.3252\n",
            "Epoch 510/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4018 - val_loss: 0.3288\n",
            "Epoch 511/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4013 - val_loss: 0.3183\n",
            "Epoch 512/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4021 - val_loss: 0.3243\n",
            "Epoch 513/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4015 - val_loss: 0.3191\n",
            "Epoch 514/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4016 - val_loss: 0.3248\n",
            "Epoch 515/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4014 - val_loss: 0.3283\n",
            "Epoch 516/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4025 - val_loss: 0.3255\n",
            "Epoch 517/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4017 - val_loss: 0.3188\n",
            "Epoch 518/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4015 - val_loss: 0.3179\n",
            "Epoch 519/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4017 - val_loss: 0.3220\n",
            "Epoch 520/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4015 - val_loss: 0.3202\n",
            "Epoch 521/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4014 - val_loss: 0.3165\n",
            "Epoch 522/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4014 - val_loss: 0.3184\n",
            "Epoch 523/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4011 - val_loss: 0.3166\n",
            "Epoch 524/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4016 - val_loss: 0.3187\n",
            "Epoch 525/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4011 - val_loss: 0.3150\n",
            "Epoch 526/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4016 - val_loss: 0.3181\n",
            "Epoch 527/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4012 - val_loss: 0.3266\n",
            "Epoch 528/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4006 - val_loss: 0.3153\n",
            "Epoch 529/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4014 - val_loss: 0.3229\n",
            "Epoch 530/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4013 - val_loss: 0.3251\n",
            "Epoch 531/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4008 - val_loss: 0.3175\n",
            "Epoch 532/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4011 - val_loss: 0.3255\n",
            "Epoch 533/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4013 - val_loss: 0.3191\n",
            "Epoch 534/5000\n",
            "165/165 [==============================] - 0s 996us/step - loss: 0.4010 - val_loss: 0.3302\n",
            "Epoch 535/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4013 - val_loss: 0.3221\n",
            "Epoch 536/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4008 - val_loss: 0.3216\n",
            "Epoch 537/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4009 - val_loss: 0.3211\n",
            "Epoch 538/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4011 - val_loss: 0.3238\n",
            "Epoch 539/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4011 - val_loss: 0.3188\n",
            "Epoch 540/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4009 - val_loss: 0.3197\n",
            "Epoch 541/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4008 - val_loss: 0.3208\n",
            "Epoch 542/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4006 - val_loss: 0.3240\n",
            "Epoch 543/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4007 - val_loss: 0.3254\n",
            "Epoch 544/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4008 - val_loss: 0.3186\n",
            "Epoch 545/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4005 - val_loss: 0.3200\n",
            "Epoch 546/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4002 - val_loss: 0.3125\n",
            "Epoch 547/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4009 - val_loss: 0.3192\n",
            "Epoch 548/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4004 - val_loss: 0.3216\n",
            "Epoch 549/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4004 - val_loss: 0.3195\n",
            "Epoch 550/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4004 - val_loss: 0.3165\n",
            "Epoch 551/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4002 - val_loss: 0.3186\n",
            "Epoch 552/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4006 - val_loss: 0.3206\n",
            "Epoch 553/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4005 - val_loss: 0.3233\n",
            "Epoch 554/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4005 - val_loss: 0.3228\n",
            "Epoch 555/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4009 - val_loss: 0.3183\n",
            "Epoch 556/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4005 - val_loss: 0.3207\n",
            "Epoch 557/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4007 - val_loss: 0.3250\n",
            "Epoch 558/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4002 - val_loss: 0.3196\n",
            "Epoch 559/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4003 - val_loss: 0.3211\n",
            "Epoch 560/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4002 - val_loss: 0.3184\n",
            "Epoch 561/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3999 - val_loss: 0.3175\n",
            "Epoch 562/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3999 - val_loss: 0.3199\n",
            "Epoch 563/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3999 - val_loss: 0.3142\n",
            "Epoch 564/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3998 - val_loss: 0.3192\n",
            "Epoch 565/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3997 - val_loss: 0.3162\n",
            "Epoch 566/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3998 - val_loss: 0.3172\n",
            "Epoch 567/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4003 - val_loss: 0.3151\n",
            "Epoch 568/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4005 - val_loss: 0.3145\n",
            "Epoch 569/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3992 - val_loss: 0.3260\n",
            "Epoch 570/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3997 - val_loss: 0.3142\n",
            "Epoch 571/5000\n",
            "165/165 [==============================] - 0s 992us/step - loss: 0.4003 - val_loss: 0.3232\n",
            "Epoch 572/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3999 - val_loss: 0.3201\n",
            "Epoch 573/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4002 - val_loss: 0.3180\n",
            "Epoch 574/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3992 - val_loss: 0.3140\n",
            "Epoch 575/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4001 - val_loss: 0.3173\n",
            "Epoch 576/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3994 - val_loss: 0.3154\n",
            "Epoch 577/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3992 - val_loss: 0.3145\n",
            "Epoch 578/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3997 - val_loss: 0.3194\n",
            "Epoch 579/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3995 - val_loss: 0.3166\n",
            "Epoch 580/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3995 - val_loss: 0.3176\n",
            "Epoch 581/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4000 - val_loss: 0.3210\n",
            "Epoch 582/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3995 - val_loss: 0.3190\n",
            "Epoch 583/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3993 - val_loss: 0.3197\n",
            "Epoch 584/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3995 - val_loss: 0.3136\n",
            "Epoch 585/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3996 - val_loss: 0.3168\n",
            "Epoch 586/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3993 - val_loss: 0.3179\n",
            "Epoch 587/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3994 - val_loss: 0.3183\n",
            "Epoch 588/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3990 - val_loss: 0.3172\n",
            "Epoch 589/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3997 - val_loss: 0.3156\n",
            "Epoch 590/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3989 - val_loss: 0.3154\n",
            "Epoch 591/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3992 - val_loss: 0.3164\n",
            "Epoch 592/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3992 - val_loss: 0.3172\n",
            "Epoch 593/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3990 - val_loss: 0.3162\n",
            "Epoch 594/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3991 - val_loss: 0.3203\n",
            "Epoch 595/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3990 - val_loss: 0.3199\n",
            "Epoch 596/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3991 - val_loss: 0.3155\n",
            "Epoch 597/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3991 - val_loss: 0.3130\n",
            "Epoch 598/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3991 - val_loss: 0.3151\n",
            "Epoch 599/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3982 - val_loss: 0.3091\n",
            "Epoch 600/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3989 - val_loss: 0.3134\n",
            "Epoch 601/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3985 - val_loss: 0.3204\n",
            "Epoch 602/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3992 - val_loss: 0.3197\n",
            "Epoch 603/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3991 - val_loss: 0.3156\n",
            "Epoch 604/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3989 - val_loss: 0.3152\n",
            "Epoch 605/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3986 - val_loss: 0.3152\n",
            "Epoch 606/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3990 - val_loss: 0.3131\n",
            "Epoch 607/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3986 - val_loss: 0.3167\n",
            "Epoch 608/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3988 - val_loss: 0.3183\n",
            "Epoch 609/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3985 - val_loss: 0.3123\n",
            "Epoch 610/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3988 - val_loss: 0.3154\n",
            "Epoch 611/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3981 - val_loss: 0.3131\n",
            "Epoch 612/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3984 - val_loss: 0.3149\n",
            "Epoch 613/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3987 - val_loss: 0.3156\n",
            "Epoch 614/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3988 - val_loss: 0.3197\n",
            "Epoch 615/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3984 - val_loss: 0.3195\n",
            "Epoch 616/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3985 - val_loss: 0.3171\n",
            "Epoch 617/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3983 - val_loss: 0.3157\n",
            "Epoch 618/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3986 - val_loss: 0.3176\n",
            "Epoch 619/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3983 - val_loss: 0.3138\n",
            "Epoch 620/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3987 - val_loss: 0.3148\n",
            "Epoch 621/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3982 - val_loss: 0.3153\n",
            "Epoch 622/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3980 - val_loss: 0.3133\n",
            "Epoch 623/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3988 - val_loss: 0.3165\n",
            "Epoch 624/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3981 - val_loss: 0.3127\n",
            "Epoch 625/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3983 - val_loss: 0.3124\n",
            "Epoch 626/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3981 - val_loss: 0.3191\n",
            "Epoch 627/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3980 - val_loss: 0.3133\n",
            "Epoch 628/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3981 - val_loss: 0.3194\n",
            "Epoch 629/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3984 - val_loss: 0.3139\n",
            "Epoch 630/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3985 - val_loss: 0.3127\n",
            "Epoch 631/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3979 - val_loss: 0.3141\n",
            "Epoch 632/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3982 - val_loss: 0.3123\n",
            "Epoch 633/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3984 - val_loss: 0.3170\n",
            "Epoch 634/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3984 - val_loss: 0.3134\n",
            "Epoch 635/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3982 - val_loss: 0.3144\n",
            "Epoch 636/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3980 - val_loss: 0.3172\n",
            "Epoch 637/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3979 - val_loss: 0.3135\n",
            "Epoch 638/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3980 - val_loss: 0.3160\n",
            "Epoch 639/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3981 - val_loss: 0.3162\n",
            "Epoch 640/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3978 - val_loss: 0.3136\n",
            "Epoch 641/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3978 - val_loss: 0.3114\n",
            "Epoch 642/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3977 - val_loss: 0.3106\n",
            "Epoch 643/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3975 - val_loss: 0.3131\n",
            "Epoch 644/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3979 - val_loss: 0.3120\n",
            "Epoch 645/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3975 - val_loss: 0.3161\n",
            "Epoch 646/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3974 - val_loss: 0.3210\n",
            "Epoch 647/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3979 - val_loss: 0.3103\n",
            "Epoch 648/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3983 - val_loss: 0.3147\n",
            "Epoch 649/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3974 - val_loss: 0.3145\n",
            "Epoch 650/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3973 - val_loss: 0.3131\n",
            "Epoch 651/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3978 - val_loss: 0.3178\n",
            "Epoch 652/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3978 - val_loss: 0.3181\n",
            "Epoch 653/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3976 - val_loss: 0.3126\n",
            "Epoch 654/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3979 - val_loss: 0.3133\n",
            "Epoch 655/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3974 - val_loss: 0.3110\n",
            "Epoch 656/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3971 - val_loss: 0.3155\n",
            "Epoch 657/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3978 - val_loss: 0.3106\n",
            "Epoch 658/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3977 - val_loss: 0.3142\n",
            "Epoch 659/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3974 - val_loss: 0.3100\n",
            "Epoch 660/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3974 - val_loss: 0.3124\n",
            "Epoch 661/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3973 - val_loss: 0.3166\n",
            "Epoch 662/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3973 - val_loss: 0.3107\n",
            "Epoch 663/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3970 - val_loss: 0.3116\n",
            "Epoch 664/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3969 - val_loss: 0.3110\n",
            "Epoch 665/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3971 - val_loss: 0.3098\n",
            "Epoch 666/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3976 - val_loss: 0.3145\n",
            "Epoch 667/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3972 - val_loss: 0.3139\n",
            "Epoch 668/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3967 - val_loss: 0.3089\n",
            "Epoch 669/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3967 - val_loss: 0.3135\n",
            "Epoch 670/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3970 - val_loss: 0.3078\n",
            "Epoch 671/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3970 - val_loss: 0.3132\n",
            "Epoch 672/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3969 - val_loss: 0.3099\n",
            "Epoch 673/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3967 - val_loss: 0.3109\n",
            "Epoch 674/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3969 - val_loss: 0.3145\n",
            "Epoch 675/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3967 - val_loss: 0.3118\n",
            "Epoch 676/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3969 - val_loss: 0.3117\n",
            "Epoch 677/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3967 - val_loss: 0.3120\n",
            "Epoch 678/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3968 - val_loss: 0.3117\n",
            "Epoch 679/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3967 - val_loss: 0.3113\n",
            "Epoch 680/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3966 - val_loss: 0.3084\n",
            "Epoch 681/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3970 - val_loss: 0.3188\n",
            "Epoch 682/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3970 - val_loss: 0.3152\n",
            "Epoch 683/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3965 - val_loss: 0.3124\n",
            "Epoch 684/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3964 - val_loss: 0.3089\n",
            "Epoch 685/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3973 - val_loss: 0.3117\n",
            "Epoch 686/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3967 - val_loss: 0.3102\n",
            "Epoch 687/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3964 - val_loss: 0.3100\n",
            "Epoch 688/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3964 - val_loss: 0.3113\n",
            "Epoch 689/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3965 - val_loss: 0.3159\n",
            "Epoch 690/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3966 - val_loss: 0.3113\n",
            "Epoch 691/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3965 - val_loss: 0.3076\n",
            "Epoch 692/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3968 - val_loss: 0.3091\n",
            "Epoch 693/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3965 - val_loss: 0.3113\n",
            "Epoch 694/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3963 - val_loss: 0.3126\n",
            "Epoch 695/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3961 - val_loss: 0.3130\n",
            "Epoch 696/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3966 - val_loss: 0.3115\n",
            "Epoch 697/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3961 - val_loss: 0.3096\n",
            "Epoch 698/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3962 - val_loss: 0.3128\n",
            "Epoch 699/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3961 - val_loss: 0.3103\n",
            "Epoch 700/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3963 - val_loss: 0.3135\n",
            "Epoch 701/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3965 - val_loss: 0.3102\n",
            "Epoch 702/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3965 - val_loss: 0.3083\n",
            "Epoch 703/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3958 - val_loss: 0.3054\n",
            "Epoch 704/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3963 - val_loss: 0.3125\n",
            "Epoch 705/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3961 - val_loss: 0.3146\n",
            "Epoch 706/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3963 - val_loss: 0.3136\n",
            "Epoch 707/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3957 - val_loss: 0.3089\n",
            "Epoch 708/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3964 - val_loss: 0.3189\n",
            "Epoch 709/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3958 - val_loss: 0.3109\n",
            "Epoch 710/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3959 - val_loss: 0.3139\n",
            "Epoch 711/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3959 - val_loss: 0.3091\n",
            "Epoch 712/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3956 - val_loss: 0.3145\n",
            "Epoch 713/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3958 - val_loss: 0.3112\n",
            "Epoch 714/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3964 - val_loss: 0.3099\n",
            "Epoch 715/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3958 - val_loss: 0.3115\n",
            "Epoch 716/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3959 - val_loss: 0.3107\n",
            "Epoch 717/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3958 - val_loss: 0.3116\n",
            "Epoch 718/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3962 - val_loss: 0.3155\n",
            "Epoch 719/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3960 - val_loss: 0.3129\n",
            "Epoch 720/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3955 - val_loss: 0.3139\n",
            "Epoch 721/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3957 - val_loss: 0.3158\n",
            "Epoch 722/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3959 - val_loss: 0.3096\n",
            "Epoch 723/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3955 - val_loss: 0.3111\n",
            "Epoch 724/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3956 - val_loss: 0.3153\n",
            "Epoch 725/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3959 - val_loss: 0.3133\n",
            "Epoch 726/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3958 - val_loss: 0.3129\n",
            "Epoch 727/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3958 - val_loss: 0.3108\n",
            "Epoch 728/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3958 - val_loss: 0.3106\n",
            "Epoch 729/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3959 - val_loss: 0.3103\n",
            "Epoch 730/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3951 - val_loss: 0.3158\n",
            "Epoch 731/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3955 - val_loss: 0.3113\n",
            "Epoch 732/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3955 - val_loss: 0.3160\n",
            "Epoch 733/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3952 - val_loss: 0.3120\n",
            "Epoch 734/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3954 - val_loss: 0.3125\n",
            "Epoch 735/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3954 - val_loss: 0.3096\n",
            "Epoch 736/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3954 - val_loss: 0.3115\n",
            "Epoch 737/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3950 - val_loss: 0.3098\n",
            "Epoch 738/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3954 - val_loss: 0.3172\n",
            "Epoch 739/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3954 - val_loss: 0.3144\n",
            "Epoch 740/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3953 - val_loss: 0.3124\n",
            "Epoch 741/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3950 - val_loss: 0.3085\n",
            "Epoch 742/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3959 - val_loss: 0.3102\n",
            "Epoch 743/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3953 - val_loss: 0.3092\n",
            "Epoch 744/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3951 - val_loss: 0.3143\n",
            "Epoch 745/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3951 - val_loss: 0.3098\n",
            "Epoch 746/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3948 - val_loss: 0.3085\n",
            "Epoch 747/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3948 - val_loss: 0.3156\n",
            "Epoch 748/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3950 - val_loss: 0.3160\n",
            "Epoch 749/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3950 - val_loss: 0.3134\n",
            "Epoch 750/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3950 - val_loss: 0.3117\n",
            "Epoch 751/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3945 - val_loss: 0.3158\n",
            "Epoch 752/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3948 - val_loss: 0.3109\n",
            "Epoch 753/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3953 - val_loss: 0.3130\n",
            "Epoch 754/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3951 - val_loss: 0.3152\n",
            "Epoch 755/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3946 - val_loss: 0.3124\n",
            "Epoch 756/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3953 - val_loss: 0.3161\n",
            "Epoch 757/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3947 - val_loss: 0.3128\n",
            "Epoch 758/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3948 - val_loss: 0.3154\n",
            "Epoch 759/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3951 - val_loss: 0.3134\n",
            "Epoch 760/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3942 - val_loss: 0.3119\n",
            "Epoch 761/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3948 - val_loss: 0.3174\n",
            "Epoch 762/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3943 - val_loss: 0.3131\n",
            "Epoch 763/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3952 - val_loss: 0.3121\n",
            "Epoch 764/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3942 - val_loss: 0.3151\n",
            "Epoch 765/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3943 - val_loss: 0.3112\n",
            "Epoch 766/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3943 - val_loss: 0.3126\n",
            "Epoch 767/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3944 - val_loss: 0.3145\n",
            "Epoch 768/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3943 - val_loss: 0.3165\n",
            "Epoch 769/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3944 - val_loss: 0.3134\n",
            "Epoch 770/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3949 - val_loss: 0.3102\n",
            "Epoch 771/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3937 - val_loss: 0.3097\n",
            "Epoch 772/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3941 - val_loss: 0.3100\n",
            "Epoch 773/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3949 - val_loss: 0.3159\n",
            "Epoch 774/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3939 - val_loss: 0.3188\n",
            "Epoch 775/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3944 - val_loss: 0.3130\n",
            "Epoch 776/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3939 - val_loss: 0.3223\n",
            "Epoch 777/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3949 - val_loss: 0.3117\n",
            "Epoch 778/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3941 - val_loss: 0.3165\n",
            "Epoch 779/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3944 - val_loss: 0.3179\n",
            "Epoch 780/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3935 - val_loss: 0.3122\n",
            "Epoch 781/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3942 - val_loss: 0.3175\n",
            "Epoch 782/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3944 - val_loss: 0.3163\n",
            "Epoch 783/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3938 - val_loss: 0.3118\n",
            "Epoch 784/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3941 - val_loss: 0.3122\n",
            "Epoch 785/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3940 - val_loss: 0.3125\n",
            "Epoch 786/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3940 - val_loss: 0.3122\n",
            "Epoch 787/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3939 - val_loss: 0.3127\n",
            "Epoch 788/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3934 - val_loss: 0.3165\n",
            "Epoch 789/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3936 - val_loss: 0.3106\n",
            "Epoch 790/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3935 - val_loss: 0.3104\n",
            "Epoch 791/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3942 - val_loss: 0.3137\n",
            "Epoch 792/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3939 - val_loss: 0.3175\n",
            "Epoch 793/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3938 - val_loss: 0.3130\n",
            "Epoch 794/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3936 - val_loss: 0.3129\n",
            "Epoch 795/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3937 - val_loss: 0.3168\n",
            "Epoch 796/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3941 - val_loss: 0.3147\n",
            "Epoch 797/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3942 - val_loss: 0.3116\n",
            "Epoch 798/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3937 - val_loss: 0.3103\n",
            "Epoch 799/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3934 - val_loss: 0.3103\n",
            "Epoch 800/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3936 - val_loss: 0.3073\n",
            "Epoch 801/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3937 - val_loss: 0.3092\n",
            "Epoch 802/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3932 - val_loss: 0.3098\n",
            "Epoch 803/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3937 - val_loss: 0.3097\n",
            "Epoch 804/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3930 - val_loss: 0.3084\n",
            "Epoch 805/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3938 - val_loss: 0.3126\n",
            "Epoch 806/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3935 - val_loss: 0.3136\n",
            "Epoch 807/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3935 - val_loss: 0.3107\n",
            "Epoch 808/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3935 - val_loss: 0.3101\n",
            "Epoch 809/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3934 - val_loss: 0.3147\n",
            "Epoch 810/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3934 - val_loss: 0.3145\n",
            "Epoch 811/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3933 - val_loss: 0.3150\n",
            "Epoch 812/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3932 - val_loss: 0.3169\n",
            "Epoch 813/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3938 - val_loss: 0.3123\n",
            "Epoch 814/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3932 - val_loss: 0.3152\n",
            "Epoch 815/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3935 - val_loss: 0.3115\n",
            "Epoch 816/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3934 - val_loss: 0.3120\n",
            "Epoch 817/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3931 - val_loss: 0.3114\n",
            "Epoch 818/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3933 - val_loss: 0.3143\n",
            "Epoch 819/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3926 - val_loss: 0.3100\n",
            "Epoch 820/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3937 - val_loss: 0.3151\n",
            "Epoch 821/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3932 - val_loss: 0.3163\n",
            "Epoch 822/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3933 - val_loss: 0.3125\n",
            "Epoch 823/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3930 - val_loss: 0.3152\n",
            "Epoch 824/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3929 - val_loss: 0.3141\n",
            "Epoch 825/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3926 - val_loss: 0.3138\n",
            "Epoch 826/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3928 - val_loss: 0.3152\n",
            "Epoch 827/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3933 - val_loss: 0.3119\n",
            "Epoch 828/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3930 - val_loss: 0.3111\n",
            "Epoch 829/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3932 - val_loss: 0.3119\n",
            "Epoch 830/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3927 - val_loss: 0.3146\n",
            "Epoch 831/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3928 - val_loss: 0.3130\n",
            "Epoch 832/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3928 - val_loss: 0.3154\n",
            "Epoch 833/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3927 - val_loss: 0.3169\n",
            "Epoch 834/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3929 - val_loss: 0.3137\n",
            "Epoch 835/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3925 - val_loss: 0.3123\n",
            "Epoch 836/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3929 - val_loss: 0.3114\n",
            "Epoch 837/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3930 - val_loss: 0.3124\n",
            "Epoch 838/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3930 - val_loss: 0.3113\n",
            "Epoch 839/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3928 - val_loss: 0.3137\n",
            "Epoch 840/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3928 - val_loss: 0.3121\n",
            "Epoch 841/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3926 - val_loss: 0.3119\n",
            "Epoch 842/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3927 - val_loss: 0.3120\n",
            "Epoch 843/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3924 - val_loss: 0.3098\n",
            "Epoch 844/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3932 - val_loss: 0.3101\n",
            "Epoch 845/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3929 - val_loss: 0.3110\n",
            "Epoch 846/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3927 - val_loss: 0.3084\n",
            "Epoch 847/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3926 - val_loss: 0.3124\n",
            "Epoch 848/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3926 - val_loss: 0.3116\n",
            "Epoch 849/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3925 - val_loss: 0.3116\n",
            "Epoch 850/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3925 - val_loss: 0.3089\n",
            "Epoch 851/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3925 - val_loss: 0.3100\n",
            "Epoch 852/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3923 - val_loss: 0.3086\n",
            "Epoch 853/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3923 - val_loss: 0.3112\n",
            "Epoch 854/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3928 - val_loss: 0.3149\n",
            "Epoch 855/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3917 - val_loss: 0.3104\n",
            "Epoch 856/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3927 - val_loss: 0.3196\n",
            "Epoch 857/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3925 - val_loss: 0.3156\n",
            "Epoch 858/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3921 - val_loss: 0.3133\n",
            "Epoch 859/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3925 - val_loss: 0.3129\n",
            "Epoch 860/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3924 - val_loss: 0.3137\n",
            "Epoch 861/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3926 - val_loss: 0.3160\n",
            "Epoch 862/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3923 - val_loss: 0.3145\n",
            "Epoch 863/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3919 - val_loss: 0.3121\n",
            "Epoch 864/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3925 - val_loss: 0.3165\n",
            "Epoch 865/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3920 - val_loss: 0.3100\n",
            "Epoch 866/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3918 - val_loss: 0.3138\n",
            "Epoch 867/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3924 - val_loss: 0.3148\n",
            "Epoch 868/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3919 - val_loss: 0.3161\n",
            "Epoch 869/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3923 - val_loss: 0.3142\n",
            "Epoch 870/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3918 - val_loss: 0.3104\n",
            "Epoch 871/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3920 - val_loss: 0.3098\n",
            "Epoch 872/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3924 - val_loss: 0.3166\n",
            "Epoch 873/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3920 - val_loss: 0.3140\n",
            "Epoch 874/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3921 - val_loss: 0.3151\n",
            "Epoch 875/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3923 - val_loss: 0.3191\n",
            "Epoch 876/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3919 - val_loss: 0.3136\n",
            "Epoch 877/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3919 - val_loss: 0.3151\n",
            "Epoch 878/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3916 - val_loss: 0.3117\n",
            "Epoch 879/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3918 - val_loss: 0.3134\n",
            "Epoch 880/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3915 - val_loss: 0.3117\n",
            "Epoch 881/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3913 - val_loss: 0.3190\n",
            "Epoch 882/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3914 - val_loss: 0.3181\n",
            "Epoch 883/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3921 - val_loss: 0.3108\n",
            "Epoch 884/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3916 - val_loss: 0.3166\n",
            "Epoch 885/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3918 - val_loss: 0.3161\n",
            "Epoch 886/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3914 - val_loss: 0.3173\n",
            "Epoch 887/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3913 - val_loss: 0.3129\n",
            "Epoch 888/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3913 - val_loss: 0.3112\n",
            "Epoch 889/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3919 - val_loss: 0.3163\n",
            "Epoch 890/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3916 - val_loss: 0.3133\n",
            "Epoch 891/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3912 - val_loss: 0.3133\n",
            "Epoch 892/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3920 - val_loss: 0.3079\n",
            "Epoch 893/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3914 - val_loss: 0.3128\n",
            "Epoch 894/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3913 - val_loss: 0.3140\n",
            "Epoch 895/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3917 - val_loss: 0.3122\n",
            "Epoch 896/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3914 - val_loss: 0.3110\n",
            "Epoch 897/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3916 - val_loss: 0.3125\n",
            "Epoch 898/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3913 - val_loss: 0.3113\n",
            "Epoch 899/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3912 - val_loss: 0.3121\n",
            "Epoch 900/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3914 - val_loss: 0.3156\n",
            "Epoch 901/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3912 - val_loss: 0.3192\n",
            "Epoch 902/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3910 - val_loss: 0.3126\n",
            "Epoch 903/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3912 - val_loss: 0.3130\n",
            "Epoch 904/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3912 - val_loss: 0.3140\n",
            "Epoch 905/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3907 - val_loss: 0.3187\n",
            "Epoch 906/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3913 - val_loss: 0.3136\n",
            "Epoch 907/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3907 - val_loss: 0.3132\n",
            "Epoch 908/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3907 - val_loss: 0.3115\n",
            "Epoch 909/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3909 - val_loss: 0.3125\n",
            "Epoch 910/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3917 - val_loss: 0.3165\n",
            "Epoch 911/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3912 - val_loss: 0.3168\n",
            "Epoch 912/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3912 - val_loss: 0.3148\n",
            "Epoch 913/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3910 - val_loss: 0.3143\n",
            "Epoch 914/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3912 - val_loss: 0.3123\n",
            "Epoch 915/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3911 - val_loss: 0.3132\n",
            "Epoch 916/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3914 - val_loss: 0.3135\n",
            "Epoch 917/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3912 - val_loss: 0.3127\n",
            "Epoch 918/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3908 - val_loss: 0.3138\n",
            "Epoch 919/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3908 - val_loss: 0.3117\n",
            "Epoch 920/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3903 - val_loss: 0.3103\n",
            "Epoch 921/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3908 - val_loss: 0.3155\n",
            "Epoch 922/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3909 - val_loss: 0.3126\n",
            "Epoch 923/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3907 - val_loss: 0.3123\n",
            "Epoch 924/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3908 - val_loss: 0.3140\n",
            "Epoch 925/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3911 - val_loss: 0.3116\n",
            "Epoch 926/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3906 - val_loss: 0.3116\n",
            "Epoch 927/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3907 - val_loss: 0.3129\n",
            "Epoch 928/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3904 - val_loss: 0.3129\n",
            "Epoch 929/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3912 - val_loss: 0.3116\n",
            "Epoch 930/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3903 - val_loss: 0.3093\n",
            "Epoch 931/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3907 - val_loss: 0.3107\n",
            "Epoch 932/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3904 - val_loss: 0.3117\n",
            "Epoch 933/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3902 - val_loss: 0.3163\n",
            "Epoch 934/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3913 - val_loss: 0.3129\n",
            "Epoch 935/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3907 - val_loss: 0.3135\n",
            "Epoch 936/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3903 - val_loss: 0.3116\n",
            "Epoch 937/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3905 - val_loss: 0.3129\n",
            "Epoch 938/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3905 - val_loss: 0.3160\n",
            "Epoch 939/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3901 - val_loss: 0.3194\n",
            "Epoch 940/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3907 - val_loss: 0.3238\n",
            "Epoch 941/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3899 - val_loss: 0.3132\n",
            "Epoch 942/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3907 - val_loss: 0.3161\n",
            "Epoch 943/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3910 - val_loss: 0.3145\n",
            "Epoch 944/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3903 - val_loss: 0.3155\n",
            "Epoch 945/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3902 - val_loss: 0.3144\n",
            "Epoch 946/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3904 - val_loss: 0.3171\n",
            "Epoch 947/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3905 - val_loss: 0.3133\n",
            "Epoch 948/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3899 - val_loss: 0.3178\n",
            "Epoch 949/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3904 - val_loss: 0.3170\n",
            "Epoch 950/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3900 - val_loss: 0.3124\n",
            "Epoch 951/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3895 - val_loss: 0.3112\n",
            "Epoch 952/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3903 - val_loss: 0.3149\n",
            "Epoch 953/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3902 - val_loss: 0.3163\n",
            "Epoch 954/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3905 - val_loss: 0.3150\n",
            "Epoch 955/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3899 - val_loss: 0.3159\n",
            "Epoch 956/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3900 - val_loss: 0.3169\n",
            "Epoch 957/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3898 - val_loss: 0.3130\n",
            "Epoch 958/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3898 - val_loss: 0.3131\n",
            "Epoch 959/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3898 - val_loss: 0.3137\n",
            "Epoch 960/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3903 - val_loss: 0.3121\n",
            "Epoch 961/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3901 - val_loss: 0.3120\n",
            "Epoch 962/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3902 - val_loss: 0.3159\n",
            "Epoch 963/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3898 - val_loss: 0.3121\n",
            "Epoch 964/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3897 - val_loss: 0.3132\n",
            "Epoch 965/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3898 - val_loss: 0.3155\n",
            "Epoch 966/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3896 - val_loss: 0.3148\n",
            "Epoch 967/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3896 - val_loss: 0.3145\n",
            "Epoch 968/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3896 - val_loss: 0.3199\n",
            "Epoch 969/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3895 - val_loss: 0.3128\n",
            "Epoch 970/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3897 - val_loss: 0.3131\n",
            "Epoch 971/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3900 - val_loss: 0.3121\n",
            "Epoch 972/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3892 - val_loss: 0.3143\n",
            "Epoch 973/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3894 - val_loss: 0.3116\n",
            "Epoch 974/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3903 - val_loss: 0.3146\n",
            "Epoch 975/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3896 - val_loss: 0.3212\n",
            "Epoch 976/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3896 - val_loss: 0.3177\n",
            "Epoch 977/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3890 - val_loss: 0.3145\n",
            "Epoch 978/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3898 - val_loss: 0.3155\n",
            "Epoch 979/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3899 - val_loss: 0.3178\n",
            "Epoch 980/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3897 - val_loss: 0.3162\n",
            "Epoch 981/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3894 - val_loss: 0.3118\n",
            "Epoch 982/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3893 - val_loss: 0.3145\n",
            "Epoch 983/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3895 - val_loss: 0.3155\n",
            "Epoch 984/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3895 - val_loss: 0.3162\n",
            "Epoch 985/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3898 - val_loss: 0.3193\n",
            "Epoch 986/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3895 - val_loss: 0.3112\n",
            "Epoch 987/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3896 - val_loss: 0.3176\n",
            "Epoch 988/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3891 - val_loss: 0.3173\n",
            "Epoch 989/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3891 - val_loss: 0.3140\n",
            "Epoch 990/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3889 - val_loss: 0.3168\n",
            "Epoch 991/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3888 - val_loss: 0.3170\n",
            "Epoch 992/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3887 - val_loss: 0.3133\n",
            "Epoch 993/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3894 - val_loss: 0.3161\n",
            "Epoch 994/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3893 - val_loss: 0.3153\n",
            "Epoch 995/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3890 - val_loss: 0.3135\n",
            "Epoch 996/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3890 - val_loss: 0.3164\n",
            "Epoch 997/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3895 - val_loss: 0.3172\n",
            "Epoch 998/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3891 - val_loss: 0.3170\n",
            "Epoch 999/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3892 - val_loss: 0.3167\n",
            "Epoch 1000/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3888 - val_loss: 0.3179\n",
            "Epoch 1001/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3883 - val_loss: 0.3132\n",
            "Epoch 1002/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3890 - val_loss: 0.3147\n",
            "Epoch 1003/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3897 - val_loss: 0.3152\n",
            "Epoch 1004/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3890 - val_loss: 0.3187\n",
            "Epoch 1005/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3886 - val_loss: 0.3163\n",
            "Epoch 1006/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3880 - val_loss: 0.3117\n",
            "Epoch 1007/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3890 - val_loss: 0.3207\n",
            "Epoch 1008/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3893 - val_loss: 0.3178\n",
            "Epoch 1009/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3885 - val_loss: 0.3171\n",
            "Epoch 1010/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3890 - val_loss: 0.3201\n",
            "Epoch 1011/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3887 - val_loss: 0.3202\n",
            "Epoch 1012/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3890 - val_loss: 0.3195\n",
            "Epoch 1013/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3887 - val_loss: 0.3165\n",
            "Epoch 1014/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3883 - val_loss: 0.3136\n",
            "Epoch 1015/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3888 - val_loss: 0.3134\n",
            "Epoch 1016/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3889 - val_loss: 0.3123\n",
            "Epoch 1017/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3889 - val_loss: 0.3218\n",
            "Epoch 1018/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3887 - val_loss: 0.3209\n",
            "Epoch 1019/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3886 - val_loss: 0.3190\n",
            "Epoch 1020/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3892 - val_loss: 0.3212\n",
            "Epoch 1021/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3880 - val_loss: 0.3163\n",
            "Epoch 1022/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3885 - val_loss: 0.3134\n",
            "Epoch 1023/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3888 - val_loss: 0.3142\n",
            "Epoch 1024/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3887 - val_loss: 0.3181\n",
            "Epoch 1025/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3884 - val_loss: 0.3141\n",
            "Epoch 1026/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3882 - val_loss: 0.3121\n",
            "Epoch 1027/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3885 - val_loss: 0.3185\n",
            "Epoch 1028/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3885 - val_loss: 0.3162\n",
            "Epoch 1029/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3887 - val_loss: 0.3172\n",
            "Epoch 1030/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3883 - val_loss: 0.3144\n",
            "Epoch 1031/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3882 - val_loss: 0.3162\n",
            "Epoch 1032/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3880 - val_loss: 0.3168\n",
            "Epoch 1033/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3882 - val_loss: 0.3167\n",
            "Epoch 1034/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3887 - val_loss: 0.3145\n",
            "Epoch 1035/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3879 - val_loss: 0.3181\n",
            "Epoch 1036/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3881 - val_loss: 0.3169\n",
            "Epoch 1037/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3880 - val_loss: 0.3166\n",
            "Epoch 1038/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3879 - val_loss: 0.3230\n",
            "Epoch 1039/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3884 - val_loss: 0.3204\n",
            "Epoch 1040/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3881 - val_loss: 0.3185\n",
            "Epoch 1041/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3883 - val_loss: 0.3191\n",
            "Epoch 1042/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3880 - val_loss: 0.3177\n",
            "Epoch 1043/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3886 - val_loss: 0.3203\n",
            "Epoch 1044/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3883 - val_loss: 0.3198\n",
            "Epoch 1045/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3877 - val_loss: 0.3158\n",
            "Epoch 1046/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3879 - val_loss: 0.3186\n",
            "Epoch 1047/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3877 - val_loss: 0.3185\n",
            "Epoch 1048/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3881 - val_loss: 0.3178\n",
            "Epoch 1049/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3879 - val_loss: 0.3141\n",
            "Epoch 1050/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3880 - val_loss: 0.3191\n",
            "Epoch 1051/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3883 - val_loss: 0.3199\n",
            "Epoch 1052/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3878 - val_loss: 0.3188\n",
            "Epoch 1053/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3878 - val_loss: 0.3175\n",
            "Epoch 1054/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3879 - val_loss: 0.3169\n",
            "Epoch 1055/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3882 - val_loss: 0.3192\n",
            "Epoch 1056/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3873 - val_loss: 0.3160\n",
            "Epoch 1057/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3881 - val_loss: 0.3209\n",
            "Epoch 1058/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3875 - val_loss: 0.3227\n",
            "Epoch 1059/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3885 - val_loss: 0.3228\n",
            "Epoch 1060/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3877 - val_loss: 0.3180\n",
            "Epoch 1061/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3878 - val_loss: 0.3170\n",
            "Epoch 1062/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3875 - val_loss: 0.3168\n",
            "Epoch 1063/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3877 - val_loss: 0.3173\n",
            "Epoch 1064/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3876 - val_loss: 0.3218\n",
            "Epoch 1065/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3883 - val_loss: 0.3200\n",
            "Epoch 1066/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3876 - val_loss: 0.3184\n",
            "Epoch 1067/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3883 - val_loss: 0.3210\n",
            "Epoch 1068/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3874 - val_loss: 0.3170\n",
            "Epoch 1069/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3872 - val_loss: 0.3217\n",
            "Epoch 1070/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3873 - val_loss: 0.3208\n",
            "Epoch 1071/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3873 - val_loss: 0.3203\n",
            "Epoch 1072/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3879 - val_loss: 0.3175\n",
            "Epoch 1073/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3875 - val_loss: 0.3197\n",
            "Epoch 1074/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3868 - val_loss: 0.3186\n",
            "Epoch 1075/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3874 - val_loss: 0.3213\n",
            "Epoch 1076/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3872 - val_loss: 0.3189\n",
            "Epoch 1077/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3871 - val_loss: 0.3197\n",
            "Epoch 1078/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3871 - val_loss: 0.3183\n",
            "Epoch 1079/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3871 - val_loss: 0.3173\n",
            "Epoch 1080/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3875 - val_loss: 0.3196\n",
            "Epoch 1081/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3874 - val_loss: 0.3185\n",
            "Epoch 1082/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3877 - val_loss: 0.3252\n",
            "Epoch 1083/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3875 - val_loss: 0.3222\n",
            "Epoch 1084/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3873 - val_loss: 0.3191\n",
            "Epoch 1085/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3872 - val_loss: 0.3169\n",
            "Epoch 1086/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3869 - val_loss: 0.3205\n",
            "Epoch 1087/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3869 - val_loss: 0.3182\n",
            "Epoch 1088/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3868 - val_loss: 0.3247\n",
            "Epoch 1089/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3869 - val_loss: 0.3210\n",
            "Epoch 1090/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3869 - val_loss: 0.3224\n",
            "Epoch 1091/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3868 - val_loss: 0.3199\n",
            "Epoch 1092/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3869 - val_loss: 0.3228\n",
            "Epoch 1093/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3869 - val_loss: 0.3222\n",
            "Epoch 1094/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3866 - val_loss: 0.3213\n",
            "Epoch 1095/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3867 - val_loss: 0.3245\n",
            "Epoch 1096/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3864 - val_loss: 0.3208\n",
            "Epoch 1097/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3867 - val_loss: 0.3189\n",
            "Epoch 1098/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3868 - val_loss: 0.3217\n",
            "Epoch 1099/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3871 - val_loss: 0.3191\n",
            "Epoch 1100/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3867 - val_loss: 0.3225\n",
            "Epoch 1101/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3865 - val_loss: 0.3264\n",
            "Epoch 1102/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3867 - val_loss: 0.3210\n",
            "Epoch 1103/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3866 - val_loss: 0.3258\n",
            "Epoch 1104/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3867 - val_loss: 0.3240\n",
            "Epoch 1105/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3868 - val_loss: 0.3220\n",
            "Epoch 1106/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3867 - val_loss: 0.3203\n",
            "Epoch 1107/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3863 - val_loss: 0.3252\n",
            "Epoch 1108/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3863 - val_loss: 0.3209\n",
            "Epoch 1109/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3865 - val_loss: 0.3246\n",
            "Epoch 1110/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3862 - val_loss: 0.3212\n",
            "Epoch 1111/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3864 - val_loss: 0.3192\n",
            "Epoch 1112/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3865 - val_loss: 0.3214\n",
            "Epoch 1113/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3864 - val_loss: 0.3218\n",
            "Epoch 1114/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3871 - val_loss: 0.3226\n",
            "Epoch 1115/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3868 - val_loss: 0.3235\n",
            "Epoch 1116/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3860 - val_loss: 0.3199\n",
            "Epoch 1117/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3866 - val_loss: 0.3221\n",
            "Epoch 1118/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3859 - val_loss: 0.3220\n",
            "Epoch 1119/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3857 - val_loss: 0.3272\n",
            "Epoch 1120/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3863 - val_loss: 0.3251\n",
            "Epoch 1121/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3863 - val_loss: 0.3260\n",
            "Epoch 1122/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3862 - val_loss: 0.3197\n",
            "Epoch 1123/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3863 - val_loss: 0.3244\n",
            "Epoch 1124/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3863 - val_loss: 0.3281\n",
            "Epoch 1125/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3859 - val_loss: 0.3274\n",
            "Epoch 1126/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3854 - val_loss: 0.3231\n",
            "Epoch 1127/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3862 - val_loss: 0.3256\n",
            "Epoch 1128/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3856 - val_loss: 0.3203\n",
            "Epoch 1129/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3867 - val_loss: 0.3257\n",
            "Epoch 1130/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3855 - val_loss: 0.3246\n",
            "Epoch 1131/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3866 - val_loss: 0.3270\n",
            "Epoch 1132/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3855 - val_loss: 0.3239\n",
            "Epoch 1133/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3859 - val_loss: 0.3217\n",
            "Epoch 1134/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3860 - val_loss: 0.3235\n",
            "Epoch 1135/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3859 - val_loss: 0.3241\n",
            "Epoch 1136/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3849 - val_loss: 0.3232\n",
            "Epoch 1137/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3866 - val_loss: 0.3272\n",
            "Epoch 1138/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3856 - val_loss: 0.3321\n",
            "Epoch 1139/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3861 - val_loss: 0.3339\n",
            "Epoch 1140/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3864 - val_loss: 0.3307\n",
            "Epoch 1141/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3857 - val_loss: 0.3265\n",
            "Epoch 1142/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3857 - val_loss: 0.3254\n",
            "Epoch 1143/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3853 - val_loss: 0.3282\n",
            "Epoch 1144/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3858 - val_loss: 0.3277\n",
            "Epoch 1145/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3852 - val_loss: 0.3276\n",
            "Epoch 1146/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3855 - val_loss: 0.3245\n",
            "Epoch 1147/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3855 - val_loss: 0.3253\n",
            "Epoch 1148/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3852 - val_loss: 0.3248\n",
            "Epoch 1149/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3856 - val_loss: 0.3256\n",
            "Epoch 1150/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3857 - val_loss: 0.3251\n",
            "Epoch 1151/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3856 - val_loss: 0.3259\n",
            "Epoch 1152/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3852 - val_loss: 0.3253\n",
            "Epoch 1153/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3852 - val_loss: 0.3272\n",
            "Epoch 1154/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3854 - val_loss: 0.3244\n",
            "Epoch 1155/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3856 - val_loss: 0.3274\n",
            "Epoch 1156/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3852 - val_loss: 0.3283\n",
            "Epoch 1157/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3855 - val_loss: 0.3285\n",
            "Epoch 1158/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3854 - val_loss: 0.3237\n",
            "Epoch 1159/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3846 - val_loss: 0.3314\n",
            "Epoch 1160/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3852 - val_loss: 0.3273\n",
            "Epoch 1161/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3852 - val_loss: 0.3268\n",
            "Epoch 1162/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3853 - val_loss: 0.3280\n",
            "Epoch 1163/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3852 - val_loss: 0.3315\n",
            "Epoch 1164/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3851 - val_loss: 0.3275\n",
            "Epoch 1165/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3853 - val_loss: 0.3250\n",
            "Epoch 1166/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3852 - val_loss: 0.3289\n",
            "Epoch 1167/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3850 - val_loss: 0.3267\n",
            "Epoch 1168/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3847 - val_loss: 0.3275\n",
            "Epoch 1169/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3850 - val_loss: 0.3310\n",
            "Epoch 1170/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3843 - val_loss: 0.3342\n",
            "Epoch 1171/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3851 - val_loss: 0.3336\n",
            "Epoch 1172/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3848 - val_loss: 0.3336\n",
            "Epoch 1173/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3848 - val_loss: 0.3296\n",
            "Epoch 1174/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3846 - val_loss: 0.3261\n",
            "Epoch 1175/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3851 - val_loss: 0.3266\n",
            "Epoch 1176/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3851 - val_loss: 0.3317\n",
            "Epoch 1177/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3850 - val_loss: 0.3274\n",
            "Epoch 1178/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3847 - val_loss: 0.3292\n",
            "Epoch 1179/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3848 - val_loss: 0.3322\n",
            "Epoch 1180/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3848 - val_loss: 0.3280\n",
            "Epoch 1181/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3852 - val_loss: 0.3284\n",
            "Epoch 1182/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3841 - val_loss: 0.3241\n",
            "Epoch 1183/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3848 - val_loss: 0.3275\n",
            "Epoch 1184/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3845 - val_loss: 0.3296\n",
            "Epoch 1185/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3849 - val_loss: 0.3300\n",
            "Epoch 1186/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3844 - val_loss: 0.3265\n",
            "Epoch 1187/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3844 - val_loss: 0.3293\n",
            "Epoch 1188/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3842 - val_loss: 0.3278\n",
            "Epoch 1189/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3846 - val_loss: 0.3268\n",
            "Epoch 1190/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3846 - val_loss: 0.3297\n",
            "Epoch 1191/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3845 - val_loss: 0.3309\n",
            "Epoch 1192/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3839 - val_loss: 0.3327\n",
            "Epoch 1193/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3839 - val_loss: 0.3290\n",
            "Epoch 1194/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3843 - val_loss: 0.3348\n",
            "Epoch 1195/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3846 - val_loss: 0.3308\n",
            "Epoch 1196/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3845 - val_loss: 0.3332\n",
            "Epoch 1197/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3841 - val_loss: 0.3324\n",
            "Epoch 1198/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3843 - val_loss: 0.3353\n",
            "Epoch 1199/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3847 - val_loss: 0.3344\n",
            "Epoch 1200/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3842 - val_loss: 0.3356\n",
            "Epoch 1201/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3840 - val_loss: 0.3334\n",
            "Epoch 1202/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3847 - val_loss: 0.3338\n",
            "Epoch 1203/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3840 - val_loss: 0.3338\n",
            "Epoch 1204/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3842 - val_loss: 0.3316\n",
            "Epoch 1205/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3839 - val_loss: 0.3318\n",
            "Epoch 1206/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3840 - val_loss: 0.3313\n",
            "Epoch 1207/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3837 - val_loss: 0.3317\n",
            "Epoch 1208/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3836 - val_loss: 0.3306\n",
            "Epoch 1209/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3843 - val_loss: 0.3331\n",
            "Epoch 1210/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3840 - val_loss: 0.3322\n",
            "Epoch 1211/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3835 - val_loss: 0.3292\n",
            "Epoch 1212/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3836 - val_loss: 0.3329\n",
            "Epoch 1213/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3838 - val_loss: 0.3322\n",
            "Epoch 1214/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3834 - val_loss: 0.3337\n",
            "Epoch 1215/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3836 - val_loss: 0.3311\n",
            "Epoch 1216/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3835 - val_loss: 0.3299\n",
            "Epoch 1217/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3838 - val_loss: 0.3290\n",
            "Epoch 1218/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3835 - val_loss: 0.3312\n",
            "Epoch 1219/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3842 - val_loss: 0.3326\n",
            "Epoch 1220/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3838 - val_loss: 0.3338\n",
            "Epoch 1221/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3836 - val_loss: 0.3341\n",
            "Epoch 1222/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3835 - val_loss: 0.3326\n",
            "Epoch 1223/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3838 - val_loss: 0.3275\n",
            "Epoch 1224/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3832 - val_loss: 0.3305\n",
            "Epoch 1225/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3842 - val_loss: 0.3312\n",
            "Epoch 1226/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3834 - val_loss: 0.3318\n",
            "Epoch 1227/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3829 - val_loss: 0.3305\n",
            "Epoch 1228/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3839 - val_loss: 0.3323\n",
            "Epoch 1229/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3829 - val_loss: 0.3323\n",
            "Epoch 1230/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3833 - val_loss: 0.3357\n",
            "Epoch 1231/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3832 - val_loss: 0.3345\n",
            "Epoch 1232/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3834 - val_loss: 0.3328\n",
            "Epoch 1233/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3837 - val_loss: 0.3352\n",
            "Epoch 1234/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3829 - val_loss: 0.3348\n",
            "Epoch 1235/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3833 - val_loss: 0.3371\n",
            "Epoch 1236/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3829 - val_loss: 0.3330\n",
            "Epoch 1237/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3832 - val_loss: 0.3302\n",
            "Epoch 1238/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3831 - val_loss: 0.3349\n",
            "Epoch 1239/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3829 - val_loss: 0.3378\n",
            "Epoch 1240/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3827 - val_loss: 0.3341\n",
            "Epoch 1241/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3829 - val_loss: 0.3334\n",
            "Epoch 1242/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3825 - val_loss: 0.3308\n",
            "Epoch 1243/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3836 - val_loss: 0.3359\n",
            "Epoch 1244/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3827 - val_loss: 0.3373\n",
            "Epoch 1245/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3837 - val_loss: 0.3380\n",
            "Epoch 1246/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3833 - val_loss: 0.3347\n",
            "Epoch 1247/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3829 - val_loss: 0.3370\n",
            "Epoch 1248/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3820 - val_loss: 0.3431\n",
            "Epoch 1249/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3831 - val_loss: 0.3403\n",
            "Epoch 1250/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3826 - val_loss: 0.3331\n",
            "Epoch 1251/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3827 - val_loss: 0.3386\n",
            "Epoch 1252/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3829 - val_loss: 0.3352\n",
            "Epoch 1253/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3825 - val_loss: 0.3372\n",
            "Epoch 1254/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3828 - val_loss: 0.3358\n",
            "Epoch 1255/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3825 - val_loss: 0.3378\n",
            "Epoch 1256/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3824 - val_loss: 0.3347\n",
            "Epoch 1257/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3823 - val_loss: 0.3353\n",
            "Epoch 1258/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3828 - val_loss: 0.3331\n",
            "Epoch 1259/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3835 - val_loss: 0.3397\n",
            "Epoch 1260/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3826 - val_loss: 0.3377\n",
            "Epoch 1261/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3821 - val_loss: 0.3380\n",
            "Epoch 1262/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3822 - val_loss: 0.3379\n",
            "Epoch 1263/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3824 - val_loss: 0.3394\n",
            "Epoch 1264/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3824 - val_loss: 0.3380\n",
            "Epoch 1265/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3824 - val_loss: 0.3377\n",
            "Epoch 1266/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3826 - val_loss: 0.3396\n",
            "Epoch 1267/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3822 - val_loss: 0.3361\n",
            "Epoch 1268/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3821 - val_loss: 0.3387\n",
            "Epoch 1269/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3824 - val_loss: 0.3400\n",
            "Epoch 1270/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3822 - val_loss: 0.3360\n",
            "Epoch 1271/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3820 - val_loss: 0.3387\n",
            "Epoch 1272/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3822 - val_loss: 0.3394\n",
            "Epoch 1273/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3824 - val_loss: 0.3386\n",
            "Epoch 1274/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3824 - val_loss: 0.3392\n",
            "Epoch 1275/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3820 - val_loss: 0.3403\n",
            "Epoch 1276/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3822 - val_loss: 0.3399\n",
            "Epoch 1277/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3815 - val_loss: 0.3395\n",
            "Epoch 1278/5000\n",
            "165/165 [==============================] - 0s 999us/step - loss: 0.3816 - val_loss: 0.3375\n",
            "Epoch 1279/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3827 - val_loss: 0.3409\n",
            "Epoch 1280/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3820 - val_loss: 0.3370\n",
            "Epoch 1281/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3818 - val_loss: 0.3383\n",
            "Epoch 1282/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3820 - val_loss: 0.3362\n",
            "Epoch 1283/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3812 - val_loss: 0.3367\n",
            "Epoch 1284/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3816 - val_loss: 0.3423\n",
            "Epoch 1285/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3815 - val_loss: 0.3461\n",
            "Epoch 1286/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3821 - val_loss: 0.3406\n",
            "Epoch 1287/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3815 - val_loss: 0.3438\n",
            "Epoch 1288/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3818 - val_loss: 0.3462\n",
            "Epoch 1289/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3820 - val_loss: 0.3452\n",
            "Epoch 1290/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3816 - val_loss: 0.3390\n",
            "Epoch 1291/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3820 - val_loss: 0.3425\n",
            "Epoch 1292/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3818 - val_loss: 0.3477\n",
            "Epoch 1293/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3816 - val_loss: 0.3428\n",
            "Epoch 1294/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3818 - val_loss: 0.3447\n",
            "Epoch 1295/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3813 - val_loss: 0.3425\n",
            "Epoch 1296/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3815 - val_loss: 0.3464\n",
            "Epoch 1297/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3811 - val_loss: 0.3457\n",
            "Epoch 1298/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3821 - val_loss: 0.3456\n",
            "Epoch 1299/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3818 - val_loss: 0.3436\n",
            "Epoch 1300/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3816 - val_loss: 0.3415\n",
            "Epoch 1301/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3818 - val_loss: 0.3423\n",
            "Epoch 1302/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3815 - val_loss: 0.3407\n",
            "Epoch 1303/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3813 - val_loss: 0.3410\n",
            "Epoch 1304/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3810 - val_loss: 0.3439\n",
            "Epoch 1305/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3807 - val_loss: 0.3505\n",
            "Epoch 1306/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3816 - val_loss: 0.3475\n",
            "Epoch 1307/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3813 - val_loss: 0.3445\n",
            "Epoch 1308/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3817 - val_loss: 0.3470\n",
            "Epoch 1309/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3812 - val_loss: 0.3449\n",
            "Epoch 1310/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3811 - val_loss: 0.3448\n",
            "Epoch 1311/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3808 - val_loss: 0.3465\n",
            "Epoch 1312/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3807 - val_loss: 0.3467\n",
            "Epoch 1313/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3819 - val_loss: 0.3500\n",
            "Epoch 1314/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3808 - val_loss: 0.3452\n",
            "Epoch 1315/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3809 - val_loss: 0.3503\n",
            "Epoch 1316/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3808 - val_loss: 0.3468\n",
            "Epoch 1317/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3812 - val_loss: 0.3523\n",
            "Epoch 1318/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3809 - val_loss: 0.3474\n",
            "Epoch 1319/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3802 - val_loss: 0.3435\n",
            "Epoch 1320/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3805 - val_loss: 0.3521\n",
            "Epoch 1321/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3807 - val_loss: 0.3491\n",
            "Epoch 1322/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3805 - val_loss: 0.3530\n",
            "Epoch 1323/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3805 - val_loss: 0.3495\n",
            "Epoch 1324/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3807 - val_loss: 0.3463\n",
            "Epoch 1325/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3806 - val_loss: 0.3448\n",
            "Epoch 1326/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3803 - val_loss: 0.3483\n",
            "Epoch 1327/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3806 - val_loss: 0.3485\n",
            "Epoch 1328/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3804 - val_loss: 0.3463\n",
            "Epoch 1329/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3806 - val_loss: 0.3504\n",
            "Epoch 1330/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3807 - val_loss: 0.3484\n",
            "Epoch 1331/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3803 - val_loss: 0.3457\n",
            "Epoch 1332/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3804 - val_loss: 0.3486\n",
            "Epoch 1333/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3806 - val_loss: 0.3543\n",
            "Epoch 1334/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3805 - val_loss: 0.3514\n",
            "Epoch 1335/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3805 - val_loss: 0.3521\n",
            "Epoch 1336/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3801 - val_loss: 0.3504\n",
            "Epoch 1337/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3801 - val_loss: 0.3524\n",
            "Epoch 1338/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3802 - val_loss: 0.3509\n",
            "Epoch 1339/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3806 - val_loss: 0.3504\n",
            "Epoch 1340/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3800 - val_loss: 0.3498\n",
            "Epoch 1341/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3802 - val_loss: 0.3504\n",
            "Epoch 1342/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3797 - val_loss: 0.3537\n",
            "Epoch 1343/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3805 - val_loss: 0.3479\n",
            "Epoch 1344/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3805 - val_loss: 0.3496\n",
            "Epoch 1345/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3802 - val_loss: 0.3547\n",
            "Epoch 1346/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3803 - val_loss: 0.3508\n",
            "Epoch 1347/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3799 - val_loss: 0.3501\n",
            "Epoch 1348/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3802 - val_loss: 0.3535\n",
            "Epoch 1349/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3798 - val_loss: 0.3481\n",
            "Epoch 1350/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3800 - val_loss: 0.3514\n",
            "Epoch 1351/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3798 - val_loss: 0.3528\n",
            "Epoch 1352/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3799 - val_loss: 0.3547\n",
            "Epoch 1353/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3797 - val_loss: 0.3538\n",
            "Epoch 1354/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3793 - val_loss: 0.3539\n",
            "Epoch 1355/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3800 - val_loss: 0.3553\n",
            "Epoch 1356/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3799 - val_loss: 0.3547\n",
            "Epoch 1357/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3796 - val_loss: 0.3466\n",
            "Epoch 1358/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3798 - val_loss: 0.3532\n",
            "Epoch 1359/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3794 - val_loss: 0.3518\n",
            "Epoch 1360/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3800 - val_loss: 0.3534\n",
            "Epoch 1361/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3793 - val_loss: 0.3573\n",
            "Epoch 1362/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3797 - val_loss: 0.3582\n",
            "Epoch 1363/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3789 - val_loss: 0.3592\n",
            "Epoch 1364/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3795 - val_loss: 0.3574\n",
            "Epoch 1365/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3798 - val_loss: 0.3569\n",
            "Epoch 1366/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3799 - val_loss: 0.3582\n",
            "Epoch 1367/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3792 - val_loss: 0.3541\n",
            "Epoch 1368/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3799 - val_loss: 0.3504\n",
            "Epoch 1369/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3791 - val_loss: 0.3581\n",
            "Epoch 1370/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3793 - val_loss: 0.3551\n",
            "Epoch 1371/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3792 - val_loss: 0.3588\n",
            "Epoch 1372/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3796 - val_loss: 0.3604\n",
            "Epoch 1373/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3790 - val_loss: 0.3631\n",
            "Epoch 1374/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3791 - val_loss: 0.3622\n",
            "Epoch 1375/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3789 - val_loss: 0.3627\n",
            "Epoch 1376/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3792 - val_loss: 0.3635\n",
            "Epoch 1377/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3789 - val_loss: 0.3576\n",
            "Epoch 1378/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3789 - val_loss: 0.3561\n",
            "Epoch 1379/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3788 - val_loss: 0.3563\n",
            "Epoch 1380/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3787 - val_loss: 0.3541\n",
            "Epoch 1381/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3789 - val_loss: 0.3493\n",
            "Epoch 1382/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3787 - val_loss: 0.3522\n",
            "Epoch 1383/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3792 - val_loss: 0.3530\n",
            "Epoch 1384/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3790 - val_loss: 0.3583\n",
            "Epoch 1385/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3785 - val_loss: 0.3553\n",
            "Epoch 1386/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3788 - val_loss: 0.3555\n",
            "Epoch 1387/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3788 - val_loss: 0.3587\n",
            "Epoch 1388/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3787 - val_loss: 0.3566\n",
            "Epoch 1389/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3787 - val_loss: 0.3607\n",
            "Epoch 1390/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3790 - val_loss: 0.3623\n",
            "Epoch 1391/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3783 - val_loss: 0.3632\n",
            "Epoch 1392/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3795 - val_loss: 0.3613\n",
            "Epoch 1393/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3786 - val_loss: 0.3624\n",
            "Epoch 1394/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3794 - val_loss: 0.3657\n",
            "Epoch 1395/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3784 - val_loss: 0.3588\n",
            "Epoch 1396/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3781 - val_loss: 0.3598\n",
            "Epoch 1397/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3786 - val_loss: 0.3685\n",
            "Epoch 1398/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3791 - val_loss: 0.3659\n",
            "Epoch 1399/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3786 - val_loss: 0.3599\n",
            "Epoch 1400/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3787 - val_loss: 0.3648\n",
            "Epoch 1401/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3781 - val_loss: 0.3592\n",
            "Epoch 1402/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3783 - val_loss: 0.3647\n",
            "Epoch 1403/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3780 - val_loss: 0.3632\n",
            "Epoch 1404/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3780 - val_loss: 0.3623\n",
            "Epoch 1405/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3780 - val_loss: 0.3568\n",
            "Epoch 1406/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3781 - val_loss: 0.3589\n",
            "Epoch 1407/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3786 - val_loss: 0.3617\n",
            "Epoch 1408/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3786 - val_loss: 0.3676\n",
            "Epoch 1409/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3773 - val_loss: 0.3642\n",
            "Epoch 1410/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3788 - val_loss: 0.3625\n",
            "Epoch 1411/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3781 - val_loss: 0.3628\n",
            "Epoch 1412/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3776 - val_loss: 0.3604\n",
            "Epoch 1413/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3782 - val_loss: 0.3562\n",
            "Epoch 1414/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3784 - val_loss: 0.3642\n",
            "Epoch 1415/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3784 - val_loss: 0.3610\n",
            "Epoch 1416/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3777 - val_loss: 0.3629\n",
            "Epoch 1417/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3776 - val_loss: 0.3646\n",
            "Epoch 1418/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3782 - val_loss: 0.3610\n",
            "Epoch 1419/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3778 - val_loss: 0.3654\n",
            "Epoch 1420/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3786 - val_loss: 0.3635\n",
            "Epoch 1421/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3774 - val_loss: 0.3622\n",
            "Epoch 1422/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3781 - val_loss: 0.3633\n",
            "Epoch 1423/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3776 - val_loss: 0.3656\n",
            "Epoch 1424/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3778 - val_loss: 0.3716\n",
            "Epoch 1425/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3773 - val_loss: 0.3645\n",
            "Epoch 1426/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3780 - val_loss: 0.3695\n",
            "Epoch 1427/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3769 - val_loss: 0.3721\n",
            "Epoch 1428/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3777 - val_loss: 0.3724\n",
            "Epoch 1429/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3776 - val_loss: 0.3683\n",
            "Epoch 1430/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3775 - val_loss: 0.3628\n",
            "Epoch 1431/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3781 - val_loss: 0.3627\n",
            "Epoch 1432/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3775 - val_loss: 0.3638\n",
            "Epoch 1433/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3775 - val_loss: 0.3656\n",
            "Epoch 1434/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3773 - val_loss: 0.3586\n",
            "Epoch 1435/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3768 - val_loss: 0.3659\n",
            "Epoch 1436/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3779 - val_loss: 0.3720\n",
            "Epoch 1437/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3768 - val_loss: 0.3607\n",
            "Epoch 1438/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3769 - val_loss: 0.3705\n",
            "Epoch 1439/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3770 - val_loss: 0.3716\n",
            "Epoch 1440/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3765 - val_loss: 0.3674\n",
            "Epoch 1441/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3773 - val_loss: 0.3669\n",
            "Epoch 1442/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3772 - val_loss: 0.3686\n",
            "Epoch 1443/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3771 - val_loss: 0.3649\n",
            "Epoch 1444/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3770 - val_loss: 0.3663\n",
            "Epoch 1445/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3763 - val_loss: 0.3692\n",
            "Epoch 1446/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3772 - val_loss: 0.3739\n",
            "Epoch 1447/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3765 - val_loss: 0.3715\n",
            "Epoch 1448/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3778 - val_loss: 0.3694\n",
            "Epoch 1449/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3771 - val_loss: 0.3654\n",
            "Epoch 1450/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3768 - val_loss: 0.3719\n",
            "Epoch 1451/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3764 - val_loss: 0.3660\n",
            "Epoch 1452/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3774 - val_loss: 0.3729\n",
            "Epoch 1453/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3773 - val_loss: 0.3773\n",
            "Epoch 1454/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3765 - val_loss: 0.3707\n",
            "Epoch 1455/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3765 - val_loss: 0.3754\n",
            "Epoch 1456/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3769 - val_loss: 0.3697\n",
            "Epoch 1457/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3761 - val_loss: 0.3621\n",
            "Epoch 1458/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3766 - val_loss: 0.3742\n",
            "Epoch 1459/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3757 - val_loss: 0.3692\n",
            "Epoch 1460/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3773 - val_loss: 0.3790\n",
            "Epoch 1461/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3762 - val_loss: 0.3759\n",
            "Epoch 1462/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3767 - val_loss: 0.3686\n",
            "Epoch 1463/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3762 - val_loss: 0.3693\n",
            "Epoch 1464/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3764 - val_loss: 0.3720\n",
            "Epoch 1465/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3767 - val_loss: 0.3705\n",
            "Epoch 1466/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3762 - val_loss: 0.3730\n",
            "Epoch 1467/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3759 - val_loss: 0.3706\n",
            "Epoch 1468/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3763 - val_loss: 0.3686\n",
            "Epoch 1469/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3762 - val_loss: 0.3724\n",
            "Epoch 1470/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3759 - val_loss: 0.3752\n",
            "Epoch 1471/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3758 - val_loss: 0.3693\n",
            "Epoch 1472/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3758 - val_loss: 0.3718\n",
            "Epoch 1473/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3762 - val_loss: 0.3681\n",
            "Epoch 1474/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3759 - val_loss: 0.3733\n",
            "Epoch 1475/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3760 - val_loss: 0.3707\n",
            "Epoch 1476/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3767 - val_loss: 0.3740\n",
            "Epoch 1477/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3759 - val_loss: 0.3765\n",
            "Epoch 1478/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3753 - val_loss: 0.3815\n",
            "Epoch 1479/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3757 - val_loss: 0.3780\n",
            "Epoch 1480/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3762 - val_loss: 0.3744\n",
            "Epoch 1481/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3755 - val_loss: 0.3761\n",
            "Epoch 1482/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3759 - val_loss: 0.3792\n",
            "Epoch 1483/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3756 - val_loss: 0.3721\n",
            "Epoch 1484/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3755 - val_loss: 0.3781\n",
            "Epoch 1485/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3761 - val_loss: 0.3831\n",
            "Epoch 1486/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3755 - val_loss: 0.3816\n",
            "Epoch 1487/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3756 - val_loss: 0.3746\n",
            "Epoch 1488/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3756 - val_loss: 0.3717\n",
            "Epoch 1489/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3752 - val_loss: 0.3764\n",
            "Epoch 1490/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3745 - val_loss: 0.3731\n",
            "Epoch 1491/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3763 - val_loss: 0.3769\n",
            "Epoch 1492/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3759 - val_loss: 0.3736\n",
            "Epoch 1493/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3754 - val_loss: 0.3785\n",
            "Epoch 1494/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3753 - val_loss: 0.3846\n",
            "Epoch 1495/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3750 - val_loss: 0.3763\n",
            "Epoch 1496/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3756 - val_loss: 0.3800\n",
            "Epoch 1497/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3754 - val_loss: 0.3852\n",
            "Epoch 1498/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3753 - val_loss: 0.3809\n",
            "Epoch 1499/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3758 - val_loss: 0.3824\n",
            "Epoch 1500/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3752 - val_loss: 0.3795\n",
            "Epoch 1501/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3752 - val_loss: 0.3872\n",
            "Epoch 1502/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3753 - val_loss: 0.3807\n",
            "Epoch 1503/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3749 - val_loss: 0.3718\n",
            "Epoch 1504/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3748 - val_loss: 0.3791\n",
            "Epoch 1505/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3747 - val_loss: 0.3804\n",
            "Epoch 1506/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3750 - val_loss: 0.3742\n",
            "Epoch 1507/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3749 - val_loss: 0.3810\n",
            "Epoch 1508/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3746 - val_loss: 0.3796\n",
            "Epoch 1509/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3748 - val_loss: 0.3788\n",
            "Epoch 1510/5000\n",
            "165/165 [==============================] - 0s 991us/step - loss: 0.3745 - val_loss: 0.3804\n",
            "Epoch 1511/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3754 - val_loss: 0.3788\n",
            "Epoch 1512/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3749 - val_loss: 0.3822\n",
            "Epoch 1513/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3747 - val_loss: 0.3820\n",
            "Epoch 1514/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3750 - val_loss: 0.3869\n",
            "Epoch 1515/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3745 - val_loss: 0.3761\n",
            "Epoch 1516/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3743 - val_loss: 0.3800\n",
            "Epoch 1517/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3743 - val_loss: 0.3795\n",
            "Epoch 1518/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3747 - val_loss: 0.3794\n",
            "Epoch 1519/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3745 - val_loss: 0.3785\n",
            "Epoch 1520/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3743 - val_loss: 0.3811\n",
            "Epoch 1521/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3750 - val_loss: 0.3798\n",
            "Epoch 1522/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3739 - val_loss: 0.3875\n",
            "Epoch 1523/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3743 - val_loss: 0.3907\n",
            "Epoch 1524/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3742 - val_loss: 0.3800\n",
            "Epoch 1525/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3744 - val_loss: 0.3808\n",
            "Epoch 1526/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3740 - val_loss: 0.3863\n",
            "Epoch 1527/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3754 - val_loss: 0.3875\n",
            "Epoch 1528/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3740 - val_loss: 0.3923\n",
            "Epoch 1529/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3754 - val_loss: 0.3971\n",
            "Epoch 1530/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3740 - val_loss: 0.3848\n",
            "Epoch 1531/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3741 - val_loss: 0.3885\n",
            "Epoch 1532/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3739 - val_loss: 0.3855\n",
            "Epoch 1533/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3746 - val_loss: 0.3861\n",
            "Epoch 1534/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3736 - val_loss: 0.3919\n",
            "Epoch 1535/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3739 - val_loss: 0.3962\n",
            "Epoch 1536/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3738 - val_loss: 0.3900\n",
            "Epoch 1537/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3736 - val_loss: 0.3824\n",
            "Epoch 1538/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3736 - val_loss: 0.3868\n",
            "Epoch 1539/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3733 - val_loss: 0.3906\n",
            "Epoch 1540/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3735 - val_loss: 0.3882\n",
            "Epoch 1541/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3736 - val_loss: 0.3886\n",
            "Epoch 1542/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3737 - val_loss: 0.3996\n",
            "Epoch 1543/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3733 - val_loss: 0.3959\n",
            "Epoch 1544/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3735 - val_loss: 0.3964\n",
            "Epoch 1545/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3724 - val_loss: 0.3926\n",
            "Epoch 1546/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3741 - val_loss: 0.3903\n",
            "Epoch 1547/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3733 - val_loss: 0.3887\n",
            "Epoch 1548/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3729 - val_loss: 0.3875\n",
            "Epoch 1549/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3736 - val_loss: 0.3877\n",
            "Epoch 1550/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3732 - val_loss: 0.3911\n",
            "Epoch 1551/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3730 - val_loss: 0.3965\n",
            "Epoch 1552/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3735 - val_loss: 0.3937\n",
            "Epoch 1553/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3722 - val_loss: 0.3882\n",
            "Epoch 1554/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3739 - val_loss: 0.4008\n",
            "Epoch 1555/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3733 - val_loss: 0.3970\n",
            "Epoch 1556/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3736 - val_loss: 0.3981\n",
            "Epoch 1557/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3724 - val_loss: 0.3937\n",
            "Epoch 1558/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3730 - val_loss: 0.3937\n",
            "Epoch 1559/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3727 - val_loss: 0.4051\n",
            "Epoch 1560/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3729 - val_loss: 0.3981\n",
            "Epoch 1561/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3729 - val_loss: 0.3916\n",
            "Epoch 1562/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3723 - val_loss: 0.3903\n",
            "Epoch 1563/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3728 - val_loss: 0.3847\n",
            "Epoch 1564/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3735 - val_loss: 0.3928\n",
            "Epoch 1565/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3725 - val_loss: 0.3927\n",
            "Epoch 1566/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3726 - val_loss: 0.3860\n",
            "Epoch 1567/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3731 - val_loss: 0.3926\n",
            "Epoch 1568/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3729 - val_loss: 0.3982\n",
            "Epoch 1569/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3730 - val_loss: 0.3994\n",
            "Epoch 1570/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3730 - val_loss: 0.3994\n",
            "Epoch 1571/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3723 - val_loss: 0.3956\n",
            "Epoch 1572/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3722 - val_loss: 0.3986\n",
            "Epoch 1573/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3725 - val_loss: 0.3992\n",
            "Epoch 1574/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3721 - val_loss: 0.3841\n",
            "Epoch 1575/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3721 - val_loss: 0.3946\n",
            "Epoch 1576/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3719 - val_loss: 0.3968\n",
            "Epoch 1577/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3722 - val_loss: 0.3874\n",
            "Epoch 1578/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3722 - val_loss: 0.3866\n",
            "Epoch 1579/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3723 - val_loss: 0.4011\n",
            "Epoch 1580/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3724 - val_loss: 0.4069\n",
            "Epoch 1581/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3726 - val_loss: 0.3910\n",
            "Epoch 1582/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3721 - val_loss: 0.4028\n",
            "Epoch 1583/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3724 - val_loss: 0.3937\n",
            "Epoch 1584/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3720 - val_loss: 0.4007\n",
            "Epoch 1585/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3716 - val_loss: 0.3917\n",
            "Epoch 1586/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3714 - val_loss: 0.3895\n",
            "Epoch 1587/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3718 - val_loss: 0.4038\n",
            "Epoch 1588/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3718 - val_loss: 0.3945\n",
            "Epoch 1589/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3722 - val_loss: 0.4026\n",
            "Epoch 1590/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3717 - val_loss: 0.4020\n",
            "Epoch 1591/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3718 - val_loss: 0.3984\n",
            "Epoch 1592/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3718 - val_loss: 0.4004\n",
            "Epoch 1593/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3718 - val_loss: 0.4011\n",
            "Epoch 1594/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3717 - val_loss: 0.4010\n",
            "Epoch 1595/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3716 - val_loss: 0.3988\n",
            "Epoch 1596/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3717 - val_loss: 0.3997\n",
            "Epoch 1597/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3715 - val_loss: 0.3956\n",
            "Epoch 1598/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3710 - val_loss: 0.3956\n",
            "Epoch 1599/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3716 - val_loss: 0.4036\n",
            "Epoch 1600/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3714 - val_loss: 0.3969\n",
            "Epoch 1601/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3708 - val_loss: 0.4074\n",
            "Epoch 1602/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3714 - val_loss: 0.3968\n",
            "Epoch 1603/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3709 - val_loss: 0.3965\n",
            "Epoch 1604/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3706 - val_loss: 0.4051\n",
            "Epoch 1605/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3711 - val_loss: 0.4089\n",
            "Epoch 1606/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3707 - val_loss: 0.4039\n",
            "Epoch 1607/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3709 - val_loss: 0.4073\n",
            "Epoch 1608/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3702 - val_loss: 0.3974\n",
            "Epoch 1609/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3706 - val_loss: 0.4030\n",
            "Epoch 1610/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3699 - val_loss: 0.4138\n",
            "Epoch 1611/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3707 - val_loss: 0.4031\n",
            "Epoch 1612/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3697 - val_loss: 0.4000\n",
            "Epoch 1613/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3706 - val_loss: 0.4091\n",
            "Epoch 1614/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3707 - val_loss: 0.4106\n",
            "Epoch 1615/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3703 - val_loss: 0.4100\n",
            "Epoch 1616/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3704 - val_loss: 0.4169\n",
            "Epoch 1617/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3692 - val_loss: 0.4116\n",
            "Epoch 1618/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3695 - val_loss: 0.4121\n",
            "Epoch 1619/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3691 - val_loss: 0.4096\n",
            "Epoch 1620/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3686 - val_loss: 0.4033\n",
            "Epoch 1621/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3686 - val_loss: 0.4020\n",
            "Epoch 1622/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3678 - val_loss: 0.4028\n",
            "Epoch 1623/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3682 - val_loss: 0.4081\n",
            "Epoch 1624/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3681 - val_loss: 0.4071\n",
            "Epoch 1625/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3675 - val_loss: 0.3983\n",
            "Epoch 1626/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3676 - val_loss: 0.4040\n",
            "Epoch 1627/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3676 - val_loss: 0.4003\n",
            "Epoch 1628/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3675 - val_loss: 0.4038\n",
            "Epoch 1629/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3682 - val_loss: 0.4022\n",
            "Epoch 1630/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3672 - val_loss: 0.3972\n",
            "Epoch 1631/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3681 - val_loss: 0.3988\n",
            "Epoch 1632/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3678 - val_loss: 0.3978\n",
            "Epoch 1633/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3666 - val_loss: 0.3987\n",
            "Epoch 1634/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3676 - val_loss: 0.3967\n",
            "Epoch 1635/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3673 - val_loss: 0.3952\n",
            "Epoch 1636/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3665 - val_loss: 0.4021\n",
            "Epoch 1637/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3668 - val_loss: 0.4001\n",
            "Epoch 1638/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3665 - val_loss: 0.4013\n",
            "Epoch 1639/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3675 - val_loss: 0.4088\n",
            "Epoch 1640/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3672 - val_loss: 0.4011\n",
            "Epoch 1641/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3661 - val_loss: 0.4110\n",
            "Epoch 1642/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3673 - val_loss: 0.4087\n",
            "Epoch 1643/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3669 - val_loss: 0.4084\n",
            "Epoch 1644/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3663 - val_loss: 0.4006\n",
            "Epoch 1645/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3660 - val_loss: 0.4018\n",
            "Epoch 1646/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3666 - val_loss: 0.3990\n",
            "Epoch 1647/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3676 - val_loss: 0.4072\n",
            "Epoch 1648/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3665 - val_loss: 0.4058\n",
            "Epoch 1649/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3665 - val_loss: 0.4039\n",
            "Epoch 1650/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3654 - val_loss: 0.4009\n",
            "Epoch 1651/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3658 - val_loss: 0.4015\n",
            "Epoch 1652/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3660 - val_loss: 0.4041\n",
            "Epoch 1653/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3662 - val_loss: 0.4077\n",
            "Epoch 1654/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3664 - val_loss: 0.4068\n",
            "Epoch 1655/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3656 - val_loss: 0.4072\n",
            "Epoch 1656/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3656 - val_loss: 0.4073\n",
            "Epoch 1657/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3652 - val_loss: 0.4043\n",
            "Epoch 1658/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3654 - val_loss: 0.4017\n",
            "Epoch 1659/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3652 - val_loss: 0.4064\n",
            "Epoch 1660/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3647 - val_loss: 0.4053\n",
            "Epoch 1661/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3658 - val_loss: 0.4089\n",
            "Epoch 1662/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3650 - val_loss: 0.4031\n",
            "Epoch 1663/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3647 - val_loss: 0.4078\n",
            "Epoch 1664/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3651 - val_loss: 0.4078\n",
            "Epoch 1665/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3643 - val_loss: 0.4084\n",
            "Epoch 1666/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3649 - val_loss: 0.4058\n",
            "Epoch 1667/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3649 - val_loss: 0.4073\n",
            "Epoch 1668/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3653 - val_loss: 0.4029\n",
            "Epoch 1669/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3650 - val_loss: 0.4020\n",
            "Epoch 1670/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3646 - val_loss: 0.4079\n",
            "Epoch 1671/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3640 - val_loss: 0.4129\n",
            "Epoch 1672/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3643 - val_loss: 0.4121\n",
            "Epoch 1673/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3641 - val_loss: 0.4153\n",
            "Epoch 1674/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3640 - val_loss: 0.4118\n",
            "Epoch 1675/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3647 - val_loss: 0.4088\n",
            "Epoch 1676/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3634 - val_loss: 0.4144\n",
            "Epoch 1677/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3644 - val_loss: 0.4111\n",
            "Epoch 1678/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3632 - val_loss: 0.4101\n",
            "Epoch 1679/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3641 - val_loss: 0.4108\n",
            "Epoch 1680/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3639 - val_loss: 0.4136\n",
            "Epoch 1681/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3632 - val_loss: 0.4127\n",
            "Epoch 1682/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3635 - val_loss: 0.4139\n",
            "Epoch 1683/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3637 - val_loss: 0.4138\n",
            "Epoch 1684/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3632 - val_loss: 0.4125\n",
            "Epoch 1685/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3634 - val_loss: 0.4132\n",
            "Epoch 1686/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3632 - val_loss: 0.4071\n",
            "Epoch 1687/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3628 - val_loss: 0.4064\n",
            "Epoch 1688/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3627 - val_loss: 0.4129\n",
            "Epoch 1689/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3629 - val_loss: 0.4088\n",
            "Epoch 1690/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3632 - val_loss: 0.4044\n",
            "Epoch 1691/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3627 - val_loss: 0.4058\n",
            "Epoch 1692/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3630 - val_loss: 0.4100\n",
            "Epoch 1693/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3631 - val_loss: 0.4074\n",
            "Epoch 1694/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3630 - val_loss: 0.4046\n",
            "Epoch 1695/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3627 - val_loss: 0.4191\n",
            "Epoch 1696/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3624 - val_loss: 0.4207\n",
            "Epoch 1697/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3627 - val_loss: 0.4162\n",
            "Epoch 1698/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3620 - val_loss: 0.4152\n",
            "Epoch 1699/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3624 - val_loss: 0.4185\n",
            "Epoch 1700/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3626 - val_loss: 0.4169\n",
            "Epoch 1701/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3618 - val_loss: 0.4164\n",
            "Epoch 1702/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3623 - val_loss: 0.4073\n",
            "Epoch 1703/5000\n",
            "123/165 [=====================>........] - ETA: 0s - loss: 0.3567Restoring model weights from the end of the best epoch: 703.\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3621 - val_loss: 0.4076\n",
            "Epoch 1703: early stopping\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 3ms/step - loss: 1.5576\n",
            "EXPECTED:\n",
            "    d18O_cel_mean  d18O_cel_variance\n",
            "0       26.663818           0.574594\n",
            "1       26.663818           0.574594\n",
            "2       26.663818           0.574594\n",
            "3       27.559140           0.780698\n",
            "4       27.559140           0.780698\n",
            "5       27.559140           0.780698\n",
            "6       27.559140           0.780698\n",
            "7       27.559140           0.780698\n",
            "8       27.559140           0.780698\n",
            "9       27.559140           0.780698\n",
            "10      27.559140           0.780698\n",
            "11      27.559140           0.780698\n",
            "12      27.559140           0.780698\n",
            "13      27.260748           0.830341\n",
            "14      27.260748           0.830341\n",
            "15      27.260748           0.830341\n",
            "16      27.260748           0.830341\n",
            "17      27.260748           0.830341\n",
            "18      27.260748           0.830341\n",
            "19      27.260748           0.830341\n",
            "20      27.260748           0.830341\n",
            "21      27.260748           0.830341\n",
            "22      27.260748           0.830341\n",
            "23      27.260748           0.830341\n",
            "24      27.260748           0.830341\n",
            "25      27.260748           0.830341\n",
            "26      27.260748           0.830341\n",
            "27      27.260748           0.830341\n",
            "28      27.260748           0.830341\n",
            "29      27.260748           0.830341\n",
            "30      27.260748           0.830341\n",
            "31      27.260748           0.830341\n",
            "32      27.260748           0.830341\n",
            "33      27.260748           0.830341\n",
            "34      27.260748           0.830341\n",
            "35      27.260748           0.830341\n",
            "36      27.260748           0.830341\n",
            "37      27.260748           0.830341\n",
            "38      27.260748           0.830341\n",
            "39      27.260748           0.830341\n",
            "40      27.260748           0.830341\n",
            "41      27.260748           0.830341\n",
            "42      27.260748           0.830341\n",
            "43      27.260748           0.830341\n",
            "44      27.260748           0.830341\n",
            "45      27.260748           0.830341\n",
            "46      27.260748           0.830341\n",
            "47      27.260748           0.830341\n",
            "48      24.964000           0.108138\n",
            "49      24.964000           0.108138\n",
            "50      24.964000           0.108138\n",
            "51      24.964000           0.108138\n",
            "52      24.964000           0.108138\n",
            "53      24.964000           0.108138\n",
            "54      24.964000           0.108138\n",
            "55      24.964000           0.108138\n",
            "56      24.964000           0.108138\n",
            "57      24.964000           0.108138\n",
            "58      23.752000           0.524370\n",
            "59      23.752000           0.524370\n",
            "60      23.752000           0.524370\n",
            "61      23.752000           0.524370\n",
            "62      23.752000           0.524370\n",
            "\n",
            "PREDICTED:\n",
            "    d18O_cel_mean  d18O_cel_variance\n",
            "0       25.902311           1.343933\n",
            "1       25.902311           1.343933\n",
            "2       25.902311           1.343933\n",
            "3       24.520834           2.342631\n",
            "4       24.520834           2.342631\n",
            "5       24.520834           2.342631\n",
            "6       24.520834           2.342631\n",
            "7       24.520834           2.342631\n",
            "8       24.520834           2.342631\n",
            "9       24.520834           2.342631\n",
            "10      24.520834           2.342631\n",
            "11      24.520834           2.342631\n",
            "12      24.520834           2.342631\n",
            "13      24.602015           2.284580\n",
            "14      24.602015           2.284580\n",
            "15      24.602015           2.284580\n",
            "16      24.602015           2.284580\n",
            "17      24.602015           2.284580\n",
            "18      24.602015           2.284580\n",
            "19      24.602015           2.284580\n",
            "20      24.602015           2.284580\n",
            "21      24.602015           2.284580\n",
            "22      24.602015           2.284580\n",
            "23      24.602015           2.284580\n",
            "24      24.602015           2.284580\n",
            "25      24.602015           2.284580\n",
            "26      24.602015           2.284580\n",
            "27      24.602015           2.284580\n",
            "28      24.602015           2.284580\n",
            "29      24.602015           2.284580\n",
            "30      24.602015           2.284580\n",
            "31      24.602015           2.284580\n",
            "32      24.602015           2.284580\n",
            "33      24.602015           2.284580\n",
            "34      24.602015           2.284580\n",
            "35      24.602015           2.284580\n",
            "36      24.602015           2.284580\n",
            "37      24.602015           2.284580\n",
            "38      24.602015           2.284580\n",
            "39      24.602015           2.284580\n",
            "40      24.602015           2.284580\n",
            "41      24.602015           2.284580\n",
            "42      24.602015           2.284580\n",
            "43      24.602015           2.284580\n",
            "44      24.602015           2.284580\n",
            "45      24.602015           2.284580\n",
            "46      24.602015           2.284580\n",
            "47      24.602015           2.284580\n",
            "48      24.869991           2.696240\n",
            "49      24.869991           2.696240\n",
            "50      24.869991           2.696240\n",
            "51      24.869991           2.696240\n",
            "52      24.869991           2.696240\n",
            "53      24.869991           2.696240\n",
            "54      24.869991           2.696240\n",
            "55      24.869991           2.696240\n",
            "56      24.869991           2.696240\n",
            "57      24.869991           2.696240\n",
            "58      24.835747           2.748287\n",
            "59      24.835747           2.748287\n",
            "60      24.835747           2.748287\n",
            "61      24.835747           2.748287\n",
            "62      24.835747           2.748287\n",
            "RMSE: 2.348332148990312\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2023-07-18 16:51:57.832476: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype double and shape [63,12]\n",
            "\t [[{{node Placeholder/_0}}]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2) Ungrouped, fixed"
      ],
      "metadata": {
        "id": "yIQGGzsIup_d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ungrouped_fixed = {\n",
        "    'TRAIN' : os.path.join(FP_ROOT, \"amazon_sample_data/uc_davis_2023_08_12_train_fixed_ungrouped.csv\"),\n",
        "    'TEST' : os.path.join(FP_ROOT, \"amazon_sample_data/uc_davis_2023_08_12_test_fixed_ungrouped.csv\"),\n",
        "    'VALIDATION' : os.path.join(FP_ROOT, \"amazon_sample_data/uc_davis_2023_08_12_validation_fixed_ungrouped.csv\"),\n",
        "}\n",
        "\n",
        "ungrouped_fixed_scaled = load_and_scale(ungrouped_fixed)\n",
        "train_and_evaluate(ungrouped_fixed_scaled, \"ungrouped_fixed\", training_batch_size=3)"
      ],
      "metadata": {
        "id": "-TkJGJ9Xux24",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "67789058-f6ca-4b05-c6ab-eb959c70c0d5"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Epoch 616/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3918 - val_loss: 0.6993\n",
            "Epoch 617/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3916 - val_loss: 0.7145\n",
            "Epoch 618/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3911 - val_loss: 0.7671\n",
            "Epoch 619/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3912 - val_loss: 0.7525\n",
            "Epoch 620/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3910 - val_loss: 0.7139\n",
            "Epoch 621/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3906 - val_loss: 0.7462\n",
            "Epoch 622/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3899 - val_loss: 0.7366\n",
            "Epoch 623/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3894 - val_loss: 0.7458\n",
            "Epoch 624/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3898 - val_loss: 0.7041\n",
            "Epoch 625/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3907 - val_loss: 0.7251\n",
            "Epoch 626/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3891 - val_loss: 0.7297\n",
            "Epoch 627/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3900 - val_loss: 0.7520\n",
            "Epoch 628/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3897 - val_loss: 0.7095\n",
            "Epoch 629/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3899 - val_loss: 0.7355\n",
            "Epoch 630/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3891 - val_loss: 0.7192\n",
            "Epoch 631/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3901 - val_loss: 0.7000\n",
            "Epoch 632/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3895 - val_loss: 0.6899\n",
            "Epoch 633/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3888 - val_loss: 0.7171\n",
            "Epoch 634/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3884 - val_loss: 0.7152\n",
            "Epoch 635/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3881 - val_loss: 0.7150\n",
            "Epoch 636/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3889 - val_loss: 0.7271\n",
            "Epoch 637/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3885 - val_loss: 0.7670\n",
            "Epoch 638/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3881 - val_loss: 0.7112\n",
            "Epoch 639/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3881 - val_loss: 0.7167\n",
            "Epoch 640/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3900 - val_loss: 0.7320\n",
            "Epoch 641/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3875 - val_loss: 0.7491\n",
            "Epoch 642/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3875 - val_loss: 0.7262\n",
            "Epoch 643/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3871 - val_loss: 0.7291\n",
            "Epoch 644/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3876 - val_loss: 0.7141\n",
            "Epoch 645/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3874 - val_loss: 0.7027\n",
            "Epoch 646/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3863 - val_loss: 0.7594\n",
            "Epoch 647/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3873 - val_loss: 0.7518\n",
            "Epoch 648/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3870 - val_loss: 0.7139\n",
            "Epoch 649/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3869 - val_loss: 0.7029\n",
            "Epoch 650/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3867 - val_loss: 0.7130\n",
            "Epoch 651/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3865 - val_loss: 0.6951\n",
            "Epoch 652/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3869 - val_loss: 0.6932\n",
            "Epoch 653/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3858 - val_loss: 0.7381\n",
            "Epoch 654/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3866 - val_loss: 0.7098\n",
            "Epoch 655/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3856 - val_loss: 0.6882\n",
            "Epoch 656/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3861 - val_loss: 0.7258\n",
            "Epoch 657/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3859 - val_loss: 0.7189\n",
            "Epoch 658/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3858 - val_loss: 0.6881\n",
            "Epoch 659/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3855 - val_loss: 0.6955\n",
            "Epoch 660/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3855 - val_loss: 0.6934\n",
            "Epoch 661/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3850 - val_loss: 0.7355\n",
            "Epoch 662/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3848 - val_loss: 0.7522\n",
            "Epoch 663/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3852 - val_loss: 0.7058\n",
            "Epoch 664/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3846 - val_loss: 0.6914\n",
            "Epoch 665/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3842 - val_loss: 0.7368\n",
            "Epoch 666/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3848 - val_loss: 0.7419\n",
            "Epoch 667/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3847 - val_loss: 0.6992\n",
            "Epoch 668/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3845 - val_loss: 0.7051\n",
            "Epoch 669/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3846 - val_loss: 0.7291\n",
            "Epoch 670/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3840 - val_loss: 0.7189\n",
            "Epoch 671/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3840 - val_loss: 0.7347\n",
            "Epoch 672/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3842 - val_loss: 0.7257\n",
            "Epoch 673/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3841 - val_loss: 0.6935\n",
            "Epoch 674/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3838 - val_loss: 0.6981\n",
            "Epoch 675/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3837 - val_loss: 0.6931\n",
            "Epoch 676/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3831 - val_loss: 0.6823\n",
            "Epoch 677/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3838 - val_loss: 0.6799\n",
            "Epoch 678/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3831 - val_loss: 0.6501\n",
            "Epoch 679/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3836 - val_loss: 0.6795\n",
            "Epoch 680/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3834 - val_loss: 0.7051\n",
            "Epoch 681/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3832 - val_loss: 0.6763\n",
            "Epoch 682/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3830 - val_loss: 0.7300\n",
            "Epoch 683/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3832 - val_loss: 0.6824\n",
            "Epoch 684/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3830 - val_loss: 0.6699\n",
            "Epoch 685/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3822 - val_loss: 0.6888\n",
            "Epoch 686/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3821 - val_loss: 0.6868\n",
            "Epoch 687/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3820 - val_loss: 0.6802\n",
            "Epoch 688/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3821 - val_loss: 0.7057\n",
            "Epoch 689/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3822 - val_loss: 0.6806\n",
            "Epoch 690/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3815 - val_loss: 0.6949\n",
            "Epoch 691/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3815 - val_loss: 0.6706\n",
            "Epoch 692/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3820 - val_loss: 0.6384\n",
            "Epoch 693/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3817 - val_loss: 0.6849\n",
            "Epoch 694/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3813 - val_loss: 0.6956\n",
            "Epoch 695/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3813 - val_loss: 0.6689\n",
            "Epoch 696/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3813 - val_loss: 0.6951\n",
            "Epoch 697/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3810 - val_loss: 0.6860\n",
            "Epoch 698/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3808 - val_loss: 0.6730\n",
            "Epoch 699/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3813 - val_loss: 0.6544\n",
            "Epoch 700/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3806 - val_loss: 0.6924\n",
            "Epoch 701/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3814 - val_loss: 0.6858\n",
            "Epoch 702/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3804 - val_loss: 0.6798\n",
            "Epoch 703/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3812 - val_loss: 0.6709\n",
            "Epoch 704/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3802 - val_loss: 0.6563\n",
            "Epoch 705/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3801 - val_loss: 0.6496\n",
            "Epoch 706/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3800 - val_loss: 0.6852\n",
            "Epoch 707/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3799 - val_loss: 0.6612\n",
            "Epoch 708/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3800 - val_loss: 0.6238\n",
            "Epoch 709/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3809 - val_loss: 0.6627\n",
            "Epoch 710/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3794 - val_loss: 0.6611\n",
            "Epoch 711/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3801 - val_loss: 0.6955\n",
            "Epoch 712/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3796 - val_loss: 0.6988\n",
            "Epoch 713/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3804 - val_loss: 0.6708\n",
            "Epoch 714/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3800 - val_loss: 0.7043\n",
            "Epoch 715/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3794 - val_loss: 0.6469\n",
            "Epoch 716/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3797 - val_loss: 0.6898\n",
            "Epoch 717/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3794 - val_loss: 0.6586\n",
            "Epoch 718/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3805 - val_loss: 0.6350\n",
            "Epoch 719/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3787 - val_loss: 0.6920\n",
            "Epoch 720/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3787 - val_loss: 0.6711\n",
            "Epoch 721/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3787 - val_loss: 0.6630\n",
            "Epoch 722/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3781 - val_loss: 0.6353\n",
            "Epoch 723/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3785 - val_loss: 0.6431\n",
            "Epoch 724/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3781 - val_loss: 0.6505\n",
            "Epoch 725/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3779 - val_loss: 0.7086\n",
            "Epoch 726/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3785 - val_loss: 0.6670\n",
            "Epoch 727/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3775 - val_loss: 0.6390\n",
            "Epoch 728/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3783 - val_loss: 0.6724\n",
            "Epoch 729/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3780 - val_loss: 0.6849\n",
            "Epoch 730/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3782 - val_loss: 0.6530\n",
            "Epoch 731/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3786 - val_loss: 0.6351\n",
            "Epoch 732/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3779 - val_loss: 0.6407\n",
            "Epoch 733/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3774 - val_loss: 0.6587\n",
            "Epoch 734/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3779 - val_loss: 0.6485\n",
            "Epoch 735/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3771 - val_loss: 0.6527\n",
            "Epoch 736/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3772 - val_loss: 0.6433\n",
            "Epoch 737/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3768 - val_loss: 0.6616\n",
            "Epoch 738/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3771 - val_loss: 0.6736\n",
            "Epoch 739/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3774 - val_loss: 0.6518\n",
            "Epoch 740/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3763 - val_loss: 0.6934\n",
            "Epoch 741/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3763 - val_loss: 0.6388\n",
            "Epoch 742/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3763 - val_loss: 0.6640\n",
            "Epoch 743/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3765 - val_loss: 0.6326\n",
            "Epoch 744/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3762 - val_loss: 0.6493\n",
            "Epoch 745/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3772 - val_loss: 0.6328\n",
            "Epoch 746/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3762 - val_loss: 0.6326\n",
            "Epoch 747/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3765 - val_loss: 0.6130\n",
            "Epoch 748/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3764 - val_loss: 0.6226\n",
            "Epoch 749/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3760 - val_loss: 0.6161\n",
            "Epoch 750/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3770 - val_loss: 0.6314\n",
            "Epoch 751/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3753 - val_loss: 0.6137\n",
            "Epoch 752/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3761 - val_loss: 0.6305\n",
            "Epoch 753/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3751 - val_loss: 0.6487\n",
            "Epoch 754/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3761 - val_loss: 0.6201\n",
            "Epoch 755/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3750 - val_loss: 0.6313\n",
            "Epoch 756/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3762 - val_loss: 0.6263\n",
            "Epoch 757/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3750 - val_loss: 0.6337\n",
            "Epoch 758/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3749 - val_loss: 0.6203\n",
            "Epoch 759/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3747 - val_loss: 0.6467\n",
            "Epoch 760/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3751 - val_loss: 0.6956\n",
            "Epoch 761/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3748 - val_loss: 0.6193\n",
            "Epoch 762/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3747 - val_loss: 0.6315\n",
            "Epoch 763/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3750 - val_loss: 0.6414\n",
            "Epoch 764/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3748 - val_loss: 0.6319\n",
            "Epoch 765/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3742 - val_loss: 0.6302\n",
            "Epoch 766/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3743 - val_loss: 0.6369\n",
            "Epoch 767/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3747 - val_loss: 0.6260\n",
            "Epoch 768/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3739 - val_loss: 0.6265\n",
            "Epoch 769/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3742 - val_loss: 0.6352\n",
            "Epoch 770/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3738 - val_loss: 0.6294\n",
            "Epoch 771/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3736 - val_loss: 0.6450\n",
            "Epoch 772/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3737 - val_loss: 0.6647\n",
            "Epoch 773/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3737 - val_loss: 0.6373\n",
            "Epoch 774/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3735 - val_loss: 0.6402\n",
            "Epoch 775/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3729 - val_loss: 0.6189\n",
            "Epoch 776/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3728 - val_loss: 0.6324\n",
            "Epoch 777/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3725 - val_loss: 0.6396\n",
            "Epoch 778/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3729 - val_loss: 0.6180\n",
            "Epoch 779/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3740 - val_loss: 0.6388\n",
            "Epoch 780/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3732 - val_loss: 0.6142\n",
            "Epoch 781/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3730 - val_loss: 0.6159\n",
            "Epoch 782/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3732 - val_loss: 0.6051\n",
            "Epoch 783/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3725 - val_loss: 0.6212\n",
            "Epoch 784/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3730 - val_loss: 0.6092\n",
            "Epoch 785/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3720 - val_loss: 0.6117\n",
            "Epoch 786/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3726 - val_loss: 0.6261\n",
            "Epoch 787/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3717 - val_loss: 0.6233\n",
            "Epoch 788/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3716 - val_loss: 0.6244\n",
            "Epoch 789/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3713 - val_loss: 0.6161\n",
            "Epoch 790/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3715 - val_loss: 0.6081\n",
            "Epoch 791/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3716 - val_loss: 0.6120\n",
            "Epoch 792/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3713 - val_loss: 0.6098\n",
            "Epoch 793/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3716 - val_loss: 0.6158\n",
            "Epoch 794/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3715 - val_loss: 0.6136\n",
            "Epoch 795/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3720 - val_loss: 0.6094\n",
            "Epoch 796/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3706 - val_loss: 0.6048\n",
            "Epoch 797/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3712 - val_loss: 0.6082\n",
            "Epoch 798/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3711 - val_loss: 0.6223\n",
            "Epoch 799/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3712 - val_loss: 0.6226\n",
            "Epoch 800/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3714 - val_loss: 0.6215\n",
            "Epoch 801/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3713 - val_loss: 0.6174\n",
            "Epoch 802/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3703 - val_loss: 0.6051\n",
            "Epoch 803/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3703 - val_loss: 0.6086\n",
            "Epoch 804/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3703 - val_loss: 0.5980\n",
            "Epoch 805/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3697 - val_loss: 0.6206\n",
            "Epoch 806/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3695 - val_loss: 0.5952\n",
            "Epoch 807/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3696 - val_loss: 0.6062\n",
            "Epoch 808/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3693 - val_loss: 0.5945\n",
            "Epoch 809/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3702 - val_loss: 0.6018\n",
            "Epoch 810/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3697 - val_loss: 0.6033\n",
            "Epoch 811/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3703 - val_loss: 0.6073\n",
            "Epoch 812/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3691 - val_loss: 0.6196\n",
            "Epoch 813/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3692 - val_loss: 0.5807\n",
            "Epoch 814/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3691 - val_loss: 0.6018\n",
            "Epoch 815/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3690 - val_loss: 0.5953\n",
            "Epoch 816/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3695 - val_loss: 0.5912\n",
            "Epoch 817/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3688 - val_loss: 0.6165\n",
            "Epoch 818/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3693 - val_loss: 0.6102\n",
            "Epoch 819/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3688 - val_loss: 0.6018\n",
            "Epoch 820/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3683 - val_loss: 0.6051\n",
            "Epoch 821/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3684 - val_loss: 0.6157\n",
            "Epoch 822/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3683 - val_loss: 0.6065\n",
            "Epoch 823/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3679 - val_loss: 0.6065\n",
            "Epoch 824/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3682 - val_loss: 0.5857\n",
            "Epoch 825/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3685 - val_loss: 0.5857\n",
            "Epoch 826/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3686 - val_loss: 0.5901\n",
            "Epoch 827/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3687 - val_loss: 0.5966\n",
            "Epoch 828/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3677 - val_loss: 0.6038\n",
            "Epoch 829/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3684 - val_loss: 0.5942\n",
            "Epoch 830/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3679 - val_loss: 0.5917\n",
            "Epoch 831/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3682 - val_loss: 0.5805\n",
            "Epoch 832/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3674 - val_loss: 0.5965\n",
            "Epoch 833/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3671 - val_loss: 0.5877\n",
            "Epoch 834/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3678 - val_loss: 0.5720\n",
            "Epoch 835/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3674 - val_loss: 0.5916\n",
            "Epoch 836/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3667 - val_loss: 0.5984\n",
            "Epoch 837/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3675 - val_loss: 0.6034\n",
            "Epoch 838/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3672 - val_loss: 0.5881\n",
            "Epoch 839/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3668 - val_loss: 0.5884\n",
            "Epoch 840/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3659 - val_loss: 0.6152\n",
            "Epoch 841/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3667 - val_loss: 0.5754\n",
            "Epoch 842/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3669 - val_loss: 0.5939\n",
            "Epoch 843/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3657 - val_loss: 0.5698\n",
            "Epoch 844/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3673 - val_loss: 0.5966\n",
            "Epoch 845/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3665 - val_loss: 0.5856\n",
            "Epoch 846/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3656 - val_loss: 0.6077\n",
            "Epoch 847/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3664 - val_loss: 0.5693\n",
            "Epoch 848/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3656 - val_loss: 0.5858\n",
            "Epoch 849/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3657 - val_loss: 0.5710\n",
            "Epoch 850/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3659 - val_loss: 0.5787\n",
            "Epoch 851/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3653 - val_loss: 0.5705\n",
            "Epoch 852/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3660 - val_loss: 0.5555\n",
            "Epoch 853/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3658 - val_loss: 0.5862\n",
            "Epoch 854/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3651 - val_loss: 0.6089\n",
            "Epoch 855/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3656 - val_loss: 0.5664\n",
            "Epoch 856/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3660 - val_loss: 0.5886\n",
            "Epoch 857/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3658 - val_loss: 0.5801\n",
            "Epoch 858/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3649 - val_loss: 0.5740\n",
            "Epoch 859/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3665 - val_loss: 0.5751\n",
            "Epoch 860/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3643 - val_loss: 0.5616\n",
            "Epoch 861/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3650 - val_loss: 0.5579\n",
            "Epoch 862/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3655 - val_loss: 0.5785\n",
            "Epoch 863/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3642 - val_loss: 0.5720\n",
            "Epoch 864/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3642 - val_loss: 0.5626\n",
            "Epoch 865/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3649 - val_loss: 0.5626\n",
            "Epoch 866/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3643 - val_loss: 0.5694\n",
            "Epoch 867/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3639 - val_loss: 0.5857\n",
            "Epoch 868/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3655 - val_loss: 0.5664\n",
            "Epoch 869/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3645 - val_loss: 0.5798\n",
            "Epoch 870/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3639 - val_loss: 0.5766\n",
            "Epoch 871/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3645 - val_loss: 0.5747\n",
            "Epoch 872/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3646 - val_loss: 0.5683\n",
            "Epoch 873/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3639 - val_loss: 0.5633\n",
            "Epoch 874/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3643 - val_loss: 0.5716\n",
            "Epoch 875/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3641 - val_loss: 0.5612\n",
            "Epoch 876/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3637 - val_loss: 0.5699\n",
            "Epoch 877/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3632 - val_loss: 0.5614\n",
            "Epoch 878/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3634 - val_loss: 0.5689\n",
            "Epoch 879/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3635 - val_loss: 0.5806\n",
            "Epoch 880/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3621 - val_loss: 0.5440\n",
            "Epoch 881/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3637 - val_loss: 0.5731\n",
            "Epoch 882/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3639 - val_loss: 0.5647\n",
            "Epoch 883/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3632 - val_loss: 0.5749\n",
            "Epoch 884/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3627 - val_loss: 0.5570\n",
            "Epoch 885/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3635 - val_loss: 0.5613\n",
            "Epoch 886/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3643 - val_loss: 0.5609\n",
            "Epoch 887/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3627 - val_loss: 0.5634\n",
            "Epoch 888/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3635 - val_loss: 0.5494\n",
            "Epoch 889/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3622 - val_loss: 0.5702\n",
            "Epoch 890/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3627 - val_loss: 0.5671\n",
            "Epoch 891/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3635 - val_loss: 0.5453\n",
            "Epoch 892/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3628 - val_loss: 0.5512\n",
            "Epoch 893/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3628 - val_loss: 0.5599\n",
            "Epoch 894/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3638 - val_loss: 0.5498\n",
            "Epoch 895/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3623 - val_loss: 0.5577\n",
            "Epoch 896/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3620 - val_loss: 0.5486\n",
            "Epoch 897/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3624 - val_loss: 0.5460\n",
            "Epoch 898/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3622 - val_loss: 0.5516\n",
            "Epoch 899/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3622 - val_loss: 0.5708\n",
            "Epoch 900/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3621 - val_loss: 0.5577\n",
            "Epoch 901/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3615 - val_loss: 0.5549\n",
            "Epoch 902/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3617 - val_loss: 0.5643\n",
            "Epoch 903/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3614 - val_loss: 0.5631\n",
            "Epoch 904/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3624 - val_loss: 0.5510\n",
            "Epoch 905/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3616 - val_loss: 0.5545\n",
            "Epoch 906/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3612 - val_loss: 0.5756\n",
            "Epoch 907/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3611 - val_loss: 0.5505\n",
            "Epoch 908/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3618 - val_loss: 0.5547\n",
            "Epoch 909/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3610 - val_loss: 0.5456\n",
            "Epoch 910/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3622 - val_loss: 0.5567\n",
            "Epoch 911/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3612 - val_loss: 0.5504\n",
            "Epoch 912/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3608 - val_loss: 0.5482\n",
            "Epoch 913/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3606 - val_loss: 0.5289\n",
            "Epoch 914/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3620 - val_loss: 0.5442\n",
            "Epoch 915/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3609 - val_loss: 0.5438\n",
            "Epoch 916/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3603 - val_loss: 0.5429\n",
            "Epoch 917/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3606 - val_loss: 0.5483\n",
            "Epoch 918/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3604 - val_loss: 0.5400\n",
            "Epoch 919/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3603 - val_loss: 0.5562\n",
            "Epoch 920/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3600 - val_loss: 0.5434\n",
            "Epoch 921/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3604 - val_loss: 0.5492\n",
            "Epoch 922/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3602 - val_loss: 0.5386\n",
            "Epoch 923/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3599 - val_loss: 0.5513\n",
            "Epoch 924/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3606 - val_loss: 0.5329\n",
            "Epoch 925/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3601 - val_loss: 0.5403\n",
            "Epoch 926/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3601 - val_loss: 0.5457\n",
            "Epoch 927/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3597 - val_loss: 0.5410\n",
            "Epoch 928/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3598 - val_loss: 0.5427\n",
            "Epoch 929/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3595 - val_loss: 0.5369\n",
            "Epoch 930/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3596 - val_loss: 0.5318\n",
            "Epoch 931/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3614 - val_loss: 0.5277\n",
            "Epoch 932/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3592 - val_loss: 0.5268\n",
            "Epoch 933/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3601 - val_loss: 0.5433\n",
            "Epoch 934/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3595 - val_loss: 0.5333\n",
            "Epoch 935/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3589 - val_loss: 0.5264\n",
            "Epoch 936/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3602 - val_loss: 0.5296\n",
            "Epoch 937/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3588 - val_loss: 0.5533\n",
            "Epoch 938/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3591 - val_loss: 0.5350\n",
            "Epoch 939/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3599 - val_loss: 0.5331\n",
            "Epoch 940/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3590 - val_loss: 0.5460\n",
            "Epoch 941/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3587 - val_loss: 0.5338\n",
            "Epoch 942/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3581 - val_loss: 0.5472\n",
            "Epoch 943/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3587 - val_loss: 0.5274\n",
            "Epoch 944/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3598 - val_loss: 0.5219\n",
            "Epoch 945/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3579 - val_loss: 0.5521\n",
            "Epoch 946/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3591 - val_loss: 0.5241\n",
            "Epoch 947/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3590 - val_loss: 0.5299\n",
            "Epoch 948/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3586 - val_loss: 0.5188\n",
            "Epoch 949/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3603 - val_loss: 0.5347\n",
            "Epoch 950/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3594 - val_loss: 0.5283\n",
            "Epoch 951/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3588 - val_loss: 0.5351\n",
            "Epoch 952/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3587 - val_loss: 0.5291\n",
            "Epoch 953/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3592 - val_loss: 0.5336\n",
            "Epoch 954/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3585 - val_loss: 0.5315\n",
            "Epoch 955/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3579 - val_loss: 0.5319\n",
            "Epoch 956/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3590 - val_loss: 0.5282\n",
            "Epoch 957/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3580 - val_loss: 0.5273\n",
            "Epoch 958/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3580 - val_loss: 0.5322\n",
            "Epoch 959/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3581 - val_loss: 0.5341\n",
            "Epoch 960/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3581 - val_loss: 0.5323\n",
            "Epoch 961/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3574 - val_loss: 0.5334\n",
            "Epoch 962/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3587 - val_loss: 0.5228\n",
            "Epoch 963/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3578 - val_loss: 0.5295\n",
            "Epoch 964/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3572 - val_loss: 0.5205\n",
            "Epoch 965/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3579 - val_loss: 0.5280\n",
            "Epoch 966/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3572 - val_loss: 0.5298\n",
            "Epoch 967/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3575 - val_loss: 0.5254\n",
            "Epoch 968/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3574 - val_loss: 0.5266\n",
            "Epoch 969/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3573 - val_loss: 0.5324\n",
            "Epoch 970/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3574 - val_loss: 0.5224\n",
            "Epoch 971/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3572 - val_loss: 0.5222\n",
            "Epoch 972/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3574 - val_loss: 0.5277\n",
            "Epoch 973/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3570 - val_loss: 0.5292\n",
            "Epoch 974/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3577 - val_loss: 0.5224\n",
            "Epoch 975/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3571 - val_loss: 0.5254\n",
            "Epoch 976/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3569 - val_loss: 0.5234\n",
            "Epoch 977/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3562 - val_loss: 0.5312\n",
            "Epoch 978/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3571 - val_loss: 0.5221\n",
            "Epoch 979/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3560 - val_loss: 0.5237\n",
            "Epoch 980/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3567 - val_loss: 0.5224\n",
            "Epoch 981/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3559 - val_loss: 0.5250\n",
            "Epoch 982/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3559 - val_loss: 0.5366\n",
            "Epoch 983/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3575 - val_loss: 0.5224\n",
            "Epoch 984/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3555 - val_loss: 0.5272\n",
            "Epoch 985/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3561 - val_loss: 0.5263\n",
            "Epoch 986/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3572 - val_loss: 0.5359\n",
            "Epoch 987/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3567 - val_loss: 0.5215\n",
            "Epoch 988/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3554 - val_loss: 0.5258\n",
            "Epoch 989/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3558 - val_loss: 0.5187\n",
            "Epoch 990/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3555 - val_loss: 0.5269\n",
            "Epoch 991/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3552 - val_loss: 0.5228\n",
            "Epoch 992/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3553 - val_loss: 0.5221\n",
            "Epoch 993/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3558 - val_loss: 0.5275\n",
            "Epoch 994/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3562 - val_loss: 0.5237\n",
            "Epoch 995/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3554 - val_loss: 0.5253\n",
            "Epoch 996/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3553 - val_loss: 0.5227\n",
            "Epoch 997/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3556 - val_loss: 0.5096\n",
            "Epoch 998/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3559 - val_loss: 0.5205\n",
            "Epoch 999/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3549 - val_loss: 0.5229\n",
            "Epoch 1000/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3545 - val_loss: 0.5264\n",
            "Epoch 1001/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3556 - val_loss: 0.5209\n",
            "Epoch 1002/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3550 - val_loss: 0.5239\n",
            "Epoch 1003/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3552 - val_loss: 0.5230\n",
            "Epoch 1004/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3547 - val_loss: 0.5239\n",
            "Epoch 1005/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3549 - val_loss: 0.5210\n",
            "Epoch 1006/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3548 - val_loss: 0.5220\n",
            "Epoch 1007/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3545 - val_loss: 0.5150\n",
            "Epoch 1008/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3543 - val_loss: 0.5228\n",
            "Epoch 1009/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3550 - val_loss: 0.5135\n",
            "Epoch 1010/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3558 - val_loss: 0.5165\n",
            "Epoch 1011/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3547 - val_loss: 0.5147\n",
            "Epoch 1012/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3547 - val_loss: 0.5177\n",
            "Epoch 1013/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3545 - val_loss: 0.5177\n",
            "Epoch 1014/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3541 - val_loss: 0.5184\n",
            "Epoch 1015/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3548 - val_loss: 0.5131\n",
            "Epoch 1016/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3553 - val_loss: 0.5169\n",
            "Epoch 1017/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3537 - val_loss: 0.5212\n",
            "Epoch 1018/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3519 - val_loss: 0.5051\n",
            "Epoch 1019/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3560 - val_loss: 0.5161\n",
            "Epoch 1020/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3547 - val_loss: 0.5128\n",
            "Epoch 1021/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3538 - val_loss: 0.5079\n",
            "Epoch 1022/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3553 - val_loss: 0.5104\n",
            "Epoch 1023/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3538 - val_loss: 0.5138\n",
            "Epoch 1024/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3539 - val_loss: 0.5174\n",
            "Epoch 1025/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3534 - val_loss: 0.5148\n",
            "Epoch 1026/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3540 - val_loss: 0.5123\n",
            "Epoch 1027/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3539 - val_loss: 0.5162\n",
            "Epoch 1028/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3536 - val_loss: 0.5121\n",
            "Epoch 1029/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3540 - val_loss: 0.5139\n",
            "Epoch 1030/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3537 - val_loss: 0.5194\n",
            "Epoch 1031/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3531 - val_loss: 0.5064\n",
            "Epoch 1032/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3540 - val_loss: 0.5168\n",
            "Epoch 1033/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3531 - val_loss: 0.5121\n",
            "Epoch 1034/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3541 - val_loss: 0.5131\n",
            "Epoch 1035/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3532 - val_loss: 0.5145\n",
            "Epoch 1036/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3542 - val_loss: 0.5097\n",
            "Epoch 1037/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3536 - val_loss: 0.5154\n",
            "Epoch 1038/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3536 - val_loss: 0.5138\n",
            "Epoch 1039/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3530 - val_loss: 0.5089\n",
            "Epoch 1040/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3532 - val_loss: 0.5073\n",
            "Epoch 1041/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3533 - val_loss: 0.5075\n",
            "Epoch 1042/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3522 - val_loss: 0.5184\n",
            "Epoch 1043/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3534 - val_loss: 0.5146\n",
            "Epoch 1044/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3529 - val_loss: 0.5168\n",
            "Epoch 1045/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3540 - val_loss: 0.5121\n",
            "Epoch 1046/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3547 - val_loss: 0.5075\n",
            "Epoch 1047/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3538 - val_loss: 0.5074\n",
            "Epoch 1048/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3526 - val_loss: 0.5169\n",
            "Epoch 1049/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3538 - val_loss: 0.5113\n",
            "Epoch 1050/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3526 - val_loss: 0.5108\n",
            "Epoch 1051/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3522 - val_loss: 0.5006\n",
            "Epoch 1052/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3528 - val_loss: 0.5049\n",
            "Epoch 1053/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3533 - val_loss: 0.5010\n",
            "Epoch 1054/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3523 - val_loss: 0.5061\n",
            "Epoch 1055/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3528 - val_loss: 0.5056\n",
            "Epoch 1056/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3527 - val_loss: 0.5013\n",
            "Epoch 1057/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3528 - val_loss: 0.5062\n",
            "Epoch 1058/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3523 - val_loss: 0.5052\n",
            "Epoch 1059/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3519 - val_loss: 0.5031\n",
            "Epoch 1060/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3519 - val_loss: 0.5079\n",
            "Epoch 1061/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3524 - val_loss: 0.5111\n",
            "Epoch 1062/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3519 - val_loss: 0.5009\n",
            "Epoch 1063/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3515 - val_loss: 0.5056\n",
            "Epoch 1064/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3519 - val_loss: 0.4906\n",
            "Epoch 1065/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3528 - val_loss: 0.4985\n",
            "Epoch 1066/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3554 - val_loss: 0.5029\n",
            "Epoch 1067/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3518 - val_loss: 0.5088\n",
            "Epoch 1068/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3518 - val_loss: 0.5070\n",
            "Epoch 1069/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3523 - val_loss: 0.5079\n",
            "Epoch 1070/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3519 - val_loss: 0.4939\n",
            "Epoch 1071/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3539 - val_loss: 0.5017\n",
            "Epoch 1072/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3512 - val_loss: 0.5085\n",
            "Epoch 1073/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3523 - val_loss: 0.5005\n",
            "Epoch 1074/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3515 - val_loss: 0.4946\n",
            "Epoch 1075/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3531 - val_loss: 0.5044\n",
            "Epoch 1076/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3513 - val_loss: 0.5065\n",
            "Epoch 1077/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3519 - val_loss: 0.5015\n",
            "Epoch 1078/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3520 - val_loss: 0.5044\n",
            "Epoch 1079/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3516 - val_loss: 0.5059\n",
            "Epoch 1080/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3520 - val_loss: 0.5030\n",
            "Epoch 1081/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3524 - val_loss: 0.5007\n",
            "Epoch 1082/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3510 - val_loss: 0.5041\n",
            "Epoch 1083/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3521 - val_loss: 0.4966\n",
            "Epoch 1084/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3514 - val_loss: 0.4982\n",
            "Epoch 1085/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3512 - val_loss: 0.4950\n",
            "Epoch 1086/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3512 - val_loss: 0.4967\n",
            "Epoch 1087/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3513 - val_loss: 0.4953\n",
            "Epoch 1088/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3516 - val_loss: 0.4918\n",
            "Epoch 1089/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3515 - val_loss: 0.4994\n",
            "Epoch 1090/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3514 - val_loss: 0.4947\n",
            "Epoch 1091/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3507 - val_loss: 0.5010\n",
            "Epoch 1092/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3509 - val_loss: 0.4922\n",
            "Epoch 1093/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3505 - val_loss: 0.5008\n",
            "Epoch 1094/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3513 - val_loss: 0.4967\n",
            "Epoch 1095/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3516 - val_loss: 0.4985\n",
            "Epoch 1096/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3503 - val_loss: 0.4927\n",
            "Epoch 1097/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3511 - val_loss: 0.4995\n",
            "Epoch 1098/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3506 - val_loss: 0.4918\n",
            "Epoch 1099/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3515 - val_loss: 0.4970\n",
            "Epoch 1100/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3513 - val_loss: 0.4939\n",
            "Epoch 1101/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3502 - val_loss: 0.4928\n",
            "Epoch 1102/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3500 - val_loss: 0.5011\n",
            "Epoch 1103/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3508 - val_loss: 0.4970\n",
            "Epoch 1104/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3505 - val_loss: 0.4933\n",
            "Epoch 1105/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3506 - val_loss: 0.4952\n",
            "Epoch 1106/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3498 - val_loss: 0.4932\n",
            "Epoch 1107/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3512 - val_loss: 0.4952\n",
            "Epoch 1108/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3503 - val_loss: 0.4951\n",
            "Epoch 1109/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3517 - val_loss: 0.4949\n",
            "Epoch 1110/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3511 - val_loss: 0.4881\n",
            "Epoch 1111/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3501 - val_loss: 0.4904\n",
            "Epoch 1112/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3515 - val_loss: 0.4932\n",
            "Epoch 1113/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3509 - val_loss: 0.4848\n",
            "Epoch 1114/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3507 - val_loss: 0.4937\n",
            "Epoch 1115/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3505 - val_loss: 0.4953\n",
            "Epoch 1116/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3507 - val_loss: 0.4902\n",
            "Epoch 1117/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3504 - val_loss: 0.4988\n",
            "Epoch 1118/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3498 - val_loss: 0.4941\n",
            "Epoch 1119/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3504 - val_loss: 0.4989\n",
            "Epoch 1120/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3505 - val_loss: 0.4924\n",
            "Epoch 1121/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3498 - val_loss: 0.4887\n",
            "Epoch 1122/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3498 - val_loss: 0.4904\n",
            "Epoch 1123/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3496 - val_loss: 0.4864\n",
            "Epoch 1124/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3515 - val_loss: 0.4886\n",
            "Epoch 1125/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3502 - val_loss: 0.4874\n",
            "Epoch 1126/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3501 - val_loss: 0.4928\n",
            "Epoch 1127/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3492 - val_loss: 0.4988\n",
            "Epoch 1128/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3508 - val_loss: 0.4905\n",
            "Epoch 1129/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3503 - val_loss: 0.4923\n",
            "Epoch 1130/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3491 - val_loss: 0.4902\n",
            "Epoch 1131/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3490 - val_loss: 0.4821\n",
            "Epoch 1132/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3499 - val_loss: 0.4853\n",
            "Epoch 1133/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3492 - val_loss: 0.4869\n",
            "Epoch 1134/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3498 - val_loss: 0.4855\n",
            "Epoch 1135/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3497 - val_loss: 0.4848\n",
            "Epoch 1136/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3494 - val_loss: 0.4936\n",
            "Epoch 1137/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3489 - val_loss: 0.4950\n",
            "Epoch 1138/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3494 - val_loss: 0.4923\n",
            "Epoch 1139/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3502 - val_loss: 0.4919\n",
            "Epoch 1140/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3496 - val_loss: 0.4941\n",
            "Epoch 1141/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3493 - val_loss: 0.4803\n",
            "Epoch 1142/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3497 - val_loss: 0.4890\n",
            "Epoch 1143/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3494 - val_loss: 0.4867\n",
            "Epoch 1144/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3494 - val_loss: 0.4829\n",
            "Epoch 1145/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3492 - val_loss: 0.4853\n",
            "Epoch 1146/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3486 - val_loss: 0.4902\n",
            "Epoch 1147/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3488 - val_loss: 0.4914\n",
            "Epoch 1148/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3487 - val_loss: 0.4837\n",
            "Epoch 1149/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3492 - val_loss: 0.4864\n",
            "Epoch 1150/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3485 - val_loss: 0.4911\n",
            "Epoch 1151/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3492 - val_loss: 0.4860\n",
            "Epoch 1152/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3490 - val_loss: 0.4897\n",
            "Epoch 1153/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3488 - val_loss: 0.4880\n",
            "Epoch 1154/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3482 - val_loss: 0.4878\n",
            "Epoch 1155/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3486 - val_loss: 0.4804\n",
            "Epoch 1156/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3484 - val_loss: 0.4841\n",
            "Epoch 1157/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3482 - val_loss: 0.4835\n",
            "Epoch 1158/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3491 - val_loss: 0.4781\n",
            "Epoch 1159/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3484 - val_loss: 0.4813\n",
            "Epoch 1160/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3484 - val_loss: 0.4770\n",
            "Epoch 1161/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3489 - val_loss: 0.4808\n",
            "Epoch 1162/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3483 - val_loss: 0.4850\n",
            "Epoch 1163/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3482 - val_loss: 0.4960\n",
            "Epoch 1164/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3485 - val_loss: 0.4834\n",
            "Epoch 1165/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3476 - val_loss: 0.4760\n",
            "Epoch 1166/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3483 - val_loss: 0.4847\n",
            "Epoch 1167/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3483 - val_loss: 0.4916\n",
            "Epoch 1168/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3487 - val_loss: 0.4813\n",
            "Epoch 1169/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3483 - val_loss: 0.4810\n",
            "Epoch 1170/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3481 - val_loss: 0.4789\n",
            "Epoch 1171/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3480 - val_loss: 0.4855\n",
            "Epoch 1172/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3473 - val_loss: 0.4773\n",
            "Epoch 1173/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3490 - val_loss: 0.4813\n",
            "Epoch 1174/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3488 - val_loss: 0.4857\n",
            "Epoch 1175/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3479 - val_loss: 0.4834\n",
            "Epoch 1176/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3478 - val_loss: 0.4775\n",
            "Epoch 1177/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3489 - val_loss: 0.4802\n",
            "Epoch 1178/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3488 - val_loss: 0.4843\n",
            "Epoch 1179/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3484 - val_loss: 0.4812\n",
            "Epoch 1180/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3481 - val_loss: 0.4800\n",
            "Epoch 1181/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3473 - val_loss: 0.4861\n",
            "Epoch 1182/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3464 - val_loss: 0.4778\n",
            "Epoch 1183/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3486 - val_loss: 0.4783\n",
            "Epoch 1184/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3474 - val_loss: 0.4803\n",
            "Epoch 1185/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3473 - val_loss: 0.4780\n",
            "Epoch 1186/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3475 - val_loss: 0.4825\n",
            "Epoch 1187/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3472 - val_loss: 0.4776\n",
            "Epoch 1188/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3476 - val_loss: 0.4827\n",
            "Epoch 1189/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3492 - val_loss: 0.4783\n",
            "Epoch 1190/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3463 - val_loss: 0.4738\n",
            "Epoch 1191/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3478 - val_loss: 0.4774\n",
            "Epoch 1192/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3474 - val_loss: 0.4785\n",
            "Epoch 1193/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3477 - val_loss: 0.4810\n",
            "Epoch 1194/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3481 - val_loss: 0.4732\n",
            "Epoch 1195/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3465 - val_loss: 0.4788\n",
            "Epoch 1196/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3469 - val_loss: 0.4755\n",
            "Epoch 1197/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3475 - val_loss: 0.4792\n",
            "Epoch 1198/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3473 - val_loss: 0.4785\n",
            "Epoch 1199/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3476 - val_loss: 0.4814\n",
            "Epoch 1200/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3469 - val_loss: 0.4711\n",
            "Epoch 1201/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3470 - val_loss: 0.4771\n",
            "Epoch 1202/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3475 - val_loss: 0.4808\n",
            "Epoch 1203/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3470 - val_loss: 0.4714\n",
            "Epoch 1204/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3465 - val_loss: 0.4701\n",
            "Epoch 1205/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3476 - val_loss: 0.4782\n",
            "Epoch 1206/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3463 - val_loss: 0.4821\n",
            "Epoch 1207/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3475 - val_loss: 0.4719\n",
            "Epoch 1208/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3480 - val_loss: 0.4782\n",
            "Epoch 1209/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3466 - val_loss: 0.4671\n",
            "Epoch 1210/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3475 - val_loss: 0.4756\n",
            "Epoch 1211/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3471 - val_loss: 0.4762\n",
            "Epoch 1212/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3466 - val_loss: 0.4781\n",
            "Epoch 1213/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3464 - val_loss: 0.4715\n",
            "Epoch 1214/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3465 - val_loss: 0.4760\n",
            "Epoch 1215/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3470 - val_loss: 0.4769\n",
            "Epoch 1216/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3468 - val_loss: 0.4748\n",
            "Epoch 1217/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3465 - val_loss: 0.4719\n",
            "Epoch 1218/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3470 - val_loss: 0.4792\n",
            "Epoch 1219/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3458 - val_loss: 0.4829\n",
            "Epoch 1220/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3480 - val_loss: 0.4827\n",
            "Epoch 1221/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3473 - val_loss: 0.4714\n",
            "Epoch 1222/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3463 - val_loss: 0.4763\n",
            "Epoch 1223/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3468 - val_loss: 0.4790\n",
            "Epoch 1224/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3469 - val_loss: 0.4740\n",
            "Epoch 1225/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3468 - val_loss: 0.4729\n",
            "Epoch 1226/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3468 - val_loss: 0.4714\n",
            "Epoch 1227/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3465 - val_loss: 0.4689\n",
            "Epoch 1228/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3463 - val_loss: 0.4734\n",
            "Epoch 1229/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3467 - val_loss: 0.4786\n",
            "Epoch 1230/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3465 - val_loss: 0.4742\n",
            "Epoch 1231/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3464 - val_loss: 0.4769\n",
            "Epoch 1232/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3465 - val_loss: 0.4703\n",
            "Epoch 1233/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3463 - val_loss: 0.4723\n",
            "Epoch 1234/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3457 - val_loss: 0.4683\n",
            "Epoch 1235/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3459 - val_loss: 0.4712\n",
            "Epoch 1236/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3461 - val_loss: 0.4740\n",
            "Epoch 1237/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3465 - val_loss: 0.4709\n",
            "Epoch 1238/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3466 - val_loss: 0.4765\n",
            "Epoch 1239/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3464 - val_loss: 0.4719\n",
            "Epoch 1240/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3461 - val_loss: 0.4743\n",
            "Epoch 1241/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3458 - val_loss: 0.4755\n",
            "Epoch 1242/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3455 - val_loss: 0.4764\n",
            "Epoch 1243/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3453 - val_loss: 0.4659\n",
            "Epoch 1244/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3467 - val_loss: 0.4653\n",
            "Epoch 1245/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3449 - val_loss: 0.4789\n",
            "Epoch 1246/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3457 - val_loss: 0.4710\n",
            "Epoch 1247/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3458 - val_loss: 0.4700\n",
            "Epoch 1248/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3452 - val_loss: 0.4755\n",
            "Epoch 1249/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3464 - val_loss: 0.4689\n",
            "Epoch 1250/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3448 - val_loss: 0.4746\n",
            "Epoch 1251/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3468 - val_loss: 0.4757\n",
            "Epoch 1252/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3453 - val_loss: 0.4666\n",
            "Epoch 1253/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3468 - val_loss: 0.4751\n",
            "Epoch 1254/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3454 - val_loss: 0.4800\n",
            "Epoch 1255/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3467 - val_loss: 0.4724\n",
            "Epoch 1256/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3451 - val_loss: 0.4743\n",
            "Epoch 1257/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3456 - val_loss: 0.4692\n",
            "Epoch 1258/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3458 - val_loss: 0.4715\n",
            "Epoch 1259/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3458 - val_loss: 0.4708\n",
            "Epoch 1260/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3449 - val_loss: 0.4704\n",
            "Epoch 1261/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3460 - val_loss: 0.4687\n",
            "Epoch 1262/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3451 - val_loss: 0.4714\n",
            "Epoch 1263/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3457 - val_loss: 0.4723\n",
            "Epoch 1264/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3460 - val_loss: 0.4700\n",
            "Epoch 1265/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3448 - val_loss: 0.4670\n",
            "Epoch 1266/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3456 - val_loss: 0.4676\n",
            "Epoch 1267/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3449 - val_loss: 0.4727\n",
            "Epoch 1268/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3457 - val_loss: 0.4722\n",
            "Epoch 1269/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3450 - val_loss: 0.4669\n",
            "Epoch 1270/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3446 - val_loss: 0.4789\n",
            "Epoch 1271/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3438 - val_loss: 0.4627\n",
            "Epoch 1272/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3460 - val_loss: 0.4738\n",
            "Epoch 1273/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3453 - val_loss: 0.4751\n",
            "Epoch 1274/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3447 - val_loss: 0.4705\n",
            "Epoch 1275/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3453 - val_loss: 0.4687\n",
            "Epoch 1276/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3450 - val_loss: 0.4722\n",
            "Epoch 1277/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3458 - val_loss: 0.4654\n",
            "Epoch 1278/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3457 - val_loss: 0.4664\n",
            "Epoch 1279/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3460 - val_loss: 0.4679\n",
            "Epoch 1280/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3453 - val_loss: 0.4718\n",
            "Epoch 1281/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3444 - val_loss: 0.4760\n",
            "Epoch 1282/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3458 - val_loss: 0.4694\n",
            "Epoch 1283/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3447 - val_loss: 0.4692\n",
            "Epoch 1284/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3450 - val_loss: 0.4645\n",
            "Epoch 1285/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3455 - val_loss: 0.4682\n",
            "Epoch 1286/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3449 - val_loss: 0.4656\n",
            "Epoch 1287/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3449 - val_loss: 0.4697\n",
            "Epoch 1288/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3441 - val_loss: 0.4715\n",
            "Epoch 1289/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3445 - val_loss: 0.4714\n",
            "Epoch 1290/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3436 - val_loss: 0.4638\n",
            "Epoch 1291/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3450 - val_loss: 0.4683\n",
            "Epoch 1292/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3453 - val_loss: 0.4644\n",
            "Epoch 1293/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3459 - val_loss: 0.4689\n",
            "Epoch 1294/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3446 - val_loss: 0.4693\n",
            "Epoch 1295/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3448 - val_loss: 0.4722\n",
            "Epoch 1296/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3446 - val_loss: 0.4719\n",
            "Epoch 1297/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3441 - val_loss: 0.4645\n",
            "Epoch 1298/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3456 - val_loss: 0.4665\n",
            "Epoch 1299/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3454 - val_loss: 0.4654\n",
            "Epoch 1300/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3452 - val_loss: 0.4703\n",
            "Epoch 1301/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3447 - val_loss: 0.4710\n",
            "Epoch 1302/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3445 - val_loss: 0.4685\n",
            "Epoch 1303/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3426 - val_loss: 0.4603\n",
            "Epoch 1304/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3456 - val_loss: 0.4681\n",
            "Epoch 1305/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3442 - val_loss: 0.4735\n",
            "Epoch 1306/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3438 - val_loss: 0.4702\n",
            "Epoch 1307/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3431 - val_loss: 0.4638\n",
            "Epoch 1308/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3433 - val_loss: 0.4734\n",
            "Epoch 1309/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3439 - val_loss: 0.4663\n",
            "Epoch 1310/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3437 - val_loss: 0.4676\n",
            "Epoch 1311/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3433 - val_loss: 0.4635\n",
            "Epoch 1312/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3437 - val_loss: 0.4623\n",
            "Epoch 1313/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3443 - val_loss: 0.4645\n",
            "Epoch 1314/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3441 - val_loss: 0.4642\n",
            "Epoch 1315/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3443 - val_loss: 0.4638\n",
            "Epoch 1316/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3434 - val_loss: 0.4658\n",
            "Epoch 1317/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3436 - val_loss: 0.4658\n",
            "Epoch 1318/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3440 - val_loss: 0.4654\n",
            "Epoch 1319/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3446 - val_loss: 0.4564\n",
            "Epoch 1320/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3429 - val_loss: 0.4662\n",
            "Epoch 1321/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3434 - val_loss: 0.4568\n",
            "Epoch 1322/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3437 - val_loss: 0.4665\n",
            "Epoch 1323/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3439 - val_loss: 0.4715\n",
            "Epoch 1324/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3452 - val_loss: 0.4703\n",
            "Epoch 1325/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3439 - val_loss: 0.4694\n",
            "Epoch 1326/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3439 - val_loss: 0.4672\n",
            "Epoch 1327/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3429 - val_loss: 0.4663\n",
            "Epoch 1328/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3431 - val_loss: 0.4661\n",
            "Epoch 1329/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3440 - val_loss: 0.4642\n",
            "Epoch 1330/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3428 - val_loss: 0.4608\n",
            "Epoch 1331/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3430 - val_loss: 0.4567\n",
            "Epoch 1332/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3434 - val_loss: 0.4654\n",
            "Epoch 1333/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3433 - val_loss: 0.4603\n",
            "Epoch 1334/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3442 - val_loss: 0.4604\n",
            "Epoch 1335/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3438 - val_loss: 0.4640\n",
            "Epoch 1336/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3439 - val_loss: 0.4710\n",
            "Epoch 1337/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3432 - val_loss: 0.4638\n",
            "Epoch 1338/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3427 - val_loss: 0.4682\n",
            "Epoch 1339/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3430 - val_loss: 0.4660\n",
            "Epoch 1340/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3438 - val_loss: 0.4657\n",
            "Epoch 1341/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3415 - val_loss: 0.4609\n",
            "Epoch 1342/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3435 - val_loss: 0.4595\n",
            "Epoch 1343/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3427 - val_loss: 0.4638\n",
            "Epoch 1344/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3429 - val_loss: 0.4651\n",
            "Epoch 1345/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3449 - val_loss: 0.4690\n",
            "Epoch 1346/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3427 - val_loss: 0.4643\n",
            "Epoch 1347/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3433 - val_loss: 0.4603\n",
            "Epoch 1348/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3428 - val_loss: 0.4652\n",
            "Epoch 1349/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3427 - val_loss: 0.4647\n",
            "Epoch 1350/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3422 - val_loss: 0.4635\n",
            "Epoch 1351/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3438 - val_loss: 0.4661\n",
            "Epoch 1352/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3416 - val_loss: 0.4576\n",
            "Epoch 1353/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3439 - val_loss: 0.4589\n",
            "Epoch 1354/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3431 - val_loss: 0.4675\n",
            "Epoch 1355/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3432 - val_loss: 0.4633\n",
            "Epoch 1356/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3428 - val_loss: 0.4637\n",
            "Epoch 1357/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3421 - val_loss: 0.4644\n",
            "Epoch 1358/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3432 - val_loss: 0.4634\n",
            "Epoch 1359/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3417 - val_loss: 0.4668\n",
            "Epoch 1360/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3424 - val_loss: 0.4602\n",
            "Epoch 1361/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3434 - val_loss: 0.4562\n",
            "Epoch 1362/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3432 - val_loss: 0.4677\n",
            "Epoch 1363/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3423 - val_loss: 0.4641\n",
            "Epoch 1364/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3438 - val_loss: 0.4647\n",
            "Epoch 1365/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3427 - val_loss: 0.4600\n",
            "Epoch 1366/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3431 - val_loss: 0.4617\n",
            "Epoch 1367/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3425 - val_loss: 0.4566\n",
            "Epoch 1368/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3425 - val_loss: 0.4701\n",
            "Epoch 1369/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3434 - val_loss: 0.4658\n",
            "Epoch 1370/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3429 - val_loss: 0.4599\n",
            "Epoch 1371/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3429 - val_loss: 0.4646\n",
            "Epoch 1372/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3427 - val_loss: 0.4559\n",
            "Epoch 1373/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3424 - val_loss: 0.4670\n",
            "Epoch 1374/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3424 - val_loss: 0.4560\n",
            "Epoch 1375/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3425 - val_loss: 0.4611\n",
            "Epoch 1376/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3423 - val_loss: 0.4601\n",
            "Epoch 1377/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3422 - val_loss: 0.4606\n",
            "Epoch 1378/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3428 - val_loss: 0.4562\n",
            "Epoch 1379/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3427 - val_loss: 0.4568\n",
            "Epoch 1380/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3439 - val_loss: 0.4591\n",
            "Epoch 1381/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3417 - val_loss: 0.4619\n",
            "Epoch 1382/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3424 - val_loss: 0.4616\n",
            "Epoch 1383/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3416 - val_loss: 0.4583\n",
            "Epoch 1384/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3431 - val_loss: 0.4603\n",
            "Epoch 1385/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3421 - val_loss: 0.4594\n",
            "Epoch 1386/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3427 - val_loss: 0.4627\n",
            "Epoch 1387/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3413 - val_loss: 0.4563\n",
            "Epoch 1388/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3421 - val_loss: 0.4611\n",
            "Epoch 1389/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3421 - val_loss: 0.4587\n",
            "Epoch 1390/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3416 - val_loss: 0.4641\n",
            "Epoch 1391/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3412 - val_loss: 0.4681\n",
            "Epoch 1392/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3415 - val_loss: 0.4594\n",
            "Epoch 1393/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3413 - val_loss: 0.4639\n",
            "Epoch 1394/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3424 - val_loss: 0.4597\n",
            "Epoch 1395/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3422 - val_loss: 0.4588\n",
            "Epoch 1396/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3421 - val_loss: 0.4564\n",
            "Epoch 1397/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3414 - val_loss: 0.4603\n",
            "Epoch 1398/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3412 - val_loss: 0.4552\n",
            "Epoch 1399/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3422 - val_loss: 0.4556\n",
            "Epoch 1400/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3407 - val_loss: 0.4656\n",
            "Epoch 1401/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3417 - val_loss: 0.4638\n",
            "Epoch 1402/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3419 - val_loss: 0.4575\n",
            "Epoch 1403/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3416 - val_loss: 0.4627\n",
            "Epoch 1404/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3419 - val_loss: 0.4639\n",
            "Epoch 1405/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3412 - val_loss: 0.4546\n",
            "Epoch 1406/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3416 - val_loss: 0.4626\n",
            "Epoch 1407/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3409 - val_loss: 0.4553\n",
            "Epoch 1408/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3424 - val_loss: 0.4573\n",
            "Epoch 1409/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3419 - val_loss: 0.4577\n",
            "Epoch 1410/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3407 - val_loss: 0.4555\n",
            "Epoch 1411/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3410 - val_loss: 0.4576\n",
            "Epoch 1412/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3414 - val_loss: 0.4574\n",
            "Epoch 1413/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3417 - val_loss: 0.4589\n",
            "Epoch 1414/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3406 - val_loss: 0.4543\n",
            "Epoch 1415/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3417 - val_loss: 0.4540\n",
            "Epoch 1416/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3419 - val_loss: 0.4628\n",
            "Epoch 1417/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3413 - val_loss: 0.4581\n",
            "Epoch 1418/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3420 - val_loss: 0.4532\n",
            "Epoch 1419/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3404 - val_loss: 0.4546\n",
            "Epoch 1420/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3415 - val_loss: 0.4579\n",
            "Epoch 1421/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3417 - val_loss: 0.4587\n",
            "Epoch 1422/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3407 - val_loss: 0.4585\n",
            "Epoch 1423/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3399 - val_loss: 0.4530\n",
            "Epoch 1424/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3422 - val_loss: 0.4553\n",
            "Epoch 1425/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3409 - val_loss: 0.4608\n",
            "Epoch 1426/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3405 - val_loss: 0.4612\n",
            "Epoch 1427/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3405 - val_loss: 0.4530\n",
            "Epoch 1428/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3408 - val_loss: 0.4578\n",
            "Epoch 1429/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3412 - val_loss: 0.4563\n",
            "Epoch 1430/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3411 - val_loss: 0.4563\n",
            "Epoch 1431/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3405 - val_loss: 0.4551\n",
            "Epoch 1432/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3404 - val_loss: 0.4564\n",
            "Epoch 1433/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3406 - val_loss: 0.4553\n",
            "Epoch 1434/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3406 - val_loss: 0.4536\n",
            "Epoch 1435/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3399 - val_loss: 0.4503\n",
            "Epoch 1436/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3410 - val_loss: 0.4576\n",
            "Epoch 1437/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3405 - val_loss: 0.4510\n",
            "Epoch 1438/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3409 - val_loss: 0.4551\n",
            "Epoch 1439/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3402 - val_loss: 0.4529\n",
            "Epoch 1440/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3414 - val_loss: 0.4555\n",
            "Epoch 1441/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3409 - val_loss: 0.4562\n",
            "Epoch 1442/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3416 - val_loss: 0.4545\n",
            "Epoch 1443/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3402 - val_loss: 0.4557\n",
            "Epoch 1444/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3413 - val_loss: 0.4537\n",
            "Epoch 1445/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3402 - val_loss: 0.4535\n",
            "Epoch 1446/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3406 - val_loss: 0.4527\n",
            "Epoch 1447/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3403 - val_loss: 0.4570\n",
            "Epoch 1448/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3403 - val_loss: 0.4583\n",
            "Epoch 1449/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3405 - val_loss: 0.4593\n",
            "Epoch 1450/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3410 - val_loss: 0.4571\n",
            "Epoch 1451/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3392 - val_loss: 0.4516\n",
            "Epoch 1452/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3402 - val_loss: 0.4541\n",
            "Epoch 1453/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3394 - val_loss: 0.4529\n",
            "Epoch 1454/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3400 - val_loss: 0.4533\n",
            "Epoch 1455/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3405 - val_loss: 0.4533\n",
            "Epoch 1456/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3400 - val_loss: 0.4554\n",
            "Epoch 1457/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3401 - val_loss: 0.4535\n",
            "Epoch 1458/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3404 - val_loss: 0.4530\n",
            "Epoch 1459/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3395 - val_loss: 0.4563\n",
            "Epoch 1460/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3401 - val_loss: 0.4521\n",
            "Epoch 1461/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3400 - val_loss: 0.4571\n",
            "Epoch 1462/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3396 - val_loss: 0.4529\n",
            "Epoch 1463/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3415 - val_loss: 0.4576\n",
            "Epoch 1464/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3395 - val_loss: 0.4536\n",
            "Epoch 1465/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3395 - val_loss: 0.4589\n",
            "Epoch 1466/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3394 - val_loss: 0.4565\n",
            "Epoch 1467/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3397 - val_loss: 0.4553\n",
            "Epoch 1468/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3395 - val_loss: 0.4522\n",
            "Epoch 1469/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3399 - val_loss: 0.4539\n",
            "Epoch 1470/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3406 - val_loss: 0.4536\n",
            "Epoch 1471/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3397 - val_loss: 0.4523\n",
            "Epoch 1472/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3402 - val_loss: 0.4517\n",
            "Epoch 1473/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3404 - val_loss: 0.4518\n",
            "Epoch 1474/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3397 - val_loss: 0.4537\n",
            "Epoch 1475/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3400 - val_loss: 0.4496\n",
            "Epoch 1476/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3399 - val_loss: 0.4543\n",
            "Epoch 1477/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3393 - val_loss: 0.4580\n",
            "Epoch 1478/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3402 - val_loss: 0.4529\n",
            "Epoch 1479/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3399 - val_loss: 0.4502\n",
            "Epoch 1480/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3394 - val_loss: 0.4541\n",
            "Epoch 1481/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3396 - val_loss: 0.4510\n",
            "Epoch 1482/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3390 - val_loss: 0.4563\n",
            "Epoch 1483/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3398 - val_loss: 0.4554\n",
            "Epoch 1484/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3391 - val_loss: 0.4509\n",
            "Epoch 1485/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3409 - val_loss: 0.4565\n",
            "Epoch 1486/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3397 - val_loss: 0.4515\n",
            "Epoch 1487/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3390 - val_loss: 0.4500\n",
            "Epoch 1488/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3394 - val_loss: 0.4546\n",
            "Epoch 1489/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3397 - val_loss: 0.4514\n",
            "Epoch 1490/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3387 - val_loss: 0.4593\n",
            "Epoch 1491/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3386 - val_loss: 0.4544\n",
            "Epoch 1492/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3389 - val_loss: 0.4552\n",
            "Epoch 1493/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3394 - val_loss: 0.4608\n",
            "Epoch 1494/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3399 - val_loss: 0.4547\n",
            "Epoch 1495/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3391 - val_loss: 0.4560\n",
            "Epoch 1496/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3385 - val_loss: 0.4548\n",
            "Epoch 1497/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3389 - val_loss: 0.4510\n",
            "Epoch 1498/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3399 - val_loss: 0.4497\n",
            "Epoch 1499/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3390 - val_loss: 0.4569\n",
            "Epoch 1500/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3397 - val_loss: 0.4543\n",
            "Epoch 1501/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3391 - val_loss: 0.4574\n",
            "Epoch 1502/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3389 - val_loss: 0.4557\n",
            "Epoch 1503/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3389 - val_loss: 0.4541\n",
            "Epoch 1504/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3383 - val_loss: 0.4512\n",
            "Epoch 1505/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3375 - val_loss: 0.4620\n",
            "Epoch 1506/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3389 - val_loss: 0.4518\n",
            "Epoch 1507/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3379 - val_loss: 0.4569\n",
            "Epoch 1508/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3399 - val_loss: 0.4592\n",
            "Epoch 1509/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3388 - val_loss: 0.4541\n",
            "Epoch 1510/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3389 - val_loss: 0.4566\n",
            "Epoch 1511/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3381 - val_loss: 0.4525\n",
            "Epoch 1512/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3378 - val_loss: 0.4484\n",
            "Epoch 1513/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3378 - val_loss: 0.4590\n",
            "Epoch 1514/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3391 - val_loss: 0.4563\n",
            "Epoch 1515/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3385 - val_loss: 0.4553\n",
            "Epoch 1516/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3381 - val_loss: 0.4503\n",
            "Epoch 1517/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3389 - val_loss: 0.4538\n",
            "Epoch 1518/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3386 - val_loss: 0.4556\n",
            "Epoch 1519/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3401 - val_loss: 0.4512\n",
            "Epoch 1520/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3392 - val_loss: 0.4543\n",
            "Epoch 1521/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3388 - val_loss: 0.4551\n",
            "Epoch 1522/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3381 - val_loss: 0.4540\n",
            "Epoch 1523/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3385 - val_loss: 0.4518\n",
            "Epoch 1524/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3389 - val_loss: 0.4532\n",
            "Epoch 1525/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3387 - val_loss: 0.4509\n",
            "Epoch 1526/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3389 - val_loss: 0.4538\n",
            "Epoch 1527/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3374 - val_loss: 0.4492\n",
            "Epoch 1528/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3381 - val_loss: 0.4573\n",
            "Epoch 1529/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3379 - val_loss: 0.4515\n",
            "Epoch 1530/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3391 - val_loss: 0.4564\n",
            "Epoch 1531/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3383 - val_loss: 0.4524\n",
            "Epoch 1532/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3386 - val_loss: 0.4514\n",
            "Epoch 1533/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3372 - val_loss: 0.4478\n",
            "Epoch 1534/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3384 - val_loss: 0.4508\n",
            "Epoch 1535/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3379 - val_loss: 0.4580\n",
            "Epoch 1536/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3378 - val_loss: 0.4552\n",
            "Epoch 1537/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3381 - val_loss: 0.4498\n",
            "Epoch 1538/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3364 - val_loss: 0.4615\n",
            "Epoch 1539/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3379 - val_loss: 0.4546\n",
            "Epoch 1540/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3378 - val_loss: 0.4541\n",
            "Epoch 1541/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3389 - val_loss: 0.4546\n",
            "Epoch 1542/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3374 - val_loss: 0.4518\n",
            "Epoch 1543/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3375 - val_loss: 0.4503\n",
            "Epoch 1544/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3376 - val_loss: 0.4506\n",
            "Epoch 1545/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3390 - val_loss: 0.4538\n",
            "Epoch 1546/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3378 - val_loss: 0.4511\n",
            "Epoch 1547/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3375 - val_loss: 0.4483\n",
            "Epoch 1548/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3391 - val_loss: 0.4497\n",
            "Epoch 1549/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3373 - val_loss: 0.4528\n",
            "Epoch 1550/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3375 - val_loss: 0.4517\n",
            "Epoch 1551/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3374 - val_loss: 0.4526\n",
            "Epoch 1552/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3375 - val_loss: 0.4505\n",
            "Epoch 1553/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3371 - val_loss: 0.4530\n",
            "Epoch 1554/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3378 - val_loss: 0.4540\n",
            "Epoch 1555/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3376 - val_loss: 0.4530\n",
            "Epoch 1556/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3369 - val_loss: 0.4495\n",
            "Epoch 1557/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3386 - val_loss: 0.4511\n",
            "Epoch 1558/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3375 - val_loss: 0.4508\n",
            "Epoch 1559/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3373 - val_loss: 0.4492\n",
            "Epoch 1560/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3371 - val_loss: 0.4519\n",
            "Epoch 1561/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3369 - val_loss: 0.4545\n",
            "Epoch 1562/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3371 - val_loss: 0.4481\n",
            "Epoch 1563/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3371 - val_loss: 0.4512\n",
            "Epoch 1564/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3381 - val_loss: 0.4516\n",
            "Epoch 1565/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3369 - val_loss: 0.4521\n",
            "Epoch 1566/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3376 - val_loss: 0.4454\n",
            "Epoch 1567/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3376 - val_loss: 0.4496\n",
            "Epoch 1568/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3368 - val_loss: 0.4478\n",
            "Epoch 1569/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3367 - val_loss: 0.4547\n",
            "Epoch 1570/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3368 - val_loss: 0.4501\n",
            "Epoch 1571/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3381 - val_loss: 0.4486\n",
            "Epoch 1572/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3374 - val_loss: 0.4488\n",
            "Epoch 1573/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3369 - val_loss: 0.4489\n",
            "Epoch 1574/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3370 - val_loss: 0.4496\n",
            "Epoch 1575/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3378 - val_loss: 0.4520\n",
            "Epoch 1576/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3375 - val_loss: 0.4486\n",
            "Epoch 1577/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3367 - val_loss: 0.4471\n",
            "Epoch 1578/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3370 - val_loss: 0.4510\n",
            "Epoch 1579/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3362 - val_loss: 0.4539\n",
            "Epoch 1580/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3365 - val_loss: 0.4512\n",
            "Epoch 1581/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3367 - val_loss: 0.4525\n",
            "Epoch 1582/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3362 - val_loss: 0.4489\n",
            "Epoch 1583/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3367 - val_loss: 0.4545\n",
            "Epoch 1584/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3365 - val_loss: 0.4523\n",
            "Epoch 1585/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3367 - val_loss: 0.4530\n",
            "Epoch 1586/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3368 - val_loss: 0.4518\n",
            "Epoch 1587/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3363 - val_loss: 0.4502\n",
            "Epoch 1588/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3358 - val_loss: 0.4534\n",
            "Epoch 1589/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3366 - val_loss: 0.4493\n",
            "Epoch 1590/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3362 - val_loss: 0.4521\n",
            "Epoch 1591/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3365 - val_loss: 0.4502\n",
            "Epoch 1592/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3365 - val_loss: 0.4515\n",
            "Epoch 1593/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3360 - val_loss: 0.4534\n",
            "Epoch 1594/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3373 - val_loss: 0.4524\n",
            "Epoch 1595/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3359 - val_loss: 0.4489\n",
            "Epoch 1596/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3363 - val_loss: 0.4497\n",
            "Epoch 1597/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3363 - val_loss: 0.4487\n",
            "Epoch 1598/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3365 - val_loss: 0.4488\n",
            "Epoch 1599/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3358 - val_loss: 0.4514\n",
            "Epoch 1600/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3387 - val_loss: 0.4501\n",
            "Epoch 1601/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3356 - val_loss: 0.4534\n",
            "Epoch 1602/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3357 - val_loss: 0.4550\n",
            "Epoch 1603/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3360 - val_loss: 0.4538\n",
            "Epoch 1604/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3356 - val_loss: 0.4488\n",
            "Epoch 1605/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3361 - val_loss: 0.4495\n",
            "Epoch 1606/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3365 - val_loss: 0.4481\n",
            "Epoch 1607/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3354 - val_loss: 0.4533\n",
            "Epoch 1608/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3358 - val_loss: 0.4476\n",
            "Epoch 1609/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3369 - val_loss: 0.4510\n",
            "Epoch 1610/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3357 - val_loss: 0.4506\n",
            "Epoch 1611/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3362 - val_loss: 0.4500\n",
            "Epoch 1612/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3353 - val_loss: 0.4460\n",
            "Epoch 1613/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3364 - val_loss: 0.4504\n",
            "Epoch 1614/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3359 - val_loss: 0.4527\n",
            "Epoch 1615/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3367 - val_loss: 0.4521\n",
            "Epoch 1616/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3353 - val_loss: 0.4471\n",
            "Epoch 1617/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3351 - val_loss: 0.4547\n",
            "Epoch 1618/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3361 - val_loss: 0.4530\n",
            "Epoch 1619/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3359 - val_loss: 0.4457\n",
            "Epoch 1620/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3357 - val_loss: 0.4473\n",
            "Epoch 1621/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3353 - val_loss: 0.4470\n",
            "Epoch 1622/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3355 - val_loss: 0.4500\n",
            "Epoch 1623/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3355 - val_loss: 0.4463\n",
            "Epoch 1624/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3367 - val_loss: 0.4484\n",
            "Epoch 1625/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3353 - val_loss: 0.4477\n",
            "Epoch 1626/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3352 - val_loss: 0.4509\n",
            "Epoch 1627/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3351 - val_loss: 0.4504\n",
            "Epoch 1628/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3353 - val_loss: 0.4463\n",
            "Epoch 1629/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3350 - val_loss: 0.4493\n",
            "Epoch 1630/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3352 - val_loss: 0.4519\n",
            "Epoch 1631/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3354 - val_loss: 0.4527\n",
            "Epoch 1632/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3357 - val_loss: 0.4506\n",
            "Epoch 1633/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3358 - val_loss: 0.4494\n",
            "Epoch 1634/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3355 - val_loss: 0.4498\n",
            "Epoch 1635/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3350 - val_loss: 0.4464\n",
            "Epoch 1636/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3358 - val_loss: 0.4434\n",
            "Epoch 1637/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3364 - val_loss: 0.4489\n",
            "Epoch 1638/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3352 - val_loss: 0.4499\n",
            "Epoch 1639/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3356 - val_loss: 0.4496\n",
            "Epoch 1640/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3361 - val_loss: 0.4462\n",
            "Epoch 1641/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3346 - val_loss: 0.4508\n",
            "Epoch 1642/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3349 - val_loss: 0.4463\n",
            "Epoch 1643/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3345 - val_loss: 0.4502\n",
            "Epoch 1644/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3350 - val_loss: 0.4491\n",
            "Epoch 1645/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3346 - val_loss: 0.4470\n",
            "Epoch 1646/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3347 - val_loss: 0.4461\n",
            "Epoch 1647/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3348 - val_loss: 0.4503\n",
            "Epoch 1648/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3356 - val_loss: 0.4482\n",
            "Epoch 1649/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3357 - val_loss: 0.4461\n",
            "Epoch 1650/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3355 - val_loss: 0.4483\n",
            "Epoch 1651/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3345 - val_loss: 0.4459\n",
            "Epoch 1652/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3349 - val_loss: 0.4486\n",
            "Epoch 1653/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3362 - val_loss: 0.4483\n",
            "Epoch 1654/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3349 - val_loss: 0.4496\n",
            "Epoch 1655/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3340 - val_loss: 0.4517\n",
            "Epoch 1656/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3345 - val_loss: 0.4491\n",
            "Epoch 1657/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3343 - val_loss: 0.4517\n",
            "Epoch 1658/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3349 - val_loss: 0.4489\n",
            "Epoch 1659/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3342 - val_loss: 0.4532\n",
            "Epoch 1660/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3358 - val_loss: 0.4497\n",
            "Epoch 1661/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3349 - val_loss: 0.4495\n",
            "Epoch 1662/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3350 - val_loss: 0.4499\n",
            "Epoch 1663/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3345 - val_loss: 0.4522\n",
            "Epoch 1664/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3351 - val_loss: 0.4453\n",
            "Epoch 1665/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3334 - val_loss: 0.4439\n",
            "Epoch 1666/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3349 - val_loss: 0.4513\n",
            "Epoch 1667/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3340 - val_loss: 0.4499\n",
            "Epoch 1668/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3344 - val_loss: 0.4472\n",
            "Epoch 1669/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3349 - val_loss: 0.4496\n",
            "Epoch 1670/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3347 - val_loss: 0.4456\n",
            "Epoch 1671/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3339 - val_loss: 0.4457\n",
            "Epoch 1672/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3342 - val_loss: 0.4454\n",
            "Epoch 1673/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3350 - val_loss: 0.4478\n",
            "Epoch 1674/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3349 - val_loss: 0.4481\n",
            "Epoch 1675/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3346 - val_loss: 0.4486\n",
            "Epoch 1676/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3338 - val_loss: 0.4449\n",
            "Epoch 1677/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3341 - val_loss: 0.4475\n",
            "Epoch 1678/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3332 - val_loss: 0.4531\n",
            "Epoch 1679/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3354 - val_loss: 0.4479\n",
            "Epoch 1680/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3333 - val_loss: 0.4549\n",
            "Epoch 1681/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3340 - val_loss: 0.4474\n",
            "Epoch 1682/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3337 - val_loss: 0.4499\n",
            "Epoch 1683/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3338 - val_loss: 0.4523\n",
            "Epoch 1684/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3337 - val_loss: 0.4480\n",
            "Epoch 1685/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3333 - val_loss: 0.4460\n",
            "Epoch 1686/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3355 - val_loss: 0.4469\n",
            "Epoch 1687/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3339 - val_loss: 0.4494\n",
            "Epoch 1688/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3340 - val_loss: 0.4488\n",
            "Epoch 1689/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3339 - val_loss: 0.4494\n",
            "Epoch 1690/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3346 - val_loss: 0.4494\n",
            "Epoch 1691/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3333 - val_loss: 0.4522\n",
            "Epoch 1692/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3326 - val_loss: 0.4489\n",
            "Epoch 1693/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3341 - val_loss: 0.4472\n",
            "Epoch 1694/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3344 - val_loss: 0.4444\n",
            "Epoch 1695/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3342 - val_loss: 0.4476\n",
            "Epoch 1696/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3336 - val_loss: 0.4468\n",
            "Epoch 1697/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3349 - val_loss: 0.4506\n",
            "Epoch 1698/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3319 - val_loss: 0.4426\n",
            "Epoch 1699/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3338 - val_loss: 0.4502\n",
            "Epoch 1700/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3341 - val_loss: 0.4518\n",
            "Epoch 1701/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3348 - val_loss: 0.4503\n",
            "Epoch 1702/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3334 - val_loss: 0.4487\n",
            "Epoch 1703/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3339 - val_loss: 0.4502\n",
            "Epoch 1704/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3332 - val_loss: 0.4489\n",
            "Epoch 1705/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3336 - val_loss: 0.4455\n",
            "Epoch 1706/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3325 - val_loss: 0.4436\n",
            "Epoch 1707/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3332 - val_loss: 0.4514\n",
            "Epoch 1708/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3335 - val_loss: 0.4497\n",
            "Epoch 1709/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3334 - val_loss: 0.4481\n",
            "Epoch 1710/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3330 - val_loss: 0.4478\n",
            "Epoch 1711/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3321 - val_loss: 0.4448\n",
            "Epoch 1712/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3339 - val_loss: 0.4502\n",
            "Epoch 1713/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3335 - val_loss: 0.4501\n",
            "Epoch 1714/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3326 - val_loss: 0.4476\n",
            "Epoch 1715/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3331 - val_loss: 0.4464\n",
            "Epoch 1716/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3333 - val_loss: 0.4468\n",
            "Epoch 1717/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3327 - val_loss: 0.4471\n",
            "Epoch 1718/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3330 - val_loss: 0.4503\n",
            "Epoch 1719/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3324 - val_loss: 0.4471\n",
            "Epoch 1720/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3338 - val_loss: 0.4474\n",
            "Epoch 1721/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3328 - val_loss: 0.4533\n",
            "Epoch 1722/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3339 - val_loss: 0.4481\n",
            "Epoch 1723/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3333 - val_loss: 0.4480\n",
            "Epoch 1724/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3329 - val_loss: 0.4497\n",
            "Epoch 1725/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3318 - val_loss: 0.4443\n",
            "Epoch 1726/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3323 - val_loss: 0.4512\n",
            "Epoch 1727/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3330 - val_loss: 0.4521\n",
            "Epoch 1728/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3322 - val_loss: 0.4486\n",
            "Epoch 1729/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3360 - val_loss: 0.4457\n",
            "Epoch 1730/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3322 - val_loss: 0.4510\n",
            "Epoch 1731/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3339 - val_loss: 0.4518\n",
            "Epoch 1732/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3324 - val_loss: 0.4465\n",
            "Epoch 1733/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3335 - val_loss: 0.4457\n",
            "Epoch 1734/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3328 - val_loss: 0.4489\n",
            "Epoch 1735/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3311 - val_loss: 0.4444\n",
            "Epoch 1736/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3331 - val_loss: 0.4509\n",
            "Epoch 1737/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3328 - val_loss: 0.4488\n",
            "Epoch 1738/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3328 - val_loss: 0.4504\n",
            "Epoch 1739/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3321 - val_loss: 0.4497\n",
            "Epoch 1740/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3318 - val_loss: 0.4457\n",
            "Epoch 1741/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3325 - val_loss: 0.4470\n",
            "Epoch 1742/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3321 - val_loss: 0.4475\n",
            "Epoch 1743/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3340 - val_loss: 0.4447\n",
            "Epoch 1744/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3318 - val_loss: 0.4481\n",
            "Epoch 1745/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3316 - val_loss: 0.4460\n",
            "Epoch 1746/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3323 - val_loss: 0.4484\n",
            "Epoch 1747/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3322 - val_loss: 0.4471\n",
            "Epoch 1748/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3319 - val_loss: 0.4415\n",
            "Epoch 1749/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3322 - val_loss: 0.4473\n",
            "Epoch 1750/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3318 - val_loss: 0.4442\n",
            "Epoch 1751/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3315 - val_loss: 0.4457\n",
            "Epoch 1752/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3326 - val_loss: 0.4433\n",
            "Epoch 1753/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3317 - val_loss: 0.4473\n",
            "Epoch 1754/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3322 - val_loss: 0.4502\n",
            "Epoch 1755/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3325 - val_loss: 0.4485\n",
            "Epoch 1756/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3318 - val_loss: 0.4464\n",
            "Epoch 1757/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3321 - val_loss: 0.4471\n",
            "Epoch 1758/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3310 - val_loss: 0.4512\n",
            "Epoch 1759/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3323 - val_loss: 0.4463\n",
            "Epoch 1760/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3316 - val_loss: 0.4467\n",
            "Epoch 1761/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3309 - val_loss: 0.4519\n",
            "Epoch 1762/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3322 - val_loss: 0.4481\n",
            "Epoch 1763/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3318 - val_loss: 0.4495\n",
            "Epoch 1764/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3324 - val_loss: 0.4480\n",
            "Epoch 1765/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3312 - val_loss: 0.4482\n",
            "Epoch 1766/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3311 - val_loss: 0.4473\n",
            "Epoch 1767/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3312 - val_loss: 0.4447\n",
            "Epoch 1768/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3316 - val_loss: 0.4457\n",
            "Epoch 1769/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3324 - val_loss: 0.4495\n",
            "Epoch 1770/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3328 - val_loss: 0.4460\n",
            "Epoch 1771/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3311 - val_loss: 0.4450\n",
            "Epoch 1772/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3309 - val_loss: 0.4440\n",
            "Epoch 1773/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3314 - val_loss: 0.4474\n",
            "Epoch 1774/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3315 - val_loss: 0.4507\n",
            "Epoch 1775/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3325 - val_loss: 0.4473\n",
            "Epoch 1776/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3316 - val_loss: 0.4506\n",
            "Epoch 1777/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3312 - val_loss: 0.4508\n",
            "Epoch 1778/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3317 - val_loss: 0.4452\n",
            "Epoch 1779/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3313 - val_loss: 0.4507\n",
            "Epoch 1780/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3319 - val_loss: 0.4435\n",
            "Epoch 1781/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3329 - val_loss: 0.4494\n",
            "Epoch 1782/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3311 - val_loss: 0.4488\n",
            "Epoch 1783/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3307 - val_loss: 0.4448\n",
            "Epoch 1784/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3316 - val_loss: 0.4495\n",
            "Epoch 1785/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3313 - val_loss: 0.4484\n",
            "Epoch 1786/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3306 - val_loss: 0.4523\n",
            "Epoch 1787/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3315 - val_loss: 0.4526\n",
            "Epoch 1788/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3315 - val_loss: 0.4498\n",
            "Epoch 1789/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3308 - val_loss: 0.4510\n",
            "Epoch 1790/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3306 - val_loss: 0.4455\n",
            "Epoch 1791/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3307 - val_loss: 0.4459\n",
            "Epoch 1792/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3307 - val_loss: 0.4458\n",
            "Epoch 1793/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3300 - val_loss: 0.4521\n",
            "Epoch 1794/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3305 - val_loss: 0.4475\n",
            "Epoch 1795/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3305 - val_loss: 0.4486\n",
            "Epoch 1796/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3300 - val_loss: 0.4506\n",
            "Epoch 1797/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3311 - val_loss: 0.4469\n",
            "Epoch 1798/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3304 - val_loss: 0.4498\n",
            "Epoch 1799/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3317 - val_loss: 0.4450\n",
            "Epoch 1800/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3310 - val_loss: 0.4486\n",
            "Epoch 1801/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3312 - val_loss: 0.4469\n",
            "Epoch 1802/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3301 - val_loss: 0.4439\n",
            "Epoch 1803/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3313 - val_loss: 0.4445\n",
            "Epoch 1804/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3299 - val_loss: 0.4477\n",
            "Epoch 1805/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3301 - val_loss: 0.4449\n",
            "Epoch 1806/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3300 - val_loss: 0.4462\n",
            "Epoch 1807/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3306 - val_loss: 0.4481\n",
            "Epoch 1808/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3308 - val_loss: 0.4481\n",
            "Epoch 1809/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3307 - val_loss: 0.4467\n",
            "Epoch 1810/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3296 - val_loss: 0.4437\n",
            "Epoch 1811/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3300 - val_loss: 0.4476\n",
            "Epoch 1812/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3302 - val_loss: 0.4490\n",
            "Epoch 1813/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3293 - val_loss: 0.4467\n",
            "Epoch 1814/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3301 - val_loss: 0.4480\n",
            "Epoch 1815/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3297 - val_loss: 0.4441\n",
            "Epoch 1816/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3300 - val_loss: 0.4512\n",
            "Epoch 1817/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3311 - val_loss: 0.4474\n",
            "Epoch 1818/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3302 - val_loss: 0.4451\n",
            "Epoch 1819/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3303 - val_loss: 0.4502\n",
            "Epoch 1820/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3299 - val_loss: 0.4493\n",
            "Epoch 1821/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3299 - val_loss: 0.4456\n",
            "Epoch 1822/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3305 - val_loss: 0.4453\n",
            "Epoch 1823/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3298 - val_loss: 0.4498\n",
            "Epoch 1824/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3300 - val_loss: 0.4475\n",
            "Epoch 1825/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3294 - val_loss: 0.4438\n",
            "Epoch 1826/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3307 - val_loss: 0.4482\n",
            "Epoch 1827/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3300 - val_loss: 0.4453\n",
            "Epoch 1828/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3308 - val_loss: 0.4478\n",
            "Epoch 1829/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3315 - val_loss: 0.4480\n",
            "Epoch 1830/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3292 - val_loss: 0.4502\n",
            "Epoch 1831/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3292 - val_loss: 0.4461\n",
            "Epoch 1832/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3293 - val_loss: 0.4516\n",
            "Epoch 1833/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3289 - val_loss: 0.4439\n",
            "Epoch 1834/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3299 - val_loss: 0.4467\n",
            "Epoch 1835/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3295 - val_loss: 0.4528\n",
            "Epoch 1836/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3297 - val_loss: 0.4492\n",
            "Epoch 1837/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3304 - val_loss: 0.4492\n",
            "Epoch 1838/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3289 - val_loss: 0.4526\n",
            "Epoch 1839/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3301 - val_loss: 0.4442\n",
            "Epoch 1840/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3296 - val_loss: 0.4541\n",
            "Epoch 1841/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3298 - val_loss: 0.4518\n",
            "Epoch 1842/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3290 - val_loss: 0.4479\n",
            "Epoch 1843/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3288 - val_loss: 0.4444\n",
            "Epoch 1844/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3300 - val_loss: 0.4488\n",
            "Epoch 1845/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3286 - val_loss: 0.4479\n",
            "Epoch 1846/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3291 - val_loss: 0.4467\n",
            "Epoch 1847/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3295 - val_loss: 0.4460\n",
            "Epoch 1848/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3300 - val_loss: 0.4493\n",
            "Epoch 1849/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3295 - val_loss: 0.4488\n",
            "Epoch 1850/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3290 - val_loss: 0.4534\n",
            "Epoch 1851/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3291 - val_loss: 0.4510\n",
            "Epoch 1852/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3290 - val_loss: 0.4503\n",
            "Epoch 1853/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3289 - val_loss: 0.4463\n",
            "Epoch 1854/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3288 - val_loss: 0.4488\n",
            "Epoch 1855/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3295 - val_loss: 0.4475\n",
            "Epoch 1856/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3292 - val_loss: 0.4466\n",
            "Epoch 1857/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3302 - val_loss: 0.4459\n",
            "Epoch 1858/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3288 - val_loss: 0.4499\n",
            "Epoch 1859/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3280 - val_loss: 0.4479\n",
            "Epoch 1860/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3308 - val_loss: 0.4477\n",
            "Epoch 1861/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3296 - val_loss: 0.4500\n",
            "Epoch 1862/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3282 - val_loss: 0.4528\n",
            "Epoch 1863/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3284 - val_loss: 0.4444\n",
            "Epoch 1864/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3287 - val_loss: 0.4454\n",
            "Epoch 1865/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3280 - val_loss: 0.4517\n",
            "Epoch 1866/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3285 - val_loss: 0.4547\n",
            "Epoch 1867/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3308 - val_loss: 0.4513\n",
            "Epoch 1868/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3283 - val_loss: 0.4470\n",
            "Epoch 1869/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3284 - val_loss: 0.4459\n",
            "Epoch 1870/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3283 - val_loss: 0.4466\n",
            "Epoch 1871/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3282 - val_loss: 0.4502\n",
            "Epoch 1872/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3280 - val_loss: 0.4501\n",
            "Epoch 1873/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3289 - val_loss: 0.4481\n",
            "Epoch 1874/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3303 - val_loss: 0.4486\n",
            "Epoch 1875/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3286 - val_loss: 0.4492\n",
            "Epoch 1876/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3281 - val_loss: 0.4471\n",
            "Epoch 1877/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3282 - val_loss: 0.4471\n",
            "Epoch 1878/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3281 - val_loss: 0.4457\n",
            "Epoch 1879/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3291 - val_loss: 0.4475\n",
            "Epoch 1880/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3273 - val_loss: 0.4432\n",
            "Epoch 1881/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3282 - val_loss: 0.4433\n",
            "Epoch 1882/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3281 - val_loss: 0.4454\n",
            "Epoch 1883/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3289 - val_loss: 0.4473\n",
            "Epoch 1884/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3279 - val_loss: 0.4499\n",
            "Epoch 1885/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3289 - val_loss: 0.4467\n",
            "Epoch 1886/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3279 - val_loss: 0.4472\n",
            "Epoch 1887/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3284 - val_loss: 0.4450\n",
            "Epoch 1888/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3279 - val_loss: 0.4482\n",
            "Epoch 1889/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3270 - val_loss: 0.4461\n",
            "Epoch 1890/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3276 - val_loss: 0.4493\n",
            "Epoch 1891/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3294 - val_loss: 0.4488\n",
            "Epoch 1892/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3273 - val_loss: 0.4457\n",
            "Epoch 1893/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3276 - val_loss: 0.4481\n",
            "Epoch 1894/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3283 - val_loss: 0.4453\n",
            "Epoch 1895/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3282 - val_loss: 0.4469\n",
            "Epoch 1896/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3276 - val_loss: 0.4398\n",
            "Epoch 1897/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3291 - val_loss: 0.4467\n",
            "Epoch 1898/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3273 - val_loss: 0.4455\n",
            "Epoch 1899/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3288 - val_loss: 0.4448\n",
            "Epoch 1900/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3278 - val_loss: 0.4455\n",
            "Epoch 1901/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3281 - val_loss: 0.4458\n",
            "Epoch 1902/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3272 - val_loss: 0.4469\n",
            "Epoch 1903/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3269 - val_loss: 0.4520\n",
            "Epoch 1904/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3257 - val_loss: 0.4439\n",
            "Epoch 1905/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3290 - val_loss: 0.4485\n",
            "Epoch 1906/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3271 - val_loss: 0.4482\n",
            "Epoch 1907/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3263 - val_loss: 0.4444\n",
            "Epoch 1908/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3280 - val_loss: 0.4466\n",
            "Epoch 1909/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3290 - val_loss: 0.4509\n",
            "Epoch 1910/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3279 - val_loss: 0.4493\n",
            "Epoch 1911/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3268 - val_loss: 0.4518\n",
            "Epoch 1912/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3260 - val_loss: 0.4435\n",
            "Epoch 1913/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3284 - val_loss: 0.4465\n",
            "Epoch 1914/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3275 - val_loss: 0.4475\n",
            "Epoch 1915/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3279 - val_loss: 0.4476\n",
            "Epoch 1916/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3264 - val_loss: 0.4484\n",
            "Epoch 1917/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3284 - val_loss: 0.4438\n",
            "Epoch 1918/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3262 - val_loss: 0.4498\n",
            "Epoch 1919/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3258 - val_loss: 0.4526\n",
            "Epoch 1920/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3263 - val_loss: 0.4436\n",
            "Epoch 1921/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3276 - val_loss: 0.4457\n",
            "Epoch 1922/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3270 - val_loss: 0.4441\n",
            "Epoch 1923/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3275 - val_loss: 0.4453\n",
            "Epoch 1924/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3274 - val_loss: 0.4455\n",
            "Epoch 1925/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3269 - val_loss: 0.4470\n",
            "Epoch 1926/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3271 - val_loss: 0.4468\n",
            "Epoch 1927/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3269 - val_loss: 0.4474\n",
            "Epoch 1928/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3276 - val_loss: 0.4446\n",
            "Epoch 1929/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3282 - val_loss: 0.4479\n",
            "Epoch 1930/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3267 - val_loss: 0.4478\n",
            "Epoch 1931/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3270 - val_loss: 0.4448\n",
            "Epoch 1932/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3259 - val_loss: 0.4485\n",
            "Epoch 1933/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3265 - val_loss: 0.4437\n",
            "Epoch 1934/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3268 - val_loss: 0.4472\n",
            "Epoch 1935/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3263 - val_loss: 0.4470\n",
            "Epoch 1936/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3264 - val_loss: 0.4457\n",
            "Epoch 1937/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3264 - val_loss: 0.4484\n",
            "Epoch 1938/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3263 - val_loss: 0.4471\n",
            "Epoch 1939/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3257 - val_loss: 0.4413\n",
            "Epoch 1940/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3257 - val_loss: 0.4439\n",
            "Epoch 1941/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3262 - val_loss: 0.4432\n",
            "Epoch 1942/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3259 - val_loss: 0.4439\n",
            "Epoch 1943/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3257 - val_loss: 0.4463\n",
            "Epoch 1944/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3256 - val_loss: 0.4479\n",
            "Epoch 1945/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3259 - val_loss: 0.4396\n",
            "Epoch 1946/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3268 - val_loss: 0.4408\n",
            "Epoch 1947/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3261 - val_loss: 0.4441\n",
            "Epoch 1948/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3256 - val_loss: 0.4456\n",
            "Epoch 1949/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3261 - val_loss: 0.4428\n",
            "Epoch 1950/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3258 - val_loss: 0.4479\n",
            "Epoch 1951/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3261 - val_loss: 0.4450\n",
            "Epoch 1952/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3261 - val_loss: 0.4445\n",
            "Epoch 1953/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3268 - val_loss: 0.4479\n",
            "Epoch 1954/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3257 - val_loss: 0.4447\n",
            "Epoch 1955/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3245 - val_loss: 0.4510\n",
            "Epoch 1956/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3256 - val_loss: 0.4422\n",
            "Epoch 1957/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3261 - val_loss: 0.4404\n",
            "Epoch 1958/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3259 - val_loss: 0.4465\n",
            "Epoch 1959/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3254 - val_loss: 0.4446\n",
            "Epoch 1960/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3256 - val_loss: 0.4453\n",
            "Epoch 1961/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3250 - val_loss: 0.4440\n",
            "Epoch 1962/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3251 - val_loss: 0.4466\n",
            "Epoch 1963/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3250 - val_loss: 0.4473\n",
            "Epoch 1964/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3254 - val_loss: 0.4404\n",
            "Epoch 1965/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3247 - val_loss: 0.4474\n",
            "Epoch 1966/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3257 - val_loss: 0.4467\n",
            "Epoch 1967/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3253 - val_loss: 0.4431\n",
            "Epoch 1968/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3251 - val_loss: 0.4493\n",
            "Epoch 1969/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3247 - val_loss: 0.4427\n",
            "Epoch 1970/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3253 - val_loss: 0.4464\n",
            "Epoch 1971/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3249 - val_loss: 0.4438\n",
            "Epoch 1972/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3247 - val_loss: 0.4486\n",
            "Epoch 1973/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3244 - val_loss: 0.4436\n",
            "Epoch 1974/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3247 - val_loss: 0.4429\n",
            "Epoch 1975/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3253 - val_loss: 0.4490\n",
            "Epoch 1976/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3260 - val_loss: 0.4465\n",
            "Epoch 1977/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3250 - val_loss: 0.4435\n",
            "Epoch 1978/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3254 - val_loss: 0.4468\n",
            "Epoch 1979/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3247 - val_loss: 0.4472\n",
            "Epoch 1980/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3250 - val_loss: 0.4475\n",
            "Epoch 1981/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3246 - val_loss: 0.4474\n",
            "Epoch 1982/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3246 - val_loss: 0.4490\n",
            "Epoch 1983/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3247 - val_loss: 0.4444\n",
            "Epoch 1984/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3252 - val_loss: 0.4486\n",
            "Epoch 1985/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3247 - val_loss: 0.4452\n",
            "Epoch 1986/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3238 - val_loss: 0.4466\n",
            "Epoch 1987/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3252 - val_loss: 0.4454\n",
            "Epoch 1988/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3246 - val_loss: 0.4475\n",
            "Epoch 1989/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3240 - val_loss: 0.4438\n",
            "Epoch 1990/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3242 - val_loss: 0.4450\n",
            "Epoch 1991/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3236 - val_loss: 0.4482\n",
            "Epoch 1992/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3242 - val_loss: 0.4493\n",
            "Epoch 1993/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3236 - val_loss: 0.4419\n",
            "Epoch 1994/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3253 - val_loss: 0.4452\n",
            "Epoch 1995/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3239 - val_loss: 0.4453\n",
            "Epoch 1996/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3238 - val_loss: 0.4462\n",
            "Epoch 1997/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3241 - val_loss: 0.4465\n",
            "Epoch 1998/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3238 - val_loss: 0.4456\n",
            "Epoch 1999/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3244 - val_loss: 0.4439\n",
            "Epoch 2000/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3237 - val_loss: 0.4463\n",
            "Epoch 2001/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3247 - val_loss: 0.4439\n",
            "Epoch 2002/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3232 - val_loss: 0.4471\n",
            "Epoch 2003/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3231 - val_loss: 0.4449\n",
            "Epoch 2004/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3248 - val_loss: 0.4407\n",
            "Epoch 2005/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3251 - val_loss: 0.4443\n",
            "Epoch 2006/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3231 - val_loss: 0.4450\n",
            "Epoch 2007/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3256 - val_loss: 0.4465\n",
            "Epoch 2008/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3234 - val_loss: 0.4446\n",
            "Epoch 2009/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3231 - val_loss: 0.4480\n",
            "Epoch 2010/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3233 - val_loss: 0.4463\n",
            "Epoch 2011/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3230 - val_loss: 0.4421\n",
            "Epoch 2012/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3246 - val_loss: 0.4440\n",
            "Epoch 2013/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3229 - val_loss: 0.4462\n",
            "Epoch 2014/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3237 - val_loss: 0.4438\n",
            "Epoch 2015/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3240 - val_loss: 0.4474\n",
            "Epoch 2016/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3227 - val_loss: 0.4483\n",
            "Epoch 2017/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3231 - val_loss: 0.4472\n",
            "Epoch 2018/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3222 - val_loss: 0.4489\n",
            "Epoch 2019/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3236 - val_loss: 0.4444\n",
            "Epoch 2020/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3231 - val_loss: 0.4482\n",
            "Epoch 2021/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3251 - val_loss: 0.4443\n",
            "Epoch 2022/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3227 - val_loss: 0.4458\n",
            "Epoch 2023/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3235 - val_loss: 0.4455\n",
            "Epoch 2024/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3237 - val_loss: 0.4399\n",
            "Epoch 2025/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3226 - val_loss: 0.4473\n",
            "Epoch 2026/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3234 - val_loss: 0.4482\n",
            "Epoch 2027/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3227 - val_loss: 0.4435\n",
            "Epoch 2028/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3234 - val_loss: 0.4393\n",
            "Epoch 2029/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3224 - val_loss: 0.4467\n",
            "Epoch 2030/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3225 - val_loss: 0.4418\n",
            "Epoch 2031/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3233 - val_loss: 0.4452\n",
            "Epoch 2032/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3231 - val_loss: 0.4430\n",
            "Epoch 2033/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3218 - val_loss: 0.4406\n",
            "Epoch 2034/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3209 - val_loss: 0.4389\n",
            "Epoch 2035/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3231 - val_loss: 0.4433\n",
            "Epoch 2036/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3235 - val_loss: 0.4440\n",
            "Epoch 2037/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3225 - val_loss: 0.4474\n",
            "Epoch 2038/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3228 - val_loss: 0.4423\n",
            "Epoch 2039/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3225 - val_loss: 0.4448\n",
            "Epoch 2040/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3226 - val_loss: 0.4448\n",
            "Epoch 2041/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3219 - val_loss: 0.4404\n",
            "Epoch 2042/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3233 - val_loss: 0.4435\n",
            "Epoch 2043/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3221 - val_loss: 0.4458\n",
            "Epoch 2044/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3227 - val_loss: 0.4458\n",
            "Epoch 2045/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3224 - val_loss: 0.4454\n",
            "Epoch 2046/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3220 - val_loss: 0.4464\n",
            "Epoch 2047/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3223 - val_loss: 0.4446\n",
            "Epoch 2048/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3224 - val_loss: 0.4443\n",
            "Epoch 2049/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3213 - val_loss: 0.4416\n",
            "Epoch 2050/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3219 - val_loss: 0.4410\n",
            "Epoch 2051/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3226 - val_loss: 0.4460\n",
            "Epoch 2052/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3223 - val_loss: 0.4413\n",
            "Epoch 2053/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3222 - val_loss: 0.4438\n",
            "Epoch 2054/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3226 - val_loss: 0.4459\n",
            "Epoch 2055/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3227 - val_loss: 0.4448\n",
            "Epoch 2056/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3217 - val_loss: 0.4425\n",
            "Epoch 2057/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3220 - val_loss: 0.4393\n",
            "Epoch 2058/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3224 - val_loss: 0.4448\n",
            "Epoch 2059/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3215 - val_loss: 0.4407\n",
            "Epoch 2060/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3218 - val_loss: 0.4414\n",
            "Epoch 2061/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3230 - val_loss: 0.4443\n",
            "Epoch 2062/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3217 - val_loss: 0.4459\n",
            "Epoch 2063/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3206 - val_loss: 0.4412\n",
            "Epoch 2064/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3219 - val_loss: 0.4418\n",
            "Epoch 2065/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3219 - val_loss: 0.4422\n",
            "Epoch 2066/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3222 - val_loss: 0.4416\n",
            "Epoch 2067/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3215 - val_loss: 0.4449\n",
            "Epoch 2068/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3211 - val_loss: 0.4412\n",
            "Epoch 2069/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3209 - val_loss: 0.4425\n",
            "Epoch 2070/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3226 - val_loss: 0.4421\n",
            "Epoch 2071/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3215 - val_loss: 0.4431\n",
            "Epoch 2072/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3218 - val_loss: 0.4417\n",
            "Epoch 2073/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3207 - val_loss: 0.4460\n",
            "Epoch 2074/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3214 - val_loss: 0.4442\n",
            "Epoch 2075/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3217 - val_loss: 0.4496\n",
            "Epoch 2076/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3215 - val_loss: 0.4453\n",
            "Epoch 2077/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3218 - val_loss: 0.4443\n",
            "Epoch 2078/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3216 - val_loss: 0.4418\n",
            "Epoch 2079/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3213 - val_loss: 0.4429\n",
            "Epoch 2080/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3202 - val_loss: 0.4458\n",
            "Epoch 2081/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3216 - val_loss: 0.4382\n",
            "Epoch 2082/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3199 - val_loss: 0.4465\n",
            "Epoch 2083/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3190 - val_loss: 0.4388\n",
            "Epoch 2084/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3210 - val_loss: 0.4414\n",
            "Epoch 2085/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3211 - val_loss: 0.4424\n",
            "Epoch 2086/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3213 - val_loss: 0.4443\n",
            "Epoch 2087/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3204 - val_loss: 0.4443\n",
            "Epoch 2088/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3204 - val_loss: 0.4429\n",
            "Epoch 2089/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3199 - val_loss: 0.4439\n",
            "Epoch 2090/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3213 - val_loss: 0.4437\n",
            "Epoch 2091/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3194 - val_loss: 0.4490\n",
            "Epoch 2092/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3198 - val_loss: 0.4473\n",
            "Epoch 2093/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3223 - val_loss: 0.4448\n",
            "Epoch 2094/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3208 - val_loss: 0.4461\n",
            "Epoch 2095/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3208 - val_loss: 0.4451\n",
            "Epoch 2096/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3220 - val_loss: 0.4467\n",
            "Epoch 2097/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3192 - val_loss: 0.4397\n",
            "Epoch 2098/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3208 - val_loss: 0.4458\n",
            "Epoch 2099/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3207 - val_loss: 0.4454\n",
            "Epoch 2100/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3203 - val_loss: 0.4436\n",
            "Epoch 2101/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3200 - val_loss: 0.4462\n",
            "Epoch 2102/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3195 - val_loss: 0.4466\n",
            "Epoch 2103/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3220 - val_loss: 0.4428\n",
            "Epoch 2104/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3191 - val_loss: 0.4474\n",
            "Epoch 2105/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3199 - val_loss: 0.4411\n",
            "Epoch 2106/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3201 - val_loss: 0.4424\n",
            "Epoch 2107/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3193 - val_loss: 0.4463\n",
            "Epoch 2108/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3195 - val_loss: 0.4444\n",
            "Epoch 2109/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3193 - val_loss: 0.4464\n",
            "Epoch 2110/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3189 - val_loss: 0.4448\n",
            "Epoch 2111/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3192 - val_loss: 0.4420\n",
            "Epoch 2112/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3203 - val_loss: 0.4419\n",
            "Epoch 2113/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3202 - val_loss: 0.4471\n",
            "Epoch 2114/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3181 - val_loss: 0.4365\n",
            "Epoch 2115/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3213 - val_loss: 0.4450\n",
            "Epoch 2116/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3187 - val_loss: 0.4428\n",
            "Epoch 2117/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3210 - val_loss: 0.4484\n",
            "Epoch 2118/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3197 - val_loss: 0.4433\n",
            "Epoch 2119/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3190 - val_loss: 0.4445\n",
            "Epoch 2120/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3194 - val_loss: 0.4423\n",
            "Epoch 2121/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3190 - val_loss: 0.4437\n",
            "Epoch 2122/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3190 - val_loss: 0.4438\n",
            "Epoch 2123/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3195 - val_loss: 0.4442\n",
            "Epoch 2124/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3192 - val_loss: 0.4428\n",
            "Epoch 2125/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3192 - val_loss: 0.4420\n",
            "Epoch 2126/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3189 - val_loss: 0.4418\n",
            "Epoch 2127/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3197 - val_loss: 0.4438\n",
            "Epoch 2128/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3185 - val_loss: 0.4451\n",
            "Epoch 2129/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3194 - val_loss: 0.4428\n",
            "Epoch 2130/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3187 - val_loss: 0.4446\n",
            "Epoch 2131/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3185 - val_loss: 0.4420\n",
            "Epoch 2132/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3184 - val_loss: 0.4457\n",
            "Epoch 2133/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3193 - val_loss: 0.4434\n",
            "Epoch 2134/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3188 - val_loss: 0.4430\n",
            "Epoch 2135/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3195 - val_loss: 0.4413\n",
            "Epoch 2136/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3183 - val_loss: 0.4420\n",
            "Epoch 2137/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3180 - val_loss: 0.4468\n",
            "Epoch 2138/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3182 - val_loss: 0.4402\n",
            "Epoch 2139/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3178 - val_loss: 0.4424\n",
            "Epoch 2140/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3186 - val_loss: 0.4404\n",
            "Epoch 2141/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3181 - val_loss: 0.4437\n",
            "Epoch 2142/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3189 - val_loss: 0.4413\n",
            "Epoch 2143/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3183 - val_loss: 0.4440\n",
            "Epoch 2144/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3178 - val_loss: 0.4392\n",
            "Epoch 2145/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3176 - val_loss: 0.4445\n",
            "Epoch 2146/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3178 - val_loss: 0.4427\n",
            "Epoch 2147/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3183 - val_loss: 0.4455\n",
            "Epoch 2148/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3190 - val_loss: 0.4444\n",
            "Epoch 2149/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3178 - val_loss: 0.4416\n",
            "Epoch 2150/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3183 - val_loss: 0.4415\n",
            "Epoch 2151/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3176 - val_loss: 0.4432\n",
            "Epoch 2152/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3185 - val_loss: 0.4461\n",
            "Epoch 2153/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3175 - val_loss: 0.4443\n",
            "Epoch 2154/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3183 - val_loss: 0.4431\n",
            "Epoch 2155/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3183 - val_loss: 0.4420\n",
            "Epoch 2156/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3174 - val_loss: 0.4419\n",
            "Epoch 2157/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3167 - val_loss: 0.4427\n",
            "Epoch 2158/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3178 - val_loss: 0.4427\n",
            "Epoch 2159/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3178 - val_loss: 0.4428\n",
            "Epoch 2160/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3178 - val_loss: 0.4435\n",
            "Epoch 2161/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3172 - val_loss: 0.4452\n",
            "Epoch 2162/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3173 - val_loss: 0.4422\n",
            "Epoch 2163/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3165 - val_loss: 0.4479\n",
            "Epoch 2164/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3181 - val_loss: 0.4436\n",
            "Epoch 2165/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3174 - val_loss: 0.4424\n",
            "Epoch 2166/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3169 - val_loss: 0.4428\n",
            "Epoch 2167/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3171 - val_loss: 0.4453\n",
            "Epoch 2168/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3178 - val_loss: 0.4412\n",
            "Epoch 2169/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3175 - val_loss: 0.4447\n",
            "Epoch 2170/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3165 - val_loss: 0.4389\n",
            "Epoch 2171/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3179 - val_loss: 0.4428\n",
            "Epoch 2172/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3155 - val_loss: 0.4461\n",
            "Epoch 2173/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3168 - val_loss: 0.4465\n",
            "Epoch 2174/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3166 - val_loss: 0.4412\n",
            "Epoch 2175/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3166 - val_loss: 0.4402\n",
            "Epoch 2176/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3168 - val_loss: 0.4407\n",
            "Epoch 2177/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3164 - val_loss: 0.4463\n",
            "Epoch 2178/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3170 - val_loss: 0.4474\n",
            "Epoch 2179/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3180 - val_loss: 0.4390\n",
            "Epoch 2180/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3166 - val_loss: 0.4424\n",
            "Epoch 2181/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3164 - val_loss: 0.4471\n",
            "Epoch 2182/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3163 - val_loss: 0.4477\n",
            "Epoch 2183/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3195 - val_loss: 0.4437\n",
            "Epoch 2184/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3154 - val_loss: 0.4487\n",
            "Epoch 2185/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3178 - val_loss: 0.4423\n",
            "Epoch 2186/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3169 - val_loss: 0.4455\n",
            "Epoch 2187/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3156 - val_loss: 0.4473\n",
            "Epoch 2188/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3162 - val_loss: 0.4428\n",
            "Epoch 2189/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3157 - val_loss: 0.4453\n",
            "Epoch 2190/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3166 - val_loss: 0.4449\n",
            "Epoch 2191/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3153 - val_loss: 0.4481\n",
            "Epoch 2192/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3166 - val_loss: 0.4454\n",
            "Epoch 2193/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3165 - val_loss: 0.4462\n",
            "Epoch 2194/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3164 - val_loss: 0.4452\n",
            "Epoch 2195/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3161 - val_loss: 0.4464\n",
            "Epoch 2196/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3168 - val_loss: 0.4412\n",
            "Epoch 2197/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3163 - val_loss: 0.4443\n",
            "Epoch 2198/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3157 - val_loss: 0.4444\n",
            "Epoch 2199/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3158 - val_loss: 0.4466\n",
            "Epoch 2200/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3155 - val_loss: 0.4447\n",
            "Epoch 2201/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3161 - val_loss: 0.4447\n",
            "Epoch 2202/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3154 - val_loss: 0.4457\n",
            "Epoch 2203/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3154 - val_loss: 0.4462\n",
            "Epoch 2204/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3153 - val_loss: 0.4463\n",
            "Epoch 2205/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3152 - val_loss: 0.4411\n",
            "Epoch 2206/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3157 - val_loss: 0.4441\n",
            "Epoch 2207/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3166 - val_loss: 0.4440\n",
            "Epoch 2208/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3157 - val_loss: 0.4447\n",
            "Epoch 2209/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3152 - val_loss: 0.4446\n",
            "Epoch 2210/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3155 - val_loss: 0.4458\n",
            "Epoch 2211/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3150 - val_loss: 0.4469\n",
            "Epoch 2212/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3154 - val_loss: 0.4434\n",
            "Epoch 2213/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3151 - val_loss: 0.4461\n",
            "Epoch 2214/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3147 - val_loss: 0.4443\n",
            "Epoch 2215/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3146 - val_loss: 0.4469\n",
            "Epoch 2216/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3158 - val_loss: 0.4457\n",
            "Epoch 2217/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3147 - val_loss: 0.4486\n",
            "Epoch 2218/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3144 - val_loss: 0.4466\n",
            "Epoch 2219/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3154 - val_loss: 0.4438\n",
            "Epoch 2220/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3145 - val_loss: 0.4456\n",
            "Epoch 2221/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3149 - val_loss: 0.4446\n",
            "Epoch 2222/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3147 - val_loss: 0.4441\n",
            "Epoch 2223/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3144 - val_loss: 0.4412\n",
            "Epoch 2224/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3150 - val_loss: 0.4434\n",
            "Epoch 2225/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3145 - val_loss: 0.4436\n",
            "Epoch 2226/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3140 - val_loss: 0.4443\n",
            "Epoch 2227/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3141 - val_loss: 0.4435\n",
            "Epoch 2228/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3149 - val_loss: 0.4393\n",
            "Epoch 2229/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3140 - val_loss: 0.4420\n",
            "Epoch 2230/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3150 - val_loss: 0.4423\n",
            "Epoch 2231/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3140 - val_loss: 0.4421\n",
            "Epoch 2232/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3139 - val_loss: 0.4418\n",
            "Epoch 2233/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3146 - val_loss: 0.4414\n",
            "Epoch 2234/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3139 - val_loss: 0.4436\n",
            "Epoch 2235/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3145 - val_loss: 0.4416\n",
            "Epoch 2236/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3132 - val_loss: 0.4412\n",
            "Epoch 2237/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3139 - val_loss: 0.4433\n",
            "Epoch 2238/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3135 - val_loss: 0.4396\n",
            "Epoch 2239/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3136 - val_loss: 0.4430\n",
            "Epoch 2240/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3135 - val_loss: 0.4452\n",
            "Epoch 2241/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3143 - val_loss: 0.4407\n",
            "Epoch 2242/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3134 - val_loss: 0.4405\n",
            "Epoch 2243/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3132 - val_loss: 0.4438\n",
            "Epoch 2244/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3138 - val_loss: 0.4441\n",
            "Epoch 2245/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3139 - val_loss: 0.4439\n",
            "Epoch 2246/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3135 - val_loss: 0.4432\n",
            "Epoch 2247/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3136 - val_loss: 0.4417\n",
            "Epoch 2248/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3138 - val_loss: 0.4439\n",
            "Epoch 2249/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3137 - val_loss: 0.4432\n",
            "Epoch 2250/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3139 - val_loss: 0.4427\n",
            "Epoch 2251/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3138 - val_loss: 0.4436\n",
            "Epoch 2252/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3130 - val_loss: 0.4445\n",
            "Epoch 2253/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3136 - val_loss: 0.4444\n",
            "Epoch 2254/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3123 - val_loss: 0.4416\n",
            "Epoch 2255/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3126 - val_loss: 0.4423\n",
            "Epoch 2256/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3128 - val_loss: 0.4447\n",
            "Epoch 2257/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3125 - val_loss: 0.4427\n",
            "Epoch 2258/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3115 - val_loss: 0.4481\n",
            "Epoch 2259/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3143 - val_loss: 0.4417\n",
            "Epoch 2260/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3132 - val_loss: 0.4419\n",
            "Epoch 2261/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3126 - val_loss: 0.4443\n",
            "Epoch 2262/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3131 - val_loss: 0.4438\n",
            "Epoch 2263/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3127 - val_loss: 0.4462\n",
            "Epoch 2264/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3125 - val_loss: 0.4404\n",
            "Epoch 2265/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3126 - val_loss: 0.4443\n",
            "Epoch 2266/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3124 - val_loss: 0.4472\n",
            "Epoch 2267/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3128 - val_loss: 0.4427\n",
            "Epoch 2268/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3126 - val_loss: 0.4417\n",
            "Epoch 2269/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3127 - val_loss: 0.4446\n",
            "Epoch 2270/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3122 - val_loss: 0.4435\n",
            "Epoch 2271/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3117 - val_loss: 0.4424\n",
            "Epoch 2272/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3128 - val_loss: 0.4448\n",
            "Epoch 2273/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3120 - val_loss: 0.4420\n",
            "Epoch 2274/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3116 - val_loss: 0.4416\n",
            "Epoch 2275/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3131 - val_loss: 0.4400\n",
            "Epoch 2276/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3122 - val_loss: 0.4440\n",
            "Epoch 2277/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3124 - val_loss: 0.4423\n",
            "Epoch 2278/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3124 - val_loss: 0.4417\n",
            "Epoch 2279/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3115 - val_loss: 0.4408\n",
            "Epoch 2280/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3119 - val_loss: 0.4417\n",
            "Epoch 2281/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3118 - val_loss: 0.4410\n",
            "Epoch 2282/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3116 - val_loss: 0.4452\n",
            "Epoch 2283/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3116 - val_loss: 0.4444\n",
            "Epoch 2284/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3120 - val_loss: 0.4433\n",
            "Epoch 2285/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3115 - val_loss: 0.4439\n",
            "Epoch 2286/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3114 - val_loss: 0.4398\n",
            "Epoch 2287/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3123 - val_loss: 0.4415\n",
            "Epoch 2288/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3109 - val_loss: 0.4470\n",
            "Epoch 2289/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3118 - val_loss: 0.4440\n",
            "Epoch 2290/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3110 - val_loss: 0.4397\n",
            "Epoch 2291/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3111 - val_loss: 0.4450\n",
            "Epoch 2292/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3107 - val_loss: 0.4439\n",
            "Epoch 2293/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3109 - val_loss: 0.4454\n",
            "Epoch 2294/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3104 - val_loss: 0.4448\n",
            "Epoch 2295/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3109 - val_loss: 0.4457\n",
            "Epoch 2296/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3120 - val_loss: 0.4442\n",
            "Epoch 2297/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3109 - val_loss: 0.4452\n",
            "Epoch 2298/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3108 - val_loss: 0.4446\n",
            "Epoch 2299/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3102 - val_loss: 0.4443\n",
            "Epoch 2300/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3108 - val_loss: 0.4432\n",
            "Epoch 2301/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3116 - val_loss: 0.4442\n",
            "Epoch 2302/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3114 - val_loss: 0.4474\n",
            "Epoch 2303/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3110 - val_loss: 0.4426\n",
            "Epoch 2304/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3111 - val_loss: 0.4436\n",
            "Epoch 2305/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3098 - val_loss: 0.4440\n",
            "Epoch 2306/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3107 - val_loss: 0.4446\n",
            "Epoch 2307/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3106 - val_loss: 0.4430\n",
            "Epoch 2308/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3103 - val_loss: 0.4429\n",
            "Epoch 2309/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3100 - val_loss: 0.4447\n",
            "Epoch 2310/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3098 - val_loss: 0.4449\n",
            "Epoch 2311/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3106 - val_loss: 0.4441\n",
            "Epoch 2312/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3098 - val_loss: 0.4455\n",
            "Epoch 2313/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3105 - val_loss: 0.4432\n",
            "Epoch 2314/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3107 - val_loss: 0.4404\n",
            "Epoch 2315/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3099 - val_loss: 0.4425\n",
            "Epoch 2316/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3102 - val_loss: 0.4451\n",
            "Epoch 2317/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3102 - val_loss: 0.4451\n",
            "Epoch 2318/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3088 - val_loss: 0.4419\n",
            "Epoch 2319/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3098 - val_loss: 0.4446\n",
            "Epoch 2320/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3096 - val_loss: 0.4456\n",
            "Epoch 2321/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3095 - val_loss: 0.4440\n",
            "Epoch 2322/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3094 - val_loss: 0.4455\n",
            "Epoch 2323/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3089 - val_loss: 0.4424\n",
            "Epoch 2324/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3093 - val_loss: 0.4420\n",
            "Epoch 2325/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3093 - val_loss: 0.4451\n",
            "Epoch 2326/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3094 - val_loss: 0.4465\n",
            "Epoch 2327/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3087 - val_loss: 0.4477\n",
            "Epoch 2328/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3100 - val_loss: 0.4433\n",
            "Epoch 2329/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3097 - val_loss: 0.4440\n",
            "Epoch 2330/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3108 - val_loss: 0.4444\n",
            "Epoch 2331/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3099 - val_loss: 0.4432\n",
            "Epoch 2332/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3089 - val_loss: 0.4461\n",
            "Epoch 2333/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3087 - val_loss: 0.4419\n",
            "Epoch 2334/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3094 - val_loss: 0.4462\n",
            "Epoch 2335/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3082 - val_loss: 0.4416\n",
            "Epoch 2336/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3103 - val_loss: 0.4446\n",
            "Epoch 2337/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3076 - val_loss: 0.4414\n",
            "Epoch 2338/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3084 - val_loss: 0.4446\n",
            "Epoch 2339/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3088 - val_loss: 0.4434\n",
            "Epoch 2340/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3082 - val_loss: 0.4475\n",
            "Epoch 2341/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3096 - val_loss: 0.4445\n",
            "Epoch 2342/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3104 - val_loss: 0.4444\n",
            "Epoch 2343/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3075 - val_loss: 0.4431\n",
            "Epoch 2344/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3086 - val_loss: 0.4446\n",
            "Epoch 2345/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3089 - val_loss: 0.4422\n",
            "Epoch 2346/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3086 - val_loss: 0.4424\n",
            "Epoch 2347/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3078 - val_loss: 0.4460\n",
            "Epoch 2348/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3087 - val_loss: 0.4428\n",
            "Epoch 2349/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3088 - val_loss: 0.4440\n",
            "Epoch 2350/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3080 - val_loss: 0.4442\n",
            "Epoch 2351/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3099 - val_loss: 0.4449\n",
            "Epoch 2352/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3086 - val_loss: 0.4437\n",
            "Epoch 2353/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3080 - val_loss: 0.4443\n",
            "Epoch 2354/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3082 - val_loss: 0.4406\n",
            "Epoch 2355/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3080 - val_loss: 0.4426\n",
            "Epoch 2356/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3075 - val_loss: 0.4463\n",
            "Epoch 2357/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3078 - val_loss: 0.4438\n",
            "Epoch 2358/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3084 - val_loss: 0.4434\n",
            "Epoch 2359/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3074 - val_loss: 0.4427\n",
            "Epoch 2360/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3073 - val_loss: 0.4433\n",
            "Epoch 2361/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3070 - val_loss: 0.4429\n",
            "Epoch 2362/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3083 - val_loss: 0.4437\n",
            "Epoch 2363/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3067 - val_loss: 0.4430\n",
            "Epoch 2364/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3075 - val_loss: 0.4431\n",
            "Epoch 2365/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3069 - val_loss: 0.4436\n",
            "Epoch 2366/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3073 - val_loss: 0.4449\n",
            "Epoch 2367/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3071 - val_loss: 0.4435\n",
            "Epoch 2368/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3073 - val_loss: 0.4445\n",
            "Epoch 2369/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3062 - val_loss: 0.4456\n",
            "Epoch 2370/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3072 - val_loss: 0.4447\n",
            "Epoch 2371/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3071 - val_loss: 0.4467\n",
            "Epoch 2372/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3062 - val_loss: 0.4460\n",
            "Epoch 2373/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3067 - val_loss: 0.4450\n",
            "Epoch 2374/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3072 - val_loss: 0.4440\n",
            "Epoch 2375/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3064 - val_loss: 0.4463\n",
            "Epoch 2376/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3073 - val_loss: 0.4448\n",
            "Epoch 2377/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3066 - val_loss: 0.4448\n",
            "Epoch 2378/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3075 - val_loss: 0.4426\n",
            "Epoch 2379/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3065 - val_loss: 0.4426\n",
            "Epoch 2380/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3064 - val_loss: 0.4446\n",
            "Epoch 2381/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3059 - val_loss: 0.4461\n",
            "Epoch 2382/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3060 - val_loss: 0.4461\n",
            "Epoch 2383/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3061 - val_loss: 0.4468\n",
            "Epoch 2384/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3056 - val_loss: 0.4451\n",
            "Epoch 2385/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3051 - val_loss: 0.4465\n",
            "Epoch 2386/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3061 - val_loss: 0.4421\n",
            "Epoch 2387/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3057 - val_loss: 0.4430\n",
            "Epoch 2388/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3064 - val_loss: 0.4463\n",
            "Epoch 2389/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3053 - val_loss: 0.4444\n",
            "Epoch 2390/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3051 - val_loss: 0.4411\n",
            "Epoch 2391/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3059 - val_loss: 0.4426\n",
            "Epoch 2392/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3056 - val_loss: 0.4434\n",
            "Epoch 2393/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3047 - val_loss: 0.4406\n",
            "Epoch 2394/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3062 - val_loss: 0.4464\n",
            "Epoch 2395/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3056 - val_loss: 0.4453\n",
            "Epoch 2396/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3056 - val_loss: 0.4452\n",
            "Epoch 2397/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3051 - val_loss: 0.4456\n",
            "Epoch 2398/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3048 - val_loss: 0.4470\n",
            "Epoch 2399/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3057 - val_loss: 0.4467\n",
            "Epoch 2400/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3052 - val_loss: 0.4435\n",
            "Epoch 2401/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3047 - val_loss: 0.4410\n",
            "Epoch 2402/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3049 - val_loss: 0.4427\n",
            "Epoch 2403/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3051 - val_loss: 0.4459\n",
            "Epoch 2404/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3058 - val_loss: 0.4457\n",
            "Epoch 2405/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3051 - val_loss: 0.4442\n",
            "Epoch 2406/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3039 - val_loss: 0.4456\n",
            "Epoch 2407/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3054 - val_loss: 0.4438\n",
            "Epoch 2408/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3054 - val_loss: 0.4447\n",
            "Epoch 2409/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3045 - val_loss: 0.4458\n",
            "Epoch 2410/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3046 - val_loss: 0.4428\n",
            "Epoch 2411/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3049 - val_loss: 0.4418\n",
            "Epoch 2412/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3052 - val_loss: 0.4451\n",
            "Epoch 2413/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3042 - val_loss: 0.4422\n",
            "Epoch 2414/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3050 - val_loss: 0.4458\n",
            "Epoch 2415/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3044 - val_loss: 0.4465\n",
            "Epoch 2416/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3043 - val_loss: 0.4449\n",
            "Epoch 2417/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3044 - val_loss: 0.4463\n",
            "Epoch 2418/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3048 - val_loss: 0.4465\n",
            "Epoch 2419/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3042 - val_loss: 0.4433\n",
            "Epoch 2420/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3043 - val_loss: 0.4454\n",
            "Epoch 2421/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3038 - val_loss: 0.4466\n",
            "Epoch 2422/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3030 - val_loss: 0.4466\n",
            "Epoch 2423/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3040 - val_loss: 0.4435\n",
            "Epoch 2424/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3038 - val_loss: 0.4458\n",
            "Epoch 2425/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3045 - val_loss: 0.4445\n",
            "Epoch 2426/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3045 - val_loss: 0.4442\n",
            "Epoch 2427/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3039 - val_loss: 0.4461\n",
            "Epoch 2428/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3043 - val_loss: 0.4474\n",
            "Epoch 2429/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3027 - val_loss: 0.4461\n",
            "Epoch 2430/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3037 - val_loss: 0.4462\n",
            "Epoch 2431/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3031 - val_loss: 0.4438\n",
            "Epoch 2432/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3033 - val_loss: 0.4477\n",
            "Epoch 2433/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3033 - val_loss: 0.4448\n",
            "Epoch 2434/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3026 - val_loss: 0.4457\n",
            "Epoch 2435/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3029 - val_loss: 0.4451\n",
            "Epoch 2436/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3028 - val_loss: 0.4476\n",
            "Epoch 2437/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3034 - val_loss: 0.4449\n",
            "Epoch 2438/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3037 - val_loss: 0.4444\n",
            "Epoch 2439/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3022 - val_loss: 0.4400\n",
            "Epoch 2440/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3033 - val_loss: 0.4445\n",
            "Epoch 2441/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3029 - val_loss: 0.4459\n",
            "Epoch 2442/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3044 - val_loss: 0.4439\n",
            "Epoch 2443/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3037 - val_loss: 0.4440\n",
            "Epoch 2444/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3021 - val_loss: 0.4434\n",
            "Epoch 2445/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3017 - val_loss: 0.4431\n",
            "Epoch 2446/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3036 - val_loss: 0.4448\n",
            "Epoch 2447/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3018 - val_loss: 0.4449\n",
            "Epoch 2448/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3019 - val_loss: 0.4478\n",
            "Epoch 2449/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3020 - val_loss: 0.4446\n",
            "Epoch 2450/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3024 - val_loss: 0.4477\n",
            "Epoch 2451/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3033 - val_loss: 0.4503\n",
            "Epoch 2452/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3020 - val_loss: 0.4471\n",
            "Epoch 2453/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3019 - val_loss: 0.4478\n",
            "Epoch 2454/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3029 - val_loss: 0.4449\n",
            "Epoch 2455/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3017 - val_loss: 0.4462\n",
            "Epoch 2456/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3014 - val_loss: 0.4451\n",
            "Epoch 2457/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3015 - val_loss: 0.4472\n",
            "Epoch 2458/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3021 - val_loss: 0.4452\n",
            "Epoch 2459/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3015 - val_loss: 0.4430\n",
            "Epoch 2460/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3014 - val_loss: 0.4456\n",
            "Epoch 2461/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3030 - val_loss: 0.4476\n",
            "Epoch 2462/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3011 - val_loss: 0.4442\n",
            "Epoch 2463/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3017 - val_loss: 0.4469\n",
            "Epoch 2464/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3015 - val_loss: 0.4455\n",
            "Epoch 2465/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3008 - val_loss: 0.4477\n",
            "Epoch 2466/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3023 - val_loss: 0.4467\n",
            "Epoch 2467/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3015 - val_loss: 0.4470\n",
            "Epoch 2468/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3008 - val_loss: 0.4473\n",
            "Epoch 2469/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3010 - val_loss: 0.4473\n",
            "Epoch 2470/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3012 - val_loss: 0.4422\n",
            "Epoch 2471/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3013 - val_loss: 0.4435\n",
            "Epoch 2472/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.2999 - val_loss: 0.4434\n",
            "Epoch 2473/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3002 - val_loss: 0.4445\n",
            "Epoch 2474/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3003 - val_loss: 0.4441\n",
            "Epoch 2475/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2997 - val_loss: 0.4420\n",
            "Epoch 2476/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3020 - val_loss: 0.4448\n",
            "Epoch 2477/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.2988 - val_loss: 0.4404\n",
            "Epoch 2478/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3009 - val_loss: 0.4452\n",
            "Epoch 2479/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3006 - val_loss: 0.4472\n",
            "Epoch 2480/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3002 - val_loss: 0.4476\n",
            "Epoch 2481/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3009 - val_loss: 0.4458\n",
            "Epoch 2482/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3006 - val_loss: 0.4458\n",
            "Epoch 2483/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2999 - val_loss: 0.4443\n",
            "Epoch 2484/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3002 - val_loss: 0.4465\n",
            "Epoch 2485/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3004 - val_loss: 0.4472\n",
            "Epoch 2486/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3029 - val_loss: 0.4443\n",
            "Epoch 2487/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2994 - val_loss: 0.4452\n",
            "Epoch 2488/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.2998 - val_loss: 0.4467\n",
            "Epoch 2489/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3004 - val_loss: 0.4449\n",
            "Epoch 2490/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3002 - val_loss: 0.4460\n",
            "Epoch 2491/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3008 - val_loss: 0.4453\n",
            "Epoch 2492/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3003 - val_loss: 0.4426\n",
            "Epoch 2493/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2997 - val_loss: 0.4440\n",
            "Epoch 2494/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2998 - val_loss: 0.4465\n",
            "Epoch 2495/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3005 - val_loss: 0.4447\n",
            "Epoch 2496/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3006 - val_loss: 0.4458\n",
            "Epoch 2497/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3001 - val_loss: 0.4446\n",
            "Epoch 2498/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3000 - val_loss: 0.4454\n",
            "Epoch 2499/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2990 - val_loss: 0.4457\n",
            "Epoch 2500/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2999 - val_loss: 0.4487\n",
            "Epoch 2501/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3002 - val_loss: 0.4428\n",
            "Epoch 2502/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2989 - val_loss: 0.4442\n",
            "Epoch 2503/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3006 - val_loss: 0.4440\n",
            "Epoch 2504/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2995 - val_loss: 0.4464\n",
            "Epoch 2505/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2994 - val_loss: 0.4482\n",
            "Epoch 2506/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2995 - val_loss: 0.4459\n",
            "Epoch 2507/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2992 - val_loss: 0.4474\n",
            "Epoch 2508/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2984 - val_loss: 0.4497\n",
            "Epoch 2509/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2997 - val_loss: 0.4477\n",
            "Epoch 2510/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2981 - val_loss: 0.4413\n",
            "Epoch 2511/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3014 - val_loss: 0.4443\n",
            "Epoch 2512/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2994 - val_loss: 0.4453\n",
            "Epoch 2513/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2993 - val_loss: 0.4441\n",
            "Epoch 2514/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3001 - val_loss: 0.4434\n",
            "Epoch 2515/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2989 - val_loss: 0.4478\n",
            "Epoch 2516/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3003 - val_loss: 0.4434\n",
            "Epoch 2517/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.2988 - val_loss: 0.4466\n",
            "Epoch 2518/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2979 - val_loss: 0.4422\n",
            "Epoch 2519/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2991 - val_loss: 0.4489\n",
            "Epoch 2520/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2990 - val_loss: 0.4494\n",
            "Epoch 2521/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2987 - val_loss: 0.4472\n",
            "Epoch 2522/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2986 - val_loss: 0.4430\n",
            "Epoch 2523/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2985 - val_loss: 0.4495\n",
            "Epoch 2524/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2992 - val_loss: 0.4487\n",
            "Epoch 2525/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2976 - val_loss: 0.4479\n",
            "Epoch 2526/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2984 - val_loss: 0.4441\n",
            "Epoch 2527/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2974 - val_loss: 0.4474\n",
            "Epoch 2528/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2965 - val_loss: 0.4425\n",
            "Epoch 2529/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2983 - val_loss: 0.4420\n",
            "Epoch 2530/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2981 - val_loss: 0.4468\n",
            "Epoch 2531/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2995 - val_loss: 0.4474\n",
            "Epoch 2532/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2979 - val_loss: 0.4472\n",
            "Epoch 2533/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2974 - val_loss: 0.4419\n",
            "Epoch 2534/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2991 - val_loss: 0.4456\n",
            "Epoch 2535/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.2965 - val_loss: 0.4474\n",
            "Epoch 2536/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2976 - val_loss: 0.4444\n",
            "Epoch 2537/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2973 - val_loss: 0.4435\n",
            "Epoch 2538/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2977 - val_loss: 0.4455\n",
            "Epoch 2539/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2970 - val_loss: 0.4439\n",
            "Epoch 2540/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2972 - val_loss: 0.4468\n",
            "Epoch 2541/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2971 - val_loss: 0.4453\n",
            "Epoch 2542/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2972 - val_loss: 0.4441\n",
            "Epoch 2543/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2968 - val_loss: 0.4451\n",
            "Epoch 2544/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2979 - val_loss: 0.4430\n",
            "Epoch 2545/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2968 - val_loss: 0.4445\n",
            "Epoch 2546/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2989 - val_loss: 0.4434\n",
            "Epoch 2547/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2961 - val_loss: 0.4478\n",
            "Epoch 2548/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2972 - val_loss: 0.4452\n",
            "Epoch 2549/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2975 - val_loss: 0.4464\n",
            "Epoch 2550/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2961 - val_loss: 0.4436\n",
            "Epoch 2551/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2976 - val_loss: 0.4459\n",
            "Epoch 2552/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2966 - val_loss: 0.4448\n",
            "Epoch 2553/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2966 - val_loss: 0.4504\n",
            "Epoch 2554/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2969 - val_loss: 0.4482\n",
            "Epoch 2555/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2969 - val_loss: 0.4473\n",
            "Epoch 2556/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2976 - val_loss: 0.4465\n",
            "Epoch 2557/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2964 - val_loss: 0.4490\n",
            "Epoch 2558/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2974 - val_loss: 0.4454\n",
            "Epoch 2559/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2962 - val_loss: 0.4454\n",
            "Epoch 2560/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2976 - val_loss: 0.4469\n",
            "Epoch 2561/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2967 - val_loss: 0.4459\n",
            "Epoch 2562/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2968 - val_loss: 0.4505\n",
            "Epoch 2563/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2969 - val_loss: 0.4483\n",
            "Epoch 2564/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2958 - val_loss: 0.4468\n",
            "Epoch 2565/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2964 - val_loss: 0.4442\n",
            "Epoch 2566/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2963 - val_loss: 0.4469\n",
            "Epoch 2567/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2963 - val_loss: 0.4443\n",
            "Epoch 2568/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2959 - val_loss: 0.4477\n",
            "Epoch 2569/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2961 - val_loss: 0.4465\n",
            "Epoch 2570/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2962 - val_loss: 0.4449\n",
            "Epoch 2571/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2964 - val_loss: 0.4446\n",
            "Epoch 2572/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2970 - val_loss: 0.4457\n",
            "Epoch 2573/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2948 - val_loss: 0.4434\n",
            "Epoch 2574/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2953 - val_loss: 0.4466\n",
            "Epoch 2575/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2949 - val_loss: 0.4485\n",
            "Epoch 2576/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2956 - val_loss: 0.4448\n",
            "Epoch 2577/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2944 - val_loss: 0.4469\n",
            "Epoch 2578/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2955 - val_loss: 0.4507\n",
            "Epoch 2579/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2965 - val_loss: 0.4488\n",
            "Epoch 2580/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2949 - val_loss: 0.4462\n",
            "Epoch 2581/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2951 - val_loss: 0.4464\n",
            "Epoch 2582/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2956 - val_loss: 0.4449\n",
            "Epoch 2583/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2955 - val_loss: 0.4448\n",
            "Epoch 2584/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2956 - val_loss: 0.4475\n",
            "Epoch 2585/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2952 - val_loss: 0.4465\n",
            "Epoch 2586/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2953 - val_loss: 0.4479\n",
            "Epoch 2587/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2945 - val_loss: 0.4457\n",
            "Epoch 2588/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2949 - val_loss: 0.4480\n",
            "Epoch 2589/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2954 - val_loss: 0.4442\n",
            "Epoch 2590/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2955 - val_loss: 0.4450\n",
            "Epoch 2591/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2948 - val_loss: 0.4502\n",
            "Epoch 2592/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2958 - val_loss: 0.4471\n",
            "Epoch 2593/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2940 - val_loss: 0.4455\n",
            "Epoch 2594/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2953 - val_loss: 0.4505\n",
            "Epoch 2595/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2944 - val_loss: 0.4456\n",
            "Epoch 2596/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2954 - val_loss: 0.4469\n",
            "Epoch 2597/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2951 - val_loss: 0.4504\n",
            "Epoch 2598/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2945 - val_loss: 0.4457\n",
            "Epoch 2599/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2945 - val_loss: 0.4484\n",
            "Epoch 2600/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2964 - val_loss: 0.4451\n",
            "Epoch 2601/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2940 - val_loss: 0.4464\n",
            "Epoch 2602/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2943 - val_loss: 0.4456\n",
            "Epoch 2603/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2938 - val_loss: 0.4476\n",
            "Epoch 2604/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2973 - val_loss: 0.4463\n",
            "Epoch 2605/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2942 - val_loss: 0.4479\n",
            "Epoch 2606/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2945 - val_loss: 0.4458\n",
            "Epoch 2607/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2943 - val_loss: 0.4462\n",
            "Epoch 2608/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2942 - val_loss: 0.4449\n",
            "Epoch 2609/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2948 - val_loss: 0.4436\n",
            "Epoch 2610/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2947 - val_loss: 0.4470\n",
            "Epoch 2611/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2943 - val_loss: 0.4485\n",
            "Epoch 2612/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2930 - val_loss: 0.4429\n",
            "Epoch 2613/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2943 - val_loss: 0.4469\n",
            "Epoch 2614/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2936 - val_loss: 0.4483\n",
            "Epoch 2615/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2942 - val_loss: 0.4489\n",
            "Epoch 2616/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2937 - val_loss: 0.4446\n",
            "Epoch 2617/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2954 - val_loss: 0.4466\n",
            "Epoch 2618/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2935 - val_loss: 0.4458\n",
            "Epoch 2619/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2935 - val_loss: 0.4492\n",
            "Epoch 2620/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2937 - val_loss: 0.4473\n",
            "Epoch 2621/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2932 - val_loss: 0.4456\n",
            "Epoch 2622/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2934 - val_loss: 0.4440\n",
            "Epoch 2623/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2930 - val_loss: 0.4472\n",
            "Epoch 2624/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2934 - val_loss: 0.4452\n",
            "Epoch 2625/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2936 - val_loss: 0.4466\n",
            "Epoch 2626/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2930 - val_loss: 0.4494\n",
            "Epoch 2627/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2926 - val_loss: 0.4445\n",
            "Epoch 2628/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2931 - val_loss: 0.4453\n",
            "Epoch 2629/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2937 - val_loss: 0.4464\n",
            "Epoch 2630/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2930 - val_loss: 0.4463\n",
            "Epoch 2631/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2931 - val_loss: 0.4472\n",
            "Epoch 2632/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2934 - val_loss: 0.4455\n",
            "Epoch 2633/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2937 - val_loss: 0.4465\n",
            "Epoch 2634/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2936 - val_loss: 0.4489\n",
            "Epoch 2635/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2944 - val_loss: 0.4463\n",
            "Epoch 2636/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2936 - val_loss: 0.4440\n",
            "Epoch 2637/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2933 - val_loss: 0.4483\n",
            "Epoch 2638/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2933 - val_loss: 0.4458\n",
            "Epoch 2639/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2924 - val_loss: 0.4483\n",
            "Epoch 2640/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2924 - val_loss: 0.4445\n",
            "Epoch 2641/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2943 - val_loss: 0.4473\n",
            "Epoch 2642/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2941 - val_loss: 0.4476\n",
            "Epoch 2643/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2933 - val_loss: 0.4488\n",
            "Epoch 2644/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2927 - val_loss: 0.4450\n",
            "Epoch 2645/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2922 - val_loss: 0.4473\n",
            "Epoch 2646/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2929 - val_loss: 0.4493\n",
            "Epoch 2647/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2928 - val_loss: 0.4466\n",
            "Epoch 2648/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2926 - val_loss: 0.4444\n",
            "Epoch 2649/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2924 - val_loss: 0.4468\n",
            "Epoch 2650/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2922 - val_loss: 0.4471\n",
            "Epoch 2651/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2928 - val_loss: 0.4456\n",
            "Epoch 2652/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2928 - val_loss: 0.4493\n",
            "Epoch 2653/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2917 - val_loss: 0.4467\n",
            "Epoch 2654/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2928 - val_loss: 0.4475\n",
            "Epoch 2655/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2914 - val_loss: 0.4464\n",
            "Epoch 2656/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2923 - val_loss: 0.4458\n",
            "Epoch 2657/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2925 - val_loss: 0.4453\n",
            "Epoch 2658/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2919 - val_loss: 0.4474\n",
            "Epoch 2659/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2929 - val_loss: 0.4494\n",
            "Epoch 2660/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2919 - val_loss: 0.4468\n",
            "Epoch 2661/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2919 - val_loss: 0.4497\n",
            "Epoch 2662/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2922 - val_loss: 0.4497\n",
            "Epoch 2663/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2919 - val_loss: 0.4506\n",
            "Epoch 2664/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2920 - val_loss: 0.4487\n",
            "Epoch 2665/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2912 - val_loss: 0.4464\n",
            "Epoch 2666/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2930 - val_loss: 0.4489\n",
            "Epoch 2667/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2917 - val_loss: 0.4445\n",
            "Epoch 2668/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2916 - val_loss: 0.4447\n",
            "Epoch 2669/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2923 - val_loss: 0.4502\n",
            "Epoch 2670/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2919 - val_loss: 0.4489\n",
            "Epoch 2671/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2923 - val_loss: 0.4495\n",
            "Epoch 2672/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2916 - val_loss: 0.4481\n",
            "Epoch 2673/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2914 - val_loss: 0.4480\n",
            "Epoch 2674/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2924 - val_loss: 0.4482\n",
            "Epoch 2675/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2917 - val_loss: 0.4421\n",
            "Epoch 2676/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2929 - val_loss: 0.4485\n",
            "Epoch 2677/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2917 - val_loss: 0.4453\n",
            "Epoch 2678/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2911 - val_loss: 0.4471\n",
            "Epoch 2679/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2916 - val_loss: 0.4485\n",
            "Epoch 2680/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2909 - val_loss: 0.4460\n",
            "Epoch 2681/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2923 - val_loss: 0.4481\n",
            "Epoch 2682/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2918 - val_loss: 0.4483\n",
            "Epoch 2683/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2913 - val_loss: 0.4484\n",
            "Epoch 2684/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2915 - val_loss: 0.4471\n",
            "Epoch 2685/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2917 - val_loss: 0.4471\n",
            "Epoch 2686/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2914 - val_loss: 0.4473\n",
            "Epoch 2687/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2914 - val_loss: 0.4477\n",
            "Epoch 2688/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2922 - val_loss: 0.4442\n",
            "Epoch 2689/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2912 - val_loss: 0.4494\n",
            "Epoch 2690/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2920 - val_loss: 0.4491\n",
            "Epoch 2691/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2912 - val_loss: 0.4508\n",
            "Epoch 2692/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2912 - val_loss: 0.4519\n",
            "Epoch 2693/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.2913 - val_loss: 0.4489\n",
            "Epoch 2694/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2911 - val_loss: 0.4450\n",
            "Epoch 2695/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2915 - val_loss: 0.4496\n",
            "Epoch 2696/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2921 - val_loss: 0.4483\n",
            "Epoch 2697/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2903 - val_loss: 0.4463\n",
            "Epoch 2698/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2923 - val_loss: 0.4492\n",
            "Epoch 2699/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2933 - val_loss: 0.4490\n",
            "Epoch 2700/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2916 - val_loss: 0.4462\n",
            "Epoch 2701/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2913 - val_loss: 0.4472\n",
            "Epoch 2702/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2917 - val_loss: 0.4507\n",
            "Epoch 2703/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2925 - val_loss: 0.4508\n",
            "Epoch 2704/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2903 - val_loss: 0.4504\n",
            "Epoch 2705/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.2905 - val_loss: 0.4514\n",
            "Epoch 2706/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2903 - val_loss: 0.4510\n",
            "Epoch 2707/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2908 - val_loss: 0.4507\n",
            "Epoch 2708/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2916 - val_loss: 0.4499\n",
            "Epoch 2709/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2901 - val_loss: 0.4476\n",
            "Epoch 2710/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2903 - val_loss: 0.4486\n",
            "Epoch 2711/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2905 - val_loss: 0.4519\n",
            "Epoch 2712/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2904 - val_loss: 0.4498\n",
            "Epoch 2713/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2903 - val_loss: 0.4509\n",
            "Epoch 2714/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2902 - val_loss: 0.4523\n",
            "Epoch 2715/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2920 - val_loss: 0.4509\n",
            "Epoch 2716/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2897 - val_loss: 0.4490\n",
            "Epoch 2717/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2902 - val_loss: 0.4471\n",
            "Epoch 2718/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2914 - val_loss: 0.4531\n",
            "Epoch 2719/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2903 - val_loss: 0.4506\n",
            "Epoch 2720/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2902 - val_loss: 0.4467\n",
            "Epoch 2721/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2920 - val_loss: 0.4520\n",
            "Epoch 2722/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2898 - val_loss: 0.4502\n",
            "Epoch 2723/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2905 - val_loss: 0.4509\n",
            "Epoch 2724/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2904 - val_loss: 0.4505\n",
            "Epoch 2725/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2900 - val_loss: 0.4498\n",
            "Epoch 2726/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2899 - val_loss: 0.4535\n",
            "Epoch 2727/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2903 - val_loss: 0.4514\n",
            "Epoch 2728/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2900 - val_loss: 0.4500\n",
            "Epoch 2729/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2899 - val_loss: 0.4526\n",
            "Epoch 2730/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2897 - val_loss: 0.4496\n",
            "Epoch 2731/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2904 - val_loss: 0.4520\n",
            "Epoch 2732/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2896 - val_loss: 0.4507\n",
            "Epoch 2733/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2894 - val_loss: 0.4574\n",
            "Epoch 2734/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2913 - val_loss: 0.4542\n",
            "Epoch 2735/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2885 - val_loss: 0.4562\n",
            "Epoch 2736/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2896 - val_loss: 0.4559\n",
            "Epoch 2737/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2883 - val_loss: 0.4566\n",
            "Epoch 2738/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2887 - val_loss: 0.4577\n",
            "Epoch 2739/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2895 - val_loss: 0.4597\n",
            "Epoch 2740/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2890 - val_loss: 0.4579\n",
            "Epoch 2741/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2887 - val_loss: 0.4586\n",
            "Epoch 2742/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2880 - val_loss: 0.4583\n",
            "Epoch 2743/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2880 - val_loss: 0.4559\n",
            "Epoch 2744/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2888 - val_loss: 0.4605\n",
            "Epoch 2745/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2882 - val_loss: 0.4559\n",
            "Epoch 2746/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2894 - val_loss: 0.4582\n",
            "Epoch 2747/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2880 - val_loss: 0.4583\n",
            "Epoch 2748/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2895 - val_loss: 0.4569\n",
            "Epoch 2749/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2892 - val_loss: 0.4561\n",
            "Epoch 2750/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2877 - val_loss: 0.4599\n",
            "Epoch 2751/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2880 - val_loss: 0.4577\n",
            "Epoch 2752/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2884 - val_loss: 0.4571\n",
            "Epoch 2753/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2877 - val_loss: 0.4570\n",
            "Epoch 2754/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2880 - val_loss: 0.4568\n",
            "Epoch 2755/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2880 - val_loss: 0.4579\n",
            "Epoch 2756/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2884 - val_loss: 0.4589\n",
            "Epoch 2757/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2889 - val_loss: 0.4597\n",
            "Epoch 2758/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2887 - val_loss: 0.4568\n",
            "Epoch 2759/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2876 - val_loss: 0.4559\n",
            "Epoch 2760/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2884 - val_loss: 0.4562\n",
            "Epoch 2761/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2877 - val_loss: 0.4572\n",
            "Epoch 2762/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2879 - val_loss: 0.4536\n",
            "Epoch 2763/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2884 - val_loss: 0.4544\n",
            "Epoch 2764/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2882 - val_loss: 0.4519\n",
            "Epoch 2765/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2880 - val_loss: 0.4560\n",
            "Epoch 2766/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2878 - val_loss: 0.4556\n",
            "Epoch 2767/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2871 - val_loss: 0.4566\n",
            "Epoch 2768/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2874 - val_loss: 0.4575\n",
            "Epoch 2769/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2885 - val_loss: 0.4563\n",
            "Epoch 2770/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2874 - val_loss: 0.4556\n",
            "Epoch 2771/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2879 - val_loss: 0.4565\n",
            "Epoch 2772/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2887 - val_loss: 0.4579\n",
            "Epoch 2773/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2870 - val_loss: 0.4572\n",
            "Epoch 2774/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2867 - val_loss: 0.4571\n",
            "Epoch 2775/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2876 - val_loss: 0.4579\n",
            "Epoch 2776/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2882 - val_loss: 0.4600\n",
            "Epoch 2777/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2870 - val_loss: 0.4545\n",
            "Epoch 2778/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2877 - val_loss: 0.4553\n",
            "Epoch 2779/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2875 - val_loss: 0.4547\n",
            "Epoch 2780/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2870 - val_loss: 0.4552\n",
            "Epoch 2781/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2867 - val_loss: 0.4557\n",
            "Epoch 2782/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2867 - val_loss: 0.4549\n",
            "Epoch 2783/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2880 - val_loss: 0.4559\n",
            "Epoch 2784/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2874 - val_loss: 0.4583\n",
            "Epoch 2785/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2869 - val_loss: 0.4556\n",
            "Epoch 2786/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2869 - val_loss: 0.4551\n",
            "Epoch 2787/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2864 - val_loss: 0.4550\n",
            "Epoch 2788/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2877 - val_loss: 0.4553\n",
            "Epoch 2789/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2869 - val_loss: 0.4540\n",
            "Epoch 2790/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2865 - val_loss: 0.4595\n",
            "Epoch 2791/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2871 - val_loss: 0.4543\n",
            "Epoch 2792/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2887 - val_loss: 0.4563\n",
            "Epoch 2793/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2867 - val_loss: 0.4553\n",
            "Epoch 2794/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2864 - val_loss: 0.4556\n",
            "Epoch 2795/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.2869 - val_loss: 0.4580\n",
            "Epoch 2796/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2872 - val_loss: 0.4557\n",
            "Epoch 2797/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2860 - val_loss: 0.4550\n",
            "Epoch 2798/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2864 - val_loss: 0.4533\n",
            "Epoch 2799/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2867 - val_loss: 0.4554\n",
            "Epoch 2800/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2861 - val_loss: 0.4537\n",
            "Epoch 2801/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2872 - val_loss: 0.4559\n",
            "Epoch 2802/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2860 - val_loss: 0.4530\n",
            "Epoch 2803/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2867 - val_loss: 0.4532\n",
            "Epoch 2804/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2860 - val_loss: 0.4545\n",
            "Epoch 2805/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2861 - val_loss: 0.4564\n",
            "Epoch 2806/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2867 - val_loss: 0.4552\n",
            "Epoch 2807/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2864 - val_loss: 0.4555\n",
            "Epoch 2808/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2860 - val_loss: 0.4550\n",
            "Epoch 2809/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2860 - val_loss: 0.4538\n",
            "Epoch 2810/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2862 - val_loss: 0.4505\n",
            "Epoch 2811/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2881 - val_loss: 0.4530\n",
            "Epoch 2812/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2867 - val_loss: 0.4550\n",
            "Epoch 2813/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2871 - val_loss: 0.4546\n",
            "Epoch 2814/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2856 - val_loss: 0.4547\n",
            "Epoch 2815/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2862 - val_loss: 0.4531\n",
            "Epoch 2816/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2865 - val_loss: 0.4557\n",
            "Epoch 2817/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2857 - val_loss: 0.4541\n",
            "Epoch 2818/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2855 - val_loss: 0.4536\n",
            "Epoch 2819/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2857 - val_loss: 0.4543\n",
            "Epoch 2820/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2880 - val_loss: 0.4539\n",
            "Epoch 2821/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2855 - val_loss: 0.4548\n",
            "Epoch 2822/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2856 - val_loss: 0.4523\n",
            "Epoch 2823/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2863 - val_loss: 0.4521\n",
            "Epoch 2824/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2853 - val_loss: 0.4548\n",
            "Epoch 2825/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2865 - val_loss: 0.4535\n",
            "Epoch 2826/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2855 - val_loss: 0.4547\n",
            "Epoch 2827/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2857 - val_loss: 0.4545\n",
            "Epoch 2828/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2856 - val_loss: 0.4541\n",
            "Epoch 2829/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2859 - val_loss: 0.4542\n",
            "Epoch 2830/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2860 - val_loss: 0.4548\n",
            "Epoch 2831/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2860 - val_loss: 0.4519\n",
            "Epoch 2832/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2855 - val_loss: 0.4561\n",
            "Epoch 2833/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2854 - val_loss: 0.4566\n",
            "Epoch 2834/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2853 - val_loss: 0.4531\n",
            "Epoch 2835/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2858 - val_loss: 0.4544\n",
            "Epoch 2836/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2851 - val_loss: 0.4535\n",
            "Epoch 2837/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2857 - val_loss: 0.4535\n",
            "Epoch 2838/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2853 - val_loss: 0.4537\n",
            "Epoch 2839/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2850 - val_loss: 0.4557\n",
            "Epoch 2840/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2853 - val_loss: 0.4542\n",
            "Epoch 2841/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2852 - val_loss: 0.4546\n",
            "Epoch 2842/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2850 - val_loss: 0.4537\n",
            "Epoch 2843/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2860 - val_loss: 0.4550\n",
            "Epoch 2844/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2866 - val_loss: 0.4555\n",
            "Epoch 2845/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2848 - val_loss: 0.4519\n",
            "Epoch 2846/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2851 - val_loss: 0.4524\n",
            "Epoch 2847/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2859 - val_loss: 0.4524\n",
            "Epoch 2848/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2847 - val_loss: 0.4512\n",
            "Epoch 2849/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2853 - val_loss: 0.4526\n",
            "Epoch 2850/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2848 - val_loss: 0.4528\n",
            "Epoch 2851/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2850 - val_loss: 0.4537\n",
            "Epoch 2852/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2855 - val_loss: 0.4485\n",
            "Epoch 2853/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2858 - val_loss: 0.4520\n",
            "Epoch 2854/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2845 - val_loss: 0.4524\n",
            "Epoch 2855/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2847 - val_loss: 0.4526\n",
            "Epoch 2856/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2848 - val_loss: 0.4537\n",
            "Epoch 2857/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2849 - val_loss: 0.4518\n",
            "Epoch 2858/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2852 - val_loss: 0.4528\n",
            "Epoch 2859/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2846 - val_loss: 0.4536\n",
            "Epoch 2860/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2848 - val_loss: 0.4543\n",
            "Epoch 2861/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2856 - val_loss: 0.4537\n",
            "Epoch 2862/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2846 - val_loss: 0.4546\n",
            "Epoch 2863/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2847 - val_loss: 0.4532\n",
            "Epoch 2864/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2853 - val_loss: 0.4505\n",
            "Epoch 2865/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2845 - val_loss: 0.4522\n",
            "Epoch 2866/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2843 - val_loss: 0.4519\n",
            "Epoch 2867/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2850 - val_loss: 0.4523\n",
            "Epoch 2868/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2848 - val_loss: 0.4532\n",
            "Epoch 2869/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2852 - val_loss: 0.4538\n",
            "Epoch 2870/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2850 - val_loss: 0.4531\n",
            "Epoch 2871/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2859 - val_loss: 0.4556\n",
            "Epoch 2872/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2844 - val_loss: 0.4539\n",
            "Epoch 2873/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2845 - val_loss: 0.4552\n",
            "Epoch 2874/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2857 - val_loss: 0.4555\n",
            "Epoch 2875/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2845 - val_loss: 0.4539\n",
            "Epoch 2876/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2866 - val_loss: 0.4558\n",
            "Epoch 2877/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2843 - val_loss: 0.4554\n",
            "Epoch 2878/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2843 - val_loss: 0.4556\n",
            "Epoch 2879/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2841 - val_loss: 0.4528\n",
            "Epoch 2880/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2838 - val_loss: 0.4537\n",
            "Epoch 2881/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2845 - val_loss: 0.4553\n",
            "Epoch 2882/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2842 - val_loss: 0.4538\n",
            "Epoch 2883/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2843 - val_loss: 0.4531\n",
            "Epoch 2884/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2840 - val_loss: 0.4544\n",
            "Epoch 2885/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2840 - val_loss: 0.4533\n",
            "Epoch 2886/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2840 - val_loss: 0.4515\n",
            "Epoch 2887/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2839 - val_loss: 0.4544\n",
            "Epoch 2888/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2839 - val_loss: 0.4541\n",
            "Epoch 2889/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2843 - val_loss: 0.4552\n",
            "Epoch 2890/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2837 - val_loss: 0.4515\n",
            "Epoch 2891/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2851 - val_loss: 0.4526\n",
            "Epoch 2892/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2845 - val_loss: 0.4534\n",
            "Epoch 2893/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2862 - val_loss: 0.4554\n",
            "Epoch 2894/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2839 - val_loss: 0.4550\n",
            "Epoch 2895/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2840 - val_loss: 0.4525\n",
            "Epoch 2896/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2842 - val_loss: 0.4558\n",
            "Epoch 2897/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2842 - val_loss: 0.4554\n",
            "Epoch 2898/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2847 - val_loss: 0.4543\n",
            "Epoch 2899/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2842 - val_loss: 0.4553\n",
            "Epoch 2900/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2844 - val_loss: 0.4550\n",
            "Epoch 2901/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2839 - val_loss: 0.4573\n",
            "Epoch 2902/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2838 - val_loss: 0.4569\n",
            "Epoch 2903/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2840 - val_loss: 0.4544\n",
            "Epoch 2904/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2842 - val_loss: 0.4552\n",
            "Epoch 2905/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2836 - val_loss: 0.4544\n",
            "Epoch 2906/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2841 - val_loss: 0.4559\n",
            "Epoch 2907/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2839 - val_loss: 0.4550\n",
            "Epoch 2908/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2839 - val_loss: 0.4571\n",
            "Epoch 2909/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.2841 - val_loss: 0.4545\n",
            "Epoch 2910/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2839 - val_loss: 0.4549\n",
            "Epoch 2911/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2841 - val_loss: 0.4572\n",
            "Epoch 2912/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2833 - val_loss: 0.4558\n",
            "Epoch 2913/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2835 - val_loss: 0.4549\n",
            "Epoch 2914/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2834 - val_loss: 0.4549\n",
            "Epoch 2915/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2833 - val_loss: 0.4531\n",
            "Epoch 2916/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2832 - val_loss: 0.4529\n",
            "Epoch 2917/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2840 - val_loss: 0.4554\n",
            "Epoch 2918/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2836 - val_loss: 0.4539\n",
            "Epoch 2919/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2841 - val_loss: 0.4552\n",
            "Epoch 2920/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2837 - val_loss: 0.4529\n",
            "Epoch 2921/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2839 - val_loss: 0.4541\n",
            "Epoch 2922/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2831 - val_loss: 0.4542\n",
            "Epoch 2923/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2838 - val_loss: 0.4529\n",
            "Epoch 2924/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2832 - val_loss: 0.4539\n",
            "Epoch 2925/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2834 - val_loss: 0.4512\n",
            "Epoch 2926/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2852 - val_loss: 0.4575\n",
            "Epoch 2927/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2837 - val_loss: 0.4530\n",
            "Epoch 2928/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2833 - val_loss: 0.4545\n",
            "Epoch 2929/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2832 - val_loss: 0.4544\n",
            "Epoch 2930/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2831 - val_loss: 0.4571\n",
            "Epoch 2931/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2836 - val_loss: 0.4546\n",
            "Epoch 2932/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2835 - val_loss: 0.4590\n",
            "Epoch 2933/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2838 - val_loss: 0.4566\n",
            "Epoch 2934/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2834 - val_loss: 0.4563\n",
            "Epoch 2935/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2834 - val_loss: 0.4573\n",
            "Epoch 2936/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2833 - val_loss: 0.4566\n",
            "Epoch 2937/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2836 - val_loss: 0.4566\n",
            "Epoch 2938/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2835 - val_loss: 0.4572\n",
            "Epoch 2939/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2832 - val_loss: 0.4560\n",
            "Epoch 2940/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2830 - val_loss: 0.4578\n",
            "Epoch 2941/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2829 - val_loss: 0.4580\n",
            "Epoch 2942/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.2830 - val_loss: 0.4578\n",
            "Epoch 2943/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2829 - val_loss: 0.4545\n",
            "Epoch 2944/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2841 - val_loss: 0.4557\n",
            "Epoch 2945/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2833 - val_loss: 0.4590\n",
            "Epoch 2946/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2830 - val_loss: 0.4555\n",
            "Epoch 2947/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2832 - val_loss: 0.4571\n",
            "Epoch 2948/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2833 - val_loss: 0.4568\n",
            "Epoch 2949/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2829 - val_loss: 0.4583\n",
            "Epoch 2950/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2833 - val_loss: 0.4555\n",
            "Epoch 2951/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2832 - val_loss: 0.4549\n",
            "Epoch 2952/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2826 - val_loss: 0.4577\n",
            "Epoch 2953/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2826 - val_loss: 0.4603\n",
            "Epoch 2954/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2832 - val_loss: 0.4550\n",
            "Epoch 2955/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2826 - val_loss: 0.4547\n",
            "Epoch 2956/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2841 - val_loss: 0.4558\n",
            "Epoch 2957/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2829 - val_loss: 0.4565\n",
            "Epoch 2958/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2826 - val_loss: 0.4562\n",
            "Epoch 2959/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2828 - val_loss: 0.4576\n",
            "Epoch 2960/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2829 - val_loss: 0.4573\n",
            "Epoch 2961/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2827 - val_loss: 0.4579\n",
            "Epoch 2962/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2827 - val_loss: 0.4582\n",
            "Epoch 2963/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2842 - val_loss: 0.4582\n",
            "Epoch 2964/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2825 - val_loss: 0.4594\n",
            "Epoch 2965/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2837 - val_loss: 0.4582\n",
            "Epoch 2966/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2828 - val_loss: 0.4600\n",
            "Epoch 2967/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2832 - val_loss: 0.4593\n",
            "Epoch 2968/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2827 - val_loss: 0.4608\n",
            "Epoch 2969/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.2827 - val_loss: 0.4607\n",
            "Epoch 2970/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2827 - val_loss: 0.4592\n",
            "Epoch 2971/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2832 - val_loss: 0.4586\n",
            "Epoch 2972/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2823 - val_loss: 0.4548\n",
            "Epoch 2973/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2830 - val_loss: 0.4605\n",
            "Epoch 2974/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2829 - val_loss: 0.4591\n",
            "Epoch 2975/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2830 - val_loss: 0.4605\n",
            "Epoch 2976/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2824 - val_loss: 0.4608\n",
            "Epoch 2977/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2823 - val_loss: 0.4609\n",
            "Epoch 2978/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2827 - val_loss: 0.4602\n",
            "Epoch 2979/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2826 - val_loss: 0.4609\n",
            "Epoch 2980/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2824 - val_loss: 0.4600\n",
            "Epoch 2981/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2825 - val_loss: 0.4601\n",
            "Epoch 2982/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2828 - val_loss: 0.4578\n",
            "Epoch 2983/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2824 - val_loss: 0.4613\n",
            "Epoch 2984/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2829 - val_loss: 0.4618\n",
            "Epoch 2985/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2823 - val_loss: 0.4608\n",
            "Epoch 2986/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2822 - val_loss: 0.4608\n",
            "Epoch 2987/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2818 - val_loss: 0.4577\n",
            "Epoch 2988/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2828 - val_loss: 0.4629\n",
            "Epoch 2989/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2823 - val_loss: 0.4580\n",
            "Epoch 2990/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2828 - val_loss: 0.4600\n",
            "Epoch 2991/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2829 - val_loss: 0.4624\n",
            "Epoch 2992/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2820 - val_loss: 0.4627\n",
            "Epoch 2993/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2823 - val_loss: 0.4644\n",
            "Epoch 2994/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2821 - val_loss: 0.4637\n",
            "Epoch 2995/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2821 - val_loss: 0.4628\n",
            "Epoch 2996/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2817 - val_loss: 0.4589\n",
            "Epoch 2997/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2819 - val_loss: 0.4618\n",
            "Epoch 2998/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2820 - val_loss: 0.4637\n",
            "Epoch 2999/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2824 - val_loss: 0.4621\n",
            "Epoch 3000/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2819 - val_loss: 0.4640\n",
            "Epoch 3001/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2818 - val_loss: 0.4607\n",
            "Epoch 3002/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2818 - val_loss: 0.4616\n",
            "Epoch 3003/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2817 - val_loss: 0.4640\n",
            "Epoch 3004/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2820 - val_loss: 0.4650\n",
            "Epoch 3005/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2818 - val_loss: 0.4615\n",
            "Epoch 3006/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2819 - val_loss: 0.4638\n",
            "Epoch 3007/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2819 - val_loss: 0.4614\n",
            "Epoch 3008/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2820 - val_loss: 0.4606\n",
            "Epoch 3009/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2817 - val_loss: 0.4635\n",
            "Epoch 3010/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2819 - val_loss: 0.4633\n",
            "Epoch 3011/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2815 - val_loss: 0.4623\n",
            "Epoch 3012/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.2817 - val_loss: 0.4601\n",
            "Epoch 3013/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.2818 - val_loss: 0.4660\n",
            "Epoch 3014/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.2818 - val_loss: 0.4647\n",
            "Epoch 3015/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2814 - val_loss: 0.4657\n",
            "Epoch 3016/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2817 - val_loss: 0.4632\n",
            "Epoch 3017/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2817 - val_loss: 0.4644\n",
            "Epoch 3018/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2816 - val_loss: 0.4647\n",
            "Epoch 3019/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2816 - val_loss: 0.4616\n",
            "Epoch 3020/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2813 - val_loss: 0.4629\n",
            "Epoch 3021/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2818 - val_loss: 0.4599\n",
            "Epoch 3022/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2815 - val_loss: 0.4628\n",
            "Epoch 3023/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2814 - val_loss: 0.4616\n",
            "Epoch 3024/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2814 - val_loss: 0.4635\n",
            "Epoch 3025/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.2816 - val_loss: 0.4660\n",
            "Epoch 3026/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.2811 - val_loss: 0.4621\n",
            "Epoch 3027/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2832 - val_loss: 0.4639\n",
            "Epoch 3028/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2815 - val_loss: 0.4623\n",
            "Epoch 3029/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2812 - val_loss: 0.4624\n",
            "Epoch 3030/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2815 - val_loss: 0.4605\n",
            "Epoch 3031/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2817 - val_loss: 0.4639\n",
            "Epoch 3032/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2813 - val_loss: 0.4636\n",
            "Epoch 3033/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2816 - val_loss: 0.4630\n",
            "Epoch 3034/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.2811 - val_loss: 0.4648\n",
            "Epoch 3035/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2817 - val_loss: 0.4616\n",
            "Epoch 3036/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2816 - val_loss: 0.4656\n",
            "Epoch 3037/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2814 - val_loss: 0.4628\n",
            "Epoch 3038/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2809 - val_loss: 0.4640\n",
            "Epoch 3039/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2812 - val_loss: 0.4651\n",
            "Epoch 3040/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2809 - val_loss: 0.4635\n",
            "Epoch 3041/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2810 - val_loss: 0.4647\n",
            "Epoch 3042/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2811 - val_loss: 0.4620\n",
            "Epoch 3043/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2812 - val_loss: 0.4642\n",
            "Epoch 3044/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2815 - val_loss: 0.4652\n",
            "Epoch 3045/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2815 - val_loss: 0.4633\n",
            "Epoch 3046/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2806 - val_loss: 0.4610\n",
            "Epoch 3047/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2810 - val_loss: 0.4638\n",
            "Epoch 3048/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2817 - val_loss: 0.4605\n",
            "Epoch 3049/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2809 - val_loss: 0.4633\n",
            "Epoch 3050/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2814 - val_loss: 0.4638\n",
            "Epoch 3051/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2807 - val_loss: 0.4617\n",
            "Epoch 3052/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2809 - val_loss: 0.4591\n",
            "Epoch 3053/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2810 - val_loss: 0.4631\n",
            "Epoch 3054/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2814 - val_loss: 0.4618\n",
            "Epoch 3055/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2811 - val_loss: 0.4619\n",
            "Epoch 3056/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2806 - val_loss: 0.4636\n",
            "Epoch 3057/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2811 - val_loss: 0.4643\n",
            "Epoch 3058/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2815 - val_loss: 0.4638\n",
            "Epoch 3059/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2806 - val_loss: 0.4659\n",
            "Epoch 3060/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2812 - val_loss: 0.4651\n",
            "Epoch 3061/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2807 - val_loss: 0.4661\n",
            "Epoch 3062/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2808 - val_loss: 0.4627\n",
            "Epoch 3063/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2810 - val_loss: 0.4671\n",
            "Epoch 3064/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2812 - val_loss: 0.4634\n",
            "Epoch 3065/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2807 - val_loss: 0.4664\n",
            "Epoch 3066/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2806 - val_loss: 0.4632\n",
            "Epoch 3067/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.2809 - val_loss: 0.4664\n",
            "Epoch 3068/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.2805 - val_loss: 0.4629\n",
            "Epoch 3069/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2816 - val_loss: 0.4634\n",
            "Epoch 3070/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2809 - val_loss: 0.4640\n",
            "Epoch 3071/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.2810 - val_loss: 0.4602\n",
            "Epoch 3072/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2806 - val_loss: 0.4647\n",
            "Epoch 3073/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2803 - val_loss: 0.4609\n",
            "Epoch 3074/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2808 - val_loss: 0.4625\n",
            "Epoch 3075/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2808 - val_loss: 0.4656\n",
            "Epoch 3076/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2805 - val_loss: 0.4657\n",
            "Epoch 3077/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2802 - val_loss: 0.4611\n",
            "Epoch 3078/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2803 - val_loss: 0.4651\n",
            "Epoch 3079/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2807 - val_loss: 0.4641\n",
            "Epoch 3080/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2807 - val_loss: 0.4646\n",
            "Epoch 3081/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2802 - val_loss: 0.4646\n",
            "Epoch 3082/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2807 - val_loss: 0.4648\n",
            "Epoch 3083/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2806 - val_loss: 0.4656\n",
            "Epoch 3084/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2801 - val_loss: 0.4658\n",
            "Epoch 3085/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2800 - val_loss: 0.4646\n",
            "Epoch 3086/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2805 - val_loss: 0.4619\n",
            "Epoch 3087/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2810 - val_loss: 0.4672\n",
            "Epoch 3088/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2798 - val_loss: 0.4620\n",
            "Epoch 3089/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2804 - val_loss: 0.4628\n",
            "Epoch 3090/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2800 - val_loss: 0.4620\n",
            "Epoch 3091/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2802 - val_loss: 0.4654\n",
            "Epoch 3092/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2805 - val_loss: 0.4671\n",
            "Epoch 3093/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2804 - val_loss: 0.4634\n",
            "Epoch 3094/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2801 - val_loss: 0.4658\n",
            "Epoch 3095/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2810 - val_loss: 0.4641\n",
            "Epoch 3096/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2808 - val_loss: 0.4656\n",
            "Epoch 3097/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2807 - val_loss: 0.4633\n",
            "Epoch 3098/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2799 - val_loss: 0.4660\n",
            "Epoch 3099/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2801 - val_loss: 0.4645\n",
            "Epoch 3100/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2805 - val_loss: 0.4668\n",
            "Epoch 3101/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2805 - val_loss: 0.4647\n",
            "Epoch 3102/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2809 - val_loss: 0.4653\n",
            "Epoch 3103/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2813 - val_loss: 0.4650\n",
            "Epoch 3104/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2809 - val_loss: 0.4667\n",
            "Epoch 3105/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2798 - val_loss: 0.4673\n",
            "Epoch 3106/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2804 - val_loss: 0.4687\n",
            "Epoch 3107/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2799 - val_loss: 0.4667\n",
            "Epoch 3108/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2803 - val_loss: 0.4663\n",
            "Epoch 3109/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2800 - val_loss: 0.4641\n",
            "Epoch 3110/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2801 - val_loss: 0.4670\n",
            "Epoch 3111/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2798 - val_loss: 0.4679\n",
            "Epoch 3112/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2807 - val_loss: 0.4666\n",
            "Epoch 3113/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2798 - val_loss: 0.4671\n",
            "Epoch 3114/5000\n",
            "110/113 [============================>.] - ETA: 0s - loss: 0.2856Restoring model weights from the end of the best epoch: 2114.\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2801 - val_loss: 0.4636\n",
            "Epoch 3114: early stopping\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 0s 1ms/step - loss: 1.7563\n",
            "EXPECTED:\n",
            "     d18O_cel_mean  d18O_cel_variance\n",
            "0        25.120750           0.844007\n",
            "1        25.120750           0.844007\n",
            "2        25.120750           0.844007\n",
            "3        25.120750           0.844007\n",
            "4        25.120750           0.844007\n",
            "5        25.120750           0.844007\n",
            "6        25.120750           0.844007\n",
            "7        25.120750           0.844007\n",
            "8        25.120750           0.844007\n",
            "9        25.120750           0.844007\n",
            "10       25.120750           0.844007\n",
            "11       25.120750           0.844007\n",
            "12       25.120750           0.844007\n",
            "13       25.120750           0.844007\n",
            "14       25.120750           0.844007\n",
            "15       25.120750           0.844007\n",
            "16       25.120750           0.844007\n",
            "17       25.120750           0.844007\n",
            "18       25.120750           0.844007\n",
            "19       25.120750           0.844007\n",
            "20       25.120750           0.844007\n",
            "21       25.120750           0.844007\n",
            "22       25.120750           0.844007\n",
            "23       25.120750           0.844007\n",
            "24       25.120750           0.844007\n",
            "25       25.120750           0.844007\n",
            "26       25.120750           0.844007\n",
            "27       25.120750           0.844007\n",
            "28       25.120750           0.844007\n",
            "29       25.120750           0.844007\n",
            "30       25.120750           0.844007\n",
            "31       25.120750           0.844007\n",
            "32       25.120750           0.844007\n",
            "33       25.120750           0.844007\n",
            "34       25.120750           0.844007\n",
            "35       25.120750           0.844007\n",
            "36       25.120750           0.844007\n",
            "37       25.120750           0.844007\n",
            "38       25.120750           0.844007\n",
            "39       25.120750           0.844007\n",
            "40       24.777670           0.736571\n",
            "41       24.777670           0.736571\n",
            "42       24.777670           0.736571\n",
            "43       24.777670           0.736571\n",
            "44       24.777670           0.736571\n",
            "45       25.551850           0.312355\n",
            "46       25.551850           0.312355\n",
            "47       25.551850           0.312355\n",
            "48       25.551850           0.312355\n",
            "49       25.551850           0.312355\n",
            "50       25.115885           0.033519\n",
            "51       25.115885           0.033519\n",
            "52       25.115885           0.033519\n",
            "53       25.115885           0.033519\n",
            "54       25.115885           0.033519\n",
            "55       25.987815           5.280825\n",
            "56       25.987815           5.280825\n",
            "57       25.987815           5.280825\n",
            "58       25.987815           5.280825\n",
            "59       25.987815           5.280825\n",
            "60       24.132031           0.389042\n",
            "61       24.132031           0.389042\n",
            "62       24.132031           0.389042\n",
            "63       24.132031           0.389042\n",
            "64       27.559140           0.780698\n",
            "65       27.559140           0.780698\n",
            "66       27.559140           0.780698\n",
            "67       27.559140           0.780698\n",
            "68       27.559140           0.780698\n",
            "69       27.559140           0.780698\n",
            "70       27.559140           0.780698\n",
            "71       27.559140           0.780698\n",
            "72       27.559140           0.780698\n",
            "73       27.559140           0.780698\n",
            "74       27.260748           0.830341\n",
            "75       27.260748           0.830341\n",
            "76       27.260748           0.830341\n",
            "77       27.260748           0.830341\n",
            "78       27.260748           0.830341\n",
            "79       27.260748           0.830341\n",
            "80       27.260748           0.830341\n",
            "81       27.260748           0.830341\n",
            "82       27.260748           0.830341\n",
            "83       27.260748           0.830341\n",
            "84       27.260748           0.830341\n",
            "85       27.260748           0.830341\n",
            "86       27.260748           0.830341\n",
            "87       27.260748           0.830341\n",
            "88       27.260748           0.830341\n",
            "89       27.260748           0.830341\n",
            "90       27.260748           0.830341\n",
            "91       27.260748           0.830341\n",
            "92       27.260748           0.830341\n",
            "93       27.260748           0.830341\n",
            "94       27.260748           0.830341\n",
            "95       27.260748           0.830341\n",
            "96       27.260748           0.830341\n",
            "97       27.260748           0.830341\n",
            "98       27.260748           0.830341\n",
            "99       27.260748           0.830341\n",
            "100      27.260748           0.830341\n",
            "101      27.260748           0.830341\n",
            "102      27.260748           0.830341\n",
            "103      27.260748           0.830341\n",
            "104      27.260748           0.830341\n",
            "105      27.260748           0.830341\n",
            "106      27.260748           0.830341\n",
            "107      27.260748           0.830341\n",
            "108      27.260748           0.830341\n",
            "\n",
            "PREDICTED:\n",
            "     d18O_cel_mean  d18O_cel_variance\n",
            "0        26.940962           0.722452\n",
            "1        26.940962           0.722452\n",
            "2        26.940962           0.722452\n",
            "3        26.940962           0.722452\n",
            "4        26.940962           0.722452\n",
            "5        26.940962           0.722452\n",
            "6        26.940962           0.722452\n",
            "7        26.940962           0.722452\n",
            "8        26.940962           0.722452\n",
            "9        26.940962           0.722452\n",
            "10       26.940962           0.722452\n",
            "11       26.940962           0.722452\n",
            "12       26.940962           0.722452\n",
            "13       26.940962           0.722452\n",
            "14       26.940962           0.722452\n",
            "15       26.940962           0.722452\n",
            "16       26.940962           0.722452\n",
            "17       26.940962           0.722452\n",
            "18       26.940962           0.722452\n",
            "19       26.940962           0.722452\n",
            "20       26.940962           0.722452\n",
            "21       26.940962           0.722452\n",
            "22       26.940962           0.722452\n",
            "23       26.940962           0.722452\n",
            "24       26.940962           0.722452\n",
            "25       26.940962           0.722452\n",
            "26       26.940962           0.722452\n",
            "27       26.940962           0.722452\n",
            "28       26.940962           0.722452\n",
            "29       26.940962           0.722452\n",
            "30       26.940962           0.722452\n",
            "31       26.940962           0.722452\n",
            "32       26.940962           0.722452\n",
            "33       26.940962           0.722452\n",
            "34       26.940962           0.722452\n",
            "35       26.940962           0.722452\n",
            "36       26.940962           0.722452\n",
            "37       26.940962           0.722452\n",
            "38       26.940962           0.722452\n",
            "39       26.940962           0.722452\n",
            "40       25.184034           1.940355\n",
            "41       25.184034           1.940355\n",
            "42       25.184034           1.940355\n",
            "43       25.184034           1.940355\n",
            "44       25.184034           1.940355\n",
            "45       25.194277           1.951819\n",
            "46       25.194277           1.951819\n",
            "47       25.194277           1.951819\n",
            "48       25.194277           1.951819\n",
            "49       25.194277           1.951819\n",
            "50       25.207182           1.943069\n",
            "51       25.207182           1.943069\n",
            "52       25.207182           1.943069\n",
            "53       25.207182           1.943069\n",
            "54       25.207182           1.943069\n",
            "55       25.171663           1.966963\n",
            "56       25.171663           1.966963\n",
            "57       25.171663           1.966963\n",
            "58       25.171663           1.966963\n",
            "59       25.171663           1.966963\n",
            "60       25.199490           1.948289\n",
            "61       25.199490           1.948289\n",
            "62       25.199490           1.948289\n",
            "63       25.199490           1.948289\n",
            "64       24.601713           2.224396\n",
            "65       24.601713           2.224396\n",
            "66       24.601713           2.224396\n",
            "67       24.601713           2.224396\n",
            "68       24.601713           2.224396\n",
            "69       24.601713           2.224396\n",
            "70       24.601713           2.224396\n",
            "71       24.601713           2.224396\n",
            "72       24.601713           2.224396\n",
            "73       24.601713           2.224396\n",
            "74       24.633543           2.202930\n",
            "75       24.633543           2.202930\n",
            "76       24.633543           2.202930\n",
            "77       24.633543           2.202930\n",
            "78       24.633543           2.202930\n",
            "79       24.633543           2.202930\n",
            "80       24.633543           2.202930\n",
            "81       24.633543           2.202930\n",
            "82       24.633543           2.202930\n",
            "83       24.633543           2.202930\n",
            "84       24.633543           2.202930\n",
            "85       24.633543           2.202930\n",
            "86       24.633543           2.202930\n",
            "87       24.633543           2.202930\n",
            "88       24.633543           2.202930\n",
            "89       24.633543           2.202930\n",
            "90       24.633543           2.202930\n",
            "91       24.633543           2.202930\n",
            "92       24.633543           2.202930\n",
            "93       24.633543           2.202930\n",
            "94       24.633543           2.202930\n",
            "95       24.633543           2.202930\n",
            "96       24.633543           2.202930\n",
            "97       24.633543           2.202930\n",
            "98       24.633543           2.202930\n",
            "99       24.633543           2.202930\n",
            "100      24.633543           2.202930\n",
            "101      24.633543           2.202930\n",
            "102      24.633543           2.202930\n",
            "103      24.633543           2.202930\n",
            "104      24.633543           2.202930\n",
            "105      24.633543           2.202930\n",
            "106      24.633543           2.202930\n",
            "107      24.633543           2.202930\n",
            "108      24.633543           2.202930\n",
            "RMSE: 2.0786436565419266\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2023-07-18 16:40:47.355482: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype double and shape [109,12]\n",
            "\t [[{{node Placeholder/_0}}]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3) Grouped, random"
      ],
      "metadata": {
        "id": "n8pNR1CrvF2a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "grouped_random = {\n",
        "    'TRAIN' : os.path.join(FP_ROOT, 'amazon_sample_data/uc_davis_2023_08_12_train_random_grouped.csv'),\n",
        "    'TEST' : os.path.join(FP_ROOT, 'amazon_sample_data/uc_davis_2023_08_12_test_random_grouped.csv'),\n",
        "    'VALIDATION' : os.path.join(FP_ROOT, 'amazon_sample_data/uc_davis_2023_08_12_validation_random_grouped.csv'),\n",
        "}\n",
        "\n",
        "grouped_random_scaled = load_and_scale(grouped_random)\n",
        "train_and_evaluate(grouped_random_scaled, \"grouped_random\", training_batch_size=3)"
      ],
      "metadata": {
        "id": "rPONfgkjvJWz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "41edbc0d-f3f6-4369-b6d5-e75b2e07545b"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================\n",
            "grouped_random\n",
            "Model: \"model_8\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_9 (InputLayer)           [(None, 12)]         0           []                               \n",
            "                                                                                                  \n",
            " dense_16 (Dense)               (None, 20)           260         ['input_9[0][0]']                \n",
            "                                                                                                  \n",
            " dense_17 (Dense)               (None, 20)           420         ['dense_16[0][0]']               \n",
            "                                                                                                  \n",
            " var_output (Dense)             (None, 1)            21          ['dense_17[0][0]']               \n",
            "                                                                                                  \n",
            " mean_output (Dense)            (None, 1)            21          ['dense_17[0][0]']               \n",
            "                                                                                                  \n",
            " tf.math.multiply_17 (TFOpLambd  (None, 1)           0           ['var_output[0][0]']             \n",
            " a)                                                                                               \n",
            "                                                                                                  \n",
            " tf.math.multiply_16 (TFOpLambd  (None, 1)           0           ['mean_output[0][0]']            \n",
            " a)                                                                                               \n",
            "                                                                                                  \n",
            " tf.__operators__.add_17 (TFOpL  (None, 1)           0           ['tf.math.multiply_17[0][0]']    \n",
            " ambda)                                                                                           \n",
            "                                                                                                  \n",
            " tf.__operators__.add_16 (TFOpL  (None, 1)           0           ['tf.math.multiply_16[0][0]']    \n",
            " ambda)                                                                                           \n",
            "                                                                                                  \n",
            " lambda_8 (Lambda)              (None, 1)            0           ['tf.__operators__.add_17[0][0]']\n",
            "                                                                                                  \n",
            " concatenate_8 (Concatenate)    (None, 2)            0           ['tf.__operators__.add_16[0][0]',\n",
            "                                                                  'lambda_8[0][0]']               \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 722\n",
            "Trainable params: 722\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/5000\n",
            "12/12 [==============================] - 1s 14ms/step - loss: 0.6836 - val_loss: 1.1953\n",
            "Epoch 2/5000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6808 - val_loss: 1.1916\n",
            "Epoch 3/5000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6780 - val_loss: 1.1889\n",
            "Epoch 4/5000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6760 - val_loss: 1.1853\n",
            "Epoch 5/5000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6734 - val_loss: 1.1826\n",
            "Epoch 6/5000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6712 - val_loss: 1.1792\n",
            "Epoch 7/5000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6691 - val_loss: 1.1759\n",
            "Epoch 8/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6670 - val_loss: 1.1727\n",
            "Epoch 9/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6652 - val_loss: 1.1702\n",
            "Epoch 10/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6634 - val_loss: 1.1672\n",
            "Epoch 11/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6615 - val_loss: 1.1647\n",
            "Epoch 12/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6607 - val_loss: 1.1623\n",
            "Epoch 13/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6585 - val_loss: 1.1596\n",
            "Epoch 14/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6570 - val_loss: 1.1575\n",
            "Epoch 15/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6559 - val_loss: 1.1554\n",
            "Epoch 16/5000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6550 - val_loss: 1.1534\n",
            "Epoch 17/5000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6538 - val_loss: 1.1524\n",
            "Epoch 18/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6530 - val_loss: 1.1510\n",
            "Epoch 19/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6523 - val_loss: 1.1492\n",
            "Epoch 20/5000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6514 - val_loss: 1.1476\n",
            "Epoch 21/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6505 - val_loss: 1.1462\n",
            "Epoch 22/5000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6498 - val_loss: 1.1446\n",
            "Epoch 23/5000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6491 - val_loss: 1.1434\n",
            "Epoch 24/5000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6482 - val_loss: 1.1423\n",
            "Epoch 25/5000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6476 - val_loss: 1.1409\n",
            "Epoch 26/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6471 - val_loss: 1.1393\n",
            "Epoch 27/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6465 - val_loss: 1.1385\n",
            "Epoch 28/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6457 - val_loss: 1.1369\n",
            "Epoch 29/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6451 - val_loss: 1.1357\n",
            "Epoch 30/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6445 - val_loss: 1.1346\n",
            "Epoch 31/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6441 - val_loss: 1.1339\n",
            "Epoch 32/5000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6435 - val_loss: 1.1321\n",
            "Epoch 33/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6429 - val_loss: 1.1310\n",
            "Epoch 34/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6425 - val_loss: 1.1300\n",
            "Epoch 35/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6420 - val_loss: 1.1286\n",
            "Epoch 36/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6415 - val_loss: 1.1276\n",
            "Epoch 37/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6411 - val_loss: 1.1265\n",
            "Epoch 38/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6406 - val_loss: 1.1255\n",
            "Epoch 39/5000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6401 - val_loss: 1.1248\n",
            "Epoch 40/5000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6398 - val_loss: 1.1234\n",
            "Epoch 41/5000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6393 - val_loss: 1.1227\n",
            "Epoch 42/5000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6389 - val_loss: 1.1223\n",
            "Epoch 43/5000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6386 - val_loss: 1.1212\n",
            "Epoch 44/5000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6383 - val_loss: 1.1204\n",
            "Epoch 45/5000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6379 - val_loss: 1.1191\n",
            "Epoch 46/5000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6375 - val_loss: 1.1185\n",
            "Epoch 47/5000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6374 - val_loss: 1.1174\n",
            "Epoch 48/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6369 - val_loss: 1.1172\n",
            "Epoch 49/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6368 - val_loss: 1.1162\n",
            "Epoch 50/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6365 - val_loss: 1.1160\n",
            "Epoch 51/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6362 - val_loss: 1.1146\n",
            "Epoch 52/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6360 - val_loss: 1.1139\n",
            "Epoch 53/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6357 - val_loss: 1.1136\n",
            "Epoch 54/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6356 - val_loss: 1.1133\n",
            "Epoch 55/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6352 - val_loss: 1.1123\n",
            "Epoch 56/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6350 - val_loss: 1.1117\n",
            "Epoch 57/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6348 - val_loss: 1.1109\n",
            "Epoch 58/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6346 - val_loss: 1.1102\n",
            "Epoch 59/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6343 - val_loss: 1.1097\n",
            "Epoch 60/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6341 - val_loss: 1.1091\n",
            "Epoch 61/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6340 - val_loss: 1.1090\n",
            "Epoch 62/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6338 - val_loss: 1.1080\n",
            "Epoch 63/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6336 - val_loss: 1.1073\n",
            "Epoch 64/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6334 - val_loss: 1.1069\n",
            "Epoch 65/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6331 - val_loss: 1.1067\n",
            "Epoch 66/5000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6330 - val_loss: 1.1062\n",
            "Epoch 67/5000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6329 - val_loss: 1.1058\n",
            "Epoch 68/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6327 - val_loss: 1.1058\n",
            "Epoch 69/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6326 - val_loss: 1.1055\n",
            "Epoch 70/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6323 - val_loss: 1.1046\n",
            "Epoch 71/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6321 - val_loss: 1.1040\n",
            "Epoch 72/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6320 - val_loss: 1.1036\n",
            "Epoch 73/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6319 - val_loss: 1.1038\n",
            "Epoch 74/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6318 - val_loss: 1.1031\n",
            "Epoch 75/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6315 - val_loss: 1.1024\n",
            "Epoch 76/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6314 - val_loss: 1.1024\n",
            "Epoch 77/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6312 - val_loss: 1.1019\n",
            "Epoch 78/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6313 - val_loss: 1.1005\n",
            "Epoch 79/5000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6311 - val_loss: 1.1000\n",
            "Epoch 80/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6308 - val_loss: 1.1003\n",
            "Epoch 81/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6308 - val_loss: 1.1003\n",
            "Epoch 82/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6306 - val_loss: 1.0991\n",
            "Epoch 83/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6305 - val_loss: 1.0985\n",
            "Epoch 84/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6304 - val_loss: 1.0979\n",
            "Epoch 85/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6303 - val_loss: 1.0977\n",
            "Epoch 86/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6302 - val_loss: 1.0975\n",
            "Epoch 87/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6300 - val_loss: 1.0971\n",
            "Epoch 88/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6300 - val_loss: 1.0964\n",
            "Epoch 89/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6299 - val_loss: 1.0957\n",
            "Epoch 90/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6297 - val_loss: 1.0958\n",
            "Epoch 91/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6296 - val_loss: 1.0957\n",
            "Epoch 92/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6295 - val_loss: 1.0950\n",
            "Epoch 93/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6295 - val_loss: 1.0947\n",
            "Epoch 94/5000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6294 - val_loss: 1.0938\n",
            "Epoch 95/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6294 - val_loss: 1.0930\n",
            "Epoch 96/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6291 - val_loss: 1.0931\n",
            "Epoch 97/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6291 - val_loss: 1.0932\n",
            "Epoch 98/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6290 - val_loss: 1.0923\n",
            "Epoch 99/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6289 - val_loss: 1.0920\n",
            "Epoch 100/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6289 - val_loss: 1.0915\n",
            "Epoch 101/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6288 - val_loss: 1.0920\n",
            "Epoch 102/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6287 - val_loss: 1.0912\n",
            "Epoch 103/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6288 - val_loss: 1.0916\n",
            "Epoch 104/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6287 - val_loss: 1.0901\n",
            "Epoch 105/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6284 - val_loss: 1.0902\n",
            "Epoch 106/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6284 - val_loss: 1.0897\n",
            "Epoch 107/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6284 - val_loss: 1.0899\n",
            "Epoch 108/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6285 - val_loss: 1.0890\n",
            "Epoch 109/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6282 - val_loss: 1.0884\n",
            "Epoch 110/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6282 - val_loss: 1.0886\n",
            "Epoch 111/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6282 - val_loss: 1.0888\n",
            "Epoch 112/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6280 - val_loss: 1.0884\n",
            "Epoch 113/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6280 - val_loss: 1.0872\n",
            "Epoch 114/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6279 - val_loss: 1.0872\n",
            "Epoch 115/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6278 - val_loss: 1.0869\n",
            "Epoch 116/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6278 - val_loss: 1.0865\n",
            "Epoch 117/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6278 - val_loss: 1.0860\n",
            "Epoch 118/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6276 - val_loss: 1.0860\n",
            "Epoch 119/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6276 - val_loss: 1.0860\n",
            "Epoch 120/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6275 - val_loss: 1.0858\n",
            "Epoch 121/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6275 - val_loss: 1.0850\n",
            "Epoch 122/5000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6275 - val_loss: 1.0849\n",
            "Epoch 123/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6274 - val_loss: 1.0851\n",
            "Epoch 124/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6273 - val_loss: 1.0849\n",
            "Epoch 125/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6273 - val_loss: 1.0843\n",
            "Epoch 126/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6273 - val_loss: 1.0838\n",
            "Epoch 127/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6273 - val_loss: 1.0840\n",
            "Epoch 128/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6273 - val_loss: 1.0831\n",
            "Epoch 129/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6271 - val_loss: 1.0830\n",
            "Epoch 130/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6271 - val_loss: 1.0828\n",
            "Epoch 131/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6270 - val_loss: 1.0826\n",
            "Epoch 132/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6270 - val_loss: 1.0824\n",
            "Epoch 133/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6270 - val_loss: 1.0826\n",
            "Epoch 134/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6269 - val_loss: 1.0822\n",
            "Epoch 135/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6269 - val_loss: 1.0818\n",
            "Epoch 136/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6268 - val_loss: 1.0814\n",
            "Epoch 137/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6268 - val_loss: 1.0812\n",
            "Epoch 138/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6268 - val_loss: 1.0807\n",
            "Epoch 139/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6267 - val_loss: 1.0808\n",
            "Epoch 140/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6266 - val_loss: 1.0807\n",
            "Epoch 141/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6266 - val_loss: 1.0806\n",
            "Epoch 142/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6266 - val_loss: 1.0804\n",
            "Epoch 143/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6266 - val_loss: 1.0799\n",
            "Epoch 144/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6265 - val_loss: 1.0796\n",
            "Epoch 145/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6265 - val_loss: 1.0800\n",
            "Epoch 146/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6265 - val_loss: 1.0801\n",
            "Epoch 147/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6264 - val_loss: 1.0793\n",
            "Epoch 148/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6265 - val_loss: 1.0787\n",
            "Epoch 149/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6264 - val_loss: 1.0784\n",
            "Epoch 150/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6264 - val_loss: 1.0790\n",
            "Epoch 151/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6263 - val_loss: 1.0789\n",
            "Epoch 152/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6263 - val_loss: 1.0782\n",
            "Epoch 153/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6262 - val_loss: 1.0779\n",
            "Epoch 154/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6263 - val_loss: 1.0783\n",
            "Epoch 155/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6261 - val_loss: 1.0781\n",
            "Epoch 156/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6261 - val_loss: 1.0778\n",
            "Epoch 157/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6261 - val_loss: 1.0774\n",
            "Epoch 158/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6261 - val_loss: 1.0772\n",
            "Epoch 159/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6261 - val_loss: 1.0770\n",
            "Epoch 160/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6260 - val_loss: 1.0772\n",
            "Epoch 161/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6260 - val_loss: 1.0770\n",
            "Epoch 162/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6259 - val_loss: 1.0770\n",
            "Epoch 163/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6260 - val_loss: 1.0765\n",
            "Epoch 164/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6260 - val_loss: 1.0765\n",
            "Epoch 165/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6259 - val_loss: 1.0761\n",
            "Epoch 166/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6259 - val_loss: 1.0759\n",
            "Epoch 167/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6259 - val_loss: 1.0763\n",
            "Epoch 168/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6258 - val_loss: 1.0757\n",
            "Epoch 169/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6258 - val_loss: 1.0756\n",
            "Epoch 170/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6257 - val_loss: 1.0758\n",
            "Epoch 171/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6257 - val_loss: 1.0756\n",
            "Epoch 172/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6257 - val_loss: 1.0758\n",
            "Epoch 173/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6257 - val_loss: 1.0756\n",
            "Epoch 174/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6258 - val_loss: 1.0751\n",
            "Epoch 175/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6256 - val_loss: 1.0748\n",
            "Epoch 176/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6256 - val_loss: 1.0749\n",
            "Epoch 177/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6256 - val_loss: 1.0748\n",
            "Epoch 178/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6255 - val_loss: 1.0743\n",
            "Epoch 179/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6255 - val_loss: 1.0744\n",
            "Epoch 180/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6255 - val_loss: 1.0746\n",
            "Epoch 181/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6255 - val_loss: 1.0743\n",
            "Epoch 182/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6257 - val_loss: 1.0733\n",
            "Epoch 183/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6254 - val_loss: 1.0738\n",
            "Epoch 184/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6255 - val_loss: 1.0743\n",
            "Epoch 185/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6255 - val_loss: 1.0739\n",
            "Epoch 186/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6254 - val_loss: 1.0741\n",
            "Epoch 187/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6253 - val_loss: 1.0739\n",
            "Epoch 188/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6254 - val_loss: 1.0735\n",
            "Epoch 189/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6253 - val_loss: 1.0733\n",
            "Epoch 190/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6253 - val_loss: 1.0734\n",
            "Epoch 191/5000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6253 - val_loss: 1.0730\n",
            "Epoch 192/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6253 - val_loss: 1.0732\n",
            "Epoch 193/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6252 - val_loss: 1.0732\n",
            "Epoch 194/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6252 - val_loss: 1.0731\n",
            "Epoch 195/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6252 - val_loss: 1.0730\n",
            "Epoch 196/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6252 - val_loss: 1.0727\n",
            "Epoch 197/5000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6251 - val_loss: 1.0726\n",
            "Epoch 198/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6251 - val_loss: 1.0728\n",
            "Epoch 199/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6251 - val_loss: 1.0722\n",
            "Epoch 200/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6251 - val_loss: 1.0727\n",
            "Epoch 201/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6250 - val_loss: 1.0725\n",
            "Epoch 202/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6251 - val_loss: 1.0720\n",
            "Epoch 203/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6250 - val_loss: 1.0718\n",
            "Epoch 204/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6250 - val_loss: 1.0719\n",
            "Epoch 205/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6250 - val_loss: 1.0716\n",
            "Epoch 206/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6249 - val_loss: 1.0717\n",
            "Epoch 207/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6249 - val_loss: 1.0715\n",
            "Epoch 208/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6250 - val_loss: 1.0720\n",
            "Epoch 209/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6249 - val_loss: 1.0720\n",
            "Epoch 210/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6249 - val_loss: 1.0717\n",
            "Epoch 211/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6249 - val_loss: 1.0719\n",
            "Epoch 212/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6249 - val_loss: 1.0712\n",
            "Epoch 213/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6250 - val_loss: 1.0707\n",
            "Epoch 214/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6248 - val_loss: 1.0711\n",
            "Epoch 215/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6249 - val_loss: 1.0717\n",
            "Epoch 216/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6248 - val_loss: 1.0708\n",
            "Epoch 217/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6248 - val_loss: 1.0707\n",
            "Epoch 218/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6249 - val_loss: 1.0713\n",
            "Epoch 219/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6248 - val_loss: 1.0704\n",
            "Epoch 220/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6247 - val_loss: 1.0707\n",
            "Epoch 221/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6247 - val_loss: 1.0706\n",
            "Epoch 222/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6248 - val_loss: 1.0700\n",
            "Epoch 223/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6246 - val_loss: 1.0705\n",
            "Epoch 224/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6246 - val_loss: 1.0708\n",
            "Epoch 225/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6246 - val_loss: 1.0709\n",
            "Epoch 226/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6246 - val_loss: 1.0704\n",
            "Epoch 227/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6246 - val_loss: 1.0702\n",
            "Epoch 228/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6246 - val_loss: 1.0699\n",
            "Epoch 229/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6246 - val_loss: 1.0706\n",
            "Epoch 230/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6245 - val_loss: 1.0703\n",
            "Epoch 231/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6245 - val_loss: 1.0704\n",
            "Epoch 232/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6245 - val_loss: 1.0698\n",
            "Epoch 233/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6244 - val_loss: 1.0700\n",
            "Epoch 234/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6245 - val_loss: 1.0698\n",
            "Epoch 235/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6245 - val_loss: 1.0702\n",
            "Epoch 236/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6244 - val_loss: 1.0698\n",
            "Epoch 237/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6244 - val_loss: 1.0694\n",
            "Epoch 238/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6244 - val_loss: 1.0695\n",
            "Epoch 239/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6243 - val_loss: 1.0698\n",
            "Epoch 240/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6243 - val_loss: 1.0699\n",
            "Epoch 241/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6243 - val_loss: 1.0698\n",
            "Epoch 242/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6243 - val_loss: 1.0694\n",
            "Epoch 243/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6243 - val_loss: 1.0688\n",
            "Epoch 244/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6242 - val_loss: 1.0689\n",
            "Epoch 245/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6242 - val_loss: 1.0693\n",
            "Epoch 246/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6242 - val_loss: 1.0699\n",
            "Epoch 247/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6242 - val_loss: 1.0700\n",
            "Epoch 248/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6242 - val_loss: 1.0701\n",
            "Epoch 249/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6241 - val_loss: 1.0697\n",
            "Epoch 250/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6241 - val_loss: 1.0696\n",
            "Epoch 251/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6241 - val_loss: 1.0689\n",
            "Epoch 252/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6241 - val_loss: 1.0688\n",
            "Epoch 253/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6240 - val_loss: 1.0689\n",
            "Epoch 254/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6240 - val_loss: 1.0691\n",
            "Epoch 255/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6240 - val_loss: 1.0692\n",
            "Epoch 256/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6240 - val_loss: 1.0694\n",
            "Epoch 257/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6239 - val_loss: 1.0693\n",
            "Epoch 258/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6240 - val_loss: 1.0692\n",
            "Epoch 259/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6240 - val_loss: 1.0690\n",
            "Epoch 260/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6240 - val_loss: 1.0681\n",
            "Epoch 261/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6239 - val_loss: 1.0682\n",
            "Epoch 262/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6240 - val_loss: 1.0689\n",
            "Epoch 263/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6239 - val_loss: 1.0691\n",
            "Epoch 264/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6238 - val_loss: 1.0692\n",
            "Epoch 265/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6238 - val_loss: 1.0688\n",
            "Epoch 266/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6238 - val_loss: 1.0685\n",
            "Epoch 267/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6238 - val_loss: 1.0688\n",
            "Epoch 268/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6238 - val_loss: 1.0682\n",
            "Epoch 269/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6237 - val_loss: 1.0683\n",
            "Epoch 270/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6237 - val_loss: 1.0687\n",
            "Epoch 271/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6237 - val_loss: 1.0687\n",
            "Epoch 272/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6237 - val_loss: 1.0687\n",
            "Epoch 273/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6237 - val_loss: 1.0690\n",
            "Epoch 274/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6235 - val_loss: 1.0686\n",
            "Epoch 275/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6236 - val_loss: 1.0682\n",
            "Epoch 276/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6236 - val_loss: 1.0680\n",
            "Epoch 277/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6236 - val_loss: 1.0683\n",
            "Epoch 278/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6236 - val_loss: 1.0688\n",
            "Epoch 279/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6236 - val_loss: 1.0687\n",
            "Epoch 280/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6235 - val_loss: 1.0681\n",
            "Epoch 281/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6235 - val_loss: 1.0684\n",
            "Epoch 282/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6235 - val_loss: 1.0685\n",
            "Epoch 283/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6234 - val_loss: 1.0683\n",
            "Epoch 284/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6236 - val_loss: 1.0673\n",
            "Epoch 285/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6234 - val_loss: 1.0679\n",
            "Epoch 286/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6234 - val_loss: 1.0679\n",
            "Epoch 287/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6234 - val_loss: 1.0680\n",
            "Epoch 288/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6235 - val_loss: 1.0672\n",
            "Epoch 289/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6233 - val_loss: 1.0676\n",
            "Epoch 290/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6233 - val_loss: 1.0679\n",
            "Epoch 291/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6233 - val_loss: 1.0683\n",
            "Epoch 292/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6232 - val_loss: 1.0678\n",
            "Epoch 293/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6234 - val_loss: 1.0686\n",
            "Epoch 294/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6232 - val_loss: 1.0681\n",
            "Epoch 295/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6232 - val_loss: 1.0677\n",
            "Epoch 296/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6232 - val_loss: 1.0678\n",
            "Epoch 297/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6231 - val_loss: 1.0677\n",
            "Epoch 298/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6231 - val_loss: 1.0673\n",
            "Epoch 299/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6232 - val_loss: 1.0677\n",
            "Epoch 300/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6231 - val_loss: 1.0675\n",
            "Epoch 301/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6231 - val_loss: 1.0678\n",
            "Epoch 302/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6232 - val_loss: 1.0685\n",
            "Epoch 303/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6230 - val_loss: 1.0684\n",
            "Epoch 304/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6230 - val_loss: 1.0676\n",
            "Epoch 305/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6230 - val_loss: 1.0679\n",
            "Epoch 306/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6229 - val_loss: 1.0676\n",
            "Epoch 307/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6229 - val_loss: 1.0676\n",
            "Epoch 308/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6229 - val_loss: 1.0669\n",
            "Epoch 309/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6229 - val_loss: 1.0669\n",
            "Epoch 310/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6229 - val_loss: 1.0672\n",
            "Epoch 311/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6228 - val_loss: 1.0673\n",
            "Epoch 312/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6228 - val_loss: 1.0675\n",
            "Epoch 313/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6228 - val_loss: 1.0676\n",
            "Epoch 314/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6227 - val_loss: 1.0675\n",
            "Epoch 315/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6228 - val_loss: 1.0675\n",
            "Epoch 316/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6228 - val_loss: 1.0669\n",
            "Epoch 317/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6227 - val_loss: 1.0670\n",
            "Epoch 318/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6227 - val_loss: 1.0674\n",
            "Epoch 319/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6226 - val_loss: 1.0678\n",
            "Epoch 320/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6227 - val_loss: 1.0680\n",
            "Epoch 321/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6226 - val_loss: 1.0679\n",
            "Epoch 322/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6228 - val_loss: 1.0667\n",
            "Epoch 323/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6227 - val_loss: 1.0677\n",
            "Epoch 324/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6226 - val_loss: 1.0677\n",
            "Epoch 325/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6226 - val_loss: 1.0671\n",
            "Epoch 326/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6225 - val_loss: 1.0673\n",
            "Epoch 327/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6225 - val_loss: 1.0673\n",
            "Epoch 328/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6224 - val_loss: 1.0673\n",
            "Epoch 329/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6225 - val_loss: 1.0673\n",
            "Epoch 330/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6224 - val_loss: 1.0673\n",
            "Epoch 331/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6223 - val_loss: 1.0672\n",
            "Epoch 332/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6224 - val_loss: 1.0675\n",
            "Epoch 333/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6223 - val_loss: 1.0670\n",
            "Epoch 334/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6224 - val_loss: 1.0675\n",
            "Epoch 335/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6222 - val_loss: 1.0672\n",
            "Epoch 336/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6222 - val_loss: 1.0669\n",
            "Epoch 337/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6222 - val_loss: 1.0671\n",
            "Epoch 338/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6222 - val_loss: 1.0671\n",
            "Epoch 339/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6222 - val_loss: 1.0673\n",
            "Epoch 340/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6222 - val_loss: 1.0668\n",
            "Epoch 341/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6221 - val_loss: 1.0670\n",
            "Epoch 342/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6222 - val_loss: 1.0677\n",
            "Epoch 343/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6222 - val_loss: 1.0670\n",
            "Epoch 344/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6221 - val_loss: 1.0668\n",
            "Epoch 345/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6220 - val_loss: 1.0673\n",
            "Epoch 346/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6220 - val_loss: 1.0674\n",
            "Epoch 347/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6220 - val_loss: 1.0670\n",
            "Epoch 348/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6221 - val_loss: 1.0664\n",
            "Epoch 349/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6220 - val_loss: 1.0668\n",
            "Epoch 350/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6219 - val_loss: 1.0667\n",
            "Epoch 351/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6219 - val_loss: 1.0670\n",
            "Epoch 352/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6220 - val_loss: 1.0663\n",
            "Epoch 353/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6219 - val_loss: 1.0666\n",
            "Epoch 354/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6218 - val_loss: 1.0672\n",
            "Epoch 355/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6218 - val_loss: 1.0671\n",
            "Epoch 356/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6218 - val_loss: 1.0672\n",
            "Epoch 357/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6218 - val_loss: 1.0674\n",
            "Epoch 358/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6218 - val_loss: 1.0677\n",
            "Epoch 359/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6217 - val_loss: 1.0672\n",
            "Epoch 360/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6218 - val_loss: 1.0665\n",
            "Epoch 361/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6217 - val_loss: 1.0668\n",
            "Epoch 362/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6216 - val_loss: 1.0669\n",
            "Epoch 363/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6216 - val_loss: 1.0669\n",
            "Epoch 364/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6219 - val_loss: 1.0666\n",
            "Epoch 365/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6216 - val_loss: 1.0670\n",
            "Epoch 366/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6216 - val_loss: 1.0667\n",
            "Epoch 367/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6216 - val_loss: 1.0669\n",
            "Epoch 368/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6216 - val_loss: 1.0676\n",
            "Epoch 369/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6215 - val_loss: 1.0668\n",
            "Epoch 370/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6215 - val_loss: 1.0671\n",
            "Epoch 371/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6215 - val_loss: 1.0675\n",
            "Epoch 372/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6214 - val_loss: 1.0674\n",
            "Epoch 373/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6214 - val_loss: 1.0670\n",
            "Epoch 374/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6214 - val_loss: 1.0674\n",
            "Epoch 375/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6214 - val_loss: 1.0668\n",
            "Epoch 376/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6212 - val_loss: 1.0668\n",
            "Epoch 377/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6212 - val_loss: 1.0665\n",
            "Epoch 378/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6213 - val_loss: 1.0669\n",
            "Epoch 379/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6213 - val_loss: 1.0671\n",
            "Epoch 380/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6211 - val_loss: 1.0671\n",
            "Epoch 381/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6212 - val_loss: 1.0674\n",
            "Epoch 382/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6211 - val_loss: 1.0670\n",
            "Epoch 383/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6211 - val_loss: 1.0666\n",
            "Epoch 384/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6211 - val_loss: 1.0668\n",
            "Epoch 385/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6212 - val_loss: 1.0676\n",
            "Epoch 386/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6210 - val_loss: 1.0674\n",
            "Epoch 387/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6210 - val_loss: 1.0671\n",
            "Epoch 388/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6212 - val_loss: 1.0660\n",
            "Epoch 389/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6209 - val_loss: 1.0666\n",
            "Epoch 390/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6210 - val_loss: 1.0673\n",
            "Epoch 391/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6210 - val_loss: 1.0663\n",
            "Epoch 392/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6208 - val_loss: 1.0666\n",
            "Epoch 393/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6209 - val_loss: 1.0677\n",
            "Epoch 394/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6208 - val_loss: 1.0672\n",
            "Epoch 395/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6208 - val_loss: 1.0670\n",
            "Epoch 396/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6209 - val_loss: 1.0663\n",
            "Epoch 397/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6208 - val_loss: 1.0666\n",
            "Epoch 398/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6208 - val_loss: 1.0675\n",
            "Epoch 399/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6207 - val_loss: 1.0672\n",
            "Epoch 400/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6207 - val_loss: 1.0675\n",
            "Epoch 401/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6207 - val_loss: 1.0668\n",
            "Epoch 402/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6206 - val_loss: 1.0668\n",
            "Epoch 403/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6207 - val_loss: 1.0675\n",
            "Epoch 404/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6205 - val_loss: 1.0673\n",
            "Epoch 405/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6205 - val_loss: 1.0671\n",
            "Epoch 406/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6205 - val_loss: 1.0666\n",
            "Epoch 407/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6206 - val_loss: 1.0676\n",
            "Epoch 408/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6204 - val_loss: 1.0672\n",
            "Epoch 409/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6204 - val_loss: 1.0668\n",
            "Epoch 410/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6204 - val_loss: 1.0666\n",
            "Epoch 411/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6204 - val_loss: 1.0663\n",
            "Epoch 412/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6204 - val_loss: 1.0671\n",
            "Epoch 413/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6204 - val_loss: 1.0665\n",
            "Epoch 414/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6203 - val_loss: 1.0662\n",
            "Epoch 415/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6204 - val_loss: 1.0671\n",
            "Epoch 416/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6202 - val_loss: 1.0670\n",
            "Epoch 417/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6202 - val_loss: 1.0671\n",
            "Epoch 418/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6201 - val_loss: 1.0670\n",
            "Epoch 419/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6201 - val_loss: 1.0667\n",
            "Epoch 420/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6203 - val_loss: 1.0673\n",
            "Epoch 421/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6201 - val_loss: 1.0671\n",
            "Epoch 422/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6201 - val_loss: 1.0667\n",
            "Epoch 423/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6200 - val_loss: 1.0665\n",
            "Epoch 424/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6200 - val_loss: 1.0672\n",
            "Epoch 425/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6200 - val_loss: 1.0670\n",
            "Epoch 426/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6199 - val_loss: 1.0668\n",
            "Epoch 427/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6200 - val_loss: 1.0667\n",
            "Epoch 428/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6198 - val_loss: 1.0665\n",
            "Epoch 429/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6199 - val_loss: 1.0668\n",
            "Epoch 430/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6199 - val_loss: 1.0666\n",
            "Epoch 431/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6198 - val_loss: 1.0663\n",
            "Epoch 432/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6198 - val_loss: 1.0672\n",
            "Epoch 433/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6197 - val_loss: 1.0671\n",
            "Epoch 434/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6197 - val_loss: 1.0668\n",
            "Epoch 435/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6197 - val_loss: 1.0669\n",
            "Epoch 436/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6196 - val_loss: 1.0671\n",
            "Epoch 437/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6196 - val_loss: 1.0666\n",
            "Epoch 438/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6196 - val_loss: 1.0667\n",
            "Epoch 439/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6197 - val_loss: 1.0663\n",
            "Epoch 440/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6195 - val_loss: 1.0664\n",
            "Epoch 441/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6196 - val_loss: 1.0670\n",
            "Epoch 442/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6195 - val_loss: 1.0671\n",
            "Epoch 443/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6195 - val_loss: 1.0665\n",
            "Epoch 444/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6194 - val_loss: 1.0665\n",
            "Epoch 445/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6194 - val_loss: 1.0666\n",
            "Epoch 446/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6193 - val_loss: 1.0669\n",
            "Epoch 447/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6194 - val_loss: 1.0668\n",
            "Epoch 448/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6194 - val_loss: 1.0674\n",
            "Epoch 449/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6195 - val_loss: 1.0663\n",
            "Epoch 450/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6192 - val_loss: 1.0668\n",
            "Epoch 451/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6193 - val_loss: 1.0674\n",
            "Epoch 452/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6193 - val_loss: 1.0666\n",
            "Epoch 453/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6191 - val_loss: 1.0672\n",
            "Epoch 454/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6193 - val_loss: 1.0664\n",
            "Epoch 455/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6190 - val_loss: 1.0667\n",
            "Epoch 456/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6191 - val_loss: 1.0670\n",
            "Epoch 457/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6190 - val_loss: 1.0674\n",
            "Epoch 458/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6190 - val_loss: 1.0670\n",
            "Epoch 459/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6190 - val_loss: 1.0668\n",
            "Epoch 460/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6189 - val_loss: 1.0669\n",
            "Epoch 461/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6189 - val_loss: 1.0670\n",
            "Epoch 462/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6189 - val_loss: 1.0672\n",
            "Epoch 463/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6188 - val_loss: 1.0674\n",
            "Epoch 464/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6188 - val_loss: 1.0670\n",
            "Epoch 465/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6188 - val_loss: 1.0664\n",
            "Epoch 466/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6188 - val_loss: 1.0672\n",
            "Epoch 467/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6188 - val_loss: 1.0669\n",
            "Epoch 468/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6187 - val_loss: 1.0666\n",
            "Epoch 469/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6187 - val_loss: 1.0665\n",
            "Epoch 470/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6188 - val_loss: 1.0673\n",
            "Epoch 471/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6186 - val_loss: 1.0669\n",
            "Epoch 472/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6186 - val_loss: 1.0675\n",
            "Epoch 473/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6187 - val_loss: 1.0679\n",
            "Epoch 474/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6185 - val_loss: 1.0673\n",
            "Epoch 475/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6185 - val_loss: 1.0663\n",
            "Epoch 476/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6186 - val_loss: 1.0675\n",
            "Epoch 477/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6186 - val_loss: 1.0661\n",
            "Epoch 478/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6184 - val_loss: 1.0671\n",
            "Epoch 479/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6184 - val_loss: 1.0680\n",
            "Epoch 480/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6184 - val_loss: 1.0679\n",
            "Epoch 481/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6182 - val_loss: 1.0676\n",
            "Epoch 482/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6184 - val_loss: 1.0666\n",
            "Epoch 483/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6182 - val_loss: 1.0665\n",
            "Epoch 484/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6182 - val_loss: 1.0668\n",
            "Epoch 485/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6182 - val_loss: 1.0663\n",
            "Epoch 486/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6181 - val_loss: 1.0669\n",
            "Epoch 487/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6182 - val_loss: 1.0663\n",
            "Epoch 488/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6181 - val_loss: 1.0671\n",
            "Epoch 489/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6181 - val_loss: 1.0675\n",
            "Epoch 490/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6182 - val_loss: 1.0684\n",
            "Epoch 491/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6181 - val_loss: 1.0670\n",
            "Epoch 492/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6180 - val_loss: 1.0669\n",
            "Epoch 493/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6179 - val_loss: 1.0669\n",
            "Epoch 494/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6178 - val_loss: 1.0672\n",
            "Epoch 495/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6178 - val_loss: 1.0674\n",
            "Epoch 496/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6178 - val_loss: 1.0671\n",
            "Epoch 497/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6178 - val_loss: 1.0675\n",
            "Epoch 498/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6180 - val_loss: 1.0661\n",
            "Epoch 499/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6178 - val_loss: 1.0672\n",
            "Epoch 500/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6177 - val_loss: 1.0671\n",
            "Epoch 501/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6177 - val_loss: 1.0670\n",
            "Epoch 502/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6177 - val_loss: 1.0670\n",
            "Epoch 503/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6176 - val_loss: 1.0671\n",
            "Epoch 504/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6176 - val_loss: 1.0666\n",
            "Epoch 505/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6176 - val_loss: 1.0667\n",
            "Epoch 506/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6174 - val_loss: 1.0669\n",
            "Epoch 507/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6175 - val_loss: 1.0674\n",
            "Epoch 508/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6174 - val_loss: 1.0668\n",
            "Epoch 509/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6174 - val_loss: 1.0665\n",
            "Epoch 510/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6176 - val_loss: 1.0676\n",
            "Epoch 511/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6173 - val_loss: 1.0675\n",
            "Epoch 512/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6173 - val_loss: 1.0673\n",
            "Epoch 513/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6172 - val_loss: 1.0672\n",
            "Epoch 514/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6172 - val_loss: 1.0667\n",
            "Epoch 515/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6173 - val_loss: 1.0671\n",
            "Epoch 516/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6171 - val_loss: 1.0668\n",
            "Epoch 517/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6171 - val_loss: 1.0675\n",
            "Epoch 518/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6170 - val_loss: 1.0672\n",
            "Epoch 519/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6170 - val_loss: 1.0671\n",
            "Epoch 520/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6172 - val_loss: 1.0661\n",
            "Epoch 521/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6170 - val_loss: 1.0670\n",
            "Epoch 522/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6169 - val_loss: 1.0665\n",
            "Epoch 523/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6169 - val_loss: 1.0663\n",
            "Epoch 524/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6169 - val_loss: 1.0672\n",
            "Epoch 525/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6169 - val_loss: 1.0672\n",
            "Epoch 526/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6168 - val_loss: 1.0670\n",
            "Epoch 527/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6168 - val_loss: 1.0667\n",
            "Epoch 528/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6168 - val_loss: 1.0671\n",
            "Epoch 529/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6167 - val_loss: 1.0673\n",
            "Epoch 530/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6169 - val_loss: 1.0663\n",
            "Epoch 531/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6166 - val_loss: 1.0666\n",
            "Epoch 532/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6166 - val_loss: 1.0671\n",
            "Epoch 533/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6166 - val_loss: 1.0674\n",
            "Epoch 534/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6165 - val_loss: 1.0669\n",
            "Epoch 535/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6169 - val_loss: 1.0683\n",
            "Epoch 536/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6165 - val_loss: 1.0677\n",
            "Epoch 537/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6164 - val_loss: 1.0669\n",
            "Epoch 538/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6163 - val_loss: 1.0668\n",
            "Epoch 539/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6165 - val_loss: 1.0661\n",
            "Epoch 540/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6163 - val_loss: 1.0670\n",
            "Epoch 541/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6163 - val_loss: 1.0669\n",
            "Epoch 542/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6163 - val_loss: 1.0677\n",
            "Epoch 543/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6163 - val_loss: 1.0678\n",
            "Epoch 544/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6165 - val_loss: 1.0665\n",
            "Epoch 545/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6162 - val_loss: 1.0664\n",
            "Epoch 546/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6161 - val_loss: 1.0668\n",
            "Epoch 547/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6161 - val_loss: 1.0663\n",
            "Epoch 548/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6160 - val_loss: 1.0668\n",
            "Epoch 549/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6161 - val_loss: 1.0676\n",
            "Epoch 550/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6161 - val_loss: 1.0670\n",
            "Epoch 551/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6160 - val_loss: 1.0679\n",
            "Epoch 552/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6160 - val_loss: 1.0680\n",
            "Epoch 553/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6163 - val_loss: 1.0664\n",
            "Epoch 554/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6159 - val_loss: 1.0671\n",
            "Epoch 555/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6158 - val_loss: 1.0670\n",
            "Epoch 556/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6157 - val_loss: 1.0673\n",
            "Epoch 557/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6157 - val_loss: 1.0674\n",
            "Epoch 558/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6157 - val_loss: 1.0670\n",
            "Epoch 559/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6157 - val_loss: 1.0674\n",
            "Epoch 560/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6158 - val_loss: 1.0670\n",
            "Epoch 561/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6156 - val_loss: 1.0677\n",
            "Epoch 562/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6156 - val_loss: 1.0679\n",
            "Epoch 563/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6157 - val_loss: 1.0666\n",
            "Epoch 564/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6156 - val_loss: 1.0676\n",
            "Epoch 565/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6154 - val_loss: 1.0674\n",
            "Epoch 566/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6155 - val_loss: 1.0664\n",
            "Epoch 567/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6156 - val_loss: 1.0676\n",
            "Epoch 568/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6153 - val_loss: 1.0672\n",
            "Epoch 569/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6154 - val_loss: 1.0666\n",
            "Epoch 570/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6153 - val_loss: 1.0669\n",
            "Epoch 571/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6152 - val_loss: 1.0668\n",
            "Epoch 572/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6154 - val_loss: 1.0664\n",
            "Epoch 573/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 1.0669\n",
            "Epoch 574/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 1.0675\n",
            "Epoch 575/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6152 - val_loss: 1.0666\n",
            "Epoch 576/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6152 - val_loss: 1.0677\n",
            "Epoch 577/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6150 - val_loss: 1.0678\n",
            "Epoch 578/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6149 - val_loss: 1.0674\n",
            "Epoch 579/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6149 - val_loss: 1.0674\n",
            "Epoch 580/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6149 - val_loss: 1.0668\n",
            "Epoch 581/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6148 - val_loss: 1.0668\n",
            "Epoch 582/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6148 - val_loss: 1.0676\n",
            "Epoch 583/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6148 - val_loss: 1.0677\n",
            "Epoch 584/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6147 - val_loss: 1.0673\n",
            "Epoch 585/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6147 - val_loss: 1.0667\n",
            "Epoch 586/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6148 - val_loss: 1.0677\n",
            "Epoch 587/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6146 - val_loss: 1.0678\n",
            "Epoch 588/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6148 - val_loss: 1.0686\n",
            "Epoch 589/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6146 - val_loss: 1.0671\n",
            "Epoch 590/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6147 - val_loss: 1.0661\n",
            "Epoch 591/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6145 - val_loss: 1.0665\n",
            "Epoch 592/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6144 - val_loss: 1.0667\n",
            "Epoch 593/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6143 - val_loss: 1.0670\n",
            "Epoch 594/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6144 - val_loss: 1.0674\n",
            "Epoch 595/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6144 - val_loss: 1.0669\n",
            "Epoch 596/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6142 - val_loss: 1.0670\n",
            "Epoch 597/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6142 - val_loss: 1.0673\n",
            "Epoch 598/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6143 - val_loss: 1.0678\n",
            "Epoch 599/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6142 - val_loss: 1.0675\n",
            "Epoch 600/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6141 - val_loss: 1.0672\n",
            "Epoch 601/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6142 - val_loss: 1.0665\n",
            "Epoch 602/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6141 - val_loss: 1.0668\n",
            "Epoch 603/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6140 - val_loss: 1.0672\n",
            "Epoch 604/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6142 - val_loss: 1.0663\n",
            "Epoch 605/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6142 - val_loss: 1.0679\n",
            "Epoch 606/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6140 - val_loss: 1.0681\n",
            "Epoch 607/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6138 - val_loss: 1.0676\n",
            "Epoch 608/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6140 - val_loss: 1.0682\n",
            "Epoch 609/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6139 - val_loss: 1.0669\n",
            "Epoch 610/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6138 - val_loss: 1.0667\n",
            "Epoch 611/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6138 - val_loss: 1.0662\n",
            "Epoch 612/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6138 - val_loss: 1.0675\n",
            "Epoch 613/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6137 - val_loss: 1.0674\n",
            "Epoch 614/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6136 - val_loss: 1.0676\n",
            "Epoch 615/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6136 - val_loss: 1.0674\n",
            "Epoch 616/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6135 - val_loss: 1.0676\n",
            "Epoch 617/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6135 - val_loss: 1.0670\n",
            "Epoch 618/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6135 - val_loss: 1.0677\n",
            "Epoch 619/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6134 - val_loss: 1.0670\n",
            "Epoch 620/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6133 - val_loss: 1.0671\n",
            "Epoch 621/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6134 - val_loss: 1.0669\n",
            "Epoch 622/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6133 - val_loss: 1.0672\n",
            "Epoch 623/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6135 - val_loss: 1.0663\n",
            "Epoch 624/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6131 - val_loss: 1.0667\n",
            "Epoch 625/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6132 - val_loss: 1.0678\n",
            "Epoch 626/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6131 - val_loss: 1.0677\n",
            "Epoch 627/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6130 - val_loss: 1.0678\n",
            "Epoch 628/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6131 - val_loss: 1.0674\n",
            "Epoch 629/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6131 - val_loss: 1.0671\n",
            "Epoch 630/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6130 - val_loss: 1.0676\n",
            "Epoch 631/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6130 - val_loss: 1.0677\n",
            "Epoch 632/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6130 - val_loss: 1.0666\n",
            "Epoch 633/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6128 - val_loss: 1.0674\n",
            "Epoch 634/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6128 - val_loss: 1.0675\n",
            "Epoch 635/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6128 - val_loss: 1.0682\n",
            "Epoch 636/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6127 - val_loss: 1.0675\n",
            "Epoch 637/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6126 - val_loss: 1.0675\n",
            "Epoch 638/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6127 - val_loss: 1.0676\n",
            "Epoch 639/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6131 - val_loss: 1.0660\n",
            "Epoch 640/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6126 - val_loss: 1.0665\n",
            "Epoch 641/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6126 - val_loss: 1.0676\n",
            "Epoch 642/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6126 - val_loss: 1.0666\n",
            "Epoch 643/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6124 - val_loss: 1.0672\n",
            "Epoch 644/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6123 - val_loss: 1.0671\n",
            "Epoch 645/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6124 - val_loss: 1.0667\n",
            "Epoch 646/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6123 - val_loss: 1.0677\n",
            "Epoch 647/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6122 - val_loss: 1.0676\n",
            "Epoch 648/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6122 - val_loss: 1.0678\n",
            "Epoch 649/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6122 - val_loss: 1.0672\n",
            "Epoch 650/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6121 - val_loss: 1.0672\n",
            "Epoch 651/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6121 - val_loss: 1.0675\n",
            "Epoch 652/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6121 - val_loss: 1.0674\n",
            "Epoch 653/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6120 - val_loss: 1.0671\n",
            "Epoch 654/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6119 - val_loss: 1.0673\n",
            "Epoch 655/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6120 - val_loss: 1.0668\n",
            "Epoch 656/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6121 - val_loss: 1.0681\n",
            "Epoch 657/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6120 - val_loss: 1.0672\n",
            "Epoch 658/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6119 - val_loss: 1.0673\n",
            "Epoch 659/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6118 - val_loss: 1.0668\n",
            "Epoch 660/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6117 - val_loss: 1.0670\n",
            "Epoch 661/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6116 - val_loss: 1.0673\n",
            "Epoch 662/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6116 - val_loss: 1.0675\n",
            "Epoch 663/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6115 - val_loss: 1.0672\n",
            "Epoch 664/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6116 - val_loss: 1.0677\n",
            "Epoch 665/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6115 - val_loss: 1.0671\n",
            "Epoch 666/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6115 - val_loss: 1.0671\n",
            "Epoch 667/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6115 - val_loss: 1.0679\n",
            "Epoch 668/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6113 - val_loss: 1.0678\n",
            "Epoch 669/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6113 - val_loss: 1.0674\n",
            "Epoch 670/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6113 - val_loss: 1.0670\n",
            "Epoch 671/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6113 - val_loss: 1.0675\n",
            "Epoch 672/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6113 - val_loss: 1.0677\n",
            "Epoch 673/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6111 - val_loss: 1.0679\n",
            "Epoch 674/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6111 - val_loss: 1.0672\n",
            "Epoch 675/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6112 - val_loss: 1.0680\n",
            "Epoch 676/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6110 - val_loss: 1.0671\n",
            "Epoch 677/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6110 - val_loss: 1.0669\n",
            "Epoch 678/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6110 - val_loss: 1.0677\n",
            "Epoch 679/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6109 - val_loss: 1.0678\n",
            "Epoch 680/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6110 - val_loss: 1.0686\n",
            "Epoch 681/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6108 - val_loss: 1.0677\n",
            "Epoch 682/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6109 - val_loss: 1.0681\n",
            "Epoch 683/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6107 - val_loss: 1.0671\n",
            "Epoch 684/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6108 - val_loss: 1.0677\n",
            "Epoch 685/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6107 - val_loss: 1.0667\n",
            "Epoch 686/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6106 - val_loss: 1.0674\n",
            "Epoch 687/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6105 - val_loss: 1.0677\n",
            "Epoch 688/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6106 - val_loss: 1.0668\n",
            "Epoch 689/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6105 - val_loss: 1.0677\n",
            "Epoch 690/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6104 - val_loss: 1.0673\n",
            "Epoch 691/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6106 - val_loss: 1.0667\n",
            "Epoch 692/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6103 - val_loss: 1.0669\n",
            "Epoch 693/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6104 - val_loss: 1.0684\n",
            "Epoch 694/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6102 - val_loss: 1.0679\n",
            "Epoch 695/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6102 - val_loss: 1.0680\n",
            "Epoch 696/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6101 - val_loss: 1.0678\n",
            "Epoch 697/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6101 - val_loss: 1.0681\n",
            "Epoch 698/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6101 - val_loss: 1.0674\n",
            "Epoch 699/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6100 - val_loss: 1.0673\n",
            "Epoch 700/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6101 - val_loss: 1.0665\n",
            "Epoch 701/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6101 - val_loss: 1.0673\n",
            "Epoch 702/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6098 - val_loss: 1.0672\n",
            "Epoch 703/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6098 - val_loss: 1.0674\n",
            "Epoch 704/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6099 - val_loss: 1.0670\n",
            "Epoch 705/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6100 - val_loss: 1.0675\n",
            "Epoch 706/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6098 - val_loss: 1.0685\n",
            "Epoch 707/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6096 - val_loss: 1.0679\n",
            "Epoch 708/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6096 - val_loss: 1.0674\n",
            "Epoch 709/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6096 - val_loss: 1.0677\n",
            "Epoch 710/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6095 - val_loss: 1.0672\n",
            "Epoch 711/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6094 - val_loss: 1.0669\n",
            "Epoch 712/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6095 - val_loss: 1.0668\n",
            "Epoch 713/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6093 - val_loss: 1.0670\n",
            "Epoch 714/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6097 - val_loss: 1.0688\n",
            "Epoch 715/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6093 - val_loss: 1.0681\n",
            "Epoch 716/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6093 - val_loss: 1.0675\n",
            "Epoch 717/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6094 - val_loss: 1.0664\n",
            "Epoch 718/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6092 - val_loss: 1.0677\n",
            "Epoch 719/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6091 - val_loss: 1.0679\n",
            "Epoch 720/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6091 - val_loss: 1.0682\n",
            "Epoch 721/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6091 - val_loss: 1.0674\n",
            "Epoch 722/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6090 - val_loss: 1.0669\n",
            "Epoch 723/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6090 - val_loss: 1.0680\n",
            "Epoch 724/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6090 - val_loss: 1.0676\n",
            "Epoch 725/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6088 - val_loss: 1.0669\n",
            "Epoch 726/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6088 - val_loss: 1.0672\n",
            "Epoch 727/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6088 - val_loss: 1.0676\n",
            "Epoch 728/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6087 - val_loss: 1.0680\n",
            "Epoch 729/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6086 - val_loss: 1.0678\n",
            "Epoch 730/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6086 - val_loss: 1.0672\n",
            "Epoch 731/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6087 - val_loss: 1.0665\n",
            "Epoch 732/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6086 - val_loss: 1.0678\n",
            "Epoch 733/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6086 - val_loss: 1.0683\n",
            "Epoch 734/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6085 - val_loss: 1.0672\n",
            "Epoch 735/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6085 - val_loss: 1.0682\n",
            "Epoch 736/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6086 - val_loss: 1.0688\n",
            "Epoch 737/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6088 - val_loss: 1.0665\n",
            "Epoch 738/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6084 - val_loss: 1.0675\n",
            "Epoch 739/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6082 - val_loss: 1.0673\n",
            "Epoch 740/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6082 - val_loss: 1.0668\n",
            "Epoch 741/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6080 - val_loss: 1.0673\n",
            "Epoch 742/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6080 - val_loss: 1.0678\n",
            "Epoch 743/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6080 - val_loss: 1.0676\n",
            "Epoch 744/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6079 - val_loss: 1.0672\n",
            "Epoch 745/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6078 - val_loss: 1.0674\n",
            "Epoch 746/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6080 - val_loss: 1.0669\n",
            "Epoch 747/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6078 - val_loss: 1.0673\n",
            "Epoch 748/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6078 - val_loss: 1.0683\n",
            "Epoch 749/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6079 - val_loss: 1.0671\n",
            "Epoch 750/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6078 - val_loss: 1.0685\n",
            "Epoch 751/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6076 - val_loss: 1.0683\n",
            "Epoch 752/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6075 - val_loss: 1.0677\n",
            "Epoch 753/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6077 - val_loss: 1.0670\n",
            "Epoch 754/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6076 - val_loss: 1.0681\n",
            "Epoch 755/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6076 - val_loss: 1.0669\n",
            "Epoch 756/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6074 - val_loss: 1.0667\n",
            "Epoch 757/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6074 - val_loss: 1.0674\n",
            "Epoch 758/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6074 - val_loss: 1.0684\n",
            "Epoch 759/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6072 - val_loss: 1.0677\n",
            "Epoch 760/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6073 - val_loss: 1.0684\n",
            "Epoch 761/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6072 - val_loss: 1.0676\n",
            "Epoch 762/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6071 - val_loss: 1.0675\n",
            "Epoch 763/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6071 - val_loss: 1.0680\n",
            "Epoch 764/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6072 - val_loss: 1.0683\n",
            "Epoch 765/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6070 - val_loss: 1.0671\n",
            "Epoch 766/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6070 - val_loss: 1.0678\n",
            "Epoch 767/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6068 - val_loss: 1.0673\n",
            "Epoch 768/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6068 - val_loss: 1.0675\n",
            "Epoch 769/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6068 - val_loss: 1.0668\n",
            "Epoch 770/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6067 - val_loss: 1.0675\n",
            "Epoch 771/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6067 - val_loss: 1.0682\n",
            "Epoch 772/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6067 - val_loss: 1.0686\n",
            "Epoch 773/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6067 - val_loss: 1.0686\n",
            "Epoch 774/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6065 - val_loss: 1.0677\n",
            "Epoch 775/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6064 - val_loss: 1.0672\n",
            "Epoch 776/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6065 - val_loss: 1.0666\n",
            "Epoch 777/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6063 - val_loss: 1.0670\n",
            "Epoch 778/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6063 - val_loss: 1.0671\n",
            "Epoch 779/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6063 - val_loss: 1.0676\n",
            "Epoch 780/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6065 - val_loss: 1.0664\n",
            "Epoch 781/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6063 - val_loss: 1.0676\n",
            "Epoch 782/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6061 - val_loss: 1.0676\n",
            "Epoch 783/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6062 - val_loss: 1.0669\n",
            "Epoch 784/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6060 - val_loss: 1.0669\n",
            "Epoch 785/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6060 - val_loss: 1.0676\n",
            "Epoch 786/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6060 - val_loss: 1.0678\n",
            "Epoch 787/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6059 - val_loss: 1.0673\n",
            "Epoch 788/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6058 - val_loss: 1.0676\n",
            "Epoch 789/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6058 - val_loss: 1.0680\n",
            "Epoch 790/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6057 - val_loss: 1.0675\n",
            "Epoch 791/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6057 - val_loss: 1.0674\n",
            "Epoch 792/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6056 - val_loss: 1.0673\n",
            "Epoch 793/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6056 - val_loss: 1.0673\n",
            "Epoch 794/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6055 - val_loss: 1.0673\n",
            "Epoch 795/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6055 - val_loss: 1.0683\n",
            "Epoch 796/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6055 - val_loss: 1.0680\n",
            "Epoch 797/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6053 - val_loss: 1.0678\n",
            "Epoch 798/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6053 - val_loss: 1.0681\n",
            "Epoch 799/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6053 - val_loss: 1.0680\n",
            "Epoch 800/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6053 - val_loss: 1.0672\n",
            "Epoch 801/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6052 - val_loss: 1.0676\n",
            "Epoch 802/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6056 - val_loss: 1.0659\n",
            "Epoch 803/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6051 - val_loss: 1.0673\n",
            "Epoch 804/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6050 - val_loss: 1.0672\n",
            "Epoch 805/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6050 - val_loss: 1.0677\n",
            "Epoch 806/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6051 - val_loss: 1.0669\n",
            "Epoch 807/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6050 - val_loss: 1.0683\n",
            "Epoch 808/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6049 - val_loss: 1.0679\n",
            "Epoch 809/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6048 - val_loss: 1.0683\n",
            "Epoch 810/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6048 - val_loss: 1.0673\n",
            "Epoch 811/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6047 - val_loss: 1.0677\n",
            "Epoch 812/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6047 - val_loss: 1.0671\n",
            "Epoch 813/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6046 - val_loss: 1.0678\n",
            "Epoch 814/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6046 - val_loss: 1.0675\n",
            "Epoch 815/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6046 - val_loss: 1.0673\n",
            "Epoch 816/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6045 - val_loss: 1.0681\n",
            "Epoch 817/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6046 - val_loss: 1.0669\n",
            "Epoch 818/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6044 - val_loss: 1.0678\n",
            "Epoch 819/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6045 - val_loss: 1.0689\n",
            "Epoch 820/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6048 - val_loss: 1.0665\n",
            "Epoch 821/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6042 - val_loss: 1.0673\n",
            "Epoch 822/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6042 - val_loss: 1.0680\n",
            "Epoch 823/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6042 - val_loss: 1.0677\n",
            "Epoch 824/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6041 - val_loss: 1.0670\n",
            "Epoch 825/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6040 - val_loss: 1.0668\n",
            "Epoch 826/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6039 - val_loss: 1.0677\n",
            "Epoch 827/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6039 - val_loss: 1.0676\n",
            "Epoch 828/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6039 - val_loss: 1.0685\n",
            "Epoch 829/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6038 - val_loss: 1.0680\n",
            "Epoch 830/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6038 - val_loss: 1.0679\n",
            "Epoch 831/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6039 - val_loss: 1.0685\n",
            "Epoch 832/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6036 - val_loss: 1.0680\n",
            "Epoch 833/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6037 - val_loss: 1.0671\n",
            "Epoch 834/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6036 - val_loss: 1.0685\n",
            "Epoch 835/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6038 - val_loss: 1.0671\n",
            "Epoch 836/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6034 - val_loss: 1.0679\n",
            "Epoch 837/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6033 - val_loss: 1.0677\n",
            "Epoch 838/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6036 - val_loss: 1.0688\n",
            "Epoch 839/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6034 - val_loss: 1.0674\n",
            "Epoch 840/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6032 - val_loss: 1.0677\n",
            "Epoch 841/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6033 - val_loss: 1.0669\n",
            "Epoch 842/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6033 - val_loss: 1.0681\n",
            "Epoch 843/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6030 - val_loss: 1.0681\n",
            "Epoch 844/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6031 - val_loss: 1.0675\n",
            "Epoch 845/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6030 - val_loss: 1.0677\n",
            "Epoch 846/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6030 - val_loss: 1.0682\n",
            "Epoch 847/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6029 - val_loss: 1.0676\n",
            "Epoch 848/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6028 - val_loss: 1.0676\n",
            "Epoch 849/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6029 - val_loss: 1.0669\n",
            "Epoch 850/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6029 - val_loss: 1.0686\n",
            "Epoch 851/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6027 - val_loss: 1.0680\n",
            "Epoch 852/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6026 - val_loss: 1.0680\n",
            "Epoch 853/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6025 - val_loss: 1.0676\n",
            "Epoch 854/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6026 - val_loss: 1.0685\n",
            "Epoch 855/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6024 - val_loss: 1.0679\n",
            "Epoch 856/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6025 - val_loss: 1.0670\n",
            "Epoch 857/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6024 - val_loss: 1.0673\n",
            "Epoch 858/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6023 - val_loss: 1.0672\n",
            "Epoch 859/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6022 - val_loss: 1.0677\n",
            "Epoch 860/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6022 - val_loss: 1.0675\n",
            "Epoch 861/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6022 - val_loss: 1.0671\n",
            "Epoch 862/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6021 - val_loss: 1.0671\n",
            "Epoch 863/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6020 - val_loss: 1.0674\n",
            "Epoch 864/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6021 - val_loss: 1.0690\n",
            "Epoch 865/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6020 - val_loss: 1.0679\n",
            "Epoch 866/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6019 - val_loss: 1.0681\n",
            "Epoch 867/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6018 - val_loss: 1.0686\n",
            "Epoch 868/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6018 - val_loss: 1.0680\n",
            "Epoch 869/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6017 - val_loss: 1.0677\n",
            "Epoch 870/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6017 - val_loss: 1.0683\n",
            "Epoch 871/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6017 - val_loss: 1.0686\n",
            "Epoch 872/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6015 - val_loss: 1.0680\n",
            "Epoch 873/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6015 - val_loss: 1.0675\n",
            "Epoch 874/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6016 - val_loss: 1.0681\n",
            "Epoch 875/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6014 - val_loss: 1.0678\n",
            "Epoch 876/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6014 - val_loss: 1.0678\n",
            "Epoch 877/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6013 - val_loss: 1.0672\n",
            "Epoch 878/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6012 - val_loss: 1.0676\n",
            "Epoch 879/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6012 - val_loss: 1.0684\n",
            "Epoch 880/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6011 - val_loss: 1.0681\n",
            "Epoch 881/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6012 - val_loss: 1.0676\n",
            "Epoch 882/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6011 - val_loss: 1.0673\n",
            "Epoch 883/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6012 - val_loss: 1.0689\n",
            "Epoch 884/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6011 - val_loss: 1.0690\n",
            "Epoch 885/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6010 - val_loss: 1.0674\n",
            "Epoch 886/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6008 - val_loss: 1.0673\n",
            "Epoch 887/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6008 - val_loss: 1.0673\n",
            "Epoch 888/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6009 - val_loss: 1.0689\n",
            "Epoch 889/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6008 - val_loss: 1.0688\n",
            "Epoch 890/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6006 - val_loss: 1.0687\n",
            "Epoch 891/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6006 - val_loss: 1.0682\n",
            "Epoch 892/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6007 - val_loss: 1.0668\n",
            "Epoch 893/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6004 - val_loss: 1.0677\n",
            "Epoch 894/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6004 - val_loss: 1.0677\n",
            "Epoch 895/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6006 - val_loss: 1.0667\n",
            "Epoch 896/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6003 - val_loss: 1.0679\n",
            "Epoch 897/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6002 - val_loss: 1.0675\n",
            "Epoch 898/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6001 - val_loss: 1.0679\n",
            "Epoch 899/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6002 - val_loss: 1.0679\n",
            "Epoch 900/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6001 - val_loss: 1.0671\n",
            "Epoch 901/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6003 - val_loss: 1.0688\n",
            "Epoch 902/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5999 - val_loss: 1.0682\n",
            "Epoch 903/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5999 - val_loss: 1.0675\n",
            "Epoch 904/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5998 - val_loss: 1.0672\n",
            "Epoch 905/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5999 - val_loss: 1.0667\n",
            "Epoch 906/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5998 - val_loss: 1.0682\n",
            "Epoch 907/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5996 - val_loss: 1.0682\n",
            "Epoch 908/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5996 - val_loss: 1.0687\n",
            "Epoch 909/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5998 - val_loss: 1.0672\n",
            "Epoch 910/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5997 - val_loss: 1.0687\n",
            "Epoch 911/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5995 - val_loss: 1.0672\n",
            "Epoch 912/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5994 - val_loss: 1.0675\n",
            "Epoch 913/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5993 - val_loss: 1.0679\n",
            "Epoch 914/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5993 - val_loss: 1.0678\n",
            "Epoch 915/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5993 - val_loss: 1.0679\n",
            "Epoch 916/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5992 - val_loss: 1.0688\n",
            "Epoch 917/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5991 - val_loss: 1.0682\n",
            "Epoch 918/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5991 - val_loss: 1.0677\n",
            "Epoch 919/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5990 - val_loss: 1.0681\n",
            "Epoch 920/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5990 - val_loss: 1.0681\n",
            "Epoch 921/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5990 - val_loss: 1.0685\n",
            "Epoch 922/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5988 - val_loss: 1.0679\n",
            "Epoch 923/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5988 - val_loss: 1.0675\n",
            "Epoch 924/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5987 - val_loss: 1.0677\n",
            "Epoch 925/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5987 - val_loss: 1.0681\n",
            "Epoch 926/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5990 - val_loss: 1.0663\n",
            "Epoch 927/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5986 - val_loss: 1.0676\n",
            "Epoch 928/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5986 - val_loss: 1.0676\n",
            "Epoch 929/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5984 - val_loss: 1.0682\n",
            "Epoch 930/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5986 - val_loss: 1.0685\n",
            "Epoch 931/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5985 - val_loss: 1.0672\n",
            "Epoch 932/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5987 - val_loss: 1.0687\n",
            "Epoch 933/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5982 - val_loss: 1.0678\n",
            "Epoch 934/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5982 - val_loss: 1.0670\n",
            "Epoch 935/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5981 - val_loss: 1.0678\n",
            "Epoch 936/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5980 - val_loss: 1.0674\n",
            "Epoch 937/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5983 - val_loss: 1.0666\n",
            "Epoch 938/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5982 - val_loss: 1.0688\n",
            "Epoch 939/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5980 - val_loss: 1.0692\n",
            "Epoch 940/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5978 - val_loss: 1.0682\n",
            "Epoch 941/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5978 - val_loss: 1.0679\n",
            "Epoch 942/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5977 - val_loss: 1.0676\n",
            "Epoch 943/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5978 - val_loss: 1.0685\n",
            "Epoch 944/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5976 - val_loss: 1.0684\n",
            "Epoch 945/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5976 - val_loss: 1.0673\n",
            "Epoch 946/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5975 - val_loss: 1.0675\n",
            "Epoch 947/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5975 - val_loss: 1.0675\n",
            "Epoch 948/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5974 - val_loss: 1.0682\n",
            "Epoch 949/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5973 - val_loss: 1.0677\n",
            "Epoch 950/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5975 - val_loss: 1.0673\n",
            "Epoch 951/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5974 - val_loss: 1.0681\n",
            "Epoch 952/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5973 - val_loss: 1.0670\n",
            "Epoch 953/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5971 - val_loss: 1.0672\n",
            "Epoch 954/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5972 - val_loss: 1.0685\n",
            "Epoch 955/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5970 - val_loss: 1.0687\n",
            "Epoch 956/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5969 - val_loss: 1.0683\n",
            "Epoch 957/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5969 - val_loss: 1.0674\n",
            "Epoch 958/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5970 - val_loss: 1.0666\n",
            "Epoch 959/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5968 - val_loss: 1.0674\n",
            "Epoch 960/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5967 - val_loss: 1.0683\n",
            "Epoch 961/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5967 - val_loss: 1.0685\n",
            "Epoch 962/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5968 - val_loss: 1.0674\n",
            "Epoch 963/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5966 - val_loss: 1.0680\n",
            "Epoch 964/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5965 - val_loss: 1.0679\n",
            "Epoch 965/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5965 - val_loss: 1.0675\n",
            "Epoch 966/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5964 - val_loss: 1.0679\n",
            "Epoch 967/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5965 - val_loss: 1.0675\n",
            "Epoch 968/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5963 - val_loss: 1.0673\n",
            "Epoch 969/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5962 - val_loss: 1.0681\n",
            "Epoch 970/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5961 - val_loss: 1.0685\n",
            "Epoch 971/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5960 - val_loss: 1.0685\n",
            "Epoch 972/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5961 - val_loss: 1.0683\n",
            "Epoch 973/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5961 - val_loss: 1.0685\n",
            "Epoch 974/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5961 - val_loss: 1.0677\n",
            "Epoch 975/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5958 - val_loss: 1.0676\n",
            "Epoch 976/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5958 - val_loss: 1.0680\n",
            "Epoch 977/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5957 - val_loss: 1.0682\n",
            "Epoch 978/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5957 - val_loss: 1.0678\n",
            "Epoch 979/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5959 - val_loss: 1.0687\n",
            "Epoch 980/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5955 - val_loss: 1.0680\n",
            "Epoch 981/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5956 - val_loss: 1.0669\n",
            "Epoch 982/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5955 - val_loss: 1.0681\n",
            "Epoch 983/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5953 - val_loss: 1.0681\n",
            "Epoch 984/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5953 - val_loss: 1.0678\n",
            "Epoch 985/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5953 - val_loss: 1.0670\n",
            "Epoch 986/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5954 - val_loss: 1.0685\n",
            "Epoch 987/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5952 - val_loss: 1.0678\n",
            "Epoch 988/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5954 - val_loss: 1.0663\n",
            "Epoch 989/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5950 - val_loss: 1.0674\n",
            "Epoch 990/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5951 - val_loss: 1.0689\n",
            "Epoch 991/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5950 - val_loss: 1.0693\n",
            "Epoch 992/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5949 - val_loss: 1.0679\n",
            "Epoch 993/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5948 - val_loss: 1.0680\n",
            "Epoch 994/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5953 - val_loss: 1.0695\n",
            "Epoch 995/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5947 - val_loss: 1.0678\n",
            "Epoch 996/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5947 - val_loss: 1.0667\n",
            "Epoch 997/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5946 - val_loss: 1.0672\n",
            "Epoch 998/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5945 - val_loss: 1.0679\n",
            "Epoch 999/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5944 - val_loss: 1.0679\n",
            "Epoch 1000/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5944 - val_loss: 1.0680\n",
            "Epoch 1001/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5943 - val_loss: 1.0680\n",
            "Epoch 1002/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5943 - val_loss: 1.0688\n",
            "Epoch 1003/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5944 - val_loss: 1.0671\n",
            "Epoch 1004/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5943 - val_loss: 1.0667\n",
            "Epoch 1005/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5942 - val_loss: 1.0687\n",
            "Epoch 1006/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5941 - val_loss: 1.0686\n",
            "Epoch 1007/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5942 - val_loss: 1.0694\n",
            "Epoch 1008/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5938 - val_loss: 1.0685\n",
            "Epoch 1009/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5939 - val_loss: 1.0672\n",
            "Epoch 1010/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5939 - val_loss: 1.0673\n",
            "Epoch 1011/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5940 - val_loss: 1.0687\n",
            "Epoch 1012/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5938 - val_loss: 1.0674\n",
            "Epoch 1013/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5937 - val_loss: 1.0678\n",
            "Epoch 1014/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5937 - val_loss: 1.0673\n",
            "Epoch 1015/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5935 - val_loss: 1.0676\n",
            "Epoch 1016/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5935 - val_loss: 1.0672\n",
            "Epoch 1017/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5935 - val_loss: 1.0681\n",
            "Epoch 1018/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5933 - val_loss: 1.0677\n",
            "Epoch 1019/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5937 - val_loss: 1.0694\n",
            "Epoch 1020/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5933 - val_loss: 1.0676\n",
            "Epoch 1021/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5931 - val_loss: 1.0674\n",
            "Epoch 1022/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5932 - val_loss: 1.0681\n",
            "Epoch 1023/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5935 - val_loss: 1.0696\n",
            "Epoch 1024/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5929 - val_loss: 1.0681\n",
            "Epoch 1025/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5929 - val_loss: 1.0678\n",
            "Epoch 1026/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5928 - val_loss: 1.0673\n",
            "Epoch 1027/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5929 - val_loss: 1.0675\n",
            "Epoch 1028/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5927 - val_loss: 1.0672\n",
            "Epoch 1029/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5926 - val_loss: 1.0675\n",
            "Epoch 1030/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5926 - val_loss: 1.0673\n",
            "Epoch 1031/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5927 - val_loss: 1.0675\n",
            "Epoch 1032/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5927 - val_loss: 1.0695\n",
            "Epoch 1033/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5928 - val_loss: 1.0701\n",
            "Epoch 1034/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5923 - val_loss: 1.0687\n",
            "Epoch 1035/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5927 - val_loss: 1.0668\n",
            "Epoch 1036/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5922 - val_loss: 1.0673\n",
            "Epoch 1037/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5924 - val_loss: 1.0668\n",
            "Epoch 1038/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5921 - val_loss: 1.0684\n",
            "Epoch 1039/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5924 - val_loss: 1.0697\n",
            "Epoch 1040/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5923 - val_loss: 1.0706\n",
            "Epoch 1041/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5920 - val_loss: 1.0686\n",
            "Epoch 1042/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5919 - val_loss: 1.0686\n",
            "Epoch 1043/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5919 - val_loss: 1.0681\n",
            "Epoch 1044/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5918 - val_loss: 1.0677\n",
            "Epoch 1045/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5917 - val_loss: 1.0673\n",
            "Epoch 1046/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5920 - val_loss: 1.0664\n",
            "Epoch 1047/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5917 - val_loss: 1.0685\n",
            "Epoch 1048/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5916 - val_loss: 1.0678\n",
            "Epoch 1049/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5915 - val_loss: 1.0678\n",
            "Epoch 1050/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5914 - val_loss: 1.0684\n",
            "Epoch 1051/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5914 - val_loss: 1.0682\n",
            "Epoch 1052/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5914 - val_loss: 1.0690\n",
            "Epoch 1053/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5913 - val_loss: 1.0693\n",
            "Epoch 1054/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5912 - val_loss: 1.0688\n",
            "Epoch 1055/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5911 - val_loss: 1.0676\n",
            "Epoch 1056/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5911 - val_loss: 1.0673\n",
            "Epoch 1057/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5910 - val_loss: 1.0674\n",
            "Epoch 1058/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5909 - val_loss: 1.0674\n",
            "Epoch 1059/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5909 - val_loss: 1.0682\n",
            "Epoch 1060/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5909 - val_loss: 1.0689\n",
            "Epoch 1061/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5910 - val_loss: 1.0697\n",
            "Epoch 1062/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5907 - val_loss: 1.0683\n",
            "Epoch 1063/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5906 - val_loss: 1.0682\n",
            "Epoch 1064/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5906 - val_loss: 1.0678\n",
            "Epoch 1065/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5905 - val_loss: 1.0673\n",
            "Epoch 1066/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5906 - val_loss: 1.0686\n",
            "Epoch 1067/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5904 - val_loss: 1.0686\n",
            "Epoch 1068/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5903 - val_loss: 1.0685\n",
            "Epoch 1069/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5903 - val_loss: 1.0685\n",
            "Epoch 1070/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5903 - val_loss: 1.0677\n",
            "Epoch 1071/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5904 - val_loss: 1.0690\n",
            "Epoch 1072/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5903 - val_loss: 1.0671\n",
            "Epoch 1073/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5900 - val_loss: 1.0677\n",
            "Epoch 1074/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5902 - val_loss: 1.0691\n",
            "Epoch 1075/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5901 - val_loss: 1.0692\n",
            "Epoch 1076/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5898 - val_loss: 1.0679\n",
            "Epoch 1077/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5899 - val_loss: 1.0665\n",
            "Epoch 1078/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5897 - val_loss: 1.0671\n",
            "Epoch 1079/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5897 - val_loss: 1.0681\n",
            "Epoch 1080/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5896 - val_loss: 1.0684\n",
            "Epoch 1081/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5897 - val_loss: 1.0691\n",
            "Epoch 1082/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5896 - val_loss: 1.0680\n",
            "Epoch 1083/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5894 - val_loss: 1.0680\n",
            "Epoch 1084/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5895 - val_loss: 1.0693\n",
            "Epoch 1085/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5894 - val_loss: 1.0676\n",
            "Epoch 1086/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5894 - val_loss: 1.0682\n",
            "Epoch 1087/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5893 - val_loss: 1.0676\n",
            "Epoch 1088/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5893 - val_loss: 1.0689\n",
            "Epoch 1089/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5891 - val_loss: 1.0678\n",
            "Epoch 1090/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5889 - val_loss: 1.0681\n",
            "Epoch 1091/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5891 - val_loss: 1.0690\n",
            "Epoch 1092/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5889 - val_loss: 1.0677\n",
            "Epoch 1093/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5889 - val_loss: 1.0667\n",
            "Epoch 1094/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5887 - val_loss: 1.0677\n",
            "Epoch 1095/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5887 - val_loss: 1.0675\n",
            "Epoch 1096/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5887 - val_loss: 1.0683\n",
            "Epoch 1097/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5886 - val_loss: 1.0685\n",
            "Epoch 1098/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5885 - val_loss: 1.0687\n",
            "Epoch 1099/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5887 - val_loss: 1.0686\n",
            "Epoch 1100/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5886 - val_loss: 1.0674\n",
            "Epoch 1101/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5884 - val_loss: 1.0679\n",
            "Epoch 1102/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5884 - val_loss: 1.0691\n",
            "Epoch 1103/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5883 - val_loss: 1.0683\n",
            "Epoch 1104/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5881 - val_loss: 1.0687\n",
            "Epoch 1105/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5881 - val_loss: 1.0691\n",
            "Epoch 1106/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5879 - val_loss: 1.0681\n",
            "Epoch 1107/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5880 - val_loss: 1.0688\n",
            "Epoch 1108/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5880 - val_loss: 1.0679\n",
            "Epoch 1109/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5878 - val_loss: 1.0679\n",
            "Epoch 1110/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5877 - val_loss: 1.0681\n",
            "Epoch 1111/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5879 - val_loss: 1.0695\n",
            "Epoch 1112/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5877 - val_loss: 1.0681\n",
            "Epoch 1113/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5878 - val_loss: 1.0695\n",
            "Epoch 1114/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5875 - val_loss: 1.0680\n",
            "Epoch 1115/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5875 - val_loss: 1.0675\n",
            "Epoch 1116/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5875 - val_loss: 1.0667\n",
            "Epoch 1117/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5873 - val_loss: 1.0682\n",
            "Epoch 1118/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5873 - val_loss: 1.0680\n",
            "Epoch 1119/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5873 - val_loss: 1.0690\n",
            "Epoch 1120/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5872 - val_loss: 1.0683\n",
            "Epoch 1121/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5871 - val_loss: 1.0688\n",
            "Epoch 1122/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5870 - val_loss: 1.0689\n",
            "Epoch 1123/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5869 - val_loss: 1.0683\n",
            "Epoch 1124/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5872 - val_loss: 1.0666\n",
            "Epoch 1125/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5868 - val_loss: 1.0675\n",
            "Epoch 1126/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5868 - val_loss: 1.0684\n",
            "Epoch 1127/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5870 - val_loss: 1.0686\n",
            "Epoch 1128/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5867 - val_loss: 1.0668\n",
            "Epoch 1129/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5866 - val_loss: 1.0667\n",
            "Epoch 1130/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5865 - val_loss: 1.0670\n",
            "Epoch 1131/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5866 - val_loss: 1.0684\n",
            "Epoch 1132/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5867 - val_loss: 1.0702\n",
            "Epoch 1133/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5864 - val_loss: 1.0690\n",
            "Epoch 1134/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5863 - val_loss: 1.0683\n",
            "Epoch 1135/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5862 - val_loss: 1.0684\n",
            "Epoch 1136/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5861 - val_loss: 1.0678\n",
            "Epoch 1137/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5862 - val_loss: 1.0671\n",
            "Epoch 1138/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5860 - val_loss: 1.0677\n",
            "Epoch 1139/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5859 - val_loss: 1.0686\n",
            "Epoch 1140/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5860 - val_loss: 1.0676\n",
            "Epoch 1141/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5858 - val_loss: 1.0685\n",
            "Epoch 1142/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5860 - val_loss: 1.0673\n",
            "Epoch 1143/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5857 - val_loss: 1.0686\n",
            "Epoch 1144/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5856 - val_loss: 1.0689\n",
            "Epoch 1145/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5856 - val_loss: 1.0686\n",
            "Epoch 1146/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5855 - val_loss: 1.0686\n",
            "Epoch 1147/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5855 - val_loss: 1.0687\n",
            "Epoch 1148/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5854 - val_loss: 1.0687\n",
            "Epoch 1149/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5853 - val_loss: 1.0673\n",
            "Epoch 1150/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5852 - val_loss: 1.0677\n",
            "Epoch 1151/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5854 - val_loss: 1.0671\n",
            "Epoch 1152/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5851 - val_loss: 1.0677\n",
            "Epoch 1153/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5855 - val_loss: 1.0696\n",
            "Epoch 1154/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5850 - val_loss: 1.0682\n",
            "Epoch 1155/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5849 - val_loss: 1.0678\n",
            "Epoch 1156/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5849 - val_loss: 1.0677\n",
            "Epoch 1157/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5850 - val_loss: 1.0674\n",
            "Epoch 1158/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5849 - val_loss: 1.0686\n",
            "Epoch 1159/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5849 - val_loss: 1.0696\n",
            "Epoch 1160/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5848 - val_loss: 1.0673\n",
            "Epoch 1161/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5846 - val_loss: 1.0683\n",
            "Epoch 1162/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5847 - val_loss: 1.0696\n",
            "Epoch 1163/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5849 - val_loss: 1.0679\n",
            "Epoch 1164/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5843 - val_loss: 1.0679\n",
            "Epoch 1165/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5848 - val_loss: 1.0696\n",
            "Epoch 1166/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5842 - val_loss: 1.0683\n",
            "Epoch 1167/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5842 - val_loss: 1.0675\n",
            "Epoch 1168/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5842 - val_loss: 1.0678\n",
            "Epoch 1169/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5842 - val_loss: 1.0672\n",
            "Epoch 1170/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5839 - val_loss: 1.0683\n",
            "Epoch 1171/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5839 - val_loss: 1.0680\n",
            "Epoch 1172/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5839 - val_loss: 1.0693\n",
            "Epoch 1173/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5839 - val_loss: 1.0681\n",
            "Epoch 1174/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5837 - val_loss: 1.0689\n",
            "Epoch 1175/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5837 - val_loss: 1.0690\n",
            "Epoch 1176/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5837 - val_loss: 1.0679\n",
            "Epoch 1177/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5836 - val_loss: 1.0689\n",
            "Epoch 1178/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5836 - val_loss: 1.0694\n",
            "Epoch 1179/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5834 - val_loss: 1.0684\n",
            "Epoch 1180/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5834 - val_loss: 1.0676\n",
            "Epoch 1181/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5836 - val_loss: 1.0668\n",
            "Epoch 1182/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5832 - val_loss: 1.0686\n",
            "Epoch 1183/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5831 - val_loss: 1.0693\n",
            "Epoch 1184/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5831 - val_loss: 1.0685\n",
            "Epoch 1185/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5831 - val_loss: 1.0684\n",
            "Epoch 1186/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5830 - val_loss: 1.0694\n",
            "Epoch 1187/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5828 - val_loss: 1.0684\n",
            "Epoch 1188/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5828 - val_loss: 1.0688\n",
            "Epoch 1189/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5828 - val_loss: 1.0688\n",
            "Epoch 1190/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5827 - val_loss: 1.0683\n",
            "Epoch 1191/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5826 - val_loss: 1.0689\n",
            "Epoch 1192/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5825 - val_loss: 1.0690\n",
            "Epoch 1193/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5825 - val_loss: 1.0687\n",
            "Epoch 1194/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5825 - val_loss: 1.0684\n",
            "Epoch 1195/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5824 - val_loss: 1.0688\n",
            "Epoch 1196/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5823 - val_loss: 1.0687\n",
            "Epoch 1197/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5824 - val_loss: 1.0693\n",
            "Epoch 1198/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5823 - val_loss: 1.0687\n",
            "Epoch 1199/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5821 - val_loss: 1.0688\n",
            "Epoch 1200/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5820 - val_loss: 1.0682\n",
            "Epoch 1201/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5820 - val_loss: 1.0678\n",
            "Epoch 1202/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5820 - val_loss: 1.0672\n",
            "Epoch 1203/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5823 - val_loss: 1.0698\n",
            "Epoch 1204/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5817 - val_loss: 1.0688\n",
            "Epoch 1205/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5817 - val_loss: 1.0678\n",
            "Epoch 1206/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5817 - val_loss: 1.0687\n",
            "Epoch 1207/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5817 - val_loss: 1.0687\n",
            "Epoch 1208/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5815 - val_loss: 1.0683\n",
            "Epoch 1209/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5820 - val_loss: 1.0701\n",
            "Epoch 1210/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5813 - val_loss: 1.0686\n",
            "Epoch 1211/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5814 - val_loss: 1.0689\n",
            "Epoch 1212/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5814 - val_loss: 1.0682\n",
            "Epoch 1213/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5813 - val_loss: 1.0689\n",
            "Epoch 1214/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5812 - val_loss: 1.0687\n",
            "Epoch 1215/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5812 - val_loss: 1.0678\n",
            "Epoch 1216/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5810 - val_loss: 1.0685\n",
            "Epoch 1217/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5810 - val_loss: 1.0686\n",
            "Epoch 1218/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5810 - val_loss: 1.0696\n",
            "Epoch 1219/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5808 - val_loss: 1.0695\n",
            "Epoch 1220/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5809 - val_loss: 1.0679\n",
            "Epoch 1221/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5808 - val_loss: 1.0690\n",
            "Epoch 1222/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5806 - val_loss: 1.0684\n",
            "Epoch 1223/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5806 - val_loss: 1.0676\n",
            "Epoch 1224/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5808 - val_loss: 1.0690\n",
            "Epoch 1225/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5804 - val_loss: 1.0689\n",
            "Epoch 1226/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5804 - val_loss: 1.0687\n",
            "Epoch 1227/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5804 - val_loss: 1.0689\n",
            "Epoch 1228/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5803 - val_loss: 1.0678\n",
            "Epoch 1229/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5805 - val_loss: 1.0691\n",
            "Epoch 1230/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5801 - val_loss: 1.0678\n",
            "Epoch 1231/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5800 - val_loss: 1.0678\n",
            "Epoch 1232/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5799 - val_loss: 1.0680\n",
            "Epoch 1233/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5799 - val_loss: 1.0676\n",
            "Epoch 1234/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5799 - val_loss: 1.0680\n",
            "Epoch 1235/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5797 - val_loss: 1.0686\n",
            "Epoch 1236/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5801 - val_loss: 1.0676\n",
            "Epoch 1237/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5795 - val_loss: 1.0685\n",
            "Epoch 1238/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5796 - val_loss: 1.0683\n",
            "Epoch 1239/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5795 - val_loss: 1.0693\n",
            "Epoch 1240/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5794 - val_loss: 1.0695\n",
            "Epoch 1241/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5795 - val_loss: 1.0697\n",
            "Epoch 1242/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5793 - val_loss: 1.0687\n",
            "Epoch 1243/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5792 - val_loss: 1.0688\n",
            "Epoch 1244/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5792 - val_loss: 1.0689\n",
            "Epoch 1245/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5791 - val_loss: 1.0690\n",
            "Epoch 1246/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5790 - val_loss: 1.0690\n",
            "Epoch 1247/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5789 - val_loss: 1.0689\n",
            "Epoch 1248/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5789 - val_loss: 1.0680\n",
            "Epoch 1249/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5789 - val_loss: 1.0689\n",
            "Epoch 1250/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5789 - val_loss: 1.0686\n",
            "Epoch 1251/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5788 - val_loss: 1.0686\n",
            "Epoch 1252/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5787 - val_loss: 1.0683\n",
            "Epoch 1253/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5787 - val_loss: 1.0684\n",
            "Epoch 1254/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5787 - val_loss: 1.0696\n",
            "Epoch 1255/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5784 - val_loss: 1.0689\n",
            "Epoch 1256/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5785 - val_loss: 1.0682\n",
            "Epoch 1257/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5783 - val_loss: 1.0688\n",
            "Epoch 1258/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5783 - val_loss: 1.0686\n",
            "Epoch 1259/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5783 - val_loss: 1.0685\n",
            "Epoch 1260/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5784 - val_loss: 1.0680\n",
            "Epoch 1261/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5783 - val_loss: 1.0678\n",
            "Epoch 1262/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5782 - val_loss: 1.0695\n",
            "Epoch 1263/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5782 - val_loss: 1.0711\n",
            "Epoch 1264/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5779 - val_loss: 1.0700\n",
            "Epoch 1265/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5783 - val_loss: 1.0675\n",
            "Epoch 1266/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5778 - val_loss: 1.0687\n",
            "Epoch 1267/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5777 - val_loss: 1.0685\n",
            "Epoch 1268/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5781 - val_loss: 1.0713\n",
            "Epoch 1269/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5777 - val_loss: 1.0708\n",
            "Epoch 1270/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5780 - val_loss: 1.0717\n",
            "Epoch 1271/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5780 - val_loss: 1.0682\n",
            "Epoch 1272/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5775 - val_loss: 1.0682\n",
            "Epoch 1273/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5773 - val_loss: 1.0686\n",
            "Epoch 1274/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5772 - val_loss: 1.0688\n",
            "Epoch 1275/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5773 - val_loss: 1.0699\n",
            "Epoch 1276/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5772 - val_loss: 1.0689\n",
            "Epoch 1277/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5771 - val_loss: 1.0690\n",
            "Epoch 1278/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5769 - val_loss: 1.0684\n",
            "Epoch 1279/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5770 - val_loss: 1.0693\n",
            "Epoch 1280/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5769 - val_loss: 1.0687\n",
            "Epoch 1281/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5769 - val_loss: 1.0678\n",
            "Epoch 1282/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5769 - val_loss: 1.0680\n",
            "Epoch 1283/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5767 - val_loss: 1.0692\n",
            "Epoch 1284/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5768 - val_loss: 1.0694\n",
            "Epoch 1285/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5765 - val_loss: 1.0693\n",
            "Epoch 1286/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5764 - val_loss: 1.0687\n",
            "Epoch 1287/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5763 - val_loss: 1.0682\n",
            "Epoch 1288/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5763 - val_loss: 1.0691\n",
            "Epoch 1289/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5766 - val_loss: 1.0709\n",
            "Epoch 1290/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5769 - val_loss: 1.0673\n",
            "Epoch 1291/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5765 - val_loss: 1.0691\n",
            "Epoch 1292/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5761 - val_loss: 1.0688\n",
            "Epoch 1293/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5763 - val_loss: 1.0699\n",
            "Epoch 1294/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5761 - val_loss: 1.0696\n",
            "Epoch 1295/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5760 - val_loss: 1.0693\n",
            "Epoch 1296/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5758 - val_loss: 1.0692\n",
            "Epoch 1297/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5758 - val_loss: 1.0693\n",
            "Epoch 1298/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5757 - val_loss: 1.0683\n",
            "Epoch 1299/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5757 - val_loss: 1.0676\n",
            "Epoch 1300/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5756 - val_loss: 1.0686\n",
            "Epoch 1301/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5755 - val_loss: 1.0693\n",
            "Epoch 1302/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5755 - val_loss: 1.0683\n",
            "Epoch 1303/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5756 - val_loss: 1.0679\n",
            "Epoch 1304/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5754 - val_loss: 1.0694\n",
            "Epoch 1305/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5755 - val_loss: 1.0682\n",
            "Epoch 1306/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5759 - val_loss: 1.0712\n",
            "Epoch 1307/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5752 - val_loss: 1.0690\n",
            "Epoch 1308/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5752 - val_loss: 1.0701\n",
            "Epoch 1309/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5750 - val_loss: 1.0684\n",
            "Epoch 1310/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5750 - val_loss: 1.0687\n",
            "Epoch 1311/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5749 - val_loss: 1.0690\n",
            "Epoch 1312/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5750 - val_loss: 1.0678\n",
            "Epoch 1313/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5748 - val_loss: 1.0693\n",
            "Epoch 1314/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5747 - val_loss: 1.0694\n",
            "Epoch 1315/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5747 - val_loss: 1.0681\n",
            "Epoch 1316/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5745 - val_loss: 1.0691\n",
            "Epoch 1317/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5744 - val_loss: 1.0694\n",
            "Epoch 1318/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5745 - val_loss: 1.0699\n",
            "Epoch 1319/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5746 - val_loss: 1.0678\n",
            "Epoch 1320/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5744 - val_loss: 1.0677\n",
            "Epoch 1321/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5745 - val_loss: 1.0673\n",
            "Epoch 1322/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5742 - val_loss: 1.0686\n",
            "Epoch 1323/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5742 - val_loss: 1.0704\n",
            "Epoch 1324/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5741 - val_loss: 1.0690\n",
            "Epoch 1325/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5740 - val_loss: 1.0699\n",
            "Epoch 1326/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5739 - val_loss: 1.0689\n",
            "Epoch 1327/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5738 - val_loss: 1.0692\n",
            "Epoch 1328/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5738 - val_loss: 1.0694\n",
            "Epoch 1329/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5738 - val_loss: 1.0685\n",
            "Epoch 1330/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5737 - val_loss: 1.0697\n",
            "Epoch 1331/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5736 - val_loss: 1.0693\n",
            "Epoch 1332/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5738 - val_loss: 1.0709\n",
            "Epoch 1333/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5737 - val_loss: 1.0684\n",
            "Epoch 1334/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5734 - val_loss: 1.0682\n",
            "Epoch 1335/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5734 - val_loss: 1.0686\n",
            "Epoch 1336/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5732 - val_loss: 1.0689\n",
            "Epoch 1337/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5733 - val_loss: 1.0702\n",
            "Epoch 1338/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5731 - val_loss: 1.0700\n",
            "Epoch 1339/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5733 - val_loss: 1.0681\n",
            "Epoch 1340/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5730 - val_loss: 1.0683\n",
            "Epoch 1341/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5731 - val_loss: 1.0700\n",
            "Epoch 1342/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5730 - val_loss: 1.0690\n",
            "Epoch 1343/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5729 - val_loss: 1.0705\n",
            "Epoch 1344/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5729 - val_loss: 1.0706\n",
            "Epoch 1345/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5727 - val_loss: 1.0694\n",
            "Epoch 1346/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5727 - val_loss: 1.0689\n",
            "Epoch 1347/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5728 - val_loss: 1.0707\n",
            "Epoch 1348/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5725 - val_loss: 1.0694\n",
            "Epoch 1349/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5724 - val_loss: 1.0696\n",
            "Epoch 1350/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5724 - val_loss: 1.0699\n",
            "Epoch 1351/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5723 - val_loss: 1.0697\n",
            "Epoch 1352/5000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.4809Restoring model weights from the end of the best epoch: 352.\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5722 - val_loss: 1.0694\n",
            "Epoch 1352: early stopping\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 18ms/step - loss: 0.6325\n",
            "EXPECTED:\n",
            "   d18O_cel_mean  d18O_cel_variance\n",
            "0      25.882000           0.233670\n",
            "1      25.654000           0.334480\n",
            "2      27.207456           1.041823\n",
            "3      25.163333           0.807832\n",
            "4      24.030630           0.579233\n",
            "5      26.040923           0.222859\n",
            "\n",
            "PREDICTED:\n",
            "   d18O_cel_mean  d18O_cel_variance\n",
            "0      25.346333           2.055920\n",
            "1      25.345732           2.054462\n",
            "2      25.347898           2.055023\n",
            "3      25.324146           2.034373\n",
            "4      25.324146           2.034373\n",
            "5      25.325953           2.035972\n",
            "RMSE: 1.0041704069426893\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2023-07-18 16:02:01.025285: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype double and shape [6,12]\n",
            "\t [[{{node Placeholder/_0}}]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4) Grouped, fixed"
      ],
      "metadata": {
        "id": "opmE3xc0vcY0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "grouped_fixed = {\n",
        "    'TRAIN': os.path.join(FP_ROOT, \"amazon_sample_data/uc_davis_2023_08_12_train_fixed_grouped.csv\"),\n",
        "    'TEST': os.path.join(FP_ROOT, \"amazon_sample_data/uc_davis_2023_08_12_test_fixed_grouped.csv\"),\n",
        "    'VALIDATION': os.path.join(FP_ROOT, \"amazon_sample_data/uc_davis_2023_08_12_validation_fixed_grouped.csv\"),\n",
        "}\n",
        "\n",
        "grouped_fixed_scaled = load_and_scale(grouped_fixed)\n",
        "train_and_evaluate(grouped_fixed_scaled, \"grouped_fixed\", training_batch_size=3)"
      ],
      "metadata": {
        "id": "KCebsA7XvfRH",
        "outputId": "169586dd-d271-43e8-875c-62082cb08c81",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================\n",
            "grouped_fixed\n",
            "Model: \"model_10\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_11 (InputLayer)          [(None, 12)]         0           []                               \n",
            "                                                                                                  \n",
            " dense_20 (Dense)               (None, 20)           260         ['input_11[0][0]']               \n",
            "                                                                                                  \n",
            " dense_21 (Dense)               (None, 20)           420         ['dense_20[0][0]']               \n",
            "                                                                                                  \n",
            " var_output (Dense)             (None, 1)            21          ['dense_21[0][0]']               \n",
            "                                                                                                  \n",
            " mean_output (Dense)            (None, 1)            21          ['dense_21[0][0]']               \n",
            "                                                                                                  \n",
            " tf.math.multiply_21 (TFOpLambd  (None, 1)           0           ['var_output[0][0]']             \n",
            " a)                                                                                               \n",
            "                                                                                                  \n",
            " tf.math.multiply_20 (TFOpLambd  (None, 1)           0           ['mean_output[0][0]']            \n",
            " a)                                                                                               \n",
            "                                                                                                  \n",
            " tf.__operators__.add_21 (TFOpL  (None, 1)           0           ['tf.math.multiply_21[0][0]']    \n",
            " ambda)                                                                                           \n",
            "                                                                                                  \n",
            " tf.__operators__.add_20 (TFOpL  (None, 1)           0           ['tf.math.multiply_20[0][0]']    \n",
            " ambda)                                                                                           \n",
            "                                                                                                  \n",
            " lambda_10 (Lambda)             (None, 1)            0           ['tf.__operators__.add_21[0][0]']\n",
            "                                                                                                  \n",
            " concatenate_10 (Concatenate)   (None, 2)            0           ['tf.__operators__.add_20[0][0]',\n",
            "                                                                  'lambda_10[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 722\n",
            "Trainable params: 722\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/5000\n",
            "10/10 [==============================] - 1s 16ms/step - loss: 1.2747 - val_loss: 1.3836\n",
            "Epoch 2/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.2494 - val_loss: 1.3603\n",
            "Epoch 3/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.2286 - val_loss: 1.3398\n",
            "Epoch 4/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.2080 - val_loss: 1.3211\n",
            "Epoch 5/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.1896 - val_loss: 1.3058\n",
            "Epoch 6/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.1722 - val_loss: 1.2905\n",
            "Epoch 7/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.1560 - val_loss: 1.2776\n",
            "Epoch 8/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.1421 - val_loss: 1.2626\n",
            "Epoch 9/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.1278 - val_loss: 1.2483\n",
            "Epoch 10/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.1154 - val_loss: 1.2346\n",
            "Epoch 11/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.1022 - val_loss: 1.2236\n",
            "Epoch 12/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.0922 - val_loss: 1.2148\n",
            "Epoch 13/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.0820 - val_loss: 1.2071\n",
            "Epoch 14/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.0715 - val_loss: 1.2014\n",
            "Epoch 15/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.0625 - val_loss: 1.1922\n",
            "Epoch 16/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.0515 - val_loss: 1.1826\n",
            "Epoch 17/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.0380 - val_loss: 1.1735\n",
            "Epoch 18/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.0244 - val_loss: 1.1624\n",
            "Epoch 19/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.0099 - val_loss: 1.1534\n",
            "Epoch 20/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.9984 - val_loss: 1.1448\n",
            "Epoch 21/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.9868 - val_loss: 1.1383\n",
            "Epoch 22/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.9768 - val_loss: 1.1323\n",
            "Epoch 23/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.9688 - val_loss: 1.1268\n",
            "Epoch 24/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.9595 - val_loss: 1.1220\n",
            "Epoch 25/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.9529 - val_loss: 1.1154\n",
            "Epoch 26/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.9454 - val_loss: 1.1106\n",
            "Epoch 27/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.9399 - val_loss: 1.1067\n",
            "Epoch 28/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.9321 - val_loss: 1.1029\n",
            "Epoch 29/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.9259 - val_loss: 1.0979\n",
            "Epoch 30/5000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.9205 - val_loss: 1.0930\n",
            "Epoch 31/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.9154 - val_loss: 1.0883\n",
            "Epoch 32/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.9091 - val_loss: 1.0840\n",
            "Epoch 33/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.9036 - val_loss: 1.0802\n",
            "Epoch 34/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.8997 - val_loss: 1.0771\n",
            "Epoch 35/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.8940 - val_loss: 1.0739\n",
            "Epoch 36/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.8896 - val_loss: 1.0696\n",
            "Epoch 37/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.8849 - val_loss: 1.0663\n",
            "Epoch 38/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.8807 - val_loss: 1.0638\n",
            "Epoch 39/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.8764 - val_loss: 1.0597\n",
            "Epoch 40/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.8725 - val_loss: 1.0566\n",
            "Epoch 41/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.8685 - val_loss: 1.0522\n",
            "Epoch 42/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.8651 - val_loss: 1.0496\n",
            "Epoch 43/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8609 - val_loss: 1.0459\n",
            "Epoch 44/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.8571 - val_loss: 1.0432\n",
            "Epoch 45/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.8539 - val_loss: 1.0416\n",
            "Epoch 46/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.8504 - val_loss: 1.0382\n",
            "Epoch 47/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.8472 - val_loss: 1.0343\n",
            "Epoch 48/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.8439 - val_loss: 1.0314\n",
            "Epoch 49/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.8407 - val_loss: 1.0287\n",
            "Epoch 50/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.8380 - val_loss: 1.0259\n",
            "Epoch 51/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.8352 - val_loss: 1.0240\n",
            "Epoch 52/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.8320 - val_loss: 1.0202\n",
            "Epoch 53/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8295 - val_loss: 1.0180\n",
            "Epoch 54/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8267 - val_loss: 1.0150\n",
            "Epoch 55/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.8241 - val_loss: 1.0133\n",
            "Epoch 56/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8216 - val_loss: 1.0101\n",
            "Epoch 57/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8194 - val_loss: 1.0054\n",
            "Epoch 58/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8163 - val_loss: 1.0040\n",
            "Epoch 59/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.8145 - val_loss: 1.0015\n",
            "Epoch 60/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.8119 - val_loss: 0.9976\n",
            "Epoch 61/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.8095 - val_loss: 0.9945\n",
            "Epoch 62/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.8071 - val_loss: 0.9930\n",
            "Epoch 63/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.8050 - val_loss: 0.9907\n",
            "Epoch 64/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.8031 - val_loss: 0.9881\n",
            "Epoch 65/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.8006 - val_loss: 0.9858\n",
            "Epoch 66/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.7988 - val_loss: 0.9847\n",
            "Epoch 67/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.7966 - val_loss: 0.9810\n",
            "Epoch 68/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.7947 - val_loss: 0.9769\n",
            "Epoch 69/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.7926 - val_loss: 0.9740\n",
            "Epoch 70/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.7909 - val_loss: 0.9711\n",
            "Epoch 71/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.7890 - val_loss: 0.9698\n",
            "Epoch 72/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.7870 - val_loss: 0.9677\n",
            "Epoch 73/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.7850 - val_loss: 0.9653\n",
            "Epoch 74/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.7839 - val_loss: 0.9613\n",
            "Epoch 75/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.7820 - val_loss: 0.9601\n",
            "Epoch 76/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.7799 - val_loss: 0.9585\n",
            "Epoch 77/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.7782 - val_loss: 0.9555\n",
            "Epoch 78/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.7769 - val_loss: 0.9526\n",
            "Epoch 79/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.7754 - val_loss: 0.9515\n",
            "Epoch 80/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.7734 - val_loss: 0.9481\n",
            "Epoch 81/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.7718 - val_loss: 0.9459\n",
            "Epoch 82/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.7700 - val_loss: 0.9436\n",
            "Epoch 83/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.7688 - val_loss: 0.9416\n",
            "Epoch 84/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.7672 - val_loss: 0.9387\n",
            "Epoch 85/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.7657 - val_loss: 0.9363\n",
            "Epoch 86/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.7639 - val_loss: 0.9342\n",
            "Epoch 87/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.7630 - val_loss: 0.9329\n",
            "Epoch 88/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.7614 - val_loss: 0.9313\n",
            "Epoch 89/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.7598 - val_loss: 0.9282\n",
            "Epoch 90/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.7587 - val_loss: 0.9248\n",
            "Epoch 91/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.7570 - val_loss: 0.9230\n",
            "Epoch 92/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.7558 - val_loss: 0.9218\n",
            "Epoch 93/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.7544 - val_loss: 0.9191\n",
            "Epoch 94/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.7532 - val_loss: 0.9191\n",
            "Epoch 95/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.7519 - val_loss: 0.9165\n",
            "Epoch 96/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.7505 - val_loss: 0.9142\n",
            "Epoch 97/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.7495 - val_loss: 0.9117\n",
            "Epoch 98/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.7482 - val_loss: 0.9108\n",
            "Epoch 99/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.7470 - val_loss: 0.9090\n",
            "Epoch 100/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.7459 - val_loss: 0.9074\n",
            "Epoch 101/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.7449 - val_loss: 0.9058\n",
            "Epoch 102/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.7438 - val_loss: 0.9037\n",
            "Epoch 103/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.7426 - val_loss: 0.9017\n",
            "Epoch 104/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.7415 - val_loss: 0.9004\n",
            "Epoch 105/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.7405 - val_loss: 0.8992\n",
            "Epoch 106/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.7394 - val_loss: 0.8982\n",
            "Epoch 107/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.7386 - val_loss: 0.8968\n",
            "Epoch 108/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.7374 - val_loss: 0.8948\n",
            "Epoch 109/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.7366 - val_loss: 0.8927\n",
            "Epoch 110/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.7355 - val_loss: 0.8919\n",
            "Epoch 111/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.7345 - val_loss: 0.8900\n",
            "Epoch 112/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.7337 - val_loss: 0.8876\n",
            "Epoch 113/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.7327 - val_loss: 0.8865\n",
            "Epoch 114/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.7317 - val_loss: 0.8847\n",
            "Epoch 115/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.7310 - val_loss: 0.8842\n",
            "Epoch 116/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.7301 - val_loss: 0.8827\n",
            "Epoch 117/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.7290 - val_loss: 0.8804\n",
            "Epoch 118/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.7283 - val_loss: 0.8795\n",
            "Epoch 119/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.7274 - val_loss: 0.8772\n",
            "Epoch 120/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.7265 - val_loss: 0.8757\n",
            "Epoch 121/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.7257 - val_loss: 0.8746\n",
            "Epoch 122/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.7249 - val_loss: 0.8723\n",
            "Epoch 123/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.7244 - val_loss: 0.8698\n",
            "Epoch 124/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.7232 - val_loss: 0.8686\n",
            "Epoch 125/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.7225 - val_loss: 0.8675\n",
            "Epoch 126/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.7218 - val_loss: 0.8662\n",
            "Epoch 127/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.7208 - val_loss: 0.8645\n",
            "Epoch 128/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.7202 - val_loss: 0.8624\n",
            "Epoch 129/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.7194 - val_loss: 0.8616\n",
            "Epoch 130/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.7186 - val_loss: 0.8599\n",
            "Epoch 131/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.7179 - val_loss: 0.8590\n",
            "Epoch 132/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.7173 - val_loss: 0.8568\n",
            "Epoch 133/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.7164 - val_loss: 0.8561\n",
            "Epoch 134/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.7157 - val_loss: 0.8544\n",
            "Epoch 135/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.7149 - val_loss: 0.8530\n",
            "Epoch 136/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.7141 - val_loss: 0.8514\n",
            "Epoch 137/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.7134 - val_loss: 0.8497\n",
            "Epoch 138/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.7127 - val_loss: 0.8477\n",
            "Epoch 139/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.7125 - val_loss: 0.8475\n",
            "Epoch 140/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.7113 - val_loss: 0.8452\n",
            "Epoch 141/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.7107 - val_loss: 0.8440\n",
            "Epoch 142/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.7099 - val_loss: 0.8428\n",
            "Epoch 143/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.7095 - val_loss: 0.8393\n",
            "Epoch 144/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.7086 - val_loss: 0.8374\n",
            "Epoch 145/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.7079 - val_loss: 0.8369\n",
            "Epoch 146/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.7072 - val_loss: 0.8359\n",
            "Epoch 147/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.7065 - val_loss: 0.8347\n",
            "Epoch 148/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.7061 - val_loss: 0.8321\n",
            "Epoch 149/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.7054 - val_loss: 0.8305\n",
            "Epoch 150/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.7047 - val_loss: 0.8293\n",
            "Epoch 151/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.7041 - val_loss: 0.8282\n",
            "Epoch 152/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.7034 - val_loss: 0.8268\n",
            "Epoch 153/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.7028 - val_loss: 0.8261\n",
            "Epoch 154/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.7025 - val_loss: 0.8250\n",
            "Epoch 155/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.7017 - val_loss: 0.8238\n",
            "Epoch 156/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.7013 - val_loss: 0.8214\n",
            "Epoch 157/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.7006 - val_loss: 0.8206\n",
            "Epoch 158/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.7001 - val_loss: 0.8184\n",
            "Epoch 159/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6996 - val_loss: 0.8182\n",
            "Epoch 160/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6990 - val_loss: 0.8166\n",
            "Epoch 161/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.6986 - val_loss: 0.8145\n",
            "Epoch 162/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6980 - val_loss: 0.8138\n",
            "Epoch 163/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6976 - val_loss: 0.8134\n",
            "Epoch 164/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6970 - val_loss: 0.8125\n",
            "Epoch 165/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6967 - val_loss: 0.8111\n",
            "Epoch 166/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6963 - val_loss: 0.8087\n",
            "Epoch 167/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.6956 - val_loss: 0.8083\n",
            "Epoch 168/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6951 - val_loss: 0.8070\n",
            "Epoch 169/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6948 - val_loss: 0.8065\n",
            "Epoch 170/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.6943 - val_loss: 0.8055\n",
            "Epoch 171/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6938 - val_loss: 0.8039\n",
            "Epoch 172/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6933 - val_loss: 0.8028\n",
            "Epoch 173/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6930 - val_loss: 0.8019\n",
            "Epoch 174/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6925 - val_loss: 0.8008\n",
            "Epoch 175/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6922 - val_loss: 0.7988\n",
            "Epoch 176/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6916 - val_loss: 0.7972\n",
            "Epoch 177/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6912 - val_loss: 0.7971\n",
            "Epoch 178/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6907 - val_loss: 0.7957\n",
            "Epoch 179/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6903 - val_loss: 0.7944\n",
            "Epoch 180/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6898 - val_loss: 0.7933\n",
            "Epoch 181/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6895 - val_loss: 0.7918\n",
            "Epoch 182/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6890 - val_loss: 0.7906\n",
            "Epoch 183/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6886 - val_loss: 0.7897\n",
            "Epoch 184/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6882 - val_loss: 0.7890\n",
            "Epoch 185/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6879 - val_loss: 0.7878\n",
            "Epoch 186/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.6875 - val_loss: 0.7867\n",
            "Epoch 187/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6871 - val_loss: 0.7858\n",
            "Epoch 188/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6868 - val_loss: 0.7845\n",
            "Epoch 189/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6864 - val_loss: 0.7840\n",
            "Epoch 190/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6860 - val_loss: 0.7828\n",
            "Epoch 191/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6859 - val_loss: 0.7806\n",
            "Epoch 192/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6853 - val_loss: 0.7792\n",
            "Epoch 193/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6851 - val_loss: 0.7800\n",
            "Epoch 194/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6845 - val_loss: 0.7794\n",
            "Epoch 195/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6842 - val_loss: 0.7776\n",
            "Epoch 196/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.6837 - val_loss: 0.7760\n",
            "Epoch 197/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6836 - val_loss: 0.7741\n",
            "Epoch 198/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6832 - val_loss: 0.7728\n",
            "Epoch 199/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6828 - val_loss: 0.7730\n",
            "Epoch 200/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6823 - val_loss: 0.7715\n",
            "Epoch 201/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6821 - val_loss: 0.7703\n",
            "Epoch 202/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6818 - val_loss: 0.7695\n",
            "Epoch 203/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6815 - val_loss: 0.7679\n",
            "Epoch 204/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6812 - val_loss: 0.7664\n",
            "Epoch 205/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6809 - val_loss: 0.7652\n",
            "Epoch 206/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6805 - val_loss: 0.7652\n",
            "Epoch 207/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6802 - val_loss: 0.7633\n",
            "Epoch 208/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6798 - val_loss: 0.7626\n",
            "Epoch 209/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.6794 - val_loss: 0.7611\n",
            "Epoch 210/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.6793 - val_loss: 0.7594\n",
            "Epoch 211/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.6788 - val_loss: 0.7586\n",
            "Epoch 212/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.6787 - val_loss: 0.7577\n",
            "Epoch 213/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.6782 - val_loss: 0.7567\n",
            "Epoch 214/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6780 - val_loss: 0.7566\n",
            "Epoch 215/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.6778 - val_loss: 0.7541\n",
            "Epoch 216/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.6773 - val_loss: 0.7532\n",
            "Epoch 217/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.6771 - val_loss: 0.7531\n",
            "Epoch 218/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.6768 - val_loss: 0.7521\n",
            "Epoch 219/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6764 - val_loss: 0.7516\n",
            "Epoch 220/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6763 - val_loss: 0.7508\n",
            "Epoch 221/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6762 - val_loss: 0.7510\n",
            "Epoch 222/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.6757 - val_loss: 0.7495\n",
            "Epoch 223/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.6756 - val_loss: 0.7477\n",
            "Epoch 224/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.6752 - val_loss: 0.7476\n",
            "Epoch 225/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6749 - val_loss: 0.7468\n",
            "Epoch 226/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.6747 - val_loss: 0.7462\n",
            "Epoch 227/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.6744 - val_loss: 0.7449\n",
            "Epoch 228/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.6741 - val_loss: 0.7445\n",
            "Epoch 229/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.6740 - val_loss: 0.7441\n",
            "Epoch 230/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.6738 - val_loss: 0.7426\n",
            "Epoch 231/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6734 - val_loss: 0.7431\n",
            "Epoch 232/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6732 - val_loss: 0.7421\n",
            "Epoch 233/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6731 - val_loss: 0.7409\n",
            "Epoch 234/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6727 - val_loss: 0.7401\n",
            "Epoch 235/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6725 - val_loss: 0.7399\n",
            "Epoch 236/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6722 - val_loss: 0.7388\n",
            "Epoch 237/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6720 - val_loss: 0.7377\n",
            "Epoch 238/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6719 - val_loss: 0.7364\n",
            "Epoch 239/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6715 - val_loss: 0.7364\n",
            "Epoch 240/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6715 - val_loss: 0.7366\n",
            "Epoch 241/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.6714 - val_loss: 0.7340\n",
            "Epoch 242/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6708 - val_loss: 0.7341\n",
            "Epoch 243/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6706 - val_loss: 0.7333\n",
            "Epoch 244/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.6704 - val_loss: 0.7319\n",
            "Epoch 245/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6701 - val_loss: 0.7311\n",
            "Epoch 246/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6700 - val_loss: 0.7300\n",
            "Epoch 247/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6698 - val_loss: 0.7292\n",
            "Epoch 248/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.6696 - val_loss: 0.7282\n",
            "Epoch 249/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6693 - val_loss: 0.7286\n",
            "Epoch 250/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6691 - val_loss: 0.7272\n",
            "Epoch 251/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.6690 - val_loss: 0.7264\n",
            "Epoch 252/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6688 - val_loss: 0.7267\n",
            "Epoch 253/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6685 - val_loss: 0.7258\n",
            "Epoch 254/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6684 - val_loss: 0.7260\n",
            "Epoch 255/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.6681 - val_loss: 0.7252\n",
            "Epoch 256/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6680 - val_loss: 0.7253\n",
            "Epoch 257/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.6678 - val_loss: 0.7251\n",
            "Epoch 258/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.6677 - val_loss: 0.7230\n",
            "Epoch 259/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6675 - val_loss: 0.7232\n",
            "Epoch 260/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.6671 - val_loss: 0.7225\n",
            "Epoch 261/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.6671 - val_loss: 0.7205\n",
            "Epoch 262/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6669 - val_loss: 0.7200\n",
            "Epoch 263/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6667 - val_loss: 0.7201\n",
            "Epoch 264/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.6664 - val_loss: 0.7192\n",
            "Epoch 265/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6663 - val_loss: 0.7192\n",
            "Epoch 266/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6664 - val_loss: 0.7201\n",
            "Epoch 267/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.6659 - val_loss: 0.7183\n",
            "Epoch 268/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.6660 - val_loss: 0.7167\n",
            "Epoch 269/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6656 - val_loss: 0.7170\n",
            "Epoch 270/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6654 - val_loss: 0.7166\n",
            "Epoch 271/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6653 - val_loss: 0.7167\n",
            "Epoch 272/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6651 - val_loss: 0.7154\n",
            "Epoch 273/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6649 - val_loss: 0.7149\n",
            "Epoch 274/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6649 - val_loss: 0.7137\n",
            "Epoch 275/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6647 - val_loss: 0.7138\n",
            "Epoch 276/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.6645 - val_loss: 0.7132\n",
            "Epoch 277/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6644 - val_loss: 0.7136\n",
            "Epoch 278/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6643 - val_loss: 0.7126\n",
            "Epoch 279/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6641 - val_loss: 0.7115\n",
            "Epoch 280/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6641 - val_loss: 0.7103\n",
            "Epoch 281/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6638 - val_loss: 0.7103\n",
            "Epoch 282/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6637 - val_loss: 0.7101\n",
            "Epoch 283/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.6636 - val_loss: 0.7088\n",
            "Epoch 284/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6635 - val_loss: 0.7083\n",
            "Epoch 285/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6633 - val_loss: 0.7081\n",
            "Epoch 286/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.6632 - val_loss: 0.7076\n",
            "Epoch 287/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6632 - val_loss: 0.7078\n",
            "Epoch 288/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6630 - val_loss: 0.7070\n",
            "Epoch 289/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6629 - val_loss: 0.7072\n",
            "Epoch 290/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6628 - val_loss: 0.7062\n",
            "Epoch 291/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6627 - val_loss: 0.7052\n",
            "Epoch 292/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6627 - val_loss: 0.7065\n",
            "Epoch 293/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.6624 - val_loss: 0.7050\n",
            "Epoch 294/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6623 - val_loss: 0.7038\n",
            "Epoch 295/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6622 - val_loss: 0.7038\n",
            "Epoch 296/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6622 - val_loss: 0.7038\n",
            "Epoch 297/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6620 - val_loss: 0.7019\n",
            "Epoch 298/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6618 - val_loss: 0.7013\n",
            "Epoch 299/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6616 - val_loss: 0.7008\n",
            "Epoch 300/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.6615 - val_loss: 0.7005\n",
            "Epoch 301/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6614 - val_loss: 0.7004\n",
            "Epoch 302/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.6612 - val_loss: 0.7003\n",
            "Epoch 303/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6612 - val_loss: 0.6991\n",
            "Epoch 304/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6611 - val_loss: 0.6986\n",
            "Epoch 305/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6609 - val_loss: 0.6990\n",
            "Epoch 306/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6609 - val_loss: 0.6987\n",
            "Epoch 307/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6607 - val_loss: 0.6980\n",
            "Epoch 308/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6607 - val_loss: 0.6969\n",
            "Epoch 309/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6604 - val_loss: 0.6969\n",
            "Epoch 310/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6606 - val_loss: 0.6976\n",
            "Epoch 311/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6604 - val_loss: 0.6966\n",
            "Epoch 312/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6603 - val_loss: 0.6959\n",
            "Epoch 313/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6601 - val_loss: 0.6957\n",
            "Epoch 314/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6601 - val_loss: 0.6962\n",
            "Epoch 315/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6599 - val_loss: 0.6957\n",
            "Epoch 316/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.6599 - val_loss: 0.6946\n",
            "Epoch 317/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6599 - val_loss: 0.6951\n",
            "Epoch 318/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6597 - val_loss: 0.6948\n",
            "Epoch 319/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6597 - val_loss: 0.6945\n",
            "Epoch 320/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6597 - val_loss: 0.6934\n",
            "Epoch 321/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6595 - val_loss: 0.6938\n",
            "Epoch 322/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6593 - val_loss: 0.6932\n",
            "Epoch 323/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6593 - val_loss: 0.6928\n",
            "Epoch 324/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6592 - val_loss: 0.6920\n",
            "Epoch 325/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6592 - val_loss: 0.6920\n",
            "Epoch 326/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6590 - val_loss: 0.6909\n",
            "Epoch 327/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.6590 - val_loss: 0.6897\n",
            "Epoch 328/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6589 - val_loss: 0.6893\n",
            "Epoch 329/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6587 - val_loss: 0.6892\n",
            "Epoch 330/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6588 - val_loss: 0.6874\n",
            "Epoch 331/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6587 - val_loss: 0.6865\n",
            "Epoch 332/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6585 - val_loss: 0.6867\n",
            "Epoch 333/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6586 - val_loss: 0.6870\n",
            "Epoch 334/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6585 - val_loss: 0.6874\n",
            "Epoch 335/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6583 - val_loss: 0.6866\n",
            "Epoch 336/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6584 - val_loss: 0.6864\n",
            "Epoch 337/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6583 - val_loss: 0.6858\n",
            "Epoch 338/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6582 - val_loss: 0.6852\n",
            "Epoch 339/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6581 - val_loss: 0.6858\n",
            "Epoch 340/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6581 - val_loss: 0.6857\n",
            "Epoch 341/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6581 - val_loss: 0.6856\n",
            "Epoch 342/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6579 - val_loss: 0.6853\n",
            "Epoch 343/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6578 - val_loss: 0.6836\n",
            "Epoch 344/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6577 - val_loss: 0.6827\n",
            "Epoch 345/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6577 - val_loss: 0.6823\n",
            "Epoch 346/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6576 - val_loss: 0.6815\n",
            "Epoch 347/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6576 - val_loss: 0.6816\n",
            "Epoch 348/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6575 - val_loss: 0.6805\n",
            "Epoch 349/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6574 - val_loss: 0.6804\n",
            "Epoch 350/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6574 - val_loss: 0.6809\n",
            "Epoch 351/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6574 - val_loss: 0.6811\n",
            "Epoch 352/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6572 - val_loss: 0.6799\n",
            "Epoch 353/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6572 - val_loss: 0.6800\n",
            "Epoch 354/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.6573 - val_loss: 0.6783\n",
            "Epoch 355/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6572 - val_loss: 0.6781\n",
            "Epoch 356/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6570 - val_loss: 0.6776\n",
            "Epoch 357/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6569 - val_loss: 0.6778\n",
            "Epoch 358/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6570 - val_loss: 0.6786\n",
            "Epoch 359/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6569 - val_loss: 0.6777\n",
            "Epoch 360/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6569 - val_loss: 0.6771\n",
            "Epoch 361/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6568 - val_loss: 0.6773\n",
            "Epoch 362/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6567 - val_loss: 0.6778\n",
            "Epoch 363/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6568 - val_loss: 0.6783\n",
            "Epoch 364/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6567 - val_loss: 0.6774\n",
            "Epoch 365/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6566 - val_loss: 0.6769\n",
            "Epoch 366/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6566 - val_loss: 0.6780\n",
            "Epoch 367/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6564 - val_loss: 0.6775\n",
            "Epoch 368/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6564 - val_loss: 0.6768\n",
            "Epoch 369/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6564 - val_loss: 0.6765\n",
            "Epoch 370/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6564 - val_loss: 0.6761\n",
            "Epoch 371/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6563 - val_loss: 0.6761\n",
            "Epoch 372/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6566 - val_loss: 0.6747\n",
            "Epoch 373/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6563 - val_loss: 0.6751\n",
            "Epoch 374/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6563 - val_loss: 0.6753\n",
            "Epoch 375/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6563 - val_loss: 0.6740\n",
            "Epoch 376/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6560 - val_loss: 0.6733\n",
            "Epoch 377/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6561 - val_loss: 0.6735\n",
            "Epoch 378/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6560 - val_loss: 0.6720\n",
            "Epoch 379/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6559 - val_loss: 0.6715\n",
            "Epoch 380/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6561 - val_loss: 0.6724\n",
            "Epoch 381/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6558 - val_loss: 0.6723\n",
            "Epoch 382/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6559 - val_loss: 0.6723\n",
            "Epoch 383/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.6559 - val_loss: 0.6715\n",
            "Epoch 384/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6558 - val_loss: 0.6719\n",
            "Epoch 385/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6557 - val_loss: 0.6715\n",
            "Epoch 386/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6557 - val_loss: 0.6714\n",
            "Epoch 387/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6557 - val_loss: 0.6716\n",
            "Epoch 388/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6557 - val_loss: 0.6718\n",
            "Epoch 389/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6556 - val_loss: 0.6710\n",
            "Epoch 390/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6557 - val_loss: 0.6716\n",
            "Epoch 391/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6555 - val_loss: 0.6708\n",
            "Epoch 392/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6555 - val_loss: 0.6704\n",
            "Epoch 393/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6554 - val_loss: 0.6703\n",
            "Epoch 394/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6556 - val_loss: 0.6695\n",
            "Epoch 395/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6554 - val_loss: 0.6694\n",
            "Epoch 396/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6553 - val_loss: 0.6698\n",
            "Epoch 397/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.6553 - val_loss: 0.6687\n",
            "Epoch 398/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6553 - val_loss: 0.6689\n",
            "Epoch 399/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6553 - val_loss: 0.6682\n",
            "Epoch 400/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6552 - val_loss: 0.6686\n",
            "Epoch 401/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6552 - val_loss: 0.6683\n",
            "Epoch 402/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6552 - val_loss: 0.6678\n",
            "Epoch 403/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6551 - val_loss: 0.6677\n",
            "Epoch 404/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6552 - val_loss: 0.6684\n",
            "Epoch 405/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6551 - val_loss: 0.6678\n",
            "Epoch 406/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6551 - val_loss: 0.6681\n",
            "Epoch 407/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6550 - val_loss: 0.6674\n",
            "Epoch 408/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6550 - val_loss: 0.6669\n",
            "Epoch 409/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6551 - val_loss: 0.6682\n",
            "Epoch 410/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6549 - val_loss: 0.6681\n",
            "Epoch 411/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6549 - val_loss: 0.6678\n",
            "Epoch 412/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6548 - val_loss: 0.6675\n",
            "Epoch 413/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6550 - val_loss: 0.6659\n",
            "Epoch 414/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6549 - val_loss: 0.6653\n",
            "Epoch 415/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6547 - val_loss: 0.6656\n",
            "Epoch 416/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6547 - val_loss: 0.6657\n",
            "Epoch 417/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6548 - val_loss: 0.6668\n",
            "Epoch 418/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6547 - val_loss: 0.6658\n",
            "Epoch 419/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6547 - val_loss: 0.6655\n",
            "Epoch 420/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6546 - val_loss: 0.6647\n",
            "Epoch 421/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6547 - val_loss: 0.6639\n",
            "Epoch 422/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6546 - val_loss: 0.6640\n",
            "Epoch 423/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6546 - val_loss: 0.6643\n",
            "Epoch 424/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6545 - val_loss: 0.6648\n",
            "Epoch 425/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6546 - val_loss: 0.6650\n",
            "Epoch 426/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6546 - val_loss: 0.6639\n",
            "Epoch 427/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6544 - val_loss: 0.6643\n",
            "Epoch 428/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6544 - val_loss: 0.6644\n",
            "Epoch 429/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6544 - val_loss: 0.6646\n",
            "Epoch 430/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6544 - val_loss: 0.6641\n",
            "Epoch 431/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6544 - val_loss: 0.6634\n",
            "Epoch 432/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6544 - val_loss: 0.6637\n",
            "Epoch 433/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6544 - val_loss: 0.6641\n",
            "Epoch 434/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6543 - val_loss: 0.6637\n",
            "Epoch 435/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6543 - val_loss: 0.6634\n",
            "Epoch 436/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6543 - val_loss: 0.6643\n",
            "Epoch 437/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6543 - val_loss: 0.6648\n",
            "Epoch 438/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6542 - val_loss: 0.6643\n",
            "Epoch 439/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6543 - val_loss: 0.6651\n",
            "Epoch 440/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6542 - val_loss: 0.6639\n",
            "Epoch 441/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6542 - val_loss: 0.6628\n",
            "Epoch 442/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6541 - val_loss: 0.6626\n",
            "Epoch 443/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6541 - val_loss: 0.6628\n",
            "Epoch 444/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6541 - val_loss: 0.6625\n",
            "Epoch 445/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6541 - val_loss: 0.6625\n",
            "Epoch 446/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6541 - val_loss: 0.6630\n",
            "Epoch 447/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6541 - val_loss: 0.6634\n",
            "Epoch 448/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6543 - val_loss: 0.6616\n",
            "Epoch 449/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6540 - val_loss: 0.6613\n",
            "Epoch 450/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6540 - val_loss: 0.6618\n",
            "Epoch 451/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6541 - val_loss: 0.6626\n",
            "Epoch 452/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.6542 - val_loss: 0.6612\n",
            "Epoch 453/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6541 - val_loss: 0.6620\n",
            "Epoch 454/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.6539 - val_loss: 0.6610\n",
            "Epoch 455/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.6539 - val_loss: 0.6606\n",
            "Epoch 456/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6539 - val_loss: 0.6607\n",
            "Epoch 457/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6539 - val_loss: 0.6602\n",
            "Epoch 458/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6538 - val_loss: 0.6604\n",
            "Epoch 459/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6539 - val_loss: 0.6601\n",
            "Epoch 460/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6541 - val_loss: 0.6614\n",
            "Epoch 461/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6538 - val_loss: 0.6613\n",
            "Epoch 462/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6538 - val_loss: 0.6603\n",
            "Epoch 463/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6538 - val_loss: 0.6601\n",
            "Epoch 464/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6538 - val_loss: 0.6607\n",
            "Epoch 465/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6538 - val_loss: 0.6605\n",
            "Epoch 466/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6538 - val_loss: 0.6608\n",
            "Epoch 467/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6537 - val_loss: 0.6605\n",
            "Epoch 468/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.6538 - val_loss: 0.6598\n",
            "Epoch 469/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6537 - val_loss: 0.6597\n",
            "Epoch 470/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6537 - val_loss: 0.6603\n",
            "Epoch 471/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6537 - val_loss: 0.6598\n",
            "Epoch 472/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6537 - val_loss: 0.6602\n",
            "Epoch 473/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6537 - val_loss: 0.6600\n",
            "Epoch 474/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6540 - val_loss: 0.6613\n",
            "Epoch 475/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6538 - val_loss: 0.6604\n",
            "Epoch 476/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6537 - val_loss: 0.6602\n",
            "Epoch 477/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6536 - val_loss: 0.6606\n",
            "Epoch 478/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6537 - val_loss: 0.6613\n",
            "Epoch 479/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6536 - val_loss: 0.6610\n",
            "Epoch 480/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6537 - val_loss: 0.6603\n",
            "Epoch 481/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6537 - val_loss: 0.6597\n",
            "Epoch 482/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6538 - val_loss: 0.6606\n",
            "Epoch 483/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6536 - val_loss: 0.6607\n",
            "Epoch 484/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6536 - val_loss: 0.6595\n",
            "Epoch 485/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6536 - val_loss: 0.6598\n",
            "Epoch 486/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.6537 - val_loss: 0.6586\n",
            "Epoch 487/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6535 - val_loss: 0.6588\n",
            "Epoch 488/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6535 - val_loss: 0.6588\n",
            "Epoch 489/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6537 - val_loss: 0.6581\n",
            "Epoch 490/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6536 - val_loss: 0.6576\n",
            "Epoch 491/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6536 - val_loss: 0.6574\n",
            "Epoch 492/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6535 - val_loss: 0.6578\n",
            "Epoch 493/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6535 - val_loss: 0.6581\n",
            "Epoch 494/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6535 - val_loss: 0.6581\n",
            "Epoch 495/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6536 - val_loss: 0.6574\n",
            "Epoch 496/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6535 - val_loss: 0.6577\n",
            "Epoch 497/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6535 - val_loss: 0.6574\n",
            "Epoch 498/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6535 - val_loss: 0.6571\n",
            "Epoch 499/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6535 - val_loss: 0.6578\n",
            "Epoch 500/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6535 - val_loss: 0.6580\n",
            "Epoch 501/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6535 - val_loss: 0.6582\n",
            "Epoch 502/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6535 - val_loss: 0.6581\n",
            "Epoch 503/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6535 - val_loss: 0.6580\n",
            "Epoch 504/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.6536 - val_loss: 0.6562\n",
            "Epoch 505/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6535 - val_loss: 0.6559\n",
            "Epoch 506/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6537 - val_loss: 0.6572\n",
            "Epoch 507/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6535 - val_loss: 0.6563\n",
            "Epoch 508/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6538 - val_loss: 0.6552\n",
            "Epoch 509/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6534 - val_loss: 0.6558\n",
            "Epoch 510/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6534 - val_loss: 0.6562\n",
            "Epoch 511/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6534 - val_loss: 0.6571\n",
            "Epoch 512/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6534 - val_loss: 0.6567\n",
            "Epoch 513/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6534 - val_loss: 0.6571\n",
            "Epoch 514/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6534 - val_loss: 0.6574\n",
            "Epoch 515/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6534 - val_loss: 0.6560\n",
            "Epoch 516/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6534 - val_loss: 0.6562\n",
            "Epoch 517/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6535 - val_loss: 0.6570\n",
            "Epoch 518/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6534 - val_loss: 0.6570\n",
            "Epoch 519/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6535 - val_loss: 0.6574\n",
            "Epoch 520/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6533 - val_loss: 0.6566\n",
            "Epoch 521/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6535 - val_loss: 0.6551\n",
            "Epoch 522/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6533 - val_loss: 0.6555\n",
            "Epoch 523/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6534 - val_loss: 0.6552\n",
            "Epoch 524/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6534 - val_loss: 0.6547\n",
            "Epoch 525/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6533 - val_loss: 0.6547\n",
            "Epoch 526/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6534 - val_loss: 0.6541\n",
            "Epoch 527/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6533 - val_loss: 0.6548\n",
            "Epoch 528/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6533 - val_loss: 0.6554\n",
            "Epoch 529/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6533 - val_loss: 0.6550\n",
            "Epoch 530/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6533 - val_loss: 0.6546\n",
            "Epoch 531/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6533 - val_loss: 0.6549\n",
            "Epoch 532/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6533 - val_loss: 0.6550\n",
            "Epoch 533/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6533 - val_loss: 0.6549\n",
            "Epoch 534/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6535 - val_loss: 0.6563\n",
            "Epoch 535/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6534 - val_loss: 0.6545\n",
            "Epoch 536/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6533 - val_loss: 0.6543\n",
            "Epoch 537/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6533 - val_loss: 0.6543\n",
            "Epoch 538/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6534 - val_loss: 0.6528\n",
            "Epoch 539/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6533 - val_loss: 0.6527\n",
            "Epoch 540/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6534 - val_loss: 0.6537\n",
            "Epoch 541/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.6533 - val_loss: 0.6526\n",
            "Epoch 542/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6533 - val_loss: 0.6533\n",
            "Epoch 543/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6532 - val_loss: 0.6530\n",
            "Epoch 544/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6532 - val_loss: 0.6529\n",
            "Epoch 545/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6533 - val_loss: 0.6531\n",
            "Epoch 546/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6532 - val_loss: 0.6531\n",
            "Epoch 547/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.6533 - val_loss: 0.6523\n",
            "Epoch 548/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6535 - val_loss: 0.6535\n",
            "Epoch 549/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6532 - val_loss: 0.6527\n",
            "Epoch 550/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6533 - val_loss: 0.6535\n",
            "Epoch 551/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6532 - val_loss: 0.6526\n",
            "Epoch 552/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6532 - val_loss: 0.6523\n",
            "Epoch 553/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6535 - val_loss: 0.6512\n",
            "Epoch 554/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6533 - val_loss: 0.6526\n",
            "Epoch 555/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6532 - val_loss: 0.6526\n",
            "Epoch 556/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6532 - val_loss: 0.6526\n",
            "Epoch 557/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6532 - val_loss: 0.6513\n",
            "Epoch 558/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.6532 - val_loss: 0.6508\n",
            "Epoch 559/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6532 - val_loss: 0.6512\n",
            "Epoch 560/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.6532 - val_loss: 0.6507\n",
            "Epoch 561/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6533 - val_loss: 0.6495\n",
            "Epoch 562/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6533 - val_loss: 0.6490\n",
            "Epoch 563/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6532 - val_loss: 0.6494\n",
            "Epoch 564/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6532 - val_loss: 0.6494\n",
            "Epoch 565/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6532 - val_loss: 0.6493\n",
            "Epoch 566/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6532 - val_loss: 0.6503\n",
            "Epoch 567/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6532 - val_loss: 0.6510\n",
            "Epoch 568/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6532 - val_loss: 0.6501\n",
            "Epoch 569/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6532 - val_loss: 0.6497\n",
            "Epoch 570/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6531 - val_loss: 0.6498\n",
            "Epoch 571/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6531 - val_loss: 0.6494\n",
            "Epoch 572/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6531 - val_loss: 0.6497\n",
            "Epoch 573/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6532 - val_loss: 0.6507\n",
            "Epoch 574/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6532 - val_loss: 0.6502\n",
            "Epoch 575/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6532 - val_loss: 0.6509\n",
            "Epoch 576/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6532 - val_loss: 0.6503\n",
            "Epoch 577/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6533 - val_loss: 0.6494\n",
            "Epoch 578/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6533 - val_loss: 0.6509\n",
            "Epoch 579/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6532 - val_loss: 0.6495\n",
            "Epoch 580/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6531 - val_loss: 0.6493\n",
            "Epoch 581/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6532 - val_loss: 0.6499\n",
            "Epoch 582/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6531 - val_loss: 0.6491\n",
            "Epoch 583/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6531 - val_loss: 0.6491\n",
            "Epoch 584/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6531 - val_loss: 0.6495\n",
            "Epoch 585/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6532 - val_loss: 0.6499\n",
            "Epoch 586/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6531 - val_loss: 0.6489\n",
            "Epoch 587/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6531 - val_loss: 0.6492\n",
            "Epoch 588/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.6533 - val_loss: 0.6474\n",
            "Epoch 589/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.6531 - val_loss: 0.6472\n",
            "Epoch 590/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6531 - val_loss: 0.6473\n",
            "Epoch 591/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6531 - val_loss: 0.6472\n",
            "Epoch 592/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6531 - val_loss: 0.6472\n",
            "Epoch 593/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6531 - val_loss: 0.6472\n",
            "Epoch 594/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.6533 - val_loss: 0.6461\n",
            "Epoch 595/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6530 - val_loss: 0.6462\n",
            "Epoch 596/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6531 - val_loss: 0.6471\n",
            "Epoch 597/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6531 - val_loss: 0.6467\n",
            "Epoch 598/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6531 - val_loss: 0.6464\n",
            "Epoch 599/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6532 - val_loss: 0.6473\n",
            "Epoch 600/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6531 - val_loss: 0.6471\n",
            "Epoch 601/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6531 - val_loss: 0.6464\n",
            "Epoch 602/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6532 - val_loss: 0.6460\n",
            "Epoch 603/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6531 - val_loss: 0.6468\n",
            "Epoch 604/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6531 - val_loss: 0.6468\n",
            "Epoch 605/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6534 - val_loss: 0.6486\n",
            "Epoch 606/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6532 - val_loss: 0.6469\n",
            "Epoch 607/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6530 - val_loss: 0.6473\n",
            "Epoch 608/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6531 - val_loss: 0.6470\n",
            "Epoch 609/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6531 - val_loss: 0.6474\n",
            "Epoch 610/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6530 - val_loss: 0.6475\n",
            "Epoch 611/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6532 - val_loss: 0.6468\n",
            "Epoch 612/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6531 - val_loss: 0.6477\n",
            "Epoch 613/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6530 - val_loss: 0.6478\n",
            "Epoch 614/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6531 - val_loss: 0.6481\n",
            "Epoch 615/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6531 - val_loss: 0.6484\n",
            "Epoch 616/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6531 - val_loss: 0.6486\n",
            "Epoch 617/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6530 - val_loss: 0.6486\n",
            "Epoch 618/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6530 - val_loss: 0.6480\n",
            "Epoch 619/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6530 - val_loss: 0.6478\n",
            "Epoch 620/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6530 - val_loss: 0.6481\n",
            "Epoch 621/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6531 - val_loss: 0.6482\n",
            "Epoch 622/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6531 - val_loss: 0.6476\n",
            "Epoch 623/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6530 - val_loss: 0.6473\n",
            "Epoch 624/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6531 - val_loss: 0.6472\n",
            "Epoch 625/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6530 - val_loss: 0.6473\n",
            "Epoch 626/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6530 - val_loss: 0.6481\n",
            "Epoch 627/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6531 - val_loss: 0.6480\n",
            "Epoch 628/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6530 - val_loss: 0.6483\n",
            "Epoch 629/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6531 - val_loss: 0.6477\n",
            "Epoch 630/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6530 - val_loss: 0.6480\n",
            "Epoch 631/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6530 - val_loss: 0.6482\n",
            "Epoch 632/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6530 - val_loss: 0.6474\n",
            "Epoch 633/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6530 - val_loss: 0.6476\n",
            "Epoch 634/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6530 - val_loss: 0.6477\n",
            "Epoch 635/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6530 - val_loss: 0.6480\n",
            "Epoch 636/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6530 - val_loss: 0.6474\n",
            "Epoch 637/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6530 - val_loss: 0.6472\n",
            "Epoch 638/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6531 - val_loss: 0.6478\n",
            "Epoch 639/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6531 - val_loss: 0.6466\n",
            "Epoch 640/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6530 - val_loss: 0.6464\n",
            "Epoch 641/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6530 - val_loss: 0.6470\n",
            "Epoch 642/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6530 - val_loss: 0.6472\n",
            "Epoch 643/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6530 - val_loss: 0.6468\n",
            "Epoch 644/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6532 - val_loss: 0.6460\n",
            "Epoch 645/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6530 - val_loss: 0.6462\n",
            "Epoch 646/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6530 - val_loss: 0.6467\n",
            "Epoch 647/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6530 - val_loss: 0.6470\n",
            "Epoch 648/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6530 - val_loss: 0.6478\n",
            "Epoch 649/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6530 - val_loss: 0.6473\n",
            "Epoch 650/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6530 - val_loss: 0.6474\n",
            "Epoch 651/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6531 - val_loss: 0.6469\n",
            "Epoch 652/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6530 - val_loss: 0.6467\n",
            "Epoch 653/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6531 - val_loss: 0.6477\n",
            "Epoch 654/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6530 - val_loss: 0.6476\n",
            "Epoch 655/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6530 - val_loss: 0.6472\n",
            "Epoch 656/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6530 - val_loss: 0.6473\n",
            "Epoch 657/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6530 - val_loss: 0.6470\n",
            "Epoch 658/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6530 - val_loss: 0.6472\n",
            "Epoch 659/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6530 - val_loss: 0.6464\n",
            "Epoch 660/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6530 - val_loss: 0.6470\n",
            "Epoch 661/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6530 - val_loss: 0.6468\n",
            "Epoch 662/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.6530 - val_loss: 0.6459\n",
            "Epoch 663/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6531 - val_loss: 0.6465\n",
            "Epoch 664/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6530 - val_loss: 0.6466\n",
            "Epoch 665/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6530 - val_loss: 0.6459\n",
            "Epoch 666/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6530 - val_loss: 0.6460\n",
            "Epoch 667/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6530 - val_loss: 0.6458\n",
            "Epoch 668/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6530 - val_loss: 0.6460\n",
            "Epoch 669/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6531 - val_loss: 0.6456\n",
            "Epoch 670/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6458\n",
            "Epoch 671/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6531 - val_loss: 0.6467\n",
            "Epoch 672/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6532 - val_loss: 0.6455\n",
            "Epoch 673/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6530 - val_loss: 0.6455\n",
            "Epoch 674/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6530 - val_loss: 0.6460\n",
            "Epoch 675/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6530 - val_loss: 0.6455\n",
            "Epoch 676/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6530 - val_loss: 0.6456\n",
            "Epoch 677/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6455\n",
            "Epoch 678/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6530 - val_loss: 0.6454\n",
            "Epoch 679/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6530 - val_loss: 0.6466\n",
            "Epoch 680/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6530 - val_loss: 0.6464\n",
            "Epoch 681/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6530 - val_loss: 0.6460\n",
            "Epoch 682/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6530 - val_loss: 0.6453\n",
            "Epoch 683/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6530 - val_loss: 0.6459\n",
            "Epoch 684/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6530 - val_loss: 0.6458\n",
            "Epoch 685/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6530 - val_loss: 0.6450\n",
            "Epoch 686/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.6531 - val_loss: 0.6444\n",
            "Epoch 687/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6530 - val_loss: 0.6444\n",
            "Epoch 688/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6530 - val_loss: 0.6449\n",
            "Epoch 689/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6530 - val_loss: 0.6447\n",
            "Epoch 690/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6452\n",
            "Epoch 691/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6531 - val_loss: 0.6442\n",
            "Epoch 692/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6443\n",
            "Epoch 693/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6446\n",
            "Epoch 694/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.6530 - val_loss: 0.6439\n",
            "Epoch 695/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6530 - val_loss: 0.6450\n",
            "Epoch 696/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6530 - val_loss: 0.6453\n",
            "Epoch 697/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6530 - val_loss: 0.6458\n",
            "Epoch 698/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6530 - val_loss: 0.6458\n",
            "Epoch 699/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6530 - val_loss: 0.6452\n",
            "Epoch 700/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6530 - val_loss: 0.6446\n",
            "Epoch 701/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6530 - val_loss: 0.6451\n",
            "Epoch 702/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6529 - val_loss: 0.6445\n",
            "Epoch 703/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6531 - val_loss: 0.6448\n",
            "Epoch 704/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6530 - val_loss: 0.6449\n",
            "Epoch 705/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6450\n",
            "Epoch 706/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6530 - val_loss: 0.6450\n",
            "Epoch 707/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6530 - val_loss: 0.6453\n",
            "Epoch 708/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6530 - val_loss: 0.6444\n",
            "Epoch 709/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6530 - val_loss: 0.6444\n",
            "Epoch 710/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6531 - val_loss: 0.6452\n",
            "Epoch 711/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6530 - val_loss: 0.6441\n",
            "Epoch 712/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6530 - val_loss: 0.6441\n",
            "Epoch 713/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6444\n",
            "Epoch 714/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6529 - val_loss: 0.6442\n",
            "Epoch 715/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6441\n",
            "Epoch 716/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6531 - val_loss: 0.6435\n",
            "Epoch 717/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6530 - val_loss: 0.6442\n",
            "Epoch 718/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6530 - val_loss: 0.6438\n",
            "Epoch 719/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6530 - val_loss: 0.6437\n",
            "Epoch 720/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6530 - val_loss: 0.6441\n",
            "Epoch 721/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6444\n",
            "Epoch 722/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6530 - val_loss: 0.6446\n",
            "Epoch 723/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6447\n",
            "Epoch 724/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6530 - val_loss: 0.6447\n",
            "Epoch 725/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6530 - val_loss: 0.6446\n",
            "Epoch 726/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6530 - val_loss: 0.6439\n",
            "Epoch 727/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6529 - val_loss: 0.6441\n",
            "Epoch 728/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6442\n",
            "Epoch 729/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6445\n",
            "Epoch 730/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6530 - val_loss: 0.6450\n",
            "Epoch 731/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6530 - val_loss: 0.6446\n",
            "Epoch 732/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6450\n",
            "Epoch 733/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6530 - val_loss: 0.6451\n",
            "Epoch 734/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6454\n",
            "Epoch 735/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6530 - val_loss: 0.6450\n",
            "Epoch 736/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6531 - val_loss: 0.6448\n",
            "Epoch 737/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6530 - val_loss: 0.6453\n",
            "Epoch 738/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6530 - val_loss: 0.6457\n",
            "Epoch 739/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6530 - val_loss: 0.6449\n",
            "Epoch 740/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6452\n",
            "Epoch 741/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6530 - val_loss: 0.6461\n",
            "Epoch 742/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6530 - val_loss: 0.6457\n",
            "Epoch 743/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6530 - val_loss: 0.6451\n",
            "Epoch 744/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6456\n",
            "Epoch 745/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6456\n",
            "Epoch 746/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6530 - val_loss: 0.6455\n",
            "Epoch 747/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6460\n",
            "Epoch 748/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6461\n",
            "Epoch 749/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6530 - val_loss: 0.6458\n",
            "Epoch 750/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6461\n",
            "Epoch 751/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6530 - val_loss: 0.6462\n",
            "Epoch 752/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6530 - val_loss: 0.6466\n",
            "Epoch 753/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6469\n",
            "Epoch 754/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6462\n",
            "Epoch 755/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6458\n",
            "Epoch 756/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6530 - val_loss: 0.6459\n",
            "Epoch 757/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6460\n",
            "Epoch 758/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6530 - val_loss: 0.6459\n",
            "Epoch 759/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6460\n",
            "Epoch 760/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6461\n",
            "Epoch 761/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6531 - val_loss: 0.6455\n",
            "Epoch 762/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6529 - val_loss: 0.6459\n",
            "Epoch 763/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6459\n",
            "Epoch 764/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6462\n",
            "Epoch 765/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6529 - val_loss: 0.6464\n",
            "Epoch 766/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6531 - val_loss: 0.6474\n",
            "Epoch 767/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6530 - val_loss: 0.6462\n",
            "Epoch 768/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6458\n",
            "Epoch 769/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6531 - val_loss: 0.6473\n",
            "Epoch 770/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6467\n",
            "Epoch 771/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6467\n",
            "Epoch 772/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6464\n",
            "Epoch 773/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6531 - val_loss: 0.6468\n",
            "Epoch 774/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6530 - val_loss: 0.6457\n",
            "Epoch 775/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6531 - val_loss: 0.6442\n",
            "Epoch 776/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6448\n",
            "Epoch 777/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6530 - val_loss: 0.6440\n",
            "Epoch 778/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6440\n",
            "Epoch 779/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6530 - val_loss: 0.6451\n",
            "Epoch 780/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6530 - val_loss: 0.6454\n",
            "Epoch 781/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6530 - val_loss: 0.6456\n",
            "Epoch 782/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6531 - val_loss: 0.6441\n",
            "Epoch 783/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6532 - val_loss: 0.6430\n",
            "Epoch 784/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6530 - val_loss: 0.6434\n",
            "Epoch 785/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6437\n",
            "Epoch 786/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6530 - val_loss: 0.6444\n",
            "Epoch 787/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6530 - val_loss: 0.6444\n",
            "Epoch 788/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6529 - val_loss: 0.6441\n",
            "Epoch 789/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6441\n",
            "Epoch 790/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6531 - val_loss: 0.6433\n",
            "Epoch 791/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6438\n",
            "Epoch 792/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6434\n",
            "Epoch 793/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6436\n",
            "Epoch 794/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6438\n",
            "Epoch 795/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6441\n",
            "Epoch 796/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6529 - val_loss: 0.6440\n",
            "Epoch 797/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6529 - val_loss: 0.6430\n",
            "Epoch 798/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6432\n",
            "Epoch 799/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6531 - val_loss: 0.6444\n",
            "Epoch 800/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6530 - val_loss: 0.6444\n",
            "Epoch 801/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6437\n",
            "Epoch 802/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6530 - val_loss: 0.6428\n",
            "Epoch 803/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6531 - val_loss: 0.6420\n",
            "Epoch 804/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6424\n",
            "Epoch 805/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6431\n",
            "Epoch 806/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6437\n",
            "Epoch 807/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6529 - val_loss: 0.6445\n",
            "Epoch 808/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6530 - val_loss: 0.6443\n",
            "Epoch 809/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6530 - val_loss: 0.6434\n",
            "Epoch 810/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6530 - val_loss: 0.6445\n",
            "Epoch 811/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6531 - val_loss: 0.6455\n",
            "Epoch 812/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6448\n",
            "Epoch 813/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6531 - val_loss: 0.6456\n",
            "Epoch 814/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6455\n",
            "Epoch 815/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6530 - val_loss: 0.6447\n",
            "Epoch 816/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6451\n",
            "Epoch 817/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6530 - val_loss: 0.6442\n",
            "Epoch 818/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6530 - val_loss: 0.6450\n",
            "Epoch 819/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6449\n",
            "Epoch 820/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6530 - val_loss: 0.6451\n",
            "Epoch 821/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6452\n",
            "Epoch 822/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6530 - val_loss: 0.6442\n",
            "Epoch 823/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6443\n",
            "Epoch 824/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6530 - val_loss: 0.6449\n",
            "Epoch 825/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6442\n",
            "Epoch 826/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6529 - val_loss: 0.6442\n",
            "Epoch 827/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6442\n",
            "Epoch 828/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6441\n",
            "Epoch 829/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6530 - val_loss: 0.6434\n",
            "Epoch 830/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6443\n",
            "Epoch 831/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6439\n",
            "Epoch 832/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6529 - val_loss: 0.6438\n",
            "Epoch 833/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6529 - val_loss: 0.6444\n",
            "Epoch 834/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6447\n",
            "Epoch 835/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6529 - val_loss: 0.6451\n",
            "Epoch 836/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6529 - val_loss: 0.6454\n",
            "Epoch 837/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6529 - val_loss: 0.6451\n",
            "Epoch 838/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6530 - val_loss: 0.6440\n",
            "Epoch 839/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6440\n",
            "Epoch 840/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6438\n",
            "Epoch 841/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6435\n",
            "Epoch 842/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6440\n",
            "Epoch 843/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6444\n",
            "Epoch 844/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6451\n",
            "Epoch 845/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6445\n",
            "Epoch 846/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6451\n",
            "Epoch 847/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6530 - val_loss: 0.6442\n",
            "Epoch 848/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6531 - val_loss: 0.6452\n",
            "Epoch 849/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6445\n",
            "Epoch 850/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6530 - val_loss: 0.6440\n",
            "Epoch 851/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6444\n",
            "Epoch 852/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6443\n",
            "Epoch 853/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6441\n",
            "Epoch 854/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6430\n",
            "Epoch 855/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6427\n",
            "Epoch 856/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6530 - val_loss: 0.6436\n",
            "Epoch 857/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6432\n",
            "Epoch 858/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6530 - val_loss: 0.6426\n",
            "Epoch 859/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6530 - val_loss: 0.6422\n",
            "Epoch 860/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6433\n",
            "Epoch 861/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6440\n",
            "Epoch 862/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6436\n",
            "Epoch 863/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6436\n",
            "Epoch 864/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6530 - val_loss: 0.6433\n",
            "Epoch 865/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6433\n",
            "Epoch 866/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6530 - val_loss: 0.6439\n",
            "Epoch 867/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6440\n",
            "Epoch 868/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6437\n",
            "Epoch 869/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6529 - val_loss: 0.6439\n",
            "Epoch 870/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6439\n",
            "Epoch 871/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6445\n",
            "Epoch 872/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6448\n",
            "Epoch 873/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6452\n",
            "Epoch 874/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6448\n",
            "Epoch 875/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6530 - val_loss: 0.6445\n",
            "Epoch 876/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6445\n",
            "Epoch 877/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6449\n",
            "Epoch 878/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6450\n",
            "Epoch 879/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6441\n",
            "Epoch 880/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6437\n",
            "Epoch 881/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6441\n",
            "Epoch 882/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6531 - val_loss: 0.6449\n",
            "Epoch 883/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6453\n",
            "Epoch 884/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6444\n",
            "Epoch 885/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6444\n",
            "Epoch 886/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6530 - val_loss: 0.6441\n",
            "Epoch 887/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6530 - val_loss: 0.6450\n",
            "Epoch 888/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6454\n",
            "Epoch 889/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6446\n",
            "Epoch 890/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6447\n",
            "Epoch 891/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6450\n",
            "Epoch 892/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6452\n",
            "Epoch 893/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6531 - val_loss: 0.6464\n",
            "Epoch 894/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6530 - val_loss: 0.6451\n",
            "Epoch 895/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6451\n",
            "Epoch 896/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6531 - val_loss: 0.6464\n",
            "Epoch 897/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6459\n",
            "Epoch 898/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6531 - val_loss: 0.6449\n",
            "Epoch 899/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6530 - val_loss: 0.6447\n",
            "Epoch 900/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6529 - val_loss: 0.6452\n",
            "Epoch 901/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6529 - val_loss: 0.6450\n",
            "Epoch 902/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6529 - val_loss: 0.6456\n",
            "Epoch 903/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6455\n",
            "Epoch 904/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6460\n",
            "Epoch 905/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6456\n",
            "Epoch 906/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6455\n",
            "Epoch 907/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6461\n",
            "Epoch 908/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6454\n",
            "Epoch 909/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6453\n",
            "Epoch 910/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6459\n",
            "Epoch 911/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6531 - val_loss: 0.6440\n",
            "Epoch 912/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6444\n",
            "Epoch 913/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6452\n",
            "Epoch 914/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6449\n",
            "Epoch 915/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6443\n",
            "Epoch 916/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6442\n",
            "Epoch 917/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6528 - val_loss: 0.6443\n",
            "Epoch 918/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6443\n",
            "Epoch 919/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6529 - val_loss: 0.6446\n",
            "Epoch 920/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6529 - val_loss: 0.6449\n",
            "Epoch 921/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6529 - val_loss: 0.6450\n",
            "Epoch 922/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6528 - val_loss: 0.6447\n",
            "Epoch 923/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6529 - val_loss: 0.6448\n",
            "Epoch 924/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6446\n",
            "Epoch 925/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6446\n",
            "Epoch 926/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6455\n",
            "Epoch 927/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6531 - val_loss: 0.6445\n",
            "Epoch 928/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6452\n",
            "Epoch 929/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6459\n",
            "Epoch 930/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6462\n",
            "Epoch 931/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6468\n",
            "Epoch 932/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6463\n",
            "Epoch 933/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6456\n",
            "Epoch 934/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6459\n",
            "Epoch 935/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6454\n",
            "Epoch 936/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6529 - val_loss: 0.6449\n",
            "Epoch 937/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6445\n",
            "Epoch 938/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6448\n",
            "Epoch 939/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6451\n",
            "Epoch 940/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6453\n",
            "Epoch 941/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6447\n",
            "Epoch 942/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6533 - val_loss: 0.6462\n",
            "Epoch 943/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6528 - val_loss: 0.6460\n",
            "Epoch 944/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6529 - val_loss: 0.6453\n",
            "Epoch 945/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6529 - val_loss: 0.6453\n",
            "Epoch 946/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6528 - val_loss: 0.6445\n",
            "Epoch 947/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6530 - val_loss: 0.6454\n",
            "Epoch 948/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6530 - val_loss: 0.6442\n",
            "Epoch 949/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6529 - val_loss: 0.6446\n",
            "Epoch 950/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6529 - val_loss: 0.6444\n",
            "Epoch 951/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6439\n",
            "Epoch 952/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6440\n",
            "Epoch 953/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6451\n",
            "Epoch 954/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6441\n",
            "Epoch 955/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6441\n",
            "Epoch 956/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6449\n",
            "Epoch 957/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6448\n",
            "Epoch 958/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6446\n",
            "Epoch 959/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6446\n",
            "Epoch 960/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6450\n",
            "Epoch 961/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6444\n",
            "Epoch 962/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6442\n",
            "Epoch 963/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6530 - val_loss: 0.6451\n",
            "Epoch 964/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6441\n",
            "Epoch 965/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6442\n",
            "Epoch 966/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6530 - val_loss: 0.6452\n",
            "Epoch 967/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6446\n",
            "Epoch 968/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6443\n",
            "Epoch 969/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6444\n",
            "Epoch 970/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6530 - val_loss: 0.6455\n",
            "Epoch 971/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6451\n",
            "Epoch 972/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6450\n",
            "Epoch 973/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6441\n",
            "Epoch 974/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6532 - val_loss: 0.6430\n",
            "Epoch 975/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6439\n",
            "Epoch 976/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6440\n",
            "Epoch 977/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6446\n",
            "Epoch 978/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6530 - val_loss: 0.6439\n",
            "Epoch 979/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6441\n",
            "Epoch 980/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6442\n",
            "Epoch 981/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6441\n",
            "Epoch 982/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6434\n",
            "Epoch 983/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6438\n",
            "Epoch 984/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6428\n",
            "Epoch 985/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6425\n",
            "Epoch 986/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6531 - val_loss: 0.6434\n",
            "Epoch 987/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6423\n",
            "Epoch 988/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6424\n",
            "Epoch 989/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6532 - val_loss: 0.6436\n",
            "Epoch 990/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6431\n",
            "Epoch 991/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6530 - val_loss: 0.6418\n",
            "Epoch 992/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6420\n",
            "Epoch 993/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6424\n",
            "Epoch 994/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6422\n",
            "Epoch 995/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6429\n",
            "Epoch 996/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6424\n",
            "Epoch 997/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6434\n",
            "Epoch 998/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6428\n",
            "Epoch 999/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6428\n",
            "Epoch 1000/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6425\n",
            "Epoch 1001/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6425\n",
            "Epoch 1002/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6420\n",
            "Epoch 1003/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6424\n",
            "Epoch 1004/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6424\n",
            "Epoch 1005/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6427\n",
            "Epoch 1006/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6428\n",
            "Epoch 1007/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6530 - val_loss: 0.6439\n",
            "Epoch 1008/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6429\n",
            "Epoch 1009/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6434\n",
            "Epoch 1010/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6434\n",
            "Epoch 1011/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6436\n",
            "Epoch 1012/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6428\n",
            "Epoch 1013/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6529 - val_loss: 0.6417\n",
            "Epoch 1014/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6426\n",
            "Epoch 1015/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6425\n",
            "Epoch 1016/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6529 - val_loss: 0.6428\n",
            "Epoch 1017/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6424\n",
            "Epoch 1018/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6528 - val_loss: 0.6422\n",
            "Epoch 1019/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6427\n",
            "Epoch 1020/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6419\n",
            "Epoch 1021/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6421\n",
            "Epoch 1022/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6420\n",
            "Epoch 1023/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6431\n",
            "Epoch 1024/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6528 - val_loss: 0.6428\n",
            "Epoch 1025/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6433\n",
            "Epoch 1026/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6431\n",
            "Epoch 1027/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6528 - val_loss: 0.6426\n",
            "Epoch 1028/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6427\n",
            "Epoch 1029/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6528 - val_loss: 0.6430\n",
            "Epoch 1030/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6427\n",
            "Epoch 1031/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6422\n",
            "Epoch 1032/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6426\n",
            "Epoch 1033/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6429\n",
            "Epoch 1034/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6430\n",
            "Epoch 1035/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6530 - val_loss: 0.6418\n",
            "Epoch 1036/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6426\n",
            "Epoch 1037/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6428\n",
            "Epoch 1038/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6421\n",
            "Epoch 1039/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6419\n",
            "Epoch 1040/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6423\n",
            "Epoch 1041/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6419\n",
            "Epoch 1042/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6419\n",
            "Epoch 1043/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6529 - val_loss: 0.6419\n",
            "Epoch 1044/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6420\n",
            "Epoch 1045/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6420\n",
            "Epoch 1046/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6423\n",
            "Epoch 1047/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.6528 - val_loss: 0.6417\n",
            "Epoch 1048/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6421\n",
            "Epoch 1049/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6421\n",
            "Epoch 1050/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6426\n",
            "Epoch 1051/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6417\n",
            "Epoch 1052/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6418\n",
            "Epoch 1053/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6423\n",
            "Epoch 1054/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6428\n",
            "Epoch 1055/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6425\n",
            "Epoch 1056/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6422\n",
            "Epoch 1057/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6528 - val_loss: 0.6418\n",
            "Epoch 1058/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6419\n",
            "Epoch 1059/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6423\n",
            "Epoch 1060/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6429\n",
            "Epoch 1061/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6529 - val_loss: 0.6417\n",
            "Epoch 1062/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6420\n",
            "Epoch 1063/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6529 - val_loss: 0.6426\n",
            "Epoch 1064/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6421\n",
            "Epoch 1065/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6419\n",
            "Epoch 1066/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6423\n",
            "Epoch 1067/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6419\n",
            "Epoch 1068/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6422\n",
            "Epoch 1069/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6424\n",
            "Epoch 1070/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6432\n",
            "Epoch 1071/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6436\n",
            "Epoch 1072/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6434\n",
            "Epoch 1073/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6427\n",
            "Epoch 1074/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6433\n",
            "Epoch 1075/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6435\n",
            "Epoch 1076/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6426\n",
            "Epoch 1077/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6432\n",
            "Epoch 1078/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6426\n",
            "Epoch 1079/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6530 - val_loss: 0.6437\n",
            "Epoch 1080/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6430\n",
            "Epoch 1081/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6426\n",
            "Epoch 1082/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6429\n",
            "Epoch 1083/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6427\n",
            "Epoch 1084/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6433\n",
            "Epoch 1085/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6528 - val_loss: 0.6434\n",
            "Epoch 1086/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6528 - val_loss: 0.6436\n",
            "Epoch 1087/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6528 - val_loss: 0.6434\n",
            "Epoch 1088/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6438\n",
            "Epoch 1089/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6433\n",
            "Epoch 1090/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6426\n",
            "Epoch 1091/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6422\n",
            "Epoch 1092/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6421\n",
            "Epoch 1093/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6420\n",
            "Epoch 1094/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6418\n",
            "Epoch 1095/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6425\n",
            "Epoch 1096/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6430\n",
            "Epoch 1097/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6435\n",
            "Epoch 1098/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6530 - val_loss: 0.6446\n",
            "Epoch 1099/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6437\n",
            "Epoch 1100/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6441\n",
            "Epoch 1101/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6444\n",
            "Epoch 1102/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6448\n",
            "Epoch 1103/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6453\n",
            "Epoch 1104/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6452\n",
            "Epoch 1105/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6450\n",
            "Epoch 1106/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6453\n",
            "Epoch 1107/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6455\n",
            "Epoch 1108/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6455\n",
            "Epoch 1109/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6461\n",
            "Epoch 1110/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6453\n",
            "Epoch 1111/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6448\n",
            "Epoch 1112/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6528 - val_loss: 0.6451\n",
            "Epoch 1113/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6450\n",
            "Epoch 1114/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6453\n",
            "Epoch 1115/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6466\n",
            "Epoch 1116/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6466\n",
            "Epoch 1117/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6462\n",
            "Epoch 1118/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6457\n",
            "Epoch 1119/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6453\n",
            "Epoch 1120/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6460\n",
            "Epoch 1121/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6455\n",
            "Epoch 1122/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6530 - val_loss: 0.6469\n",
            "Epoch 1123/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6528 - val_loss: 0.6460\n",
            "Epoch 1124/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6457\n",
            "Epoch 1125/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6528 - val_loss: 0.6461\n",
            "Epoch 1126/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6454\n",
            "Epoch 1127/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6454\n",
            "Epoch 1128/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6528 - val_loss: 0.6462\n",
            "Epoch 1129/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6461\n",
            "Epoch 1130/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6450\n",
            "Epoch 1131/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6452\n",
            "Epoch 1132/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6459\n",
            "Epoch 1133/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6458\n",
            "Epoch 1134/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6453\n",
            "Epoch 1135/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6451\n",
            "Epoch 1136/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6456\n",
            "Epoch 1137/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6459\n",
            "Epoch 1138/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6458\n",
            "Epoch 1139/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6457\n",
            "Epoch 1140/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6449\n",
            "Epoch 1141/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6447\n",
            "Epoch 1142/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6457\n",
            "Epoch 1143/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6448\n",
            "Epoch 1144/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6451\n",
            "Epoch 1145/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6448\n",
            "Epoch 1146/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6530 - val_loss: 0.6458\n",
            "Epoch 1147/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6527 - val_loss: 0.6449\n",
            "Epoch 1148/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6443\n",
            "Epoch 1149/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6439\n",
            "Epoch 1150/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6445\n",
            "Epoch 1151/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6441\n",
            "Epoch 1152/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6527 - val_loss: 0.6438\n",
            "Epoch 1153/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6436\n",
            "Epoch 1154/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6436\n",
            "Epoch 1155/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6429\n",
            "Epoch 1156/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6435\n",
            "Epoch 1157/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6433\n",
            "Epoch 1158/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6527 - val_loss: 0.6434\n",
            "Epoch 1159/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6531 - val_loss: 0.6445\n",
            "Epoch 1160/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6443\n",
            "Epoch 1161/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6527 - val_loss: 0.6438\n",
            "Epoch 1162/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6527 - val_loss: 0.6432\n",
            "Epoch 1163/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6530 - val_loss: 0.6424\n",
            "Epoch 1164/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6420\n",
            "Epoch 1165/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6527 - val_loss: 0.6423\n",
            "Epoch 1166/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6433\n",
            "Epoch 1167/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6423\n",
            "Epoch 1168/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6423\n",
            "Epoch 1169/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6421\n",
            "Epoch 1170/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6417\n",
            "Epoch 1171/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6424\n",
            "Epoch 1172/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6420\n",
            "Epoch 1173/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6528 - val_loss: 0.6417\n",
            "Epoch 1174/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6419\n",
            "Epoch 1175/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6528 - val_loss: 0.6424\n",
            "Epoch 1176/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6528 - val_loss: 0.6417\n",
            "Epoch 1177/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6528 - val_loss: 0.6413\n",
            "Epoch 1178/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6529 - val_loss: 0.6425\n",
            "Epoch 1179/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6527 - val_loss: 0.6424\n",
            "Epoch 1180/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6529 - val_loss: 0.6413\n",
            "Epoch 1181/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6417\n",
            "Epoch 1182/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6426\n",
            "Epoch 1183/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6527 - val_loss: 0.6421\n",
            "Epoch 1184/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6422\n",
            "Epoch 1185/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6528 - val_loss: 0.6426\n",
            "Epoch 1186/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6527 - val_loss: 0.6425\n",
            "Epoch 1187/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6424\n",
            "Epoch 1188/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6529 - val_loss: 0.6419\n",
            "Epoch 1189/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6528 - val_loss: 0.6423\n",
            "Epoch 1190/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6528 - val_loss: 0.6412\n",
            "Epoch 1191/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6528 - val_loss: 0.6410\n",
            "Epoch 1192/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6415\n",
            "Epoch 1193/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6413\n",
            "Epoch 1194/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6417\n",
            "Epoch 1195/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6429\n",
            "Epoch 1196/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6425\n",
            "Epoch 1197/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6530 - val_loss: 0.6439\n",
            "Epoch 1198/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6527 - val_loss: 0.6438\n",
            "Epoch 1199/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6527 - val_loss: 0.6434\n",
            "Epoch 1200/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6432\n",
            "Epoch 1201/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6426\n",
            "Epoch 1202/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6422\n",
            "Epoch 1203/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6530 - val_loss: 0.6438\n",
            "Epoch 1204/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6527 - val_loss: 0.6437\n",
            "Epoch 1205/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6527 - val_loss: 0.6435\n",
            "Epoch 1206/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6437\n",
            "Epoch 1207/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6439\n",
            "Epoch 1208/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6451\n",
            "Epoch 1209/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6449\n",
            "Epoch 1210/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6527 - val_loss: 0.6443\n",
            "Epoch 1211/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6530 - val_loss: 0.6432\n",
            "Epoch 1212/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6527 - val_loss: 0.6437\n",
            "Epoch 1213/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6448\n",
            "Epoch 1214/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6528 - val_loss: 0.6448\n",
            "Epoch 1215/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6527 - val_loss: 0.6443\n",
            "Epoch 1216/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6527 - val_loss: 0.6445\n",
            "Epoch 1217/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6527 - val_loss: 0.6444\n",
            "Epoch 1218/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6528 - val_loss: 0.6441\n",
            "Epoch 1219/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6441\n",
            "Epoch 1220/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6528 - val_loss: 0.6439\n",
            "Epoch 1221/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6434\n",
            "Epoch 1222/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6431\n",
            "Epoch 1223/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6437\n",
            "Epoch 1224/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6445\n",
            "Epoch 1225/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6436\n",
            "Epoch 1226/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6440\n",
            "Epoch 1227/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6431\n",
            "Epoch 1228/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6427\n",
            "Epoch 1229/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6428\n",
            "Epoch 1230/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6435\n",
            "Epoch 1231/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6527 - val_loss: 0.6434\n",
            "Epoch 1232/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6527 - val_loss: 0.6433\n",
            "Epoch 1233/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6431\n",
            "Epoch 1234/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6527 - val_loss: 0.6433\n",
            "Epoch 1235/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6442\n",
            "Epoch 1236/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6527 - val_loss: 0.6435\n",
            "Epoch 1237/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6527 - val_loss: 0.6434\n",
            "Epoch 1238/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6528 - val_loss: 0.6439\n",
            "Epoch 1239/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6427\n",
            "Epoch 1240/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6424\n",
            "Epoch 1241/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6431\n",
            "Epoch 1242/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6527 - val_loss: 0.6421\n",
            "Epoch 1243/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6419\n",
            "Epoch 1244/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6529 - val_loss: 0.6409\n",
            "Epoch 1245/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6412\n",
            "Epoch 1246/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.6528 - val_loss: 0.6408\n",
            "Epoch 1247/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6528 - val_loss: 0.6408\n",
            "Epoch 1248/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6531 - val_loss: 0.6421\n",
            "Epoch 1249/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.6530 - val_loss: 0.6405\n",
            "Epoch 1250/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6530 - val_loss: 0.6421\n",
            "Epoch 1251/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6527 - val_loss: 0.6422\n",
            "Epoch 1252/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6427\n",
            "Epoch 1253/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6421\n",
            "Epoch 1254/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6527 - val_loss: 0.6428\n",
            "Epoch 1255/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6423\n",
            "Epoch 1256/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6527 - val_loss: 0.6426\n",
            "Epoch 1257/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6436\n",
            "Epoch 1258/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6527 - val_loss: 0.6437\n",
            "Epoch 1259/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6441\n",
            "Epoch 1260/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6527 - val_loss: 0.6443\n",
            "Epoch 1261/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6444\n",
            "Epoch 1262/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6527 - val_loss: 0.6440\n",
            "Epoch 1263/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6527 - val_loss: 0.6440\n",
            "Epoch 1264/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6527 - val_loss: 0.6440\n",
            "Epoch 1265/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6527 - val_loss: 0.6440\n",
            "Epoch 1266/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6527 - val_loss: 0.6440\n",
            "Epoch 1267/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6530 - val_loss: 0.6433\n",
            "Epoch 1268/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6527 - val_loss: 0.6440\n",
            "Epoch 1269/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6527 - val_loss: 0.6437\n",
            "Epoch 1270/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6527 - val_loss: 0.6433\n",
            "Epoch 1271/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6437\n",
            "Epoch 1272/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6440\n",
            "Epoch 1273/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6528 - val_loss: 0.6425\n",
            "Epoch 1274/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6419\n",
            "Epoch 1275/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6527 - val_loss: 0.6422\n",
            "Epoch 1276/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6527 - val_loss: 0.6425\n",
            "Epoch 1277/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6434\n",
            "Epoch 1278/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6528 - val_loss: 0.6425\n",
            "Epoch 1279/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6527 - val_loss: 0.6426\n",
            "Epoch 1280/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6527 - val_loss: 0.6425\n",
            "Epoch 1281/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6527 - val_loss: 0.6427\n",
            "Epoch 1282/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6423\n",
            "Epoch 1283/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6528 - val_loss: 0.6431\n",
            "Epoch 1284/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6527 - val_loss: 0.6432\n",
            "Epoch 1285/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6527 - val_loss: 0.6435\n",
            "Epoch 1286/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6527 - val_loss: 0.6439\n",
            "Epoch 1287/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6527 - val_loss: 0.6437\n",
            "Epoch 1288/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6527 - val_loss: 0.6437\n",
            "Epoch 1289/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6527 - val_loss: 0.6436\n",
            "Epoch 1290/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6527 - val_loss: 0.6439\n",
            "Epoch 1291/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6527 - val_loss: 0.6431\n",
            "Epoch 1292/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6432\n",
            "Epoch 1293/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6527 - val_loss: 0.6432\n",
            "Epoch 1294/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6435\n",
            "Epoch 1295/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6527 - val_loss: 0.6428\n",
            "Epoch 1296/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6424\n",
            "Epoch 1297/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6527 - val_loss: 0.6430\n",
            "Epoch 1298/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6527 - val_loss: 0.6427\n",
            "Epoch 1299/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6527 - val_loss: 0.6428\n",
            "Epoch 1300/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6527 - val_loss: 0.6431\n",
            "Epoch 1301/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6432\n",
            "Epoch 1302/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6430\n",
            "Epoch 1303/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6529 - val_loss: 0.6438\n",
            "Epoch 1304/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6424\n",
            "Epoch 1305/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6528 - val_loss: 0.6430\n",
            "Epoch 1306/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6527 - val_loss: 0.6432\n",
            "Epoch 1307/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6527 - val_loss: 0.6428\n",
            "Epoch 1308/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6423\n",
            "Epoch 1309/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6528 - val_loss: 0.6429\n",
            "Epoch 1310/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6527 - val_loss: 0.6434\n",
            "Epoch 1311/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6527 - val_loss: 0.6432\n",
            "Epoch 1312/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6530 - val_loss: 0.6425\n",
            "Epoch 1313/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6526 - val_loss: 0.6439\n",
            "Epoch 1314/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6527 - val_loss: 0.6447\n",
            "Epoch 1315/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6528 - val_loss: 0.6446\n",
            "Epoch 1316/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6527 - val_loss: 0.6457\n",
            "Epoch 1317/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6529 - val_loss: 0.6449\n",
            "Epoch 1318/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6528 - val_loss: 0.6457\n",
            "Epoch 1319/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6527 - val_loss: 0.6456\n",
            "Epoch 1320/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6455\n",
            "Epoch 1321/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6529 - val_loss: 0.6467\n",
            "Epoch 1322/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6528 - val_loss: 0.6469\n",
            "Epoch 1323/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6528 - val_loss: 0.6450\n",
            "Epoch 1324/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6527 - val_loss: 0.6449\n",
            "Epoch 1325/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6531 - val_loss: 0.6436\n",
            "Epoch 1326/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6528 - val_loss: 0.6450\n",
            "Epoch 1327/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6527 - val_loss: 0.6450\n",
            "Epoch 1328/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6527 - val_loss: 0.6449\n",
            "Epoch 1329/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6527 - val_loss: 0.6447\n",
            "Epoch 1330/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6432\n",
            "Epoch 1331/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6428\n",
            "Epoch 1332/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6437\n",
            "Epoch 1333/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6527 - val_loss: 0.6438\n",
            "Epoch 1334/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6430\n",
            "Epoch 1335/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6528 - val_loss: 0.6437\n",
            "Epoch 1336/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6527 - val_loss: 0.6436\n",
            "Epoch 1337/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6527 - val_loss: 0.6439\n",
            "Epoch 1338/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6530 - val_loss: 0.6425\n",
            "Epoch 1339/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6422\n",
            "Epoch 1340/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6527 - val_loss: 0.6434\n",
            "Epoch 1341/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6528 - val_loss: 0.6431\n",
            "Epoch 1342/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6527 - val_loss: 0.6436\n",
            "Epoch 1343/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6527 - val_loss: 0.6434\n",
            "Epoch 1344/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6528 - val_loss: 0.6432\n",
            "Epoch 1345/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6527 - val_loss: 0.6437\n",
            "Epoch 1346/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6443\n",
            "Epoch 1347/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6527 - val_loss: 0.6434\n",
            "Epoch 1348/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6527 - val_loss: 0.6434\n",
            "Epoch 1349/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6422\n",
            "Epoch 1350/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6432\n",
            "Epoch 1351/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6527 - val_loss: 0.6433\n",
            "Epoch 1352/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6424\n",
            "Epoch 1353/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6527 - val_loss: 0.6429\n",
            "Epoch 1354/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6434\n",
            "Epoch 1355/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6527 - val_loss: 0.6424\n",
            "Epoch 1356/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6527 - val_loss: 0.6428\n",
            "Epoch 1357/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6527 - val_loss: 0.6430\n",
            "Epoch 1358/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6527 - val_loss: 0.6429\n",
            "Epoch 1359/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6527 - val_loss: 0.6427\n",
            "Epoch 1360/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6417\n",
            "Epoch 1361/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6528 - val_loss: 0.6424\n",
            "Epoch 1362/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6527 - val_loss: 0.6415\n",
            "Epoch 1363/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6416\n",
            "Epoch 1364/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6411\n",
            "Epoch 1365/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6421\n",
            "Epoch 1366/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6527 - val_loss: 0.6415\n",
            "Epoch 1367/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6527 - val_loss: 0.6418\n",
            "Epoch 1368/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6408\n",
            "Epoch 1369/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6425\n",
            "Epoch 1370/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6415\n",
            "Epoch 1371/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6527 - val_loss: 0.6420\n",
            "Epoch 1372/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6527 - val_loss: 0.6422\n",
            "Epoch 1373/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6527 - val_loss: 0.6428\n",
            "Epoch 1374/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6421\n",
            "Epoch 1375/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6527 - val_loss: 0.6419\n",
            "Epoch 1376/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6421\n",
            "Epoch 1377/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6527 - val_loss: 0.6423\n",
            "Epoch 1378/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6527 - val_loss: 0.6419\n",
            "Epoch 1379/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6527 - val_loss: 0.6414\n",
            "Epoch 1380/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6526 - val_loss: 0.6422\n",
            "Epoch 1381/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6527 - val_loss: 0.6424\n",
            "Epoch 1382/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6527 - val_loss: 0.6424\n",
            "Epoch 1383/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6527 - val_loss: 0.6423\n",
            "Epoch 1384/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6527 - val_loss: 0.6426\n",
            "Epoch 1385/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6527 - val_loss: 0.6425\n",
            "Epoch 1386/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6527 - val_loss: 0.6431\n",
            "Epoch 1387/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6527 - val_loss: 0.6434\n",
            "Epoch 1388/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6527 - val_loss: 0.6436\n",
            "Epoch 1389/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6527 - val_loss: 0.6444\n",
            "Epoch 1390/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6527 - val_loss: 0.6437\n",
            "Epoch 1391/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6527 - val_loss: 0.6439\n",
            "Epoch 1392/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6444\n",
            "Epoch 1393/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6527 - val_loss: 0.6448\n",
            "Epoch 1394/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6438\n",
            "Epoch 1395/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6527 - val_loss: 0.6443\n",
            "Epoch 1396/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6527 - val_loss: 0.6445\n",
            "Epoch 1397/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6527 - val_loss: 0.6450\n",
            "Epoch 1398/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6527 - val_loss: 0.6450\n",
            "Epoch 1399/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6450\n",
            "Epoch 1400/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6463\n",
            "Epoch 1401/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6527 - val_loss: 0.6461\n",
            "Epoch 1402/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6527 - val_loss: 0.6456\n",
            "Epoch 1403/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6452\n",
            "Epoch 1404/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6527 - val_loss: 0.6453\n",
            "Epoch 1405/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6527 - val_loss: 0.6454\n",
            "Epoch 1406/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6441\n",
            "Epoch 1407/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6527 - val_loss: 0.6449\n",
            "Epoch 1408/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6527 - val_loss: 0.6449\n",
            "Epoch 1409/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6527 - val_loss: 0.6446\n",
            "Epoch 1410/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6527 - val_loss: 0.6443\n",
            "Epoch 1411/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6527 - val_loss: 0.6448\n",
            "Epoch 1412/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6528 - val_loss: 0.6449\n",
            "Epoch 1413/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6527 - val_loss: 0.6453\n",
            "Epoch 1414/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6527 - val_loss: 0.6453\n",
            "Epoch 1415/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6527 - val_loss: 0.6446\n",
            "Epoch 1416/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6527 - val_loss: 0.6443\n",
            "Epoch 1417/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6527 - val_loss: 0.6445\n",
            "Epoch 1418/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6527 - val_loss: 0.6444\n",
            "Epoch 1419/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6455\n",
            "Epoch 1420/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6527 - val_loss: 0.6452\n",
            "Epoch 1421/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6526 - val_loss: 0.6454\n",
            "Epoch 1422/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6527 - val_loss: 0.6456\n",
            "Epoch 1423/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6527 - val_loss: 0.6461\n",
            "Epoch 1424/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6527 - val_loss: 0.6457\n",
            "Epoch 1425/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6527 - val_loss: 0.6454\n",
            "Epoch 1426/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6450\n",
            "Epoch 1427/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6527 - val_loss: 0.6451\n",
            "Epoch 1428/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6526 - val_loss: 0.6456\n",
            "Epoch 1429/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6527 - val_loss: 0.6457\n",
            "Epoch 1430/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6527 - val_loss: 0.6451\n",
            "Epoch 1431/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6527 - val_loss: 0.6456\n",
            "Epoch 1432/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6526 - val_loss: 0.6456\n",
            "Epoch 1433/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6527 - val_loss: 0.6451\n",
            "Epoch 1434/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6527 - val_loss: 0.6455\n",
            "Epoch 1435/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6449\n",
            "Epoch 1436/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6527 - val_loss: 0.6449\n",
            "Epoch 1437/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6527 - val_loss: 0.6457\n",
            "Epoch 1438/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6527 - val_loss: 0.6462\n",
            "Epoch 1439/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6527 - val_loss: 0.6457\n",
            "Epoch 1440/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6527 - val_loss: 0.6451\n",
            "Epoch 1441/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6527 - val_loss: 0.6449\n",
            "Epoch 1442/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6527 - val_loss: 0.6457\n",
            "Epoch 1443/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6527 - val_loss: 0.6453\n",
            "Epoch 1444/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6527 - val_loss: 0.6455\n",
            "Epoch 1445/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6527 - val_loss: 0.6456\n",
            "Epoch 1446/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6444\n",
            "Epoch 1447/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6454\n",
            "Epoch 1448/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6526 - val_loss: 0.6444\n",
            "Epoch 1449/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6431\n",
            "Epoch 1450/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6527 - val_loss: 0.6430\n",
            "Epoch 1451/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6527 - val_loss: 0.6439\n",
            "Epoch 1452/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6428\n",
            "Epoch 1453/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6526 - val_loss: 0.6429\n",
            "Epoch 1454/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6527 - val_loss: 0.6430\n",
            "Epoch 1455/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6526 - val_loss: 0.6430\n",
            "Epoch 1456/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6527 - val_loss: 0.6421\n",
            "Epoch 1457/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6527 - val_loss: 0.6431\n",
            "Epoch 1458/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6527 - val_loss: 0.6434\n",
            "Epoch 1459/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6527 - val_loss: 0.6436\n",
            "Epoch 1460/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6527 - val_loss: 0.6428\n",
            "Epoch 1461/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6527 - val_loss: 0.6434\n",
            "Epoch 1462/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6527 - val_loss: 0.6434\n",
            "Epoch 1463/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6425\n",
            "Epoch 1464/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6527 - val_loss: 0.6426\n",
            "Epoch 1465/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6527 - val_loss: 0.6435\n",
            "Epoch 1466/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6527 - val_loss: 0.6423\n",
            "Epoch 1467/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6530 - val_loss: 0.6414\n",
            "Epoch 1468/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6527 - val_loss: 0.6425\n",
            "Epoch 1469/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6527 - val_loss: 0.6426\n",
            "Epoch 1470/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6527 - val_loss: 0.6429\n",
            "Epoch 1471/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6527 - val_loss: 0.6428\n",
            "Epoch 1472/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6527 - val_loss: 0.6434\n",
            "Epoch 1473/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6527 - val_loss: 0.6435\n",
            "Epoch 1474/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6526 - val_loss: 0.6438\n",
            "Epoch 1475/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6527 - val_loss: 0.6436\n",
            "Epoch 1476/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6527 - val_loss: 0.6442\n",
            "Epoch 1477/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6526 - val_loss: 0.6437\n",
            "Epoch 1478/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6527 - val_loss: 0.6441\n",
            "Epoch 1479/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6527 - val_loss: 0.6439\n",
            "Epoch 1480/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6526 - val_loss: 0.6437\n",
            "Epoch 1481/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6526 - val_loss: 0.6433\n",
            "Epoch 1482/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6526 - val_loss: 0.6429\n",
            "Epoch 1483/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6526 - val_loss: 0.6426\n",
            "Epoch 1484/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6527 - val_loss: 0.6427\n",
            "Epoch 1485/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6527 - val_loss: 0.6427\n",
            "Epoch 1486/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6527 - val_loss: 0.6433\n",
            "Epoch 1487/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6527 - val_loss: 0.6428\n",
            "Epoch 1488/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6526 - val_loss: 0.6428\n",
            "Epoch 1489/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6527 - val_loss: 0.6430\n",
            "Epoch 1490/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6526 - val_loss: 0.6422\n",
            "Epoch 1491/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6527 - val_loss: 0.6421\n",
            "Epoch 1492/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6526 - val_loss: 0.6421\n",
            "Epoch 1493/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6527 - val_loss: 0.6428\n",
            "Epoch 1494/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6420\n",
            "Epoch 1495/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6527 - val_loss: 0.6420\n",
            "Epoch 1496/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6434\n",
            "Epoch 1497/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6444\n",
            "Epoch 1498/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6446\n",
            "Epoch 1499/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6527 - val_loss: 0.6433\n",
            "Epoch 1500/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6527 - val_loss: 0.6438\n",
            "Epoch 1501/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6526 - val_loss: 0.6434\n",
            "Epoch 1502/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6527 - val_loss: 0.6441\n",
            "Epoch 1503/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6526 - val_loss: 0.6437\n",
            "Epoch 1504/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6527 - val_loss: 0.6440\n",
            "Epoch 1505/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6425\n",
            "Epoch 1506/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6436\n",
            "Epoch 1507/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6441\n",
            "Epoch 1508/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6526 - val_loss: 0.6439\n",
            "Epoch 1509/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6428\n",
            "Epoch 1510/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6526 - val_loss: 0.6430\n",
            "Epoch 1511/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6526 - val_loss: 0.6431\n",
            "Epoch 1512/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6526 - val_loss: 0.6431\n",
            "Epoch 1513/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6527 - val_loss: 0.6421\n",
            "Epoch 1514/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6527 - val_loss: 0.6420\n",
            "Epoch 1515/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6526 - val_loss: 0.6424\n",
            "Epoch 1516/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6526 - val_loss: 0.6421\n",
            "Epoch 1517/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6526 - val_loss: 0.6419\n",
            "Epoch 1518/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6526 - val_loss: 0.6417\n",
            "Epoch 1519/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6526 - val_loss: 0.6423\n",
            "Epoch 1520/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6527 - val_loss: 0.6424\n",
            "Epoch 1521/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6414\n",
            "Epoch 1522/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6526 - val_loss: 0.6420\n",
            "Epoch 1523/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6527 - val_loss: 0.6421\n",
            "Epoch 1524/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6527 - val_loss: 0.6433\n",
            "Epoch 1525/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6526 - val_loss: 0.6426\n",
            "Epoch 1526/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6527 - val_loss: 0.6426\n",
            "Epoch 1527/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6527 - val_loss: 0.6437\n",
            "Epoch 1528/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6526 - val_loss: 0.6432\n",
            "Epoch 1529/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6526 - val_loss: 0.6432\n",
            "Epoch 1530/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6527 - val_loss: 0.6427\n",
            "Epoch 1531/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6526 - val_loss: 0.6429\n",
            "Epoch 1532/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6439\n",
            "Epoch 1533/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6526 - val_loss: 0.6432\n",
            "Epoch 1534/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6526 - val_loss: 0.6422\n",
            "Epoch 1535/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6527 - val_loss: 0.6426\n",
            "Epoch 1536/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6526 - val_loss: 0.6431\n",
            "Epoch 1537/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6527 - val_loss: 0.6425\n",
            "Epoch 1538/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6527 - val_loss: 0.6417\n",
            "Epoch 1539/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6526 - val_loss: 0.6416\n",
            "Epoch 1540/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6527 - val_loss: 0.6420\n",
            "Epoch 1541/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6526 - val_loss: 0.6422\n",
            "Epoch 1542/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6417\n",
            "Epoch 1543/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6526 - val_loss: 0.6419\n",
            "Epoch 1544/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6527 - val_loss: 0.6429\n",
            "Epoch 1545/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6526 - val_loss: 0.6425\n",
            "Epoch 1546/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6526 - val_loss: 0.6429\n",
            "Epoch 1547/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6530 - val_loss: 0.6417\n",
            "Epoch 1548/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6526 - val_loss: 0.6423\n",
            "Epoch 1549/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6526 - val_loss: 0.6427\n",
            "Epoch 1550/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6437\n",
            "Epoch 1551/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6526 - val_loss: 0.6443\n",
            "Epoch 1552/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6430\n",
            "Epoch 1553/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6526 - val_loss: 0.6439\n",
            "Epoch 1554/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6527 - val_loss: 0.6444\n",
            "Epoch 1555/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6526 - val_loss: 0.6438\n",
            "Epoch 1556/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6527 - val_loss: 0.6427\n",
            "Epoch 1557/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6526 - val_loss: 0.6430\n",
            "Epoch 1558/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6527 - val_loss: 0.6433\n",
            "Epoch 1559/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6526 - val_loss: 0.6431\n",
            "Epoch 1560/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6527 - val_loss: 0.6434\n",
            "Epoch 1561/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6526 - val_loss: 0.6430\n",
            "Epoch 1562/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6526 - val_loss: 0.6422\n",
            "Epoch 1563/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6526 - val_loss: 0.6423\n",
            "Epoch 1564/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6526 - val_loss: 0.6424\n",
            "Epoch 1565/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6527 - val_loss: 0.6419\n",
            "Epoch 1566/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6527 - val_loss: 0.6416\n",
            "Epoch 1567/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6526 - val_loss: 0.6422\n",
            "Epoch 1568/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6526 - val_loss: 0.6420\n",
            "Epoch 1569/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6526 - val_loss: 0.6419\n",
            "Epoch 1570/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6526 - val_loss: 0.6422\n",
            "Epoch 1571/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6526 - val_loss: 0.6424\n",
            "Epoch 1572/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6526 - val_loss: 0.6428\n",
            "Epoch 1573/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6526 - val_loss: 0.6427\n",
            "Epoch 1574/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6527 - val_loss: 0.6425\n",
            "Epoch 1575/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6526 - val_loss: 0.6435\n",
            "Epoch 1576/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6426\n",
            "Epoch 1577/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6526 - val_loss: 0.6435\n",
            "Epoch 1578/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6449\n",
            "Epoch 1579/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6526 - val_loss: 0.6438\n",
            "Epoch 1580/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6526 - val_loss: 0.6438\n",
            "Epoch 1581/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6428\n",
            "Epoch 1582/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6526 - val_loss: 0.6437\n",
            "Epoch 1583/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6447\n",
            "Epoch 1584/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6526 - val_loss: 0.6437\n",
            "Epoch 1585/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6526 - val_loss: 0.6438\n",
            "Epoch 1586/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6526 - val_loss: 0.6437\n",
            "Epoch 1587/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6527 - val_loss: 0.6431\n",
            "Epoch 1588/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6526 - val_loss: 0.6426\n",
            "Epoch 1589/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6526 - val_loss: 0.6430\n",
            "Epoch 1590/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6526 - val_loss: 0.6429\n",
            "Epoch 1591/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6526 - val_loss: 0.6420\n",
            "Epoch 1592/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6529 - val_loss: 0.6411\n",
            "Epoch 1593/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6526 - val_loss: 0.6422\n",
            "Epoch 1594/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6529 - val_loss: 0.6434\n",
            "Epoch 1595/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6416\n",
            "Epoch 1596/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6530 - val_loss: 0.6433\n",
            "Epoch 1597/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6527 - val_loss: 0.6432\n",
            "Epoch 1598/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6527 - val_loss: 0.6421\n",
            "Epoch 1599/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6527 - val_loss: 0.6409\n",
            "Epoch 1600/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6526 - val_loss: 0.6412\n",
            "Epoch 1601/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6527 - val_loss: 0.6409\n",
            "Epoch 1602/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6526 - val_loss: 0.6410\n",
            "Epoch 1603/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6526 - val_loss: 0.6408\n",
            "Epoch 1604/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6527 - val_loss: 0.6406\n",
            "Epoch 1605/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6527 - val_loss: 0.6418\n",
            "Epoch 1606/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6526 - val_loss: 0.6418\n",
            "Epoch 1607/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6528 - val_loss: 0.6404\n",
            "Epoch 1608/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6421\n",
            "Epoch 1609/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6526 - val_loss: 0.6417\n",
            "Epoch 1610/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6528 - val_loss: 0.6425\n",
            "Epoch 1611/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6526 - val_loss: 0.6417\n",
            "Epoch 1612/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6527 - val_loss: 0.6407\n",
            "Epoch 1613/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6526 - val_loss: 0.6412\n",
            "Epoch 1614/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6526 - val_loss: 0.6412\n",
            "Epoch 1615/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6527 - val_loss: 0.6417\n",
            "Epoch 1616/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6526 - val_loss: 0.6417\n",
            "Epoch 1617/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6526 - val_loss: 0.6417\n",
            "Epoch 1618/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6527 - val_loss: 0.6417\n",
            "Epoch 1619/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6526 - val_loss: 0.6420\n",
            "Epoch 1620/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6526 - val_loss: 0.6427\n",
            "Epoch 1621/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6526 - val_loss: 0.6425\n",
            "Epoch 1622/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6526 - val_loss: 0.6420\n",
            "Epoch 1623/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6526 - val_loss: 0.6421\n",
            "Epoch 1624/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6526 - val_loss: 0.6419\n",
            "Epoch 1625/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6526 - val_loss: 0.6418\n",
            "Epoch 1626/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6527 - val_loss: 0.6415\n",
            "Epoch 1627/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6526 - val_loss: 0.6420\n",
            "Epoch 1628/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6526 - val_loss: 0.6425\n",
            "Epoch 1629/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6526 - val_loss: 0.6420\n",
            "Epoch 1630/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6526 - val_loss: 0.6420\n",
            "Epoch 1631/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6527 - val_loss: 0.6413\n",
            "Epoch 1632/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6527 - val_loss: 0.6412\n",
            "Epoch 1633/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6527 - val_loss: 0.6421\n",
            "Epoch 1634/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6526 - val_loss: 0.6420\n",
            "Epoch 1635/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6526 - val_loss: 0.6421\n",
            "Epoch 1636/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6526 - val_loss: 0.6420\n",
            "Epoch 1637/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6527 - val_loss: 0.6426\n",
            "Epoch 1638/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6526 - val_loss: 0.6430\n",
            "Epoch 1639/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6526 - val_loss: 0.6418\n",
            "Epoch 1640/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6526 - val_loss: 0.6419\n",
            "Epoch 1641/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6527 - val_loss: 0.6424\n",
            "Epoch 1642/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6526 - val_loss: 0.6420\n",
            "Epoch 1643/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6525 - val_loss: 0.6425\n",
            "Epoch 1644/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6526 - val_loss: 0.6428\n",
            "Epoch 1645/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6526 - val_loss: 0.6422\n",
            "Epoch 1646/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6527 - val_loss: 0.6417\n",
            "Epoch 1647/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6526 - val_loss: 0.6425\n",
            "Epoch 1648/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6436\n",
            "Epoch 1649/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6526 - val_loss: 0.6433\n",
            "Epoch 1650/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6526 - val_loss: 0.6428\n",
            "Epoch 1651/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6527 - val_loss: 0.6428\n",
            "Epoch 1652/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6526 - val_loss: 0.6428\n",
            "Epoch 1653/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6526 - val_loss: 0.6434\n",
            "Epoch 1654/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6527 - val_loss: 0.6424\n",
            "Epoch 1655/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6527 - val_loss: 0.6418\n",
            "Epoch 1656/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6526 - val_loss: 0.6421\n",
            "Epoch 1657/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6526 - val_loss: 0.6431\n",
            "Epoch 1658/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6526 - val_loss: 0.6430\n",
            "Epoch 1659/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6525 - val_loss: 0.6429\n",
            "Epoch 1660/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6525 - val_loss: 0.6430\n",
            "Epoch 1661/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6526 - val_loss: 0.6434\n",
            "Epoch 1662/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6527 - val_loss: 0.6427\n",
            "Epoch 1663/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6526 - val_loss: 0.6428\n",
            "Epoch 1664/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6526 - val_loss: 0.6433\n",
            "Epoch 1665/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6529 - val_loss: 0.6445\n",
            "Epoch 1666/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6527 - val_loss: 0.6434\n",
            "Epoch 1667/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6525 - val_loss: 0.6440\n",
            "Epoch 1668/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6526 - val_loss: 0.6449\n",
            "Epoch 1669/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6525 - val_loss: 0.6449\n",
            "Epoch 1670/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6526 - val_loss: 0.6443\n",
            "Epoch 1671/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6528 - val_loss: 0.6435\n",
            "Epoch 1672/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6527 - val_loss: 0.6435\n",
            "Epoch 1673/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6525 - val_loss: 0.6443\n",
            "Epoch 1674/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6526 - val_loss: 0.6451\n",
            "Epoch 1675/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6462\n",
            "Epoch 1676/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6526 - val_loss: 0.6447\n",
            "Epoch 1677/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6526 - val_loss: 0.6438\n",
            "Epoch 1678/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6527 - val_loss: 0.6447\n",
            "Epoch 1679/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6525 - val_loss: 0.6444\n",
            "Epoch 1680/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6525 - val_loss: 0.6445\n",
            "Epoch 1681/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6526 - val_loss: 0.6445\n",
            "Epoch 1682/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6526 - val_loss: 0.6447\n",
            "Epoch 1683/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6525 - val_loss: 0.6442\n",
            "Epoch 1684/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6431\n",
            "Epoch 1685/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6526 - val_loss: 0.6443\n",
            "Epoch 1686/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6526 - val_loss: 0.6439\n",
            "Epoch 1687/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6525 - val_loss: 0.6438\n",
            "Epoch 1688/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6526 - val_loss: 0.6441\n",
            "Epoch 1689/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6526 - val_loss: 0.6442\n",
            "Epoch 1690/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6525 - val_loss: 0.6443\n",
            "Epoch 1691/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6526 - val_loss: 0.6444\n",
            "Epoch 1692/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6527 - val_loss: 0.6437\n",
            "Epoch 1693/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6525 - val_loss: 0.6445\n",
            "Epoch 1694/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6457\n",
            "Epoch 1695/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6525 - val_loss: 0.6448\n",
            "Epoch 1696/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6529 - val_loss: 0.6425\n",
            "Epoch 1697/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6526 - val_loss: 0.6423\n",
            "Epoch 1698/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6526 - val_loss: 0.6424\n",
            "Epoch 1699/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6525 - val_loss: 0.6431\n",
            "Epoch 1700/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6527 - val_loss: 0.6444\n",
            "Epoch 1701/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6526 - val_loss: 0.6433\n",
            "Epoch 1702/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6526 - val_loss: 0.6434\n",
            "Epoch 1703/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6526 - val_loss: 0.6434\n",
            "Epoch 1704/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6526 - val_loss: 0.6438\n",
            "Epoch 1705/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6527 - val_loss: 0.6423\n",
            "Epoch 1706/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6526 - val_loss: 0.6428\n",
            "Epoch 1707/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6525 - val_loss: 0.6423\n",
            "Epoch 1708/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6526 - val_loss: 0.6418\n",
            "Epoch 1709/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6527 - val_loss: 0.6427\n",
            "Epoch 1710/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6526 - val_loss: 0.6421\n",
            "Epoch 1711/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6526 - val_loss: 0.6423\n",
            "Epoch 1712/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6526 - val_loss: 0.6417\n",
            "Epoch 1713/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6526 - val_loss: 0.6415\n",
            "Epoch 1714/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6525 - val_loss: 0.6416\n",
            "Epoch 1715/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6526 - val_loss: 0.6410\n",
            "Epoch 1716/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6528 - val_loss: 0.6401\n",
            "Epoch 1717/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6525 - val_loss: 0.6405\n",
            "Epoch 1718/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6525 - val_loss: 0.6414\n",
            "Epoch 1719/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6527 - val_loss: 0.6410\n",
            "Epoch 1720/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6526 - val_loss: 0.6413\n",
            "Epoch 1721/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6526 - val_loss: 0.6420\n",
            "Epoch 1722/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6526 - val_loss: 0.6417\n",
            "Epoch 1723/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6525 - val_loss: 0.6421\n",
            "Epoch 1724/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6525 - val_loss: 0.6428\n",
            "Epoch 1725/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6526 - val_loss: 0.6431\n",
            "Epoch 1726/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6526 - val_loss: 0.6424\n",
            "Epoch 1727/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6526 - val_loss: 0.6424\n",
            "Epoch 1728/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6526 - val_loss: 0.6419\n",
            "Epoch 1729/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6526 - val_loss: 0.6428\n",
            "Epoch 1730/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6526 - val_loss: 0.6422\n",
            "Epoch 1731/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6526 - val_loss: 0.6424\n",
            "Epoch 1732/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6525 - val_loss: 0.6426\n",
            "Epoch 1733/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6526 - val_loss: 0.6429\n",
            "Epoch 1734/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6525 - val_loss: 0.6425\n",
            "Epoch 1735/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6526 - val_loss: 0.6430\n",
            "Epoch 1736/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6526 - val_loss: 0.6425\n",
            "Epoch 1737/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6525 - val_loss: 0.6432\n",
            "Epoch 1738/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6526 - val_loss: 0.6436\n",
            "Epoch 1739/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6526 - val_loss: 0.6435\n",
            "Epoch 1740/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6525 - val_loss: 0.6438\n",
            "Epoch 1741/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6526 - val_loss: 0.6437\n",
            "Epoch 1742/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6526 - val_loss: 0.6453\n",
            "Epoch 1743/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6526 - val_loss: 0.6447\n",
            "Epoch 1744/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6526 - val_loss: 0.6441\n",
            "Epoch 1745/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6525 - val_loss: 0.6446\n",
            "Epoch 1746/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6525 - val_loss: 0.6442\n",
            "Epoch 1747/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6526 - val_loss: 0.6445\n",
            "Epoch 1748/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6526 - val_loss: 0.6444\n",
            "Epoch 1749/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6526 - val_loss: 0.6444\n",
            "Epoch 1750/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6525 - val_loss: 0.6442\n",
            "Epoch 1751/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6526 - val_loss: 0.6446\n",
            "Epoch 1752/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6526 - val_loss: 0.6437\n",
            "Epoch 1753/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6526 - val_loss: 0.6449\n",
            "Epoch 1754/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6527 - val_loss: 0.6455\n",
            "Epoch 1755/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6526 - val_loss: 0.6455\n",
            "Epoch 1756/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6526 - val_loss: 0.6445\n",
            "Epoch 1757/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6526 - val_loss: 0.6445\n",
            "Epoch 1758/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6525 - val_loss: 0.6451\n",
            "Epoch 1759/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6526 - val_loss: 0.6451\n",
            "Epoch 1760/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6525 - val_loss: 0.6447\n",
            "Epoch 1761/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6525 - val_loss: 0.6444\n",
            "Epoch 1762/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6525 - val_loss: 0.6437\n",
            "Epoch 1763/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6525 - val_loss: 0.6438\n",
            "Epoch 1764/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6526 - val_loss: 0.6436\n",
            "Epoch 1765/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6526 - val_loss: 0.6430\n",
            "Epoch 1766/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6525 - val_loss: 0.6434\n",
            "Epoch 1767/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6525 - val_loss: 0.6436\n",
            "Epoch 1768/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6526 - val_loss: 0.6442\n",
            "Epoch 1769/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6527 - val_loss: 0.6431\n",
            "Epoch 1770/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6525 - val_loss: 0.6432\n",
            "Epoch 1771/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6526 - val_loss: 0.6442\n",
            "Epoch 1772/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6424\n",
            "Epoch 1773/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6525 - val_loss: 0.6431\n",
            "Epoch 1774/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6525 - val_loss: 0.6437\n",
            "Epoch 1775/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6526 - val_loss: 0.6433\n",
            "Epoch 1776/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6443\n",
            "Epoch 1777/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6525 - val_loss: 0.6437\n",
            "Epoch 1778/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6526 - val_loss: 0.6444\n",
            "Epoch 1779/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6526 - val_loss: 0.6433\n",
            "Epoch 1780/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6526 - val_loss: 0.6430\n",
            "Epoch 1781/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6525 - val_loss: 0.6434\n",
            "Epoch 1782/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6526 - val_loss: 0.6427\n",
            "Epoch 1783/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6525 - val_loss: 0.6433\n",
            "Epoch 1784/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6525 - val_loss: 0.6438\n",
            "Epoch 1785/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6528 - val_loss: 0.6448\n",
            "Epoch 1786/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6525 - val_loss: 0.6446\n",
            "Epoch 1787/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6525 - val_loss: 0.6446\n",
            "Epoch 1788/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6525 - val_loss: 0.6439\n",
            "Epoch 1789/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6526 - val_loss: 0.6442\n",
            "Epoch 1790/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6526 - val_loss: 0.6443\n",
            "Epoch 1791/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6527 - val_loss: 0.6435\n",
            "Epoch 1792/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6525 - val_loss: 0.6438\n",
            "Epoch 1793/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6525 - val_loss: 0.6436\n",
            "Epoch 1794/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6527 - val_loss: 0.6447\n",
            "Epoch 1795/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6525 - val_loss: 0.6434\n",
            "Epoch 1796/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6526 - val_loss: 0.6429\n",
            "Epoch 1797/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6525 - val_loss: 0.6433\n",
            "Epoch 1798/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6525 - val_loss: 0.6428\n",
            "Epoch 1799/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6526 - val_loss: 0.6424\n",
            "Epoch 1800/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6525 - val_loss: 0.6430\n",
            "Epoch 1801/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6526 - val_loss: 0.6428\n",
            "Epoch 1802/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6525 - val_loss: 0.6435\n",
            "Epoch 1803/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6526 - val_loss: 0.6432\n",
            "Epoch 1804/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6527 - val_loss: 0.6438\n",
            "Epoch 1805/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6526 - val_loss: 0.6437\n",
            "Epoch 1806/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6527 - val_loss: 0.6448\n",
            "Epoch 1807/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6525 - val_loss: 0.6447\n",
            "Epoch 1808/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6525 - val_loss: 0.6443\n",
            "Epoch 1809/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6525 - val_loss: 0.6443\n",
            "Epoch 1810/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6526 - val_loss: 0.6450\n",
            "Epoch 1811/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6528 - val_loss: 0.6436\n",
            "Epoch 1812/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6525 - val_loss: 0.6441\n",
            "Epoch 1813/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6456\n",
            "Epoch 1814/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6526 - val_loss: 0.6450\n",
            "Epoch 1815/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6525 - val_loss: 0.6440\n",
            "Epoch 1816/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6525 - val_loss: 0.6445\n",
            "Epoch 1817/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6526 - val_loss: 0.6447\n",
            "Epoch 1818/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6525 - val_loss: 0.6442\n",
            "Epoch 1819/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6527 - val_loss: 0.6449\n",
            "Epoch 1820/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6524 - val_loss: 0.6437\n",
            "Epoch 1821/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6525 - val_loss: 0.6432\n",
            "Epoch 1822/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6525 - val_loss: 0.6427\n",
            "Epoch 1823/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6526 - val_loss: 0.6435\n",
            "Epoch 1824/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6526 - val_loss: 0.6435\n",
            "Epoch 1825/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6525 - val_loss: 0.6435\n",
            "Epoch 1826/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6526 - val_loss: 0.6434\n",
            "Epoch 1827/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6525 - val_loss: 0.6433\n",
            "Epoch 1828/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6525 - val_loss: 0.6439\n",
            "Epoch 1829/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6525 - val_loss: 0.6440\n",
            "Epoch 1830/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6527 - val_loss: 0.6422\n",
            "Epoch 1831/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6526 - val_loss: 0.6430\n",
            "Epoch 1832/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6527 - val_loss: 0.6417\n",
            "Epoch 1833/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6526 - val_loss: 0.6430\n",
            "Epoch 1834/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6527 - val_loss: 0.6419\n",
            "Epoch 1835/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6525 - val_loss: 0.6423\n",
            "Epoch 1836/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6526 - val_loss: 0.6423\n",
            "Epoch 1837/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6525 - val_loss: 0.6429\n",
            "Epoch 1838/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6525 - val_loss: 0.6427\n",
            "Epoch 1839/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6526 - val_loss: 0.6438\n",
            "Epoch 1840/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6525 - val_loss: 0.6432\n",
            "Epoch 1841/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6526 - val_loss: 0.6442\n",
            "Epoch 1842/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6524 - val_loss: 0.6437\n",
            "Epoch 1843/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6525 - val_loss: 0.6434\n",
            "Epoch 1844/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6526 - val_loss: 0.6428\n",
            "Epoch 1845/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6527 - val_loss: 0.6438\n",
            "Epoch 1846/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6527 - val_loss: 0.6419\n",
            "Epoch 1847/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6526 - val_loss: 0.6417\n",
            "Epoch 1848/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6525 - val_loss: 0.6421\n",
            "Epoch 1849/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6526 - val_loss: 0.6415\n",
            "Epoch 1850/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6525 - val_loss: 0.6421\n",
            "Epoch 1851/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6525 - val_loss: 0.6421\n",
            "Epoch 1852/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6525 - val_loss: 0.6425\n",
            "Epoch 1853/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6526 - val_loss: 0.6423\n",
            "Epoch 1854/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6527 - val_loss: 0.6436\n",
            "Epoch 1855/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6526 - val_loss: 0.6426\n",
            "Epoch 1856/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6528 - val_loss: 0.6445\n",
            "Epoch 1857/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6525 - val_loss: 0.6440\n",
            "Epoch 1858/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6525 - val_loss: 0.6435\n",
            "Epoch 1859/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6526 - val_loss: 0.6440\n",
            "Epoch 1860/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6526 - val_loss: 0.6444\n",
            "Epoch 1861/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6526 - val_loss: 0.6434\n",
            "Epoch 1862/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6525 - val_loss: 0.6435\n",
            "Epoch 1863/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6525 - val_loss: 0.6435\n",
            "Epoch 1864/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6525 - val_loss: 0.6442\n",
            "Epoch 1865/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6525 - val_loss: 0.6440\n",
            "Epoch 1866/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6525 - val_loss: 0.6434\n",
            "Epoch 1867/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6525 - val_loss: 0.6443\n",
            "Epoch 1868/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6525 - val_loss: 0.6437\n",
            "Epoch 1869/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6526 - val_loss: 0.6432\n",
            "Epoch 1870/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6525 - val_loss: 0.6431\n",
            "Epoch 1871/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6525 - val_loss: 0.6436\n",
            "Epoch 1872/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6524 - val_loss: 0.6441\n",
            "Epoch 1873/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6525 - val_loss: 0.6448\n",
            "Epoch 1874/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6525 - val_loss: 0.6446\n",
            "Epoch 1875/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6525 - val_loss: 0.6452\n",
            "Epoch 1876/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6526 - val_loss: 0.6458\n",
            "Epoch 1877/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6525 - val_loss: 0.6456\n",
            "Epoch 1878/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6526 - val_loss: 0.6445\n",
            "Epoch 1879/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6524 - val_loss: 0.6449\n",
            "Epoch 1880/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6527 - val_loss: 0.6460\n",
            "Epoch 1881/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6525 - val_loss: 0.6448\n",
            "Epoch 1882/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6526 - val_loss: 0.6458\n",
            "Epoch 1883/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6526 - val_loss: 0.6447\n",
            "Epoch 1884/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6525 - val_loss: 0.6444\n",
            "Epoch 1885/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6525 - val_loss: 0.6451\n",
            "Epoch 1886/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6526 - val_loss: 0.6457\n",
            "Epoch 1887/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6525 - val_loss: 0.6444\n",
            "Epoch 1888/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6525 - val_loss: 0.6443\n",
            "Epoch 1889/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6525 - val_loss: 0.6435\n",
            "Epoch 1890/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6524 - val_loss: 0.6433\n",
            "Epoch 1891/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6524 - val_loss: 0.6430\n",
            "Epoch 1892/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6525 - val_loss: 0.6434\n",
            "Epoch 1893/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6525 - val_loss: 0.6430\n",
            "Epoch 1894/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6525 - val_loss: 0.6430\n",
            "Epoch 1895/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6525 - val_loss: 0.6437\n",
            "Epoch 1896/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6525 - val_loss: 0.6443\n",
            "Epoch 1897/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6525 - val_loss: 0.6441\n",
            "Epoch 1898/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6525 - val_loss: 0.6436\n",
            "Epoch 1899/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6526 - val_loss: 0.6441\n",
            "Epoch 1900/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6525 - val_loss: 0.6431\n",
            "Epoch 1901/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6525 - val_loss: 0.6434\n",
            "Epoch 1902/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6525 - val_loss: 0.6433\n",
            "Epoch 1903/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6526 - val_loss: 0.6423\n",
            "Epoch 1904/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6525 - val_loss: 0.6420\n",
            "Epoch 1905/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6525 - val_loss: 0.6431\n",
            "Epoch 1906/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6525 - val_loss: 0.6436\n",
            "Epoch 1907/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6524 - val_loss: 0.6435\n",
            "Epoch 1908/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6525 - val_loss: 0.6435\n",
            "Epoch 1909/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6526 - val_loss: 0.6440\n",
            "Epoch 1910/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6524 - val_loss: 0.6436\n",
            "Epoch 1911/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6525 - val_loss: 0.6429\n",
            "Epoch 1912/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6525 - val_loss: 0.6430\n",
            "Epoch 1913/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6525 - val_loss: 0.6431\n",
            "Epoch 1914/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6525 - val_loss: 0.6428\n",
            "Epoch 1915/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6526 - val_loss: 0.6423\n",
            "Epoch 1916/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6527 - val_loss: 0.6438\n",
            "Epoch 1917/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6526 - val_loss: 0.6425\n",
            "Epoch 1918/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6526 - val_loss: 0.6434\n",
            "Epoch 1919/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6524 - val_loss: 0.6431\n",
            "Epoch 1920/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6525 - val_loss: 0.6431\n",
            "Epoch 1921/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6525 - val_loss: 0.6423\n",
            "Epoch 1922/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6526 - val_loss: 0.6418\n",
            "Epoch 1923/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6526 - val_loss: 0.6414\n",
            "Epoch 1924/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6524 - val_loss: 0.6420\n",
            "Epoch 1925/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6525 - val_loss: 0.6433\n",
            "Epoch 1926/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6525 - val_loss: 0.6434\n",
            "Epoch 1927/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6525 - val_loss: 0.6431\n",
            "Epoch 1928/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6525 - val_loss: 0.6423\n",
            "Epoch 1929/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6525 - val_loss: 0.6422\n",
            "Epoch 1930/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6525 - val_loss: 0.6420\n",
            "Epoch 1931/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6525 - val_loss: 0.6417\n",
            "Epoch 1932/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6525 - val_loss: 0.6419\n",
            "Epoch 1933/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6526 - val_loss: 0.6409\n",
            "Epoch 1934/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6525 - val_loss: 0.6416\n",
            "Epoch 1935/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6525 - val_loss: 0.6416\n",
            "Epoch 1936/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6525 - val_loss: 0.6418\n",
            "Epoch 1937/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6525 - val_loss: 0.6424\n",
            "Epoch 1938/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6526 - val_loss: 0.6431\n",
            "Epoch 1939/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6526 - val_loss: 0.6416\n",
            "Epoch 1940/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6525 - val_loss: 0.6415\n",
            "Epoch 1941/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6526 - val_loss: 0.6424\n",
            "Epoch 1942/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6525 - val_loss: 0.6422\n",
            "Epoch 1943/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6525 - val_loss: 0.6419\n",
            "Epoch 1944/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6524 - val_loss: 0.6424\n",
            "Epoch 1945/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6524 - val_loss: 0.6427\n",
            "Epoch 1946/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6524 - val_loss: 0.6429\n",
            "Epoch 1947/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6525 - val_loss: 0.6435\n",
            "Epoch 1948/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.6450\n",
            "Epoch 1949/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6525 - val_loss: 0.6435\n",
            "Epoch 1950/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6525 - val_loss: 0.6439\n",
            "Epoch 1951/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6530 - val_loss: 0.6416\n",
            "Epoch 1952/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6526 - val_loss: 0.6434\n",
            "Epoch 1953/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6525 - val_loss: 0.6432\n",
            "Epoch 1954/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6525 - val_loss: 0.6432\n",
            "Epoch 1955/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6525 - val_loss: 0.6429\n",
            "Epoch 1956/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6524 - val_loss: 0.6426\n",
            "Epoch 1957/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6525 - val_loss: 0.6430\n",
            "Epoch 1958/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6524 - val_loss: 0.6426\n",
            "Epoch 1959/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6525 - val_loss: 0.6426\n",
            "Epoch 1960/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6525 - val_loss: 0.6434\n",
            "Epoch 1961/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6524 - val_loss: 0.6426\n",
            "Epoch 1962/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6526 - val_loss: 0.6434\n",
            "Epoch 1963/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6525 - val_loss: 0.6436\n",
            "Epoch 1964/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6525 - val_loss: 0.6433\n",
            "Epoch 1965/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6526 - val_loss: 0.6429\n",
            "Epoch 1966/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6526 - val_loss: 0.6429\n",
            "Epoch 1967/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6526 - val_loss: 0.6414\n",
            "Epoch 1968/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6524 - val_loss: 0.6418\n",
            "Epoch 1969/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6525 - val_loss: 0.6426\n",
            "Epoch 1970/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6524 - val_loss: 0.6419\n",
            "Epoch 1971/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6525 - val_loss: 0.6415\n",
            "Epoch 1972/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6524 - val_loss: 0.6421\n",
            "Epoch 1973/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6525 - val_loss: 0.6422\n",
            "Epoch 1974/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6525 - val_loss: 0.6427\n",
            "Epoch 1975/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6525 - val_loss: 0.6418\n",
            "Epoch 1976/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6525 - val_loss: 0.6422\n",
            "Epoch 1977/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6528 - val_loss: 0.6435\n",
            "Epoch 1978/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6525 - val_loss: 0.6424\n",
            "Epoch 1979/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6524 - val_loss: 0.6422\n",
            "Epoch 1980/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6525 - val_loss: 0.6422\n",
            "Epoch 1981/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6525 - val_loss: 0.6433\n",
            "Epoch 1982/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6525 - val_loss: 0.6434\n",
            "Epoch 1983/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6526 - val_loss: 0.6441\n",
            "Epoch 1984/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6525 - val_loss: 0.6434\n",
            "Epoch 1985/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6525 - val_loss: 0.6438\n",
            "Epoch 1986/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6524 - val_loss: 0.6436\n",
            "Epoch 1987/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6525 - val_loss: 0.6440\n",
            "Epoch 1988/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6524 - val_loss: 0.6436\n",
            "Epoch 1989/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6525 - val_loss: 0.6432\n",
            "Epoch 1990/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6525 - val_loss: 0.6430\n",
            "Epoch 1991/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6527 - val_loss: 0.6417\n",
            "Epoch 1992/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6524 - val_loss: 0.6427\n",
            "Epoch 1993/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6524 - val_loss: 0.6430\n",
            "Epoch 1994/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6525 - val_loss: 0.6439\n",
            "Epoch 1995/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6527 - val_loss: 0.6424\n",
            "Epoch 1996/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6525 - val_loss: 0.6420\n",
            "Epoch 1997/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6525 - val_loss: 0.6425\n",
            "Epoch 1998/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6524 - val_loss: 0.6428\n",
            "Epoch 1999/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6524 - val_loss: 0.6430\n",
            "Epoch 2000/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6525 - val_loss: 0.6425\n",
            "Epoch 2001/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6525 - val_loss: 0.6423\n",
            "Epoch 2002/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6524 - val_loss: 0.6427\n",
            "Epoch 2003/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6525 - val_loss: 0.6436\n",
            "Epoch 2004/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6524 - val_loss: 0.6436\n",
            "Epoch 2005/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6524 - val_loss: 0.6436\n",
            "Epoch 2006/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6526 - val_loss: 0.6427\n",
            "Epoch 2007/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6524 - val_loss: 0.6430\n",
            "Epoch 2008/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6526 - val_loss: 0.6438\n",
            "Epoch 2009/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6524 - val_loss: 0.6437\n",
            "Epoch 2010/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6524 - val_loss: 0.6436\n",
            "Epoch 2011/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6527 - val_loss: 0.6448\n",
            "Epoch 2012/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6526 - val_loss: 0.6430\n",
            "Epoch 2013/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6525 - val_loss: 0.6432\n",
            "Epoch 2014/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6525 - val_loss: 0.6440\n",
            "Epoch 2015/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6525 - val_loss: 0.6432\n",
            "Epoch 2016/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6526 - val_loss: 0.6418\n",
            "Epoch 2017/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6526 - val_loss: 0.6429\n",
            "Epoch 2018/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6525 - val_loss: 0.6430\n",
            "Epoch 2019/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6524 - val_loss: 0.6429\n",
            "Epoch 2020/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6525 - val_loss: 0.6423\n",
            "Epoch 2021/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6524 - val_loss: 0.6425\n",
            "Epoch 2022/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6525 - val_loss: 0.6425\n",
            "Epoch 2023/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6525 - val_loss: 0.6435\n",
            "Epoch 2024/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6525 - val_loss: 0.6427\n",
            "Epoch 2025/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6525 - val_loss: 0.6434\n",
            "Epoch 2026/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6524 - val_loss: 0.6436\n",
            "Epoch 2027/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6524 - val_loss: 0.6433\n",
            "Epoch 2028/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6524 - val_loss: 0.6435\n",
            "Epoch 2029/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6524 - val_loss: 0.6434\n",
            "Epoch 2030/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6524 - val_loss: 0.6434\n",
            "Epoch 2031/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6524 - val_loss: 0.6442\n",
            "Epoch 2032/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6524 - val_loss: 0.6441\n",
            "Epoch 2033/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6525 - val_loss: 0.6439\n",
            "Epoch 2034/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6524 - val_loss: 0.6435\n",
            "Epoch 2035/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6526 - val_loss: 0.6426\n",
            "Epoch 2036/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6524 - val_loss: 0.6426\n",
            "Epoch 2037/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6524 - val_loss: 0.6426\n",
            "Epoch 2038/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6525 - val_loss: 0.6420\n",
            "Epoch 2039/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6524 - val_loss: 0.6428\n",
            "Epoch 2040/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6525 - val_loss: 0.6425\n",
            "Epoch 2041/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6524 - val_loss: 0.6428\n",
            "Epoch 2042/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6524 - val_loss: 0.6437\n",
            "Epoch 2043/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6524 - val_loss: 0.6433\n",
            "Epoch 2044/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6526 - val_loss: 0.6426\n",
            "Epoch 2045/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6524 - val_loss: 0.6434\n",
            "Epoch 2046/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6525 - val_loss: 0.6442\n",
            "Epoch 2047/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6527 - val_loss: 0.6431\n",
            "Epoch 2048/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6524 - val_loss: 0.6439\n",
            "Epoch 2049/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6524 - val_loss: 0.6443\n",
            "Epoch 2050/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6525 - val_loss: 0.6435\n",
            "Epoch 2051/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6525 - val_loss: 0.6440\n",
            "Epoch 2052/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6525 - val_loss: 0.6448\n",
            "Epoch 2053/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6524 - val_loss: 0.6444\n",
            "Epoch 2054/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6524 - val_loss: 0.6449\n",
            "Epoch 2055/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6525 - val_loss: 0.6455\n",
            "Epoch 2056/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6524 - val_loss: 0.6454\n",
            "Epoch 2057/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6526 - val_loss: 0.6441\n",
            "Epoch 2058/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6524 - val_loss: 0.6449\n",
            "Epoch 2059/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6527 - val_loss: 0.6437\n",
            "Epoch 2060/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6524 - val_loss: 0.6447\n",
            "Epoch 2061/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6524 - val_loss: 0.6446\n",
            "Epoch 2062/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6525 - val_loss: 0.6455\n",
            "Epoch 2063/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6524 - val_loss: 0.6457\n",
            "Epoch 2064/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6524 - val_loss: 0.6451\n",
            "Epoch 2065/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6524 - val_loss: 0.6455\n",
            "Epoch 2066/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6525 - val_loss: 0.6461\n",
            "Epoch 2067/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6524 - val_loss: 0.6459\n",
            "Epoch 2068/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6525 - val_loss: 0.6453\n",
            "Epoch 2069/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6524 - val_loss: 0.6461\n",
            "Epoch 2070/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6525 - val_loss: 0.6470\n",
            "Epoch 2071/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6525 - val_loss: 0.6457\n",
            "Epoch 2072/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6524 - val_loss: 0.6455\n",
            "Epoch 2073/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6524 - val_loss: 0.6448\n",
            "Epoch 2074/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6525 - val_loss: 0.6444\n",
            "Epoch 2075/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6524 - val_loss: 0.6448\n",
            "Epoch 2076/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6524 - val_loss: 0.6448\n",
            "Epoch 2077/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6524 - val_loss: 0.6449\n",
            "Epoch 2078/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6525 - val_loss: 0.6441\n",
            "Epoch 2079/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6524 - val_loss: 0.6449\n",
            "Epoch 2080/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6524 - val_loss: 0.6450\n",
            "Epoch 2081/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6524 - val_loss: 0.6445\n",
            "Epoch 2082/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6524 - val_loss: 0.6450\n",
            "Epoch 2083/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6524 - val_loss: 0.6454\n",
            "Epoch 2084/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6524 - val_loss: 0.6449\n",
            "Epoch 2085/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6524 - val_loss: 0.6446\n",
            "Epoch 2086/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6524 - val_loss: 0.6446\n",
            "Epoch 2087/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6524 - val_loss: 0.6440\n",
            "Epoch 2088/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6525 - val_loss: 0.6447\n",
            "Epoch 2089/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6526 - val_loss: 0.6436\n",
            "Epoch 2090/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6525 - val_loss: 0.6446\n",
            "Epoch 2091/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6526 - val_loss: 0.6450\n",
            "Epoch 2092/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6525 - val_loss: 0.6436\n",
            "Epoch 2093/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6524 - val_loss: 0.6436\n",
            "Epoch 2094/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6524 - val_loss: 0.6432\n",
            "Epoch 2095/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6524 - val_loss: 0.6433\n",
            "Epoch 2096/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6525 - val_loss: 0.6423\n",
            "Epoch 2097/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6524 - val_loss: 0.6433\n",
            "Epoch 2098/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6524 - val_loss: 0.6436\n",
            "Epoch 2099/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6525 - val_loss: 0.6438\n",
            "Epoch 2100/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6524 - val_loss: 0.6440\n",
            "Epoch 2101/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6524 - val_loss: 0.6439\n",
            "Epoch 2102/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6524 - val_loss: 0.6443\n",
            "Epoch 2103/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6525 - val_loss: 0.6446\n",
            "Epoch 2104/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6525 - val_loss: 0.6434\n",
            "Epoch 2105/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6524 - val_loss: 0.6442\n",
            "Epoch 2106/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6524 - val_loss: 0.6437\n",
            "Epoch 2107/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6525 - val_loss: 0.6433\n",
            "Epoch 2108/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6525 - val_loss: 0.6434\n",
            "Epoch 2109/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6525 - val_loss: 0.6444\n",
            "Epoch 2110/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6524 - val_loss: 0.6443\n",
            "Epoch 2111/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6524 - val_loss: 0.6432\n",
            "Epoch 2112/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6524 - val_loss: 0.6437\n",
            "Epoch 2113/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6524 - val_loss: 0.6441\n",
            "Epoch 2114/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6524 - val_loss: 0.6440\n",
            "Epoch 2115/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6525 - val_loss: 0.6434\n",
            "Epoch 2116/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6525 - val_loss: 0.6446\n",
            "Epoch 2117/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6524 - val_loss: 0.6439\n",
            "Epoch 2118/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6524 - val_loss: 0.6441\n",
            "Epoch 2119/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6524 - val_loss: 0.6442\n",
            "Epoch 2120/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6524 - val_loss: 0.6444\n",
            "Epoch 2121/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6525 - val_loss: 0.6436\n",
            "Epoch 2122/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6524 - val_loss: 0.6443\n",
            "Epoch 2123/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6524 - val_loss: 0.6437\n",
            "Epoch 2124/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6524 - val_loss: 0.6429\n",
            "Epoch 2125/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6524 - val_loss: 0.6440\n",
            "Epoch 2126/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6524 - val_loss: 0.6440\n",
            "Epoch 2127/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6526 - val_loss: 0.6450\n",
            "Epoch 2128/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6524 - val_loss: 0.6436\n",
            "Epoch 2129/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6524 - val_loss: 0.6435\n",
            "Epoch 2130/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6525 - val_loss: 0.6445\n",
            "Epoch 2131/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6524 - val_loss: 0.6432\n",
            "Epoch 2132/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6523 - val_loss: 0.6431\n",
            "Epoch 2133/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6525 - val_loss: 0.6436\n",
            "Epoch 2134/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6525 - val_loss: 0.6429\n",
            "Epoch 2135/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6526 - val_loss: 0.6419\n",
            "Epoch 2136/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6525 - val_loss: 0.6433\n",
            "Epoch 2137/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6524 - val_loss: 0.6430\n",
            "Epoch 2138/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6524 - val_loss: 0.6427\n",
            "Epoch 2139/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6524 - val_loss: 0.6430\n",
            "Epoch 2140/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6525 - val_loss: 0.6424\n",
            "Epoch 2141/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6524 - val_loss: 0.6431\n",
            "Epoch 2142/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6524 - val_loss: 0.6431\n",
            "Epoch 2143/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6524 - val_loss: 0.6430\n",
            "Epoch 2144/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6525 - val_loss: 0.6438\n",
            "Epoch 2145/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6524 - val_loss: 0.6434\n",
            "Epoch 2146/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6525 - val_loss: 0.6441\n",
            "Epoch 2147/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6524 - val_loss: 0.6428\n",
            "Epoch 2148/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6525 - val_loss: 0.6423\n",
            "Epoch 2149/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6524 - val_loss: 0.6430\n",
            "Epoch 2150/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6526 - val_loss: 0.6438\n",
            "Epoch 2151/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6524 - val_loss: 0.6429\n",
            "Epoch 2152/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6525 - val_loss: 0.6439\n",
            "Epoch 2153/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6524 - val_loss: 0.6431\n",
            "Epoch 2154/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6524 - val_loss: 0.6438\n",
            "Epoch 2155/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6524 - val_loss: 0.6434\n",
            "Epoch 2156/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6524 - val_loss: 0.6431\n",
            "Epoch 2157/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6524 - val_loss: 0.6436\n",
            "Epoch 2158/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6524 - val_loss: 0.6441\n",
            "Epoch 2159/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6524 - val_loss: 0.6429\n",
            "Epoch 2160/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6524 - val_loss: 0.6432\n",
            "Epoch 2161/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6524 - val_loss: 0.6430\n",
            "Epoch 2162/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6524 - val_loss: 0.6435\n",
            "Epoch 2163/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6525 - val_loss: 0.6444\n",
            "Epoch 2164/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6524 - val_loss: 0.6443\n",
            "Epoch 2165/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6524 - val_loss: 0.6432\n",
            "Epoch 2166/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6524 - val_loss: 0.6429\n",
            "Epoch 2167/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6524 - val_loss: 0.6431\n",
            "Epoch 2168/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6524 - val_loss: 0.6428\n",
            "Epoch 2169/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6524 - val_loss: 0.6424\n",
            "Epoch 2170/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6523 - val_loss: 0.6428\n",
            "Epoch 2171/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6525 - val_loss: 0.6436\n",
            "Epoch 2172/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6524 - val_loss: 0.6435\n",
            "Epoch 2173/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6524 - val_loss: 0.6439\n",
            "Epoch 2174/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6527 - val_loss: 0.6420\n",
            "Epoch 2175/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6524 - val_loss: 0.6418\n",
            "Epoch 2176/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6524 - val_loss: 0.6426\n",
            "Epoch 2177/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6525 - val_loss: 0.6439\n",
            "Epoch 2178/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6524 - val_loss: 0.6436\n",
            "Epoch 2179/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6523 - val_loss: 0.6429\n",
            "Epoch 2180/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6524 - val_loss: 0.6427\n",
            "Epoch 2181/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6524 - val_loss: 0.6425\n",
            "Epoch 2182/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6524 - val_loss: 0.6420\n",
            "Epoch 2183/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6523 - val_loss: 0.6426\n",
            "Epoch 2184/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6525 - val_loss: 0.6431\n",
            "Epoch 2185/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6524 - val_loss: 0.6420\n",
            "Epoch 2186/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6525 - val_loss: 0.6421\n",
            "Epoch 2187/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 0.6437\n",
            "Epoch 2188/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6523 - val_loss: 0.6426\n",
            "Epoch 2189/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6524 - val_loss: 0.6422\n",
            "Epoch 2190/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6524 - val_loss: 0.6418\n",
            "Epoch 2191/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6524 - val_loss: 0.6418\n",
            "Epoch 2192/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6524 - val_loss: 0.6425\n",
            "Epoch 2193/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6524 - val_loss: 0.6430\n",
            "Epoch 2194/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6524 - val_loss: 0.6423\n",
            "Epoch 2195/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6525 - val_loss: 0.6429\n",
            "Epoch 2196/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6523 - val_loss: 0.6430\n",
            "Epoch 2197/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6524 - val_loss: 0.6431\n",
            "Epoch 2198/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6524 - val_loss: 0.6430\n",
            "Epoch 2199/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6523 - val_loss: 0.6421\n",
            "Epoch 2200/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6524 - val_loss: 0.6416\n",
            "Epoch 2201/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6524 - val_loss: 0.6421\n",
            "Epoch 2202/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6525 - val_loss: 0.6428\n",
            "Epoch 2203/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6523 - val_loss: 0.6416\n",
            "Epoch 2204/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6523 - val_loss: 0.6417\n",
            "Epoch 2205/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6525 - val_loss: 0.6425\n",
            "Epoch 2206/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6523 - val_loss: 0.6420\n",
            "Epoch 2207/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6523 - val_loss: 0.6419\n",
            "Epoch 2208/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6523 - val_loss: 0.6419\n",
            "Epoch 2209/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6523 - val_loss: 0.6416\n",
            "Epoch 2210/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6523 - val_loss: 0.6417\n",
            "Epoch 2211/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6524 - val_loss: 0.6419\n",
            "Epoch 2212/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6524 - val_loss: 0.6424\n",
            "Epoch 2213/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6524 - val_loss: 0.6416\n",
            "Epoch 2214/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6524 - val_loss: 0.6406\n",
            "Epoch 2215/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6524 - val_loss: 0.6406\n",
            "Epoch 2216/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6525 - val_loss: 0.6415\n",
            "Epoch 2217/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6524 - val_loss: 0.6415\n",
            "Epoch 2218/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6524 - val_loss: 0.6406\n",
            "Epoch 2219/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6524 - val_loss: 0.6413\n",
            "Epoch 2220/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6524 - val_loss: 0.6413\n",
            "Epoch 2221/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6524 - val_loss: 0.6404\n",
            "Epoch 2222/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6524 - val_loss: 0.6413\n",
            "Epoch 2223/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6524 - val_loss: 0.6409\n",
            "Epoch 2224/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6523 - val_loss: 0.6415\n",
            "Epoch 2225/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6523 - val_loss: 0.6418\n",
            "Epoch 2226/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6526 - val_loss: 0.6432\n",
            "Epoch 2227/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6523 - val_loss: 0.6428\n",
            "Epoch 2228/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6524 - val_loss: 0.6422\n",
            "Epoch 2229/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6523 - val_loss: 0.6426\n",
            "Epoch 2230/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6526 - val_loss: 0.6435\n",
            "Epoch 2231/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6524 - val_loss: 0.6427\n",
            "Epoch 2232/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6524 - val_loss: 0.6427\n",
            "Epoch 2233/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6524 - val_loss: 0.6431\n",
            "Epoch 2234/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6523 - val_loss: 0.6429\n",
            "Epoch 2235/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6523 - val_loss: 0.6423\n",
            "Epoch 2236/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6525 - val_loss: 0.6431\n",
            "Epoch 2237/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6524 - val_loss: 0.6419\n",
            "Epoch 2238/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6523 - val_loss: 0.6418\n",
            "Epoch 2239/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6524 - val_loss: 0.6420\n",
            "Epoch 2240/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6523 - val_loss: 0.6416\n",
            "Epoch 2241/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6523 - val_loss: 0.6420\n",
            "Epoch 2242/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6524 - val_loss: 0.6406\n",
            "Epoch 2243/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6525 - val_loss: 0.6417\n",
            "Epoch 2244/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6527 - val_loss: 0.6401\n",
            "Epoch 2245/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6523 - val_loss: 0.6407\n",
            "Epoch 2246/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6523 - val_loss: 0.6408\n",
            "Epoch 2247/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6524 - val_loss: 0.6409\n",
            "Epoch 2248/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6524 - val_loss: 0.6414\n",
            "Epoch 2249/5000\n",
            " 1/10 [==>...........................] - ETA: 0s - loss: 0.3181Restoring model weights from the end of the best epoch: 1249.\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6524 - val_loss: 0.6410\n",
            "Epoch 2249: early stopping\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 19ms/step - loss: 0.7751\n",
            "EXPECTED:\n",
            "   d18O_cel_mean  d18O_cel_variance\n",
            "0      27.559140           0.780698\n",
            "1      27.260748           0.830341\n",
            "2      24.777670           0.736571\n",
            "3      25.987815           5.280825\n",
            "4      25.551850           0.312355\n",
            "5      25.115885           0.033519\n",
            "6      24.132031           0.389042\n",
            "7      25.120750           0.844007\n",
            "\n",
            "PREDICTED:\n",
            "   d18O_cel_mean  d18O_cel_variance\n",
            "0      25.416954           1.809567\n",
            "1      25.416189           1.809168\n",
            "2      25.406351           1.833399\n",
            "3      25.405458           1.839788\n",
            "4      25.405212           1.839388\n",
            "5      25.405077           1.839163\n",
            "6      25.405159           1.839299\n",
            "7      25.405226           1.818285\n",
            "RMSE: 1.147423837955431\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2023-07-18 16:46:29.550564: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype double and shape [8,12]\n",
            "\t [[{{node Placeholder/_0}}]]\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}