{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tnc-br/ddf-isoscapes/blob/split_experiments/dnn/variational_split_experiments.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Variational model\n",
        "\n",
        "Find the mean/variance of O18 ratios (as well as N15 and C13 in the future) at a particular lat/lon across Brazil. At the bottom of the colab, train and evaluate 4 different versions of the model with different data partitioning strategies."
      ],
      "metadata": {
        "id": "-0IfT3kGwgK6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "henIPlAPCb4i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4a631dd-c3f8-43cc-99ab-70f566b1062a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2023-07-20 14:16:28.780384: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2023-07-20 14:16:28.815964: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2023-07-20 14:16:28.817303: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-07-20 14:16:29.518127: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        }
      ],
      "source": [
        "from collections import defaultdict\n",
        "import math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import datetime\n",
        "import os\n",
        "from typing import List, Tuple, Dict\n",
        "from dataclasses import dataclass\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, regularizers\n",
        "from matplotlib import pyplot as plt\n",
        "from tensorflow.python.ops import math_ops\n",
        "from sklearn.preprocessing import StandardScaler, Normalizer, MinMaxScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "\n",
        "#@title Debugging\n",
        "# See https://zohaib.me/debugging-in-google-collab-notebook/ for tips,\n",
        "# as well as docs for pdb and ipdb.\n",
        "DEBUG = False #@param {type:\"boolean\"}\n",
        "USE_LOCAL_DRIVE = True #@param {type:\"boolean\"}\n",
        "LOCAL_DIR = \"/usr/local/google/home/ruru/Downloads/amazon_sample_data-20230712T203059Z-001\" #@param\n",
        "GDRIVE_DIR = \"MyDrive/amazon_rainforest_files/\" #@param\n",
        "FP_ROOT = LOCAL_DIR\n",
        "\n",
        "def get_model_save_location(filename) -> str:\n",
        "  root = '' if USE_LOCAL_DRIVE else '/content/drive'\n",
        "  return os.path.join(root, GDRIVE_DIR,'variational/model', filename)\n",
        "\n",
        "# Access data stored on Google Drive if not reading data locally.\n",
        "if not USE_LOCAL_DRIVE:\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive')\n",
        "  global FP_ROOT\n",
        "  FP_ROOT = os.path.join('/content/drive', GDRIVE_DIR)\n",
        "\n",
        "if DEBUG:\n",
        "    %pip install -Uqq ipdb\n",
        "    import ipdb\n",
        "    %pdb on"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GQrEv57zCb4q"
      },
      "source": [
        "# Data preparation\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_dataset(path: str):\n",
        "  df = pd.read_csv(path, encoding=\"ISO-8859-1\", sep=',')\n",
        "  df = df[df['d18O_cel_variance'].notna()]\n",
        "\n",
        "  # Family is too sparse. Too many families exist in validation/test that won't\n",
        "  # exist in train, so drop it.\n",
        "  X = df.drop([\"d18O_cel_mean\", \"d18O_cel_variance\", \"Code\", \"Family\", \"Unnamed: 0\"], axis=1)\n",
        "  Y = df[[\"d18O_cel_mean\", \"d18O_cel_variance\"]]\n",
        "  return X, Y"
      ],
      "metadata": {
        "id": "6XMee1aHfcik"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Standardization"
      ],
      "metadata": {
        "id": "DtkKhMOtb6cS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@dataclass\n",
        "class FeaturesToLabels:\n",
        "  def __init__(self, X: pd.DataFrame, Y: pd.DataFrame):\n",
        "    self.X = X\n",
        "    self.Y = Y\n",
        "\n",
        "  def as_tuple(self):\n",
        "    return (self.X, self.Y)\n",
        "\n",
        "\n",
        "def create_feature_scaler(X: pd.DataFrame) -> ColumnTransformer:\n",
        "  columns_to_normalize = ['lat', 'long', 'VPD', 'RH', 'PET', 'DEM', 'PA',\n",
        "       'Mean Annual Temperature', 'Mean Annual Precipitation']\n",
        "  columns_to_standardize = ['Iso_Oxi_Stack_mean_TERZER',\n",
        "                            'predkrig_br_lat_ISORG',\n",
        "                            'isoscape_fullmodel_d18O_prec_REGRESSION']\n",
        "  feature_scaler = ColumnTransformer([\n",
        "      ('feature_normalizer', Normalizer(), columns_to_normalize),\n",
        "      ('feature_standardizer', StandardScaler(), columns_to_standardize)],\n",
        "      remainder='passthrough')\n",
        "  feature_scaler.fit(X)\n",
        "  return feature_scaler\n",
        "\n",
        "def create_label_scaler(Y: pd.DataFrame) -> ColumnTransformer:\n",
        "  label_scaler = ColumnTransformer([\n",
        "      ('mean_std_scaler', StandardScaler(), ['d18O_cel_mean']),\n",
        "      ('var_minmax_scaler', MinMaxScaler(), ['d18O_cel_variance'])],\n",
        "      remainder='passthrough')\n",
        "  label_scaler.fit(Y)\n",
        "  return label_scaler\n",
        "\n",
        "def scale(X: pd.DataFrame, Y: pd.DataFrame, feature_scaler, label_scaler):\n",
        "  # transform() outputs numpy arrays :(  need to convert back to DataFrame.\n",
        "  X_standardized = pd.DataFrame(feature_scaler.transform(X),\n",
        "                        index=X.index, columns=X.columns)\n",
        "  # Y_standardized = pd.DataFrame(label_scaler.transform(Y),\n",
        "  #                                     index=Y.index, columns=Y.columns)\n",
        "  # FOR NOW, DO NOT SCALE Y.\n",
        "  return FeaturesToLabels(X_standardized, Y)"
      ],
      "metadata": {
        "id": "XSDwdvMkb7w8"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Just a class organization, holds each scaled dataset and the scaler used.\n",
        "# Useful for unscaling predictions.\n",
        "@dataclass\n",
        "class ScaledPartitions():\n",
        "  def __init__(self,\n",
        "               feature_scaler: ColumnTransformer,\n",
        "               label_scaler: ColumnTransformer,\n",
        "               train: FeaturesToLabels, val: FeaturesToLabels,\n",
        "               test: FeaturesToLabels):\n",
        "    self.feature_scaler = feature_scaler\n",
        "    self.label_scaler = label_scaler\n",
        "    self.train = train\n",
        "    self.val = val\n",
        "    self.test = test\n",
        "\n",
        "\n",
        "def load_and_scale(config: Dict) -> ScaledPartitions:\n",
        "  X_train, Y_train = load_dataset(config['TRAIN'])\n",
        "  X_val, Y_val = load_dataset(config['VALIDATION'])\n",
        "  X_test, Y_test = load_dataset(config['TEST'])\n",
        "\n",
        "  feature_scaler = create_feature_scaler(X_train)\n",
        "  label_scaler = create_label_scaler(Y_train)\n",
        "  train = scale(X_train, Y_train, feature_scaler, label_scaler)\n",
        "  val = scale(X_val, Y_val, feature_scaler, label_scaler)\n",
        "  test = scale(X_test, Y_test, feature_scaler, label_scaler)\n",
        "  return ScaledPartitions(feature_scaler, label_scaler, train, val, test)\n"
      ],
      "metadata": {
        "id": "_kf2e_fKon2P"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Definition\n",
        "\n"
      ],
      "metadata": {
        "id": "usGznR593LZc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The KL Loss function:"
      ],
      "metadata": {
        "id": "khK7C8WvU8ZR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# log(σ2/σ1) + ( σ1^2+(μ1−μ2)^2 ) / 2* σ^2   − 1/2\n",
        "def kl_divergence(real, predicted):\n",
        "    real_value = tf.gather(real, [0], axis=1)\n",
        "    real_std = tf.math.sqrt(tf.gather(real, [1], axis=1))\n",
        "\n",
        "    predicted_value = tf.gather(predicted, [0], axis=1)\n",
        "    predicted_std = tf.math.sqrt(tf.gather(predicted, [1], axis=1))\n",
        "\n",
        "    kl_loss = -0.5 + tf.math.log(predicted_std/real_std) + \\\n",
        "     (tf.square(real_std) + tf.square(real_value - predicted_value))/ \\\n",
        "     (2*tf.square(predicted_std))\n",
        "\n",
        "    return tf.math.reduce_mean(kl_loss)"
      ],
      "metadata": {
        "id": "urGjYNNnemX6"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test the loss function:"
      ],
      "metadata": {
        "id": "fJzBFWQVeqNE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pytest\n",
        "\n",
        "test_real = tf.convert_to_tensor(np.array([[1, 0.02]]))\n",
        "test_pred = tf.convert_to_tensor(np.array([[0.98, 0.021]]))\n",
        "\n",
        "# https://screenshot.googleplex.com/5WM9dinAbhR26ZS\n",
        "assert float(kl_divergence(test_real, test_pred)) == pytest.approx(0.0101094, 1e-5)\n",
        "\n",
        "test_neg_real = tf.convert_to_tensor(np.array([[32.32, 0.0344]]))\n",
        "test_neg_pred = tf.convert_to_tensor(np.array([[32.01, -0.322]]))\n",
        "\n",
        "# Negative variance causes NaN\n",
        "assert tf.math.is_nan(kl_divergence(test_neg_real, test_neg_pred))\n",
        "\n",
        "# Calculated manually by computing the result of this equation in wolfram alpha:\n",
        "# log(σ2/σ1) + ( σ1^2+(μ1−μ2)^2 ) / 2* σ^2   − 1/2\n",
        "test_real_2d = tf.convert_to_tensor(np.array(\n",
        "    [[1.00, 0.020],\n",
        "     [1.01, 0.042]]))\n",
        "test_pred_2d = tf.convert_to_tensor(np.array(\n",
        "    [[0.98, 0.021],\n",
        "     [0.99, 0.012]]))\n",
        "\n",
        "# Should reduce to the average loss of all rows.\n",
        "assert float(kl_divergence(test_real_2d, test_pred_2d)) == pytest.approx(\n",
        "    sum([0.0101094, 0.6402851])/2, 1e-5)"
      ],
      "metadata": {
        "id": "48TaPd70erSk",
        "outputId": "c2062fad-1a13-4c52-a758-634a77a28950",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 209
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpytest\u001b[39;00m\n\u001b[1;32m      3\u001b[0m test_real \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mconvert_to_tensor(np\u001b[38;5;241m.\u001b[39marray([[\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0.02\u001b[39m]]))\n\u001b[1;32m      4\u001b[0m test_pred \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mconvert_to_tensor(np\u001b[38;5;241m.\u001b[39marray([[\u001b[38;5;241m0.98\u001b[39m, \u001b[38;5;241m0.021\u001b[39m]]))\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pytest'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model definition"
      ],
      "metadata": {
        "id": "8rI6qPRh7oO7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "\n",
        "def get_early_stopping_callback():\n",
        "  return EarlyStopping(monitor='val_loss', patience=100, min_delta=0.001,\n",
        "                       verbose=1, restore_best_weights=True, start_from_epoch=10)\n",
        "\n",
        "tf.keras.utils.set_random_seed(18731)\n",
        "\n",
        "# I was experimenting with models that took longer to train, and used this\n",
        "# checkpointing callback to periodically save the model. It's optional.\n",
        "def get_checkpoint_callback(model_file):\n",
        "  return ModelCheckpoint(\n",
        "      get_model_save_location(model_file),\n",
        "      monitor='val_loss', verbose=0, save_best_only=True, mode='min')\n",
        "\n",
        "def train_or_update_variational_model(\n",
        "        sp: ScaledPartitions,\n",
        "        hidden_layers: List[int],\n",
        "        epochs: int,\n",
        "        batch_size: int,\n",
        "        lr: float,\n",
        "        model_file=None,\n",
        "        use_checkpoint=False):\n",
        "  callbacks_list = [get_early_stopping_callback(),\n",
        "                    get_checkpoint_callback(model_file)]\n",
        "  if not use_checkpoint:\n",
        "    inputs = keras.Input(shape=(sp.train.X.shape[1],))\n",
        "    x = inputs\n",
        "    for layer_size in hidden_layers:\n",
        "      x = keras.layers.Dense(\n",
        "          layer_size, activation='relu')(x)\n",
        "    mean_output = keras.layers.Dense(\n",
        "        1, name='mean_output')(x)\n",
        "\n",
        "    # We can not have negative variance. Apply very little variance.\n",
        "    var_output = keras.layers.Dense(\n",
        "        1, name='var_output')(x)\n",
        "\n",
        "    # Invert the normalization on our outputs\n",
        "    mean_scaler = sp.label_scaler.named_transformers_['mean_std_scaler']\n",
        "    untransformed_mean = mean_output * mean_scaler.var_ + mean_scaler.mean_\n",
        "\n",
        "    var_scaler = sp.label_scaler.named_transformers_['var_minmax_scaler']\n",
        "    untransformed_var = var_output * var_scaler.scale_ + var_scaler.min_\n",
        "\n",
        "    untransformed_abs_var = keras.layers.Lambda(lambda t: tf.abs(t))(untransformed_var)\n",
        "\n",
        "    # Output mean, |variance| tuples.\n",
        "    outputs = keras.layers.concatenate([untransformed_mean, untransformed_abs_var])\n",
        "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "    # Later epochs seem to benefit from lower learning rate... but it takes\n",
        "    # a while to get there.\n",
        "    decay = keras.optimizers.schedules.ExponentialDecay(\n",
        "       lr, decay_steps=100, decay_rate=0.5, staircase=True)\n",
        "\n",
        "    optimizer = keras.optimizers.Adam(learning_rate=lr)\n",
        "    model.compile(optimizer=optimizer, loss=kl_divergence)\n",
        "    model.summary()\n",
        "  else:\n",
        "    model = keras.models.load_model(\n",
        "        get_model_save_location(model_file),\n",
        "        custom_objects={\"kl_divergence\": kl_divergence})\n",
        "  history = model.fit(sp.train.X, sp.train.Y, verbose=1, epochs=epochs, batch_size=batch_size,\n",
        "                      validation_data=sp.val.as_tuple(),\n",
        "                      shuffle=True, callbacks=callbacks_list)\n",
        "  return history, model"
      ],
      "metadata": {
        "id": "HCkGSPUo3KqY"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "def render_plot_loss(history, name):\n",
        "  plt.plot(history.history['loss'])\n",
        "  plt.plot(history.history['val_loss'])\n",
        "  plt.title(name + ' model loss')\n",
        "  plt.ylabel('loss')\n",
        "  plt.yscale(\"log\")\n",
        "  plt.xlabel('epoch')\n",
        "  plt.legend(['loss', 'val_loss'], loc='upper left')\n",
        "  plt.show()\n",
        "\n",
        "def destandardize(sd: ScaledPartitions, df: pd.DataFrame):\n",
        "  means = pd.DataFrame(\n",
        "      sd.label_scaler.named_transformers_['var_std_scaler'].inverse_transform(df[['d18O_cel_mean']]),\n",
        "      index=df.index, columns=['d18O_cel_mean'])\n",
        "  vars = df['d18O_cel_variance']\n",
        "  return means.join(vars)\n",
        "\n",
        "def train_and_evaluate(sp: ScaledPartitions, run_id: str, training_batch_size=5):\n",
        "  print(\"==================\")\n",
        "  print(run_id)\n",
        "  history, model = train_or_update_variational_model(\n",
        "      sp, hidden_layers=[20, 20], epochs=5000, batch_size=training_batch_size,\n",
        "      lr=0.0001, model_file=run_id+\".h5\", use_checkpoint=False)\n",
        "  render_plot_loss(history, run_id+\" kl_loss\")\n",
        "  model.save(get_model_save_location(run_id+\".h5\"), save_format=\"h5\")\n",
        "\n",
        "  model.evaluate(x=sp.test.X, y=sp.test.Y)\n",
        "  predictions = model.predict_on_batch(sp.test.X)\n",
        "  print(\"EXPECTED:\")\n",
        "  print(sp.test.Y.to_string())\n",
        "  print()\n",
        "  print(\"PREDICTED:\")\n",
        "  predictions = pd.DataFrame(predictions, columns=['d18O_cel_mean', 'd18O_cel_variance'])\n",
        "  print(predictions.to_string())\n",
        "\n",
        "  print(sp.val.Y)\n",
        "  val_pred = model.predict_on_batch(sp.val.X)\n",
        "  print(val_pred)\n",
        "\n",
        "  rmse = np.sqrt(mean_squared_error(sp.test.Y['d18O_cel_mean'], predictions['d18O_cel_mean']))\n",
        "  print(\"RMSE: \"+ str(rmse))"
      ],
      "metadata": {
        "id": "DALuUm8UOgNu"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load and evaluate the model with each set of data.\n",
        "\n",
        "Use the same model configured the same way for every run, with the exception of the training batch size setting, which is 1 for grouped and 5 for ungrouped."
      ],
      "metadata": {
        "id": "WF_1T_zZtK0T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1) Ungrouped, random"
      ],
      "metadata": {
        "id": "q6vAjessuMSM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ungrouped_random = {\n",
        "    'TRAIN' : os.path.join(FP_ROOT, \"amazon_sample_data/uc_davis_2023_08_12_train_random_ungrouped.csv\"),\n",
        "    'TEST' : os.path.join(FP_ROOT, \"amazon_sample_data/uc_davis_2023_08_12_test_random_ungrouped.csv\"),\n",
        "    'VALIDATION' : os.path.join(FP_ROOT, \"amazon_sample_data/uc_davis_2023_08_12_validation_random_ungrouped.csv\"),\n",
        "}\n",
        "\n",
        "ungrouped_random_scaled = load_and_scale(ungrouped_random)\n",
        "train_and_evaluate(ungrouped_random_scaled, \"ungrouped_random\", training_batch_size=3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "qM5zP9M9tQqE",
        "outputId": "794eb45d-4b27-4877-bcc9-6393943fc6ad"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================\n",
            "ungrouped_random\n",
            "Model: \"model_10\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_11 (InputLayer)          [(None, 12)]         0           []                               \n",
            "                                                                                                  \n",
            " dense_20 (Dense)               (None, 20)           260         ['input_11[0][0]']               \n",
            "                                                                                                  \n",
            " dense_21 (Dense)               (None, 20)           420         ['dense_20[0][0]']               \n",
            "                                                                                                  \n",
            " var_output (Dense)             (None, 1)            21          ['dense_21[0][0]']               \n",
            "                                                                                                  \n",
            " mean_output (Dense)            (None, 1)            21          ['dense_21[0][0]']               \n",
            "                                                                                                  \n",
            " tf.math.multiply_21 (TFOpLambd  (None, 1)           0           ['var_output[0][0]']             \n",
            " a)                                                                                               \n",
            "                                                                                                  \n",
            " tf.math.multiply_20 (TFOpLambd  (None, 1)           0           ['mean_output[0][0]']            \n",
            " a)                                                                                               \n",
            "                                                                                                  \n",
            " tf.__operators__.add_21 (TFOpL  (None, 1)           0           ['tf.math.multiply_21[0][0]']    \n",
            " ambda)                                                                                           \n",
            "                                                                                                  \n",
            " tf.__operators__.add_20 (TFOpL  (None, 1)           0           ['tf.math.multiply_20[0][0]']    \n",
            " ambda)                                                                                           \n",
            "                                                                                                  \n",
            " lambda_10 (Lambda)             (None, 1)            0           ['tf.__operators__.add_21[0][0]']\n",
            "                                                                                                  \n",
            " concatenate_10 (Concatenate)   (None, 2)            0           ['tf.__operators__.add_20[0][0]',\n",
            "                                                                  'lambda_10[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 722\n",
            "Trainable params: 722\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/5000\n",
            "165/165 [==============================] - 1s 2ms/step - loss: 103.7250 - val_loss: 18.2819\n",
            "Epoch 2/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 66.6872 - val_loss: 16.8408\n",
            "Epoch 3/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 54.9417 - val_loss: 15.8385\n",
            "Epoch 4/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 47.1265 - val_loss: 14.9409\n",
            "Epoch 5/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 40.6231 - val_loss: 14.1561\n",
            "Epoch 6/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 36.0578 - val_loss: 13.4443\n",
            "Epoch 7/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 32.8529 - val_loss: 12.7746\n",
            "Epoch 8/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 30.2023 - val_loss: 11.7619\n",
            "Epoch 9/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 27.7272 - val_loss: 11.0902\n",
            "Epoch 10/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 25.5688 - val_loss: 10.6324\n",
            "Epoch 11/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 23.9772 - val_loss: 10.2137\n",
            "Epoch 12/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 22.5955 - val_loss: 9.8564\n",
            "Epoch 13/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 21.3175 - val_loss: 9.5068\n",
            "Epoch 14/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 20.2129 - val_loss: 9.1940\n",
            "Epoch 15/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 19.2199 - val_loss: 8.9260\n",
            "Epoch 16/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 18.3343 - val_loss: 8.6673\n",
            "Epoch 17/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 17.5303 - val_loss: 8.4539\n",
            "Epoch 18/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 16.8015 - val_loss: 8.2468\n",
            "Epoch 19/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 16.1310 - val_loss: 8.0696\n",
            "Epoch 20/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 15.5190 - val_loss: 7.9251\n",
            "Epoch 21/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 14.9564 - val_loss: 7.7911\n",
            "Epoch 22/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 14.4307 - val_loss: 7.6539\n",
            "Epoch 23/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 13.9404 - val_loss: 7.5361\n",
            "Epoch 24/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 13.4863 - val_loss: 7.4133\n",
            "Epoch 25/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 13.0659 - val_loss: 7.3133\n",
            "Epoch 26/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 12.6666 - val_loss: 7.2124\n",
            "Epoch 27/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 12.2906 - val_loss: 7.1144\n",
            "Epoch 28/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 11.9322 - val_loss: 7.0339\n",
            "Epoch 29/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 11.5974 - val_loss: 6.9400\n",
            "Epoch 30/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 11.2824 - val_loss: 6.8635\n",
            "Epoch 31/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 10.9803 - val_loss: 6.7819\n",
            "Epoch 32/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 10.6963 - val_loss: 6.7102\n",
            "Epoch 33/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 10.4232 - val_loss: 6.6417\n",
            "Epoch 34/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 10.1548 - val_loss: 6.5739\n",
            "Epoch 35/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 9.9016 - val_loss: 6.5188\n",
            "Epoch 36/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 9.6620 - val_loss: 6.4620\n",
            "Epoch 37/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 9.4384 - val_loss: 6.4119\n",
            "Epoch 38/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 9.2281 - val_loss: 6.3714\n",
            "Epoch 39/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 9.0261 - val_loss: 6.3239\n",
            "Epoch 40/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 8.8278 - val_loss: 6.2769\n",
            "Epoch 41/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 8.6396 - val_loss: 6.2305\n",
            "Epoch 42/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 8.4613 - val_loss: 6.1847\n",
            "Epoch 43/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 8.2942 - val_loss: 6.1423\n",
            "Epoch 44/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 8.1345 - val_loss: 6.1013\n",
            "Epoch 45/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 7.9815 - val_loss: 6.0507\n",
            "Epoch 46/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 7.8318 - val_loss: 6.0122\n",
            "Epoch 47/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 7.6888 - val_loss: 5.9678\n",
            "Epoch 48/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 7.5501 - val_loss: 5.9254\n",
            "Epoch 49/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 7.4161 - val_loss: 5.8842\n",
            "Epoch 50/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 7.2878 - val_loss: 5.8286\n",
            "Epoch 51/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 7.1636 - val_loss: 5.7776\n",
            "Epoch 52/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 7.0420 - val_loss: 5.7142\n",
            "Epoch 53/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 6.9228 - val_loss: 5.6603\n",
            "Epoch 54/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 6.8080 - val_loss: 5.6129\n",
            "Epoch 55/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 6.6972 - val_loss: 5.5619\n",
            "Epoch 56/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 6.5899 - val_loss: 5.5091\n",
            "Epoch 57/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 6.4863 - val_loss: 5.4568\n",
            "Epoch 58/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 6.3816 - val_loss: 5.3983\n",
            "Epoch 59/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 6.2807 - val_loss: 5.3487\n",
            "Epoch 60/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 6.1807 - val_loss: 5.2929\n",
            "Epoch 61/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 6.0814 - val_loss: 5.2353\n",
            "Epoch 62/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 5.9831 - val_loss: 5.1899\n",
            "Epoch 63/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 5.8861 - val_loss: 5.1251\n",
            "Epoch 64/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 5.7974 - val_loss: 5.0622\n",
            "Epoch 65/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 5.7101 - val_loss: 5.0201\n",
            "Epoch 66/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 5.6242 - val_loss: 4.9740\n",
            "Epoch 67/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 5.5387 - val_loss: 4.9124\n",
            "Epoch 68/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 5.4531 - val_loss: 4.8498\n",
            "Epoch 69/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 5.3683 - val_loss: 4.7915\n",
            "Epoch 70/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 5.2831 - val_loss: 4.7395\n",
            "Epoch 71/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 5.1976 - val_loss: 4.6778\n",
            "Epoch 72/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 5.1121 - val_loss: 4.6311\n",
            "Epoch 73/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 5.0259 - val_loss: 4.5693\n",
            "Epoch 74/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 4.9397 - val_loss: 4.5006\n",
            "Epoch 75/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 4.8517 - val_loss: 4.4240\n",
            "Epoch 76/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 4.7636 - val_loss: 4.3615\n",
            "Epoch 77/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 4.6755 - val_loss: 4.3110\n",
            "Epoch 78/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 4.5867 - val_loss: 4.2196\n",
            "Epoch 79/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 4.4962 - val_loss: 4.1578\n",
            "Epoch 80/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 4.4073 - val_loss: 4.0809\n",
            "Epoch 81/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 4.3247 - val_loss: 4.0095\n",
            "Epoch 82/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 4.2463 - val_loss: 3.9605\n",
            "Epoch 83/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 4.1680 - val_loss: 3.9056\n",
            "Epoch 84/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 4.0890 - val_loss: 3.8439\n",
            "Epoch 85/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 4.0097 - val_loss: 3.7712\n",
            "Epoch 86/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 3.9293 - val_loss: 3.7017\n",
            "Epoch 87/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 3.8488 - val_loss: 3.6208\n",
            "Epoch 88/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 3.7669 - val_loss: 3.5500\n",
            "Epoch 89/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 3.6842 - val_loss: 3.4841\n",
            "Epoch 90/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 3.6082 - val_loss: 3.4165\n",
            "Epoch 91/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 3.5350 - val_loss: 3.3540\n",
            "Epoch 92/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 3.4561 - val_loss: 3.2921\n",
            "Epoch 93/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 3.3815 - val_loss: 3.2364\n",
            "Epoch 94/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 3.3078 - val_loss: 3.1526\n",
            "Epoch 95/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 3.2352 - val_loss: 3.0721\n",
            "Epoch 96/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 3.1639 - val_loss: 3.0179\n",
            "Epoch 97/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 3.0947 - val_loss: 2.9552\n",
            "Epoch 98/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 3.0258 - val_loss: 2.9006\n",
            "Epoch 99/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 2.9618 - val_loss: 2.8243\n",
            "Epoch 100/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 2.9061 - val_loss: 2.7906\n",
            "Epoch 101/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 2.8490 - val_loss: 2.7404\n",
            "Epoch 102/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 2.7928 - val_loss: 2.7006\n",
            "Epoch 103/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 2.7369 - val_loss: 2.6320\n",
            "Epoch 104/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 2.6820 - val_loss: 2.5879\n",
            "Epoch 105/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 2.6270 - val_loss: 2.5090\n",
            "Epoch 106/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 2.5736 - val_loss: 2.4666\n",
            "Epoch 107/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 2.5196 - val_loss: 2.4244\n",
            "Epoch 108/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 2.4672 - val_loss: 2.3892\n",
            "Epoch 109/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 2.4147 - val_loss: 2.3438\n",
            "Epoch 110/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 2.3629 - val_loss: 2.2992\n",
            "Epoch 111/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 2.3118 - val_loss: 2.2417\n",
            "Epoch 112/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 2.2630 - val_loss: 2.2120\n",
            "Epoch 113/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 2.2204 - val_loss: 2.1747\n",
            "Epoch 114/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 2.1792 - val_loss: 2.1143\n",
            "Epoch 115/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 2.1384 - val_loss: 2.0432\n",
            "Epoch 116/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 2.0994 - val_loss: 2.0446\n",
            "Epoch 117/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 2.0618 - val_loss: 1.9977\n",
            "Epoch 118/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 2.0238 - val_loss: 1.9393\n",
            "Epoch 119/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 1.9877 - val_loss: 1.9384\n",
            "Epoch 120/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 1.9517 - val_loss: 1.9061\n",
            "Epoch 121/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 1.9164 - val_loss: 1.8785\n",
            "Epoch 122/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 1.8818 - val_loss: 1.8322\n",
            "Epoch 123/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 1.8476 - val_loss: 1.8001\n",
            "Epoch 124/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 1.8145 - val_loss: 1.7785\n",
            "Epoch 125/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 1.7818 - val_loss: 1.7433\n",
            "Epoch 126/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 1.7494 - val_loss: 1.7104\n",
            "Epoch 127/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 1.7175 - val_loss: 1.6866\n",
            "Epoch 128/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 1.6865 - val_loss: 1.6490\n",
            "Epoch 129/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 1.6579 - val_loss: 1.6187\n",
            "Epoch 130/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 1.6331 - val_loss: 1.5836\n",
            "Epoch 131/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 1.6084 - val_loss: 1.5860\n",
            "Epoch 132/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 1.5846 - val_loss: 1.5789\n",
            "Epoch 133/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 1.5622 - val_loss: 1.5303\n",
            "Epoch 134/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 1.5389 - val_loss: 1.5162\n",
            "Epoch 135/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 1.5171 - val_loss: 1.4796\n",
            "Epoch 136/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 1.4960 - val_loss: 1.4943\n",
            "Epoch 137/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 1.4758 - val_loss: 1.4518\n",
            "Epoch 138/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 1.4585 - val_loss: 1.4399\n",
            "Epoch 139/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 1.4423 - val_loss: 1.4468\n",
            "Epoch 140/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 1.4266 - val_loss: 1.4536\n",
            "Epoch 141/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 1.4112 - val_loss: 1.4379\n",
            "Epoch 142/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 1.3972 - val_loss: 1.3927\n",
            "Epoch 143/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 1.3829 - val_loss: 1.3906\n",
            "Epoch 144/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 1.3676 - val_loss: 1.3797\n",
            "Epoch 145/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 1.3532 - val_loss: 1.3564\n",
            "Epoch 146/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 1.3401 - val_loss: 1.3460\n",
            "Epoch 147/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 1.3264 - val_loss: 1.3528\n",
            "Epoch 148/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 1.3132 - val_loss: 1.3046\n",
            "Epoch 149/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 1.3002 - val_loss: 1.3218\n",
            "Epoch 150/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 1.2873 - val_loss: 1.3434\n",
            "Epoch 151/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 1.2750 - val_loss: 1.2852\n",
            "Epoch 152/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 1.2625 - val_loss: 1.3053\n",
            "Epoch 153/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 1.2503 - val_loss: 1.3094\n",
            "Epoch 154/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 1.2387 - val_loss: 1.2985\n",
            "Epoch 155/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 1.2273 - val_loss: 1.2467\n",
            "Epoch 156/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 1.2157 - val_loss: 1.2767\n",
            "Epoch 157/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 1.2044 - val_loss: 1.2612\n",
            "Epoch 158/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 1.1935 - val_loss: 1.2267\n",
            "Epoch 159/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 1.1827 - val_loss: 1.2271\n",
            "Epoch 160/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 1.1717 - val_loss: 1.2222\n",
            "Epoch 161/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 1.1609 - val_loss: 1.1981\n",
            "Epoch 162/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 1.1511 - val_loss: 1.1879\n",
            "Epoch 163/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 1.1407 - val_loss: 1.1845\n",
            "Epoch 164/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 1.1303 - val_loss: 1.1857\n",
            "Epoch 165/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 1.1208 - val_loss: 1.1738\n",
            "Epoch 166/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 1.1113 - val_loss: 1.1723\n",
            "Epoch 167/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 1.1013 - val_loss: 1.1658\n",
            "Epoch 168/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 1.0924 - val_loss: 1.1464\n",
            "Epoch 169/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 1.0829 - val_loss: 1.1325\n",
            "Epoch 170/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 1.0743 - val_loss: 1.1113\n",
            "Epoch 171/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 1.0656 - val_loss: 1.1310\n",
            "Epoch 172/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 1.0562 - val_loss: 1.1156\n",
            "Epoch 173/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 1.0477 - val_loss: 1.1043\n",
            "Epoch 174/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 1.0395 - val_loss: 1.0860\n",
            "Epoch 175/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 1.0309 - val_loss: 1.1047\n",
            "Epoch 176/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 1.0236 - val_loss: 1.1117\n",
            "Epoch 177/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 1.0149 - val_loss: 1.1094\n",
            "Epoch 178/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 1.0064 - val_loss: 1.0556\n",
            "Epoch 179/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.9994 - val_loss: 1.0868\n",
            "Epoch 180/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.9910 - val_loss: 1.0541\n",
            "Epoch 181/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.9837 - val_loss: 1.0411\n",
            "Epoch 182/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.9762 - val_loss: 1.0537\n",
            "Epoch 183/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.9688 - val_loss: 1.0502\n",
            "Epoch 184/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.9611 - val_loss: 1.0399\n",
            "Epoch 185/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.9537 - val_loss: 1.0605\n",
            "Epoch 186/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.9467 - val_loss: 1.0508\n",
            "Epoch 187/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.9392 - val_loss: 1.0117\n",
            "Epoch 188/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.9326 - val_loss: 1.0281\n",
            "Epoch 189/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.9256 - val_loss: 1.0172\n",
            "Epoch 190/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.9190 - val_loss: 1.0035\n",
            "Epoch 191/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.9125 - val_loss: 1.0030\n",
            "Epoch 192/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.9054 - val_loss: 1.0301\n",
            "Epoch 193/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.8983 - val_loss: 0.9723\n",
            "Epoch 194/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.8925 - val_loss: 1.0156\n",
            "Epoch 195/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.8861 - val_loss: 0.9802\n",
            "Epoch 196/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.8808 - val_loss: 0.9853\n",
            "Epoch 197/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.8753 - val_loss: 0.9790\n",
            "Epoch 198/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.8689 - val_loss: 0.9291\n",
            "Epoch 199/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.8635 - val_loss: 0.9291\n",
            "Epoch 200/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.8583 - val_loss: 0.9534\n",
            "Epoch 201/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.8520 - val_loss: 0.9568\n",
            "Epoch 202/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.8471 - val_loss: 0.9421\n",
            "Epoch 203/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.8424 - val_loss: 0.9690\n",
            "Epoch 204/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.8362 - val_loss: 0.9608\n",
            "Epoch 205/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.8313 - val_loss: 0.9517\n",
            "Epoch 206/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.8258 - val_loss: 0.9578\n",
            "Epoch 207/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.8208 - val_loss: 0.9219\n",
            "Epoch 208/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.8157 - val_loss: 0.9478\n",
            "Epoch 209/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.8109 - val_loss: 0.9386\n",
            "Epoch 210/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.8058 - val_loss: 0.9536\n",
            "Epoch 211/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.8007 - val_loss: 0.8966\n",
            "Epoch 212/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.7956 - val_loss: 0.9623\n",
            "Epoch 213/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.7907 - val_loss: 0.9237\n",
            "Epoch 214/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.7854 - val_loss: 0.9449\n",
            "Epoch 215/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.7819 - val_loss: 0.9138\n",
            "Epoch 216/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.7769 - val_loss: 0.8928\n",
            "Epoch 217/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.7734 - val_loss: 0.8826\n",
            "Epoch 218/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.7688 - val_loss: 0.8817\n",
            "Epoch 219/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.7652 - val_loss: 0.9035\n",
            "Epoch 220/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.7617 - val_loss: 0.9222\n",
            "Epoch 221/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.7590 - val_loss: 0.8739\n",
            "Epoch 222/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.7548 - val_loss: 0.8731\n",
            "Epoch 223/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.7512 - val_loss: 0.9172\n",
            "Epoch 224/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.7488 - val_loss: 0.9233\n",
            "Epoch 225/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.7446 - val_loss: 0.8804\n",
            "Epoch 226/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.7422 - val_loss: 0.8955\n",
            "Epoch 227/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.7387 - val_loss: 0.8707\n",
            "Epoch 228/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.7360 - val_loss: 0.8956\n",
            "Epoch 229/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.7326 - val_loss: 0.8770\n",
            "Epoch 230/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.7290 - val_loss: 0.9172\n",
            "Epoch 231/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.7262 - val_loss: 0.9112\n",
            "Epoch 232/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.7236 - val_loss: 0.9099\n",
            "Epoch 233/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.7204 - val_loss: 0.9188\n",
            "Epoch 234/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.7179 - val_loss: 0.8653\n",
            "Epoch 235/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.7147 - val_loss: 0.8749\n",
            "Epoch 236/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.7124 - val_loss: 0.8747\n",
            "Epoch 237/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.7094 - val_loss: 0.8656\n",
            "Epoch 238/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.7063 - val_loss: 0.8762\n",
            "Epoch 239/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.7032 - val_loss: 0.8888\n",
            "Epoch 240/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.7015 - val_loss: 0.8420\n",
            "Epoch 241/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.6982 - val_loss: 0.8903\n",
            "Epoch 242/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.6958 - val_loss: 0.8726\n",
            "Epoch 243/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.6930 - val_loss: 0.8909\n",
            "Epoch 244/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.6903 - val_loss: 0.8767\n",
            "Epoch 245/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.6879 - val_loss: 0.8423\n",
            "Epoch 246/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.6856 - val_loss: 0.8756\n",
            "Epoch 247/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.6830 - val_loss: 0.8531\n",
            "Epoch 248/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.6804 - val_loss: 0.8310\n",
            "Epoch 249/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.6778 - val_loss: 0.8377\n",
            "Epoch 250/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.6758 - val_loss: 0.8781\n",
            "Epoch 251/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.6718 - val_loss: 0.9390\n",
            "Epoch 252/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.6707 - val_loss: 0.8713\n",
            "Epoch 253/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.6688 - val_loss: 0.8745\n",
            "Epoch 254/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.6657 - val_loss: 0.8232\n",
            "Epoch 255/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.6646 - val_loss: 0.8783\n",
            "Epoch 256/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.6618 - val_loss: 0.8603\n",
            "Epoch 257/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.6594 - val_loss: 0.8295\n",
            "Epoch 258/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.6579 - val_loss: 0.8490\n",
            "Epoch 259/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.6549 - val_loss: 0.8605\n",
            "Epoch 260/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.6526 - val_loss: 0.8321\n",
            "Epoch 261/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.6518 - val_loss: 0.8562\n",
            "Epoch 262/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.6491 - val_loss: 0.8636\n",
            "Epoch 263/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.6467 - val_loss: 0.8374\n",
            "Epoch 264/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.6442 - val_loss: 0.8625\n",
            "Epoch 265/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.6421 - val_loss: 0.8456\n",
            "Epoch 266/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.6401 - val_loss: 0.8699\n",
            "Epoch 267/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.6379 - val_loss: 0.8750\n",
            "Epoch 268/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.6362 - val_loss: 0.8384\n",
            "Epoch 269/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.6341 - val_loss: 0.8415\n",
            "Epoch 270/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.6325 - val_loss: 0.8412\n",
            "Epoch 271/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.6306 - val_loss: 0.8300\n",
            "Epoch 272/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.6281 - val_loss: 0.8614\n",
            "Epoch 273/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.6261 - val_loss: 0.8235\n",
            "Epoch 274/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.6242 - val_loss: 0.8295\n",
            "Epoch 275/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.6223 - val_loss: 0.8300\n",
            "Epoch 276/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.6204 - val_loss: 0.7870\n",
            "Epoch 277/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.6188 - val_loss: 0.8325\n",
            "Epoch 278/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.6175 - val_loss: 0.8422\n",
            "Epoch 279/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.6163 - val_loss: 0.8417\n",
            "Epoch 280/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.6141 - val_loss: 0.8310\n",
            "Epoch 281/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.6115 - val_loss: 0.8748\n",
            "Epoch 282/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.6100 - val_loss: 0.8879\n",
            "Epoch 283/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.6082 - val_loss: 0.8784\n",
            "Epoch 284/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.6066 - val_loss: 0.8166\n",
            "Epoch 285/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.6051 - val_loss: 0.8450\n",
            "Epoch 286/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.6033 - val_loss: 0.8320\n",
            "Epoch 287/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.6011 - val_loss: 0.8038\n",
            "Epoch 288/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.6006 - val_loss: 0.8140\n",
            "Epoch 289/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.5990 - val_loss: 0.8357\n",
            "Epoch 290/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.5969 - val_loss: 0.8217\n",
            "Epoch 291/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.5955 - val_loss: 0.8409\n",
            "Epoch 292/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.5933 - val_loss: 0.8813\n",
            "Epoch 293/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.5917 - val_loss: 0.8169\n",
            "Epoch 294/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.5907 - val_loss: 0.8173\n",
            "Epoch 295/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.5893 - val_loss: 0.8555\n",
            "Epoch 296/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.5876 - val_loss: 0.8394\n",
            "Epoch 297/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.5861 - val_loss: 0.8143\n",
            "Epoch 298/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.5843 - val_loss: 0.8167\n",
            "Epoch 299/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.5835 - val_loss: 0.7964\n",
            "Epoch 300/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.5819 - val_loss: 0.7742\n",
            "Epoch 301/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.5797 - val_loss: 0.8804\n",
            "Epoch 302/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.5782 - val_loss: 0.8009\n",
            "Epoch 303/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.5777 - val_loss: 0.8656\n",
            "Epoch 304/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.5770 - val_loss: 0.7818\n",
            "Epoch 305/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.5742 - val_loss: 0.7864\n",
            "Epoch 306/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.5732 - val_loss: 0.7978\n",
            "Epoch 307/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.5723 - val_loss: 0.8124\n",
            "Epoch 308/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.5705 - val_loss: 0.7551\n",
            "Epoch 309/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.5686 - val_loss: 0.8685\n",
            "Epoch 310/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.5679 - val_loss: 0.8467\n",
            "Epoch 311/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.5662 - val_loss: 0.7849\n",
            "Epoch 312/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.5656 - val_loss: 0.7806\n",
            "Epoch 313/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.5646 - val_loss: 0.8283\n",
            "Epoch 314/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.5627 - val_loss: 0.8134\n",
            "Epoch 315/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.5609 - val_loss: 0.8467\n",
            "Epoch 316/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.5597 - val_loss: 0.8024\n",
            "Epoch 317/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.5587 - val_loss: 0.8131\n",
            "Epoch 318/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.5569 - val_loss: 0.8774\n",
            "Epoch 319/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.5568 - val_loss: 0.8058\n",
            "Epoch 320/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.5554 - val_loss: 0.8804\n",
            "Epoch 321/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.5537 - val_loss: 0.8423\n",
            "Epoch 322/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.5524 - val_loss: 0.8251\n",
            "Epoch 323/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.5520 - val_loss: 0.7763\n",
            "Epoch 324/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.5511 - val_loss: 0.8405\n",
            "Epoch 325/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.5490 - val_loss: 0.8014\n",
            "Epoch 326/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.5487 - val_loss: 0.7958\n",
            "Epoch 327/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.5461 - val_loss: 0.7847\n",
            "Epoch 328/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.5451 - val_loss: 0.7943\n",
            "Epoch 329/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.5448 - val_loss: 0.7960\n",
            "Epoch 330/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.5434 - val_loss: 0.8210\n",
            "Epoch 331/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.5419 - val_loss: 0.7751\n",
            "Epoch 332/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.5407 - val_loss: 0.7895\n",
            "Epoch 333/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.5403 - val_loss: 0.8310\n",
            "Epoch 334/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.5386 - val_loss: 0.8253\n",
            "Epoch 335/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.5373 - val_loss: 0.7912\n",
            "Epoch 336/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.5361 - val_loss: 0.8073\n",
            "Epoch 337/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.5353 - val_loss: 0.8385\n",
            "Epoch 338/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.5339 - val_loss: 0.8364\n",
            "Epoch 339/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.5335 - val_loss: 0.7801\n",
            "Epoch 340/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.5320 - val_loss: 0.7808\n",
            "Epoch 341/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.5305 - val_loss: 0.8023\n",
            "Epoch 342/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.5303 - val_loss: 0.8350\n",
            "Epoch 343/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.5288 - val_loss: 0.8193\n",
            "Epoch 344/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.5275 - val_loss: 0.7707\n",
            "Epoch 345/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.5262 - val_loss: 0.8541\n",
            "Epoch 346/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.5268 - val_loss: 0.8314\n",
            "Epoch 347/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.5248 - val_loss: 0.8158\n",
            "Epoch 348/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.5237 - val_loss: 0.8192\n",
            "Epoch 349/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.5232 - val_loss: 0.8264\n",
            "Epoch 350/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.5222 - val_loss: 0.8176\n",
            "Epoch 351/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.5213 - val_loss: 0.8601\n",
            "Epoch 352/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.5198 - val_loss: 0.8220\n",
            "Epoch 353/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.5184 - val_loss: 0.8510\n",
            "Epoch 354/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.5177 - val_loss: 0.8595\n",
            "Epoch 355/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.5183 - val_loss: 0.7813\n",
            "Epoch 356/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.5156 - val_loss: 0.8168\n",
            "Epoch 357/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.5150 - val_loss: 0.8121\n",
            "Epoch 358/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.5144 - val_loss: 0.8447\n",
            "Epoch 359/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.5139 - val_loss: 0.8333\n",
            "Epoch 360/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.5115 - val_loss: 0.8783\n",
            "Epoch 361/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.5112 - val_loss: 0.8000\n",
            "Epoch 362/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.5101 - val_loss: 0.8216\n",
            "Epoch 363/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.5098 - val_loss: 0.7805\n",
            "Epoch 364/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.5094 - val_loss: 0.8255\n",
            "Epoch 365/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.5077 - val_loss: 0.8103\n",
            "Epoch 366/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.5075 - val_loss: 0.8494\n",
            "Epoch 367/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.5060 - val_loss: 0.7869\n",
            "Epoch 368/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.5046 - val_loss: 0.8227\n",
            "Epoch 369/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.5045 - val_loss: 0.8066\n",
            "Epoch 370/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.5042 - val_loss: 0.8598\n",
            "Epoch 371/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.5033 - val_loss: 0.7668\n",
            "Epoch 372/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.5012 - val_loss: 0.7426\n",
            "Epoch 373/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.5015 - val_loss: 0.7865\n",
            "Epoch 374/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4995 - val_loss: 0.7586\n",
            "Epoch 375/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4991 - val_loss: 0.8067\n",
            "Epoch 376/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4994 - val_loss: 0.7686\n",
            "Epoch 377/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4970 - val_loss: 0.7850\n",
            "Epoch 378/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4975 - val_loss: 0.7447\n",
            "Epoch 379/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4971 - val_loss: 0.8058\n",
            "Epoch 380/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4960 - val_loss: 0.8018\n",
            "Epoch 381/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4945 - val_loss: 0.7722\n",
            "Epoch 382/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4934 - val_loss: 0.7771\n",
            "Epoch 383/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4924 - val_loss: 0.8159\n",
            "Epoch 384/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4920 - val_loss: 0.8319\n",
            "Epoch 385/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4923 - val_loss: 0.8172\n",
            "Epoch 386/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4909 - val_loss: 0.7769\n",
            "Epoch 387/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4895 - val_loss: 0.8165\n",
            "Epoch 388/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4888 - val_loss: 0.8161\n",
            "Epoch 389/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4882 - val_loss: 0.7909\n",
            "Epoch 390/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4873 - val_loss: 0.7413\n",
            "Epoch 391/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4868 - val_loss: 0.8110\n",
            "Epoch 392/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4863 - val_loss: 0.8589\n",
            "Epoch 393/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4862 - val_loss: 0.7979\n",
            "Epoch 394/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4844 - val_loss: 0.7797\n",
            "Epoch 395/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4845 - val_loss: 0.7578\n",
            "Epoch 396/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4835 - val_loss: 0.8289\n",
            "Epoch 397/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4825 - val_loss: 0.7763\n",
            "Epoch 398/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4818 - val_loss: 0.8014\n",
            "Epoch 399/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4810 - val_loss: 0.7739\n",
            "Epoch 400/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4804 - val_loss: 0.8175\n",
            "Epoch 401/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4792 - val_loss: 0.7738\n",
            "Epoch 402/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4791 - val_loss: 0.8008\n",
            "Epoch 403/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4782 - val_loss: 0.8257\n",
            "Epoch 404/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4783 - val_loss: 0.8533\n",
            "Epoch 405/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4771 - val_loss: 0.7603\n",
            "Epoch 406/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4763 - val_loss: 0.7905\n",
            "Epoch 407/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4751 - val_loss: 0.7317\n",
            "Epoch 408/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4748 - val_loss: 0.7583\n",
            "Epoch 409/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4746 - val_loss: 0.7764\n",
            "Epoch 410/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4736 - val_loss: 0.8049\n",
            "Epoch 411/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4733 - val_loss: 0.7813\n",
            "Epoch 412/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4723 - val_loss: 0.7982\n",
            "Epoch 413/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4717 - val_loss: 0.8164\n",
            "Epoch 414/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4712 - val_loss: 0.7575\n",
            "Epoch 415/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4711 - val_loss: 0.7983\n",
            "Epoch 416/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4699 - val_loss: 0.7674\n",
            "Epoch 417/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4702 - val_loss: 0.7826\n",
            "Epoch 418/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4682 - val_loss: 0.7702\n",
            "Epoch 419/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4679 - val_loss: 0.8003\n",
            "Epoch 420/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4680 - val_loss: 0.7863\n",
            "Epoch 421/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4675 - val_loss: 0.8263\n",
            "Epoch 422/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4665 - val_loss: 0.7925\n",
            "Epoch 423/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4650 - val_loss: 0.7944\n",
            "Epoch 424/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4645 - val_loss: 0.7495\n",
            "Epoch 425/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4639 - val_loss: 0.7841\n",
            "Epoch 426/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4635 - val_loss: 0.7807\n",
            "Epoch 427/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4635 - val_loss: 0.7444\n",
            "Epoch 428/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4608 - val_loss: 0.8706\n",
            "Epoch 429/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4620 - val_loss: 0.7754\n",
            "Epoch 430/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4613 - val_loss: 0.8019\n",
            "Epoch 431/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4615 - val_loss: 0.8122\n",
            "Epoch 432/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4605 - val_loss: 0.8350\n",
            "Epoch 433/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4597 - val_loss: 0.7928\n",
            "Epoch 434/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4594 - val_loss: 0.7883\n",
            "Epoch 435/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4583 - val_loss: 0.8085\n",
            "Epoch 436/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4589 - val_loss: 0.7821\n",
            "Epoch 437/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4576 - val_loss: 0.7533\n",
            "Epoch 438/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4574 - val_loss: 0.7716\n",
            "Epoch 439/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4563 - val_loss: 0.8295\n",
            "Epoch 440/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4554 - val_loss: 0.8640\n",
            "Epoch 441/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4562 - val_loss: 0.8166\n",
            "Epoch 442/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4551 - val_loss: 0.7836\n",
            "Epoch 443/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4535 - val_loss: 0.7566\n",
            "Epoch 444/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4539 - val_loss: 0.7553\n",
            "Epoch 445/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4528 - val_loss: 0.7363\n",
            "Epoch 446/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4531 - val_loss: 0.7870\n",
            "Epoch 447/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4523 - val_loss: 0.7982\n",
            "Epoch 448/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4516 - val_loss: 0.7681\n",
            "Epoch 449/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4514 - val_loss: 0.7814\n",
            "Epoch 450/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4508 - val_loss: 0.7613\n",
            "Epoch 451/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4516 - val_loss: 0.7440\n",
            "Epoch 452/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4490 - val_loss: 0.7943\n",
            "Epoch 453/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4493 - val_loss: 0.7816\n",
            "Epoch 454/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4487 - val_loss: 0.7853\n",
            "Epoch 455/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4481 - val_loss: 0.7727\n",
            "Epoch 456/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4478 - val_loss: 0.8210\n",
            "Epoch 457/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4478 - val_loss: 0.7750\n",
            "Epoch 458/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4473 - val_loss: 0.7864\n",
            "Epoch 459/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4458 - val_loss: 0.7463\n",
            "Epoch 460/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4451 - val_loss: 0.7345\n",
            "Epoch 461/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4451 - val_loss: 0.7710\n",
            "Epoch 462/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4456 - val_loss: 0.7729\n",
            "Epoch 463/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4442 - val_loss: 0.7832\n",
            "Epoch 464/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4432 - val_loss: 0.8243\n",
            "Epoch 465/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4436 - val_loss: 0.7968\n",
            "Epoch 466/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4439 - val_loss: 0.7126\n",
            "Epoch 467/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4428 - val_loss: 0.8388\n",
            "Epoch 468/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4437 - val_loss: 0.7525\n",
            "Epoch 469/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4421 - val_loss: 0.7460\n",
            "Epoch 470/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4409 - val_loss: 0.7206\n",
            "Epoch 471/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4405 - val_loss: 0.7429\n",
            "Epoch 472/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4393 - val_loss: 0.8851\n",
            "Epoch 473/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4402 - val_loss: 0.7844\n",
            "Epoch 474/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4401 - val_loss: 0.7651\n",
            "Epoch 475/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4394 - val_loss: 0.7388\n",
            "Epoch 476/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4382 - val_loss: 0.7862\n",
            "Epoch 477/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4380 - val_loss: 0.7773\n",
            "Epoch 478/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4383 - val_loss: 0.8007\n",
            "Epoch 479/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4375 - val_loss: 0.7126\n",
            "Epoch 480/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4373 - val_loss: 0.7784\n",
            "Epoch 481/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4373 - val_loss: 0.7506\n",
            "Epoch 482/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4371 - val_loss: 0.8227\n",
            "Epoch 483/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4359 - val_loss: 0.7378\n",
            "Epoch 484/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4354 - val_loss: 0.7472\n",
            "Epoch 485/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4350 - val_loss: 0.7639\n",
            "Epoch 486/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4339 - val_loss: 0.7291\n",
            "Epoch 487/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4347 - val_loss: 0.7931\n",
            "Epoch 488/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4339 - val_loss: 0.8028\n",
            "Epoch 489/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4337 - val_loss: 0.8117\n",
            "Epoch 490/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4327 - val_loss: 0.7439\n",
            "Epoch 491/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4319 - val_loss: 0.8464\n",
            "Epoch 492/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4321 - val_loss: 0.7640\n",
            "Epoch 493/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4324 - val_loss: 0.7810\n",
            "Epoch 494/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4319 - val_loss: 0.7706\n",
            "Epoch 495/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4313 - val_loss: 0.7500\n",
            "Epoch 496/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4323 - val_loss: 0.8098\n",
            "Epoch 497/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4299 - val_loss: 0.7442\n",
            "Epoch 498/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4297 - val_loss: 0.7664\n",
            "Epoch 499/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4295 - val_loss: 0.7823\n",
            "Epoch 500/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4285 - val_loss: 0.7641\n",
            "Epoch 501/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4281 - val_loss: 0.7814\n",
            "Epoch 502/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4279 - val_loss: 0.7976\n",
            "Epoch 503/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4280 - val_loss: 0.7035\n",
            "Epoch 504/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4271 - val_loss: 0.7187\n",
            "Epoch 505/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4269 - val_loss: 0.7416\n",
            "Epoch 506/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4268 - val_loss: 0.8114\n",
            "Epoch 507/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4274 - val_loss: 0.8135\n",
            "Epoch 508/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4264 - val_loss: 0.7267\n",
            "Epoch 509/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4261 - val_loss: 0.7518\n",
            "Epoch 510/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4261 - val_loss: 0.8360\n",
            "Epoch 511/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4251 - val_loss: 0.7018\n",
            "Epoch 512/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4254 - val_loss: 0.8134\n",
            "Epoch 513/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4245 - val_loss: 0.7572\n",
            "Epoch 514/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4239 - val_loss: 0.7573\n",
            "Epoch 515/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4238 - val_loss: 0.7972\n",
            "Epoch 516/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4227 - val_loss: 0.7913\n",
            "Epoch 517/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4221 - val_loss: 0.6905\n",
            "Epoch 518/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4225 - val_loss: 0.7500\n",
            "Epoch 519/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4227 - val_loss: 0.8238\n",
            "Epoch 520/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4213 - val_loss: 0.7660\n",
            "Epoch 521/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4198 - val_loss: 0.7614\n",
            "Epoch 522/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4209 - val_loss: 0.7345\n",
            "Epoch 523/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4203 - val_loss: 0.7196\n",
            "Epoch 524/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4210 - val_loss: 0.7288\n",
            "Epoch 525/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4202 - val_loss: 0.7196\n",
            "Epoch 526/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4204 - val_loss: 0.7728\n",
            "Epoch 527/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4211 - val_loss: 0.8494\n",
            "Epoch 528/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4186 - val_loss: 0.7347\n",
            "Epoch 529/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4184 - val_loss: 0.7817\n",
            "Epoch 530/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4193 - val_loss: 0.8368\n",
            "Epoch 531/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4179 - val_loss: 0.7398\n",
            "Epoch 532/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4173 - val_loss: 0.8683\n",
            "Epoch 533/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4182 - val_loss: 0.7726\n",
            "Epoch 534/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4175 - val_loss: 0.9031\n",
            "Epoch 535/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4170 - val_loss: 0.7883\n",
            "Epoch 536/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4160 - val_loss: 0.8025\n",
            "Epoch 537/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4160 - val_loss: 0.8149\n",
            "Epoch 538/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4160 - val_loss: 0.7975\n",
            "Epoch 539/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4159 - val_loss: 0.7566\n",
            "Epoch 540/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4148 - val_loss: 0.7996\n",
            "Epoch 541/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4139 - val_loss: 0.8164\n",
            "Epoch 542/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4149 - val_loss: 0.8541\n",
            "Epoch 543/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4139 - val_loss: 0.7816\n",
            "Epoch 544/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4137 - val_loss: 0.7969\n",
            "Epoch 545/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4133 - val_loss: 0.8180\n",
            "Epoch 546/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4128 - val_loss: 0.7413\n",
            "Epoch 547/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4134 - val_loss: 0.8111\n",
            "Epoch 548/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4124 - val_loss: 0.8240\n",
            "Epoch 549/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4119 - val_loss: 0.7741\n",
            "Epoch 550/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4122 - val_loss: 0.7938\n",
            "Epoch 551/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4114 - val_loss: 0.8241\n",
            "Epoch 552/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4114 - val_loss: 0.8634\n",
            "Epoch 553/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4113 - val_loss: 0.8562\n",
            "Epoch 554/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4111 - val_loss: 0.8481\n",
            "Epoch 555/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4099 - val_loss: 0.7712\n",
            "Epoch 556/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4108 - val_loss: 0.8387\n",
            "Epoch 557/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4104 - val_loss: 0.7890\n",
            "Epoch 558/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4096 - val_loss: 0.7740\n",
            "Epoch 559/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4090 - val_loss: 0.8468\n",
            "Epoch 560/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4086 - val_loss: 0.8390\n",
            "Epoch 561/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4078 - val_loss: 0.7966\n",
            "Epoch 562/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4078 - val_loss: 0.8119\n",
            "Epoch 563/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4076 - val_loss: 0.7425\n",
            "Epoch 564/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4077 - val_loss: 0.8088\n",
            "Epoch 565/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4069 - val_loss: 0.8038\n",
            "Epoch 566/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4068 - val_loss: 0.8244\n",
            "Epoch 567/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4073 - val_loss: 0.8329\n",
            "Epoch 568/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4075 - val_loss: 0.7818\n",
            "Epoch 569/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4049 - val_loss: 0.8480\n",
            "Epoch 570/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4057 - val_loss: 0.7927\n",
            "Epoch 571/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4072 - val_loss: 0.8648\n",
            "Epoch 572/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4057 - val_loss: 0.8728\n",
            "Epoch 573/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4059 - val_loss: 0.8531\n",
            "Epoch 574/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4038 - val_loss: 0.7535\n",
            "Epoch 575/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4053 - val_loss: 0.8221\n",
            "Epoch 576/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4034 - val_loss: 0.8196\n",
            "Epoch 577/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4029 - val_loss: 0.7767\n",
            "Epoch 578/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4041 - val_loss: 0.8512\n",
            "Epoch 579/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4035 - val_loss: 0.8841\n",
            "Epoch 580/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4022 - val_loss: 0.8626\n",
            "Epoch 581/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4035 - val_loss: 0.8634\n",
            "Epoch 582/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4025 - val_loss: 0.8633\n",
            "Epoch 583/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4020 - val_loss: 0.8917\n",
            "Epoch 584/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4020 - val_loss: 0.8188\n",
            "Epoch 585/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4021 - val_loss: 0.8549\n",
            "Epoch 586/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4020 - val_loss: 0.8592\n",
            "Epoch 587/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4022 - val_loss: 0.8989\n",
            "Epoch 588/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4003 - val_loss: 0.8587\n",
            "Epoch 589/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4021 - val_loss: 0.8794\n",
            "Epoch 590/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4000 - val_loss: 0.7901\n",
            "Epoch 591/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4000 - val_loss: 0.8548\n",
            "Epoch 592/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4000 - val_loss: 0.8423\n",
            "Epoch 593/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3998 - val_loss: 0.8603\n",
            "Epoch 594/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.4005 - val_loss: 0.8147\n",
            "Epoch 595/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3985 - val_loss: 0.7926\n",
            "Epoch 596/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3994 - val_loss: 0.8104\n",
            "Epoch 597/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3987 - val_loss: 0.7389\n",
            "Epoch 598/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3998 - val_loss: 0.8384\n",
            "Epoch 599/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3968 - val_loss: 0.7625\n",
            "Epoch 600/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3975 - val_loss: 0.8259\n",
            "Epoch 601/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3975 - val_loss: 0.8555\n",
            "Epoch 602/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3979 - val_loss: 0.8452\n",
            "Epoch 603/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3985 - val_loss: 0.8387\n",
            "Epoch 604/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3968 - val_loss: 0.7978\n",
            "Epoch 605/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3969 - val_loss: 0.7996\n",
            "Epoch 606/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3979 - val_loss: 0.8734\n",
            "Epoch 607/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3953 - val_loss: 0.8288\n",
            "Epoch 608/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3960 - val_loss: 0.8464\n",
            "Epoch 609/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3958 - val_loss: 0.8859\n",
            "Epoch 610/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3959 - val_loss: 0.8223\n",
            "Epoch 611/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3940 - val_loss: 0.8301\n",
            "Epoch 612/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3941 - val_loss: 0.8075\n",
            "Epoch 613/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3952 - val_loss: 0.8416\n",
            "Epoch 614/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3944 - val_loss: 0.7783\n",
            "Epoch 615/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3944 - val_loss: 0.8514\n",
            "Epoch 616/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3949 - val_loss: 0.8873\n",
            "Epoch 617/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3934 - val_loss: 0.8591\n",
            "Epoch 618/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3943 - val_loss: 0.8284\n",
            "Epoch 619/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3928 - val_loss: 0.8762\n",
            "Epoch 620/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3937 - val_loss: 0.7252\n",
            "Epoch 621/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3938 - val_loss: 0.8649\n",
            "Epoch 622/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3915 - val_loss: 0.7913\n",
            "Epoch 623/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3939 - val_loss: 0.8219\n",
            "Epoch 624/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3919 - val_loss: 0.7934\n",
            "Epoch 625/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3914 - val_loss: 0.7940\n",
            "Epoch 626/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3922 - val_loss: 0.9160\n",
            "Epoch 627/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3910 - val_loss: 0.7827\n",
            "Epoch 628/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3914 - val_loss: 0.8276\n",
            "Epoch 629/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3916 - val_loss: 0.8467\n",
            "Epoch 630/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3930 - val_loss: 0.8216\n",
            "Epoch 631/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3902 - val_loss: 0.8244\n",
            "Epoch 632/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3904 - val_loss: 0.8546\n",
            "Epoch 633/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3895 - val_loss: 0.8883\n",
            "Epoch 634/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3916 - val_loss: 0.8646\n",
            "Epoch 635/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3899 - val_loss: 0.8915\n",
            "Epoch 636/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3904 - val_loss: 0.8561\n",
            "Epoch 637/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3896 - val_loss: 0.8539\n",
            "Epoch 638/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3881 - val_loss: 0.7966\n",
            "Epoch 639/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3901 - val_loss: 0.8677\n",
            "Epoch 640/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3888 - val_loss: 0.9117\n",
            "Epoch 641/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3885 - val_loss: 0.7735\n",
            "Epoch 642/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3892 - val_loss: 0.8393\n",
            "Epoch 643/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3874 - val_loss: 0.8876\n",
            "Epoch 644/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3889 - val_loss: 0.8745\n",
            "Epoch 645/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3874 - val_loss: 0.8603\n",
            "Epoch 646/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3866 - val_loss: 1.0143\n",
            "Epoch 647/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3877 - val_loss: 0.8343\n",
            "Epoch 648/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3881 - val_loss: 0.8842\n",
            "Epoch 649/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3869 - val_loss: 0.8152\n",
            "Epoch 650/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3864 - val_loss: 0.8604\n",
            "Epoch 651/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3872 - val_loss: 0.8867\n",
            "Epoch 652/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3863 - val_loss: 0.8336\n",
            "Epoch 653/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3861 - val_loss: 0.7996\n",
            "Epoch 654/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3862 - val_loss: 0.9153\n",
            "Epoch 655/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3864 - val_loss: 0.8922\n",
            "Epoch 656/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3847 - val_loss: 0.8381\n",
            "Epoch 657/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3847 - val_loss: 0.7797\n",
            "Epoch 658/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3859 - val_loss: 0.8499\n",
            "Epoch 659/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3852 - val_loss: 0.8401\n",
            "Epoch 660/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3851 - val_loss: 0.8413\n",
            "Epoch 661/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3837 - val_loss: 0.9245\n",
            "Epoch 662/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3840 - val_loss: 0.7865\n",
            "Epoch 663/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3841 - val_loss: 0.8963\n",
            "Epoch 664/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3834 - val_loss: 0.8980\n",
            "Epoch 665/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3837 - val_loss: 0.8501\n",
            "Epoch 666/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3839 - val_loss: 0.8146\n",
            "Epoch 667/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3842 - val_loss: 0.8873\n",
            "Epoch 668/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3838 - val_loss: 0.8023\n",
            "Epoch 669/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3823 - val_loss: 0.8359\n",
            "Epoch 670/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3832 - val_loss: 0.8812\n",
            "Epoch 671/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3833 - val_loss: 0.8712\n",
            "Epoch 672/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3823 - val_loss: 0.8167\n",
            "Epoch 673/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3815 - val_loss: 0.7917\n",
            "Epoch 674/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3816 - val_loss: 0.8854\n",
            "Epoch 675/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3813 - val_loss: 0.8908\n",
            "Epoch 676/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3816 - val_loss: 0.8181\n",
            "Epoch 677/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3822 - val_loss: 0.9009\n",
            "Epoch 678/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3821 - val_loss: 0.8628\n",
            "Epoch 679/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3808 - val_loss: 0.8899\n",
            "Epoch 680/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3800 - val_loss: 0.8787\n",
            "Epoch 681/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3804 - val_loss: 0.8900\n",
            "Epoch 682/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3805 - val_loss: 0.8427\n",
            "Epoch 683/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3796 - val_loss: 0.8555\n",
            "Epoch 684/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3804 - val_loss: 0.8221\n",
            "Epoch 685/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3809 - val_loss: 0.8522\n",
            "Epoch 686/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3801 - val_loss: 0.8075\n",
            "Epoch 687/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3799 - val_loss: 0.8019\n",
            "Epoch 688/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3793 - val_loss: 0.8723\n",
            "Epoch 689/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3801 - val_loss: 0.8651\n",
            "Epoch 690/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3798 - val_loss: 0.8057\n",
            "Epoch 691/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3800 - val_loss: 0.9032\n",
            "Epoch 692/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3792 - val_loss: 0.8259\n",
            "Epoch 693/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3794 - val_loss: 0.9228\n",
            "Epoch 694/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3785 - val_loss: 0.8821\n",
            "Epoch 695/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3776 - val_loss: 0.9458\n",
            "Epoch 696/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3800 - val_loss: 0.8240\n",
            "Epoch 697/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3777 - val_loss: 0.8339\n",
            "Epoch 698/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3773 - val_loss: 0.8325\n",
            "Epoch 699/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3773 - val_loss: 0.8899\n",
            "Epoch 700/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3769 - val_loss: 0.8548\n",
            "Epoch 701/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3777 - val_loss: 0.9203\n",
            "Epoch 702/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3774 - val_loss: 0.8902\n",
            "Epoch 703/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3762 - val_loss: 0.7955\n",
            "Epoch 704/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3763 - val_loss: 0.8163\n",
            "Epoch 705/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3765 - val_loss: 0.9433\n",
            "Epoch 706/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3770 - val_loss: 0.8768\n",
            "Epoch 707/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3769 - val_loss: 0.8116\n",
            "Epoch 708/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3760 - val_loss: 0.8790\n",
            "Epoch 709/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3763 - val_loss: 0.8409\n",
            "Epoch 710/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3759 - val_loss: 0.8298\n",
            "Epoch 711/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3759 - val_loss: 0.8518\n",
            "Epoch 712/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3749 - val_loss: 0.8587\n",
            "Epoch 713/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3756 - val_loss: 0.8440\n",
            "Epoch 714/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3764 - val_loss: 1.0034\n",
            "Epoch 715/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3762 - val_loss: 0.8838\n",
            "Epoch 716/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3752 - val_loss: 0.8556\n",
            "Epoch 717/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3748 - val_loss: 0.9084\n",
            "Epoch 718/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3748 - val_loss: 0.8635\n",
            "Epoch 719/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3747 - val_loss: 0.8452\n",
            "Epoch 720/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3744 - val_loss: 0.9041\n",
            "Epoch 721/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3733 - val_loss: 1.0016\n",
            "Epoch 722/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3752 - val_loss: 0.8536\n",
            "Epoch 723/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3740 - val_loss: 0.8545\n",
            "Epoch 724/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3731 - val_loss: 0.9713\n",
            "Epoch 725/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3745 - val_loss: 0.7998\n",
            "Epoch 726/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3738 - val_loss: 0.9663\n",
            "Epoch 727/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3737 - val_loss: 0.8667\n",
            "Epoch 728/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3739 - val_loss: 0.8238\n",
            "Epoch 729/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3750 - val_loss: 0.8894\n",
            "Epoch 730/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3719 - val_loss: 0.8921\n",
            "Epoch 731/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3729 - val_loss: 0.8477\n",
            "Epoch 732/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3737 - val_loss: 0.9307\n",
            "Epoch 733/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3723 - val_loss: 0.8825\n",
            "Epoch 734/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3724 - val_loss: 0.8854\n",
            "Epoch 735/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3724 - val_loss: 0.9040\n",
            "Epoch 736/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3734 - val_loss: 0.8895\n",
            "Epoch 737/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3708 - val_loss: 0.8799\n",
            "Epoch 738/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3720 - val_loss: 0.8781\n",
            "Epoch 739/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3719 - val_loss: 0.8384\n",
            "Epoch 740/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3710 - val_loss: 0.8495\n",
            "Epoch 741/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3723 - val_loss: 0.8327\n",
            "Epoch 742/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3725 - val_loss: 0.9084\n",
            "Epoch 743/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3719 - val_loss: 0.9075\n",
            "Epoch 744/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3697 - val_loss: 0.9368\n",
            "Epoch 745/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3698 - val_loss: 0.8070\n",
            "Epoch 746/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3696 - val_loss: 0.8499\n",
            "Epoch 747/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3700 - val_loss: 0.8676\n",
            "Epoch 748/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3704 - val_loss: 0.9628\n",
            "Epoch 749/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3698 - val_loss: 0.9241\n",
            "Epoch 750/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3701 - val_loss: 0.8477\n",
            "Epoch 751/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3692 - val_loss: 0.9610\n",
            "Epoch 752/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3693 - val_loss: 0.9304\n",
            "Epoch 753/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3695 - val_loss: 1.0381\n",
            "Epoch 754/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3704 - val_loss: 0.8988\n",
            "Epoch 755/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3688 - val_loss: 0.8511\n",
            "Epoch 756/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3702 - val_loss: 1.0176\n",
            "Epoch 757/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3687 - val_loss: 0.8208\n",
            "Epoch 758/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3694 - val_loss: 0.8833\n",
            "Epoch 759/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3701 - val_loss: 0.9134\n",
            "Epoch 760/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3684 - val_loss: 0.8019\n",
            "Epoch 761/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3700 - val_loss: 0.9046\n",
            "Epoch 762/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3675 - val_loss: 0.8794\n",
            "Epoch 763/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3697 - val_loss: 0.9715\n",
            "Epoch 764/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3682 - val_loss: 0.8152\n",
            "Epoch 765/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3682 - val_loss: 0.9159\n",
            "Epoch 766/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3682 - val_loss: 0.8601\n",
            "Epoch 767/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3675 - val_loss: 0.8161\n",
            "Epoch 768/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3676 - val_loss: 0.9040\n",
            "Epoch 769/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3672 - val_loss: 0.8820\n",
            "Epoch 770/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3683 - val_loss: 0.9370\n",
            "Epoch 771/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3666 - val_loss: 0.8496\n",
            "Epoch 772/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3664 - val_loss: 0.8959\n",
            "Epoch 773/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3688 - val_loss: 0.9230\n",
            "Epoch 774/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3670 - val_loss: 0.9306\n",
            "Epoch 775/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3664 - val_loss: 0.8893\n",
            "Epoch 776/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3661 - val_loss: 1.0463\n",
            "Epoch 777/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3671 - val_loss: 0.8921\n",
            "Epoch 778/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3668 - val_loss: 0.8905\n",
            "Epoch 779/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3667 - val_loss: 0.9718\n",
            "Epoch 780/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3658 - val_loss: 0.9144\n",
            "Epoch 781/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3649 - val_loss: 0.9981\n",
            "Epoch 782/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3677 - val_loss: 0.9348\n",
            "Epoch 783/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3649 - val_loss: 0.8240\n",
            "Epoch 784/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3655 - val_loss: 0.8039\n",
            "Epoch 785/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3662 - val_loss: 0.9064\n",
            "Epoch 786/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3647 - val_loss: 0.8607\n",
            "Epoch 787/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3649 - val_loss: 0.9523\n",
            "Epoch 788/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3644 - val_loss: 0.9488\n",
            "Epoch 789/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3647 - val_loss: 0.8703\n",
            "Epoch 790/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3645 - val_loss: 0.8350\n",
            "Epoch 791/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3653 - val_loss: 0.8824\n",
            "Epoch 792/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3645 - val_loss: 0.8732\n",
            "Epoch 793/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3642 - val_loss: 0.8567\n",
            "Epoch 794/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3654 - val_loss: 0.9099\n",
            "Epoch 795/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3641 - val_loss: 0.9418\n",
            "Epoch 796/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3644 - val_loss: 0.9593\n",
            "Epoch 797/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3642 - val_loss: 0.9183\n",
            "Epoch 798/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3642 - val_loss: 0.9208\n",
            "Epoch 799/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3632 - val_loss: 0.9227\n",
            "Epoch 800/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3635 - val_loss: 0.8551\n",
            "Epoch 801/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3632 - val_loss: 0.9830\n",
            "Epoch 802/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3630 - val_loss: 0.8417\n",
            "Epoch 803/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3633 - val_loss: 0.8516\n",
            "Epoch 804/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3643 - val_loss: 0.8312\n",
            "Epoch 805/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3630 - val_loss: 0.8952\n",
            "Epoch 806/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3625 - val_loss: 0.9008\n",
            "Epoch 807/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3630 - val_loss: 0.8705\n",
            "Epoch 808/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3622 - val_loss: 0.9196\n",
            "Epoch 809/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3628 - val_loss: 0.8703\n",
            "Epoch 810/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3620 - val_loss: 0.8405\n",
            "Epoch 811/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3625 - val_loss: 0.9675\n",
            "Epoch 812/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3630 - val_loss: 0.9002\n",
            "Epoch 813/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3618 - val_loss: 0.8258\n",
            "Epoch 814/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3621 - val_loss: 0.8436\n",
            "Epoch 815/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3621 - val_loss: 0.7800\n",
            "Epoch 816/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3625 - val_loss: 0.8427\n",
            "Epoch 817/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3625 - val_loss: 0.8752\n",
            "Epoch 818/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3618 - val_loss: 0.9359\n",
            "Epoch 819/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3605 - val_loss: 0.8667\n",
            "Epoch 820/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3611 - val_loss: 0.9744\n",
            "Epoch 821/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3607 - val_loss: 1.0426\n",
            "Epoch 822/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3618 - val_loss: 0.9632\n",
            "Epoch 823/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3609 - val_loss: 0.8771\n",
            "Epoch 824/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3608 - val_loss: 0.8957\n",
            "Epoch 825/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3606 - val_loss: 0.8497\n",
            "Epoch 826/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3600 - val_loss: 0.9970\n",
            "Epoch 827/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3601 - val_loss: 0.9105\n",
            "Epoch 828/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3606 - val_loss: 0.9133\n",
            "Epoch 829/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3603 - val_loss: 0.9605\n",
            "Epoch 830/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3594 - val_loss: 0.9261\n",
            "Epoch 831/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3601 - val_loss: 0.9173\n",
            "Epoch 832/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3591 - val_loss: 0.9570\n",
            "Epoch 833/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3595 - val_loss: 0.9044\n",
            "Epoch 834/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3594 - val_loss: 0.9132\n",
            "Epoch 835/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3588 - val_loss: 0.9242\n",
            "Epoch 836/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3595 - val_loss: 0.9026\n",
            "Epoch 837/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3594 - val_loss: 0.9284\n",
            "Epoch 838/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3611 - val_loss: 0.8833\n",
            "Epoch 839/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3599 - val_loss: 0.9189\n",
            "Epoch 840/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3595 - val_loss: 0.9832\n",
            "Epoch 841/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3596 - val_loss: 0.8499\n",
            "Epoch 842/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3589 - val_loss: 0.9149\n",
            "Epoch 843/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3584 - val_loss: 0.8122\n",
            "Epoch 844/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3600 - val_loss: 0.9087\n",
            "Epoch 845/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3600 - val_loss: 0.9646\n",
            "Epoch 846/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3584 - val_loss: 0.9278\n",
            "Epoch 847/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3588 - val_loss: 0.9561\n",
            "Epoch 848/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3583 - val_loss: 0.9408\n",
            "Epoch 849/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3589 - val_loss: 0.8684\n",
            "Epoch 850/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3586 - val_loss: 0.9442\n",
            "Epoch 851/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3589 - val_loss: 0.9408\n",
            "Epoch 852/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3572 - val_loss: 0.9416\n",
            "Epoch 853/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3575 - val_loss: 0.9948\n",
            "Epoch 854/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3588 - val_loss: 0.9139\n",
            "Epoch 855/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3566 - val_loss: 0.8956\n",
            "Epoch 856/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3572 - val_loss: 0.8801\n",
            "Epoch 857/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3567 - val_loss: 0.9868\n",
            "Epoch 858/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3568 - val_loss: 0.8756\n",
            "Epoch 859/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3579 - val_loss: 0.8555\n",
            "Epoch 860/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3578 - val_loss: 0.9676\n",
            "Epoch 861/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3594 - val_loss: 0.9369\n",
            "Epoch 862/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3574 - val_loss: 0.9497\n",
            "Epoch 863/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3568 - val_loss: 0.9512\n",
            "Epoch 864/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3569 - val_loss: 1.0397\n",
            "Epoch 865/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3572 - val_loss: 0.8855\n",
            "Epoch 866/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3566 - val_loss: 0.9675\n",
            "Epoch 867/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3565 - val_loss: 0.8331\n",
            "Epoch 868/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3563 - val_loss: 0.9789\n",
            "Epoch 869/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3570 - val_loss: 0.9122\n",
            "Epoch 870/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3561 - val_loss: 0.8867\n",
            "Epoch 871/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3566 - val_loss: 0.9714\n",
            "Epoch 872/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3561 - val_loss: 0.9095\n",
            "Epoch 873/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3567 - val_loss: 0.9034\n",
            "Epoch 874/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3562 - val_loss: 0.9144\n",
            "Epoch 875/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3557 - val_loss: 0.9580\n",
            "Epoch 876/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3546 - val_loss: 1.0138\n",
            "Epoch 877/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3572 - val_loss: 0.8650\n",
            "Epoch 878/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3552 - val_loss: 0.9033\n",
            "Epoch 879/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3548 - val_loss: 0.9865\n",
            "Epoch 880/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3552 - val_loss: 0.8618\n",
            "Epoch 881/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3541 - val_loss: 1.0733\n",
            "Epoch 882/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3536 - val_loss: 1.1097\n",
            "Epoch 883/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3552 - val_loss: 0.9307\n",
            "Epoch 884/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3536 - val_loss: 1.0386\n",
            "Epoch 885/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3556 - val_loss: 0.9063\n",
            "Epoch 886/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3538 - val_loss: 1.0734\n",
            "Epoch 887/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3541 - val_loss: 1.0366\n",
            "Epoch 888/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3538 - val_loss: 0.8512\n",
            "Epoch 889/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3552 - val_loss: 0.9566\n",
            "Epoch 890/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3550 - val_loss: 0.9138\n",
            "Epoch 891/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3532 - val_loss: 0.9919\n",
            "Epoch 892/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3530 - val_loss: 0.9840\n",
            "Epoch 893/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3541 - val_loss: 0.9137\n",
            "Epoch 894/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3545 - val_loss: 0.9928\n",
            "Epoch 895/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3557 - val_loss: 0.8840\n",
            "Epoch 896/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3540 - val_loss: 0.9195\n",
            "Epoch 897/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3533 - val_loss: 0.8226\n",
            "Epoch 898/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3548 - val_loss: 0.8648\n",
            "Epoch 899/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3536 - val_loss: 0.9925\n",
            "Epoch 900/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3540 - val_loss: 0.9760\n",
            "Epoch 901/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3520 - val_loss: 1.0251\n",
            "Epoch 902/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3530 - val_loss: 0.9605\n",
            "Epoch 903/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3538 - val_loss: 1.0202\n",
            "Epoch 904/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3553 - val_loss: 0.9999\n",
            "Epoch 905/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3518 - val_loss: 1.0216\n",
            "Epoch 906/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3526 - val_loss: 0.9205\n",
            "Epoch 907/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3525 - val_loss: 0.9439\n",
            "Epoch 908/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3525 - val_loss: 0.8889\n",
            "Epoch 909/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3524 - val_loss: 0.8633\n",
            "Epoch 910/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3513 - val_loss: 1.0616\n",
            "Epoch 911/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3532 - val_loss: 0.9730\n",
            "Epoch 912/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3514 - val_loss: 0.8631\n",
            "Epoch 913/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3541 - val_loss: 0.9471\n",
            "Epoch 914/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3525 - val_loss: 0.8904\n",
            "Epoch 915/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3532 - val_loss: 0.9810\n",
            "Epoch 916/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3525 - val_loss: 0.8740\n",
            "Epoch 917/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3508 - val_loss: 0.9361\n",
            "Epoch 918/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3517 - val_loss: 0.9516\n",
            "Epoch 919/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3519 - val_loss: 0.9558\n",
            "Epoch 920/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3514 - val_loss: 0.9214\n",
            "Epoch 921/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3511 - val_loss: 1.0317\n",
            "Epoch 922/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3524 - val_loss: 0.8557\n",
            "Epoch 923/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3518 - val_loss: 0.9336\n",
            "Epoch 924/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3522 - val_loss: 1.0600\n",
            "Epoch 925/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3526 - val_loss: 0.9211\n",
            "Epoch 926/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3518 - val_loss: 0.9421\n",
            "Epoch 927/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3503 - val_loss: 0.9284\n",
            "Epoch 928/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3508 - val_loss: 0.9289\n",
            "Epoch 929/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3513 - val_loss: 0.9883\n",
            "Epoch 930/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3505 - val_loss: 0.9478\n",
            "Epoch 931/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3502 - val_loss: 0.9456\n",
            "Epoch 932/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3501 - val_loss: 1.0205\n",
            "Epoch 933/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3505 - val_loss: 1.0208\n",
            "Epoch 934/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3513 - val_loss: 0.9460\n",
            "Epoch 935/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3505 - val_loss: 0.9707\n",
            "Epoch 936/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3504 - val_loss: 0.9828\n",
            "Epoch 937/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3495 - val_loss: 0.9131\n",
            "Epoch 938/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3500 - val_loss: 1.0109\n",
            "Epoch 939/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3491 - val_loss: 0.9908\n",
            "Epoch 940/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3480 - val_loss: 1.0521\n",
            "Epoch 941/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3494 - val_loss: 0.8424\n",
            "Epoch 942/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3494 - val_loss: 0.8989\n",
            "Epoch 943/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3514 - val_loss: 1.0514\n",
            "Epoch 944/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3509 - val_loss: 0.9563\n",
            "Epoch 945/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3488 - val_loss: 0.8550\n",
            "Epoch 946/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3509 - val_loss: 0.9405\n",
            "Epoch 947/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3505 - val_loss: 0.8938\n",
            "Epoch 948/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3484 - val_loss: 1.0023\n",
            "Epoch 949/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3491 - val_loss: 0.8898\n",
            "Epoch 950/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3494 - val_loss: 0.9956\n",
            "Epoch 951/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3490 - val_loss: 0.8758\n",
            "Epoch 952/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3487 - val_loss: 0.9405\n",
            "Epoch 953/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3499 - val_loss: 0.8817\n",
            "Epoch 954/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3507 - val_loss: 0.9472\n",
            "Epoch 955/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3488 - val_loss: 1.0060\n",
            "Epoch 956/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3468 - val_loss: 0.9808\n",
            "Epoch 957/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3480 - val_loss: 1.0204\n",
            "Epoch 958/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3489 - val_loss: 0.9749\n",
            "Epoch 959/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3491 - val_loss: 0.9312\n",
            "Epoch 960/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3498 - val_loss: 0.9598\n",
            "Epoch 961/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3499 - val_loss: 0.9738\n",
            "Epoch 962/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3487 - val_loss: 0.8935\n",
            "Epoch 963/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3488 - val_loss: 0.9034\n",
            "Epoch 964/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3474 - val_loss: 0.9588\n",
            "Epoch 965/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3487 - val_loss: 0.9439\n",
            "Epoch 966/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3476 - val_loss: 1.0127\n",
            "Epoch 967/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3475 - val_loss: 1.0223\n",
            "Epoch 968/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3475 - val_loss: 1.0493\n",
            "Epoch 969/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3491 - val_loss: 0.8174\n",
            "Epoch 970/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3481 - val_loss: 0.9250\n",
            "Epoch 971/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3471 - val_loss: 1.0687\n",
            "Epoch 972/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3471 - val_loss: 0.9339\n",
            "Epoch 973/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3469 - val_loss: 0.9265\n",
            "Epoch 974/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3479 - val_loss: 1.0999\n",
            "Epoch 975/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3480 - val_loss: 1.0570\n",
            "Epoch 976/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3468 - val_loss: 1.0173\n",
            "Epoch 977/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3463 - val_loss: 0.9132\n",
            "Epoch 978/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3459 - val_loss: 1.1028\n",
            "Epoch 979/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3492 - val_loss: 1.0503\n",
            "Epoch 980/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3478 - val_loss: 0.9141\n",
            "Epoch 981/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3472 - val_loss: 0.9145\n",
            "Epoch 982/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3454 - val_loss: 1.0646\n",
            "Epoch 983/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3472 - val_loss: 0.9774\n",
            "Epoch 984/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3459 - val_loss: 1.1256\n",
            "Epoch 985/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3475 - val_loss: 1.0947\n",
            "Epoch 986/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3478 - val_loss: 0.9510\n",
            "Epoch 987/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3459 - val_loss: 1.1108\n",
            "Epoch 988/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3460 - val_loss: 1.0406\n",
            "Epoch 989/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3474 - val_loss: 0.9820\n",
            "Epoch 990/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3464 - val_loss: 0.9645\n",
            "Epoch 991/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3458 - val_loss: 0.9641\n",
            "Epoch 992/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3455 - val_loss: 1.0337\n",
            "Epoch 993/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3455 - val_loss: 0.9234\n",
            "Epoch 994/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3458 - val_loss: 0.9665\n",
            "Epoch 995/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3455 - val_loss: 0.9769\n",
            "Epoch 996/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3453 - val_loss: 0.9393\n",
            "Epoch 997/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3474 - val_loss: 0.9724\n",
            "Epoch 998/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3450 - val_loss: 0.9071\n",
            "Epoch 999/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3452 - val_loss: 0.9579\n",
            "Epoch 1000/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3454 - val_loss: 1.0301\n",
            "Epoch 1001/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3453 - val_loss: 0.9007\n",
            "Epoch 1002/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3446 - val_loss: 0.9844\n",
            "Epoch 1003/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3463 - val_loss: 0.8914\n",
            "Epoch 1004/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3445 - val_loss: 1.0312\n",
            "Epoch 1005/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3443 - val_loss: 0.9752\n",
            "Epoch 1006/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3441 - val_loss: 1.0138\n",
            "Epoch 1007/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3438 - val_loss: 1.0032\n",
            "Epoch 1008/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3470 - val_loss: 0.9779\n",
            "Epoch 1009/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3435 - val_loss: 1.0916\n",
            "Epoch 1010/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3463 - val_loss: 0.9249\n",
            "Epoch 1011/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3452 - val_loss: 1.0856\n",
            "Epoch 1012/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3436 - val_loss: 0.9670\n",
            "Epoch 1013/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3440 - val_loss: 0.9209\n",
            "Epoch 1014/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3430 - val_loss: 0.8685\n",
            "Epoch 1015/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3450 - val_loss: 0.9371\n",
            "Epoch 1016/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3448 - val_loss: 1.0260\n",
            "Epoch 1017/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3424 - val_loss: 1.1678\n",
            "Epoch 1018/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3444 - val_loss: 1.0427\n",
            "Epoch 1019/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3443 - val_loss: 1.0639\n",
            "Epoch 1020/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3463 - val_loss: 0.9117\n",
            "Epoch 1021/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3439 - val_loss: 0.9731\n",
            "Epoch 1022/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3425 - val_loss: 1.0610\n",
            "Epoch 1023/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3453 - val_loss: 0.9386\n",
            "Epoch 1024/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3440 - val_loss: 1.0341\n",
            "Epoch 1025/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3442 - val_loss: 1.0422\n",
            "Epoch 1026/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3432 - val_loss: 0.9572\n",
            "Epoch 1027/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3452 - val_loss: 0.9681\n",
            "Epoch 1028/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3441 - val_loss: 1.1166\n",
            "Epoch 1029/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3435 - val_loss: 0.8807\n",
            "Epoch 1030/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3432 - val_loss: 1.0496\n",
            "Epoch 1031/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3442 - val_loss: 0.9852\n",
            "Epoch 1032/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3426 - val_loss: 1.0052\n",
            "Epoch 1033/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3436 - val_loss: 1.1161\n",
            "Epoch 1034/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3458 - val_loss: 0.9467\n",
            "Epoch 1035/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3426 - val_loss: 1.0342\n",
            "Epoch 1036/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3422 - val_loss: 0.8781\n",
            "Epoch 1037/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3443 - val_loss: 0.9995\n",
            "Epoch 1038/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3433 - val_loss: 1.0130\n",
            "Epoch 1039/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3421 - val_loss: 1.0047\n",
            "Epoch 1040/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3444 - val_loss: 0.9954\n",
            "Epoch 1041/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3423 - val_loss: 0.9272\n",
            "Epoch 1042/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3439 - val_loss: 0.9140\n",
            "Epoch 1043/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3446 - val_loss: 1.0448\n",
            "Epoch 1044/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3435 - val_loss: 0.9953\n",
            "Epoch 1045/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3409 - val_loss: 1.1079\n",
            "Epoch 1046/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3433 - val_loss: 0.9600\n",
            "Epoch 1047/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3425 - val_loss: 1.0021\n",
            "Epoch 1048/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3409 - val_loss: 1.1659\n",
            "Epoch 1049/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3420 - val_loss: 0.9463\n",
            "Epoch 1050/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3412 - val_loss: 1.0448\n",
            "Epoch 1051/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3417 - val_loss: 1.1362\n",
            "Epoch 1052/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3439 - val_loss: 0.9404\n",
            "Epoch 1053/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3416 - val_loss: 0.9945\n",
            "Epoch 1054/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3410 - val_loss: 1.1203\n",
            "Epoch 1055/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3426 - val_loss: 0.9420\n",
            "Epoch 1056/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3420 - val_loss: 0.9519\n",
            "Epoch 1057/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3421 - val_loss: 0.9493\n",
            "Epoch 1058/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3421 - val_loss: 1.0019\n",
            "Epoch 1059/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3445 - val_loss: 0.9215\n",
            "Epoch 1060/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3418 - val_loss: 0.9433\n",
            "Epoch 1061/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3436 - val_loss: 0.8968\n",
            "Epoch 1062/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3411 - val_loss: 1.0027\n",
            "Epoch 1063/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3421 - val_loss: 0.9303\n",
            "Epoch 1064/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3403 - val_loss: 1.1045\n",
            "Epoch 1065/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3420 - val_loss: 0.8917\n",
            "Epoch 1066/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3420 - val_loss: 0.9878\n",
            "Epoch 1067/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3428 - val_loss: 0.9328\n",
            "Epoch 1068/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3408 - val_loss: 0.9860\n",
            "Epoch 1069/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3408 - val_loss: 1.0156\n",
            "Epoch 1070/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3397 - val_loss: 1.0529\n",
            "Epoch 1071/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3410 - val_loss: 1.0094\n",
            "Epoch 1072/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3419 - val_loss: 0.9336\n",
            "Epoch 1073/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3411 - val_loss: 1.0029\n",
            "Epoch 1074/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3404 - val_loss: 1.0181\n",
            "Epoch 1075/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3416 - val_loss: 0.8810\n",
            "Epoch 1076/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3405 - val_loss: 1.0391\n",
            "Epoch 1077/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3401 - val_loss: 1.0409\n",
            "Epoch 1078/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3414 - val_loss: 0.9787\n",
            "Epoch 1079/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3410 - val_loss: 1.0021\n",
            "Epoch 1080/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3404 - val_loss: 0.9453\n",
            "Epoch 1081/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3406 - val_loss: 0.9217\n",
            "Epoch 1082/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3417 - val_loss: 1.1097\n",
            "Epoch 1083/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3405 - val_loss: 1.0667\n",
            "Epoch 1084/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3412 - val_loss: 1.0301\n",
            "Epoch 1085/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3413 - val_loss: 0.9769\n",
            "Epoch 1086/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3394 - val_loss: 1.0609\n",
            "Epoch 1087/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3396 - val_loss: 1.0321\n",
            "Epoch 1088/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3395 - val_loss: 1.0019\n",
            "Epoch 1089/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3410 - val_loss: 1.0090\n",
            "Epoch 1090/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3396 - val_loss: 0.9949\n",
            "Epoch 1091/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3399 - val_loss: 0.9867\n",
            "Epoch 1092/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3394 - val_loss: 1.0489\n",
            "Epoch 1093/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3395 - val_loss: 1.0979\n",
            "Epoch 1094/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3395 - val_loss: 0.9888\n",
            "Epoch 1095/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3397 - val_loss: 1.0569\n",
            "Epoch 1096/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3397 - val_loss: 0.9598\n",
            "Epoch 1097/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3392 - val_loss: 0.8950\n",
            "Epoch 1098/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3380 - val_loss: 0.9813\n",
            "Epoch 1099/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3402 - val_loss: 0.9702\n",
            "Epoch 1100/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3396 - val_loss: 1.0153\n",
            "Epoch 1101/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3393 - val_loss: 1.3252\n",
            "Epoch 1102/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3398 - val_loss: 0.9486\n",
            "Epoch 1103/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3390 - val_loss: 1.0333\n",
            "Epoch 1104/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3380 - val_loss: 1.1090\n",
            "Epoch 1105/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3408 - val_loss: 0.8701\n",
            "Epoch 1106/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3382 - val_loss: 1.0085\n",
            "Epoch 1107/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3390 - val_loss: 1.0880\n",
            "Epoch 1108/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3385 - val_loss: 1.0734\n",
            "Epoch 1109/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3396 - val_loss: 1.0137\n",
            "Epoch 1110/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3384 - val_loss: 0.9532\n",
            "Epoch 1111/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3383 - val_loss: 1.1694\n",
            "Epoch 1112/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3399 - val_loss: 0.9708\n",
            "Epoch 1113/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3382 - val_loss: 1.0032\n",
            "Epoch 1114/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3389 - val_loss: 0.9567\n",
            "Epoch 1115/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3398 - val_loss: 0.9767\n",
            "Epoch 1116/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3374 - val_loss: 0.9884\n",
            "Epoch 1117/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3399 - val_loss: 0.9816\n",
            "Epoch 1118/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3371 - val_loss: 0.9403\n",
            "Epoch 1119/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3376 - val_loss: 1.1338\n",
            "Epoch 1120/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3400 - val_loss: 1.0954\n",
            "Epoch 1121/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3380 - val_loss: 1.0173\n",
            "Epoch 1122/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3391 - val_loss: 1.0398\n",
            "Epoch 1123/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3393 - val_loss: 1.0088\n",
            "Epoch 1124/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3369 - val_loss: 1.0384\n",
            "Epoch 1125/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3366 - val_loss: 1.1249\n",
            "Epoch 1126/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3363 - val_loss: 0.9140\n",
            "Epoch 1127/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3381 - val_loss: 0.9755\n",
            "Epoch 1128/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3377 - val_loss: 0.9734\n",
            "Epoch 1129/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3377 - val_loss: 0.9795\n",
            "Epoch 1130/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3372 - val_loss: 1.0262\n",
            "Epoch 1131/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3381 - val_loss: 1.1478\n",
            "Epoch 1132/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3380 - val_loss: 1.0532\n",
            "Epoch 1133/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3382 - val_loss: 1.0658\n",
            "Epoch 1134/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3396 - val_loss: 1.0738\n",
            "Epoch 1135/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3378 - val_loss: 1.0675\n",
            "Epoch 1136/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3385 - val_loss: 0.8721\n",
            "Epoch 1137/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3370 - val_loss: 0.9784\n",
            "Epoch 1138/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3362 - val_loss: 1.1502\n",
            "Epoch 1139/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3378 - val_loss: 1.0806\n",
            "Epoch 1140/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3365 - val_loss: 0.8925\n",
            "Epoch 1141/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3375 - val_loss: 1.0262\n",
            "Epoch 1142/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3374 - val_loss: 1.0784\n",
            "Epoch 1143/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3371 - val_loss: 1.1284\n",
            "Epoch 1144/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3376 - val_loss: 1.0691\n",
            "Epoch 1145/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3355 - val_loss: 1.0631\n",
            "Epoch 1146/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3366 - val_loss: 1.0325\n",
            "Epoch 1147/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3367 - val_loss: 1.0158\n",
            "Epoch 1148/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3365 - val_loss: 0.9862\n",
            "Epoch 1149/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3371 - val_loss: 0.9562\n",
            "Epoch 1150/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3366 - val_loss: 1.0456\n",
            "Epoch 1151/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3358 - val_loss: 1.0325\n",
            "Epoch 1152/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3358 - val_loss: 1.0134\n",
            "Epoch 1153/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3370 - val_loss: 1.1019\n",
            "Epoch 1154/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3365 - val_loss: 1.0973\n",
            "Epoch 1155/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3366 - val_loss: 0.9901\n",
            "Epoch 1156/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3368 - val_loss: 0.9770\n",
            "Epoch 1157/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3363 - val_loss: 1.0903\n",
            "Epoch 1158/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3366 - val_loss: 0.9785\n",
            "Epoch 1159/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3364 - val_loss: 1.0168\n",
            "Epoch 1160/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3354 - val_loss: 1.0575\n",
            "Epoch 1161/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3369 - val_loss: 1.0072\n",
            "Epoch 1162/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3365 - val_loss: 1.0343\n",
            "Epoch 1163/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3350 - val_loss: 1.1023\n",
            "Epoch 1164/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3362 - val_loss: 1.0531\n",
            "Epoch 1165/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3371 - val_loss: 1.0873\n",
            "Epoch 1166/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3351 - val_loss: 1.0223\n",
            "Epoch 1167/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3356 - val_loss: 1.0228\n",
            "Epoch 1168/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3359 - val_loss: 1.0484\n",
            "Epoch 1169/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3357 - val_loss: 1.0236\n",
            "Epoch 1170/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3344 - val_loss: 1.0561\n",
            "Epoch 1171/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3358 - val_loss: 1.0312\n",
            "Epoch 1172/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3353 - val_loss: 1.1273\n",
            "Epoch 1173/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3347 - val_loss: 1.0411\n",
            "Epoch 1174/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3354 - val_loss: 1.0025\n",
            "Epoch 1175/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3352 - val_loss: 0.9930\n",
            "Epoch 1176/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3353 - val_loss: 0.9548\n",
            "Epoch 1177/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3364 - val_loss: 1.0641\n",
            "Epoch 1178/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3346 - val_loss: 1.1479\n",
            "Epoch 1179/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3341 - val_loss: 1.0218\n",
            "Epoch 1180/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3352 - val_loss: 1.0159\n",
            "Epoch 1181/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3381 - val_loss: 1.0510\n",
            "Epoch 1182/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3337 - val_loss: 0.9272\n",
            "Epoch 1183/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3351 - val_loss: 1.1540\n",
            "Epoch 1184/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3353 - val_loss: 1.0488\n",
            "Epoch 1185/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3352 - val_loss: 1.0270\n",
            "Epoch 1186/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3340 - val_loss: 1.1162\n",
            "Epoch 1187/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3345 - val_loss: 1.0424\n",
            "Epoch 1188/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3347 - val_loss: 1.0885\n",
            "Epoch 1189/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3343 - val_loss: 1.0218\n",
            "Epoch 1190/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3348 - val_loss: 1.1266\n",
            "Epoch 1191/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3352 - val_loss: 1.1389\n",
            "Epoch 1192/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3338 - val_loss: 1.1071\n",
            "Epoch 1193/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3340 - val_loss: 0.9742\n",
            "Epoch 1194/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3334 - val_loss: 1.1099\n",
            "Epoch 1195/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3342 - val_loss: 1.0759\n",
            "Epoch 1196/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3344 - val_loss: 0.9887\n",
            "Epoch 1197/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3341 - val_loss: 1.0064\n",
            "Epoch 1198/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3347 - val_loss: 1.0348\n",
            "Epoch 1199/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3350 - val_loss: 0.9398\n",
            "Epoch 1200/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3330 - val_loss: 1.0521\n",
            "Epoch 1201/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3333 - val_loss: 1.1998\n",
            "Epoch 1202/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3342 - val_loss: 0.9949\n",
            "Epoch 1203/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3332 - val_loss: 1.1365\n",
            "Epoch 1204/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3346 - val_loss: 1.0400\n",
            "Epoch 1205/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3353 - val_loss: 1.0930\n",
            "Epoch 1206/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3340 - val_loss: 1.0969\n",
            "Epoch 1207/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3331 - val_loss: 1.0003\n",
            "Epoch 1208/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3333 - val_loss: 0.9558\n",
            "Epoch 1209/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3343 - val_loss: 1.0573\n",
            "Epoch 1210/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3332 - val_loss: 1.0684\n",
            "Epoch 1211/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3322 - val_loss: 1.1757\n",
            "Epoch 1212/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3336 - val_loss: 1.0637\n",
            "Epoch 1213/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3337 - val_loss: 1.1808\n",
            "Epoch 1214/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3336 - val_loss: 1.0247\n",
            "Epoch 1215/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3330 - val_loss: 0.9470\n",
            "Epoch 1216/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3330 - val_loss: 1.0374\n",
            "Epoch 1217/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3340 - val_loss: 1.0257\n",
            "Epoch 1218/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3330 - val_loss: 1.1312\n",
            "Epoch 1219/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3341 - val_loss: 1.0959\n",
            "Epoch 1220/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3337 - val_loss: 1.1864\n",
            "Epoch 1221/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3331 - val_loss: 1.0653\n",
            "Epoch 1222/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3326 - val_loss: 0.9634\n",
            "Epoch 1223/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3328 - val_loss: 1.1718\n",
            "Epoch 1224/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3335 - val_loss: 0.9078\n",
            "Epoch 1225/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3353 - val_loss: 1.0567\n",
            "Epoch 1226/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3334 - val_loss: 1.1011\n",
            "Epoch 1227/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3325 - val_loss: 1.1371\n",
            "Epoch 1228/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3321 - val_loss: 1.0404\n",
            "Epoch 1229/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3324 - val_loss: 1.0884\n",
            "Epoch 1230/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3347 - val_loss: 1.0160\n",
            "Epoch 1231/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3320 - val_loss: 1.0785\n",
            "Epoch 1232/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3315 - val_loss: 0.9959\n",
            "Epoch 1233/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3338 - val_loss: 1.1621\n",
            "Epoch 1234/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3323 - val_loss: 1.0785\n",
            "Epoch 1235/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3334 - val_loss: 1.1240\n",
            "Epoch 1236/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3317 - val_loss: 1.0263\n",
            "Epoch 1237/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3319 - val_loss: 0.9874\n",
            "Epoch 1238/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3322 - val_loss: 1.0626\n",
            "Epoch 1239/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3330 - val_loss: 1.1224\n",
            "Epoch 1240/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3316 - val_loss: 0.9879\n",
            "Epoch 1241/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3310 - val_loss: 1.1232\n",
            "Epoch 1242/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3318 - val_loss: 0.9697\n",
            "Epoch 1243/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3328 - val_loss: 1.0458\n",
            "Epoch 1244/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3314 - val_loss: 1.1230\n",
            "Epoch 1245/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3333 - val_loss: 1.0495\n",
            "Epoch 1246/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3338 - val_loss: 1.0220\n",
            "Epoch 1247/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3349 - val_loss: 1.0752\n",
            "Epoch 1248/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3313 - val_loss: 1.1702\n",
            "Epoch 1249/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3316 - val_loss: 1.0316\n",
            "Epoch 1250/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3331 - val_loss: 1.0534\n",
            "Epoch 1251/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3308 - val_loss: 0.9788\n",
            "Epoch 1252/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3317 - val_loss: 1.0708\n",
            "Epoch 1253/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3336 - val_loss: 1.0359\n",
            "Epoch 1254/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3319 - val_loss: 1.1155\n",
            "Epoch 1255/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3319 - val_loss: 1.0278\n",
            "Epoch 1256/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3317 - val_loss: 1.0123\n",
            "Epoch 1257/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3304 - val_loss: 1.0917\n",
            "Epoch 1258/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3314 - val_loss: 1.0727\n",
            "Epoch 1259/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3323 - val_loss: 1.0924\n",
            "Epoch 1260/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3311 - val_loss: 1.0940\n",
            "Epoch 1261/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3309 - val_loss: 1.1260\n",
            "Epoch 1262/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3316 - val_loss: 1.1184\n",
            "Epoch 1263/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3318 - val_loss: 1.1676\n",
            "Epoch 1264/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3312 - val_loss: 1.2086\n",
            "Epoch 1265/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3313 - val_loss: 1.0278\n",
            "Epoch 1266/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3317 - val_loss: 1.1251\n",
            "Epoch 1267/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3297 - val_loss: 1.0869\n",
            "Epoch 1268/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3310 - val_loss: 1.1327\n",
            "Epoch 1269/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3318 - val_loss: 1.1442\n",
            "Epoch 1270/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3315 - val_loss: 1.1144\n",
            "Epoch 1271/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3324 - val_loss: 1.0748\n",
            "Epoch 1272/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3313 - val_loss: 1.1887\n",
            "Epoch 1273/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3325 - val_loss: 1.0406\n",
            "Epoch 1274/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3333 - val_loss: 1.0396\n",
            "Epoch 1275/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3318 - val_loss: 1.0915\n",
            "Epoch 1276/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3312 - val_loss: 1.1851\n",
            "Epoch 1277/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3305 - val_loss: 1.0095\n",
            "Epoch 1278/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3302 - val_loss: 1.0012\n",
            "Epoch 1279/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3306 - val_loss: 1.0309\n",
            "Epoch 1280/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3316 - val_loss: 0.9407\n",
            "Epoch 1281/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3305 - val_loss: 1.0457\n",
            "Epoch 1282/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3302 - val_loss: 1.2017\n",
            "Epoch 1283/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3309 - val_loss: 0.9811\n",
            "Epoch 1284/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3300 - val_loss: 1.0967\n",
            "Epoch 1285/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3305 - val_loss: 1.1785\n",
            "Epoch 1286/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3304 - val_loss: 1.0710\n",
            "Epoch 1287/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3301 - val_loss: 1.1160\n",
            "Epoch 1288/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3308 - val_loss: 1.0026\n",
            "Epoch 1289/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3298 - val_loss: 1.1654\n",
            "Epoch 1290/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3309 - val_loss: 1.0859\n",
            "Epoch 1291/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3299 - val_loss: 1.2259\n",
            "Epoch 1292/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3313 - val_loss: 1.0775\n",
            "Epoch 1293/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3317 - val_loss: 1.0610\n",
            "Epoch 1294/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3308 - val_loss: 1.0852\n",
            "Epoch 1295/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3298 - val_loss: 1.0677\n",
            "Epoch 1296/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3306 - val_loss: 1.0900\n",
            "Epoch 1297/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3301 - val_loss: 1.1119\n",
            "Epoch 1298/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3329 - val_loss: 1.0286\n",
            "Epoch 1299/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3299 - val_loss: 1.0198\n",
            "Epoch 1300/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3287 - val_loss: 1.2115\n",
            "Epoch 1301/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3345 - val_loss: 1.0447\n",
            "Epoch 1302/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3290 - val_loss: 1.1112\n",
            "Epoch 1303/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3294 - val_loss: 1.0755\n",
            "Epoch 1304/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3296 - val_loss: 1.0644\n",
            "Epoch 1305/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3276 - val_loss: 1.2614\n",
            "Epoch 1306/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3296 - val_loss: 1.1300\n",
            "Epoch 1307/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3281 - val_loss: 1.0804\n",
            "Epoch 1308/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3312 - val_loss: 1.2880\n",
            "Epoch 1309/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3312 - val_loss: 1.1290\n",
            "Epoch 1310/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3293 - val_loss: 1.1346\n",
            "Epoch 1311/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3294 - val_loss: 1.1922\n",
            "Epoch 1312/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3309 - val_loss: 1.0316\n",
            "Epoch 1313/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3293 - val_loss: 1.2087\n",
            "Epoch 1314/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3295 - val_loss: 1.1213\n",
            "Epoch 1315/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3292 - val_loss: 1.1221\n",
            "Epoch 1316/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3292 - val_loss: 1.0967\n",
            "Epoch 1317/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3305 - val_loss: 1.1470\n",
            "Epoch 1318/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3286 - val_loss: 1.3086\n",
            "Epoch 1319/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3296 - val_loss: 1.0712\n",
            "Epoch 1320/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3292 - val_loss: 1.1447\n",
            "Epoch 1321/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3293 - val_loss: 1.1191\n",
            "Epoch 1322/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3286 - val_loss: 1.0628\n",
            "Epoch 1323/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3290 - val_loss: 1.1085\n",
            "Epoch 1324/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3286 - val_loss: 1.1554\n",
            "Epoch 1325/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3300 - val_loss: 1.0251\n",
            "Epoch 1326/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3291 - val_loss: 1.0260\n",
            "Epoch 1327/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3302 - val_loss: 1.1435\n",
            "Epoch 1328/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3296 - val_loss: 1.0694\n",
            "Epoch 1329/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3284 - val_loss: 1.2901\n",
            "Epoch 1330/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3308 - val_loss: 1.1024\n",
            "Epoch 1331/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3286 - val_loss: 1.1006\n",
            "Epoch 1332/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3279 - val_loss: 1.0957\n",
            "Epoch 1333/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3295 - val_loss: 1.0881\n",
            "Epoch 1334/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3294 - val_loss: 1.0839\n",
            "Epoch 1335/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3287 - val_loss: 1.1543\n",
            "Epoch 1336/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3287 - val_loss: 1.1660\n",
            "Epoch 1337/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3294 - val_loss: 1.1078\n",
            "Epoch 1338/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3281 - val_loss: 1.0864\n",
            "Epoch 1339/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3288 - val_loss: 1.0867\n",
            "Epoch 1340/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3286 - val_loss: 1.0297\n",
            "Epoch 1341/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3298 - val_loss: 1.1671\n",
            "Epoch 1342/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3283 - val_loss: 1.1581\n",
            "Epoch 1343/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3268 - val_loss: 1.2232\n",
            "Epoch 1344/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3298 - val_loss: 1.1375\n",
            "Epoch 1345/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3290 - val_loss: 1.1001\n",
            "Epoch 1346/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3281 - val_loss: 1.0841\n",
            "Epoch 1347/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3283 - val_loss: 1.0696\n",
            "Epoch 1348/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3298 - val_loss: 1.2204\n",
            "Epoch 1349/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3280 - val_loss: 1.0861\n",
            "Epoch 1350/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3274 - val_loss: 1.1963\n",
            "Epoch 1351/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3287 - val_loss: 1.2575\n",
            "Epoch 1352/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3289 - val_loss: 1.1401\n",
            "Epoch 1353/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3271 - val_loss: 1.1179\n",
            "Epoch 1354/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3274 - val_loss: 1.0979\n",
            "Epoch 1355/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3288 - val_loss: 1.1080\n",
            "Epoch 1356/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3276 - val_loss: 1.1393\n",
            "Epoch 1357/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3289 - val_loss: 1.0734\n",
            "Epoch 1358/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3293 - val_loss: 1.0601\n",
            "Epoch 1359/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3275 - val_loss: 1.0464\n",
            "Epoch 1360/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3290 - val_loss: 1.1965\n",
            "Epoch 1361/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3271 - val_loss: 1.0679\n",
            "Epoch 1362/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3270 - val_loss: 1.0807\n",
            "Epoch 1363/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3260 - val_loss: 1.2616\n",
            "Epoch 1364/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3294 - val_loss: 1.0914\n",
            "Epoch 1365/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3277 - val_loss: 1.1395\n",
            "Epoch 1366/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3279 - val_loss: 1.1030\n",
            "Epoch 1367/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3279 - val_loss: 1.1992\n",
            "Epoch 1368/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3276 - val_loss: 1.1580\n",
            "Epoch 1369/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3270 - val_loss: 1.0196\n",
            "Epoch 1370/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3283 - val_loss: 1.1079\n",
            "Epoch 1371/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3270 - val_loss: 1.2474\n",
            "Epoch 1372/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3286 - val_loss: 1.1698\n",
            "Epoch 1373/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3274 - val_loss: 1.1319\n",
            "Epoch 1374/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3264 - val_loss: 1.1133\n",
            "Epoch 1375/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3276 - val_loss: 1.1115\n",
            "Epoch 1376/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3277 - val_loss: 1.1310\n",
            "Epoch 1377/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3270 - val_loss: 1.1154\n",
            "Epoch 1378/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3276 - val_loss: 1.1167\n",
            "Epoch 1379/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3259 - val_loss: 1.1666\n",
            "Epoch 1380/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3276 - val_loss: 1.1498\n",
            "Epoch 1381/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3262 - val_loss: 1.2285\n",
            "Epoch 1382/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3263 - val_loss: 1.0944\n",
            "Epoch 1383/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3277 - val_loss: 1.2397\n",
            "Epoch 1384/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3270 - val_loss: 1.0574\n",
            "Epoch 1385/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3260 - val_loss: 0.9783\n",
            "Epoch 1386/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3262 - val_loss: 1.1288\n",
            "Epoch 1387/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3275 - val_loss: 1.1382\n",
            "Epoch 1388/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3266 - val_loss: 1.1280\n",
            "Epoch 1389/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3271 - val_loss: 1.0659\n",
            "Epoch 1390/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3251 - val_loss: 1.2236\n",
            "Epoch 1391/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3270 - val_loss: 1.1877\n",
            "Epoch 1392/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3277 - val_loss: 1.0450\n",
            "Epoch 1393/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3260 - val_loss: 1.1602\n",
            "Epoch 1394/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3263 - val_loss: 1.1599\n",
            "Epoch 1395/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3267 - val_loss: 1.0999\n",
            "Epoch 1396/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3261 - val_loss: 1.0955\n",
            "Epoch 1397/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3261 - val_loss: 1.1993\n",
            "Epoch 1398/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3285 - val_loss: 1.0807\n",
            "Epoch 1399/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3266 - val_loss: 1.1230\n",
            "Epoch 1400/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3265 - val_loss: 1.1677\n",
            "Epoch 1401/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3252 - val_loss: 1.1621\n",
            "Epoch 1402/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3261 - val_loss: 1.1159\n",
            "Epoch 1403/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3258 - val_loss: 1.1867\n",
            "Epoch 1404/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3256 - val_loss: 1.1625\n",
            "Epoch 1405/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3257 - val_loss: 1.1723\n",
            "Epoch 1406/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3256 - val_loss: 1.1149\n",
            "Epoch 1407/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3271 - val_loss: 1.1479\n",
            "Epoch 1408/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3270 - val_loss: 1.1478\n",
            "Epoch 1409/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3261 - val_loss: 1.1106\n",
            "Epoch 1410/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3270 - val_loss: 1.0535\n",
            "Epoch 1411/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3253 - val_loss: 1.0413\n",
            "Epoch 1412/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3248 - val_loss: 0.9850\n",
            "Epoch 1413/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3259 - val_loss: 1.2097\n",
            "Epoch 1414/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3296 - val_loss: 1.1901\n",
            "Epoch 1415/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3282 - val_loss: 1.2017\n",
            "Epoch 1416/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3254 - val_loss: 1.0744\n",
            "Epoch 1417/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3251 - val_loss: 1.0304\n",
            "Epoch 1418/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3263 - val_loss: 1.2360\n",
            "Epoch 1419/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3254 - val_loss: 1.1184\n",
            "Epoch 1420/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3262 - val_loss: 1.1219\n",
            "Epoch 1421/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3253 - val_loss: 1.1468\n",
            "Epoch 1422/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3267 - val_loss: 1.3832\n",
            "Epoch 1423/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3257 - val_loss: 1.0516\n",
            "Epoch 1424/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3258 - val_loss: 1.2022\n",
            "Epoch 1425/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3260 - val_loss: 1.0593\n",
            "Epoch 1426/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3264 - val_loss: 1.2462\n",
            "Epoch 1427/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3264 - val_loss: 1.1317\n",
            "Epoch 1428/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3241 - val_loss: 1.2993\n",
            "Epoch 1429/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3249 - val_loss: 1.0070\n",
            "Epoch 1430/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3254 - val_loss: 1.1424\n",
            "Epoch 1431/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3268 - val_loss: 1.1312\n",
            "Epoch 1432/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3247 - val_loss: 1.0929\n",
            "Epoch 1433/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3250 - val_loss: 1.1874\n",
            "Epoch 1434/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3245 - val_loss: 1.2072\n",
            "Epoch 1435/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3244 - val_loss: 1.1511\n",
            "Epoch 1436/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3267 - val_loss: 1.1377\n",
            "Epoch 1437/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3248 - val_loss: 1.1319\n",
            "Epoch 1438/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3242 - val_loss: 1.1055\n",
            "Epoch 1439/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3242 - val_loss: 1.1311\n",
            "Epoch 1440/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3236 - val_loss: 1.1928\n",
            "Epoch 1441/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3264 - val_loss: 1.1402\n",
            "Epoch 1442/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3254 - val_loss: 1.0099\n",
            "Epoch 1443/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3255 - val_loss: 1.2321\n",
            "Epoch 1444/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3248 - val_loss: 1.1420\n",
            "Epoch 1445/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3255 - val_loss: 1.2388\n",
            "Epoch 1446/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3253 - val_loss: 1.0895\n",
            "Epoch 1447/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3249 - val_loss: 1.1012\n",
            "Epoch 1448/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3255 - val_loss: 1.1672\n",
            "Epoch 1449/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3256 - val_loss: 1.1234\n",
            "Epoch 1450/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3247 - val_loss: 1.1719\n",
            "Epoch 1451/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3239 - val_loss: 1.0885\n",
            "Epoch 1452/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3263 - val_loss: 1.2398\n",
            "Epoch 1453/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3255 - val_loss: 1.1073\n",
            "Epoch 1454/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3246 - val_loss: 1.0898\n",
            "Epoch 1455/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3243 - val_loss: 1.2486\n",
            "Epoch 1456/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3245 - val_loss: 1.2024\n",
            "Epoch 1457/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3243 - val_loss: 1.0721\n",
            "Epoch 1458/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3244 - val_loss: 1.1277\n",
            "Epoch 1459/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3237 - val_loss: 0.9768\n",
            "Epoch 1460/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3240 - val_loss: 1.2074\n",
            "Epoch 1461/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3242 - val_loss: 1.1783\n",
            "Epoch 1462/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3244 - val_loss: 1.0741\n",
            "Epoch 1463/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3247 - val_loss: 1.1206\n",
            "Epoch 1464/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3239 - val_loss: 1.1533\n",
            "Epoch 1465/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3237 - val_loss: 1.1364\n",
            "Epoch 1466/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3242 - val_loss: 1.1713\n",
            "Epoch 1467/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3237 - val_loss: 1.0997\n",
            "Epoch 1468/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3243 - val_loss: 1.0769\n",
            "Epoch 1469/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3245 - val_loss: 1.0292\n",
            "Epoch 1470/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3230 - val_loss: 1.2108\n",
            "Epoch 1471/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3235 - val_loss: 1.0910\n",
            "Epoch 1472/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3236 - val_loss: 1.0687\n",
            "Epoch 1473/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3248 - val_loss: 1.1526\n",
            "Epoch 1474/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3242 - val_loss: 1.1715\n",
            "Epoch 1475/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3237 - val_loss: 1.2499\n",
            "Epoch 1476/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3240 - val_loss: 1.2003\n",
            "Epoch 1477/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3234 - val_loss: 1.1922\n",
            "Epoch 1478/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3227 - val_loss: 1.1881\n",
            "Epoch 1479/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3242 - val_loss: 1.1697\n",
            "Epoch 1480/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3238 - val_loss: 1.3171\n",
            "Epoch 1481/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3236 - val_loss: 1.0460\n",
            "Epoch 1482/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3233 - val_loss: 1.2258\n",
            "Epoch 1483/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3231 - val_loss: 1.2624\n",
            "Epoch 1484/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3245 - val_loss: 1.1014\n",
            "Epoch 1485/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3233 - val_loss: 1.1643\n",
            "Epoch 1486/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3232 - val_loss: 1.1265\n",
            "Epoch 1487/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3267 - val_loss: 1.0757\n",
            "Epoch 1488/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3243 - val_loss: 1.1592\n",
            "Epoch 1489/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3233 - val_loss: 1.0280\n",
            "Epoch 1490/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3226 - val_loss: 1.1314\n",
            "Epoch 1491/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3224 - val_loss: 1.1678\n",
            "Epoch 1492/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3254 - val_loss: 1.1394\n",
            "Epoch 1493/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3249 - val_loss: 1.0770\n",
            "Epoch 1494/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3226 - val_loss: 1.1979\n",
            "Epoch 1495/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3234 - val_loss: 1.1836\n",
            "Epoch 1496/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3231 - val_loss: 1.0303\n",
            "Epoch 1497/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3237 - val_loss: 1.1637\n",
            "Epoch 1498/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3232 - val_loss: 1.1118\n",
            "Epoch 1499/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3237 - val_loss: 1.0927\n",
            "Epoch 1500/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3242 - val_loss: 1.1292\n",
            "Epoch 1501/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3240 - val_loss: 1.2590\n",
            "Epoch 1502/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3225 - val_loss: 1.1616\n",
            "Epoch 1503/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3225 - val_loss: 1.1723\n",
            "Epoch 1504/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3233 - val_loss: 1.1948\n",
            "Epoch 1505/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3240 - val_loss: 1.1421\n",
            "Epoch 1506/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3229 - val_loss: 1.1449\n",
            "Epoch 1507/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3230 - val_loss: 1.1543\n",
            "Epoch 1508/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3239 - val_loss: 1.2191\n",
            "Epoch 1509/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3237 - val_loss: 1.0941\n",
            "Epoch 1510/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3220 - val_loss: 1.1932\n",
            "Epoch 1511/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3244 - val_loss: 1.0811\n",
            "Epoch 1512/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3245 - val_loss: 1.1637\n",
            "Epoch 1513/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3228 - val_loss: 1.1034\n",
            "Epoch 1514/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3226 - val_loss: 1.2085\n",
            "Epoch 1515/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3221 - val_loss: 1.1580\n",
            "Epoch 1516/5000\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3233 - val_loss: 1.1605\n",
            "Epoch 1517/5000\n",
            "118/165 [====================>.........] - ETA: 0s - loss: 0.3190Restoring model weights from the end of the best epoch: 517.\n",
            "165/165 [==============================] - 0s 1ms/step - loss: 0.3227 - val_loss: 1.2224\n",
            "Epoch 1517: early stopping\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjoAAAHHCAYAAAC2rPKaAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAB3R0lEQVR4nO3dd3hTZcMG8DujSffetKVlU7ZlyFBWBQHBgaiALEVFQUQQge914MS9KzgBX1FURPRlDxmCbCh7FUrL6qZ7pE2e749D0qZJIZQmaZP7d125mpxzcvKcNm3uPlMmhBAgIiIickByexeAiIiIyFoYdIiIiMhhMegQERGRw2LQISIiIofFoENEREQOi0GHiIiIHBaDDhERETksBh0iIiJyWAw6RERE5LAYdIgasPPnz0Mmk2HRokX2LspN69OnD/r06WPvYhiMHz8enp6eNzyuNuWub9daX8hkMsydO/emn2fp+37Lli2QyWTYsmVLrcpHjoFBh4iIiBwWgw4RERE5LAYdclo6nQ6lpaX2Lka9UFpaCp1OZ+9iEBHVOQYdspnx48cjOjraZPvcuXMhk8mMtslkMkyZMgUrVqxA27ZtoVar0aZNG6xdu9bk+Vu2bEHnzp3h6uqKpk2b4quvvrruOZcsWYI2bdpArVYbznfw4EEMGjQI3t7e8PT0RP/+/bFr164blhMAFi1aBJlMhvPnzxu2RUdH45577sH69evRsWNHuLq6IjY2FsuXLzd5fm5uLqZNm4bIyEio1Wo0a9YM7777rknwyM3Nxfjx4+Hj4wNfX1+MGzcOubm5Jue7EX2/haVLl+Kll15Co0aN4O7ujvz8fOTk5OCFF15Au3bt4OnpCW9vbwwaNAiHDh0ye45ff/0Vb731FiIiIuDq6or+/fsjKSnJ5DW//vprNG3aFG5ubujatSv++ecfs2XLyMjA448/jpCQELi6uqJDhw5YvHix0TH6/hkffPABEhIS0KRJE7i7u2PAgAG4cOEChBB44403EBERATc3N9x7773Iycm56e8TACQmJiIoKAh9+vRBYWFhrc5RE0uuFQCWLl2KuLg4eHl5wdvbG+3atcOnn35q2F9eXo7XXnsNzZs3h6urKwICAtCrVy9s2LDhuq+vf99u374dU6dORVBQEHx9ffHUU09Bo9EgNzcXY8eOhZ+fH/z8/PDiiy9CCGF0jqKiIsyYMcPw3m3ZsiU++OADk+PKysrw/PPPIygoCF5eXhg2bBguXrxotlyXLl3CY489hpCQEMPv/ffff2/pt9Uiv/32G+Li4uDm5obAwEA8+uijuHTpktExaWlpmDBhAiIiIqBWqxEWFoZ7773X6Pd83759GDhwIAIDA+Hm5oaYmBg89thjdVpWunVKexeAqCbbt2/H8uXL8cwzz8DLywufffYZhg8fjtTUVAQEBACQAsrdd9+NsLAwvPbaa9BqtXj99dcRFBRk9px///03fv31V0yZMgWBgYGIjo7GsWPHcMcdd8Db2xsvvvgiXFxc8NVXX6FPnz7YunUrunXrVqvynzlzBg8//DAmTZqEcePGYeHChRgxYgTWrl2Lu+66CwBQXFyM3r1749KlS3jqqacQFRWFf//9F3PmzMGVK1fwySefAACEELj33nuxfft2TJo0Ca1bt8Yff/yBcePG1apsAPDGG29ApVLhhRdeQFlZGVQqFY4fP44VK1ZgxIgRiImJQXp6Or766iv07t0bx48fR3h4uNE53nnnHcjlcrzwwgvIy8vDe++9h9GjR2P37t2GY7777js89dRT6NGjB6ZNm4Zz585h2LBh8Pf3R2RkpOG4kpIS9OnTB0lJSZgyZQpiYmLw22+/Yfz48cjNzcVzzz1n9NpLliyBRqPBs88+i5ycHLz33nt46KGH0K9fP2zZsgWzZs1CUlISPv/8c7zwwgs3/WG5d+9eDBw4EJ07d8aff/4JNze3WnyXzbP0Wjds2ICRI0eif//+ePfddwEAJ06cwI4dOwzHzJ07F/PmzcPEiRPRtWtX5OfnY9++fThw4IDhfXY9zz77LEJDQ/Haa69h165d+Prrr+Hr64t///0XUVFRePvtt7F69Wq8//77aNu2LcaOHQtAek8OGzYMmzdvxuOPP46OHTti3bp1mDlzJi5duoSPP/7Y8BoTJ07Ejz/+iFGjRqFHjx74+++/MWTIEJOypKen4/bbbzf8UxIUFIQ1a9bg8ccfR35+PqZNm3ar33osWrQIEyZMQJcuXTBv3jykp6fj008/xY4dO3Dw4EH4+voCAIYPH45jx47h2WefRXR0NDIyMrBhwwakpqYaHg8YMABBQUGYPXs2fH19cf78ebP/zJCdCSIbGTdunGjcuLHJ9ldffVVUfysCECqVSiQlJRm2HTp0SAAQn3/+uWHb0KFDhbu7u7h06ZJh25kzZ4RSqTR7TrlcLo4dO2a0/b777hMqlUqcPXvWsO3y5cvCy8tL3HnnndctpxBCLFy4UAAQycnJhm2NGzcWAMTvv/9u2JaXlyfCwsJEp06dDNveeOMN4eHhIU6fPm10ztmzZwuFQiFSU1OFEEKsWLFCABDvvfee4ZiKigpxxx13CABi4cKFJuWqyebNmwUA0aRJE1FcXGy0r7S0VGi1WqNtycnJQq1Wi9dff93kHK1btxZlZWWG7Z9++qkAII4cOSKEEEKj0Yjg4GDRsWNHo+O+/vprAUD07t3bsO2TTz4RAMSPP/5o2KbRaET37t2Fp6enyM/PN5QHgAgKChK5ubmGY+fMmSMAiA4dOojy8nLD9pEjRwqVSiVKS0uv+30ZN26c8PDwEEIIsX37duHt7S2GDBli8rzevXsbldsS1Z9j6bU+99xzwtvbW1RUVNR47g4dOoghQ4bcVHmEqHzfDhw4UOh0OsP27t27C5lMJiZNmmTYVlFRISIiIoyuQf+efPPNN43O++CDDwqZTGb43U1MTBQAxDPPPGN03KhRowQA8eqrrxq2Pf744yIsLExkZWUZHfvII48IHx8fw/tV/x640fte/z7dvHmzEKLy/di2bVtRUlJiOG7lypUCgHjllVeEEEJcvXpVABDvv/9+jef+448/BACxd+/e65aB7I9NV1RvxcfHo2nTpobH7du3h7e3N86dOwcA0Gq12LhxI+677z6jmoZmzZph0KBBZs/Zu3dvxMbGGh5rtVqsX78e9913H5o0aWLYHhYWhlGjRmH79u3Iz8+vVfnDw8Nx//33Gx57e3tj7NixOHjwINLS0gBIVeh33HEH/Pz8kJWVZbjFx8dDq9Vi27ZtAIDVq1dDqVTi6aefNpxPoVDg2WefrVXZAGDcuHEmtRRqtRpyufRnQavVIjs7G56enmjZsiUOHDhgco4JEyZApVIZHt9xxx0AYPgZ7du3DxkZGZg0aZLRcfomuKpWr16N0NBQjBw50rDNxcUFU6dORWFhIbZu3Wp0/IgRI4zOoa95e/TRR6FUKo22azQak6aJmmzevBkDBw5E//79sXz5cqjVaouedzMsvVZfX18UFRVdtxnK19cXx44dw5kzZ2pVlscff9yoSbZbt24QQuDxxx83bFMoFOjcubPh56q/BoVCgalTpxqdb8aMGRBCYM2aNYbjAJgcV712RgiB33//HUOHDoUQwuj3YeDAgcjLyzP7HrwZ+vfjM888A1dXV8P2IUOGoFWrVli1ahUAwM3NDSqVClu2bMHVq1fNnktf87Ny5UqUl5ffUrnIuhh0qN6Kiooy2ebn52f4w5ORkYGSkhI0a9bM5Dhz2wAgJibG6HFmZiaKi4vRsmVLk2Nbt24NnU6HCxcu1Kb4aNasmUmfnhYtWgCAoZ3/zJkzWLt2LYKCgoxu8fHxAKRrBICUlBSEhYWZzPNirtyWqv69AKQO2h9//DGaN28OtVqNwMBABAUF4fDhw8jLyzM5vvrPyM/PDwAMP6OUlBQAQPPmzY2Oc3FxMQqW+mObN29uCFp6rVu3NjpXTa+tDz1Vm8Oqbq/pA6uq0tJSDBkyBJ06dcKvv/5qFM7qkqXX+swzz6BFixYYNGgQIiIi8Nhjj5n0U3v99deRm5uLFi1aoF27dpg5cyYOHz5scVlu5vtY9XuYkpKC8PBweHl5XfcaUlJSIJfLjf5pAUzfu5mZmcjNzcXXX39t8vswYcIEAJW/D7WlL5O535tWrVoZ9qvVarz77rtYs2YNQkJCcOedd+K9994z/IMCSP80DR8+HK+99hoCAwNx7733YuHChSgrK7ulMlLdY9AhmzHXkReQag7MUSgUZreLah0db8at9LO42fJbQqfT4a677sKGDRvM3oYPH17rc9+Iue/F22+/jenTp+POO+/Ejz/+iHXr1mHDhg1o06aN2VFZ1vgZWaqm176VMqnVagwZMgS7d+822/Hd1oKDg5GYmIi//vrL0B9m0KBBRn2z7rzzTpw9exbff/892rZti2+//Ra33XYbvv32W4te42a+j9b8uerfX48++miNvw89e/a02utXN23aNJw+fRrz5s2Dq6srXn75ZbRu3RoHDx4EIP09WLZsGXbu3IkpU6YYOlHHxcXVecd1ujUMOmQzfn5+ZkcJVf9P3VLBwcFwdXU1O8rH3DZzgoKC4O7ujlOnTpnsO3nyJORyueE/W31tRfVrqKn8SUlJJh8Mp0+fBgDD6LOmTZuisLAQ8fHxZm/6/7YbN26MK1eumPwBNVfuW7Fs2TL07dsX3333HR555BEMGDAA8fHxtRrdBUjlBmDSrFJeXo7k5GSTY8+cOWMSqE6ePGl0LmuSyWRYsmQJ+vfvjxEjRlhtRt2buVaVSoWhQ4fiyy+/xNmzZ/HUU0/hhx9+MHqP+/v7Y8KECfj5559x4cIFtG/fvlYzDt/sNVy+fBkFBQXXvYbGjRtDp9Ph7NmzRsdVf+/qR2Rptdoafx+Cg4NvuczmXlu/rfp7rGnTppgxYwbWr1+Po0ePQqPR4MMPPzQ65vbbb8dbb72Fffv2YcmSJTh27BiWLl16S+WkusWgQzbTtGlT5OXlGVWrX7lyBX/88UetzqdQKBAfH48VK1bg8uXLhu1JSUmG/gGWnGPAgAH4888/jYaNpqen46effkKvXr3g7e1tKD8AQ78ZQBpea25IMABcvnzZ6Nry8/Pxww8/oGPHjggNDQUAPPTQQ9i5cyfWrVtn8vzc3FxUVFQAAAYPHoyKigrMnz/fsF+r1eLzzz+36DotpVAoTMLZb7/9ZnH/luo6d+6MoKAgLFiwABqNxrB90aJFJuFp8ODBSEtLwy+//GLYVlFRgc8//xyenp7o3bt3rcpws1QqFZYvX44uXbpg6NCh2LNnT52/hqXXmp2dbfQ8uVyO9u3bA4ChiaT6MZ6enmjWrJnVm1AGDx4MrVaLL774wmj7xx9/DJlMZugnp//62WefGR2nH1Gop1AoMHz4cPz+++84evSoyetlZmbecpk7d+6M4OBgLFiwwOj7s2bNGpw4ccIwEqy4uNhkjq2mTZvCy8vL8LyrV6+a/K507NgRANh8Vc9weDnZzCOPPIJZs2bh/vvvx9SpU1FcXIz58+ejRYsWte5kOHfuXKxfvx49e/bE008/bfjD27ZtWyQmJlp0jjfffBMbNmxAr1698Mwzz0CpVOKrr75CWVkZ3nvvPcNxAwYMQFRUFB5//HHMnDkTCoUC33//PYKCgpCammpy3hYtWuDxxx/H3r17ERISgu+//x7p6elYuHCh4ZiZM2fir7/+wj333IPx48cjLi4ORUVFOHLkCJYtW4bz588jMDAQQ4cORc+ePTF79mycP3/eMCePuX4zt+Kee+7B66+/jgkTJqBHjx44cuQIlixZYtKfxlIuLi5488038dRTT6Ffv354+OGHkZycjIULF5qc88knn8RXX32F8ePHY//+/YiOjsayZcuwY8cOfPLJJyZ9QazJzc0NK1euRL9+/TBo0CBs3boVbdu2rbPzW3qtEydORE5ODvr164eIiAikpKTg888/R8eOHQ19YWJjY9GnTx/ExcXB398f+/btw7JlyzBlypQ6K685Q4cORd++ffGf//wH58+fR4cOHbB+/Xr8+eefmDZtmuEfg44dO2LkyJH48ssvkZeXhx49emDTpk1ma13feecdbN68Gd26dcMTTzyB2NhY5OTk4MCBA9i4cWOt50PSc3FxwbvvvosJEyagd+/eGDlypGF4eXR0NJ5//nkAUs1r//798dBDDyE2NhZKpRJ//PEH0tPT8cgjjwAAFi9ejC+//BL3338/mjZtioKCAnzzzTfw9vbG4MGDb6mcVMfsNNqLnNT69etF27ZthUqlEi1bthQ//vhjjcPLJ0+ebPL8xo0bi3Hjxhlt27Rpk+jUqZNQqVSiadOm4ttvvxUzZswQrq6uFp1TCCEOHDggBg4cKDw9PYW7u7vo27ev+Pfff02O279/v+jWrZtQqVQiKipKfPTRRzUOLx8yZIhYt26daN++vVCr1aJVq1bit99+MzlnQUGBmDNnjmjWrJlQqVQiMDBQ9OjRQ3zwwQdCo9EYjsvOzhZjxowR3t7ewsfHR4wZM0YcPHiw1sPLzZWltLRUzJgxQ4SFhQk3NzfRs2dPsXPnTpPh0TWdo6Zhv19++aWIiYkRarVadO7cWWzbts3sMO309HQxYcIEERgYKFQqlWjXrp3JufSvUX3ob01l0v98bjQMuOrwcr2srCwRGxsrQkNDxZkzZ4QQdTO8XAjLrnXZsmViwIABIjg42PCee+qpp8SVK1cMx7z55puia9euwtfXV7i5uYlWrVqJt956y+i9Y05N3xf972NmZqbRdnPfn4KCAvH888+L8PBw4eLiIpo3by7ef/99o+HqQghRUlIipk6dKgICAoSHh4cYOnSouHDhgsnwcv33ZfLkySIyMlK4uLiI0NBQ0b9/f/H1118bjqnt8HK9X375RXTq1Emo1Wrh7+8vRo8eLS5evGjYn5WVJSZPnixatWolPDw8hI+Pj+jWrZv49ddfDcccOHBAjBw5UkRFRQm1Wi2Cg4PFPffcI/bt23fdMpHtyYSwQa9BIhu77777bmnI7a2Kjo5G27ZtsXLlSru8PhERSdhHhxq8kpISo8dnzpzB6tWr0adPH/sUiIiI6g320aEGr0mTJhg/fjyaNGmClJQUzJ8/HyqVCi+++KK9i2ZTGo3mhn0YfHx86nQpA2eXmZl53ekFVCoV/P39bVgiIqqOQYcavLvvvhs///wz0tLSoFar0b17d7z99tsmk9Q5un///Rd9+/a97jELFy7E+PHjbVMgJ9ClS5frTo/Qu3dvqw1RJyLLsI8OkYO4evUq9u/ff91j2rRpg7CwMBuVyPHt2LHDpOm0Kj8/P8TFxdmwRERUHYMOEREROSx2RiYiIiKH5fR9dHQ6HS5fvgwvL68a1zIiIiKi+kUIgYKCAoSHh5sskFuV0wedy5cvm6zSS0RERA3DhQsXEBERUeN+pw86+qnWL1y4YFjTiIiIiOq3/Px8REZG3nB5GKcPOvrmKm9vbwYdIiKiBuZG3U7YGZmIiIgcFoMOEREROSwGHSIiInJYTt9HxxI6nQ4ajcbexaAqXFxcoFAo7F0MIiKq5xh0bkCj0SA5ORk6nc7eRaFqfH19ERoayvmPiIioRgw61yGEwJUrV6BQKBAZGXndCYnIdoQQKC4uRkZGBgBw7SYiIqoRg851VFRUoLi4GOHh4XB3d7d3cagKNzc3AEBGRgaCg4PZjEVERGaxiuI6tFotAEClUtm5JGSOPnyWl5fbuSRERFRfMehYgH1A6if+XIiI6EYYdIiIiMhhNfigc+HCBfTp0wexsbFo3749fvvtN3sXye769OmDadOm2bsYREREdtfgOyMrlUp88skn6NixI9LS0hAXF4fBgwfDw8PD3kUjIiIiO2vwQScsLMwwvDg0NBSBgYHIycmxe9DRVOgACCgVcsjZl4SIiMgu7N50tW3bNgwdOhTh4eGQyWRYsWKFyTEJCQmIjo6Gq6srunXrhj179pg91/79+6HVahEZGWnlUt/YmYwCnEwruBZ47Ofq1asYO3Ys/Pz84O7ujkGDBuHMmTOG/SkpKRg6dCj8/Pzg4eGBNm3aYPXq1Ybnjh49GkFBQXBzc0Pz5s2xcOFCe10KERHRTbN7jU5RURE6dOiAxx57DA888IDJ/l9++QXTp0/HggUL0K1bN3zyyScYOHAgTp06heDgYMNxOTk5GDt2LL755hurlVUIgZJyrUXHlpXrUKHToVhTAZ0Qt/zabi6KWo0yGj9+PM6cOYO//voL3t7emDVrFgYPHozjx4/DxcUFkydPhkajwbZt2+Dh4YHjx4/D09MTAPDyyy/j+PHjWLNmDQIDA5GUlISSkpJbvhYiIiJbsXvQGTRoEAYNGlTj/o8++ghPPPEEJkyYAABYsGABVq1ahe+//x6zZ88GAJSVleG+++7D7Nmz0aNHj+u+XllZGcrKygyP8/PzLS5rSbkWsa+ss/j4unT89YFwV93cj0sfcHbs2GH4vixZsgSRkZFYsWIFRowYgdTUVAwfPhzt2rUDADRp0sTw/NTUVHTq1AmdO3cGAERHR9fNxRAREdmI3Zuurkej0WD//v2Ij483bJPL5YiPj8fOnTsBSLUs48ePR79+/TBmzJgbnnPevHnw8fEx3OpDM5e1nDhxAkqlEt26dTNsCwgIQMuWLXHixAkAwNSpU/Hmm2+iZ8+eePXVV3H48GHDsU8//TSWLl2Kjh074sUXX8S///5r82sgIiK6FXav0bmerKwsaLVahISEGG0PCQnByZMnAQA7duzAL7/8gvbt2xv69/z3v/811FBUN2fOHEyfPt3wOD8/3+Kw4+aiwPHXB1p07Km0ApRrdWgS5HHTNTE1vbY1TJw4EQMHDsSqVauwfv16zJs3Dx9++CGeffZZDBo0CCkpKVi9ejU2bNiA/v37Y/Lkyfjggw+sUhYiIqK6Vq+DjiV69ep1UyuLq9VqqNXqWr2WTCazOLS4uSigkMvg7qKsk6BTG61bt0ZFRQV2795taLrKzs7GqVOnEBsbazguMjISkyZNwqRJkzBnzhx88803ePbZZwEAQUFBGDduHMaNG4c77rgDM2fOZNAhIqIGo14HncDAQCgUCqSnpxttT09PR2hoqJ1KZaFr/YZvvRty7TVv3hz33nsvnnjiCXz11Vfw8vLC7Nmz0ahRI9x7770AgGnTpmHQoEFo0aIFrl69is2bN6N169YAgFdeeQVxcXFo06YNysrKsHLlSsM+IiKihqBe99FRqVSIi4vDpk2bDNt0Oh02bdqE7t2727FkNyZD/Zg7Z+HChYiLi8M999yD7t27QwiB1atXw8XFBYC0cOnkyZPRunVr3H333WjRogW+/PJLANL3f86cOWjfvj3uvPNOKBQKLF261J6XQ0REdFPsXqNTWFiIpKQkw+Pk5GQkJibC398fUVFRmD59OsaNG4fOnTuja9eu+OSTT1BUVGQYhVXf2aNGZ8uWLYb7fn5++OGHH2o89vPPP69x30svvYSXXnqpLotGRERkU3YPOvv27UPfvn0Nj/UdhceNG4dFixbh4YcfRmZmJl555RWkpaWhY8eOWLt2rUkH5ZuVkJCAhIQEaLWWzYtzswxT3tTBHDpERERUOzIhnPuTOD8/Hz4+PsjLy4O3t7fRvtLSUiQnJyMmJgaurq43dd7T6QUoLdciJtADXq4udVlkuuZWfj5ERNSwXe/zu6p63UenIasfPXSIiIicG4OOtehHXTl1fRkREZF9MehYSX0ZdUVEROTMGHSsjBU6RERE9sOgYyWG+hy2XREREdmN0wadhIQExMbGokuXLtZ5gXowMzIREZGzc9qgM3nyZBw/fhx79+61yvnZQ4eIiMj+nDbo2EpDbLmKjo7GJ598YtGxMpnMsGo8ERFRfcOgYyWya1MjN8CcQ0RE5DAYdKyksumKUYeIiMheGHSszNZNV19//TXCw8Oh0+mMtt9777147LHHcPbsWdx7770ICQmBp6cnunTpgo0bN9bZ6x85cgT9+vWDm5sbAgIC8OSTT6KwsNCwf8uWLejatSs8PDzg6+uLnj17IiUlBQBw6NAh9O3bF15eXvD29kZcXBz27dtXZ2UjIiLnw6BzM4QANEUW3eQVxZCVF1t8/A1vFiamESNGIDs7G5s3bzZsy8nJwdq1azF69GgUFhZi8ODB2LRpEw4ePIi7774bQ4cORWpq6i1/e4qKijBw4ED4+flh7969+O2337Bx40ZMmTIFAFBRUYH77rsPvXv3xuHDh7Fz5048+eSThma+0aNHIyIiAnv37sX+/fsxe/ZsuLhwnTAiIqo9u69e3qCUFwNvh1t0aFRdv/b/XQZUHjc8zM/PD4MGDcJPP/2E/v37AwCWLVuGwMBA9O3bF3K5HB06dDAc/8Ybb+CPP/7AX3/9ZQgktfXTTz+htLQUP/zwAzw8pLJ+8cUXGDp0KN599124uLggLy8P99xzD5o2bQoAaN26teH5qampmDlzJlq1agUAaN68+S2Vh4iIyGlrdKw+j44djR49Gr///jvKysoAAEuWLMEjjzwCuVyOwsJCvPDCC2jdujV8fX3h6emJEydO1EmNzokTJ9ChQwdDyAGAnj17QqfT4dSpU/D398f48eMxcOBADB06FJ9++imuXLliOHb69OmYOHEi4uPj8c477+Ds2bO3XCYiInJuTlujM3nyZEyePNmwzLtFXNylmhULXLhagtxiDUJ9XBHkqb6FklZ5bQsNHToUQgisWrUKXbp0wT///IOPP/4YAPDCCy9gw4YN+OCDD9CsWTO4ubnhwQcfhEajufUyWmDhwoWYOnUq1q5di19++QUvvfQSNmzYgNtvvx1z587FqFGjsGrVKqxZswavvvoqli5divvvv98mZSMiIsfjtEGnVmQyi5qPAAAuMggXJeDiCqhcrVuualxdXfHAAw9gyZIlSEpKQsuWLXHbbbcBAHbs2IHx48cbwkNhYSHOnz9fJ6/bunVrLFq0CEVFRYZanR07dkAul6Nly5aG4zp16oROnTphzpw56N69O3766SfcfvvtAIAWLVqgRYsWeP755zFy5EgsXLiQQYeIiGrNaZuurO1a/1ro7DS6fPTo0Vi1ahW+//57jB492rC9efPmWL58ORITE3Ho0CGMGjXKZITWrbymq6srxo0bh6NHj2Lz5s149tlnMWbMGISEhCA5ORlz5szBzp07kZKSgvXr1+PMmTNo3bo1SkpKMGXKFGzZsgUpKSnYsWMH9u7da9SHh4iI6GaxRsdKDBMG2ino9OvXD/7+/jh16hRGjRpl2P7RRx/hscceQ48ePRAYGIhZs2YhPz+/Tl7T3d0d69atw3PPPYcuXbrA3d0dw4cPx0cffWTYf/LkSSxevBjZ2dkICwvD5MmT8dRTT6GiogLZ2dkYO3Ys0tPTERgYiAceeACvvfZanZSNiIick0yIhrhIQd3R99HJy8uDt7e30b7S0lIkJycjJiYGrq431/x0Ja8EmQVlCPJSI8zHrS6LTNfcys+HiIgatut9flfFpisrkcG+NTpERETEoGM1lX10Gm7SWbJkCTw9Pc3e2rRpY+/iERER3RD76FiJ/FrQacA5B8OGDUO3bt3M7uOMxURE1BA4bdBJSEhAQkICtFqtVc6v74zckGt0vLy84OXlZe9iEBER1ZrTNl1NnjwZx48fx969e294bG36a+tXL2/AOafec/J+9EREZAGnDTqWUCgUAFCrWYPl+uHldVoiqqq4uBgAm9GIiKhmTtt0ZQmlUgl3d3dkZmbCxcUFcrnlubBco4Go0KBco0VpqcKKpXQ+QggUFxcjIyMDvr6+hkBKRERUHYPOdchkMoSFhSE5ORkpKSk39dySci2yCzVQKeXQ5tXBWldkwtfXF6GhofYuBhER1WMMOjegUqnQvHnzm26+2pOcjbmbj6BZsCe+GtPKSqVzXi4uLqzJISKiG2LQsYBcLr/pmXddVK64VKCFm5uWs/YSERHZCTsjW4lKKX1rNRV1s2AmERER3TwGHStRXws6ZRXWmaeHiIiIboxBx0rUrNEhIiKyO6cNOgkJCYiNjUWXLl2scn61UuooW8agQ0REZDdOG3RuZmbk2lC76JuuGHSIiIjsxWmDjrWpFNK3VqsTqNAy7BAREdkDg46V6Gt0AEDDoENERGQXDDpWou+jAwCl5Qw6RERE9sCgYyUKucwwl05pOYeYExER2QODjhW5Xgs6JQw6REREdsGgY0VuKqn5qkTDoENERGQPDDpW5OYiBR02XREREdkHg44VuRqCDjsjExER2QODjhUZmq5Yo0NERGQXDDpW5Kpk0CEiIrInBh0r0tfolLIzMhERkV04bdCx9qKeQJXOyBUMOkRERPbgtEHH2ot6ApWdkTm8nIiIyD6cNujYgpuKEwYSERHZE4OOFbEzMhERkX0x6FgROyMTERHZF4OOFXHCQCIiIvti0LEi92s1OkWaCjuXhIiIyDkx6FiRp1oJACgsY9AhIiKyBwYdK/JydQEA5JeU27kkREREzolBx4q83aQanYJS1ugQERHZA4OOFXlfq9Fh0CEiIrIPBh0r8nKVanTyS9l0RUREZA8MOlak76NTrNGiQssh5kRERLbGoGNF+hodgCOviIiI7IFBx4pcFHLDCubsp0NERGR7DDpWpq/VyeMQcyIiIptj0LEyfdBhjQ4REZHtOW3QSUhIQGxsLLp06WLV1/EyDDFnjQ4REZGtOW3QmTx5Mo4fP469e/da9XW83TiXDhERkb04bdCxFc6lQ0REZD8MOlbmzT46REREdsOgY2Xso0NERGQ/DDpWxhodIiIi+2HQsTJ9jQ776BAREdkeg46VcR4dIiIi+2HQsbLKGh0GHSIiIltj0LEyfR+dvGKNnUtCRETkfBh0rCzAUw0AyC5i0CEiIrI1Bh0rC/RUAZD66JRVaO1cGiIiIufCoGNlPm4uUMplAIAc1uoQERHZFIOOlclkMgRcq9XJKmDQISIisiUGHRsI8JD66WQVldm5JERERM6FQccG9DU62YWs0SEiIrIlBh0bCNKPvCpkjQ4REZEtMejYgKGPDoMOERGRTTHo2IBhLh02XREREdkUg44NBHhcq9Hh8HIiIiKbYtCxgUCva6OuCth0RUREZEsMOjYQ6KFfBoJBh4iIyJYYdGyg6vByIYSdS0NEROQ8GHRsIPBaZ+QKneAyEERERDbktEEnISEBsbGx6NKli9VfS6WUG8LOlbxSq78eERERSZw26EyePBnHjx/H3r17bfJ6YT6uAIA0Bh0iIiKbcdqgY2uh14LOlbwSO5eEiIjIeTDoWEthJpB5GtCWAwDCDUGHNTpERES2wqBjLZ+0AxK6APmXAAChPm4A2HRFRERkSww61uLuL30tzgFQ2UfnMpuuiIiIbIZBx1rc/KSvJVcBsDMyERGRPTDoWItJ0JGarq7klXLSQCIiIhth0LGWakEn2FuaR6esQoerxeX2KhUREZFTYdCxFkPQyQUAuLooDKuYX85lPx0iIiJbYNCxFkPQyTFsivCTmq8uXmXQISIisgUGHWvRj7q61nQFAJH+7gCACznF9igRERGR02HQsZZqfXQAoHGAFHRScorsUSIiIiKnw6BjLW76eXSyDZuirtXopOaw6YqIiMgWGHSsxTNY+lqYYdgU5e8BgE1XREREtsKgYy0egdLXokzDpqhrTVcXrxZDq+NcOkRERNbGoGMtHtdqdMqLgbJCAECotytUCjnKtYKrmBMREdkAg461qD0BF6kGB0VS85VCLjMMMU9l8xUREZHVMehYk0eQ9LXQtPkqJZtBh4iIyNoYdKxJ3yG5qLJDckyg1CH5XGahPUpERETkVBh0rMnDdORVs2BPAEBSBoMOERGRtTHoWJPntaarKiOvmgVdCzqs0SEiIrI6Bh1rMlOj0/Rajc7FqyUoLdfao1REREROg0HHmsz00QnwUMHX3QVCAGdZq0NERGRVDDrWZBh1VRl0ZDKZofnqbCbXvCIiIrImBh1rMrMMBAA0DWKHZCIiIltg0LEmfR+dKp2RgcqRV2cZdIiIiKyKQcea9KOuNIWApnKCQA4xJyIisg0GHWtSewMKtXS/yHQunXNZhdBU6OxRMiIiIqfAoGNNMlmVfjqVzVcRfm7wclWiXCtYq0NERGRFDDrWph95VWQ88qp1qDcA4MSVfHuUioiIyCkw6FhbDSOvYsMZdIiIiKyNQcfaPEyXgQCA1mFeAIATaQw6RERE1sKgY2011Oi0DpNqdI5fzocQwtalIiIicgoOEXTuv/9++Pn54cEHH7R3UUx5mC4DAQAtQrwglwFXi8uRnl9mh4IRERE5PocIOs899xx++OEHexfDPP1cOoXGTVeuLgo0uTZDMvvpEBERWYdDBJ0+ffrAy8vL3sUwzzNU+lpwxWRXm2sdko9eyrNliYiIiJyG3YPOtm3bMHToUISHh0Mmk2HFihUmxyQkJCA6Ohqurq7o1q0b9uzZY/uC1pZfY+lr3gVAW2G0q32ELwDg0MVc25aJiIjISdg96BQVFaFDhw5ISEgwu/+XX37B9OnT8eqrr+LAgQPo0KEDBg4ciIyMDLPH1zteYYBCBegqgPyLRrs6RPgAAA5dzGOHZCIiIiuwe9AZNGgQ3nzzTdx///1m93/00Ud44oknMGHCBMTGxmLBggVwd3fH999/X6vXKysrQ35+vtHNquQKwPdarU5OstGuNuE+UMhlyCwoQ1p+qXXLQURE5ITsHnSuR6PRYP/+/YiPjzdsk8vliI+Px86dO2t1znnz5sHHx8dwi4yMrKvi1sw/Rvp61TjouKkUaH5t3atDF9hPh4iIqK7V66CTlZUFrVaLkJAQo+0hISFIS0szPI6Pj8eIESOwevVqREREXDcEzZkzB3l5eYbbhQsXrFZ+A79rQadajQ4AdLjWT+cw++kQERHVOaW9C1AXNm7caPGxarUaarXaiqUxQ1+jk3POZFf7SB/8su8CDl9kjQ4REVFdq9c1OoGBgVAoFEhPTzfanp6ejtDQUDuVqhYCmklfs5NMdnWoMvJKp2OHZCIiorpUr4OOSqVCXFwcNm3aZNim0+mwadMmdO/e3Y4lu0lBraSv2UlAhcZoV8tQL6iUchSUVuBcVpEdCkdEROS47B50CgsLkZiYiMTERABAcnIyEhMTkZqaCgCYPn06vvnmGyxevBgnTpzA008/jaKiIkyYMMGOpb5JPhGAylMaYl6t+cpFIUfHa7U6+87n2KFwREREjsvuQWffvn3o1KkTOnXqBEAKNp06dcIrr7wCAHj44YfxwQcf4JVXXkHHjh2RmJiItWvXmnRQvlkJCQmIjY1Fly5dbvkabkgmA4JaSvczT5js7tbEHwCwJ5lBh4iIqC7JhJPPVJefnw8fHx/k5eXB29vbei+04hkgcQnQZw7QZ7bRrn/OZGLMd3vQyNcNO2b3s14ZiIiIHISln992r9FxGsGtpa9pR0x23RblB4Vchku5Jbh4tdjGBSMiInJcDDq2En6b9PXSfpNdHmol2jWSloNg8xUREVHdYdCxlfCOgEwhrWKed8lkd7cYqZ/O7nMMOkRERHWFQcdWVB5AcKx030ytjr5D8u7kbFuWioiIyKEx6NhSRGfpa8q/Jrs6R/tDIZfhfHYxLuSwnw4REVFdcNqgY9Ph5XpNr42oOr0WqDbYzdvVBbdF+QIAtp3JtF2ZiIiIHJjTBp3Jkyfj+PHj2Lt3r+1etGk/QKGSVjHPOm2yu3eLIADA1lMMOkRERHXBaYOOXag9gZg7pfunVpvs7t0iGADw79lsaCp0tiwZERGRQ2LQsbUWd0tfT6012dUm3BsBHioUllXgQOpVGxeMiIjI8TDo2FrLQdLXC7uB3FSjXXK5DHfqm69Os/mKiIjoVjHo2JpPxLXmKwEc/NFkN/vpEBER1R0GHXuIGy99PfBfQFthtOuO5oGQyYDjV/JxJa/E9mUjIiJyIAw69tDqHsDNHyi4DCRtNNoV4KnGbVF+AICNx9PtUToiIiKH4bRBxy7z6Ogp1UDHUdL9fd+Z7B4QGwIAWM+gQ0REdEtqFXQWL16MVatWGR6/+OKL8PX1RY8ePZCSklJnhbMmu8yjU1XnxwDIgDPrgfRjRrsGtAkFAOw8m428knI7FI6IiMgx1CrovP3223BzcwMA7Ny5EwkJCXjvvfcQGBiI559/vk4L6LACmgKx90r3//nIaFdMoAeaBXuiQiew5VSGHQpHRETkGGoVdC5cuIBmzZoBAFasWIHhw4fjySefxLx58/DPP//UaQEd2h3Tpa9Hl5msf8XmKyIioltXq6Dj6emJ7Gxple3169fjrrvuAgC4urqipIQjhSwW1gHoNEa6/+cUQFO5mKe++WrLyQyUVWjtUToiIqIGr1ZB56677sLEiRMxceJEnD59GoMHDwYAHDt2DNHR0XVZPsc34E3AKwzIOQv8/aZhc/tGPgjxVqNIo8XOs9l2LCAREVHDVaugk5CQgO7duyMzMxO///47AgICAAD79+/HyJEj67SADs/NFxj6mXR/15fA+R0ApFmS41tLzVfrjrH5ioiIqDZkQghh70LYU35+Pnx8fJCXlwdvb2/7FeSvZ4EDPwC+jYGn/wXUnth6OhPjvt+DIC81ds/pD7lcZr/yERER1SOWfn7XqkZn7dq12L59u+FxQkICOnbsiFGjRuHqVS5GWSsD3gJ8IoHcFGDDywCA7k0C4KVWIrOgDIkXc+1bPiIiogaoVkFn5syZyM/PBwAcOXIEM2bMwODBg5GcnIzp06fXaQGtxa4TBprj6g3cmyDd3/c9kLQRKqUcfVoFAwA2cPQVERHRTatV0ElOTkZsbCwA4Pfff8c999yDt99+GwkJCVizZk2dFtBa7D5hoDlNegNdn5Lu/zUV0BTjLv0w82NpdiwYERFRw1SroKNSqVBcLA2F3rhxIwYMGAAA8Pf3N9T0UC3FzwV8ooD8S8Cer9CnZRBcFDKczSxCUkahvUtHRETUoNQq6PTq1QvTp0/HG2+8gT179mDIkCEAgNOnTyMiIqJOC+h0VO5A3/+T7m//GN6iEN2bBgJg8xUREdHNqlXQ+eKLL6BUKrFs2TLMnz8fjRo1AgCsWbMGd999d50W0Cm1fwgIag2U5gE7PjPMkrzhOJuviIiIbgaHl9eX4eXVnVwNLB0JKN2Q+dhudPnsKGQyYPec/gj2drV36YiIiOzK0s9vZW1fQKvVYsWKFThx4gQAoE2bNhg2bBgUCkVtT0lVtRwERHQFLu5B0JGv0SFyMA5dyMXGExkY1S3K3qUjIiJqEGrVdJWUlITWrVtj7NixWL58OZYvX45HH30Ubdq0wdmzZ+u6jM5JJgN6z5Lu71uIoc2lWpz1bL4iIiKyWK2CztSpU9G0aVNcuHABBw4cwIEDB5CamoqYmBhMnTq1rsvovJr1B0LbAeVFuL98FQDg36RsFJZV2LlgREREDUOtgs7WrVvx3nvvwd/f37AtICAA77zzDrZu3VpnhXN6MhnQ63kAgP/RhWgdoIBGq8PWU5l2LhgREVHDUKugo1arUVBQYLK9sLAQKpXqlgtlC/VuZuSatL4X8IuBrCQH0wN2AWDzFRERkaVqFXTuuecePPnkk9i9ezeEEBBCYNeuXZg0aRKGDRtW12W0ino5M7I5CiXQU2oO7J39C5SowN8nM1Cu1dm5YERERPVfrYLOZ599hqZNm6J79+5wdXWFq6srevTogWbNmuGTTz6p4yISOowCPIKgKrqMB9wPo6C0ArvP5di7VERERPVerYaX+/r64s8//0RSUpJheHnr1q3RrFmzOi0cXePiCtw2FvjnQzzhthm/Ft+GdcfS0Kt5oL1LRkREVK9ZHHRutCr55s2bDfc/+uij2peIzIsbD/zzEZoX7UcT2WVsPe1u7xIRERHVexYHnYMHD1p0nEwmq3Vh6Dp8o4AWA4HTazFGuQmv5YTjQk4xIv0ZeIiIiGpicdCpWmNDdtL5ceD0WgxX7sCb5aOw82w2gw4REdF11KozMtlJ036Amz+8RT66yU9gx9kse5eIiIioXmPQaUgUSqD1UADACMVW/Hs2G06+JisREdF1Meg0NJ0eBQD0lx9ETkExkjIK7VwgIiKi+otBp6FpFCc1X8mKcZvsDHYksfmKiIioJgw6DY1cIfXVAXCn4jB2nM22c4GIiIjqLwadhqhZPACgjzwRu85lQ6tjPx0iIiJznDboNJhFPc1p1h9CJkc7+XkElaXi6KU8e5eIiIioXnLaoNNgFvU0xzMYsuYDAAAPKP7Bv2y+IiIiMstpg06D1+YBAEA/eSL+5Xw6REREZjHoNFTN+kNAhlh5ClLOJ6GsQmvvEhEREdU7DDoNlUcg0Og2AMDtuoPsp0NERGQGg04DJrs2zLyH/Bj2nr9q59IQERHVPww6DVnMnQCA7vLj2HuOHZKJiIiqY9BpyCK6QqdQI0SWi8yUY9BxPh0iIiIjDDoNmYsrECHNA9S+/BDOcN0rIiIiIww6DZy8SW8AwO3y49h7PsfOpSEiIqpfGHQauug7AAC3y09gbzL76RAREVXFoNPQNYqDVuGGQFk+spMP2bs0RERE9QqDTkOnVAGR3QAATYsO4lJuiZ0LREREVH8w6DgARVNpmHkP+THsYz8dIiIiAwYdRxAtBZ0u8pPYw/l0iIiIDBh0HEFYB2jlavjLCpF27oi9S0NERFRvMOg4AqUKuvA4AEDQ1QPILdbYuUBERET1g9MGnYSEBMTGxqJLly72LkqdcGkqDTOX+ulw3SsiIiLAiYPO5MmTcfz4cezdu9feRakbMdLEgd3lxzifDhER0TVOG3QcTkQXVCjcECTLR1rSAXuXhoiIqF5g0HEUShXKG0nz6QRm7kZhWYWdC0RERGR/DDoOxK1lPwBAD9kR7E9hPx0iIiIGHUfSpC8AaYHPPUlpdi4MERGR/THoOJKQtihV+cNDVoa80zvsXRoiIiK7Y9BxJHI5tNdGX4Vl70QR++kQEZGTY9BxMO6t4gEA3WTH2U+HiIicHoOOg5E1kmZIbim7gN3nsuxcGiIiIvti0HE0/k2hlSnhJStB6hmue0VERM6NQcfRKFUob3Q7ACA0YxuKNeynQ0REzotBxwGpY+8GANyJg+ynQ0RETo1BxwHJWkhBp5v8BA6cuWDn0hAREdkPg44jCmiGAvdIqGRaaE5vsndpiIiI7IZBxxHJZBDNBwAAGmXvQolGa+cCERER2QeDjoPyan4HAKCt7CwOprKfDhEROScGHQcli5JWMm8rO4+jJ07YuTRERET2waDjqLzDkeXXEXKZgOz0GnuXhoiIyC4YdByYS3NpNXOv3BPILy23c2mIiIhsj0HHgflEtgUANJVdxL9J2XYuDRERke0x6DiyoFYAgC7y0/j3ZKqdC0NERGR7DDqOLKCZ4a7XyWUQQtixMERERLbHoOPIXFyhbXwnAKBR6WmczSyyc4GIiIhsy2mDTkJCAmJjY9GlSxd7F8WqFF0fAwCMUm7GtlPpdi4NERGRbTlt0Jk8eTKOHz+OvXv32rso1tUoznA39/BqOxaEiIjI9pw26DgN3yiUBrYBAASlb0dpOZeDICIi58Gg4wTU/WYDAHrgEPYk59i5NERERLbDoOMEZDF3QgsFmsqv4NCRw/YuDhERkc0w6DgDN1/k+bcHAFSc2WjnwhAREdkOg46TcI8dCABoVbQXl3NL7FwaIiIi22DQcRKurQcAAHrKj2Lrict2Lg0REZFtMOg4i7BOKHHxhbesBKmHt9q7NERERDbBoOMs5HJoonoDAHwubeUwcyIicgoMOk7Eu93dAICeSMTOs1zNnIiIHB+DjhORNe0PAGgnP49ticftXBoiIiLrY9BxJl4hKPSXZkl++ORUlFWw+YqIiBwbg46Tce/4IACgFVKwe98+O5eGiIjIuhh0nIy851RUyFwAACcP/Wvn0hAREVkXg46zUSiR33IEAOCRy++hoLTczgUiIiKyHgYdJ+TXbRQAwFtWjANbVti3MERERFbEoOOEZI3iDPd775oIcYULfRIRkWNi0HFGKncUd3/B8DD3fy/ZsTBERETWw6DjpNz7TkeGazQAwOfyP/YtDBERkZUw6DgrlQc0EzZBJ2SQQ4fUDfPtXSIiIrKmklzg6z7Ajs/sXRKbYtBxYhEhgdjrNxgAELVjNpD8DyCEnUtFRERWsTMBuHwQ2PCyvUtiUww6Ti5ixLuVDxbfA5z4y36FISLHl38FOLES0OnsXRLnoymsm/PodICu4cysz6Dj5Bo1isQx7zsqN/w6FijMtF+BiMixfdEZ+GU0kPijvUtiHzodsP4l4NgK27+2qBIu044C2opanEMA3w8AvurdYMIOgw4hePAc4w1/PmOfghCR49PXKiRttG85bEmnA/56Ftj7HXBqFfDv58Bv46R9m98Glo62TWioGnQW9ARWTb/5c5QVABf3AulHgPzLdVc2K2LQIQS16olE/7srN5xZD1zcb78CEZETkNm7ALbz1xTgwA9SsKgeDra+C5xcCZzbYrxdp5XCYMlV6fGl/cCu+bfW5CeqPffA4ps/R0Vp5f3Ta4335aZKNVX1rK8ngw4BAMLHL8Z83f2VG7a+W/PBRES3SuYkQacoC0hcUvlYV0NzUXmJ8eO93wE/DgeWSEv24Jt+wNrZwOY3gQW9pH5OAHBhD7Bv4Y3DhbZc+if2euXc8RmQkwz8/gQw1wc4+rvxMUmbgA+aVz5e/YLx/s9uk2qqDv96/bLYmNLeBaD6IdjbFYWdJwMH/pA2nFkH5F0CfBrZt2BE5KAacNDRVgCKGj4+NUXAjw8CLQYCPZ8DMk8Z769aI2IUTq7dP7ESOPIrcPxP6fHFvcbP/+dD6esvo4EJa4CFg6THlw9Iw8fvmw+oPauVtxz4+w2pxsUcnQ54v6l0v+qIrGWPAW0ekEJpeQnw00OmzxWiMrTqrq2duHsBkH8J6PaU9L1w9QGGfQZ4Bpt/fStj0CGDx/q1x/373sMf8helDXu+Bu56zb6FIiLHZOsancSfpf5BXZ+4tfPkXwa+7A60GwEMfh/QagClGjjwXyD9KOAXDaT+K9205VINTFWbXq+8r62yqLI+9Pwy2vQ1awooS6sce+AH6WtpHhDZFeg5DVB5SN/nBXcAmSfMn+OjNlIIqclXdwKPbwA+bmO+NqqiFMg4Id30Lh+QbpuqfH4oXWt+DStj0CGDAE814vv2x0sbJ+BNl4XAjk8Ad3/pvxIicg7Xq62oUzLpw70sX/qP35p0WmDFJOl+q3uAC7uBjXOB/i8D618BmvUDhnxs/rrLCgEIQO0lPd76HlCaC+z9Bsi7CJxeA3iFAwVmOuZWDznVlRdX3q/ef6aq+T3Nby/NNd2WvFW6bXtfejzjdM0hBwDyLwI/PlDz/rTDwK4vgeJs8/vLS4DFwwBNQc3nACq/f3bAPjpk5PFeMdjheTcuikBpw4ZXKtuCicixbXkXeLcxkHGy5mPObwc+bgucXndrryWTS00j70QBaUdM9+u0UpNKYcbNnVdbDpz9GyjOqdymKaq8X5or9SO5miy9fv5FqTbkz8lAVhLw80jg4r7KMrwXA7zTGKjQSNsK0irPdXrNtW21HH20f2Hl/TWzgDeCzB9Xlm9++/XCkd6HLW6+XNVtuk7N/nsxNw45gF37ZDHokBFXFwWmDWqHfmUfYp9oJW3c/JZxFSsROaYtb0vNO9ebOXfxMCDvgtRfo2qAuFkyGXBsuXT/3y+kmdlL86THq2ZIfUb+e6/U+TV5243PJ4Q0hPuNQOC/9wNf95b6uRz4r3HNSfU+M3qHlwJfdgNOrQa+7S9tK82TmqaEFii6Nr9YwZXaXa85G+dW3i9Mk17LEQW2tOvLM+iQiWEdwhEbGYSZmmtt2RnHpf9y8i7Zt2BEDZ0QQEWZ7V83eRvwRRfguIUznwshNUkcWirVjiRXWfhXVJnv5e3wa007NSgvrXlf1dqIw0ulmdnfiZImotv7rTSsWh9wFg8F/ppa87kSf5aCkb6fCiD1a/l1rDS0O/1o5Xb9/DXmVO2DMtdHqq3QS9oAZJ0BriTW/Hwyb5x9Z9xn0CETMpkML98Ti2QRVrkxaQPwcazlfyiJyNTSUcCHrSrnRrGmwgxg3X+AH+6VgkLWaeDXMcCpNabHaoqr1doKYP3LwB9PSbUji++Rlm5IO2r63G3vS8OQfxxu3Fx0cR/wTiSw5R3p8el1wIUqI4iO/Ga+3DUFiQOLpZC4ZhZwZJlUm/TXVODMBqn/TU19SACpbLfqf89JszrTzfMKtevLO0TQWblyJVq2bInmzZvj22+/tXdxHEJcYz8Mvy0CT2qeN97x6xiuUUNUGzqt1CxSkmOb6f//mgrs/MJ0IrqV1WbD1RQDb4dJTT56QicNca6q4IpUO1Jd5impr0vSRmDLvMrtm16XmmK2zAOyz0pNXd/F39IlIfkfaejy749LtUkHFgNLHry1czqykLb2ed021+ncbAcNPuhUVFRg+vTp+Pvvv3Hw4EG8//77yM6+TrIni/3f4FbYre6B6ZpJxjv++QBIP26fQhE1VFWHCK+cJk2+Vl1RFrBrQWXNiLYcOLr85jvkZiVVdpStrvrCjlcOmR5z9u/K/jJ6cqXppHYAIFdU3i/KqvxHyM2vcvuRZTcusyWuHKyb8ziCcf8DXrlOzaCbP/DUPzXv1xvwJhDaru7KNWIxMPDtyseD3q+7c9dSgw86e/bsQZs2bdCoUSN4enpi0KBBWL/+OrM/ksUCPNWYM6gVluvuxFJxV+WOzW8B87tLa54Q1Uf5V8z3hSnOAVa9AFy+yQ/M89uBc1tv7jlpR42bcqoHh1UzTJ/z23hg7SyphgSQ1kRaNqGycywg9ZuZ6yPdci+YnqM4B/giruZyVf+9rWmm3uqEFsg0MxqratA5thxI6ApcOmC81MGWt02fVxt/32C4dkMR1Mp02/hVptvumw8Meq/ycdVOvWpvQC4HWg4xfd7gD4Cntkr7b6TbJMA7ovLxq7nAS9cJ1r2er3kfALS5D/AOAybvAe798tbnLaoDdg8627Ztw9ChQxEeHg6ZTIYVK1aYHJOQkIDo6Gi4urqiW7du2LNnj2Hf5cuX0ahR5ey9jRo1wqVL7DRbVx7qHIm4xn54u8zMjJjzIoDtH9u+UETXk3EC+KgV8E1/031rZknzn3zdx/LzlZcCi4YAPwwDSmsY5lvd5YPSoomfVwkc1Ucu5lf5O3X4N6kD7vlr/4Gf2ywFI/2w3txUqV9P1hmp34zehlekr0IAV89LX9dfZ8SUdDCw8nmp+ezD1lL/G0vsqGFSOZnC+HH2GeCbvsDFPeaPb+jaVunvc71J8MI7GT+ecbry/vBvjQPMw0uA6F6Vj0PbAy9nAR1HSRMT6o1aWnnf1Vv6am7un65PAL5R0n3/JjWXEQAULsZhVSaTJkDsMrFyW5sqywP1fxXwtKDPTVBLoNPoerHUh92DTlFRETp06ICEhASz+3/55RdMnz4dr776Kg4cOIAOHTpg4MCByMi4yapcqhW5XIa37m+LIrkn2pd+g+zQXsYHbJwLnGYNGlUhBLD8SWD1zLo7p6ZYqr0Q4sY1ifp1dtKPANs+MN5nbr6WGym5Tq1MTU6tNX7u6XXA9wOMj9EPJU7aBCyfaFrDs+NT48df9jDtDJubKvX9+XE48GkHaV6WkxbMe7Xve2n00c3M/6IfCl5dTXO8OKqqHckf+qHm4x7+sfL+PR8DXiGVj/1igNh7Kx/rl0Zo0kf6GjdOCiCANGnr5L3A0/9KzVF6Lu7SV4Xa+DUn7TAuR1hH48djVgDDvjDeJjcTlqoG2A4jpa++UVJwmfQP8MjPwNBq4dcrDPWR3WdGHjRoEAYNGlTj/o8++ghPPPEEJkyYAABYsGABVq1ahe+//x6zZ89GeHi4UQ3OpUuX0LVr1xrPV1ZWhrKyyirt/Hwn+yWthVah3pjYKwZfbTuHoVenY3O3jlDvrvKL8tMIYK6FHwDk+HLOAYd/ke4PnFc3s+zO7y7VWIR1lEblPL0TCIk1f2zV4c9/vwHcWWXhwar/XX5/NzD2L0CpqvJcId2qVvlXbX768nbpgyKyi/RYp638bzj7LLD5baD1PaYf/ubWCAKAhUNM1zLSK8oyfmwulFzaB7xe5cNv5Q2aFawhaaPtX9Oe4iYA8a9JEw/G3CmFBnOdtH0igD7/Jy0F0WGUtG32BalmT+0p3e6bL61P1ehagH3kJymMR1T7DAuqMulf+0ek97jnteCkrBJ0Wg81LYebb+V9/e9N9WbYZv2B4yuMw03VWp4WA6V1tQKvlcMzGGg1WOqP5REINIqTAqB3uOnr1wN2r9G5Ho1Gg/379yM+vrKnvlwuR3x8PHbu3AkA6Nq1K44ePYpLly6hsLAQa9aswcCBA2s857x58+Dj42O4RUZGWv06HMFz8c0R5e+Oy3mleL3gPuNqTUCqqi9It0vZqJ6pOulZXU2AdvW89FU/9Fjfh8Ucndb48fkd5jvzpu40/ZBe8iAwv4f0YaQtl2bDrVqjoykEvr/29yXtiDRjrr759udHgKPLpH42u76sfM7iYTWXNWU7oK1hXp0Di2t+HlV6NVe6VRfeyTQw3Ija23SbT1Tl/Yl/S2EirL0UcgDjZh09/bI5fWYBY/8EXK41cbl6Ax4Blcd1HAV0f6YyWKs8gKjbr9+35oGvpKYvfWi/0RpSVcOH/p+DmDuB+LnAqGtD/Ds+Cgz/DngusfJYWbUyNO4hhZqq5HKg1RBp+Hhwa+sv5VFL9TroZGVlQavVIiQkxGh7SEgI0tKkabiVSiU+/PBD9O3bFx07dsSMGTMQEBBg7nQAgDlz5iAvL89wu3DBTGc+MuGuUuL9B9tDJgOWHMjApiYvGh/wdR9pqvG/pgLf9Ku5PZ8cX9UVmWv6EL9VmSeA/5oZwnpkmTSkuqpFg4HPO5uWDZDWKtIUXesP87oUfDJPSOv7fHWntJBh9QAvtMA/H0nzqmgKpObbuT7SPDXmJN9kJ2ZHpG9mqWvj/id94Mtkps0vugrjfi+WmLIXeHIrEH1H5baWd1fej4gz7XNSfaXwEYuBu16HzbS99nvg29j8/m6TpMAXP7dym0wmdSpuca05VS4H2j1Y2a8HAJr2tUpx7cHuTVd1YdiwYRg27Dr/NVWhVquhVqtvfCCZ6NYkAI/3jMG325Mx6/fD+PvBX+C97GHjg/T/hV7aL/W+r/qLY46mWBrREnNn5X891LBVHcVzs0uHZJwE1r8E9JkjVY/vmg90e8r8sWerDc8uzZPmVzGnLA+4mmI6tHrNTGDbe9KK01WbkLTl0ozgAHBhl+n5rrf2DxmL6AqM+UNaW2rBTQSP9g9XNoEC0pww6UeBgGbSkGi1l3GQib5D6sStp9MCvV8E3AOA9f+Rtrm4Gy8HUZ2bn1Q7MX4lcHAJcOIvKSB0nwKoPGt+XlVt7rP0CutG4x7ApO01/61VewETN9z8eZvFSz83Oy/fUBfqdY1OYGAgFAoF0tON/6NKT09HaKh9Z1p0Vi8MbImWIV7IKtRgxoFAiMEf1HzwgjuktuCTq6WhvtpyaWXkqv43Verjs/4l6xacbKdqc5V+iHdhJnDwxxuvjfRlN2kW7u8HAt/GA7sSpJl5a/LtXVJQBqQRRNfzaXtpjabqijJN+8lUXdZgrwNNQhrV3favGdZeqvWoqVlD3z+luuq1QA//CPR4Fhi5FGg5yLS25v4FlX1hAOnvjYsb0GMK4H6tySXqdmDEIqDvfypfd0CVIeuKKv21Oo0GRv0iNSf5NTZucqpO34k4uIZ+Y9YW2s46zUZN+wE+jW58XD1Xr4OOSqVCXFwcNm2q/M9Np9Nh06ZN6N7dDr+wBFcXBT5+uCNcFDJsOJ6OzVeDaz64NFcakrt0JPBujDTz6rvRxqNm9NPA7/3GmsV2LuYmdbOW38YDS0dXNgmdXA2snVO5P3GJFHg/v01aHVo/HNqcqp1+deXSIocAkHO25udc3CMN/c67BJTfwgKT1S2pgyUD6hu5Enhsbd2c69kDQLenAbUFH676UUE1fRA/sUnqJNt7FtCuSqdtXbXaQJ9IKZQENjd/Hq9Q4P75QNC1wFu178zj66VamfsWSNt7vyh1rn3hjDQCSq+2Q6Ef+FbqeDy6hmUtyK7sHnQKCwuRmJiIxMREAEBycjISExORmirNIjp9+nR88803WLx4MU6cOIGnn34aRUVFhlFYZHux4d6YMUCqznx2hwppI1YCUw8C41fX/CT9h5CmAEjZCZxcJc0JYilNMZeesETqbuCt0NpNrJZ/WeqnsnAwkGmmv4k+zOi0Us1caR5w7A9pOHNuqvQzXTrSeP6ULfOk/i76UUh7vwWKsqVzfT9I6ttybov0+H/P3XyZ9RbWPHKzwWhxg2uYcVr6sK5JcJvrP1//3Ed+Mt3X7Wkz2yaZbgOkeV0CmgKD3gFmmvkdrtpXpvWwyo65Kq+ayxYSC/T9P6Dztb/rYR1Ma38tHb03fpXUT+bOKtMbBDQFBr5lPMRbqZKaRz2CLDvv9XgGSR2PfSJufCzZnEyI6r3zbGvLli3o29e009O4ceOwaNEiAMAXX3yB999/H2lpaejYsSM+++wzdOvW7ZZeNyEhAQkJCdBqtTh9+jTy8vLg7W2mxz2ZpdUJjPxmF/Yk56BzYz8sffJ2KBVy6QN2Wy2n/H7ukNRXQlMk/YeuH1J5aT/w3UDgtjFSe/nGudJ/fmpPaTHBXtMrJ88qzpFqGVoPtXxGzhMrpaGa+iHD9rD1Pak/wPhVt1YF/U0/6fsFWDbkv7xUmq9jwyumnXirPl9TJDUT+UZKTT2X9kv/EddVwBj9e8OpRWk+EDizru7P+/jGmteCenS5NARYWy4tDHrGzNxV5sr1yM/S+8nFFQjrVDmapzhHmsG4KFN6POo3qQkZkEbbjL62aOavY4zP98wuqdOrqkqz0uKhlauMA1Lzj775svp7cK6Z93b1Y7KSpOaSPydLv981HVdXhJCWtQlsYTy3DdV7+fn58PHxueHnt92Djr1Z+o0iUxdyijHo039QWFaB8T2iMXdYG2k47rktUlOUuT/GN9J9SuUH7t3vSiMBVs+snKys46NA4o+mz2vSF2j/kDTJmn6a+heTpcm2zCkrkEbJaIorZ4admyfVTLj6mIYNIYCCNGlq8xv5aypw+YD0wSWTS7UYzfpLM4XWRP8B0O9l43lfblbVD5KqHwzJ26RraNK7cltRNvB1bwAyIK/KOkx6T2wGGt1mel5nd98CoOPIuv+ezE4F3qmhQ+n41UB0T+n++peBf82ManzkZ6CiRHpv62vHJqwFGl+nmX//ImlRzgFvAa9fW5vKMwR44bRU41p9gsJXcoznVwGk1zuxUhoq3/UpIPEnYPd8qX/HmD+Mj724X1oc9JfRldtqCjC/P1G5sOiIxbbv5Ev1nqWf3w4x6orsI9LfHR8+1AFP/Xc/Fv17Hi1CvDCqW5Q0ZDG6J7DzS+lDXt/XwhJVaxXWzpJmcPWs0g/odA19DM5tNh5xAUh/UKsHnbN/S7VO+lqPqtbMlv5Au/oCs1OM9218VQpRw7+TpoBfO1uqoh/4lul59CPPzqwDcpKl525wAV7JMj22uuojQi4nStd/o4m4SnKBA9VmaV01Q+pUe89H0n/dgPSBEdAMCG0LbH7TfOdcvW/6Std7vX41DdHgD6RO0vqRODerNFf6+sTfUg1aVUM/kzrYVzfofWmEV3URXSo7QlcP1+4BQPG1BYqrjkisPjN0s3hpzpiWg6Q+JkXZlUGn6mSI5sSNr7zf9Ulgz9fSFP+A1Bdm3P+k4HNxn9Qpt3rIAaRRPR1HSjdACvQxd5of2h1xbUmMoZ9KZbxvfs1l6/cSkPKvNOqOIYduAYMO3ZKBbULxwoAW+GD9abzy51E0CfLA7U0CpD+KvWdKN73iHGl6/rWzLH+BrFPSzXAOC8KC3vwe0kykJVelxRFzU6/f5LD72h9d/QcZIA1J1lVUTsf/17PSh8ruBdLjfi9JIzvM+eejysm8qnes1Cu5Ki2XoFd1sruspGs1LjD+rzf/svSB1PlxqSkJkD40jq8wPrd+tFD7Kmvl/DZO+jp+tRQib6Sm4doNWWh7IOOY6fYuE2seYeUVJgVnAAi41hnWN9r4mKkHpXWFsk4De76RJlfTr2fVeYIUYlN3SaOAFl1biFFRLYhMWAP8/ZY0N0qXx6XmwoI0aWi1XtUh+6HtgEd/Nz5H1b4schfz12PO3e8Ctz8D+FfpnKufFO96tZHVKdXSrLnXEzde6uuj8qj5GL/GwHQzPyeim8SgQ7dsct9mOJVeiP8duoynf9yPPyf3QlSAmQnC3P2B2ycB2Um2G2X1ZXcg/+LNP08I6b/+r/sYz4xbXmy8IKSmSJp0zi9aWmyx6jo4+ll8q8u7BBz6Geg0Rppk0eh1tcCJ/0kfiCE1dC79eaR07tPrpeG2ydtMQ05VP5rp+7LoBh9E9VFYR2mek+o1dw//CPzyqPG2PnOkjtDVDf4AiOomzelS3ZAPpRmUT/xluq/tcGm9n7TDUjMkYDrcWL944sC3pOHL294Htn8kbVO4AL2mVR47cZM0fPqPJ43P0bgHMKHKKtaPrQWErnLdI0Bq2kzaKPVZ6z3btKxVw5O5NYxqIpcbhxxru17IIapDDDp0y2QyGd5/sD1Ssotw+GIeJv6wF78/3QNerjX8NznkA2nl3rxUYNUL0rwpeuGdpAXwzmwANptpFrpZtQk5gNRck5tiHHL0qq5j9Nt4acXpdg8Zd5w0p6xAquZfMkKqUfj7DdNjKspMP7QBaduQj4BTayoDVMYxYEUNI2McjVcY8OQWqWmmat+YB74BWt0D9H9FGjEGSLVo3SaZDzpx10b1uPlVbuvzf5Wz3z70g9Qs6eojBc1fx1YeF9pWulUldzFfW6dylwKJrlwaeVRdxLW+L+0ekpaSqL7SteH8CgDVmov8Y4AZJ2seCl21Fqf6rL1EToidkdkZuc6k5ZVi2BfbkVFQhv6tgvH12M5QyC2Yl6I0X/rwbtzTuA/Anm+A1dc65g56D1jzotmnNxhu/lLfpRP/s3dJatb1KWDPV7V7rouH8Vw2Ie2kFcSvJ/41aSjxf++r3DZ+tVSzpe9XBACzzleGk6pB59Xcyg/8L3tI4e+2scCwz4E/pwAH/1t57O2Tgbvflu7nXQI+vja52+wLlaP2qtO/Vvcp5vtjHf9TCkMD50lrFt0sbbm0enlUN+Pwdau2fSDNAl112n8iB2Pp57fd59Gxl4SEBMTGxqJLFzsOKXYwoT6u+HpsZ6iUcmw6mYH315268ZMA6UMm5k7Tjo5V+wV0mQg8uFCa7+OlDNN+CTfrkZ9v7fm1UZJTv0OOmz8w+L2a93e+zkKajXsBd1VbFmHSP5V9PKrS93EBpI6mTftKUwQAUvNRdE/jOWFmpRiHgBGLpA7jY1YY12o8+rv0/LvfkR7f8zHQfIDUvDM3rzLkANLw5f6vAn1fqjnkVFVT7UnsvcCcS7ULOYDUJNXy7roNOYBUm8SQQwSANTqs0bGCPxMv4bmliQCAdx5oh0e63mC9q5poy6XJ6wKaStO7V1WYCXzQzPQ5t42VmgP0Q8Zr8uD3wKGl0hD4RnHmR2E5m8Y9gQmrpZFph38DDlWZWG7i39JQ80/amR+p9dB/pbmLXvOt3DY3T+rrVHVb/1eAO2ZIy0EAQCczzXR6aUelpj4/M4sVClH7WWxvhr5G56H/ArGWradHRLbBeXQsxKBjHe+vO4mEzdLU/c/Ht8DU/s0gq+sPphXPSHPmVA0pLyRJo11WvyBN7e7mK9WiDPtCGpr+15TK45Qqafhq0/7SaKzgWGmpgrrS6dHKD/T6yDdKGomm99xh41BRtYloziWpv0dOstQc9M+H0vYuTwBx46RRQTKZ1EF61XTgvi8ra3MyTkhDqDuNsU04qUuZp4DLB6UFJhta2YkcHIOOhRh0rEOnE3hv3Sks2CqFneG3RWDeA+2gUlqhtfTH4dIolDteAPq/fP1jKzRS34WaJhKsPglcl4nStO4b50qPZXJp/pSNc6WJEasauRT4+ZHKx2P/BH6w00yrHsFAUUbl457TpPV9FGrgjWujhfTrCh35VarVeuJv43PUNPlg1X09njVeFJGIyEY4YSDZlVwuw+xBrRDp74ZX/jyG3w9cxOXcEnwxqhMCPNV1+2IjFkvDsc31B6lOqQKUNYQcwHTm5S4TjYeMzzx7bZj85MqgM/2k1M/DxR2I6Q0kb5VWRm7SR+pXFNRSmtNHzzNEGhlT2xFhlnh2nzSJ4KftpceNe1QO5/WJkka8tbkPiL5DWtHZ3MggyAAIoP0jZvZVPYaIqP5ijQ5rdKxu86kMTFlyAEUaLUK81fj0kU7SpIL1UXmJ1MwS0VWq+fEIlLafXC3NFKtfObk4B3i/mdTUM/Wg8TkKM6Xgo6wS6P79QprvZsiHUuAoSJOmwc85d/3yxI0Hhnws9YupPqdPTZ7cUjlcOfsskH5UCjL6ppfiHKk5qXGP6zfHZJyQ+jH1fM60Bkxfo3P3u9LcSERENsamKwsx6NjGybR8TF5yAGcziyCXAVP7N8ez/ZpbNvy8virKkkJLTTMjW6Jq89Bdr1cut9BxtDSlf4u7KyeLs2RtparDra3p5CqpI/eg94wDHRGRjTDoWIhBx3aKNRV45c9jWLZfarLp3iQAnzzSESHerjd4pgO7dEBa36vP/wGBzYAzG4Gjy6QAUX3Y808PSx2q5UppWYqqph0BPENvvLYREZGDYNC5gYSEBCQkJECr1eL06dMMOja0/MBFvLTiKIo1WgR4qPDhQx3Qp2XwjZ/o7AozpBFk7R8Gdn0prTydf0la/PHFGzSBERE5GAYdC7FGxz7OZhZiyk8HceKKtJzCk3c2wXP9m8NDzf7xFivJldYMa/ugbdcoIiKqBxh0LMSgYz+l5Vq8teoE/rsrBQAQ5e+Ojx/uiLjGdTxLLBERORwuAUH1nquLAm/c1xYLHo1DuI8rUnOK8eCCf/Hqn0dRUGpmoUQiIqKbxKBDdnd321Csff5ODL8tAkIAi3em4K6PtmH1kStw8gpHIiK6RQw6VC94u7rgw4c64MfHu6FxgDvS8kvxzJIDGL9wL85nFd34BERERGYw6FC90qt5INZNuxNT+zWDSinH1tOZuOvjrXhr1XHklbA5i4iIbg47I7Mzcr2VlFGIN1Yex9bTmQAAP3cXPNuvOUZ0joCXq4udS0dERPbEUVcWYtCp/7acysCbq04gKaMQABDoqcL0u1pieFwjqJUKO5eOiIjsgUHnBjhhYMNSodVh6d4L+PafczifXQwACPFW44k7muCRrlHw5Pw7REROhUHHQqzRaVg0FTr8d1cKvtl2Dmn5pQAAL7USz/Rthkdvj2KTFhGRk2DQsRCDTsNUVqHFioOX8NmmJFzKLQEAeKqVGNohHM/2a4Zw31tYaJOIiOo9Bh0LMeg0bBVaHX4/cBFfbzuHs5nSMHS5DLijeRAe6hyJQW1DIW/IK6QTEZFZDDoWYtBxDDqdwK7kbHy+KQk7z2UbtrcM8cLEO2JwT/twuKnYcZmIyFEw6FiIQcfxnM8qwtK9F/Dd9nMo10pvby+1Evd2CseDcZHoEOEDmYy1PEREDRmDjoUYdBxXZkEZft13Ab/svYDUnGLD9iaBHhgeF4EH4yIQ4u1qxxISEVFtMehYiEHH8el0ArvOZWPJ7lSsO5aGCp30llfIZWgT7o2Hu0TigU4RbNoiImpAGHQsxKDjXDILyrD8wEWsPZaGg6m5hu1uLgp0bxqAEXER6NE0ED7uHKZORFSfMehYiEHHeSVeyMWPu1Kw+WQGsos0Rvv6tgxCj6aBGNYxnM1bRET1EIPODXBmZNIr1+pw+GIe/ky8hPXH0g0TEQJS81aHCB8Mj4tAfOsQhh4ionqCQcdCrNGhqnQ6ga1nMrH+WBqOXMrD0Uv5RvtbhHhiQGwo+rUORssQL3hw6QkiIrtg0LEQgw5dz9nMQqw9mob1x9Jw+FIeqv62eKgU6NsqGB0jfXFbYz90jPDl5IRERDbCoGMhBh2y1NUiDbadycTKw1dwMPUqsgqN+/UEeKhwe9MA9G4ehO5NAxDp726nkhIROT4GHQsx6FBtCCGwJzkH+1KuYte5bPxzJsvkmEa+bmgR4okOkb64o3kgOkX6scaHiKiOMOhYiEGH6kKJRou953Ow+VQG1hxJM+rQXFXLEC80D/HEvR0bIa6xH/w9VDYuKRGRY2DQsRCDDtW1Cq0OhWUVOHghF8cv52PjiXSjOXuq8nJVopGvGzpH+6Ffq2DEBHoiws8NLgq5bQtNRNTAMOhYiEGHbEFToUNqTjF+P3AR57OKcCajEEkZhWaPVcplaBLkgd4tgtAuwheNfF3h5qJEbDjfn0REegw6FmLQIXvJKy7H3vM5OJ9dhD3JOUjNKcb57CKUluvMHh/p74Yu0f4I8XZFiJca7SJ80LaRD9RKLl1BRM6HQcdCDDpUn+h0Amn5pdidnI0DKbk4eOEqTqUVGFZhr04pl8HTVYm24T5QKeVoHeaFdo180TXGH37uLlylnYgcFoOOhRh0qCFIzy/F/pSrOJ9dhIz8MpzJKMDhC3koKKuo8TkKuQy3RfkiJtADjQM8EOylRpS/OzpF+UGlZB8gImrYGHQsxKBDDZVOJ3Dscj62J2XharEGp9MLcOlqCQrLKnAlz/yoLwBQK+Vo5OuGYo0WmYVliA5wx/C4CHSJ9kezIE+4qRRQK+WsDSKieo1Bx0IMOuSI8kvLcfRiHk6nFyAlpxiZBWVIzSnG2YxCFGm0Fp0jyt8dHmolYsO80SrUC8HeavRpGQwfN67sTkT2x6BzA1zUk5yREALJWUXILtJg+5ks7DybjT3nc2p9Pj93FwzrEI7jV/LRJtwHPZoGICbQA2G+bvDkOmBEZEUMOhZijQ6RRAiBYo0Why7m4nJuKU6nF+DrbefQOswbJ67k3/gE1aiuNZFFB7jD280FsWHeCPF2RYVOoFmwJ1qHeUEIwNWFo8aI6OYx6FiIQYfIckkZBbhaXI5DF3Kx9XQmLl4tQYVOhws5JbU6n0wmLZUhkwG+bir4eahwOq0Aw+MaoXmwF2ICPeDqooC/hwr5peVoEuhx7XnsP0Tk7Bh0LMSgQ1R3Ssu10Gh1OJNegJyichSVVeDElXxkFWqQV1KO7KIy5BWX41xW0S29jkohh0YrzTfUJMgD+SUVGNAmBN2bBKBxgDtcFHJkFZbB100FL1clGge4QyaTQQjBkETkIBh0LMSgQ2R75VodisoqkFlQhtPphZDJgLySclwt1uC9tafg7apEgKca+SXlqNAJ5JWU3/JreqgUKNJo0a6RDzILypCWX4p+rYJxV2wIMgvKEO7rhiZBHnBXKeDuokSEnxt0QkAhlzEcEdVDDDoWYtAhqt+EECgoq4CLXI6zmYXYn3IVLgo5Dl/MRWm5FheulsBdpUBhWQVSs4sBANlFmjp7fbkM8HVXIdhLjXBfN3i5KuHlqkRaXhlUShlclQq4qRRoEuQJIQRiAj1wJa/02pxFvnBXSZ2yS8u18GAHbaI6w6BjIQYdIsekb0ZLySqGTgik5BTjQMpV+HuocPFqMX7ddxEdI33hrlLgUm4JijValGq0152E8Vbpm9w8VAq0DPVCUZkWF64Ww8fNBYVlFWgT7o2iMi3KtTrc3TYU0QEeEBAI93FDTJAHZJDB200JuUyGCznFCPZ2hadaiXKtjgvBktNh0LEQgw4RVVdarsXVYg3KKwRkMiA5qwgZBWXQ6nQoKK1AQWkFcos1SMsvRX5JBWQyoKxCh/0pV+1a7nAfV1zOK8VtUb4I9nKFr7sLtpzKhJerEsUaLTpG+uKO5oHwdXdBak4xmgR6wtfdBYcv5iHS3x09mwWgoLQCqTnFaBXqhXKtgKdaiXNZhWgV6g2tTkAIASVDFdUDDDoWYtAhImsQQqCsQocSjRbZRWU4kJqLorIKfLzhNHq3DIaPmxLFZVqkF5TifFYxLuWWIK6xnyEsKeUy+HmoUKrRorRCW+N6Z/bi5aqEWqlAVmGZYVvXGH94u7pA7SJNLaDTCSgUMvi7qxDl746mwZ5IyyuFUiHDxasliA2TwlNhWQU81Up4qBWI9HeHWqlAiUaLIk0FAj3VdrxKqs8YdCzEoENE9Z0QAiXlWshlMhy5lIfkzCI0C/HEhZxiuLoocCqtAEWaCsSGeWNHUhZKy3XILy1HoKcaO5KyDEuCRPm7o1hTgazCuuvDZA0+bi5GHdD1Hcn7tAyCTgAySOu/ZRVq4O2mhEohR4cIX6hd5PjjwCUUlFXg+fgWCPRSQSeAYC81sgrLUF6hg1IhR0ygB4K8pM7uWp2AAJBVWAZvVxeEeLsiws8NKqUcWp3AjqQsxIZ7w81FAV93lUlZC8sq4O6igFxuvsP6ybR8hHi5ws/D9Ll0axh0LMSgQ0TOrKisAmn5pVDKZUi+Nuzfy1UJQAalXIYTV/JRrtXhXFYRFDIZzmUV4XxWEQSAliFeUMhlWHXkCkK9XeGhVkAIwEUhh7ebEnkl5cgq1CCnSANfdxdoKnQotnAJkvrK30OFIE81TqUXGLbFBHrA280FEX5uKNFo8ffJDAR6qo1quwDp+9Um3BuFZRWI8ndHhU5ge1IWyiq0uKd9ONRKOUo0WpSUaxHq4wpXpQJqFzku55Yg1NsVKqUczUO8cLVIg8YB0ghBD7USEIDaRY4KnYBaKUdKdjGiA9yhVMih00md+TefzMBdsSEO1SGeQcdCDDpERLYhhNRM5eaiQF5JOTxdlSjV6HAxV1qPLcLPDXvPX4W7SoHWYd7IyC/Dn4mX0LaRD7KLNPBzl2p6fN1ccCW/FLvO5aCgpBwxgR7ILpICVWqONPKuQ4QPCssqUKLRoqxCV6cj8RoKfw8Vcsxcd5iPq9HCvzIZEOChRrivK/JKypGSXYwh7cLQyM8NQgjI5TJUaAUyCsoQ5uOKCq2Au0qBr7adhY+bClH+bvBzV6FrjD/KtToo5HJcvFoMmQxoFeqN7k0D0DTIs86vj0HHQgw6RETOpbRcC50QcLu2/IgQQEFpBTIKSpFfWg6ZTIa8knIUlFagaZAHDqRcRaiPG67klSC3uByNfN1w6GIuovzdEeXvjqxCDXYnZ8Pb1QVyGXAuqwjNg73w79ksnEwrMHrtqh3GizVaw/5Gvm4o1lTgavGtzxlVH618thfaNvKp03Na+vntOHVYREREFqi+vppMBvi4u8DH3cXs8W3CTT+gh8dFGD0e1S2qzsqnqdBBpZRDCAGtThrllldSjsKyCoR4qVGhE8gtLodcDlzIKUGojyuuFmlwNrMQMYEeKNcKXM4tgVoph4tCjuSsIoR4u+LwpVwo5TI09vfA6fQC5JWUo7hci8LSClwt1uCRLlEQENh2OhP+HmoIIaBSypFfUo7krCIEeamhkMuQkl0MuUyG41XWwPNSK9E6zNsw8adOCGQVauBxrXktNsx+FQms0WGNDhERkdXog1tds/Tzm5MhEBERkdVYI+TcDAYdIiIiclhOG3QSEhIQGxuLLl262LsoREREZCXso8M+OkRERA0O++gQERGR02PQISIiIofFoENEREQOi0GHiIiIHBaDDhERETksBh0iIiJyWAw6RERE5LAYdIiIiMhhMegQERGRw2LQISIiIoeltHcB7E2/AkZ+fr6dS0JERESW0n9u32glK6cPOgUFBQCAyMhIO5eEiIiIblZBQQF8fHxq3O/0i3rqdDpcvnwZXl5ekMlkdXbe/Px8REZG4sKFC06xWKgzXa8zXSvgXNfrTNcKONf1OtO1As5xvUIIFBQUIDw8HHJ5zT1xnL5GRy6XIyIiwmrn9/b2dtg3mTnOdL3OdK2Ac12vM10r4FzX60zXCjj+9V6vJkePnZGJiIjIYTHoEBERkcNi0LEStVqNV199FWq12t5FsQlnul5nulbAua7Xma4VcK7rdaZrBZzveq/H6TsjExERkeNijQ4RERE5LAYdIiIiclgMOkREROSwGHSIiIjIYTHoWElCQgKio6Ph6uqKbt26Yc+ePfYu0k2ZN28eunTpAi8vLwQHB+O+++7DqVOnjI4pLS3F5MmTERAQAE9PTwwfPhzp6elGx6SmpmLIkCFwd3dHcHAwZs6ciYqKClteSq288847kMlkmDZtmmGbI13vpUuX8OijjyIgIABubm5o164d9u3bZ9gvhMArr7yCsLAwuLm5IT4+HmfOnDE6R05ODkaPHg1vb2/4+vri8ccfR2Fhoa0v5Ya0Wi1efvllxMTEwM3NDU2bNsUbb7xhtD5OQ77ebdu2YejQoQgPD4dMJsOKFSuM9tfVtR0+fBh33HEHXF1dERkZiffee8/al2bietdaXl6OWbNmoV27dvDw8EB4eDjGjh2Ly5cvG52joVwrcOOfbVWTJk2CTCbDJ598YrS9IV2v1Qiqc0uXLhUqlUp8//334tixY+KJJ54Qvr6+Ij093d5Fs9jAgQPFwoULxdGjR0ViYqIYPHiwiIqKEoWFhYZjJk2aJCIjI8WmTZvEvn37xO233y569Ohh2F9RUSHatm0r4uPjxcGDB8Xq1atFYGCgmDNnjj0uyWJ79uwR0dHRon379uK5554zbHeU683JyRGNGzcW48ePF7t37xbnzp0T69atE0lJSYZj3nnnHeHj4yNWrFghDh06JIYNGyZiYmJESUmJ4Zi7775bdOjQQezatUv8888/olmzZmLkyJH2uKTreuutt0RAQIBYuXKlSE5OFr/99pvw9PQUn376qeGYhny9q1evFv/5z3/E8uXLBQDxxx9/GO2vi2vLy8sTISEhYvTo0eLo0aPi559/Fm5ubuKrr76y1WUKIa5/rbm5uSI+Pl788ssv4uTJk2Lnzp2ia9euIi4uzugcDeVahbjxz1Zv+fLlokOHDiI8PFx8/PHHRvsa0vVaC4OOFXTt2lVMnjzZ8Fir1Yrw8HAxb948O5bq1mRkZAgAYuvWrUII6Y+Ki4uL+O233wzHnDhxQgAQO3fuFEJIv6RyuVykpaUZjpk/f77w9vYWZWVltr0ACxUUFIjmzZuLDRs2iN69exuCjiNd76xZs0SvXr1q3K/T6URoaKh4//33Ddtyc3OFWq0WP//8sxBCiOPHjwsAYu/evYZj1qxZI2Qymbh06ZL1Cl8LQ4YMEY899pjRtgceeECMHj1aCOFY11v9w7Curu3LL78Ufn5+Ru/jWbNmiZYtW1r5imp2vQ9+vT179ggAIiUlRQjRcK9ViJqv9+LFi6JRo0bi6NGjonHjxkZBpyFfb11i01Ud02g02L9/P+Lj4w3b5HI54uPjsXPnTjuW7Nbk5eUBAPz9/QEA+/fvR3l5udF1tmrVClFRUYbr3LlzJ9q1a4eQkBDDMQMHDkR+fj6OHTtmw9JbbvLkyRgyZIjRdQGOdb1//fUXOnfujBEjRiA4OBidOnXCN998Y9ifnJyMtLQ0o2v18fFBt27djK7V19cXnTt3NhwTHx8PuVyO3bt32+5iLNCjRw9s2rQJp0+fBgAcOnQI27dvx6BBgwA43vVWVVfXtnPnTtx5551QqVSGYwYOHIhTp07h6tWrNrqam5eXlweZTAZfX18AjnetOp0OY8aMwcyZM9GmTRuT/Y52vbXFoFPHsrKyoNVqjT7sACAkJARpaWl2KtWt0el0mDZtGnr27Im2bdsCANLS0qBSqQx/QPSqXmdaWprZ74N+X32zdOlSHDhwAPPmzTPZ50jXe+7cOcyfPx/NmzfHunXr8PTTT2Pq1KlYvHgxgMqyXu89nJaWhuDgYKP9SqUS/v7+9epaAWD27Nl45JFH0KpVK7i4uKBTp06YNm0aRo8eDcDxrrequrq2hvLerqq0tBSzZs3CyJEjDYtaOtq1vvvuu1AqlZg6darZ/Y52vbXl9KuX041NnjwZR48exfbt2+1dFKu5cOECnnvuOWzYsAGurq72Lo5V6XQ6dO7cGW+//TYAoFOnTjh69CgWLFiAcePG2bl0de/XX3/FkiVL8NNPP6FNmzZITEzEtGnTEB4e7pDXS1LH5IceeghCCMyfP9/exbGK/fv349NPP8WBAwcgk8nsXZx6jTU6dSwwMBAKhcJkNE56ejpCQ0PtVKramzJlClauXInNmzcjIiLCsD00NBQajQa5ublGx1e9ztDQULPfB/2++mT//v3IyMjAbbfdBqVSCaVSia1bt+Kzzz6DUqlESEiIw1xvWFgYYmNjjba1bt0aqampACrLer33cGhoKDIyMoz2V1RUICcnp15dKwDMnDnTUKvTrl07jBkzBs8//7yh5s7Rrrequrq2hvLeBipDTkpKCjZs2GCozQEc61r/+ecfZGRkICoqyvA3KyUlBTNmzEB0dDQAx7reW8GgU8dUKhXi4uKwadMmwzadTodNmzahe/fudizZzRFCYMqUKfjjjz/w999/IyYmxmh/XFwcXFxcjK7z1KlTSE1NNVxn9+7dceTIEaNfNP0fnuoftPbWv39/HDlyBImJiYZb586dMXr0aMN9R7nenj17mkwVcPr0aTRu3BgAEBMTg9DQUKNrzc/Px+7du42uNTc3F/v37zcc8/fff0On06Fbt242uArLFRcXQy43/lOnUCig0+kAON71VlVX19a9e3ds27YN5eXlhmM2bNiAli1bws/Pz0ZXc2P6kHPmzBls3LgRAQEBRvsd6VrHjBmDw4cPG/3NCg8Px8yZM7Fu3ToAjnW9t8TevaEd0dKlS4VarRaLFi0Sx48fF08++aTw9fU1Go1T3z399NPCx8dHbNmyRVy5csVwKy4uNhwzadIkERUVJf7++2+xb98+0b17d9G9e3fDfv1w6wEDBojExESxdu1aERQUVO+GW9ek6qgrIRznevfs2SOUSqV46623xJkzZ8SSJUuEu7u7+PHHHw3HvPPOO8LX11f8+eef4vDhw+Lee+81OyS5U6dOYvfu3WL79u2iefPm9WK4dXXjxo0TjRo1MgwvX758uQgMDBQvvvii4ZiGfL0FBQXi4MGD4uDBgwKA+Oijj8TBgwcNI43q4tpyc3NFSEiIGDNmjDh69KhYunSpcHd3t/kQ5Otdq0ajEcOGDRMREREiMTHR6O9W1RFFDeVab3S95lQfdSVEw7pea2HQsZLPP/9cREVFCZVKJbp27Sp27dpl7yLdFABmbwsXLjQcU1JSIp555hnh5+cn3N3dxf333y+uXLlidJ7z58+LQYMGCTc3NxEYGChmzJghysvLbXw1tVM96DjS9f7vf/8Tbdu2FWq1WrRq1Up8/fXXRvt1Op14+eWXRUhIiFCr1aJ///7i1KlTRsdkZ2eLkSNHCk9PT+Ht7S0mTJggCgoKbHkZFsnPzxfPPfeciIqKEq6urqJJkybiP//5j9GHX0O+3s2bN5v9XR03bpwQou6u7dChQ6JXr15CrVaLRo0aiXfeecdWl2hwvWtNTk6u8e/W5s2bDedoKNcqxI1/ttWZCzoN6XqtRSZElelBiYiIiBwI++gQERGRw2LQISIiIofFoENEREQOi0GHiIiIHBaDDhERETksBh0iIiJyWAw6RERE5LAYdIiIqtiyZQtkMpnJumZE1DAx6BAREZHDYtAhIiIih8WgQ0T1ik6nw7x58xATEwM3Nzd06NABy5YtA1DZrLRq1Sq0b98erq6uuP3223H06FGjc/z+++9o06YN1Go1oqOj8eGHHxrtLysrw6xZsxAZGQm1Wo1mzZrhu+++Mzpm//796Ny5M9zd3dGjRw+TFd+JqGFg0CGiemXevHn44YcfsGDBAhw7dgzPP/88Hn30UWzdutVwzMyZM/Hhhx9i7969CAoKwtChQ1FeXg5ACigPPfQQHnnkERw5cgRz587Fyy+/jEWLFhmeP3bsWPz888/47LPPcOLECXz11Vfw9PQ0Ksd//vMffPjhh9i3bx+USiUee+wxm1w/EdUtLupJRPVGWVkZ/P39sXHjRnTv3t2wfeLEiSguLsaTTz6Jvn37YunSpXj44YcBADk5OYiIiMCiRYvw0EMPYfTo0cjMzMT69esNz3/xxRexatUqHDt2DKdPn0bLli2xYcMGxMfHm5Rhy5Yt6Nu3LzZu3Ij+/fsDAFavXo0hQ4agpKQErq6uVv4uEFFdYo0OEdUbSUlJKC4uxl133QVPT0/D7YcffsDZs2cNx1UNQf7+/mjZsiVOnDgBADhx4gR69uxpdN6ePXvizJkz0Gq1SExMhEKhQO/eva9blvbt2xvuh4WFAQAyMjJu+RqJyLaU9i4AEZFeYWEhAGDVqlVo1KiR0T61Wm0UdmrLzc3NouNcXFwM92UyGQCp/xARNSys0SGieiM2NhZqtRqpqalo1qyZ0S0yMtJw3K5duwz3r169itOnT6N169YAgNatW2PHjh1G592xYwdatGgBhUKBdu3aQafTGfX5ISLHxRodIqo3vLy88MILL+D555+HTqdDr169kJeXhx07dsDb2xuNGzcGALz++usICAhASEgI/vOf/yAwMBD33XcfAGDGjBno0qUL3njjDTz88MPYuXMnvvjiC3z55ZcAgOjoaIwbNw6PPfYYPvvsM3To0AEpKSnIyMjAQw89ZK9LJyIrYdAhonrljTfeQFBQEObNm4dz587B19cXt912G/7v//7P0HT0zjvv4LnnnsOZM2fQsWNH/O9//4NKpQIA3Hbbbfj111/xyiuv4I033kBYWBhef/11jB8/3vAa8+fPx//93//hmWeeQXZ2NqKiovB///d/9rhcIrIyjroiogZDPyLq6tWr8PX1tXdxiKgBYB8dIiIiclgMOkREROSw2HRFREREDos1OkREROSwGHSIiIjIYTHoEBERkcNi0CEiIiKHxaBDREREDotBh4iIiBwWgw4RERE5LAYdIiIiclgMOkREROSw/h+Xry4ddFZ5vAAAAABJRU5ErkJggg=="
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 2ms/step - loss: 0.7303\n",
            "EXPECTED:\n",
            "    d18O_cel_mean  d18O_cel_variance\n",
            "0       26.663818           0.574594\n",
            "1       26.663818           0.574594\n",
            "2       26.663818           0.574594\n",
            "3       27.559140           0.780698\n",
            "4       27.559140           0.780698\n",
            "5       27.559140           0.780698\n",
            "6       27.559140           0.780698\n",
            "7       27.559140           0.780698\n",
            "8       27.559140           0.780698\n",
            "9       27.559140           0.780698\n",
            "10      27.559140           0.780698\n",
            "11      27.559140           0.780698\n",
            "12      27.559140           0.780698\n",
            "13      27.260748           0.830341\n",
            "14      27.260748           0.830341\n",
            "15      27.260748           0.830341\n",
            "16      27.260748           0.830341\n",
            "17      27.260748           0.830341\n",
            "18      27.260748           0.830341\n",
            "19      27.260748           0.830341\n",
            "20      27.260748           0.830341\n",
            "21      27.260748           0.830341\n",
            "22      27.260748           0.830341\n",
            "23      27.260748           0.830341\n",
            "24      27.260748           0.830341\n",
            "25      27.260748           0.830341\n",
            "26      27.260748           0.830341\n",
            "27      27.260748           0.830341\n",
            "28      27.260748           0.830341\n",
            "29      27.260748           0.830341\n",
            "30      27.260748           0.830341\n",
            "31      27.260748           0.830341\n",
            "32      27.260748           0.830341\n",
            "33      27.260748           0.830341\n",
            "34      27.260748           0.830341\n",
            "35      27.260748           0.830341\n",
            "36      27.260748           0.830341\n",
            "37      27.260748           0.830341\n",
            "38      27.260748           0.830341\n",
            "39      27.260748           0.830341\n",
            "40      27.260748           0.830341\n",
            "41      27.260748           0.830341\n",
            "42      27.260748           0.830341\n",
            "43      27.260748           0.830341\n",
            "44      27.260748           0.830341\n",
            "45      27.260748           0.830341\n",
            "46      27.260748           0.830341\n",
            "47      27.260748           0.830341\n",
            "48      24.964000           0.108138\n",
            "49      24.964000           0.108138\n",
            "50      24.964000           0.108138\n",
            "51      24.964000           0.108138\n",
            "52      24.964000           0.108138\n",
            "53      24.964000           0.108138\n",
            "54      24.964000           0.108138\n",
            "55      24.964000           0.108138\n",
            "56      24.964000           0.108138\n",
            "57      24.964000           0.108138\n",
            "58      23.752000           0.524370\n",
            "59      23.752000           0.524370\n",
            "60      23.752000           0.524370\n",
            "61      23.752000           0.524370\n",
            "62      23.752000           0.524370\n",
            "\n",
            "PREDICTED:\n",
            "    d18O_cel_mean  d18O_cel_variance\n",
            "0       25.455982           1.526049\n",
            "1       25.455982           1.526049\n",
            "2       25.455982           1.526049\n",
            "3       26.260670           2.765454\n",
            "4       26.260670           2.765454\n",
            "5       26.260670           2.765454\n",
            "6       26.260670           2.765454\n",
            "7       26.260670           2.765454\n",
            "8       26.260670           2.765454\n",
            "9       26.260670           2.765454\n",
            "10      26.260670           2.765454\n",
            "11      26.260670           2.765454\n",
            "12      26.260670           2.765454\n",
            "13      26.260351           2.763674\n",
            "14      26.260351           2.763674\n",
            "15      26.260351           2.763674\n",
            "16      26.260351           2.763674\n",
            "17      26.260351           2.763674\n",
            "18      26.260351           2.763674\n",
            "19      26.260351           2.763674\n",
            "20      26.260351           2.763674\n",
            "21      26.260351           2.763674\n",
            "22      26.260351           2.763674\n",
            "23      26.260351           2.763674\n",
            "24      26.260351           2.763674\n",
            "25      26.260351           2.763674\n",
            "26      26.260351           2.763674\n",
            "27      26.260351           2.763674\n",
            "28      26.260351           2.763674\n",
            "29      26.260351           2.763674\n",
            "30      26.260351           2.763674\n",
            "31      26.260351           2.763674\n",
            "32      26.260351           2.763674\n",
            "33      26.260351           2.763674\n",
            "34      26.260351           2.763674\n",
            "35      26.260351           2.763674\n",
            "36      26.260351           2.763674\n",
            "37      26.260351           2.763674\n",
            "38      26.260351           2.763674\n",
            "39      26.260351           2.763674\n",
            "40      26.260351           2.763674\n",
            "41      26.260351           2.763674\n",
            "42      26.260351           2.763674\n",
            "43      26.260351           2.763674\n",
            "44      26.260351           2.763674\n",
            "45      26.260351           2.763674\n",
            "46      26.260351           2.763674\n",
            "47      26.260351           2.763674\n",
            "48      24.356632           2.800734\n",
            "49      24.356632           2.800734\n",
            "50      24.356632           2.800734\n",
            "51      24.356632           2.800734\n",
            "52      24.356632           2.800734\n",
            "53      24.356632           2.800734\n",
            "54      24.356632           2.800734\n",
            "55      24.356632           2.800734\n",
            "56      24.356632           2.800734\n",
            "57      24.356632           2.800734\n",
            "58      25.118982           1.666644\n",
            "59      25.118982           1.666644\n",
            "60      25.118982           1.666644\n",
            "61      25.118982           1.666644\n",
            "62      25.118982           1.666644\n",
            "    d18O_cel_mean  d18O_cel_variance\n",
            "0       25.701136           1.171127\n",
            "1       25.701136           1.171127\n",
            "2       25.701136           1.171127\n",
            "3       25.701136           1.171127\n",
            "4       25.701136           1.171127\n",
            "..            ...                ...\n",
            "57      26.663818           0.574594\n",
            "58      26.663818           0.574594\n",
            "59      26.663818           0.574594\n",
            "60      26.663818           0.574594\n",
            "61      26.663818           0.574594\n",
            "\n",
            "[62 rows x 2 columns]\n",
            "[[25.920929   2.6107845]\n",
            " [25.920929   2.6107845]\n",
            " [25.920929   2.6107845]\n",
            " [25.920929   2.6107845]\n",
            " [25.920929   2.6107845]\n",
            " [25.920929   2.6107845]\n",
            " [25.920929   2.6107845]\n",
            " [25.920929   2.6107845]\n",
            " [25.920929   2.6107845]\n",
            " [25.455982   1.5260487]\n",
            " [25.455982   1.5260487]\n",
            " [25.455982   1.5260487]\n",
            " [25.455982   1.5260487]\n",
            " [25.455982   1.5260487]\n",
            " [25.455982   1.5260487]\n",
            " [25.455982   1.5260487]\n",
            " [25.455982   1.5260487]\n",
            " [25.455982   1.5260487]\n",
            " [25.455982   1.5260487]\n",
            " [25.455982   1.5260487]\n",
            " [25.455982   1.5260487]\n",
            " [25.455982   1.5260487]\n",
            " [25.455982   1.5260487]\n",
            " [25.455982   1.5260487]\n",
            " [25.455982   1.5260487]\n",
            " [25.455982   1.5260487]\n",
            " [25.455982   1.5260487]\n",
            " [25.455982   1.5260487]\n",
            " [25.455982   1.5260487]\n",
            " [25.455982   1.5260487]\n",
            " [25.455982   1.5260487]\n",
            " [25.455982   1.5260487]\n",
            " [25.455982   1.5260487]\n",
            " [25.455982   1.5260487]\n",
            " [25.455982   1.5260487]\n",
            " [25.455982   1.5260487]\n",
            " [25.455982   1.5260487]\n",
            " [25.455982   1.5260487]\n",
            " [25.455982   1.5260487]\n",
            " [25.455982   1.5260487]\n",
            " [25.455982   1.5260487]\n",
            " [25.455982   1.5260487]\n",
            " [25.455982   1.5260487]\n",
            " [25.455982   1.5260487]\n",
            " [25.455982   1.5260487]\n",
            " [25.455982   1.5260487]\n",
            " [25.455982   1.5260487]\n",
            " [25.455982   1.5260487]\n",
            " [25.455982   1.5260487]\n",
            " [25.455982   1.5260487]\n",
            " [25.455982   1.5260487]\n",
            " [25.455982   1.5260487]\n",
            " [25.455982   1.5260487]\n",
            " [25.455982   1.5260487]\n",
            " [25.455982   1.5260487]\n",
            " [25.455982   1.5260487]\n",
            " [25.455982   1.5260487]\n",
            " [25.455982   1.5260487]\n",
            " [25.455982   1.5260487]\n",
            " [25.455982   1.5260487]\n",
            " [25.455982   1.5260487]\n",
            " [25.455982   1.5260487]]\n",
            "RMSE: 1.0487845295546343\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2023-07-20 20:42:49.914360: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype double and shape [63,12]\n",
            "\t [[{{node Placeholder/_0}}]]\n",
            "2023-07-20 20:42:49.962977: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype double and shape [62,12]\n",
            "\t [[{{node Placeholder/_0}}]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2) Ungrouped, fixed"
      ],
      "metadata": {
        "id": "yIQGGzsIup_d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ungrouped_fixed = {\n",
        "    'TRAIN' : os.path.join(FP_ROOT, \"amazon_sample_data/uc_davis_2023_08_12_train_fixed_ungrouped.csv\"),\n",
        "    'TEST' : os.path.join(FP_ROOT, \"amazon_sample_data/uc_davis_2023_08_12_test_fixed_ungrouped.csv\"),\n",
        "    'VALIDATION' : os.path.join(FP_ROOT, \"amazon_sample_data/uc_davis_2023_08_12_validation_fixed_ungrouped.csv\"),\n",
        "}\n",
        "\n",
        "ungrouped_fixed_scaled = load_and_scale(ungrouped_fixed)\n",
        "train_and_evaluate(ungrouped_fixed_scaled, \"ungrouped_fixed\", training_batch_size=3)"
      ],
      "metadata": {
        "id": "-TkJGJ9Xux24",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "12b511e2-7e10-48eb-f4cf-d68633efceef"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================\n",
            "ungrouped_fixed\n",
            "Model: \"model_5\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_6 (InputLayer)           [(None, 12)]         0           []                               \n",
            "                                                                                                  \n",
            " dense_10 (Dense)               (None, 20)           260         ['input_6[0][0]']                \n",
            "                                                                                                  \n",
            " dense_11 (Dense)               (None, 20)           420         ['dense_10[0][0]']               \n",
            "                                                                                                  \n",
            " var_output (Dense)             (None, 1)            21          ['dense_11[0][0]']               \n",
            "                                                                                                  \n",
            " mean_output (Dense)            (None, 1)            21          ['dense_11[0][0]']               \n",
            "                                                                                                  \n",
            " tf.math.multiply_11 (TFOpLambd  (None, 1)           0           ['var_output[0][0]']             \n",
            " a)                                                                                               \n",
            "                                                                                                  \n",
            " tf.math.multiply_10 (TFOpLambd  (None, 1)           0           ['mean_output[0][0]']            \n",
            " a)                                                                                               \n",
            "                                                                                                  \n",
            " tf.__operators__.add_11 (TFOpL  (None, 1)           0           ['tf.math.multiply_11[0][0]']    \n",
            " ambda)                                                                                           \n",
            "                                                                                                  \n",
            " tf.__operators__.add_10 (TFOpL  (None, 1)           0           ['tf.math.multiply_10[0][0]']    \n",
            " ambda)                                                                                           \n",
            "                                                                                                  \n",
            " lambda_5 (Lambda)              (None, 1)            0           ['tf.__operators__.add_11[0][0]']\n",
            "                                                                                                  \n",
            " concatenate_5 (Concatenate)    (None, 2)            0           ['tf.__operators__.add_10[0][0]',\n",
            "                                                                  'lambda_5[0][0]']               \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 722\n",
            "Trainable params: 722\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/5000\n",
            "113/113 [==============================] - 1s 3ms/step - loss: 80.3548 - val_loss: 16.4458\n",
            "Epoch 2/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 70.1936 - val_loss: 16.0258\n",
            "Epoch 3/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 63.0194 - val_loss: 15.6056\n",
            "Epoch 4/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 57.6400 - val_loss: 15.2960\n",
            "Epoch 5/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 53.4223 - val_loss: 15.0314\n",
            "Epoch 6/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 49.8727 - val_loss: 14.7396\n",
            "Epoch 7/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 46.9347 - val_loss: 14.5106\n",
            "Epoch 8/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 44.4245 - val_loss: 14.2919\n",
            "Epoch 9/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 42.1981 - val_loss: 14.0864\n",
            "Epoch 10/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 40.2514 - val_loss: 13.8938\n",
            "Epoch 11/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 38.5086 - val_loss: 13.6671\n",
            "Epoch 12/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 36.9391 - val_loss: 13.5127\n",
            "Epoch 13/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 35.4740 - val_loss: 13.3149\n",
            "Epoch 14/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 34.1789 - val_loss: 13.1638\n",
            "Epoch 15/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 32.9871 - val_loss: 12.9990\n",
            "Epoch 16/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 31.8843 - val_loss: 12.8407\n",
            "Epoch 17/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 30.8526 - val_loss: 12.7065\n",
            "Epoch 18/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 29.9035 - val_loss: 12.5638\n",
            "Epoch 19/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 28.9919 - val_loss: 12.4092\n",
            "Epoch 20/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 28.1449 - val_loss: 12.2580\n",
            "Epoch 21/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 27.3368 - val_loss: 12.1498\n",
            "Epoch 22/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 26.5829 - val_loss: 12.0161\n",
            "Epoch 23/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 25.8550 - val_loss: 11.8935\n",
            "Epoch 24/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 25.1567 - val_loss: 11.7795\n",
            "Epoch 25/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 24.4930 - val_loss: 11.6523\n",
            "Epoch 26/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 23.8587 - val_loss: 11.5294\n",
            "Epoch 27/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 23.2509 - val_loss: 11.4069\n",
            "Epoch 28/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 22.6659 - val_loss: 11.2832\n",
            "Epoch 29/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 22.1171 - val_loss: 11.1683\n",
            "Epoch 30/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 21.5939 - val_loss: 11.0529\n",
            "Epoch 31/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 21.0901 - val_loss: 10.9363\n",
            "Epoch 32/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 20.5982 - val_loss: 10.8307\n",
            "Epoch 33/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 20.1310 - val_loss: 10.7252\n",
            "Epoch 34/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 19.6692 - val_loss: 10.6289\n",
            "Epoch 35/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 19.2282 - val_loss: 10.5227\n",
            "Epoch 36/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 18.8054 - val_loss: 10.4125\n",
            "Epoch 37/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 18.3996 - val_loss: 10.3020\n",
            "Epoch 38/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 18.0033 - val_loss: 10.2051\n",
            "Epoch 39/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 17.6106 - val_loss: 10.1191\n",
            "Epoch 40/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 17.1806 - val_loss: 10.0308\n",
            "Epoch 41/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 16.7912 - val_loss: 9.9346\n",
            "Epoch 42/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 16.4232 - val_loss: 9.8410\n",
            "Epoch 43/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 16.0650 - val_loss: 9.7316\n",
            "Epoch 44/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 15.7253 - val_loss: 9.6269\n",
            "Epoch 45/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 15.3960 - val_loss: 9.5106\n",
            "Epoch 46/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 15.0776 - val_loss: 9.4066\n",
            "Epoch 47/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 14.7771 - val_loss: 9.2882\n",
            "Epoch 48/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 14.4848 - val_loss: 9.1718\n",
            "Epoch 49/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 14.1992 - val_loss: 9.0621\n",
            "Epoch 50/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 13.9208 - val_loss: 8.9470\n",
            "Epoch 51/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 13.6484 - val_loss: 8.8429\n",
            "Epoch 52/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 13.3863 - val_loss: 8.7408\n",
            "Epoch 53/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 13.1302 - val_loss: 8.6383\n",
            "Epoch 54/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 12.8702 - val_loss: 8.5318\n",
            "Epoch 55/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 12.4880 - val_loss: 8.4347\n",
            "Epoch 56/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 12.1602 - val_loss: 8.3106\n",
            "Epoch 57/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 11.8784 - val_loss: 8.1893\n",
            "Epoch 58/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 11.5992 - val_loss: 8.0559\n",
            "Epoch 59/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 11.3418 - val_loss: 7.9433\n",
            "Epoch 60/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 11.0977 - val_loss: 7.8195\n",
            "Epoch 61/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 10.8655 - val_loss: 7.7006\n",
            "Epoch 62/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 10.6464 - val_loss: 7.5844\n",
            "Epoch 63/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 10.4369 - val_loss: 7.4542\n",
            "Epoch 64/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 10.2366 - val_loss: 7.3577\n",
            "Epoch 65/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 10.0415 - val_loss: 7.2416\n",
            "Epoch 66/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 9.8566 - val_loss: 7.1268\n",
            "Epoch 67/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 9.6756 - val_loss: 7.0243\n",
            "Epoch 68/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 9.4988 - val_loss: 6.9192\n",
            "Epoch 69/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 9.3288 - val_loss: 6.8192\n",
            "Epoch 70/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 9.1647 - val_loss: 6.7247\n",
            "Epoch 71/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 9.0057 - val_loss: 6.6565\n",
            "Epoch 72/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 8.8505 - val_loss: 6.5860\n",
            "Epoch 73/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 8.7004 - val_loss: 6.5174\n",
            "Epoch 74/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 8.5572 - val_loss: 6.4561\n",
            "Epoch 75/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 8.4223 - val_loss: 6.3911\n",
            "Epoch 76/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 8.2889 - val_loss: 6.3319\n",
            "Epoch 77/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 8.1586 - val_loss: 6.2760\n",
            "Epoch 78/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 8.0278 - val_loss: 6.2175\n",
            "Epoch 79/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 7.8988 - val_loss: 6.1441\n",
            "Epoch 80/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 7.7746 - val_loss: 6.0831\n",
            "Epoch 81/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 7.6541 - val_loss: 6.0197\n",
            "Epoch 82/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 7.5349 - val_loss: 5.9516\n",
            "Epoch 83/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 7.4190 - val_loss: 5.8890\n",
            "Epoch 84/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 7.3017 - val_loss: 5.8285\n",
            "Epoch 85/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 7.1890 - val_loss: 5.7664\n",
            "Epoch 86/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 7.0760 - val_loss: 5.7002\n",
            "Epoch 87/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 6.9648 - val_loss: 5.6326\n",
            "Epoch 88/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 6.8567 - val_loss: 5.5631\n",
            "Epoch 89/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 6.7518 - val_loss: 5.4915\n",
            "Epoch 90/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 6.6457 - val_loss: 5.4120\n",
            "Epoch 91/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 6.5421 - val_loss: 5.3417\n",
            "Epoch 92/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 6.4421 - val_loss: 5.2689\n",
            "Epoch 93/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 6.3445 - val_loss: 5.2051\n",
            "Epoch 94/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 6.2450 - val_loss: 5.1292\n",
            "Epoch 95/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 6.1471 - val_loss: 5.0601\n",
            "Epoch 96/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 6.0472 - val_loss: 4.9955\n",
            "Epoch 97/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 5.9516 - val_loss: 4.9259\n",
            "Epoch 98/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 5.8586 - val_loss: 4.8627\n",
            "Epoch 99/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 5.7654 - val_loss: 4.7972\n",
            "Epoch 100/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 5.6754 - val_loss: 4.7303\n",
            "Epoch 101/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 5.5885 - val_loss: 4.6692\n",
            "Epoch 102/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 5.5029 - val_loss: 4.6060\n",
            "Epoch 103/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 5.4175 - val_loss: 4.5470\n",
            "Epoch 104/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 5.3349 - val_loss: 4.4816\n",
            "Epoch 105/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 5.2530 - val_loss: 4.4227\n",
            "Epoch 106/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 5.1734 - val_loss: 4.3640\n",
            "Epoch 107/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 5.0953 - val_loss: 4.3080\n",
            "Epoch 108/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 5.0195 - val_loss: 4.2477\n",
            "Epoch 109/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 4.9453 - val_loss: 4.1952\n",
            "Epoch 110/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 4.8708 - val_loss: 4.1367\n",
            "Epoch 111/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 4.7978 - val_loss: 4.0750\n",
            "Epoch 112/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 4.7269 - val_loss: 4.0222\n",
            "Epoch 113/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 4.6576 - val_loss: 3.9623\n",
            "Epoch 114/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 4.5900 - val_loss: 3.9040\n",
            "Epoch 115/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 4.5237 - val_loss: 3.8517\n",
            "Epoch 116/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 4.4580 - val_loss: 3.7998\n",
            "Epoch 117/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 4.3940 - val_loss: 3.7453\n",
            "Epoch 118/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 4.3307 - val_loss: 3.6911\n",
            "Epoch 119/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 4.2679 - val_loss: 3.6392\n",
            "Epoch 120/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 4.2065 - val_loss: 3.5886\n",
            "Epoch 121/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 4.1461 - val_loss: 3.5327\n",
            "Epoch 122/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 4.0860 - val_loss: 3.4816\n",
            "Epoch 123/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 4.0271 - val_loss: 3.4303\n",
            "Epoch 124/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 3.9688 - val_loss: 3.3797\n",
            "Epoch 125/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 3.9119 - val_loss: 3.3278\n",
            "Epoch 126/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 3.8543 - val_loss: 3.2695\n",
            "Epoch 127/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 3.7950 - val_loss: 3.2138\n",
            "Epoch 128/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 3.7389 - val_loss: 3.1670\n",
            "Epoch 129/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 3.6838 - val_loss: 3.1155\n",
            "Epoch 130/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 3.6297 - val_loss: 3.0705\n",
            "Epoch 131/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 3.5759 - val_loss: 3.0172\n",
            "Epoch 132/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 3.5076 - val_loss: 2.9659\n",
            "Epoch 133/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 3.4416 - val_loss: 2.9155\n",
            "Epoch 134/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 3.3808 - val_loss: 2.8696\n",
            "Epoch 135/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 3.3243 - val_loss: 2.8226\n",
            "Epoch 136/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 3.2698 - val_loss: 2.7750\n",
            "Epoch 137/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 3.2179 - val_loss: 2.7329\n",
            "Epoch 138/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 3.1671 - val_loss: 2.6917\n",
            "Epoch 139/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 3.1185 - val_loss: 2.6480\n",
            "Epoch 140/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 3.0699 - val_loss: 2.6068\n",
            "Epoch 141/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 3.0227 - val_loss: 2.5705\n",
            "Epoch 142/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 2.9761 - val_loss: 2.5283\n",
            "Epoch 143/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 2.9310 - val_loss: 2.4940\n",
            "Epoch 144/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 2.8870 - val_loss: 2.4558\n",
            "Epoch 145/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 2.8442 - val_loss: 2.4200\n",
            "Epoch 146/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 2.8022 - val_loss: 2.3853\n",
            "Epoch 147/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 2.7599 - val_loss: 2.3500\n",
            "Epoch 148/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 2.7193 - val_loss: 2.3111\n",
            "Epoch 149/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 2.6793 - val_loss: 2.2803\n",
            "Epoch 150/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 2.6401 - val_loss: 2.2447\n",
            "Epoch 151/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 2.6020 - val_loss: 2.2088\n",
            "Epoch 152/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 2.5641 - val_loss: 2.1786\n",
            "Epoch 153/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 2.5263 - val_loss: 2.1438\n",
            "Epoch 154/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 2.4891 - val_loss: 2.1111\n",
            "Epoch 155/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 2.4527 - val_loss: 2.0780\n",
            "Epoch 156/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 2.4172 - val_loss: 2.0443\n",
            "Epoch 157/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 2.3825 - val_loss: 2.0124\n",
            "Epoch 158/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 2.3479 - val_loss: 1.9785\n",
            "Epoch 159/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 2.3147 - val_loss: 1.9461\n",
            "Epoch 160/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 2.2815 - val_loss: 1.9165\n",
            "Epoch 161/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 2.2492 - val_loss: 1.8858\n",
            "Epoch 162/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 2.2179 - val_loss: 1.8554\n",
            "Epoch 163/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 2.1879 - val_loss: 1.8276\n",
            "Epoch 164/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 2.1583 - val_loss: 1.7978\n",
            "Epoch 165/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 2.1294 - val_loss: 1.7678\n",
            "Epoch 166/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 2.1005 - val_loss: 1.7399\n",
            "Epoch 167/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 2.0717 - val_loss: 1.7138\n",
            "Epoch 168/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 2.0436 - val_loss: 1.6867\n",
            "Epoch 169/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 2.0161 - val_loss: 1.6597\n",
            "Epoch 170/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 1.9893 - val_loss: 1.6321\n",
            "Epoch 171/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 1.9622 - val_loss: 1.6044\n",
            "Epoch 172/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 1.9362 - val_loss: 1.5756\n",
            "Epoch 173/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 1.9104 - val_loss: 1.5515\n",
            "Epoch 174/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 1.8851 - val_loss: 1.5272\n",
            "Epoch 175/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 1.8604 - val_loss: 1.5009\n",
            "Epoch 176/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 1.8359 - val_loss: 1.4758\n",
            "Epoch 177/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 1.8118 - val_loss: 1.4511\n",
            "Epoch 178/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 1.7879 - val_loss: 1.4275\n",
            "Epoch 179/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 1.7644 - val_loss: 1.4041\n",
            "Epoch 180/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 1.7406 - val_loss: 1.3785\n",
            "Epoch 181/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 1.7181 - val_loss: 1.3540\n",
            "Epoch 182/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 1.6959 - val_loss: 1.3327\n",
            "Epoch 183/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 1.6747 - val_loss: 1.3102\n",
            "Epoch 184/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 1.6534 - val_loss: 1.2883\n",
            "Epoch 185/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 1.6326 - val_loss: 1.2676\n",
            "Epoch 186/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 1.6114 - val_loss: 1.2456\n",
            "Epoch 187/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 1.5911 - val_loss: 1.2252\n",
            "Epoch 188/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 1.5716 - val_loss: 1.2051\n",
            "Epoch 189/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 1.5524 - val_loss: 1.1858\n",
            "Epoch 190/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 1.5335 - val_loss: 1.1673\n",
            "Epoch 191/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 1.5147 - val_loss: 1.1476\n",
            "Epoch 192/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 1.4962 - val_loss: 1.1299\n",
            "Epoch 193/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 1.4782 - val_loss: 1.1110\n",
            "Epoch 194/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 1.4603 - val_loss: 1.0946\n",
            "Epoch 195/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 1.4427 - val_loss: 1.0773\n",
            "Epoch 196/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 1.4253 - val_loss: 1.0601\n",
            "Epoch 197/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 1.4084 - val_loss: 1.0440\n",
            "Epoch 198/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 1.3916 - val_loss: 1.0285\n",
            "Epoch 199/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 1.3752 - val_loss: 1.0128\n",
            "Epoch 200/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 1.3589 - val_loss: 0.9971\n",
            "Epoch 201/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 1.3429 - val_loss: 0.9817\n",
            "Epoch 202/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 1.3271 - val_loss: 0.9670\n",
            "Epoch 203/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 1.3115 - val_loss: 0.9515\n",
            "Epoch 204/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 1.2963 - val_loss: 0.9377\n",
            "Epoch 205/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 1.2812 - val_loss: 0.9228\n",
            "Epoch 206/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 1.2663 - val_loss: 0.9087\n",
            "Epoch 207/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 1.2518 - val_loss: 0.8943\n",
            "Epoch 208/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 1.2374 - val_loss: 0.8800\n",
            "Epoch 209/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 1.2230 - val_loss: 0.8669\n",
            "Epoch 210/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 1.2090 - val_loss: 0.8528\n",
            "Epoch 211/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 1.1953 - val_loss: 0.8400\n",
            "Epoch 212/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 1.1815 - val_loss: 0.8291\n",
            "Epoch 213/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 1.1679 - val_loss: 0.8147\n",
            "Epoch 214/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 1.1548 - val_loss: 0.8031\n",
            "Epoch 215/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 1.1417 - val_loss: 0.7898\n",
            "Epoch 216/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 1.1289 - val_loss: 0.7775\n",
            "Epoch 217/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 1.1161 - val_loss: 0.7658\n",
            "Epoch 218/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 1.1030 - val_loss: 0.7533\n",
            "Epoch 219/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 1.0901 - val_loss: 0.7427\n",
            "Epoch 220/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 1.0772 - val_loss: 0.7305\n",
            "Epoch 221/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 1.0649 - val_loss: 0.7187\n",
            "Epoch 222/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 1.0530 - val_loss: 0.7083\n",
            "Epoch 223/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 1.0411 - val_loss: 0.6971\n",
            "Epoch 224/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 1.0295 - val_loss: 0.6871\n",
            "Epoch 225/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 1.0182 - val_loss: 0.6764\n",
            "Epoch 226/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 1.0069 - val_loss: 0.6662\n",
            "Epoch 227/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.9959 - val_loss: 0.6560\n",
            "Epoch 228/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.9851 - val_loss: 0.6462\n",
            "Epoch 229/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.9744 - val_loss: 0.6366\n",
            "Epoch 230/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.9639 - val_loss: 0.6275\n",
            "Epoch 231/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.9535 - val_loss: 0.6183\n",
            "Epoch 232/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.9433 - val_loss: 0.6080\n",
            "Epoch 233/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.9332 - val_loss: 0.5999\n",
            "Epoch 234/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.9234 - val_loss: 0.5914\n",
            "Epoch 235/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.9137 - val_loss: 0.5821\n",
            "Epoch 236/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.9041 - val_loss: 0.5740\n",
            "Epoch 237/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.8948 - val_loss: 0.5657\n",
            "Epoch 238/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.8855 - val_loss: 0.5576\n",
            "Epoch 239/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.8764 - val_loss: 0.5501\n",
            "Epoch 240/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.8675 - val_loss: 0.5413\n",
            "Epoch 241/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.8584 - val_loss: 0.5345\n",
            "Epoch 242/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.8498 - val_loss: 0.5262\n",
            "Epoch 243/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.8413 - val_loss: 0.5194\n",
            "Epoch 244/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.8328 - val_loss: 0.5122\n",
            "Epoch 245/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.8246 - val_loss: 0.5047\n",
            "Epoch 246/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.8166 - val_loss: 0.4984\n",
            "Epoch 247/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.8086 - val_loss: 0.4913\n",
            "Epoch 248/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.8008 - val_loss: 0.4849\n",
            "Epoch 249/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.7931 - val_loss: 0.4785\n",
            "Epoch 250/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.7854 - val_loss: 0.4718\n",
            "Epoch 251/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.7779 - val_loss: 0.4664\n",
            "Epoch 252/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.7705 - val_loss: 0.4601\n",
            "Epoch 253/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.7630 - val_loss: 0.4535\n",
            "Epoch 254/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.7558 - val_loss: 0.4481\n",
            "Epoch 255/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.7488 - val_loss: 0.4422\n",
            "Epoch 256/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.7417 - val_loss: 0.4368\n",
            "Epoch 257/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.7348 - val_loss: 0.4317\n",
            "Epoch 258/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.7281 - val_loss: 0.4264\n",
            "Epoch 259/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.7214 - val_loss: 0.4216\n",
            "Epoch 260/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.7148 - val_loss: 0.4166\n",
            "Epoch 261/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.7083 - val_loss: 0.4116\n",
            "Epoch 262/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.7019 - val_loss: 0.4067\n",
            "Epoch 263/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.6958 - val_loss: 0.4022\n",
            "Epoch 264/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.3974\n",
            "Epoch 265/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.6839 - val_loss: 0.3936\n",
            "Epoch 266/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.6780 - val_loss: 0.3898\n",
            "Epoch 267/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.6723 - val_loss: 0.3859\n",
            "Epoch 268/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.6666 - val_loss: 0.3824\n",
            "Epoch 269/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.6611 - val_loss: 0.3785\n",
            "Epoch 270/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.6556 - val_loss: 0.3750\n",
            "Epoch 271/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.6502 - val_loss: 0.3716\n",
            "Epoch 272/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.6449 - val_loss: 0.3683\n",
            "Epoch 273/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.6397 - val_loss: 0.3654\n",
            "Epoch 274/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.6346 - val_loss: 0.3626\n",
            "Epoch 275/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.6297 - val_loss: 0.3595\n",
            "Epoch 276/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.6248 - val_loss: 0.3565\n",
            "Epoch 277/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.6199 - val_loss: 0.3542\n",
            "Epoch 278/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.3514\n",
            "Epoch 279/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.6104 - val_loss: 0.3486\n",
            "Epoch 280/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.6058 - val_loss: 0.3461\n",
            "Epoch 281/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.6012 - val_loss: 0.3435\n",
            "Epoch 282/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.5965 - val_loss: 0.3407\n",
            "Epoch 283/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.5920 - val_loss: 0.3386\n",
            "Epoch 284/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.5876 - val_loss: 0.3359\n",
            "Epoch 285/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.5833 - val_loss: 0.3337\n",
            "Epoch 286/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.5790 - val_loss: 0.3320\n",
            "Epoch 287/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.5746 - val_loss: 0.3292\n",
            "Epoch 288/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.5704 - val_loss: 0.3274\n",
            "Epoch 289/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.5663 - val_loss: 0.3255\n",
            "Epoch 290/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.5623 - val_loss: 0.3233\n",
            "Epoch 291/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.5583 - val_loss: 0.3218\n",
            "Epoch 292/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.5545 - val_loss: 0.3198\n",
            "Epoch 293/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.5506 - val_loss: 0.3184\n",
            "Epoch 294/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.5469 - val_loss: 0.3168\n",
            "Epoch 295/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.5431 - val_loss: 0.3151\n",
            "Epoch 296/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.5394 - val_loss: 0.3134\n",
            "Epoch 297/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.5358 - val_loss: 0.3123\n",
            "Epoch 298/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.5321 - val_loss: 0.3105\n",
            "Epoch 299/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.5285 - val_loss: 0.3093\n",
            "Epoch 300/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.5251 - val_loss: 0.3079\n",
            "Epoch 301/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.5217 - val_loss: 0.3065\n",
            "Epoch 302/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.5183 - val_loss: 0.3051\n",
            "Epoch 303/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.5150 - val_loss: 0.3042\n",
            "Epoch 304/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.5118 - val_loss: 0.3029\n",
            "Epoch 305/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.5086 - val_loss: 0.3021\n",
            "Epoch 306/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.5053 - val_loss: 0.3012\n",
            "Epoch 307/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.5022 - val_loss: 0.2998\n",
            "Epoch 308/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.4990 - val_loss: 0.2992\n",
            "Epoch 309/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.4960 - val_loss: 0.2981\n",
            "Epoch 310/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.4930 - val_loss: 0.2973\n",
            "Epoch 311/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.4900 - val_loss: 0.2965\n",
            "Epoch 312/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.4871 - val_loss: 0.2956\n",
            "Epoch 313/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.4843 - val_loss: 0.2948\n",
            "Epoch 314/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.4815 - val_loss: 0.2942\n",
            "Epoch 315/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.4788 - val_loss: 0.2935\n",
            "Epoch 316/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.4761 - val_loss: 0.2928\n",
            "Epoch 317/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.4735 - val_loss: 0.2923\n",
            "Epoch 318/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.4709 - val_loss: 0.2917\n",
            "Epoch 319/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.4684 - val_loss: 0.2915\n",
            "Epoch 320/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.4659 - val_loss: 0.2911\n",
            "Epoch 321/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.4634 - val_loss: 0.2907\n",
            "Epoch 322/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.4610 - val_loss: 0.2902\n",
            "Epoch 323/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.4586 - val_loss: 0.2902\n",
            "Epoch 324/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.4563 - val_loss: 0.2896\n",
            "Epoch 325/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.4539 - val_loss: 0.2894\n",
            "Epoch 326/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.4517 - val_loss: 0.2892\n",
            "Epoch 327/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.4493 - val_loss: 0.2890\n",
            "Epoch 328/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.4470 - val_loss: 0.2886\n",
            "Epoch 329/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.4448 - val_loss: 0.2883\n",
            "Epoch 330/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.4426 - val_loss: 0.2883\n",
            "Epoch 331/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.4405 - val_loss: 0.2882\n",
            "Epoch 332/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.4384 - val_loss: 0.2881\n",
            "Epoch 333/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.4363 - val_loss: 0.2880\n",
            "Epoch 334/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.4343 - val_loss: 0.2880\n",
            "Epoch 335/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.4323 - val_loss: 0.2881\n",
            "Epoch 336/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.4303 - val_loss: 0.2881\n",
            "Epoch 337/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.4283 - val_loss: 0.2880\n",
            "Epoch 338/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.4264 - val_loss: 0.2881\n",
            "Epoch 339/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.4245 - val_loss: 0.2880\n",
            "Epoch 340/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.4226 - val_loss: 0.2882\n",
            "Epoch 341/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.4208 - val_loss: 0.2882\n",
            "Epoch 342/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.4189 - val_loss: 0.2884\n",
            "Epoch 343/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.4171 - val_loss: 0.2885\n",
            "Epoch 344/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.4153 - val_loss: 0.2886\n",
            "Epoch 345/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.4136 - val_loss: 0.2887\n",
            "Epoch 346/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.4119 - val_loss: 0.2889\n",
            "Epoch 347/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.4102 - val_loss: 0.2890\n",
            "Epoch 348/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.4086 - val_loss: 0.2891\n",
            "Epoch 349/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.4069 - val_loss: 0.2893\n",
            "Epoch 350/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.4053 - val_loss: 0.2897\n",
            "Epoch 351/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.4037 - val_loss: 0.2898\n",
            "Epoch 352/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.4021 - val_loss: 0.2901\n",
            "Epoch 353/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.4006 - val_loss: 0.2904\n",
            "Epoch 354/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3991 - val_loss: 0.2906\n",
            "Epoch 355/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3976 - val_loss: 0.2908\n",
            "Epoch 356/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3961 - val_loss: 0.2911\n",
            "Epoch 357/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3946 - val_loss: 0.2914\n",
            "Epoch 358/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3932 - val_loss: 0.2917\n",
            "Epoch 359/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3918 - val_loss: 0.2920\n",
            "Epoch 360/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3904 - val_loss: 0.2921\n",
            "Epoch 361/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3890 - val_loss: 0.2926\n",
            "Epoch 362/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3876 - val_loss: 0.2929\n",
            "Epoch 363/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3863 - val_loss: 0.2932\n",
            "Epoch 364/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3850 - val_loss: 0.2935\n",
            "Epoch 365/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3837 - val_loss: 0.2938\n",
            "Epoch 366/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3825 - val_loss: 0.2941\n",
            "Epoch 367/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3812 - val_loss: 0.2945\n",
            "Epoch 368/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3800 - val_loss: 0.2949\n",
            "Epoch 369/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3787 - val_loss: 0.2951\n",
            "Epoch 370/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3776 - val_loss: 0.2955\n",
            "Epoch 371/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3764 - val_loss: 0.2959\n",
            "Epoch 372/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3752 - val_loss: 0.2963\n",
            "Epoch 373/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3741 - val_loss: 0.2966\n",
            "Epoch 374/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3730 - val_loss: 0.2970\n",
            "Epoch 375/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3719 - val_loss: 0.2973\n",
            "Epoch 376/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3708 - val_loss: 0.2977\n",
            "Epoch 377/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3698 - val_loss: 0.2981\n",
            "Epoch 378/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3687 - val_loss: 0.2985\n",
            "Epoch 379/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3677 - val_loss: 0.2988\n",
            "Epoch 380/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3667 - val_loss: 0.2992\n",
            "Epoch 381/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3657 - val_loss: 0.2997\n",
            "Epoch 382/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3647 - val_loss: 0.3000\n",
            "Epoch 383/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3637 - val_loss: 0.3004\n",
            "Epoch 384/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3628 - val_loss: 0.3009\n",
            "Epoch 385/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3619 - val_loss: 0.3012\n",
            "Epoch 386/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3609 - val_loss: 0.3017\n",
            "Epoch 387/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3600 - val_loss: 0.3021\n",
            "Epoch 388/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3591 - val_loss: 0.3025\n",
            "Epoch 389/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3583 - val_loss: 0.3029\n",
            "Epoch 390/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3574 - val_loss: 0.3033\n",
            "Epoch 391/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3565 - val_loss: 0.3037\n",
            "Epoch 392/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3557 - val_loss: 0.3041\n",
            "Epoch 393/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3549 - val_loss: 0.3045\n",
            "Epoch 394/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3541 - val_loss: 0.3049\n",
            "Epoch 395/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3533 - val_loss: 0.3054\n",
            "Epoch 396/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3525 - val_loss: 0.3058\n",
            "Epoch 397/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3517 - val_loss: 0.3062\n",
            "Epoch 398/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3509 - val_loss: 0.3067\n",
            "Epoch 399/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3501 - val_loss: 0.3070\n",
            "Epoch 400/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3494 - val_loss: 0.3075\n",
            "Epoch 401/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3487 - val_loss: 0.3079\n",
            "Epoch 402/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3480 - val_loss: 0.3083\n",
            "Epoch 403/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3473 - val_loss: 0.3088\n",
            "Epoch 404/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3466 - val_loss: 0.3092\n",
            "Epoch 405/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3459 - val_loss: 0.3096\n",
            "Epoch 406/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3452 - val_loss: 0.3100\n",
            "Epoch 407/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3445 - val_loss: 0.3104\n",
            "Epoch 408/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3439 - val_loss: 0.3108\n",
            "Epoch 409/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3432 - val_loss: 0.3112\n",
            "Epoch 410/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3426 - val_loss: 0.3117\n",
            "Epoch 411/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3419 - val_loss: 0.3121\n",
            "Epoch 412/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3413 - val_loss: 0.3126\n",
            "Epoch 413/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3407 - val_loss: 0.3130\n",
            "Epoch 414/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3401 - val_loss: 0.3135\n",
            "Epoch 415/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3395 - val_loss: 0.3141\n",
            "Epoch 416/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3389 - val_loss: 0.3144\n",
            "Epoch 417/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3383 - val_loss: 0.3150\n",
            "Epoch 418/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3378 - val_loss: 0.3154\n",
            "Epoch 419/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3372 - val_loss: 0.3158\n",
            "Epoch 420/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3367 - val_loss: 0.3163\n",
            "Epoch 421/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3361 - val_loss: 0.3168\n",
            "Epoch 422/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3356 - val_loss: 0.3173\n",
            "Epoch 423/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3351 - val_loss: 0.3178\n",
            "Epoch 424/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3345 - val_loss: 0.3182\n",
            "Epoch 425/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3340 - val_loss: 0.3187\n",
            "Epoch 426/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3335 - val_loss: 0.3191\n",
            "Epoch 427/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3330 - val_loss: 0.3196\n",
            "Epoch 428/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3325 - val_loss: 0.3201\n",
            "Epoch 429/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3320 - val_loss: 0.3206\n",
            "Epoch 430/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3315 - val_loss: 0.3210\n",
            "Epoch 431/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3310 - val_loss: 0.3216\n",
            "Epoch 432/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3306 - val_loss: 0.3221\n",
            "Epoch 433/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3301 - val_loss: 0.3226\n",
            "Epoch 434/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3297 - val_loss: 0.3230\n",
            "Epoch 435/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3293 - val_loss: 0.3235\n",
            "Epoch 436/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3288 - val_loss: 0.3241\n",
            "Epoch 437/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3284 - val_loss: 0.3245\n",
            "Epoch 438/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3280 - val_loss: 0.3251\n",
            "Epoch 439/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3275 - val_loss: 0.3255\n",
            "Epoch 440/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3271 - val_loss: 0.3260\n",
            "Epoch 441/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3267 - val_loss: 0.3265\n",
            "Epoch 442/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3263 - val_loss: 0.3270\n",
            "Epoch 443/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3260 - val_loss: 0.3277\n",
            "Epoch 444/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3256 - val_loss: 0.3281\n",
            "Epoch 445/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3252 - val_loss: 0.3288\n",
            "Epoch 446/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3248 - val_loss: 0.3293\n",
            "Epoch 447/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3244 - val_loss: 0.3298\n",
            "Epoch 448/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3240 - val_loss: 0.3303\n",
            "Epoch 449/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3237 - val_loss: 0.3307\n",
            "Epoch 450/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3233 - val_loss: 0.3311\n",
            "Epoch 451/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3230 - val_loss: 0.3317\n",
            "Epoch 452/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3226 - val_loss: 0.3321\n",
            "Epoch 453/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3223 - val_loss: 0.3327\n",
            "Epoch 454/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3219 - val_loss: 0.3332\n",
            "Epoch 455/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3216 - val_loss: 0.3334\n",
            "Epoch 456/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3212 - val_loss: 0.3341\n",
            "Epoch 457/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3209 - val_loss: 0.3346\n",
            "Epoch 458/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3206 - val_loss: 0.3351\n",
            "Epoch 459/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3202 - val_loss: 0.3356\n",
            "Epoch 460/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3200 - val_loss: 0.3362\n",
            "Epoch 461/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3196 - val_loss: 0.3365\n",
            "Epoch 462/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3193 - val_loss: 0.3371\n",
            "Epoch 463/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3190 - val_loss: 0.3375\n",
            "Epoch 464/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3187 - val_loss: 0.3381\n",
            "Epoch 465/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3184 - val_loss: 0.3385\n",
            "Epoch 466/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3181 - val_loss: 0.3390\n",
            "Epoch 467/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3179 - val_loss: 0.3394\n",
            "Epoch 468/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3176 - val_loss: 0.3400\n",
            "Epoch 469/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3173 - val_loss: 0.3405\n",
            "Epoch 470/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3170 - val_loss: 0.3409\n",
            "Epoch 471/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3168 - val_loss: 0.3412\n",
            "Epoch 472/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3165 - val_loss: 0.3419\n",
            "Epoch 473/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3162 - val_loss: 0.3423\n",
            "Epoch 474/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3160 - val_loss: 0.3428\n",
            "Epoch 475/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3157 - val_loss: 0.3433\n",
            "Epoch 476/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3154 - val_loss: 0.3438\n",
            "Epoch 477/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3152 - val_loss: 0.3443\n",
            "Epoch 478/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3150 - val_loss: 0.3450\n",
            "Epoch 479/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3147 - val_loss: 0.3454\n",
            "Epoch 480/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3145 - val_loss: 0.3460\n",
            "Epoch 481/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3143 - val_loss: 0.3465\n",
            "Epoch 482/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3140 - val_loss: 0.3470\n",
            "Epoch 483/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3138 - val_loss: 0.3476\n",
            "Epoch 484/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3136 - val_loss: 0.3484\n",
            "Epoch 485/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3134 - val_loss: 0.3487\n",
            "Epoch 486/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3132 - val_loss: 0.3492\n",
            "Epoch 487/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3130 - val_loss: 0.3498\n",
            "Epoch 488/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3128 - val_loss: 0.3504\n",
            "Epoch 489/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3126 - val_loss: 0.3509\n",
            "Epoch 490/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3124 - val_loss: 0.3514\n",
            "Epoch 491/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3122 - val_loss: 0.3519\n",
            "Epoch 492/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3120 - val_loss: 0.3523\n",
            "Epoch 493/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3118 - val_loss: 0.3530\n",
            "Epoch 494/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3116 - val_loss: 0.3535\n",
            "Epoch 495/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3114 - val_loss: 0.3540\n",
            "Epoch 496/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3112 - val_loss: 0.3546\n",
            "Epoch 497/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3111 - val_loss: 0.3550\n",
            "Epoch 498/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3109 - val_loss: 0.3556\n",
            "Epoch 499/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3107 - val_loss: 0.3562\n",
            "Epoch 500/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3105 - val_loss: 0.3566\n",
            "Epoch 501/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3104 - val_loss: 0.3573\n",
            "Epoch 502/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3102 - val_loss: 0.3578\n",
            "Epoch 503/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3100 - val_loss: 0.3586\n",
            "Epoch 504/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3099 - val_loss: 0.3593\n",
            "Epoch 505/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3097 - val_loss: 0.3595\n",
            "Epoch 506/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3095 - val_loss: 0.3600\n",
            "Epoch 507/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3093 - val_loss: 0.3602\n",
            "Epoch 508/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3092 - val_loss: 0.3608\n",
            "Epoch 509/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3091 - val_loss: 0.3614\n",
            "Epoch 510/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3089 - val_loss: 0.3618\n",
            "Epoch 511/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3087 - val_loss: 0.3625\n",
            "Epoch 512/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3086 - val_loss: 0.3630\n",
            "Epoch 513/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3085 - val_loss: 0.3634\n",
            "Epoch 514/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3083 - val_loss: 0.3642\n",
            "Epoch 515/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3081 - val_loss: 0.3649\n",
            "Epoch 516/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3080 - val_loss: 0.3652\n",
            "Epoch 517/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3079 - val_loss: 0.3658\n",
            "Epoch 518/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3077 - val_loss: 0.3661\n",
            "Epoch 519/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3076 - val_loss: 0.3667\n",
            "Epoch 520/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3075 - val_loss: 0.3673\n",
            "Epoch 521/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3073 - val_loss: 0.3678\n",
            "Epoch 522/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3072 - val_loss: 0.3683\n",
            "Epoch 523/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3071 - val_loss: 0.3689\n",
            "Epoch 524/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3069 - val_loss: 0.3696\n",
            "Epoch 525/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3068 - val_loss: 0.3697\n",
            "Epoch 526/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3067 - val_loss: 0.3706\n",
            "Epoch 527/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3065 - val_loss: 0.3708\n",
            "Epoch 528/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3064 - val_loss: 0.3714\n",
            "Epoch 529/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3063 - val_loss: 0.3722\n",
            "Epoch 530/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3062 - val_loss: 0.3725\n",
            "Epoch 531/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3061 - val_loss: 0.3732\n",
            "Epoch 532/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3060 - val_loss: 0.3739\n",
            "Epoch 533/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3058 - val_loss: 0.3744\n",
            "Epoch 534/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3057 - val_loss: 0.3746\n",
            "Epoch 535/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3056 - val_loss: 0.3750\n",
            "Epoch 536/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3055 - val_loss: 0.3756\n",
            "Epoch 537/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3054 - val_loss: 0.3763\n",
            "Epoch 538/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3053 - val_loss: 0.3768\n",
            "Epoch 539/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3052 - val_loss: 0.3769\n",
            "Epoch 540/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3050 - val_loss: 0.3775\n",
            "Epoch 541/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3049 - val_loss: 0.3781\n",
            "Epoch 542/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3048 - val_loss: 0.3786\n",
            "Epoch 543/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3047 - val_loss: 0.3790\n",
            "Epoch 544/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3046 - val_loss: 0.3796\n",
            "Epoch 545/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3045 - val_loss: 0.3799\n",
            "Epoch 546/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3044 - val_loss: 0.3808\n",
            "Epoch 547/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3043 - val_loss: 0.3814\n",
            "Epoch 548/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3043 - val_loss: 0.3817\n",
            "Epoch 549/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3041 - val_loss: 0.3824\n",
            "Epoch 550/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3041 - val_loss: 0.3828\n",
            "Epoch 551/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3040 - val_loss: 0.3834\n",
            "Epoch 552/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3039 - val_loss: 0.3843\n",
            "Epoch 553/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3037 - val_loss: 0.3849\n",
            "Epoch 554/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3037 - val_loss: 0.3854\n",
            "Epoch 555/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3036 - val_loss: 0.3860\n",
            "Epoch 556/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3035 - val_loss: 0.3864\n",
            "Epoch 557/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3034 - val_loss: 0.3869\n",
            "Epoch 558/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3033 - val_loss: 0.3877\n",
            "Epoch 559/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3032 - val_loss: 0.3884\n",
            "Epoch 560/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3031 - val_loss: 0.3886\n",
            "Epoch 561/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3030 - val_loss: 0.3894\n",
            "Epoch 562/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3030 - val_loss: 0.3897\n",
            "Epoch 563/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3029 - val_loss: 0.3906\n",
            "Epoch 564/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3028 - val_loss: 0.3915\n",
            "Epoch 565/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3027 - val_loss: 0.3921\n",
            "Epoch 566/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3026 - val_loss: 0.3926\n",
            "Epoch 567/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3025 - val_loss: 0.3934\n",
            "Epoch 568/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3025 - val_loss: 0.3939\n",
            "Epoch 569/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3024 - val_loss: 0.3944\n",
            "Epoch 570/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3023 - val_loss: 0.3951\n",
            "Epoch 571/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3023 - val_loss: 0.3957\n",
            "Epoch 572/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3022 - val_loss: 0.3967\n",
            "Epoch 573/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3021 - val_loss: 0.3971\n",
            "Epoch 574/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3020 - val_loss: 0.3977\n",
            "Epoch 575/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3019 - val_loss: 0.3983\n",
            "Epoch 576/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3019 - val_loss: 0.3991\n",
            "Epoch 577/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3018 - val_loss: 0.3996\n",
            "Epoch 578/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3017 - val_loss: 0.4007\n",
            "Epoch 579/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3016 - val_loss: 0.4006\n",
            "Epoch 580/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3015 - val_loss: 0.4010\n",
            "Epoch 581/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3015 - val_loss: 0.4017\n",
            "Epoch 582/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3014 - val_loss: 0.4027\n",
            "Epoch 583/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3014 - val_loss: 0.4034\n",
            "Epoch 584/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3013 - val_loss: 0.4039\n",
            "Epoch 585/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3012 - val_loss: 0.4046\n",
            "Epoch 586/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3011 - val_loss: 0.4054\n",
            "Epoch 587/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3011 - val_loss: 0.4060\n",
            "Epoch 588/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3010 - val_loss: 0.4072\n",
            "Epoch 589/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3009 - val_loss: 0.4077\n",
            "Epoch 590/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3009 - val_loss: 0.4083\n",
            "Epoch 591/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3008 - val_loss: 0.4093\n",
            "Epoch 592/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3008 - val_loss: 0.4104\n",
            "Epoch 593/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3007 - val_loss: 0.4109\n",
            "Epoch 594/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3006 - val_loss: 0.4115\n",
            "Epoch 595/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3006 - val_loss: 0.4122\n",
            "Epoch 596/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3005 - val_loss: 0.4138\n",
            "Epoch 597/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3005 - val_loss: 0.4141\n",
            "Epoch 598/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3004 - val_loss: 0.4152\n",
            "Epoch 599/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3003 - val_loss: 0.4158\n",
            "Epoch 600/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3003 - val_loss: 0.4169\n",
            "Epoch 601/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3002 - val_loss: 0.4178\n",
            "Epoch 602/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3001 - val_loss: 0.4184\n",
            "Epoch 603/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3001 - val_loss: 0.4198\n",
            "Epoch 604/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3000 - val_loss: 0.4201\n",
            "Epoch 605/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.3000 - val_loss: 0.4217\n",
            "Epoch 606/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2999 - val_loss: 0.4227\n",
            "Epoch 607/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2999 - val_loss: 0.4232\n",
            "Epoch 608/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2998 - val_loss: 0.4243\n",
            "Epoch 609/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2998 - val_loss: 0.4250\n",
            "Epoch 610/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2997 - val_loss: 0.4260\n",
            "Epoch 611/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2996 - val_loss: 0.4269\n",
            "Epoch 612/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2996 - val_loss: 0.4274\n",
            "Epoch 613/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2995 - val_loss: 0.4280\n",
            "Epoch 614/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2995 - val_loss: 0.4292\n",
            "Epoch 615/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2994 - val_loss: 0.4304\n",
            "Epoch 616/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2994 - val_loss: 0.4312\n",
            "Epoch 617/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2993 - val_loss: 0.4321\n",
            "Epoch 618/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2992 - val_loss: 0.4331\n",
            "Epoch 619/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2992 - val_loss: 0.4342\n",
            "Epoch 620/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2992 - val_loss: 0.4353\n",
            "Epoch 621/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2991 - val_loss: 0.4365\n",
            "Epoch 622/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2990 - val_loss: 0.4377\n",
            "Epoch 623/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2990 - val_loss: 0.4384\n",
            "Epoch 624/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2989 - val_loss: 0.4396\n",
            "Epoch 625/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2989 - val_loss: 0.4403\n",
            "Epoch 626/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2988 - val_loss: 0.4412\n",
            "Epoch 627/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2988 - val_loss: 0.4422\n",
            "Epoch 628/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2987 - val_loss: 0.4432\n",
            "Epoch 629/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2987 - val_loss: 0.4452\n",
            "Epoch 630/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2986 - val_loss: 0.4451\n",
            "Epoch 631/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2986 - val_loss: 0.4466\n",
            "Epoch 632/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2986 - val_loss: 0.4482\n",
            "Epoch 633/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2985 - val_loss: 0.4489\n",
            "Epoch 634/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2984 - val_loss: 0.4501\n",
            "Epoch 635/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2984 - val_loss: 0.4512\n",
            "Epoch 636/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2984 - val_loss: 0.4518\n",
            "Epoch 637/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2983 - val_loss: 0.4530\n",
            "Epoch 638/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2982 - val_loss: 0.4544\n",
            "Epoch 639/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2982 - val_loss: 0.4558\n",
            "Epoch 640/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2982 - val_loss: 0.4574\n",
            "Epoch 641/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2981 - val_loss: 0.4585\n",
            "Epoch 642/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2981 - val_loss: 0.4588\n",
            "Epoch 643/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2980 - val_loss: 0.4605\n",
            "Epoch 644/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2980 - val_loss: 0.4615\n",
            "Epoch 645/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2979 - val_loss: 0.4627\n",
            "Epoch 646/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2979 - val_loss: 0.4642\n",
            "Epoch 647/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2978 - val_loss: 0.4655\n",
            "Epoch 648/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2978 - val_loss: 0.4667\n",
            "Epoch 649/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2977 - val_loss: 0.4679\n",
            "Epoch 650/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2977 - val_loss: 0.4684\n",
            "Epoch 651/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2976 - val_loss: 0.4695\n",
            "Epoch 652/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2976 - val_loss: 0.4708\n",
            "Epoch 653/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2976 - val_loss: 0.4723\n",
            "Epoch 654/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2975 - val_loss: 0.4731\n",
            "Epoch 655/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2975 - val_loss: 0.4748\n",
            "Epoch 656/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2974 - val_loss: 0.4754\n",
            "Epoch 657/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2974 - val_loss: 0.4767\n",
            "Epoch 658/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2973 - val_loss: 0.4782\n",
            "Epoch 659/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2973 - val_loss: 0.4795\n",
            "Epoch 660/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2972 - val_loss: 0.4805\n",
            "Epoch 661/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2972 - val_loss: 0.4822\n",
            "Epoch 662/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2972 - val_loss: 0.4836\n",
            "Epoch 663/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2971 - val_loss: 0.4850\n",
            "Epoch 664/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2971 - val_loss: 0.4864\n",
            "Epoch 665/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2970 - val_loss: 0.4880\n",
            "Epoch 666/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2970 - val_loss: 0.4888\n",
            "Epoch 667/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2969 - val_loss: 0.4900\n",
            "Epoch 668/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2969 - val_loss: 0.4917\n",
            "Epoch 669/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2968 - val_loss: 0.4931\n",
            "Epoch 670/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2968 - val_loss: 0.4944\n",
            "Epoch 671/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2967 - val_loss: 0.4955\n",
            "Epoch 672/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2967 - val_loss: 0.4959\n",
            "Epoch 673/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2967 - val_loss: 0.4986\n",
            "Epoch 674/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2966 - val_loss: 0.4994\n",
            "Epoch 675/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2966 - val_loss: 0.5003\n",
            "Epoch 676/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2965 - val_loss: 0.5024\n",
            "Epoch 677/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2965 - val_loss: 0.5034\n",
            "Epoch 678/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2964 - val_loss: 0.5047\n",
            "Epoch 679/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2964 - val_loss: 0.5060\n",
            "Epoch 680/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2964 - val_loss: 0.5081\n",
            "Epoch 681/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2963 - val_loss: 0.5081\n",
            "Epoch 682/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2963 - val_loss: 0.5103\n",
            "Epoch 683/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2962 - val_loss: 0.5107\n",
            "Epoch 684/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2962 - val_loss: 0.5124\n",
            "Epoch 685/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2961 - val_loss: 0.5131\n",
            "Epoch 686/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2961 - val_loss: 0.5154\n",
            "Epoch 687/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2960 - val_loss: 0.5169\n",
            "Epoch 688/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2960 - val_loss: 0.5185\n",
            "Epoch 689/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2960 - val_loss: 0.5197\n",
            "Epoch 690/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2959 - val_loss: 0.5211\n",
            "Epoch 691/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2959 - val_loss: 0.5229\n",
            "Epoch 692/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2959 - val_loss: 0.5250\n",
            "Epoch 693/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2958 - val_loss: 0.5267\n",
            "Epoch 694/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2958 - val_loss: 0.5285\n",
            "Epoch 695/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2957 - val_loss: 0.5305\n",
            "Epoch 696/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2957 - val_loss: 0.5319\n",
            "Epoch 697/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2956 - val_loss: 0.5340\n",
            "Epoch 698/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2956 - val_loss: 0.5348\n",
            "Epoch 699/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2955 - val_loss: 0.5371\n",
            "Epoch 700/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2955 - val_loss: 0.5387\n",
            "Epoch 701/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2955 - val_loss: 0.5400\n",
            "Epoch 702/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2954 - val_loss: 0.5415\n",
            "Epoch 703/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2954 - val_loss: 0.5442\n",
            "Epoch 704/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2953 - val_loss: 0.5450\n",
            "Epoch 705/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2953 - val_loss: 0.5461\n",
            "Epoch 706/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.2953 - val_loss: 0.5483\n",
            "Epoch 707/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2952 - val_loss: 0.5504\n",
            "Epoch 708/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2952 - val_loss: 0.5520\n",
            "Epoch 709/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2951 - val_loss: 0.5533\n",
            "Epoch 710/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2951 - val_loss: 0.5551\n",
            "Epoch 711/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2950 - val_loss: 0.5572\n",
            "Epoch 712/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2950 - val_loss: 0.5599\n",
            "Epoch 713/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2950 - val_loss: 0.5614\n",
            "Epoch 714/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2949 - val_loss: 0.5633\n",
            "Epoch 715/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2949 - val_loss: 0.5646\n",
            "Epoch 716/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2948 - val_loss: 0.5671\n",
            "Epoch 717/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.2948 - val_loss: 0.5675\n",
            "Epoch 718/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2947 - val_loss: 0.5691\n",
            "Epoch 719/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2947 - val_loss: 0.5710\n",
            "Epoch 720/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2946 - val_loss: 0.5732\n",
            "Epoch 721/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2946 - val_loss: 0.5749\n",
            "Epoch 722/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2945 - val_loss: 0.5764\n",
            "Epoch 723/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2945 - val_loss: 0.5777\n",
            "Epoch 724/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2945 - val_loss: 0.5800\n",
            "Epoch 725/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2944 - val_loss: 0.5815\n",
            "Epoch 726/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2944 - val_loss: 0.5835\n",
            "Epoch 727/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2943 - val_loss: 0.5864\n",
            "Epoch 728/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2943 - val_loss: 0.5870\n",
            "Epoch 729/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2943 - val_loss: 0.5892\n",
            "Epoch 730/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2942 - val_loss: 0.5914\n",
            "Epoch 731/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2942 - val_loss: 0.5931\n",
            "Epoch 732/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2941 - val_loss: 0.5950\n",
            "Epoch 733/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2941 - val_loss: 0.5968\n",
            "Epoch 734/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2941 - val_loss: 0.5985\n",
            "Epoch 735/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2940 - val_loss: 0.6005\n",
            "Epoch 736/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2939 - val_loss: 0.6025\n",
            "Epoch 737/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2939 - val_loss: 0.6045\n",
            "Epoch 738/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2939 - val_loss: 0.6076\n",
            "Epoch 739/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2938 - val_loss: 0.6092\n",
            "Epoch 740/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2938 - val_loss: 0.6114\n",
            "Epoch 741/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2937 - val_loss: 0.6129\n",
            "Epoch 742/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2937 - val_loss: 0.6139\n",
            "Epoch 743/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2937 - val_loss: 0.6158\n",
            "Epoch 744/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2936 - val_loss: 0.6177\n",
            "Epoch 745/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2936 - val_loss: 0.6202\n",
            "Epoch 746/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2935 - val_loss: 0.6225\n",
            "Epoch 747/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2935 - val_loss: 0.6243\n",
            "Epoch 748/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2935 - val_loss: 0.6265\n",
            "Epoch 749/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2934 - val_loss: 0.6294\n",
            "Epoch 750/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2934 - val_loss: 0.6304\n",
            "Epoch 751/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2933 - val_loss: 0.6336\n",
            "Epoch 752/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2933 - val_loss: 0.6356\n",
            "Epoch 753/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2932 - val_loss: 0.6383\n",
            "Epoch 754/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2932 - val_loss: 0.6400\n",
            "Epoch 755/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2931 - val_loss: 0.6421\n",
            "Epoch 756/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2931 - val_loss: 0.6455\n",
            "Epoch 757/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2930 - val_loss: 0.6473\n",
            "Epoch 758/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2930 - val_loss: 0.6488\n",
            "Epoch 759/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2930 - val_loss: 0.6517\n",
            "Epoch 760/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2929 - val_loss: 0.6549\n",
            "Epoch 761/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2929 - val_loss: 0.6582\n",
            "Epoch 762/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2928 - val_loss: 0.6606\n",
            "Epoch 763/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2928 - val_loss: 0.6634\n",
            "Epoch 764/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2927 - val_loss: 0.6663\n",
            "Epoch 765/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2927 - val_loss: 0.6693\n",
            "Epoch 766/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2926 - val_loss: 0.6722\n",
            "Epoch 767/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2926 - val_loss: 0.6747\n",
            "Epoch 768/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2925 - val_loss: 0.6766\n",
            "Epoch 769/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2925 - val_loss: 0.6795\n",
            "Epoch 770/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2925 - val_loss: 0.6831\n",
            "Epoch 771/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2924 - val_loss: 0.6861\n",
            "Epoch 772/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2924 - val_loss: 0.6901\n",
            "Epoch 773/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2923 - val_loss: 0.6928\n",
            "Epoch 774/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2923 - val_loss: 0.6949\n",
            "Epoch 775/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2922 - val_loss: 0.6983\n",
            "Epoch 776/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2922 - val_loss: 0.7025\n",
            "Epoch 777/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2921 - val_loss: 0.7044\n",
            "Epoch 778/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2921 - val_loss: 0.7090\n",
            "Epoch 779/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2920 - val_loss: 0.7118\n",
            "Epoch 780/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2920 - val_loss: 0.7151\n",
            "Epoch 781/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2920 - val_loss: 0.7183\n",
            "Epoch 782/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2919 - val_loss: 0.7201\n",
            "Epoch 783/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2918 - val_loss: 0.7247\n",
            "Epoch 784/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2918 - val_loss: 0.7277\n",
            "Epoch 785/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2918 - val_loss: 0.7310\n",
            "Epoch 786/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2917 - val_loss: 0.7331\n",
            "Epoch 787/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2917 - val_loss: 0.7378\n",
            "Epoch 788/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.2916 - val_loss: 0.7399\n",
            "Epoch 789/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.2916 - val_loss: 0.7427\n",
            "Epoch 790/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2915 - val_loss: 0.7459\n",
            "Epoch 791/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2915 - val_loss: 0.7495\n",
            "Epoch 792/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2914 - val_loss: 0.7530\n",
            "Epoch 793/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2914 - val_loss: 0.7564\n",
            "Epoch 794/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2914 - val_loss: 0.7588\n",
            "Epoch 795/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2913 - val_loss: 0.7624\n",
            "Epoch 796/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2913 - val_loss: 0.7658\n",
            "Epoch 797/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2912 - val_loss: 0.7697\n",
            "Epoch 798/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2912 - val_loss: 0.7738\n",
            "Epoch 799/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2911 - val_loss: 0.7769\n",
            "Epoch 800/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2911 - val_loss: 0.7809\n",
            "Epoch 801/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2910 - val_loss: 0.7866\n",
            "Epoch 802/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2910 - val_loss: 0.7892\n",
            "Epoch 803/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2909 - val_loss: 0.7926\n",
            "Epoch 804/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2909 - val_loss: 0.7955\n",
            "Epoch 805/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2908 - val_loss: 0.7993\n",
            "Epoch 806/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2908 - val_loss: 0.8033\n",
            "Epoch 807/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2907 - val_loss: 0.8083\n",
            "Epoch 808/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2907 - val_loss: 0.8104\n",
            "Epoch 809/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2906 - val_loss: 0.8150\n",
            "Epoch 810/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2906 - val_loss: 0.8186\n",
            "Epoch 811/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2905 - val_loss: 0.8226\n",
            "Epoch 812/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.2905 - val_loss: 0.8272\n",
            "Epoch 813/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2905 - val_loss: 0.8304\n",
            "Epoch 814/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2904 - val_loss: 0.8340\n",
            "Epoch 815/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2904 - val_loss: 0.8375\n",
            "Epoch 816/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2904 - val_loss: 0.8440\n",
            "Epoch 817/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2903 - val_loss: 0.8479\n",
            "Epoch 818/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2902 - val_loss: 0.8515\n",
            "Epoch 819/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2902 - val_loss: 0.8555\n",
            "Epoch 820/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2901 - val_loss: 0.8598\n",
            "Epoch 821/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2901 - val_loss: 0.8651\n",
            "Epoch 822/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2900 - val_loss: 0.8705\n",
            "Epoch 823/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2900 - val_loss: 0.8741\n",
            "Epoch 824/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2899 - val_loss: 0.8777\n",
            "Epoch 825/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2899 - val_loss: 0.8818\n",
            "Epoch 826/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.2899 - val_loss: 0.8868\n",
            "Epoch 827/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.2898 - val_loss: 0.8916\n",
            "Epoch 828/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2898 - val_loss: 0.8942\n",
            "Epoch 829/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2898 - val_loss: 0.9008\n",
            "Epoch 830/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2897 - val_loss: 0.9047\n",
            "Epoch 831/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2896 - val_loss: 0.9078\n",
            "Epoch 832/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2896 - val_loss: 0.9132\n",
            "Epoch 833/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2895 - val_loss: 0.9163\n",
            "Epoch 834/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2895 - val_loss: 0.9207\n",
            "Epoch 835/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2895 - val_loss: 0.9258\n",
            "Epoch 836/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2894 - val_loss: 0.9303\n",
            "Epoch 837/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2894 - val_loss: 0.9356\n",
            "Epoch 838/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2893 - val_loss: 0.9390\n",
            "Epoch 839/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2893 - val_loss: 0.9445\n",
            "Epoch 840/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2892 - val_loss: 0.9498\n",
            "Epoch 841/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2892 - val_loss: 0.9559\n",
            "Epoch 842/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2891 - val_loss: 0.9603\n",
            "Epoch 843/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2891 - val_loss: 0.9643\n",
            "Epoch 844/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2891 - val_loss: 0.9716\n",
            "Epoch 845/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2890 - val_loss: 0.9759\n",
            "Epoch 846/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2890 - val_loss: 0.9811\n",
            "Epoch 847/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2889 - val_loss: 0.9835\n",
            "Epoch 848/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2889 - val_loss: 0.9883\n",
            "Epoch 849/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2888 - val_loss: 0.9943\n",
            "Epoch 850/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2888 - val_loss: 0.9971\n",
            "Epoch 851/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2887 - val_loss: 1.0051\n",
            "Epoch 852/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2887 - val_loss: 1.0099\n",
            "Epoch 853/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2886 - val_loss: 1.0209\n",
            "Epoch 854/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2886 - val_loss: 1.0274\n",
            "Epoch 855/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2885 - val_loss: 1.0346\n",
            "Epoch 856/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2884 - val_loss: 1.0428\n",
            "Epoch 857/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2883 - val_loss: 1.0498\n",
            "Epoch 858/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2883 - val_loss: 1.0550\n",
            "Epoch 859/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2883 - val_loss: 1.0607\n",
            "Epoch 860/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2882 - val_loss: 1.0670\n",
            "Epoch 861/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2881 - val_loss: 1.0724\n",
            "Epoch 862/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2880 - val_loss: 1.0800\n",
            "Epoch 863/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2880 - val_loss: 1.0870\n",
            "Epoch 864/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2879 - val_loss: 1.0936\n",
            "Epoch 865/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2879 - val_loss: 1.0981\n",
            "Epoch 866/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2878 - val_loss: 1.1065\n",
            "Epoch 867/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2878 - val_loss: 1.1121\n",
            "Epoch 868/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2877 - val_loss: 1.1165\n",
            "Epoch 869/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2877 - val_loss: 1.1281\n",
            "Epoch 870/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2876 - val_loss: 1.1334\n",
            "Epoch 871/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2875 - val_loss: 1.1395\n",
            "Epoch 872/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2875 - val_loss: 1.1447\n",
            "Epoch 873/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2874 - val_loss: 1.1506\n",
            "Epoch 874/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2874 - val_loss: 1.1596\n",
            "Epoch 875/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.2873 - val_loss: 1.1628\n",
            "Epoch 876/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2873 - val_loss: 1.1712\n",
            "Epoch 877/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2872 - val_loss: 1.1765\n",
            "Epoch 878/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2872 - val_loss: 1.1827\n",
            "Epoch 879/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2871 - val_loss: 1.1906\n",
            "Epoch 880/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2871 - val_loss: 1.1950\n",
            "Epoch 881/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2870 - val_loss: 1.2027\n",
            "Epoch 882/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2870 - val_loss: 1.2113\n",
            "Epoch 883/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2869 - val_loss: 1.2154\n",
            "Epoch 884/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2869 - val_loss: 1.2231\n",
            "Epoch 885/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2868 - val_loss: 1.2300\n",
            "Epoch 886/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2868 - val_loss: 1.2387\n",
            "Epoch 887/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2867 - val_loss: 1.2455\n",
            "Epoch 888/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2867 - val_loss: 1.2519\n",
            "Epoch 889/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.2866 - val_loss: 1.2577\n",
            "Epoch 890/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2866 - val_loss: 1.2643\n",
            "Epoch 891/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2865 - val_loss: 1.2715\n",
            "Epoch 892/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2864 - val_loss: 1.2776\n",
            "Epoch 893/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.2864 - val_loss: 1.2823\n",
            "Epoch 894/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2864 - val_loss: 1.2870\n",
            "Epoch 895/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2863 - val_loss: 1.2970\n",
            "Epoch 896/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2863 - val_loss: 1.3063\n",
            "Epoch 897/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2862 - val_loss: 1.3124\n",
            "Epoch 898/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2861 - val_loss: 1.3181\n",
            "Epoch 899/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2861 - val_loss: 1.3265\n",
            "Epoch 900/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2860 - val_loss: 1.3331\n",
            "Epoch 901/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2860 - val_loss: 1.3409\n",
            "Epoch 902/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2860 - val_loss: 1.3480\n",
            "Epoch 903/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2859 - val_loss: 1.3559\n",
            "Epoch 904/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.2859 - val_loss: 1.3615\n",
            "Epoch 905/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2858 - val_loss: 1.3680\n",
            "Epoch 906/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2858 - val_loss: 1.3756\n",
            "Epoch 907/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2857 - val_loss: 1.3840\n",
            "Epoch 908/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2857 - val_loss: 1.3930\n",
            "Epoch 909/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2856 - val_loss: 1.4004\n",
            "Epoch 910/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2856 - val_loss: 1.4086\n",
            "Epoch 911/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2855 - val_loss: 1.4136\n",
            "Epoch 912/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2855 - val_loss: 1.4211\n",
            "Epoch 913/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2854 - val_loss: 1.4266\n",
            "Epoch 914/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2854 - val_loss: 1.4379\n",
            "Epoch 915/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2853 - val_loss: 1.4425\n",
            "Epoch 916/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2853 - val_loss: 1.4521\n",
            "Epoch 917/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2852 - val_loss: 1.4569\n",
            "Epoch 918/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2852 - val_loss: 1.4664\n",
            "Epoch 919/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2851 - val_loss: 1.4737\n",
            "Epoch 920/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2851 - val_loss: 1.4817\n",
            "Epoch 921/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2851 - val_loss: 1.4885\n",
            "Epoch 922/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2850 - val_loss: 1.4980\n",
            "Epoch 923/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2850 - val_loss: 1.5062\n",
            "Epoch 924/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2849 - val_loss: 1.5126\n",
            "Epoch 925/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2849 - val_loss: 1.5224\n",
            "Epoch 926/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2848 - val_loss: 1.5294\n",
            "Epoch 927/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2848 - val_loss: 1.5374\n",
            "Epoch 928/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2848 - val_loss: 1.5423\n",
            "Epoch 929/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2847 - val_loss: 1.5506\n",
            "Epoch 930/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2847 - val_loss: 1.5621\n",
            "Epoch 931/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2847 - val_loss: 1.5639\n",
            "Epoch 932/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2846 - val_loss: 1.5759\n",
            "Epoch 933/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2846 - val_loss: 1.5805\n",
            "Epoch 934/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2845 - val_loss: 1.5893\n",
            "Epoch 935/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2845 - val_loss: 1.5966\n",
            "Epoch 936/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2844 - val_loss: 1.6038\n",
            "Epoch 937/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2844 - val_loss: 1.6106\n",
            "Epoch 938/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2843 - val_loss: 1.6184\n",
            "Epoch 939/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2843 - val_loss: 1.6274\n",
            "Epoch 940/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2843 - val_loss: 1.6350\n",
            "Epoch 941/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2842 - val_loss: 1.6417\n",
            "Epoch 942/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.2842 - val_loss: 1.6495\n",
            "Epoch 943/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2842 - val_loss: 1.6604\n",
            "Epoch 944/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2842 - val_loss: 1.6670\n",
            "Epoch 945/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2841 - val_loss: 1.6769\n",
            "Epoch 946/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2841 - val_loss: 1.6828\n",
            "Epoch 947/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2840 - val_loss: 1.6942\n",
            "Epoch 948/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2839 - val_loss: 1.7021\n",
            "Epoch 949/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2839 - val_loss: 1.7131\n",
            "Epoch 950/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2839 - val_loss: 1.7161\n",
            "Epoch 951/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2839 - val_loss: 1.7264\n",
            "Epoch 952/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2838 - val_loss: 1.7367\n",
            "Epoch 953/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2838 - val_loss: 1.7406\n",
            "Epoch 954/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2837 - val_loss: 1.7482\n",
            "Epoch 955/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2837 - val_loss: 1.7558\n",
            "Epoch 956/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2837 - val_loss: 1.7635\n",
            "Epoch 957/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2836 - val_loss: 1.7704\n",
            "Epoch 958/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2836 - val_loss: 1.7825\n",
            "Epoch 959/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2836 - val_loss: 1.7914\n",
            "Epoch 960/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2835 - val_loss: 1.7977\n",
            "Epoch 961/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2835 - val_loss: 1.8070\n",
            "Epoch 962/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2835 - val_loss: 1.8140\n",
            "Epoch 963/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2834 - val_loss: 1.8241\n",
            "Epoch 964/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2834 - val_loss: 1.8327\n",
            "Epoch 965/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2833 - val_loss: 1.8429\n",
            "Epoch 966/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2833 - val_loss: 1.8511\n",
            "Epoch 967/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2832 - val_loss: 1.8609\n",
            "Epoch 968/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2832 - val_loss: 1.8696\n",
            "Epoch 969/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2832 - val_loss: 1.8847\n",
            "Epoch 970/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2831 - val_loss: 1.8846\n",
            "Epoch 971/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2831 - val_loss: 1.8960\n",
            "Epoch 972/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2831 - val_loss: 1.9072\n",
            "Epoch 973/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2831 - val_loss: 1.9161\n",
            "Epoch 974/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2830 - val_loss: 1.9247\n",
            "Epoch 975/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2830 - val_loss: 1.9373\n",
            "Epoch 976/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2830 - val_loss: 1.9473\n",
            "Epoch 977/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2829 - val_loss: 1.9558\n",
            "Epoch 978/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2829 - val_loss: 1.9633\n",
            "Epoch 979/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2828 - val_loss: 1.9719\n",
            "Epoch 980/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2828 - val_loss: 1.9816\n",
            "Epoch 981/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2828 - val_loss: 1.9923\n",
            "Epoch 982/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2828 - val_loss: 2.0020\n",
            "Epoch 983/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2827 - val_loss: 2.0138\n",
            "Epoch 984/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2827 - val_loss: 2.0211\n",
            "Epoch 985/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2827 - val_loss: 2.0302\n",
            "Epoch 986/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2827 - val_loss: 2.0472\n",
            "Epoch 987/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.2826 - val_loss: 2.0503\n",
            "Epoch 988/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2826 - val_loss: 2.0593\n",
            "Epoch 989/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2825 - val_loss: 2.0688\n",
            "Epoch 990/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2825 - val_loss: 2.0780\n",
            "Epoch 991/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2825 - val_loss: 2.0900\n",
            "Epoch 992/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2824 - val_loss: 2.0964\n",
            "Epoch 993/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2824 - val_loss: 2.1051\n",
            "Epoch 994/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2824 - val_loss: 2.1184\n",
            "Epoch 995/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2824 - val_loss: 2.1296\n",
            "Epoch 996/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.2823 - val_loss: 2.1401\n",
            "Epoch 997/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.2823 - val_loss: 2.1447\n",
            "Epoch 998/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2823 - val_loss: 2.1581\n",
            "Epoch 999/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2823 - val_loss: 2.1665\n",
            "Epoch 1000/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2822 - val_loss: 2.1760\n",
            "Epoch 1001/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2822 - val_loss: 2.1880\n",
            "Epoch 1002/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2822 - val_loss: 2.1972\n",
            "Epoch 1003/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2821 - val_loss: 2.2094\n",
            "Epoch 1004/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2821 - val_loss: 2.2190\n",
            "Epoch 1005/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.2821 - val_loss: 2.2276\n",
            "Epoch 1006/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.2820 - val_loss: 2.2365\n",
            "Epoch 1007/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2820 - val_loss: 2.2470\n",
            "Epoch 1008/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2820 - val_loss: 2.2553\n",
            "Epoch 1009/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2820 - val_loss: 2.2659\n",
            "Epoch 1010/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2819 - val_loss: 2.2761\n",
            "Epoch 1011/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2819 - val_loss: 2.2873\n",
            "Epoch 1012/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2819 - val_loss: 2.2965\n",
            "Epoch 1013/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2819 - val_loss: 2.3060\n",
            "Epoch 1014/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2818 - val_loss: 2.3162\n",
            "Epoch 1015/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2818 - val_loss: 2.3259\n",
            "Epoch 1016/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2818 - val_loss: 2.3356\n",
            "Epoch 1017/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2818 - val_loss: 2.3463\n",
            "Epoch 1018/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2817 - val_loss: 2.3579\n",
            "Epoch 1019/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2817 - val_loss: 2.3679\n",
            "Epoch 1020/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2817 - val_loss: 2.3735\n",
            "Epoch 1021/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2817 - val_loss: 2.3838\n",
            "Epoch 1022/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2817 - val_loss: 2.3951\n",
            "Epoch 1023/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2816 - val_loss: 2.4072\n",
            "Epoch 1024/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2816 - val_loss: 2.4188\n",
            "Epoch 1025/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2816 - val_loss: 2.4278\n",
            "Epoch 1026/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2815 - val_loss: 2.4398\n",
            "Epoch 1027/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2815 - val_loss: 2.4505\n",
            "Epoch 1028/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2815 - val_loss: 2.4554\n",
            "Epoch 1029/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2815 - val_loss: 2.4656\n",
            "Epoch 1030/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2814 - val_loss: 2.4825\n",
            "Epoch 1031/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2814 - val_loss: 2.4903\n",
            "Epoch 1032/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2814 - val_loss: 2.5013\n",
            "Epoch 1033/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2814 - val_loss: 2.5106\n",
            "Epoch 1034/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2814 - val_loss: 2.5159\n",
            "Epoch 1035/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2814 - val_loss: 2.5259\n",
            "Epoch 1036/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2813 - val_loss: 2.5410\n",
            "Epoch 1037/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2813 - val_loss: 2.5545\n",
            "Epoch 1038/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2813 - val_loss: 2.5627\n",
            "Epoch 1039/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2813 - val_loss: 2.5778\n",
            "Epoch 1040/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2812 - val_loss: 2.5836\n",
            "Epoch 1041/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.2812 - val_loss: 2.5964\n",
            "Epoch 1042/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2812 - val_loss: 2.6043\n",
            "Epoch 1043/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2812 - val_loss: 2.6138\n",
            "Epoch 1044/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2811 - val_loss: 2.6277\n",
            "Epoch 1045/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2811 - val_loss: 2.6372\n",
            "Epoch 1046/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2811 - val_loss: 2.6443\n",
            "Epoch 1047/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2811 - val_loss: 2.6514\n",
            "Epoch 1048/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2811 - val_loss: 2.6664\n",
            "Epoch 1049/5000\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.2811 - val_loss: 2.6804\n",
            "Epoch 1050/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2810 - val_loss: 2.6896\n",
            "Epoch 1051/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2810 - val_loss: 2.6981\n",
            "Epoch 1052/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2810 - val_loss: 2.7053\n",
            "Epoch 1053/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2810 - val_loss: 2.7117\n",
            "Epoch 1054/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2810 - val_loss: 2.7233\n",
            "Epoch 1055/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2810 - val_loss: 2.7370\n",
            "Epoch 1056/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2809 - val_loss: 2.7463\n",
            "Epoch 1057/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2809 - val_loss: 2.7631\n",
            "Epoch 1058/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2809 - val_loss: 2.7726\n",
            "Epoch 1059/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2809 - val_loss: 2.7793\n",
            "Epoch 1060/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2808 - val_loss: 2.7912\n",
            "Epoch 1061/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2808 - val_loss: 2.7969\n",
            "Epoch 1062/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2808 - val_loss: 2.8066\n",
            "Epoch 1063/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2808 - val_loss: 2.8217\n",
            "Epoch 1064/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2808 - val_loss: 2.8312\n",
            "Epoch 1065/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2807 - val_loss: 2.8425\n",
            "Epoch 1066/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2807 - val_loss: 2.8473\n",
            "Epoch 1067/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2807 - val_loss: 2.8664\n",
            "Epoch 1068/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2807 - val_loss: 2.8721\n",
            "Epoch 1069/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2807 - val_loss: 2.8901\n",
            "Epoch 1070/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2807 - val_loss: 2.8958\n",
            "Epoch 1071/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2807 - val_loss: 2.9043\n",
            "Epoch 1072/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2806 - val_loss: 2.9168\n",
            "Epoch 1073/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2806 - val_loss: 2.9258\n",
            "Epoch 1074/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2806 - val_loss: 2.9364\n",
            "Epoch 1075/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2806 - val_loss: 2.9466\n",
            "Epoch 1076/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2806 - val_loss: 2.9549\n",
            "Epoch 1077/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2806 - val_loss: 2.9631\n",
            "Epoch 1078/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2805 - val_loss: 2.9804\n",
            "Epoch 1079/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2805 - val_loss: 2.9870\n",
            "Epoch 1080/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2805 - val_loss: 3.0036\n",
            "Epoch 1081/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2805 - val_loss: 2.9998\n",
            "Epoch 1082/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2805 - val_loss: 3.0143\n",
            "Epoch 1083/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2805 - val_loss: 3.0278\n",
            "Epoch 1084/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2804 - val_loss: 3.0388\n",
            "Epoch 1085/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2804 - val_loss: 3.0450\n",
            "Epoch 1086/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2804 - val_loss: 3.0582\n",
            "Epoch 1087/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2804 - val_loss: 3.0665\n",
            "Epoch 1088/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2804 - val_loss: 3.0801\n",
            "Epoch 1089/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2804 - val_loss: 3.0849\n",
            "Epoch 1090/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2804 - val_loss: 3.0957\n",
            "Epoch 1091/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2803 - val_loss: 3.1125\n",
            "Epoch 1092/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2803 - val_loss: 3.1182\n",
            "Epoch 1093/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2803 - val_loss: 3.1248\n",
            "Epoch 1094/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2803 - val_loss: 3.1355\n",
            "Epoch 1095/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2803 - val_loss: 3.1459\n",
            "Epoch 1096/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2803 - val_loss: 3.1597\n",
            "Epoch 1097/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2802 - val_loss: 3.1676\n",
            "Epoch 1098/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2803 - val_loss: 3.1739\n",
            "Epoch 1099/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2802 - val_loss: 3.1883\n",
            "Epoch 1100/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2802 - val_loss: 3.1917\n",
            "Epoch 1101/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2802 - val_loss: 3.2013\n",
            "Epoch 1102/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2802 - val_loss: 3.2113\n",
            "Epoch 1103/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2802 - val_loss: 3.2190\n",
            "Epoch 1104/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2802 - val_loss: 3.2239\n",
            "Epoch 1105/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2802 - val_loss: 3.2363\n",
            "Epoch 1106/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2801 - val_loss: 3.2376\n",
            "Epoch 1107/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2801 - val_loss: 3.2431\n",
            "Epoch 1108/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2801 - val_loss: 3.2529\n",
            "Epoch 1109/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2801 - val_loss: 3.2572\n",
            "Epoch 1110/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2801 - val_loss: 3.2613\n",
            "Epoch 1111/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2801 - val_loss: 3.2708\n",
            "Epoch 1112/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2801 - val_loss: 3.2782\n",
            "Epoch 1113/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2801 - val_loss: 3.2794\n",
            "Epoch 1114/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2800 - val_loss: 3.2877\n",
            "Epoch 1115/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2800 - val_loss: 3.2922\n",
            "Epoch 1116/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2801 - val_loss: 3.2899\n",
            "Epoch 1117/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2800 - val_loss: 3.3009\n",
            "Epoch 1118/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2800 - val_loss: 3.3057\n",
            "Epoch 1119/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2800 - val_loss: 3.3114\n",
            "Epoch 1120/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2800 - val_loss: 3.3060\n",
            "Epoch 1121/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2800 - val_loss: 3.3147\n",
            "Epoch 1122/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2800 - val_loss: 3.3134\n",
            "Epoch 1123/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2799 - val_loss: 3.3240\n",
            "Epoch 1124/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2799 - val_loss: 3.3270\n",
            "Epoch 1125/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2799 - val_loss: 3.3286\n",
            "Epoch 1126/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2799 - val_loss: 3.3351\n",
            "Epoch 1127/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2799 - val_loss: 3.3392\n",
            "Epoch 1128/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2799 - val_loss: 3.3371\n",
            "Epoch 1129/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2799 - val_loss: 3.3488\n",
            "Epoch 1130/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2799 - val_loss: 3.3521\n",
            "Epoch 1131/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2798 - val_loss: 3.3495\n",
            "Epoch 1132/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2798 - val_loss: 3.3565\n",
            "Epoch 1133/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2798 - val_loss: 3.3670\n",
            "Epoch 1134/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2799 - val_loss: 3.3613\n",
            "Epoch 1135/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2798 - val_loss: 3.3698\n",
            "Epoch 1136/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2798 - val_loss: 3.3728\n",
            "Epoch 1137/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2798 - val_loss: 3.3776\n",
            "Epoch 1138/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2798 - val_loss: 3.3793\n",
            "Epoch 1139/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2798 - val_loss: 3.3849\n",
            "Epoch 1140/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2798 - val_loss: 3.3882\n",
            "Epoch 1141/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2797 - val_loss: 3.3886\n",
            "Epoch 1142/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2798 - val_loss: 3.3879\n",
            "Epoch 1143/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2797 - val_loss: 3.3933\n",
            "Epoch 1144/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2797 - val_loss: 3.3872\n",
            "Epoch 1145/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2797 - val_loss: 3.3929\n",
            "Epoch 1146/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2797 - val_loss: 3.4002\n",
            "Epoch 1147/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2797 - val_loss: 3.4068\n",
            "Epoch 1148/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2797 - val_loss: 3.4034\n",
            "Epoch 1149/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2797 - val_loss: 3.4035\n",
            "Epoch 1150/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2796 - val_loss: 3.4105\n",
            "Epoch 1151/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2797 - val_loss: 3.4099\n",
            "Epoch 1152/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2797 - val_loss: 3.4075\n",
            "Epoch 1153/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2796 - val_loss: 3.4082\n",
            "Epoch 1154/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2796 - val_loss: 3.4168\n",
            "Epoch 1155/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2796 - val_loss: 3.4147\n",
            "Epoch 1156/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2796 - val_loss: 3.4117\n",
            "Epoch 1157/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2796 - val_loss: 3.4225\n",
            "Epoch 1158/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2796 - val_loss: 3.4142\n",
            "Epoch 1159/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2796 - val_loss: 3.4180\n",
            "Epoch 1160/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2796 - val_loss: 3.4184\n",
            "Epoch 1161/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2796 - val_loss: 3.4215\n",
            "Epoch 1162/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2795 - val_loss: 3.4280\n",
            "Epoch 1163/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2796 - val_loss: 3.4304\n",
            "Epoch 1164/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2795 - val_loss: 3.4242\n",
            "Epoch 1165/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2795 - val_loss: 3.4266\n",
            "Epoch 1166/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2795 - val_loss: 3.4279\n",
            "Epoch 1167/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2795 - val_loss: 3.4309\n",
            "Epoch 1168/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2795 - val_loss: 3.4323\n",
            "Epoch 1169/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2795 - val_loss: 3.4348\n",
            "Epoch 1170/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2795 - val_loss: 3.4331\n",
            "Epoch 1171/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2795 - val_loss: 3.4386\n",
            "Epoch 1172/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2795 - val_loss: 3.4316\n",
            "Epoch 1173/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2795 - val_loss: 3.4384\n",
            "Epoch 1174/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2795 - val_loss: 3.4415\n",
            "Epoch 1175/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2794 - val_loss: 3.4384\n",
            "Epoch 1176/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2794 - val_loss: 3.4438\n",
            "Epoch 1177/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2794 - val_loss: 3.4436\n",
            "Epoch 1178/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2794 - val_loss: 3.4459\n",
            "Epoch 1179/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2794 - val_loss: 3.4461\n",
            "Epoch 1180/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2794 - val_loss: 3.4492\n",
            "Epoch 1181/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2794 - val_loss: 3.4528\n",
            "Epoch 1182/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2794 - val_loss: 3.4498\n",
            "Epoch 1183/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2794 - val_loss: 3.4543\n",
            "Epoch 1184/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2794 - val_loss: 3.4599\n",
            "Epoch 1185/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2794 - val_loss: 3.4644\n",
            "Epoch 1186/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2794 - val_loss: 3.4679\n",
            "Epoch 1187/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2794 - val_loss: 3.4662\n",
            "Epoch 1188/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2793 - val_loss: 3.4763\n",
            "Epoch 1189/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2793 - val_loss: 3.4766\n",
            "Epoch 1190/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2793 - val_loss: 3.4844\n",
            "Epoch 1191/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2793 - val_loss: 3.4790\n",
            "Epoch 1192/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2793 - val_loss: 3.4854\n",
            "Epoch 1193/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2793 - val_loss: 3.4868\n",
            "Epoch 1194/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2793 - val_loss: 3.4876\n",
            "Epoch 1195/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2793 - val_loss: 3.4972\n",
            "Epoch 1196/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2793 - val_loss: 3.5053\n",
            "Epoch 1197/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2793 - val_loss: 3.5043\n",
            "Epoch 1198/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2793 - val_loss: 3.5090\n",
            "Epoch 1199/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2793 - val_loss: 3.5085\n",
            "Epoch 1200/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2793 - val_loss: 3.5101\n",
            "Epoch 1201/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2792 - val_loss: 3.5175\n",
            "Epoch 1202/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2792 - val_loss: 3.5236\n",
            "Epoch 1203/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2792 - val_loss: 3.5186\n",
            "Epoch 1204/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2792 - val_loss: 3.5243\n",
            "Epoch 1205/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2792 - val_loss: 3.5318\n",
            "Epoch 1206/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2792 - val_loss: 3.5360\n",
            "Epoch 1207/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2792 - val_loss: 3.5334\n",
            "Epoch 1208/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2792 - val_loss: 3.5449\n",
            "Epoch 1209/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2792 - val_loss: 3.5341\n",
            "Epoch 1210/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2792 - val_loss: 3.5460\n",
            "Epoch 1211/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2792 - val_loss: 3.5478\n",
            "Epoch 1212/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2792 - val_loss: 3.5521\n",
            "Epoch 1213/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2791 - val_loss: 3.5516\n",
            "Epoch 1214/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2791 - val_loss: 3.5554\n",
            "Epoch 1215/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2791 - val_loss: 3.5577\n",
            "Epoch 1216/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2792 - val_loss: 3.5664\n",
            "Epoch 1217/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2791 - val_loss: 3.5689\n",
            "Epoch 1218/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2791 - val_loss: 3.5656\n",
            "Epoch 1219/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2791 - val_loss: 3.5672\n",
            "Epoch 1220/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2791 - val_loss: 3.5698\n",
            "Epoch 1221/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2791 - val_loss: 3.5701\n",
            "Epoch 1222/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2791 - val_loss: 3.5739\n",
            "Epoch 1223/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2791 - val_loss: 3.5821\n",
            "Epoch 1224/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2791 - val_loss: 3.5788\n",
            "Epoch 1225/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2791 - val_loss: 3.5855\n",
            "Epoch 1226/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2791 - val_loss: 3.5822\n",
            "Epoch 1227/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2791 - val_loss: 3.5834\n",
            "Epoch 1228/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2791 - val_loss: 3.5966\n",
            "Epoch 1229/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2791 - val_loss: 3.5959\n",
            "Epoch 1230/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2790 - val_loss: 3.5958\n",
            "Epoch 1231/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2790 - val_loss: 3.5963\n",
            "Epoch 1232/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2790 - val_loss: 3.6002\n",
            "Epoch 1233/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2790 - val_loss: 3.5983\n",
            "Epoch 1234/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2790 - val_loss: 3.6000\n",
            "Epoch 1235/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2790 - val_loss: 3.6046\n",
            "Epoch 1236/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2790 - val_loss: 3.6065\n",
            "Epoch 1237/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2790 - val_loss: 3.6105\n",
            "Epoch 1238/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2790 - val_loss: 3.6110\n",
            "Epoch 1239/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2790 - val_loss: 3.6115\n",
            "Epoch 1240/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2790 - val_loss: 3.6126\n",
            "Epoch 1241/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2790 - val_loss: 3.6150\n",
            "Epoch 1242/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2789 - val_loss: 3.6197\n",
            "Epoch 1243/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2789 - val_loss: 3.6223\n",
            "Epoch 1244/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2790 - val_loss: 3.6200\n",
            "Epoch 1245/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2789 - val_loss: 3.6332\n",
            "Epoch 1246/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2789 - val_loss: 3.6268\n",
            "Epoch 1247/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2789 - val_loss: 3.6279\n",
            "Epoch 1248/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2789 - val_loss: 3.6392\n",
            "Epoch 1249/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2789 - val_loss: 3.6355\n",
            "Epoch 1250/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2789 - val_loss: 3.6360\n",
            "Epoch 1251/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2789 - val_loss: 3.6479\n",
            "Epoch 1252/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2789 - val_loss: 3.6476\n",
            "Epoch 1253/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2789 - val_loss: 3.6550\n",
            "Epoch 1254/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2789 - val_loss: 3.6484\n",
            "Epoch 1255/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2789 - val_loss: 3.6521\n",
            "Epoch 1256/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2789 - val_loss: 3.6632\n",
            "Epoch 1257/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2789 - val_loss: 3.6587\n",
            "Epoch 1258/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2789 - val_loss: 3.6661\n",
            "Epoch 1259/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2788 - val_loss: 3.6694\n",
            "Epoch 1260/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2788 - val_loss: 3.6741\n",
            "Epoch 1261/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2788 - val_loss: 3.6698\n",
            "Epoch 1262/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2788 - val_loss: 3.6717\n",
            "Epoch 1263/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2788 - val_loss: 3.6731\n",
            "Epoch 1264/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2788 - val_loss: 3.6818\n",
            "Epoch 1265/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2788 - val_loss: 3.6889\n",
            "Epoch 1266/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2788 - val_loss: 3.6909\n",
            "Epoch 1267/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2788 - val_loss: 3.6886\n",
            "Epoch 1268/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2788 - val_loss: 3.6987\n",
            "Epoch 1269/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2788 - val_loss: 3.6981\n",
            "Epoch 1270/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2788 - val_loss: 3.7106\n",
            "Epoch 1271/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2788 - val_loss: 3.7048\n",
            "Epoch 1272/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2788 - val_loss: 3.7061\n",
            "Epoch 1273/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2787 - val_loss: 3.7141\n",
            "Epoch 1274/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2787 - val_loss: 3.7162\n",
            "Epoch 1275/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2787 - val_loss: 3.7147\n",
            "Epoch 1276/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2787 - val_loss: 3.7226\n",
            "Epoch 1277/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2787 - val_loss: 3.7208\n",
            "Epoch 1278/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2787 - val_loss: 3.7290\n",
            "Epoch 1279/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2787 - val_loss: 3.7335\n",
            "Epoch 1280/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2787 - val_loss: 3.7375\n",
            "Epoch 1281/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2787 - val_loss: 3.7399\n",
            "Epoch 1282/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2787 - val_loss: 3.7446\n",
            "Epoch 1283/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2787 - val_loss: 3.7439\n",
            "Epoch 1284/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2787 - val_loss: 3.7505\n",
            "Epoch 1285/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2786 - val_loss: 3.7588\n",
            "Epoch 1286/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2787 - val_loss: 3.7571\n",
            "Epoch 1287/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2787 - val_loss: 3.7609\n",
            "Epoch 1288/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2787 - val_loss: 3.7653\n",
            "Epoch 1289/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2786 - val_loss: 3.7729\n",
            "Epoch 1290/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2786 - val_loss: 3.7747\n",
            "Epoch 1291/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2786 - val_loss: 3.7734\n",
            "Epoch 1292/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2786 - val_loss: 3.7851\n",
            "Epoch 1293/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2786 - val_loss: 3.7873\n",
            "Epoch 1294/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2786 - val_loss: 3.7944\n",
            "Epoch 1295/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2786 - val_loss: 3.7979\n",
            "Epoch 1296/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2786 - val_loss: 3.8021\n",
            "Epoch 1297/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2786 - val_loss: 3.7986\n",
            "Epoch 1298/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2786 - val_loss: 3.8044\n",
            "Epoch 1299/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2786 - val_loss: 3.8105\n",
            "Epoch 1300/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2786 - val_loss: 3.8160\n",
            "Epoch 1301/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2786 - val_loss: 3.8198\n",
            "Epoch 1302/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2786 - val_loss: 3.8264\n",
            "Epoch 1303/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2785 - val_loss: 3.8278\n",
            "Epoch 1304/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2786 - val_loss: 3.8352\n",
            "Epoch 1305/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2785 - val_loss: 3.8389\n",
            "Epoch 1306/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2785 - val_loss: 3.8363\n",
            "Epoch 1307/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2785 - val_loss: 3.8436\n",
            "Epoch 1308/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2785 - val_loss: 3.8493\n",
            "Epoch 1309/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2785 - val_loss: 3.8531\n",
            "Epoch 1310/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2785 - val_loss: 3.8487\n",
            "Epoch 1311/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2785 - val_loss: 3.8602\n",
            "Epoch 1312/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2785 - val_loss: 3.8618\n",
            "Epoch 1313/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2785 - val_loss: 3.8677\n",
            "Epoch 1314/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2785 - val_loss: 3.8747\n",
            "Epoch 1315/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2784 - val_loss: 3.8821\n",
            "Epoch 1316/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2784 - val_loss: 3.8871\n",
            "Epoch 1317/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2784 - val_loss: 3.8891\n",
            "Epoch 1318/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2784 - val_loss: 3.8961\n",
            "Epoch 1319/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2784 - val_loss: 3.8981\n",
            "Epoch 1320/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2784 - val_loss: 3.9013\n",
            "Epoch 1321/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2784 - val_loss: 3.9018\n",
            "Epoch 1322/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2784 - val_loss: 3.9097\n",
            "Epoch 1323/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2784 - val_loss: 3.9178\n",
            "Epoch 1324/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2784 - val_loss: 3.9231\n",
            "Epoch 1325/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2784 - val_loss: 3.9220\n",
            "Epoch 1326/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2784 - val_loss: 3.9340\n",
            "Epoch 1327/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2784 - val_loss: 3.9358\n",
            "Epoch 1328/5000\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2784 - val_loss: 3.9420\n",
            "Epoch 1329/5000\n",
            " 59/113 [==============>...............] - ETA: 0s - loss: 0.3056Restoring model weights from the end of the best epoch: 329.\n",
            "113/113 [==============================] - 0s 1ms/step - loss: 0.2784 - val_loss: 3.9479\n",
            "Epoch 1329: early stopping\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 0s 1ms/step - loss: 0.9197\n",
            "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f8658f03880> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "EXPECTED:\n",
            "     d18O_cel_mean  d18O_cel_variance\n",
            "0        25.120750           0.844007\n",
            "1        25.120750           0.844007\n",
            "2        25.120750           0.844007\n",
            "3        25.120750           0.844007\n",
            "4        25.120750           0.844007\n",
            "5        25.120750           0.844007\n",
            "6        25.120750           0.844007\n",
            "7        25.120750           0.844007\n",
            "8        25.120750           0.844007\n",
            "9        25.120750           0.844007\n",
            "10       25.120750           0.844007\n",
            "11       25.120750           0.844007\n",
            "12       25.120750           0.844007\n",
            "13       25.120750           0.844007\n",
            "14       25.120750           0.844007\n",
            "15       25.120750           0.844007\n",
            "16       25.120750           0.844007\n",
            "17       25.120750           0.844007\n",
            "18       25.120750           0.844007\n",
            "19       25.120750           0.844007\n",
            "20       25.120750           0.844007\n",
            "21       25.120750           0.844007\n",
            "22       25.120750           0.844007\n",
            "23       25.120750           0.844007\n",
            "24       25.120750           0.844007\n",
            "25       25.120750           0.844007\n",
            "26       25.120750           0.844007\n",
            "27       25.120750           0.844007\n",
            "28       25.120750           0.844007\n",
            "29       25.120750           0.844007\n",
            "30       25.120750           0.844007\n",
            "31       25.120750           0.844007\n",
            "32       25.120750           0.844007\n",
            "33       25.120750           0.844007\n",
            "34       25.120750           0.844007\n",
            "35       25.120750           0.844007\n",
            "36       25.120750           0.844007\n",
            "37       25.120750           0.844007\n",
            "38       25.120750           0.844007\n",
            "39       25.120750           0.844007\n",
            "40       24.777670           0.736571\n",
            "41       24.777670           0.736571\n",
            "42       24.777670           0.736571\n",
            "43       24.777670           0.736571\n",
            "44       24.777670           0.736571\n",
            "45       25.551850           0.312355\n",
            "46       25.551850           0.312355\n",
            "47       25.551850           0.312355\n",
            "48       25.551850           0.312355\n",
            "49       25.551850           0.312355\n",
            "50       25.115885           0.033519\n",
            "51       25.115885           0.033519\n",
            "52       25.115885           0.033519\n",
            "53       25.115885           0.033519\n",
            "54       25.115885           0.033519\n",
            "55       25.987815           5.280825\n",
            "56       25.987815           5.280825\n",
            "57       25.987815           5.280825\n",
            "58       25.987815           5.280825\n",
            "59       25.987815           5.280825\n",
            "60       24.132031           0.389042\n",
            "61       24.132031           0.389042\n",
            "62       24.132031           0.389042\n",
            "63       24.132031           0.389042\n",
            "64       27.559140           0.780698\n",
            "65       27.559140           0.780698\n",
            "66       27.559140           0.780698\n",
            "67       27.559140           0.780698\n",
            "68       27.559140           0.780698\n",
            "69       27.559140           0.780698\n",
            "70       27.559140           0.780698\n",
            "71       27.559140           0.780698\n",
            "72       27.559140           0.780698\n",
            "73       27.559140           0.780698\n",
            "74       27.260748           0.830341\n",
            "75       27.260748           0.830341\n",
            "76       27.260748           0.830341\n",
            "77       27.260748           0.830341\n",
            "78       27.260748           0.830341\n",
            "79       27.260748           0.830341\n",
            "80       27.260748           0.830341\n",
            "81       27.260748           0.830341\n",
            "82       27.260748           0.830341\n",
            "83       27.260748           0.830341\n",
            "84       27.260748           0.830341\n",
            "85       27.260748           0.830341\n",
            "86       27.260748           0.830341\n",
            "87       27.260748           0.830341\n",
            "88       27.260748           0.830341\n",
            "89       27.260748           0.830341\n",
            "90       27.260748           0.830341\n",
            "91       27.260748           0.830341\n",
            "92       27.260748           0.830341\n",
            "93       27.260748           0.830341\n",
            "94       27.260748           0.830341\n",
            "95       27.260748           0.830341\n",
            "96       27.260748           0.830341\n",
            "97       27.260748           0.830341\n",
            "98       27.260748           0.830341\n",
            "99       27.260748           0.830341\n",
            "100      27.260748           0.830341\n",
            "101      27.260748           0.830341\n",
            "102      27.260748           0.830341\n",
            "103      27.260748           0.830341\n",
            "104      27.260748           0.830341\n",
            "105      27.260748           0.830341\n",
            "106      27.260748           0.830341\n",
            "107      27.260748           0.830341\n",
            "108      27.260748           0.830341\n",
            "\n",
            "PREDICTED:\n",
            "     d18O_cel_mean  d18O_cel_variance\n",
            "0        25.466181           1.429170\n",
            "1        25.466181           1.429170\n",
            "2        25.466181           1.429170\n",
            "3        25.466181           1.429170\n",
            "4        25.466181           1.429170\n",
            "5        25.466181           1.429170\n",
            "6        25.466181           1.429170\n",
            "7        25.466181           1.429170\n",
            "8        25.466181           1.429170\n",
            "9        25.466181           1.429170\n",
            "10       25.466181           1.429170\n",
            "11       25.466181           1.429170\n",
            "12       25.466181           1.429170\n",
            "13       25.466181           1.429170\n",
            "14       25.466181           1.429170\n",
            "15       25.466181           1.429170\n",
            "16       25.466181           1.429170\n",
            "17       25.466181           1.429170\n",
            "18       25.466181           1.429170\n",
            "19       25.466181           1.429170\n",
            "20       25.466181           1.429170\n",
            "21       25.466181           1.429170\n",
            "22       25.466181           1.429170\n",
            "23       25.466181           1.429170\n",
            "24       25.466181           1.429170\n",
            "25       25.466181           1.429170\n",
            "26       25.466181           1.429170\n",
            "27       25.466181           1.429170\n",
            "28       25.466181           1.429170\n",
            "29       25.466181           1.429170\n",
            "30       25.466181           1.429170\n",
            "31       25.466181           1.429170\n",
            "32       25.466181           1.429170\n",
            "33       25.466181           1.429170\n",
            "34       25.466181           1.429170\n",
            "35       25.466181           1.429170\n",
            "36       25.466181           1.429170\n",
            "37       25.466181           1.429170\n",
            "38       25.466181           1.429170\n",
            "39       25.466181           1.429170\n",
            "40       25.199160           2.473576\n",
            "41       25.199160           2.473576\n",
            "42       25.199160           2.473576\n",
            "43       25.199160           2.473576\n",
            "44       25.199160           2.473576\n",
            "45       24.930946           3.478738\n",
            "46       24.930946           3.478738\n",
            "47       24.930946           3.478738\n",
            "48       24.930946           3.478738\n",
            "49       24.930946           3.478738\n",
            "50       24.924721           3.473716\n",
            "51       24.924721           3.473716\n",
            "52       24.924721           3.473716\n",
            "53       24.924721           3.473716\n",
            "54       24.924721           3.473716\n",
            "55       24.898170           3.557746\n",
            "56       24.898170           3.557746\n",
            "57       24.898170           3.557746\n",
            "58       24.898170           3.557746\n",
            "59       24.898170           3.557746\n",
            "60       24.930853           3.478565\n",
            "61       24.930853           3.478565\n",
            "62       24.930853           3.478565\n",
            "63       24.930853           3.478565\n",
            "64       24.823786           1.998169\n",
            "65       24.823786           1.998169\n",
            "66       24.823786           1.998169\n",
            "67       24.823786           1.998169\n",
            "68       24.823786           1.998169\n",
            "69       24.823786           1.998169\n",
            "70       24.823786           1.998169\n",
            "71       24.823786           1.998169\n",
            "72       24.823786           1.998169\n",
            "73       24.823786           1.998169\n",
            "74       24.823252           1.997152\n",
            "75       24.823252           1.997152\n",
            "76       24.823252           1.997152\n",
            "77       24.823252           1.997152\n",
            "78       24.823252           1.997152\n",
            "79       24.823252           1.997152\n",
            "80       24.823252           1.997152\n",
            "81       24.823252           1.997152\n",
            "82       24.823252           1.997152\n",
            "83       24.823252           1.997152\n",
            "84       24.823252           1.997152\n",
            "85       24.823252           1.997152\n",
            "86       24.823252           1.997152\n",
            "87       24.823252           1.997152\n",
            "88       24.823252           1.997152\n",
            "89       24.823252           1.997152\n",
            "90       24.823252           1.997152\n",
            "91       24.823252           1.997152\n",
            "92       24.823252           1.997152\n",
            "93       24.823252           1.997152\n",
            "94       24.823252           1.997152\n",
            "95       24.823252           1.997152\n",
            "96       24.823252           1.997152\n",
            "97       24.823252           1.997152\n",
            "98       24.823252           1.997152\n",
            "99       24.823252           1.997152\n",
            "100      24.823252           1.997152\n",
            "101      24.823252           1.997152\n",
            "102      24.823252           1.997152\n",
            "103      24.823252           1.997152\n",
            "104      24.823252           1.997152\n",
            "105      24.823252           1.997152\n",
            "106      24.823252           1.997152\n",
            "107      24.823252           1.997152\n",
            "108      24.823252           1.997152\n",
            "RMSE: 1.6563216861335217\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2023-07-20 14:08:27.131268: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype double and shape [109,12]\n",
            "\t [[{{node Placeholder/_0}}]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3) Grouped, random"
      ],
      "metadata": {
        "id": "n8pNR1CrvF2a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "grouped_random = {\n",
        "    'TRAIN' : os.path.join(FP_ROOT, 'amazon_sample_data/uc_davis_2023_08_12_train_random_grouped.csv'),\n",
        "    'TEST' : os.path.join(FP_ROOT, 'amazon_sample_data/uc_davis_2023_08_12_test_random_grouped.csv'),\n",
        "    'VALIDATION' : os.path.join(FP_ROOT, 'amazon_sample_data/uc_davis_2023_08_12_validation_random_grouped.csv'),\n",
        "}\n",
        "\n",
        "grouped_random_scaled = load_and_scale(grouped_random)\n",
        "train_and_evaluate(grouped_random_scaled, \"grouped_random\", training_batch_size=3)"
      ],
      "metadata": {
        "id": "rPONfgkjvJWz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7a41df98-7237-444f-85cb-70bf09fdb1a0"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Epoch 221/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 13.4158 - val_loss: 11.8819\n",
            "Epoch 222/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 13.3559 - val_loss: 11.8281\n",
            "Epoch 223/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 13.3046 - val_loss: 11.7881\n",
            "Epoch 224/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 13.2484 - val_loss: 11.7686\n",
            "Epoch 225/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 13.1999 - val_loss: 11.7519\n",
            "Epoch 226/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 13.1496 - val_loss: 11.7114\n",
            "Epoch 227/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 13.0994 - val_loss: 11.6768\n",
            "Epoch 228/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 13.0524 - val_loss: 11.6370\n",
            "Epoch 229/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 12.9971 - val_loss: 11.6405\n",
            "Epoch 230/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 12.9439 - val_loss: 11.5990\n",
            "Epoch 231/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 12.8973 - val_loss: 11.5580\n",
            "Epoch 232/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 12.8510 - val_loss: 11.5210\n",
            "Epoch 233/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 12.7971 - val_loss: 11.5016\n",
            "Epoch 234/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 12.7499 - val_loss: 11.4715\n",
            "Epoch 235/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 12.7087 - val_loss: 11.4533\n",
            "Epoch 236/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 12.6589 - val_loss: 11.3909\n",
            "Epoch 237/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 12.6105 - val_loss: 11.3642\n",
            "Epoch 238/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 12.5632 - val_loss: 11.3530\n",
            "Epoch 239/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 12.5178 - val_loss: 11.3172\n",
            "Epoch 240/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 12.4746 - val_loss: 11.2758\n",
            "Epoch 241/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 12.4281 - val_loss: 11.2628\n",
            "Epoch 242/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 12.3822 - val_loss: 11.2276\n",
            "Epoch 243/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 12.3362 - val_loss: 11.1915\n",
            "Epoch 244/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 12.2957 - val_loss: 11.1650\n",
            "Epoch 245/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 12.2455 - val_loss: 11.1351\n",
            "Epoch 246/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 12.2029 - val_loss: 11.1119\n",
            "Epoch 247/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 12.1569 - val_loss: 11.0866\n",
            "Epoch 248/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 12.1152 - val_loss: 11.0533\n",
            "Epoch 249/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 12.0714 - val_loss: 11.0228\n",
            "Epoch 250/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 12.0287 - val_loss: 11.0000\n",
            "Epoch 251/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 11.9911 - val_loss: 10.9772\n",
            "Epoch 252/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 11.9450 - val_loss: 10.9402\n",
            "Epoch 253/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 11.9076 - val_loss: 10.9085\n",
            "Epoch 254/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 11.8672 - val_loss: 10.8825\n",
            "Epoch 255/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 11.8222 - val_loss: 10.8687\n",
            "Epoch 256/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 11.7765 - val_loss: 10.8319\n",
            "Epoch 257/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 11.7343 - val_loss: 10.8060\n",
            "Epoch 258/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 11.7000 - val_loss: 10.7795\n",
            "Epoch 259/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 11.6553 - val_loss: 10.7669\n",
            "Epoch 260/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 11.6239 - val_loss: 10.7116\n",
            "Epoch 261/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 11.5724 - val_loss: 10.6957\n",
            "Epoch 262/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 11.5428 - val_loss: 10.6896\n",
            "Epoch 263/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 11.5004 - val_loss: 10.6529\n",
            "Epoch 264/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 11.4626 - val_loss: 10.6372\n",
            "Epoch 265/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 11.4199 - val_loss: 10.5901\n",
            "Epoch 266/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 11.3807 - val_loss: 10.5688\n",
            "Epoch 267/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 11.3393 - val_loss: 10.5471\n",
            "Epoch 268/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 11.3071 - val_loss: 10.5199\n",
            "Epoch 269/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 11.2677 - val_loss: 10.5071\n",
            "Epoch 270/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 11.2265 - val_loss: 10.4738\n",
            "Epoch 271/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 11.1920 - val_loss: 10.4599\n",
            "Epoch 272/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 11.1579 - val_loss: 10.4375\n",
            "Epoch 273/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 11.1157 - val_loss: 10.4121\n",
            "Epoch 274/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 11.0831 - val_loss: 10.3663\n",
            "Epoch 275/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 11.0500 - val_loss: 10.3654\n",
            "Epoch 276/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 11.0083 - val_loss: 10.3241\n",
            "Epoch 277/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 10.9741 - val_loss: 10.3034\n",
            "Epoch 278/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 10.9412 - val_loss: 10.2989\n",
            "Epoch 279/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 10.9052 - val_loss: 10.2671\n",
            "Epoch 280/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 10.8802 - val_loss: 10.2149\n",
            "Epoch 281/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 10.8366 - val_loss: 10.2176\n",
            "Epoch 282/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 10.7962 - val_loss: 10.1930\n",
            "Epoch 283/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 10.7677 - val_loss: 10.1779\n",
            "Epoch 284/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 10.7316 - val_loss: 10.1434\n",
            "Epoch 285/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 10.6958 - val_loss: 10.1319\n",
            "Epoch 286/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 10.6642 - val_loss: 10.0920\n",
            "Epoch 287/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 10.6285 - val_loss: 10.0787\n",
            "Epoch 288/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 10.5978 - val_loss: 10.0418\n",
            "Epoch 289/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 10.5589 - val_loss: 10.0189\n",
            "Epoch 290/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 10.5306 - val_loss: 10.0004\n",
            "Epoch 291/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 10.4953 - val_loss: 9.9907\n",
            "Epoch 292/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 10.4640 - val_loss: 9.9625\n",
            "Epoch 293/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 10.4343 - val_loss: 9.9534\n",
            "Epoch 294/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 10.3979 - val_loss: 9.9121\n",
            "Epoch 295/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 10.3706 - val_loss: 9.8773\n",
            "Epoch 296/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 10.3364 - val_loss: 9.8653\n",
            "Epoch 297/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 10.3029 - val_loss: 9.8421\n",
            "Epoch 298/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 10.2760 - val_loss: 9.8301\n",
            "Epoch 299/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 10.2395 - val_loss: 9.8013\n",
            "Epoch 300/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 10.2092 - val_loss: 9.7719\n",
            "Epoch 301/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 10.1840 - val_loss: 9.7687\n",
            "Epoch 302/5000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 10.1414 - val_loss: 9.7386\n",
            "Epoch 303/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 10.1150 - val_loss: 9.7065\n",
            "Epoch 304/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 10.0859 - val_loss: 9.6776\n",
            "Epoch 305/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 10.0547 - val_loss: 9.6711\n",
            "Epoch 306/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 10.0207 - val_loss: 9.6439\n",
            "Epoch 307/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 9.9910 - val_loss: 9.6159\n",
            "Epoch 308/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 9.9630 - val_loss: 9.5907\n",
            "Epoch 309/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 9.9306 - val_loss: 9.5660\n",
            "Epoch 310/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 9.8999 - val_loss: 9.5569\n",
            "Epoch 311/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 9.8701 - val_loss: 9.5378\n",
            "Epoch 312/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 9.8406 - val_loss: 9.5183\n",
            "Epoch 313/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 9.8118 - val_loss: 9.4743\n",
            "Epoch 314/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 9.7862 - val_loss: 9.4523\n",
            "Epoch 315/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 9.7536 - val_loss: 9.4470\n",
            "Epoch 316/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 9.7225 - val_loss: 9.4148\n",
            "Epoch 317/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 9.6948 - val_loss: 9.4037\n",
            "Epoch 318/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 9.6701 - val_loss: 9.3830\n",
            "Epoch 319/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 9.6362 - val_loss: 9.3597\n",
            "Epoch 320/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 9.6051 - val_loss: 9.3388\n",
            "Epoch 321/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 9.5832 - val_loss: 9.3279\n",
            "Epoch 322/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 9.5540 - val_loss: 9.2970\n",
            "Epoch 323/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 9.5209 - val_loss: 9.2788\n",
            "Epoch 324/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 9.5001 - val_loss: 9.2497\n",
            "Epoch 325/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 9.4670 - val_loss: 9.2332\n",
            "Epoch 326/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 9.4389 - val_loss: 9.2177\n",
            "Epoch 327/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 9.4147 - val_loss: 9.1977\n",
            "Epoch 328/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 9.3863 - val_loss: 9.1727\n",
            "Epoch 329/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 9.3595 - val_loss: 9.1481\n",
            "Epoch 330/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 9.3290 - val_loss: 9.1296\n",
            "Epoch 331/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 9.3022 - val_loss: 9.1068\n",
            "Epoch 332/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 9.2780 - val_loss: 9.0965\n",
            "Epoch 333/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 9.2550 - val_loss: 9.0601\n",
            "Epoch 334/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 9.2261 - val_loss: 9.0493\n",
            "Epoch 335/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 9.1973 - val_loss: 9.0259\n",
            "Epoch 336/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 9.1722 - val_loss: 9.0208\n",
            "Epoch 337/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 9.1464 - val_loss: 9.0001\n",
            "Epoch 338/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 9.1203 - val_loss: 8.9876\n",
            "Epoch 339/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 9.0985 - val_loss: 8.9645\n",
            "Epoch 340/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 9.0691 - val_loss: 8.9434\n",
            "Epoch 341/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 9.0415 - val_loss: 8.9319\n",
            "Epoch 342/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 9.0192 - val_loss: 8.9190\n",
            "Epoch 343/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 8.9946 - val_loss: 8.8923\n",
            "Epoch 344/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 8.9703 - val_loss: 8.8663\n",
            "Epoch 345/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 8.9461 - val_loss: 8.8615\n",
            "Epoch 346/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 8.9221 - val_loss: 8.8315\n",
            "Epoch 347/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 8.8936 - val_loss: 8.8160\n",
            "Epoch 348/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 8.8702 - val_loss: 8.8040\n",
            "Epoch 349/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 8.8474 - val_loss: 8.7789\n",
            "Epoch 350/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 8.8217 - val_loss: 8.7541\n",
            "Epoch 351/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 8.7982 - val_loss: 8.7540\n",
            "Epoch 352/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 8.7725 - val_loss: 8.7255\n",
            "Epoch 353/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 8.7506 - val_loss: 8.6969\n",
            "Epoch 354/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 8.7251 - val_loss: 8.6949\n",
            "Epoch 355/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 8.7017 - val_loss: 8.6691\n",
            "Epoch 356/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 8.6750 - val_loss: 8.6549\n",
            "Epoch 357/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 8.6526 - val_loss: 8.6493\n",
            "Epoch 358/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 8.6279 - val_loss: 8.6269\n",
            "Epoch 359/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 8.6054 - val_loss: 8.6034\n",
            "Epoch 360/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 8.5824 - val_loss: 8.5845\n",
            "Epoch 361/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 8.5573 - val_loss: 8.5635\n",
            "Epoch 362/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 8.5345 - val_loss: 8.5437\n",
            "Epoch 363/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 8.5105 - val_loss: 8.5316\n",
            "Epoch 364/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 8.4881 - val_loss: 8.5189\n",
            "Epoch 365/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 8.4684 - val_loss: 8.4883\n",
            "Epoch 366/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 8.4422 - val_loss: 8.4787\n",
            "Epoch 367/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 8.4238 - val_loss: 8.4541\n",
            "Epoch 368/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 8.3956 - val_loss: 8.4509\n",
            "Epoch 369/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 8.3731 - val_loss: 8.4293\n",
            "Epoch 370/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 8.3512 - val_loss: 8.4056\n",
            "Epoch 371/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 8.3291 - val_loss: 8.3959\n",
            "Epoch 372/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 8.3066 - val_loss: 8.3833\n",
            "Epoch 373/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 8.2864 - val_loss: 8.3675\n",
            "Epoch 374/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 8.2614 - val_loss: 8.3475\n",
            "Epoch 375/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 8.2392 - val_loss: 8.3318\n",
            "Epoch 376/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 8.2176 - val_loss: 8.3072\n",
            "Epoch 377/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 8.1991 - val_loss: 8.2832\n",
            "Epoch 378/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 8.1765 - val_loss: 8.2737\n",
            "Epoch 379/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 8.1548 - val_loss: 8.2599\n",
            "Epoch 380/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 8.1282 - val_loss: 8.2359\n",
            "Epoch 381/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 8.1083 - val_loss: 8.2207\n",
            "Epoch 382/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 8.0868 - val_loss: 8.2098\n",
            "Epoch 383/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 8.0676 - val_loss: 8.1821\n",
            "Epoch 384/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 8.0445 - val_loss: 8.1622\n",
            "Epoch 385/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 8.0204 - val_loss: 8.1577\n",
            "Epoch 386/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 8.0016 - val_loss: 8.1352\n",
            "Epoch 387/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 7.9820 - val_loss: 8.1274\n",
            "Epoch 388/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 7.9614 - val_loss: 8.1021\n",
            "Epoch 389/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 7.9350 - val_loss: 8.0798\n",
            "Epoch 390/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 7.9185 - val_loss: 8.0750\n",
            "Epoch 391/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 7.8984 - val_loss: 8.0370\n",
            "Epoch 392/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 7.8759 - val_loss: 8.0237\n",
            "Epoch 393/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 7.8520 - val_loss: 8.0243\n",
            "Epoch 394/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 7.8289 - val_loss: 8.0030\n",
            "Epoch 395/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 7.8094 - val_loss: 7.9834\n",
            "Epoch 396/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 7.7883 - val_loss: 7.9752\n",
            "Epoch 397/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 7.7712 - val_loss: 7.9410\n",
            "Epoch 398/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 7.7484 - val_loss: 7.9415\n",
            "Epoch 399/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 7.7260 - val_loss: 7.9224\n",
            "Epoch 400/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 7.7080 - val_loss: 7.9051\n",
            "Epoch 401/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 7.6862 - val_loss: 7.8868\n",
            "Epoch 402/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 7.6682 - val_loss: 7.8613\n",
            "Epoch 403/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 7.6495 - val_loss: 7.8676\n",
            "Epoch 404/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 7.6263 - val_loss: 7.8430\n",
            "Epoch 405/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 7.6056 - val_loss: 7.8234\n",
            "Epoch 406/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 7.5863 - val_loss: 7.7971\n",
            "Epoch 407/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 7.5654 - val_loss: 7.7920\n",
            "Epoch 408/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 7.5436 - val_loss: 7.7667\n",
            "Epoch 409/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 7.5255 - val_loss: 7.7493\n",
            "Epoch 410/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 7.5107 - val_loss: 7.7403\n",
            "Epoch 411/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 7.4879 - val_loss: 7.7089\n",
            "Epoch 412/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 7.4661 - val_loss: 7.7062\n",
            "Epoch 413/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 7.4489 - val_loss: 7.6891\n",
            "Epoch 414/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 7.4296 - val_loss: 7.6726\n",
            "Epoch 415/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 7.4066 - val_loss: 7.6543\n",
            "Epoch 416/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 7.3911 - val_loss: 7.6327\n",
            "Epoch 417/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 7.3708 - val_loss: 7.6275\n",
            "Epoch 418/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 7.3513 - val_loss: 7.5983\n",
            "Epoch 419/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 7.3301 - val_loss: 7.5851\n",
            "Epoch 420/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 7.3132 - val_loss: 7.5817\n",
            "Epoch 421/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 7.2929 - val_loss: 7.5622\n",
            "Epoch 422/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 7.2754 - val_loss: 7.5293\n",
            "Epoch 423/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 7.2549 - val_loss: 7.5297\n",
            "Epoch 424/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 7.2338 - val_loss: 7.5140\n",
            "Epoch 425/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 7.2190 - val_loss: 7.4946\n",
            "Epoch 426/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 7.1970 - val_loss: 7.4803\n",
            "Epoch 427/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 7.1767 - val_loss: 7.4619\n",
            "Epoch 428/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 7.1632 - val_loss: 7.4455\n",
            "Epoch 429/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 7.1417 - val_loss: 7.4336\n",
            "Epoch 430/5000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 7.1225 - val_loss: 7.4126\n",
            "Epoch 431/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 7.1029 - val_loss: 7.3978\n",
            "Epoch 432/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 7.0851 - val_loss: 7.3788\n",
            "Epoch 433/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 7.0669 - val_loss: 7.3652\n",
            "Epoch 434/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 7.0490 - val_loss: 7.3416\n",
            "Epoch 435/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 7.0326 - val_loss: 7.3267\n",
            "Epoch 436/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 7.0120 - val_loss: 7.3169\n",
            "Epoch 437/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 6.9946 - val_loss: 7.2936\n",
            "Epoch 438/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 6.9740 - val_loss: 7.2842\n",
            "Epoch 439/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 6.9592 - val_loss: 7.2733\n",
            "Epoch 440/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 6.9390 - val_loss: 7.2596\n",
            "Epoch 441/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 6.9249 - val_loss: 7.2357\n",
            "Epoch 442/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 6.9043 - val_loss: 7.2286\n",
            "Epoch 443/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 6.8892 - val_loss: 7.2001\n",
            "Epoch 444/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 6.8709 - val_loss: 7.1917\n",
            "Epoch 445/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 6.8528 - val_loss: 7.1843\n",
            "Epoch 446/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 6.8337 - val_loss: 7.1584\n",
            "Epoch 447/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 6.8165 - val_loss: 7.1462\n",
            "Epoch 448/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 6.7979 - val_loss: 7.1312\n",
            "Epoch 449/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 6.7791 - val_loss: 7.1146\n",
            "Epoch 450/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 6.7623 - val_loss: 7.0981\n",
            "Epoch 451/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 6.7464 - val_loss: 7.0951\n",
            "Epoch 452/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 6.7300 - val_loss: 7.0643\n",
            "Epoch 453/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 6.7114 - val_loss: 7.0616\n",
            "Epoch 454/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 6.6946 - val_loss: 7.0346\n",
            "Epoch 455/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 6.6768 - val_loss: 7.0211\n",
            "Epoch 456/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 6.6583 - val_loss: 7.0076\n",
            "Epoch 457/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 6.6406 - val_loss: 6.9950\n",
            "Epoch 458/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 6.6244 - val_loss: 6.9795\n",
            "Epoch 459/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 6.6119 - val_loss: 6.9552\n",
            "Epoch 460/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 6.5923 - val_loss: 6.9531\n",
            "Epoch 461/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 6.5751 - val_loss: 6.9251\n",
            "Epoch 462/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 6.5591 - val_loss: 6.9264\n",
            "Epoch 463/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 6.5406 - val_loss: 6.9076\n",
            "Epoch 464/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 6.5227 - val_loss: 6.8960\n",
            "Epoch 465/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 6.5077 - val_loss: 6.8735\n",
            "Epoch 466/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 6.4902 - val_loss: 6.8591\n",
            "Epoch 467/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 6.4730 - val_loss: 6.8485\n",
            "Epoch 468/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 6.4572 - val_loss: 6.8246\n",
            "Epoch 469/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 6.4405 - val_loss: 6.8088\n",
            "Epoch 470/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 6.4219 - val_loss: 6.8007\n",
            "Epoch 471/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 6.4088 - val_loss: 6.7788\n",
            "Epoch 472/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 6.3890 - val_loss: 6.7735\n",
            "Epoch 473/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 6.3747 - val_loss: 6.7588\n",
            "Epoch 474/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 6.3577 - val_loss: 6.7435\n",
            "Epoch 475/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 6.3438 - val_loss: 6.7293\n",
            "Epoch 476/5000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 6.3252 - val_loss: 6.7216\n",
            "Epoch 477/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 6.3134 - val_loss: 6.6848\n",
            "Epoch 478/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 6.2928 - val_loss: 6.6774\n",
            "Epoch 479/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 6.2769 - val_loss: 6.6741\n",
            "Epoch 480/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 6.2638 - val_loss: 6.6467\n",
            "Epoch 481/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 6.2445 - val_loss: 6.6282\n",
            "Epoch 482/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 6.2304 - val_loss: 6.6253\n",
            "Epoch 483/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 6.2142 - val_loss: 6.6074\n",
            "Epoch 484/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 6.1987 - val_loss: 6.5959\n",
            "Epoch 485/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 6.1822 - val_loss: 6.5828\n",
            "Epoch 486/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 6.1672 - val_loss: 6.5660\n",
            "Epoch 487/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 6.1533 - val_loss: 6.5388\n",
            "Epoch 488/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 6.1355 - val_loss: 6.5308\n",
            "Epoch 489/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 6.1221 - val_loss: 6.5163\n",
            "Epoch 490/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 6.1053 - val_loss: 6.5190\n",
            "Epoch 491/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 6.0888 - val_loss: 6.4945\n",
            "Epoch 492/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 6.0728 - val_loss: 6.4801\n",
            "Epoch 493/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 6.0580 - val_loss: 6.4722\n",
            "Epoch 494/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 6.0407 - val_loss: 6.4599\n",
            "Epoch 495/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 6.0265 - val_loss: 6.4393\n",
            "Epoch 496/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 6.0143 - val_loss: 6.4273\n",
            "Epoch 497/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 6.0013 - val_loss: 6.4115\n",
            "Epoch 498/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 5.9823 - val_loss: 6.3995\n",
            "Epoch 499/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 5.9661 - val_loss: 6.3889\n",
            "Epoch 500/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 5.9545 - val_loss: 6.3642\n",
            "Epoch 501/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 5.9376 - val_loss: 6.3590\n",
            "Epoch 502/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 5.9231 - val_loss: 6.3493\n",
            "Epoch 503/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 5.9089 - val_loss: 6.3252\n",
            "Epoch 504/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 5.8933 - val_loss: 6.3169\n",
            "Epoch 505/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 5.8767 - val_loss: 6.3042\n",
            "Epoch 506/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 5.8624 - val_loss: 6.2875\n",
            "Epoch 507/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 5.8480 - val_loss: 6.2702\n",
            "Epoch 508/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 5.8375 - val_loss: 6.2675\n",
            "Epoch 509/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 5.8207 - val_loss: 6.2449\n",
            "Epoch 510/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 5.8055 - val_loss: 6.2349\n",
            "Epoch 511/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 5.7933 - val_loss: 6.2182\n",
            "Epoch 512/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 5.7768 - val_loss: 6.2110\n",
            "Epoch 513/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 5.7623 - val_loss: 6.1940\n",
            "Epoch 514/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 5.7491 - val_loss: 6.1873\n",
            "Epoch 515/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 5.7322 - val_loss: 6.1664\n",
            "Epoch 516/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 5.7203 - val_loss: 6.1543\n",
            "Epoch 517/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 5.7066 - val_loss: 6.1487\n",
            "Epoch 518/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 5.6937 - val_loss: 6.1293\n",
            "Epoch 519/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 5.6792 - val_loss: 6.1156\n",
            "Epoch 520/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 5.6637 - val_loss: 6.0967\n",
            "Epoch 521/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 5.6506 - val_loss: 6.0890\n",
            "Epoch 522/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 5.6371 - val_loss: 6.0725\n",
            "Epoch 523/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 5.6238 - val_loss: 6.0555\n",
            "Epoch 524/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 5.6122 - val_loss: 6.0505\n",
            "Epoch 525/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 5.6007 - val_loss: 6.0334\n",
            "Epoch 526/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 5.5844 - val_loss: 6.0179\n",
            "Epoch 527/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 5.5705 - val_loss: 6.0051\n",
            "Epoch 528/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 5.5568 - val_loss: 5.9957\n",
            "Epoch 529/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 5.5471 - val_loss: 5.9808\n",
            "Epoch 530/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 5.5326 - val_loss: 5.9673\n",
            "Epoch 531/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 5.5191 - val_loss: 5.9584\n",
            "Epoch 532/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 5.5056 - val_loss: 5.9413\n",
            "Epoch 533/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 5.4959 - val_loss: 5.9309\n",
            "Epoch 534/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 5.4809 - val_loss: 5.9186\n",
            "Epoch 535/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 5.4678 - val_loss: 5.9167\n",
            "Epoch 536/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 5.4565 - val_loss: 5.9020\n",
            "Epoch 537/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 5.4441 - val_loss: 5.8714\n",
            "Epoch 538/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 5.4293 - val_loss: 5.8642\n",
            "Epoch 539/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 5.4183 - val_loss: 5.8511\n",
            "Epoch 540/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 5.4021 - val_loss: 5.8429\n",
            "Epoch 541/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 5.3909 - val_loss: 5.8309\n",
            "Epoch 542/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 5.3801 - val_loss: 5.8238\n",
            "Epoch 543/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 5.3659 - val_loss: 5.8013\n",
            "Epoch 544/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 5.3546 - val_loss: 5.7875\n",
            "Epoch 545/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 5.3408 - val_loss: 5.7731\n",
            "Epoch 546/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 5.3281 - val_loss: 5.7652\n",
            "Epoch 547/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 5.3162 - val_loss: 5.7459\n",
            "Epoch 548/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 5.3041 - val_loss: 5.7346\n",
            "Epoch 549/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 5.2926 - val_loss: 5.7309\n",
            "Epoch 550/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 5.2792 - val_loss: 5.7085\n",
            "Epoch 551/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 5.2677 - val_loss: 5.7091\n",
            "Epoch 552/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 5.2565 - val_loss: 5.6859\n",
            "Epoch 553/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 5.2433 - val_loss: 5.6788\n",
            "Epoch 554/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 5.2294 - val_loss: 5.6680\n",
            "Epoch 555/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 5.2178 - val_loss: 5.6554\n",
            "Epoch 556/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 5.2053 - val_loss: 5.6419\n",
            "Epoch 557/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 5.1933 - val_loss: 5.6290\n",
            "Epoch 558/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 5.1818 - val_loss: 5.6182\n",
            "Epoch 559/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 5.1704 - val_loss: 5.6000\n",
            "Epoch 560/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 5.1587 - val_loss: 5.5922\n",
            "Epoch 561/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 5.1473 - val_loss: 5.5833\n",
            "Epoch 562/5000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 5.1367 - val_loss: 5.5726\n",
            "Epoch 563/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 5.1198 - val_loss: 5.5562\n",
            "Epoch 564/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 5.1118 - val_loss: 5.5496\n",
            "Epoch 565/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 5.0975 - val_loss: 5.5352\n",
            "Epoch 566/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 5.0865 - val_loss: 5.5131\n",
            "Epoch 567/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 5.0748 - val_loss: 5.5101\n",
            "Epoch 568/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 5.0611 - val_loss: 5.4937\n",
            "Epoch 569/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 5.0503 - val_loss: 5.4784\n",
            "Epoch 570/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 5.0389 - val_loss: 5.4723\n",
            "Epoch 571/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 5.0280 - val_loss: 5.4625\n",
            "Epoch 572/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 5.0161 - val_loss: 5.4500\n",
            "Epoch 573/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 5.0035 - val_loss: 5.4335\n",
            "Epoch 574/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 4.9925 - val_loss: 5.4180\n",
            "Epoch 575/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 4.9812 - val_loss: 5.4069\n",
            "Epoch 576/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 4.9690 - val_loss: 5.4045\n",
            "Epoch 577/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 4.9600 - val_loss: 5.3933\n",
            "Epoch 578/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 4.9489 - val_loss: 5.3787\n",
            "Epoch 579/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 4.9374 - val_loss: 5.3666\n",
            "Epoch 580/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 4.9258 - val_loss: 5.3477\n",
            "Epoch 581/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 4.9143 - val_loss: 5.3416\n",
            "Epoch 582/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 4.9031 - val_loss: 5.3330\n",
            "Epoch 583/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 4.8938 - val_loss: 5.3216\n",
            "Epoch 584/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 4.8808 - val_loss: 5.3076\n",
            "Epoch 585/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 4.8714 - val_loss: 5.2902\n",
            "Epoch 586/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 4.8583 - val_loss: 5.2873\n",
            "Epoch 587/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 4.8482 - val_loss: 5.2716\n",
            "Epoch 588/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 4.8367 - val_loss: 5.2692\n",
            "Epoch 589/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 4.8267 - val_loss: 5.2527\n",
            "Epoch 590/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 4.8177 - val_loss: 5.2336\n",
            "Epoch 591/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 4.8056 - val_loss: 5.2197\n",
            "Epoch 592/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 4.8005 - val_loss: 5.2201\n",
            "Epoch 593/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 4.7847 - val_loss: 5.2020\n",
            "Epoch 594/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 4.7716 - val_loss: 5.1931\n",
            "Epoch 595/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 4.7626 - val_loss: 5.1853\n",
            "Epoch 596/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 4.7489 - val_loss: 5.1712\n",
            "Epoch 597/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 4.7407 - val_loss: 5.1573\n",
            "Epoch 598/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 4.7283 - val_loss: 5.1466\n",
            "Epoch 599/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 4.7166 - val_loss: 5.1375\n",
            "Epoch 600/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 4.7074 - val_loss: 5.1215\n",
            "Epoch 601/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 4.6979 - val_loss: 5.1130\n",
            "Epoch 602/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 4.6852 - val_loss: 5.1040\n",
            "Epoch 603/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 4.6750 - val_loss: 5.0919\n",
            "Epoch 604/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 4.6648 - val_loss: 5.0753\n",
            "Epoch 605/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 4.6537 - val_loss: 5.0760\n",
            "Epoch 606/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 4.6431 - val_loss: 5.0659\n",
            "Epoch 607/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 4.6352 - val_loss: 5.0445\n",
            "Epoch 608/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 4.6254 - val_loss: 5.0407\n",
            "Epoch 609/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 4.6135 - val_loss: 5.0208\n",
            "Epoch 610/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 4.6034 - val_loss: 5.0162\n",
            "Epoch 611/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 4.5918 - val_loss: 5.0017\n",
            "Epoch 612/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 4.5832 - val_loss: 4.9983\n",
            "Epoch 613/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 4.5719 - val_loss: 4.9758\n",
            "Epoch 614/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 4.5631 - val_loss: 4.9741\n",
            "Epoch 615/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 4.5506 - val_loss: 4.9612\n",
            "Epoch 616/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 4.5412 - val_loss: 4.9483\n",
            "Epoch 617/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 4.5308 - val_loss: 4.9385\n",
            "Epoch 618/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 4.5205 - val_loss: 4.9277\n",
            "Epoch 619/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 4.5099 - val_loss: 4.9120\n",
            "Epoch 620/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 4.4989 - val_loss: 4.9078\n",
            "Epoch 621/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 4.4899 - val_loss: 4.8954\n",
            "Epoch 622/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 4.4805 - val_loss: 4.8850\n",
            "Epoch 623/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 4.4719 - val_loss: 4.8774\n",
            "Epoch 624/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 4.4598 - val_loss: 4.8635\n",
            "Epoch 625/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 4.4499 - val_loss: 4.8510\n",
            "Epoch 626/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 4.4405 - val_loss: 4.8449\n",
            "Epoch 627/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 4.4293 - val_loss: 4.8349\n",
            "Epoch 628/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 4.4188 - val_loss: 4.8243\n",
            "Epoch 629/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 4.4101 - val_loss: 4.8039\n",
            "Epoch 630/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 4.4001 - val_loss: 4.8003\n",
            "Epoch 631/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 4.3905 - val_loss: 4.7888\n",
            "Epoch 632/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 4.3794 - val_loss: 4.7786\n",
            "Epoch 633/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 4.3718 - val_loss: 4.7728\n",
            "Epoch 634/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 4.3596 - val_loss: 4.7611\n",
            "Epoch 635/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 4.3489 - val_loss: 4.7532\n",
            "Epoch 636/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 4.3408 - val_loss: 4.7427\n",
            "Epoch 637/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 4.3311 - val_loss: 4.7306\n",
            "Epoch 638/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 4.3191 - val_loss: 4.7202\n",
            "Epoch 639/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 4.3132 - val_loss: 4.7086\n",
            "Epoch 640/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 4.3016 - val_loss: 4.6988\n",
            "Epoch 641/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 4.2932 - val_loss: 4.6872\n",
            "Epoch 642/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 4.2851 - val_loss: 4.6751\n",
            "Epoch 643/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 4.2736 - val_loss: 4.6678\n",
            "Epoch 644/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 4.2630 - val_loss: 4.6619\n",
            "Epoch 645/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 4.2543 - val_loss: 4.6482\n",
            "Epoch 646/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 4.2449 - val_loss: 4.6381\n",
            "Epoch 647/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 4.2365 - val_loss: 4.6297\n",
            "Epoch 648/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 4.2252 - val_loss: 4.6181\n",
            "Epoch 649/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 4.2146 - val_loss: 4.6074\n",
            "Epoch 650/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 4.2057 - val_loss: 4.6036\n",
            "Epoch 651/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 4.1959 - val_loss: 4.5914\n",
            "Epoch 652/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 4.1890 - val_loss: 4.5777\n",
            "Epoch 653/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 4.1773 - val_loss: 4.5754\n",
            "Epoch 654/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 4.1664 - val_loss: 4.5620\n",
            "Epoch 655/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 4.1568 - val_loss: 4.5493\n",
            "Epoch 656/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 4.1477 - val_loss: 4.5454\n",
            "Epoch 657/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 4.1402 - val_loss: 4.5270\n",
            "Epoch 658/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 4.1312 - val_loss: 4.5253\n",
            "Epoch 659/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 4.1204 - val_loss: 4.5128\n",
            "Epoch 660/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 4.1102 - val_loss: 4.5018\n",
            "Epoch 661/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 4.1018 - val_loss: 4.4916\n",
            "Epoch 662/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 4.0951 - val_loss: 4.4837\n",
            "Epoch 663/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 4.0837 - val_loss: 4.4687\n",
            "Epoch 664/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 4.0770 - val_loss: 4.4587\n",
            "Epoch 665/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 4.0676 - val_loss: 4.4520\n",
            "Epoch 666/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 4.0563 - val_loss: 4.4499\n",
            "Epoch 667/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 4.0462 - val_loss: 4.4352\n",
            "Epoch 668/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 4.0390 - val_loss: 4.4248\n",
            "Epoch 669/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 4.0278 - val_loss: 4.4199\n",
            "Epoch 670/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 4.0183 - val_loss: 4.4094\n",
            "Epoch 671/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 4.0102 - val_loss: 4.3986\n",
            "Epoch 672/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 3.9998 - val_loss: 4.3901\n",
            "Epoch 673/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 3.9909 - val_loss: 4.3809\n",
            "Epoch 674/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 3.9848 - val_loss: 4.3747\n",
            "Epoch 675/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 3.9756 - val_loss: 4.3584\n",
            "Epoch 676/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 3.9638 - val_loss: 4.3504\n",
            "Epoch 677/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 3.9586 - val_loss: 4.3424\n",
            "Epoch 678/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 3.9453 - val_loss: 4.3334\n",
            "Epoch 679/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 3.9420 - val_loss: 4.3259\n",
            "Epoch 680/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 3.9296 - val_loss: 4.3172\n",
            "Epoch 681/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 3.9190 - val_loss: 4.3066\n",
            "Epoch 682/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 3.9114 - val_loss: 4.2975\n",
            "Epoch 683/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 3.9024 - val_loss: 4.2875\n",
            "Epoch 684/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 3.8943 - val_loss: 4.2766\n",
            "Epoch 685/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 3.8849 - val_loss: 4.2657\n",
            "Epoch 686/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 3.8753 - val_loss: 4.2589\n",
            "Epoch 687/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 3.8659 - val_loss: 4.2530\n",
            "Epoch 688/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 3.8584 - val_loss: 4.2438\n",
            "Epoch 689/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 3.8490 - val_loss: 4.2376\n",
            "Epoch 690/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 3.8424 - val_loss: 4.2254\n",
            "Epoch 691/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 3.8323 - val_loss: 4.2150\n",
            "Epoch 692/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 3.8216 - val_loss: 4.2052\n",
            "Epoch 693/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 3.8155 - val_loss: 4.2006\n",
            "Epoch 694/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 3.8051 - val_loss: 4.1861\n",
            "Epoch 695/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 3.7960 - val_loss: 4.1820\n",
            "Epoch 696/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 3.7881 - val_loss: 4.1691\n",
            "Epoch 697/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 3.7804 - val_loss: 4.1607\n",
            "Epoch 698/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 3.7709 - val_loss: 4.1546\n",
            "Epoch 699/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 3.7620 - val_loss: 4.1419\n",
            "Epoch 700/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 3.7537 - val_loss: 4.1374\n",
            "Epoch 701/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 3.7451 - val_loss: 4.1271\n",
            "Epoch 702/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 3.7375 - val_loss: 4.1166\n",
            "Epoch 703/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 3.7308 - val_loss: 4.1079\n",
            "Epoch 704/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 3.7218 - val_loss: 4.1047\n",
            "Epoch 705/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 3.7120 - val_loss: 4.0888\n",
            "Epoch 706/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 3.7040 - val_loss: 4.0853\n",
            "Epoch 707/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 3.6949 - val_loss: 4.0749\n",
            "Epoch 708/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 3.6873 - val_loss: 4.0624\n",
            "Epoch 709/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 3.6777 - val_loss: 4.0600\n",
            "Epoch 710/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 3.6706 - val_loss: 4.0427\n",
            "Epoch 711/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 3.6629 - val_loss: 4.0366\n",
            "Epoch 712/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 3.6524 - val_loss: 4.0300\n",
            "Epoch 713/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 3.6469 - val_loss: 4.0220\n",
            "Epoch 714/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 3.6376 - val_loss: 4.0177\n",
            "Epoch 715/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 3.6288 - val_loss: 4.0070\n",
            "Epoch 716/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 3.6201 - val_loss: 3.9950\n",
            "Epoch 717/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 3.6117 - val_loss: 3.9876\n",
            "Epoch 718/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 3.6040 - val_loss: 3.9830\n",
            "Epoch 719/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 3.5952 - val_loss: 3.9718\n",
            "Epoch 720/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 3.5863 - val_loss: 3.9662\n",
            "Epoch 721/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 3.5794 - val_loss: 3.9552\n",
            "Epoch 722/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 3.5721 - val_loss: 3.9453\n",
            "Epoch 723/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 3.5644 - val_loss: 3.9401\n",
            "Epoch 724/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 3.5571 - val_loss: 3.9349\n",
            "Epoch 725/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 3.5485 - val_loss: 3.9220\n",
            "Epoch 726/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 3.5398 - val_loss: 3.9164\n",
            "Epoch 727/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 3.5317 - val_loss: 3.9114\n",
            "Epoch 728/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 3.5239 - val_loss: 3.9028\n",
            "Epoch 729/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 3.5156 - val_loss: 3.8921\n",
            "Epoch 730/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 3.5057 - val_loss: 3.8818\n",
            "Epoch 731/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 3.5009 - val_loss: 3.8729\n",
            "Epoch 732/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 3.4906 - val_loss: 3.8696\n",
            "Epoch 733/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 3.4826 - val_loss: 3.8625\n",
            "Epoch 734/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 3.4758 - val_loss: 3.8533\n",
            "Epoch 735/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 3.4665 - val_loss: 3.8458\n",
            "Epoch 736/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 3.4596 - val_loss: 3.8408\n",
            "Epoch 737/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 3.4539 - val_loss: 3.8285\n",
            "Epoch 738/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 3.4447 - val_loss: 3.8220\n",
            "Epoch 739/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 3.4397 - val_loss: 3.8097\n",
            "Epoch 740/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 3.4288 - val_loss: 3.8036\n",
            "Epoch 741/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 3.4203 - val_loss: 3.7977\n",
            "Epoch 742/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 3.4143 - val_loss: 3.7846\n",
            "Epoch 743/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 3.4063 - val_loss: 3.7820\n",
            "Epoch 744/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 3.3981 - val_loss: 3.7747\n",
            "Epoch 745/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 3.3898 - val_loss: 3.7664\n",
            "Epoch 746/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 3.3845 - val_loss: 3.7555\n",
            "Epoch 747/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 3.3756 - val_loss: 3.7476\n",
            "Epoch 748/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 3.3666 - val_loss: 3.7442\n",
            "Epoch 749/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 3.3599 - val_loss: 3.7353\n",
            "Epoch 750/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 3.3524 - val_loss: 3.7303\n",
            "Epoch 751/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 3.3439 - val_loss: 3.7236\n",
            "Epoch 752/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 3.3374 - val_loss: 3.7143\n",
            "Epoch 753/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 3.3288 - val_loss: 3.7064\n",
            "Epoch 754/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 3.3241 - val_loss: 3.6981\n",
            "Epoch 755/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 3.3147 - val_loss: 3.6916\n",
            "Epoch 756/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 3.3089 - val_loss: 3.6847\n",
            "Epoch 757/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 3.3018 - val_loss: 3.6732\n",
            "Epoch 758/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 3.2924 - val_loss: 3.6720\n",
            "Epoch 759/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 3.2847 - val_loss: 3.6606\n",
            "Epoch 760/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 3.2771 - val_loss: 3.6571\n",
            "Epoch 761/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 3.2719 - val_loss: 3.6443\n",
            "Epoch 762/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 3.2637 - val_loss: 3.6415\n",
            "Epoch 763/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 3.2570 - val_loss: 3.6361\n",
            "Epoch 764/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 3.2472 - val_loss: 3.6288\n",
            "Epoch 765/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 3.2406 - val_loss: 3.6171\n",
            "Epoch 766/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 3.2317 - val_loss: 3.6110\n",
            "Epoch 767/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 3.2256 - val_loss: 3.6052\n",
            "Epoch 768/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 3.2203 - val_loss: 3.5990\n",
            "Epoch 769/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 3.2140 - val_loss: 3.5905\n",
            "Epoch 770/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 3.2053 - val_loss: 3.5839\n",
            "Epoch 771/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 3.1956 - val_loss: 3.5761\n",
            "Epoch 772/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 3.1890 - val_loss: 3.5709\n",
            "Epoch 773/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 3.1838 - val_loss: 3.5655\n",
            "Epoch 774/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 3.1758 - val_loss: 3.5536\n",
            "Epoch 775/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 3.1686 - val_loss: 3.5470\n",
            "Epoch 776/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 3.1612 - val_loss: 3.5394\n",
            "Epoch 777/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 3.1540 - val_loss: 3.5348\n",
            "Epoch 778/5000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 3.1484 - val_loss: 3.5262\n",
            "Epoch 779/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 3.1412 - val_loss: 3.5258\n",
            "Epoch 780/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 3.1339 - val_loss: 3.5127\n",
            "Epoch 781/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 3.1255 - val_loss: 3.5069\n",
            "Epoch 782/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 3.1196 - val_loss: 3.4963\n",
            "Epoch 783/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 3.1123 - val_loss: 3.4936\n",
            "Epoch 784/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 3.1064 - val_loss: 3.4855\n",
            "Epoch 785/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 3.0973 - val_loss: 3.4801\n",
            "Epoch 786/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 3.0936 - val_loss: 3.4743\n",
            "Epoch 787/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 3.0847 - val_loss: 3.4680\n",
            "Epoch 788/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 3.0791 - val_loss: 3.4586\n",
            "Epoch 789/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 3.0721 - val_loss: 3.4490\n",
            "Epoch 790/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 3.0651 - val_loss: 3.4499\n",
            "Epoch 791/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 3.0578 - val_loss: 3.4439\n",
            "Epoch 792/5000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 3.0509 - val_loss: 3.4352\n",
            "Epoch 793/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 3.0447 - val_loss: 3.4264\n",
            "Epoch 794/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 3.0371 - val_loss: 3.4180\n",
            "Epoch 795/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 3.0298 - val_loss: 3.4169\n",
            "Epoch 796/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 3.0232 - val_loss: 3.4078\n",
            "Epoch 797/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 3.0167 - val_loss: 3.3989\n",
            "Epoch 798/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 3.0091 - val_loss: 3.3940\n",
            "Epoch 799/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 3.0037 - val_loss: 3.3870\n",
            "Epoch 800/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.9973 - val_loss: 3.3821\n",
            "Epoch 801/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.9896 - val_loss: 3.3762\n",
            "Epoch 802/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.9845 - val_loss: 3.3658\n",
            "Epoch 803/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.9759 - val_loss: 3.3579\n",
            "Epoch 804/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.9701 - val_loss: 3.3523\n",
            "Epoch 805/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.9615 - val_loss: 3.3467\n",
            "Epoch 806/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.9580 - val_loss: 3.3370\n",
            "Epoch 807/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2.9518 - val_loss: 3.3385\n",
            "Epoch 808/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.9436 - val_loss: 3.3281\n",
            "Epoch 809/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.9356 - val_loss: 3.3233\n",
            "Epoch 810/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.9300 - val_loss: 3.3149\n",
            "Epoch 811/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.9233 - val_loss: 3.3066\n",
            "Epoch 812/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.9163 - val_loss: 3.2995\n",
            "Epoch 813/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.9101 - val_loss: 3.2957\n",
            "Epoch 814/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.9039 - val_loss: 3.2934\n",
            "Epoch 815/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.8979 - val_loss: 3.2838\n",
            "Epoch 816/5000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 2.8908 - val_loss: 3.2787\n",
            "Epoch 817/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.8841 - val_loss: 3.2709\n",
            "Epoch 818/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.8769 - val_loss: 3.2642\n",
            "Epoch 819/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.8720 - val_loss: 3.2618\n",
            "Epoch 820/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.8650 - val_loss: 3.2523\n",
            "Epoch 821/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.8577 - val_loss: 3.2480\n",
            "Epoch 822/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.8528 - val_loss: 3.2376\n",
            "Epoch 823/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.8440 - val_loss: 3.2343\n",
            "Epoch 824/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.8395 - val_loss: 3.2288\n",
            "Epoch 825/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.8323 - val_loss: 3.2233\n",
            "Epoch 826/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.8254 - val_loss: 3.2162\n",
            "Epoch 827/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.8189 - val_loss: 3.2082\n",
            "Epoch 828/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.8126 - val_loss: 3.2048\n",
            "Epoch 829/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.8081 - val_loss: 3.1991\n",
            "Epoch 830/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.8032 - val_loss: 3.1930\n",
            "Epoch 831/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.7940 - val_loss: 3.1877\n",
            "Epoch 832/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.7881 - val_loss: 3.1813\n",
            "Epoch 833/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.7840 - val_loss: 3.1724\n",
            "Epoch 834/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.7764 - val_loss: 3.1685\n",
            "Epoch 835/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.7695 - val_loss: 3.1611\n",
            "Epoch 836/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.7638 - val_loss: 3.1588\n",
            "Epoch 837/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.7570 - val_loss: 3.1521\n",
            "Epoch 838/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.7512 - val_loss: 3.1437\n",
            "Epoch 839/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.7450 - val_loss: 3.1393\n",
            "Epoch 840/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.7377 - val_loss: 3.1333\n",
            "Epoch 841/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.7320 - val_loss: 3.1257\n",
            "Epoch 842/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.7265 - val_loss: 3.1195\n",
            "Epoch 843/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.7204 - val_loss: 3.1135\n",
            "Epoch 844/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.7137 - val_loss: 3.1086\n",
            "Epoch 845/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.7072 - val_loss: 3.1022\n",
            "Epoch 846/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.7018 - val_loss: 3.0977\n",
            "Epoch 847/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.6967 - val_loss: 3.0915\n",
            "Epoch 848/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.6906 - val_loss: 3.0862\n",
            "Epoch 849/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.6833 - val_loss: 3.0816\n",
            "Epoch 850/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.6769 - val_loss: 3.0753\n",
            "Epoch 851/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.6716 - val_loss: 3.0689\n",
            "Epoch 852/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.6649 - val_loss: 3.0642\n",
            "Epoch 853/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.6597 - val_loss: 3.0583\n",
            "Epoch 854/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.6539 - val_loss: 3.0565\n",
            "Epoch 855/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.6484 - val_loss: 3.0458\n",
            "Epoch 856/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.6414 - val_loss: 3.0408\n",
            "Epoch 857/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.6361 - val_loss: 3.0346\n",
            "Epoch 858/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.6293 - val_loss: 3.0279\n",
            "Epoch 859/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.6239 - val_loss: 3.0246\n",
            "Epoch 860/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.6202 - val_loss: 3.0197\n",
            "Epoch 861/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.6121 - val_loss: 3.0118\n",
            "Epoch 862/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.6068 - val_loss: 3.0055\n",
            "Epoch 863/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.6017 - val_loss: 3.0033\n",
            "Epoch 864/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.5955 - val_loss: 3.0029\n",
            "Epoch 865/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.5888 - val_loss: 2.9931\n",
            "Epoch 866/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.5815 - val_loss: 2.9863\n",
            "Epoch 867/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.5767 - val_loss: 2.9850\n",
            "Epoch 868/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.5723 - val_loss: 2.9768\n",
            "Epoch 869/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.5653 - val_loss: 2.9724\n",
            "Epoch 870/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.5596 - val_loss: 2.9663\n",
            "Epoch 871/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.5538 - val_loss: 2.9613\n",
            "Epoch 872/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.5480 - val_loss: 2.9534\n",
            "Epoch 873/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.5421 - val_loss: 2.9499\n",
            "Epoch 874/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.5364 - val_loss: 2.9451\n",
            "Epoch 875/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.5328 - val_loss: 2.9416\n",
            "Epoch 876/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.5254 - val_loss: 2.9371\n",
            "Epoch 877/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.5219 - val_loss: 2.9273\n",
            "Epoch 878/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.5161 - val_loss: 2.9249\n",
            "Epoch 879/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.5091 - val_loss: 2.9185\n",
            "Epoch 880/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.5040 - val_loss: 2.9155\n",
            "Epoch 881/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.4981 - val_loss: 2.9053\n",
            "Epoch 882/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.4922 - val_loss: 2.9001\n",
            "Epoch 883/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.4879 - val_loss: 2.8999\n",
            "Epoch 884/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.4816 - val_loss: 2.8983\n",
            "Epoch 885/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.4754 - val_loss: 2.8852\n",
            "Epoch 886/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.4699 - val_loss: 2.8807\n",
            "Epoch 887/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.4654 - val_loss: 2.8796\n",
            "Epoch 888/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.4588 - val_loss: 2.8758\n",
            "Epoch 889/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.4532 - val_loss: 2.8659\n",
            "Epoch 890/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.4482 - val_loss: 2.8617\n",
            "Epoch 891/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.4421 - val_loss: 2.8579\n",
            "Epoch 892/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.4363 - val_loss: 2.8501\n",
            "Epoch 893/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.4310 - val_loss: 2.8471\n",
            "Epoch 894/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.4257 - val_loss: 2.8410\n",
            "Epoch 895/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.4214 - val_loss: 2.8360\n",
            "Epoch 896/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.4143 - val_loss: 2.8319\n",
            "Epoch 897/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.4101 - val_loss: 2.8276\n",
            "Epoch 898/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.4036 - val_loss: 2.8221\n",
            "Epoch 899/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.3988 - val_loss: 2.8183\n",
            "Epoch 900/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.3959 - val_loss: 2.8101\n",
            "Epoch 901/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.3890 - val_loss: 2.8093\n",
            "Epoch 902/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.3845 - val_loss: 2.8062\n",
            "Epoch 903/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.3778 - val_loss: 2.7967\n",
            "Epoch 904/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.3718 - val_loss: 2.7915\n",
            "Epoch 905/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.3692 - val_loss: 2.7887\n",
            "Epoch 906/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.3615 - val_loss: 2.7829\n",
            "Epoch 907/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.3570 - val_loss: 2.7803\n",
            "Epoch 908/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.3534 - val_loss: 2.7763\n",
            "Epoch 909/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.3476 - val_loss: 2.7668\n",
            "Epoch 910/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2.3401 - val_loss: 2.7669\n",
            "Epoch 911/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.3370 - val_loss: 2.7546\n",
            "Epoch 912/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.3303 - val_loss: 2.7543\n",
            "Epoch 913/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.3267 - val_loss: 2.7522\n",
            "Epoch 914/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.3199 - val_loss: 2.7445\n",
            "Epoch 915/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.3153 - val_loss: 2.7386\n",
            "Epoch 916/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.3088 - val_loss: 2.7356\n",
            "Epoch 917/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.3043 - val_loss: 2.7291\n",
            "Epoch 918/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.2992 - val_loss: 2.7272\n",
            "Epoch 919/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.2939 - val_loss: 2.7224\n",
            "Epoch 920/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.2906 - val_loss: 2.7167\n",
            "Epoch 921/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.2851 - val_loss: 2.7126\n",
            "Epoch 922/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.2797 - val_loss: 2.7076\n",
            "Epoch 923/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.2746 - val_loss: 2.7049\n",
            "Epoch 924/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.2688 - val_loss: 2.6975\n",
            "Epoch 925/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.2640 - val_loss: 2.6946\n",
            "Epoch 926/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.2599 - val_loss: 2.6881\n",
            "Epoch 927/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.2545 - val_loss: 2.6843\n",
            "Epoch 928/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.2487 - val_loss: 2.6806\n",
            "Epoch 929/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.2442 - val_loss: 2.6774\n",
            "Epoch 930/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.2386 - val_loss: 2.6742\n",
            "Epoch 931/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.2346 - val_loss: 2.6646\n",
            "Epoch 932/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.2289 - val_loss: 2.6616\n",
            "Epoch 933/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.2237 - val_loss: 2.6587\n",
            "Epoch 934/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.2202 - val_loss: 2.6513\n",
            "Epoch 935/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.2135 - val_loss: 2.6474\n",
            "Epoch 936/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.2103 - val_loss: 2.6434\n",
            "Epoch 937/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.2042 - val_loss: 2.6382\n",
            "Epoch 938/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.1999 - val_loss: 2.6378\n",
            "Epoch 939/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.1935 - val_loss: 2.6327\n",
            "Epoch 940/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.1895 - val_loss: 2.6257\n",
            "Epoch 941/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.1836 - val_loss: 2.6220\n",
            "Epoch 942/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.1814 - val_loss: 2.6175\n",
            "Epoch 943/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.1763 - val_loss: 2.6158\n",
            "Epoch 944/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.1709 - val_loss: 2.6091\n",
            "Epoch 945/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.1648 - val_loss: 2.6048\n",
            "Epoch 946/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.1615 - val_loss: 2.6005\n",
            "Epoch 947/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.1560 - val_loss: 2.5958\n",
            "Epoch 948/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.1508 - val_loss: 2.5912\n",
            "Epoch 949/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.1470 - val_loss: 2.5887\n",
            "Epoch 950/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.1417 - val_loss: 2.5841\n",
            "Epoch 951/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.1367 - val_loss: 2.5809\n",
            "Epoch 952/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.1333 - val_loss: 2.5765\n",
            "Epoch 953/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.1274 - val_loss: 2.5712\n",
            "Epoch 954/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.1229 - val_loss: 2.5698\n",
            "Epoch 955/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.1177 - val_loss: 2.5648\n",
            "Epoch 956/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.1132 - val_loss: 2.5592\n",
            "Epoch 957/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.1095 - val_loss: 2.5554\n",
            "Epoch 958/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.1043 - val_loss: 2.5485\n",
            "Epoch 959/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.1002 - val_loss: 2.5476\n",
            "Epoch 960/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.0955 - val_loss: 2.5428\n",
            "Epoch 961/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.0899 - val_loss: 2.5382\n",
            "Epoch 962/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.0865 - val_loss: 2.5302\n",
            "Epoch 963/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.0814 - val_loss: 2.5299\n",
            "Epoch 964/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.0764 - val_loss: 2.5263\n",
            "Epoch 965/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.0731 - val_loss: 2.5210\n",
            "Epoch 966/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.0673 - val_loss: 2.5172\n",
            "Epoch 967/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.0641 - val_loss: 2.5122\n",
            "Epoch 968/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.0596 - val_loss: 2.5053\n",
            "Epoch 969/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2.0552 - val_loss: 2.5066\n",
            "Epoch 970/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.0498 - val_loss: 2.5008\n",
            "Epoch 971/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.0468 - val_loss: 2.4979\n",
            "Epoch 972/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.0415 - val_loss: 2.4928\n",
            "Epoch 973/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.0393 - val_loss: 2.4898\n",
            "Epoch 974/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.0318 - val_loss: 2.4856\n",
            "Epoch 975/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.0273 - val_loss: 2.4809\n",
            "Epoch 976/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.0233 - val_loss: 2.4771\n",
            "Epoch 977/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.0186 - val_loss: 2.4729\n",
            "Epoch 978/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.0145 - val_loss: 2.4690\n",
            "Epoch 979/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.0103 - val_loss: 2.4645\n",
            "Epoch 980/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.0050 - val_loss: 2.4604\n",
            "Epoch 981/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.0016 - val_loss: 2.4564\n",
            "Epoch 982/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.9980 - val_loss: 2.4544\n",
            "Epoch 983/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.9923 - val_loss: 2.4490\n",
            "Epoch 984/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.9885 - val_loss: 2.4442\n",
            "Epoch 985/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.9845 - val_loss: 2.4410\n",
            "Epoch 986/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.9797 - val_loss: 2.4400\n",
            "Epoch 987/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.9757 - val_loss: 2.4343\n",
            "Epoch 988/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.9717 - val_loss: 2.4295\n",
            "Epoch 989/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.9664 - val_loss: 2.4254\n",
            "Epoch 990/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.9633 - val_loss: 2.4215\n",
            "Epoch 991/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.9590 - val_loss: 2.4216\n",
            "Epoch 992/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.9547 - val_loss: 2.4136\n",
            "Epoch 993/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.9505 - val_loss: 2.4120\n",
            "Epoch 994/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.9461 - val_loss: 2.4097\n",
            "Epoch 995/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.9423 - val_loss: 2.4046\n",
            "Epoch 996/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.9372 - val_loss: 2.3995\n",
            "Epoch 997/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.9336 - val_loss: 2.3961\n",
            "Epoch 998/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.9287 - val_loss: 2.3906\n",
            "Epoch 999/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.9249 - val_loss: 2.3871\n",
            "Epoch 1000/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.9210 - val_loss: 2.3859\n",
            "Epoch 1001/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.9165 - val_loss: 2.3807\n",
            "Epoch 1002/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.9140 - val_loss: 2.3773\n",
            "Epoch 1003/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.9089 - val_loss: 2.3710\n",
            "Epoch 1004/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.9051 - val_loss: 2.3675\n",
            "Epoch 1005/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.9011 - val_loss: 2.3671\n",
            "Epoch 1006/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.8970 - val_loss: 2.3617\n",
            "Epoch 1007/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.8931 - val_loss: 2.3587\n",
            "Epoch 1008/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.8890 - val_loss: 2.3549\n",
            "Epoch 1009/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.8840 - val_loss: 2.3508\n",
            "Epoch 1010/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.8808 - val_loss: 2.3454\n",
            "Epoch 1011/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.8773 - val_loss: 2.3449\n",
            "Epoch 1012/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.8723 - val_loss: 2.3398\n",
            "Epoch 1013/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.8673 - val_loss: 2.3360\n",
            "Epoch 1014/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.8650 - val_loss: 2.3312\n",
            "Epoch 1015/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.8603 - val_loss: 2.3293\n",
            "Epoch 1016/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.8565 - val_loss: 2.3245\n",
            "Epoch 1017/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.8522 - val_loss: 2.3226\n",
            "Epoch 1018/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.8481 - val_loss: 2.3172\n",
            "Epoch 1019/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.8454 - val_loss: 2.3156\n",
            "Epoch 1020/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.8410 - val_loss: 2.3102\n",
            "Epoch 1021/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.8369 - val_loss: 2.3051\n",
            "Epoch 1022/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.8325 - val_loss: 2.3047\n",
            "Epoch 1023/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.8290 - val_loss: 2.3034\n",
            "Epoch 1024/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.8260 - val_loss: 2.2985\n",
            "Epoch 1025/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.8209 - val_loss: 2.2948\n",
            "Epoch 1026/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.8179 - val_loss: 2.2892\n",
            "Epoch 1027/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.8131 - val_loss: 2.2858\n",
            "Epoch 1028/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.8103 - val_loss: 2.2824\n",
            "Epoch 1029/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.8047 - val_loss: 2.2775\n",
            "Epoch 1030/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.8002 - val_loss: 2.2732\n",
            "Epoch 1031/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.7967 - val_loss: 2.2712\n",
            "Epoch 1032/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.7921 - val_loss: 2.2714\n",
            "Epoch 1033/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.7876 - val_loss: 2.2672\n",
            "Epoch 1034/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.7827 - val_loss: 2.2622\n",
            "Epoch 1035/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.7803 - val_loss: 2.2568\n",
            "Epoch 1036/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.7737 - val_loss: 2.2538\n",
            "Epoch 1037/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.7708 - val_loss: 2.2490\n",
            "Epoch 1038/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.7667 - val_loss: 2.2475\n",
            "Epoch 1039/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.7638 - val_loss: 2.2447\n",
            "Epoch 1040/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.7582 - val_loss: 2.2430\n",
            "Epoch 1041/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.7539 - val_loss: 2.2371\n",
            "Epoch 1042/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.7497 - val_loss: 2.2366\n",
            "Epoch 1043/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.7459 - val_loss: 2.2299\n",
            "Epoch 1044/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.7418 - val_loss: 2.2261\n",
            "Epoch 1045/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.7373 - val_loss: 2.2234\n",
            "Epoch 1046/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.7342 - val_loss: 2.2197\n",
            "Epoch 1047/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.7309 - val_loss: 2.2207\n",
            "Epoch 1048/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.7260 - val_loss: 2.2124\n",
            "Epoch 1049/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.7225 - val_loss: 2.2090\n",
            "Epoch 1050/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.7194 - val_loss: 2.2083\n",
            "Epoch 1051/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.7142 - val_loss: 2.2057\n",
            "Epoch 1052/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.7105 - val_loss: 2.2016\n",
            "Epoch 1053/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.7081 - val_loss: 2.1980\n",
            "Epoch 1054/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.7039 - val_loss: 2.1967\n",
            "Epoch 1055/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.6993 - val_loss: 2.1905\n",
            "Epoch 1056/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.6946 - val_loss: 2.1861\n",
            "Epoch 1057/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.6916 - val_loss: 2.1831\n",
            "Epoch 1058/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.6878 - val_loss: 2.1816\n",
            "Epoch 1059/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.6842 - val_loss: 2.1775\n",
            "Epoch 1060/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.6802 - val_loss: 2.1744\n",
            "Epoch 1061/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.6765 - val_loss: 2.1729\n",
            "Epoch 1062/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.6723 - val_loss: 2.1678\n",
            "Epoch 1063/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.6694 - val_loss: 2.1661\n",
            "Epoch 1064/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.6650 - val_loss: 2.1621\n",
            "Epoch 1065/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.6634 - val_loss: 2.1567\n",
            "Epoch 1066/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.6587 - val_loss: 2.1559\n",
            "Epoch 1067/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.6546 - val_loss: 2.1519\n",
            "Epoch 1068/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.6511 - val_loss: 2.1500\n",
            "Epoch 1069/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.6480 - val_loss: 2.1471\n",
            "Epoch 1070/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.6449 - val_loss: 2.1430\n",
            "Epoch 1071/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.6403 - val_loss: 2.1401\n",
            "Epoch 1072/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.6374 - val_loss: 2.1354\n",
            "Epoch 1073/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.6331 - val_loss: 2.1331\n",
            "Epoch 1074/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.6296 - val_loss: 2.1330\n",
            "Epoch 1075/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.6270 - val_loss: 2.1289\n",
            "Epoch 1076/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.6224 - val_loss: 2.1243\n",
            "Epoch 1077/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.6195 - val_loss: 2.1205\n",
            "Epoch 1078/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.6155 - val_loss: 2.1179\n",
            "Epoch 1079/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.6133 - val_loss: 2.1152\n",
            "Epoch 1080/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.6101 - val_loss: 2.1125\n",
            "Epoch 1081/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.6063 - val_loss: 2.1109\n",
            "Epoch 1082/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.6032 - val_loss: 2.1057\n",
            "Epoch 1083/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.5989 - val_loss: 2.1027\n",
            "Epoch 1084/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.5962 - val_loss: 2.1010\n",
            "Epoch 1085/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.5932 - val_loss: 2.0963\n",
            "Epoch 1086/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.5883 - val_loss: 2.0947\n",
            "Epoch 1087/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.5861 - val_loss: 2.0910\n",
            "Epoch 1088/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.5831 - val_loss: 2.0906\n",
            "Epoch 1089/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.5798 - val_loss: 2.0847\n",
            "Epoch 1090/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.5762 - val_loss: 2.0825\n",
            "Epoch 1091/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.5725 - val_loss: 2.0803\n",
            "Epoch 1092/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.5695 - val_loss: 2.0769\n",
            "Epoch 1093/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.5675 - val_loss: 2.0729\n",
            "Epoch 1094/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.5629 - val_loss: 2.0717\n",
            "Epoch 1095/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.5594 - val_loss: 2.0668\n",
            "Epoch 1096/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.5567 - val_loss: 2.0663\n",
            "Epoch 1097/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.5528 - val_loss: 2.0613\n",
            "Epoch 1098/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.5494 - val_loss: 2.0582\n",
            "Epoch 1099/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.5466 - val_loss: 2.0569\n",
            "Epoch 1100/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.5433 - val_loss: 2.0521\n",
            "Epoch 1101/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.5402 - val_loss: 2.0505\n",
            "Epoch 1102/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.5390 - val_loss: 2.0482\n",
            "Epoch 1103/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.5339 - val_loss: 2.0456\n",
            "Epoch 1104/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.5311 - val_loss: 2.0431\n",
            "Epoch 1105/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.5283 - val_loss: 2.0415\n",
            "Epoch 1106/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.5247 - val_loss: 2.0364\n",
            "Epoch 1107/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.5219 - val_loss: 2.0349\n",
            "Epoch 1108/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.5190 - val_loss: 2.0301\n",
            "Epoch 1109/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.5154 - val_loss: 2.0282\n",
            "Epoch 1110/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.5121 - val_loss: 2.0256\n",
            "Epoch 1111/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.5093 - val_loss: 2.0226\n",
            "Epoch 1112/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.5065 - val_loss: 2.0181\n",
            "Epoch 1113/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.5026 - val_loss: 2.0191\n",
            "Epoch 1114/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.4994 - val_loss: 2.0148\n",
            "Epoch 1115/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.4965 - val_loss: 2.0113\n",
            "Epoch 1116/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.4935 - val_loss: 2.0075\n",
            "Epoch 1117/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.4905 - val_loss: 2.0071\n",
            "Epoch 1118/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.4875 - val_loss: 2.0025\n",
            "Epoch 1119/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.4845 - val_loss: 2.0006\n",
            "Epoch 1120/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.4821 - val_loss: 1.9968\n",
            "Epoch 1121/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.4789 - val_loss: 1.9963\n",
            "Epoch 1122/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.4758 - val_loss: 1.9943\n",
            "Epoch 1123/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.4728 - val_loss: 1.9900\n",
            "Epoch 1124/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.4705 - val_loss: 1.9849\n",
            "Epoch 1125/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.4666 - val_loss: 1.9825\n",
            "Epoch 1126/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.4648 - val_loss: 1.9831\n",
            "Epoch 1127/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.4614 - val_loss: 1.9796\n",
            "Epoch 1128/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.4585 - val_loss: 1.9747\n",
            "Epoch 1129/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.4551 - val_loss: 1.9726\n",
            "Epoch 1130/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.4523 - val_loss: 1.9696\n",
            "Epoch 1131/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.4507 - val_loss: 1.9678\n",
            "Epoch 1132/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.4467 - val_loss: 1.9681\n",
            "Epoch 1133/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.4440 - val_loss: 1.9629\n",
            "Epoch 1134/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.4413 - val_loss: 1.9599\n",
            "Epoch 1135/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.4378 - val_loss: 1.9587\n",
            "Epoch 1136/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.4357 - val_loss: 1.9548\n",
            "Epoch 1137/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.4330 - val_loss: 1.9506\n",
            "Epoch 1138/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.4292 - val_loss: 1.9486\n",
            "Epoch 1139/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.4275 - val_loss: 1.9489\n",
            "Epoch 1140/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.4243 - val_loss: 1.9445\n",
            "Epoch 1141/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.4208 - val_loss: 1.9418\n",
            "Epoch 1142/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.4190 - val_loss: 1.9382\n",
            "Epoch 1143/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.4157 - val_loss: 1.9387\n",
            "Epoch 1144/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.4131 - val_loss: 1.9355\n",
            "Epoch 1145/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.4102 - val_loss: 1.9314\n",
            "Epoch 1146/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.4081 - val_loss: 1.9290\n",
            "Epoch 1147/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.4047 - val_loss: 1.9273\n",
            "Epoch 1148/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.4016 - val_loss: 1.9266\n",
            "Epoch 1149/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.3990 - val_loss: 1.9216\n",
            "Epoch 1150/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.3963 - val_loss: 1.9195\n",
            "Epoch 1151/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.3938 - val_loss: 1.9153\n",
            "Epoch 1152/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.3912 - val_loss: 1.9134\n",
            "Epoch 1153/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.3886 - val_loss: 1.9138\n",
            "Epoch 1154/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.3859 - val_loss: 1.9097\n",
            "Epoch 1155/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.3825 - val_loss: 1.9069\n",
            "Epoch 1156/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.3808 - val_loss: 1.9032\n",
            "Epoch 1157/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.3779 - val_loss: 1.9008\n",
            "Epoch 1158/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.3751 - val_loss: 1.8989\n",
            "Epoch 1159/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.3727 - val_loss: 1.8981\n",
            "Epoch 1160/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.3699 - val_loss: 1.8933\n",
            "Epoch 1161/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.3672 - val_loss: 1.8911\n",
            "Epoch 1162/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.3645 - val_loss: 1.8918\n",
            "Epoch 1163/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.3627 - val_loss: 1.8865\n",
            "Epoch 1164/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.3589 - val_loss: 1.8839\n",
            "Epoch 1165/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.3569 - val_loss: 1.8828\n",
            "Epoch 1166/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.3536 - val_loss: 1.8789\n",
            "Epoch 1167/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.3521 - val_loss: 1.8756\n",
            "Epoch 1168/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.3499 - val_loss: 1.8749\n",
            "Epoch 1169/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.3464 - val_loss: 1.8713\n",
            "Epoch 1170/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.3435 - val_loss: 1.8698\n",
            "Epoch 1171/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.3419 - val_loss: 1.8670\n",
            "Epoch 1172/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.3384 - val_loss: 1.8649\n",
            "Epoch 1173/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.3360 - val_loss: 1.8614\n",
            "Epoch 1174/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.3336 - val_loss: 1.8595\n",
            "Epoch 1175/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.3311 - val_loss: 1.8582\n",
            "Epoch 1176/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.3284 - val_loss: 1.8545\n",
            "Epoch 1177/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.3266 - val_loss: 1.8528\n",
            "Epoch 1178/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.3235 - val_loss: 1.8520\n",
            "Epoch 1179/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.3207 - val_loss: 1.8484\n",
            "Epoch 1180/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.3183 - val_loss: 1.8451\n",
            "Epoch 1181/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.3166 - val_loss: 1.8420\n",
            "Epoch 1182/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.3132 - val_loss: 1.8416\n",
            "Epoch 1183/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.3114 - val_loss: 1.8394\n",
            "Epoch 1184/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.3097 - val_loss: 1.8378\n",
            "Epoch 1185/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.3064 - val_loss: 1.8334\n",
            "Epoch 1186/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.3043 - val_loss: 1.8311\n",
            "Epoch 1187/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.3014 - val_loss: 1.8304\n",
            "Epoch 1188/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.2994 - val_loss: 1.8286\n",
            "Epoch 1189/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.2966 - val_loss: 1.8258\n",
            "Epoch 1190/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.2941 - val_loss: 1.8226\n",
            "Epoch 1191/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.2922 - val_loss: 1.8207\n",
            "Epoch 1192/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.2895 - val_loss: 1.8191\n",
            "Epoch 1193/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.2868 - val_loss: 1.8160\n",
            "Epoch 1194/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.2844 - val_loss: 1.8127\n",
            "Epoch 1195/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.2825 - val_loss: 1.8109\n",
            "Epoch 1196/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.2795 - val_loss: 1.8083\n",
            "Epoch 1197/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.2781 - val_loss: 1.8104\n",
            "Epoch 1198/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.2755 - val_loss: 1.8061\n",
            "Epoch 1199/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.2723 - val_loss: 1.8037\n",
            "Epoch 1200/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.2698 - val_loss: 1.8009\n",
            "Epoch 1201/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.2669 - val_loss: 1.7982\n",
            "Epoch 1202/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.2665 - val_loss: 1.7957\n",
            "Epoch 1203/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.2636 - val_loss: 1.7984\n",
            "Epoch 1204/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.2598 - val_loss: 1.7924\n",
            "Epoch 1205/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.2580 - val_loss: 1.7893\n",
            "Epoch 1206/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.2554 - val_loss: 1.7891\n",
            "Epoch 1207/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.2526 - val_loss: 1.7866\n",
            "Epoch 1208/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.2508 - val_loss: 1.7856\n",
            "Epoch 1209/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.2491 - val_loss: 1.7845\n",
            "Epoch 1210/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.2457 - val_loss: 1.7802\n",
            "Epoch 1211/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.2433 - val_loss: 1.7789\n",
            "Epoch 1212/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.2412 - val_loss: 1.7749\n",
            "Epoch 1213/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.2384 - val_loss: 1.7751\n",
            "Epoch 1214/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.2366 - val_loss: 1.7730\n",
            "Epoch 1215/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.2348 - val_loss: 1.7680\n",
            "Epoch 1216/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.2322 - val_loss: 1.7668\n",
            "Epoch 1217/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.2300 - val_loss: 1.7661\n",
            "Epoch 1218/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.2274 - val_loss: 1.7645\n",
            "Epoch 1219/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.2249 - val_loss: 1.7613\n",
            "Epoch 1220/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.2230 - val_loss: 1.7575\n",
            "Epoch 1221/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.2206 - val_loss: 1.7580\n",
            "Epoch 1222/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.2184 - val_loss: 1.7549\n",
            "Epoch 1223/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.2162 - val_loss: 1.7521\n",
            "Epoch 1224/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.2139 - val_loss: 1.7517\n",
            "Epoch 1225/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.2124 - val_loss: 1.7507\n",
            "Epoch 1226/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.2097 - val_loss: 1.7479\n",
            "Epoch 1227/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.2080 - val_loss: 1.7452\n",
            "Epoch 1228/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.2050 - val_loss: 1.7431\n",
            "Epoch 1229/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.2040 - val_loss: 1.7423\n",
            "Epoch 1230/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.2012 - val_loss: 1.7380\n",
            "Epoch 1231/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.1985 - val_loss: 1.7370\n",
            "Epoch 1232/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.1970 - val_loss: 1.7355\n",
            "Epoch 1233/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.1949 - val_loss: 1.7319\n",
            "Epoch 1234/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.1924 - val_loss: 1.7298\n",
            "Epoch 1235/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.1903 - val_loss: 1.7285\n",
            "Epoch 1236/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.1883 - val_loss: 1.7257\n",
            "Epoch 1237/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.1857 - val_loss: 1.7267\n",
            "Epoch 1238/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.1846 - val_loss: 1.7239\n",
            "Epoch 1239/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.1821 - val_loss: 1.7225\n",
            "Epoch 1240/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.1804 - val_loss: 1.7224\n",
            "Epoch 1241/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.1777 - val_loss: 1.7197\n",
            "Epoch 1242/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.1760 - val_loss: 1.7161\n",
            "Epoch 1243/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.1748 - val_loss: 1.7147\n",
            "Epoch 1244/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.1715 - val_loss: 1.7136\n",
            "Epoch 1245/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.1696 - val_loss: 1.7137\n",
            "Epoch 1246/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.1673 - val_loss: 1.7111\n",
            "Epoch 1247/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.1656 - val_loss: 1.7092\n",
            "Epoch 1248/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.1639 - val_loss: 1.7054\n",
            "Epoch 1249/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.1619 - val_loss: 1.7054\n",
            "Epoch 1250/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.1595 - val_loss: 1.7023\n",
            "Epoch 1251/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.1579 - val_loss: 1.7010\n",
            "Epoch 1252/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.1568 - val_loss: 1.6986\n",
            "Epoch 1253/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.1538 - val_loss: 1.6975\n",
            "Epoch 1254/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.1511 - val_loss: 1.6974\n",
            "Epoch 1255/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.1493 - val_loss: 1.6940\n",
            "Epoch 1256/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.1484 - val_loss: 1.6916\n",
            "Epoch 1257/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.1456 - val_loss: 1.6921\n",
            "Epoch 1258/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.1435 - val_loss: 1.6889\n",
            "Epoch 1259/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.1421 - val_loss: 1.6864\n",
            "Epoch 1260/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.1401 - val_loss: 1.6830\n",
            "Epoch 1261/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.1388 - val_loss: 1.6818\n",
            "Epoch 1262/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.1366 - val_loss: 1.6825\n",
            "Epoch 1263/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.1341 - val_loss: 1.6828\n",
            "Epoch 1264/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.1321 - val_loss: 1.6799\n",
            "Epoch 1265/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.1313 - val_loss: 1.6745\n",
            "Epoch 1266/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.1282 - val_loss: 1.6737\n",
            "Epoch 1267/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.1264 - val_loss: 1.6726\n",
            "Epoch 1268/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.1254 - val_loss: 1.6751\n",
            "Epoch 1269/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.1227 - val_loss: 1.6716\n",
            "Epoch 1270/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.1218 - val_loss: 1.6709\n",
            "Epoch 1271/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.1201 - val_loss: 1.6651\n",
            "Epoch 1272/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.1175 - val_loss: 1.6649\n",
            "Epoch 1273/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.1153 - val_loss: 1.6628\n",
            "Epoch 1274/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.1132 - val_loss: 1.6618\n",
            "Epoch 1275/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.1114 - val_loss: 1.6611\n",
            "Epoch 1276/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.1105 - val_loss: 1.6570\n",
            "Epoch 1277/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.1079 - val_loss: 1.6569\n",
            "Epoch 1278/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.1063 - val_loss: 1.6535\n",
            "Epoch 1279/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.1048 - val_loss: 1.6530\n",
            "Epoch 1280/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.1026 - val_loss: 1.6516\n",
            "Epoch 1281/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.1010 - val_loss: 1.6486\n",
            "Epoch 1282/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.0989 - val_loss: 1.6473\n",
            "Epoch 1283/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.0970 - val_loss: 1.6467\n",
            "Epoch 1284/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.0956 - val_loss: 1.6455\n",
            "Epoch 1285/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.0934 - val_loss: 1.6433\n",
            "Epoch 1286/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.0919 - val_loss: 1.6414\n",
            "Epoch 1287/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.0902 - val_loss: 1.6394\n",
            "Epoch 1288/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.0883 - val_loss: 1.6387\n",
            "Epoch 1289/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0869 - val_loss: 1.6398\n",
            "Epoch 1290/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.0855 - val_loss: 1.6333\n",
            "Epoch 1291/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.0837 - val_loss: 1.6331\n",
            "Epoch 1292/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.0817 - val_loss: 1.6313\n",
            "Epoch 1293/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.0801 - val_loss: 1.6313\n",
            "Epoch 1294/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.0781 - val_loss: 1.6284\n",
            "Epoch 1295/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.0763 - val_loss: 1.6274\n",
            "Epoch 1296/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.0746 - val_loss: 1.6272\n",
            "Epoch 1297/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.0732 - val_loss: 1.6248\n",
            "Epoch 1298/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.0719 - val_loss: 1.6213\n",
            "Epoch 1299/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.0696 - val_loss: 1.6192\n",
            "Epoch 1300/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.0679 - val_loss: 1.6178\n",
            "Epoch 1301/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.0661 - val_loss: 1.6169\n",
            "Epoch 1302/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.0647 - val_loss: 1.6142\n",
            "Epoch 1303/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.0628 - val_loss: 1.6127\n",
            "Epoch 1304/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0606 - val_loss: 1.6130\n",
            "Epoch 1305/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.0595 - val_loss: 1.6097\n",
            "Epoch 1306/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0582 - val_loss: 1.6123\n",
            "Epoch 1307/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.0562 - val_loss: 1.6085\n",
            "Epoch 1308/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.0546 - val_loss: 1.6067\n",
            "Epoch 1309/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.0527 - val_loss: 1.6040\n",
            "Epoch 1310/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.0509 - val_loss: 1.6033\n",
            "Epoch 1311/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.0495 - val_loss: 1.6023\n",
            "Epoch 1312/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.0487 - val_loss: 1.5993\n",
            "Epoch 1313/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.0473 - val_loss: 1.5990\n",
            "Epoch 1314/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.0452 - val_loss: 1.5971\n",
            "Epoch 1315/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.0436 - val_loss: 1.5938\n",
            "Epoch 1316/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0420 - val_loss: 1.5939\n",
            "Epoch 1317/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.0396 - val_loss: 1.5932\n",
            "Epoch 1318/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.0388 - val_loss: 1.5928\n",
            "Epoch 1319/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.0369 - val_loss: 1.5872\n",
            "Epoch 1320/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.0347 - val_loss: 1.5856\n",
            "Epoch 1321/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.0335 - val_loss: 1.5846\n",
            "Epoch 1322/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.0318 - val_loss: 1.5828\n",
            "Epoch 1323/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0303 - val_loss: 1.5848\n",
            "Epoch 1324/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.0290 - val_loss: 1.5807\n",
            "Epoch 1325/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0268 - val_loss: 1.5809\n",
            "Epoch 1326/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.0258 - val_loss: 1.5779\n",
            "Epoch 1327/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.0240 - val_loss: 1.5770\n",
            "Epoch 1328/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.0222 - val_loss: 1.5767\n",
            "Epoch 1329/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.0208 - val_loss: 1.5733\n",
            "Epoch 1330/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.0190 - val_loss: 1.5716\n",
            "Epoch 1331/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.0179 - val_loss: 1.5703\n",
            "Epoch 1332/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0161 - val_loss: 1.5714\n",
            "Epoch 1333/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.0148 - val_loss: 1.5665\n",
            "Epoch 1334/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.0128 - val_loss: 1.5657\n",
            "Epoch 1335/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.0110 - val_loss: 1.5641\n",
            "Epoch 1336/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.0102 - val_loss: 1.5625\n",
            "Epoch 1337/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.0081 - val_loss: 1.5624\n",
            "Epoch 1338/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.0072 - val_loss: 1.5616\n",
            "Epoch 1339/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.0056 - val_loss: 1.5577\n",
            "Epoch 1340/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.0039 - val_loss: 1.5565\n",
            "Epoch 1341/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.0024 - val_loss: 1.5562\n",
            "Epoch 1342/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.0015 - val_loss: 1.5535\n",
            "Epoch 1343/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9991 - val_loss: 1.5536\n",
            "Epoch 1344/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.9977 - val_loss: 1.5526\n",
            "Epoch 1345/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.9966 - val_loss: 1.5494\n",
            "Epoch 1346/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.9947 - val_loss: 1.5472\n",
            "Epoch 1347/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9935 - val_loss: 1.5483\n",
            "Epoch 1348/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.9918 - val_loss: 1.5451\n",
            "Epoch 1349/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9903 - val_loss: 1.5456\n",
            "Epoch 1350/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.9893 - val_loss: 1.5443\n",
            "Epoch 1351/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.9875 - val_loss: 1.5418\n",
            "Epoch 1352/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.9860 - val_loss: 1.5393\n",
            "Epoch 1353/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.9847 - val_loss: 1.5384\n",
            "Epoch 1354/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.9833 - val_loss: 1.5378\n",
            "Epoch 1355/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.9820 - val_loss: 1.5361\n",
            "Epoch 1356/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.9801 - val_loss: 1.5348\n",
            "Epoch 1357/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.9790 - val_loss: 1.5325\n",
            "Epoch 1358/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.9785 - val_loss: 1.5306\n",
            "Epoch 1359/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.9763 - val_loss: 1.5301\n",
            "Epoch 1360/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.9756 - val_loss: 1.5285\n",
            "Epoch 1361/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9741 - val_loss: 1.5290\n",
            "Epoch 1362/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.9724 - val_loss: 1.5273\n",
            "Epoch 1363/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.9711 - val_loss: 1.5244\n",
            "Epoch 1364/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.9698 - val_loss: 1.5221\n",
            "Epoch 1365/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.9684 - val_loss: 1.5211\n",
            "Epoch 1366/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.9671 - val_loss: 1.5205\n",
            "Epoch 1367/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9654 - val_loss: 1.5205\n",
            "Epoch 1368/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.9642 - val_loss: 1.5194\n",
            "Epoch 1369/5000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.9635 - val_loss: 1.5163\n",
            "Epoch 1370/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.9616 - val_loss: 1.5142\n",
            "Epoch 1371/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.9600 - val_loss: 1.5123\n",
            "Epoch 1372/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.9589 - val_loss: 1.5123\n",
            "Epoch 1373/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.9575 - val_loss: 1.5113\n",
            "Epoch 1374/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.9561 - val_loss: 1.5083\n",
            "Epoch 1375/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9548 - val_loss: 1.5084\n",
            "Epoch 1376/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.9537 - val_loss: 1.5056\n",
            "Epoch 1377/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.9522 - val_loss: 1.5045\n",
            "Epoch 1378/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.9508 - val_loss: 1.5043\n",
            "Epoch 1379/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.9496 - val_loss: 1.5016\n",
            "Epoch 1380/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.9482 - val_loss: 1.5004\n",
            "Epoch 1381/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9472 - val_loss: 1.5014\n",
            "Epoch 1382/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.9456 - val_loss: 1.4991\n",
            "Epoch 1383/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.9443 - val_loss: 1.4977\n",
            "Epoch 1384/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.9430 - val_loss: 1.4965\n",
            "Epoch 1385/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9420 - val_loss: 1.4972\n",
            "Epoch 1386/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.9408 - val_loss: 1.4949\n",
            "Epoch 1387/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.9395 - val_loss: 1.4911\n",
            "Epoch 1388/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.9380 - val_loss: 1.4895\n",
            "Epoch 1389/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.9367 - val_loss: 1.4888\n",
            "Epoch 1390/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9358 - val_loss: 1.4907\n",
            "Epoch 1391/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.9344 - val_loss: 1.4864\n",
            "Epoch 1392/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.9334 - val_loss: 1.4843\n",
            "Epoch 1393/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9317 - val_loss: 1.4848\n",
            "Epoch 1394/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.9303 - val_loss: 1.4837\n",
            "Epoch 1395/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.9290 - val_loss: 1.4817\n",
            "Epoch 1396/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.9286 - val_loss: 1.4807\n",
            "Epoch 1397/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.9267 - val_loss: 1.4800\n",
            "Epoch 1398/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.9255 - val_loss: 1.4780\n",
            "Epoch 1399/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.9240 - val_loss: 1.4766\n",
            "Epoch 1400/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.9234 - val_loss: 1.4759\n",
            "Epoch 1401/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.9225 - val_loss: 1.4755\n",
            "Epoch 1402/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.9207 - val_loss: 1.4737\n",
            "Epoch 1403/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.9197 - val_loss: 1.4729\n",
            "Epoch 1404/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9187 - val_loss: 1.4729\n",
            "Epoch 1405/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.9173 - val_loss: 1.4700\n",
            "Epoch 1406/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.9163 - val_loss: 1.4680\n",
            "Epoch 1407/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.9156 - val_loss: 1.4664\n",
            "Epoch 1408/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.9139 - val_loss: 1.4642\n",
            "Epoch 1409/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.9123 - val_loss: 1.4630\n",
            "Epoch 1410/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9111 - val_loss: 1.4634\n",
            "Epoch 1411/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.9100 - val_loss: 1.4621\n",
            "Epoch 1412/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.9085 - val_loss: 1.4617\n",
            "Epoch 1413/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.9078 - val_loss: 1.4599\n",
            "Epoch 1414/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.9070 - val_loss: 1.4578\n",
            "Epoch 1415/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9054 - val_loss: 1.4578\n",
            "Epoch 1416/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.9043 - val_loss: 1.4560\n",
            "Epoch 1417/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.9033 - val_loss: 1.4551\n",
            "Epoch 1418/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.9018 - val_loss: 1.4540\n",
            "Epoch 1419/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.9010 - val_loss: 1.4507\n",
            "Epoch 1420/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8997 - val_loss: 1.4507\n",
            "Epoch 1421/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8988 - val_loss: 1.4518\n",
            "Epoch 1422/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.8975 - val_loss: 1.4486\n",
            "Epoch 1423/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.8962 - val_loss: 1.4466\n",
            "Epoch 1424/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8952 - val_loss: 1.4474\n",
            "Epoch 1425/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.8942 - val_loss: 1.4437\n",
            "Epoch 1426/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.8930 - val_loss: 1.4429\n",
            "Epoch 1427/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.8919 - val_loss: 1.4414\n",
            "Epoch 1428/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8907 - val_loss: 1.4417\n",
            "Epoch 1429/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.8894 - val_loss: 1.4404\n",
            "Epoch 1430/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.8885 - val_loss: 1.4385\n",
            "Epoch 1431/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.8875 - val_loss: 1.4363\n",
            "Epoch 1432/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8865 - val_loss: 1.4379\n",
            "Epoch 1433/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.8851 - val_loss: 1.4356\n",
            "Epoch 1434/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8843 - val_loss: 1.4357\n",
            "Epoch 1435/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.8829 - val_loss: 1.4324\n",
            "Epoch 1436/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.8824 - val_loss: 1.4316\n",
            "Epoch 1437/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8812 - val_loss: 1.4322\n",
            "Epoch 1438/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.8801 - val_loss: 1.4297\n",
            "Epoch 1439/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.8788 - val_loss: 1.4290\n",
            "Epoch 1440/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.8773 - val_loss: 1.4280\n",
            "Epoch 1441/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.8764 - val_loss: 1.4260\n",
            "Epoch 1442/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8757 - val_loss: 1.4263\n",
            "Epoch 1443/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.8751 - val_loss: 1.4238\n",
            "Epoch 1444/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.8733 - val_loss: 1.4221\n",
            "Epoch 1445/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.8727 - val_loss: 1.4196\n",
            "Epoch 1446/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8718 - val_loss: 1.4223\n",
            "Epoch 1447/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8702 - val_loss: 1.4197\n",
            "Epoch 1448/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.8692 - val_loss: 1.4180\n",
            "Epoch 1449/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.8686 - val_loss: 1.4180\n",
            "Epoch 1450/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.8673 - val_loss: 1.4172\n",
            "Epoch 1451/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.8659 - val_loss: 1.4153\n",
            "Epoch 1452/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.8649 - val_loss: 1.4143\n",
            "Epoch 1453/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.8644 - val_loss: 1.4103\n",
            "Epoch 1454/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8630 - val_loss: 1.4118\n",
            "Epoch 1455/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8616 - val_loss: 1.4115\n",
            "Epoch 1456/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.8609 - val_loss: 1.4092\n",
            "Epoch 1457/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.8597 - val_loss: 1.4083\n",
            "Epoch 1458/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.8590 - val_loss: 1.4059\n",
            "Epoch 1459/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.8580 - val_loss: 1.4058\n",
            "Epoch 1460/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8569 - val_loss: 1.4064\n",
            "Epoch 1461/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.8558 - val_loss: 1.4028\n",
            "Epoch 1462/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8551 - val_loss: 1.4034\n",
            "Epoch 1463/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.8538 - val_loss: 1.4024\n",
            "Epoch 1464/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.8527 - val_loss: 1.4019\n",
            "Epoch 1465/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.8519 - val_loss: 1.4017\n",
            "Epoch 1466/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.8504 - val_loss: 1.3992\n",
            "Epoch 1467/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.8499 - val_loss: 1.3975\n",
            "Epoch 1468/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.8487 - val_loss: 1.3960\n",
            "Epoch 1469/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.8475 - val_loss: 1.3960\n",
            "Epoch 1470/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8470 - val_loss: 1.3967\n",
            "Epoch 1471/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.8463 - val_loss: 1.3944\n",
            "Epoch 1472/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.8450 - val_loss: 1.3920\n",
            "Epoch 1473/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8440 - val_loss: 1.3925\n",
            "Epoch 1474/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.8429 - val_loss: 1.3908\n",
            "Epoch 1475/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.8419 - val_loss: 1.3898\n",
            "Epoch 1476/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.8411 - val_loss: 1.3873\n",
            "Epoch 1477/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8398 - val_loss: 1.3878\n",
            "Epoch 1478/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.8390 - val_loss: 1.3859\n",
            "Epoch 1479/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8382 - val_loss: 1.3862\n",
            "Epoch 1480/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.8372 - val_loss: 1.3842\n",
            "Epoch 1481/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8363 - val_loss: 1.3844\n",
            "Epoch 1482/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.8350 - val_loss: 1.3816\n",
            "Epoch 1483/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.8344 - val_loss: 1.3798\n",
            "Epoch 1484/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.8337 - val_loss: 1.3791\n",
            "Epoch 1485/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8329 - val_loss: 1.3795\n",
            "Epoch 1486/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.8313 - val_loss: 1.3785\n",
            "Epoch 1487/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.8307 - val_loss: 1.3759\n",
            "Epoch 1488/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8298 - val_loss: 1.3765\n",
            "Epoch 1489/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8295 - val_loss: 1.3766\n",
            "Epoch 1490/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.8280 - val_loss: 1.3747\n",
            "Epoch 1491/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.8276 - val_loss: 1.3741\n",
            "Epoch 1492/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.8264 - val_loss: 1.3736\n",
            "Epoch 1493/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.8252 - val_loss: 1.3717\n",
            "Epoch 1494/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.8243 - val_loss: 1.3692\n",
            "Epoch 1495/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8235 - val_loss: 1.3703\n",
            "Epoch 1496/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8222 - val_loss: 1.3694\n",
            "Epoch 1497/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.8220 - val_loss: 1.3654\n",
            "Epoch 1498/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.8207 - val_loss: 1.3649\n",
            "Epoch 1499/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8195 - val_loss: 1.3664\n",
            "Epoch 1500/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8192 - val_loss: 1.3659\n",
            "Epoch 1501/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.8179 - val_loss: 1.3640\n",
            "Epoch 1502/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.8173 - val_loss: 1.3626\n",
            "Epoch 1503/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.8160 - val_loss: 1.3623\n",
            "Epoch 1504/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.8154 - val_loss: 1.3599\n",
            "Epoch 1505/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8145 - val_loss: 1.3602\n",
            "Epoch 1506/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.8134 - val_loss: 1.3591\n",
            "Epoch 1507/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.8124 - val_loss: 1.3585\n",
            "Epoch 1508/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.8118 - val_loss: 1.3575\n",
            "Epoch 1509/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.8110 - val_loss: 1.3546\n",
            "Epoch 1510/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.8100 - val_loss: 1.3538\n",
            "Epoch 1511/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8091 - val_loss: 1.3548\n",
            "Epoch 1512/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8081 - val_loss: 1.3539\n",
            "Epoch 1513/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.8073 - val_loss: 1.3515\n",
            "Epoch 1514/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.8064 - val_loss: 1.3499\n",
            "Epoch 1515/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.8056 - val_loss: 1.3488\n",
            "Epoch 1516/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8046 - val_loss: 1.3489\n",
            "Epoch 1517/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8042 - val_loss: 1.3495\n",
            "Epoch 1518/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.8033 - val_loss: 1.3465\n",
            "Epoch 1519/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.8026 - val_loss: 1.3452\n",
            "Epoch 1520/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.8016 - val_loss: 1.3443\n",
            "Epoch 1521/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.8007 - val_loss: 1.3436\n",
            "Epoch 1522/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7996 - val_loss: 1.3445\n",
            "Epoch 1523/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7992 - val_loss: 1.3452\n",
            "Epoch 1524/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.7984 - val_loss: 1.3415\n",
            "Epoch 1525/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.7972 - val_loss: 1.3413\n",
            "Epoch 1526/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.7963 - val_loss: 1.3398\n",
            "Epoch 1527/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.7955 - val_loss: 1.3384\n",
            "Epoch 1528/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7948 - val_loss: 1.3392\n",
            "Epoch 1529/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.7945 - val_loss: 1.3363\n",
            "Epoch 1530/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7929 - val_loss: 1.3363\n",
            "Epoch 1531/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.7927 - val_loss: 1.3348\n",
            "Epoch 1532/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.7918 - val_loss: 1.3348\n",
            "Epoch 1533/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7908 - val_loss: 1.3354\n",
            "Epoch 1534/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.7903 - val_loss: 1.3318\n",
            "Epoch 1535/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7890 - val_loss: 1.3322\n",
            "Epoch 1536/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.7883 - val_loss: 1.3310\n",
            "Epoch 1537/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.7875 - val_loss: 1.3305\n",
            "Epoch 1538/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7870 - val_loss: 1.3307\n",
            "Epoch 1539/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.7862 - val_loss: 1.3288\n",
            "Epoch 1540/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7853 - val_loss: 1.3296\n",
            "Epoch 1541/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.7842 - val_loss: 1.3274\n",
            "Epoch 1542/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.7837 - val_loss: 1.3255\n",
            "Epoch 1543/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.7827 - val_loss: 1.3246\n",
            "Epoch 1544/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7821 - val_loss: 1.3247\n",
            "Epoch 1545/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7815 - val_loss: 1.3258\n",
            "Epoch 1546/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.7802 - val_loss: 1.3225\n",
            "Epoch 1547/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7802 - val_loss: 1.3240\n",
            "Epoch 1548/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.7791 - val_loss: 1.3194\n",
            "Epoch 1549/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.7782 - val_loss: 1.3190\n",
            "Epoch 1550/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.7777 - val_loss: 1.3181\n",
            "Epoch 1551/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7768 - val_loss: 1.3185\n",
            "Epoch 1552/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.7757 - val_loss: 1.3168\n",
            "Epoch 1553/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7752 - val_loss: 1.3180\n",
            "Epoch 1554/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.7741 - val_loss: 1.3167\n",
            "Epoch 1555/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.7734 - val_loss: 1.3153\n",
            "Epoch 1556/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.7729 - val_loss: 1.3152\n",
            "Epoch 1557/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.7725 - val_loss: 1.3140\n",
            "Epoch 1558/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.7713 - val_loss: 1.3118\n",
            "Epoch 1559/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.7709 - val_loss: 1.3099\n",
            "Epoch 1560/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.7697 - val_loss: 1.3095\n",
            "Epoch 1561/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7691 - val_loss: 1.3109\n",
            "Epoch 1562/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.7683 - val_loss: 1.3093\n",
            "Epoch 1563/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.7676 - val_loss: 1.3084\n",
            "Epoch 1564/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7669 - val_loss: 1.3085\n",
            "Epoch 1565/5000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.7663 - val_loss: 1.3066\n",
            "Epoch 1566/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.7654 - val_loss: 1.3054\n",
            "Epoch 1567/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7647 - val_loss: 1.3060\n",
            "Epoch 1568/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.7644 - val_loss: 1.3031\n",
            "Epoch 1569/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.7634 - val_loss: 1.3021\n",
            "Epoch 1570/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.7631 - val_loss: 1.3033\n",
            "Epoch 1571/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7621 - val_loss: 1.3040\n",
            "Epoch 1572/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7613 - val_loss: 1.3030\n",
            "Epoch 1573/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.7609 - val_loss: 1.2994\n",
            "Epoch 1574/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.7597 - val_loss: 1.2979\n",
            "Epoch 1575/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7595 - val_loss: 1.2990\n",
            "Epoch 1576/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.7588 - val_loss: 1.2959\n",
            "Epoch 1577/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7576 - val_loss: 1.2975\n",
            "Epoch 1578/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7570 - val_loss: 1.2975\n",
            "Epoch 1579/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.7561 - val_loss: 1.2959\n",
            "Epoch 1580/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.7562 - val_loss: 1.2958\n",
            "Epoch 1581/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.7549 - val_loss: 1.2954\n",
            "Epoch 1582/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.7546 - val_loss: 1.2920\n",
            "Epoch 1583/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7535 - val_loss: 1.2923\n",
            "Epoch 1584/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7526 - val_loss: 1.2923\n",
            "Epoch 1585/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.7525 - val_loss: 1.2896\n",
            "Epoch 1586/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7515 - val_loss: 1.2905\n",
            "Epoch 1587/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7510 - val_loss: 1.2919\n",
            "Epoch 1588/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7507 - val_loss: 1.2905\n",
            "Epoch 1589/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.7499 - val_loss: 1.2872\n",
            "Epoch 1590/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7489 - val_loss: 1.2883\n",
            "Epoch 1591/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7481 - val_loss: 1.2878\n",
            "Epoch 1592/5000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.7479 - val_loss: 1.2861\n",
            "Epoch 1593/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.7469 - val_loss: 1.2847\n",
            "Epoch 1594/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7465 - val_loss: 1.2868\n",
            "Epoch 1595/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.7456 - val_loss: 1.2834\n",
            "Epoch 1596/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.7447 - val_loss: 1.2830\n",
            "Epoch 1597/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.7442 - val_loss: 1.2822\n",
            "Epoch 1598/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.7436 - val_loss: 1.2822\n",
            "Epoch 1599/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.7429 - val_loss: 1.2814\n",
            "Epoch 1600/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.7426 - val_loss: 1.2793\n",
            "Epoch 1601/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7417 - val_loss: 1.2804\n",
            "Epoch 1602/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.7408 - val_loss: 1.2789\n",
            "Epoch 1603/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.7401 - val_loss: 1.2775\n",
            "Epoch 1604/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.7397 - val_loss: 1.2767\n",
            "Epoch 1605/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7388 - val_loss: 1.2779\n",
            "Epoch 1606/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.7381 - val_loss: 1.2753\n",
            "Epoch 1607/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7380 - val_loss: 1.2763\n",
            "Epoch 1608/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.7371 - val_loss: 1.2745\n",
            "Epoch 1609/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.7366 - val_loss: 1.2727\n",
            "Epoch 1610/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7354 - val_loss: 1.2727\n",
            "Epoch 1611/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7349 - val_loss: 1.2727\n",
            "Epoch 1612/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.7341 - val_loss: 1.2721\n",
            "Epoch 1613/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.7342 - val_loss: 1.2713\n",
            "Epoch 1614/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7335 - val_loss: 1.2719\n",
            "Epoch 1615/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.7327 - val_loss: 1.2688\n",
            "Epoch 1616/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7325 - val_loss: 1.2706\n",
            "Epoch 1617/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.7314 - val_loss: 1.2683\n",
            "Epoch 1618/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.7311 - val_loss: 1.2673\n",
            "Epoch 1619/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.7302 - val_loss: 1.2658\n",
            "Epoch 1620/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.7293 - val_loss: 1.2649\n",
            "Epoch 1621/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7290 - val_loss: 1.2667\n",
            "Epoch 1622/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7281 - val_loss: 1.2658\n",
            "Epoch 1623/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.7275 - val_loss: 1.2643\n",
            "Epoch 1624/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.7273 - val_loss: 1.2631\n",
            "Epoch 1625/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.7266 - val_loss: 1.2624\n",
            "Epoch 1626/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7263 - val_loss: 1.2627\n",
            "Epoch 1627/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7255 - val_loss: 1.2630\n",
            "Epoch 1628/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.7245 - val_loss: 1.2616\n",
            "Epoch 1629/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.7241 - val_loss: 1.2601\n",
            "Epoch 1630/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7240 - val_loss: 1.2606\n",
            "Epoch 1631/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.7229 - val_loss: 1.2579\n",
            "Epoch 1632/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.7223 - val_loss: 1.2567\n",
            "Epoch 1633/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7219 - val_loss: 1.2578\n",
            "Epoch 1634/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7211 - val_loss: 1.2573\n",
            "Epoch 1635/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.7205 - val_loss: 1.2551\n",
            "Epoch 1636/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.7200 - val_loss: 1.2551\n",
            "Epoch 1637/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7193 - val_loss: 1.2571\n",
            "Epoch 1638/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.7190 - val_loss: 1.2540\n",
            "Epoch 1639/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.7181 - val_loss: 1.2530\n",
            "Epoch 1640/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7186 - val_loss: 1.2536\n",
            "Epoch 1641/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.7173 - val_loss: 1.2510\n",
            "Epoch 1642/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7166 - val_loss: 1.2512\n",
            "Epoch 1643/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7158 - val_loss: 1.2512\n",
            "Epoch 1644/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7152 - val_loss: 1.2514\n",
            "Epoch 1645/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.7148 - val_loss: 1.2488\n",
            "Epoch 1646/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.7142 - val_loss: 1.2482\n",
            "Epoch 1647/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.7137 - val_loss: 1.2468\n",
            "Epoch 1648/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.7131 - val_loss: 1.2459\n",
            "Epoch 1649/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7124 - val_loss: 1.2471\n",
            "Epoch 1650/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7126 - val_loss: 1.2485\n",
            "Epoch 1651/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.7114 - val_loss: 1.2449\n",
            "Epoch 1652/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.7108 - val_loss: 1.2440\n",
            "Epoch 1653/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7105 - val_loss: 1.2455\n",
            "Epoch 1654/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7098 - val_loss: 1.2452\n",
            "Epoch 1655/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.7095 - val_loss: 1.2426\n",
            "Epoch 1656/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7095 - val_loss: 1.2429\n",
            "Epoch 1657/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.7084 - val_loss: 1.2425\n",
            "Epoch 1658/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.7074 - val_loss: 1.2410\n",
            "Epoch 1659/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.7076 - val_loss: 1.2388\n",
            "Epoch 1660/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7069 - val_loss: 1.2398\n",
            "Epoch 1661/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7060 - val_loss: 1.2402\n",
            "Epoch 1662/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7054 - val_loss: 1.2391\n",
            "Epoch 1663/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.7050 - val_loss: 1.2371\n",
            "Epoch 1664/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7049 - val_loss: 1.2385\n",
            "Epoch 1665/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.7044 - val_loss: 1.2368\n",
            "Epoch 1666/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7032 - val_loss: 1.2369\n",
            "Epoch 1667/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7026 - val_loss: 1.2374\n",
            "Epoch 1668/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.7022 - val_loss: 1.2353\n",
            "Epoch 1669/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7021 - val_loss: 1.2361\n",
            "Epoch 1670/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.7015 - val_loss: 1.2343\n",
            "Epoch 1671/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.7008 - val_loss: 1.2325\n",
            "Epoch 1672/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.7003 - val_loss: 1.2309\n",
            "Epoch 1673/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7000 - val_loss: 1.2332\n",
            "Epoch 1674/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6992 - val_loss: 1.2318\n",
            "Epoch 1675/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6988 - val_loss: 1.2332\n",
            "Epoch 1676/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6980 - val_loss: 1.2305\n",
            "Epoch 1677/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6971 - val_loss: 1.2307\n",
            "Epoch 1678/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6960 - val_loss: 1.2297\n",
            "Epoch 1679/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6955 - val_loss: 1.2286\n",
            "Epoch 1680/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6944 - val_loss: 1.2279\n",
            "Epoch 1681/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6935 - val_loss: 1.2276\n",
            "Epoch 1682/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6926 - val_loss: 1.2277\n",
            "Epoch 1683/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6920 - val_loss: 1.2270\n",
            "Epoch 1684/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6914 - val_loss: 1.2259\n",
            "Epoch 1685/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6905 - val_loss: 1.2245\n",
            "Epoch 1686/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 1.2249\n",
            "Epoch 1687/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6887 - val_loss: 1.2245\n",
            "Epoch 1688/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6880 - val_loss: 1.2244\n",
            "Epoch 1689/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6873 - val_loss: 1.2227\n",
            "Epoch 1690/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6871 - val_loss: 1.2211\n",
            "Epoch 1691/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6858 - val_loss: 1.2231\n",
            "Epoch 1692/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6854 - val_loss: 1.2222\n",
            "Epoch 1693/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6844 - val_loss: 1.2205\n",
            "Epoch 1694/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6836 - val_loss: 1.2204\n",
            "Epoch 1695/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6831 - val_loss: 1.2204\n",
            "Epoch 1696/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6826 - val_loss: 1.2198\n",
            "Epoch 1697/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6815 - val_loss: 1.2193\n",
            "Epoch 1698/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6811 - val_loss: 1.2178\n",
            "Epoch 1699/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6804 - val_loss: 1.2179\n",
            "Epoch 1700/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6799 - val_loss: 1.2164\n",
            "Epoch 1701/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6792 - val_loss: 1.2160\n",
            "Epoch 1702/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6790 - val_loss: 1.2161\n",
            "Epoch 1703/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6782 - val_loss: 1.2147\n",
            "Epoch 1704/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6779 - val_loss: 1.2150\n",
            "Epoch 1705/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6777 - val_loss: 1.2129\n",
            "Epoch 1706/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6768 - val_loss: 1.2133\n",
            "Epoch 1707/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6763 - val_loss: 1.2124\n",
            "Epoch 1708/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6761 - val_loss: 1.2117\n",
            "Epoch 1709/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6754 - val_loss: 1.2132\n",
            "Epoch 1710/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6751 - val_loss: 1.2124\n",
            "Epoch 1711/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6744 - val_loss: 1.2113\n",
            "Epoch 1712/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6744 - val_loss: 1.2096\n",
            "Epoch 1713/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6733 - val_loss: 1.2088\n",
            "Epoch 1714/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6731 - val_loss: 1.2093\n",
            "Epoch 1715/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6725 - val_loss: 1.2074\n",
            "Epoch 1716/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6721 - val_loss: 1.2085\n",
            "Epoch 1717/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6723 - val_loss: 1.2047\n",
            "Epoch 1718/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6710 - val_loss: 1.2063\n",
            "Epoch 1719/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6706 - val_loss: 1.2052\n",
            "Epoch 1720/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6704 - val_loss: 1.2063\n",
            "Epoch 1721/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6696 - val_loss: 1.2056\n",
            "Epoch 1722/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6693 - val_loss: 1.2048\n",
            "Epoch 1723/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6694 - val_loss: 1.2036\n",
            "Epoch 1724/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6688 - val_loss: 1.2047\n",
            "Epoch 1725/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6678 - val_loss: 1.2028\n",
            "Epoch 1726/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6671 - val_loss: 1.2027\n",
            "Epoch 1727/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6669 - val_loss: 1.2017\n",
            "Epoch 1728/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6662 - val_loss: 1.2015\n",
            "Epoch 1729/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6659 - val_loss: 1.2012\n",
            "Epoch 1730/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6658 - val_loss: 1.2001\n",
            "Epoch 1731/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6650 - val_loss: 1.2001\n",
            "Epoch 1732/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6645 - val_loss: 1.1983\n",
            "Epoch 1733/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6646 - val_loss: 1.1977\n",
            "Epoch 1734/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6636 - val_loss: 1.1979\n",
            "Epoch 1735/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6632 - val_loss: 1.1978\n",
            "Epoch 1736/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6627 - val_loss: 1.1977\n",
            "Epoch 1737/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6625 - val_loss: 1.1981\n",
            "Epoch 1738/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6620 - val_loss: 1.1963\n",
            "Epoch 1739/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6617 - val_loss: 1.1963\n",
            "Epoch 1740/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6609 - val_loss: 1.1966\n",
            "Epoch 1741/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6607 - val_loss: 1.1941\n",
            "Epoch 1742/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6603 - val_loss: 1.1954\n",
            "Epoch 1743/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6605 - val_loss: 1.1921\n",
            "Epoch 1744/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6597 - val_loss: 1.1935\n",
            "Epoch 1745/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6589 - val_loss: 1.1930\n",
            "Epoch 1746/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6584 - val_loss: 1.1931\n",
            "Epoch 1747/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6579 - val_loss: 1.1915\n",
            "Epoch 1748/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6577 - val_loss: 1.1900\n",
            "Epoch 1749/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6572 - val_loss: 1.1910\n",
            "Epoch 1750/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6568 - val_loss: 1.1900\n",
            "Epoch 1751/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6564 - val_loss: 1.1899\n",
            "Epoch 1752/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6562 - val_loss: 1.1918\n",
            "Epoch 1753/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6556 - val_loss: 1.1894\n",
            "Epoch 1754/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6549 - val_loss: 1.1883\n",
            "Epoch 1755/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6545 - val_loss: 1.1883\n",
            "Epoch 1756/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6541 - val_loss: 1.1878\n",
            "Epoch 1757/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6538 - val_loss: 1.1873\n",
            "Epoch 1758/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6534 - val_loss: 1.1863\n",
            "Epoch 1759/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6531 - val_loss: 1.1885\n",
            "Epoch 1760/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6528 - val_loss: 1.1858\n",
            "Epoch 1761/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6522 - val_loss: 1.1863\n",
            "Epoch 1762/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6523 - val_loss: 1.1852\n",
            "Epoch 1763/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6516 - val_loss: 1.1835\n",
            "Epoch 1764/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6513 - val_loss: 1.1856\n",
            "Epoch 1765/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6508 - val_loss: 1.1840\n",
            "Epoch 1766/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6503 - val_loss: 1.1840\n",
            "Epoch 1767/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6502 - val_loss: 1.1835\n",
            "Epoch 1768/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6496 - val_loss: 1.1824\n",
            "Epoch 1769/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6495 - val_loss: 1.1830\n",
            "Epoch 1770/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6488 - val_loss: 1.1815\n",
            "Epoch 1771/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6485 - val_loss: 1.1816\n",
            "Epoch 1772/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6482 - val_loss: 1.1801\n",
            "Epoch 1773/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6476 - val_loss: 1.1808\n",
            "Epoch 1774/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6473 - val_loss: 1.1811\n",
            "Epoch 1775/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6471 - val_loss: 1.1784\n",
            "Epoch 1776/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6470 - val_loss: 1.1786\n",
            "Epoch 1777/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6464 - val_loss: 1.1794\n",
            "Epoch 1778/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6458 - val_loss: 1.1793\n",
            "Epoch 1779/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6455 - val_loss: 1.1778\n",
            "Epoch 1780/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6455 - val_loss: 1.1761\n",
            "Epoch 1781/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6448 - val_loss: 1.1776\n",
            "Epoch 1782/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6444 - val_loss: 1.1772\n",
            "Epoch 1783/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6441 - val_loss: 1.1779\n",
            "Epoch 1784/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6442 - val_loss: 1.1773\n",
            "Epoch 1785/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6432 - val_loss: 1.1759\n",
            "Epoch 1786/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6429 - val_loss: 1.1753\n",
            "Epoch 1787/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6426 - val_loss: 1.1756\n",
            "Epoch 1788/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6423 - val_loss: 1.1763\n",
            "Epoch 1789/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6425 - val_loss: 1.1737\n",
            "Epoch 1790/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6416 - val_loss: 1.1734\n",
            "Epoch 1791/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6413 - val_loss: 1.1740\n",
            "Epoch 1792/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6412 - val_loss: 1.1729\n",
            "Epoch 1793/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6403 - val_loss: 1.1733\n",
            "Epoch 1794/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6402 - val_loss: 1.1742\n",
            "Epoch 1795/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6401 - val_loss: 1.1720\n",
            "Epoch 1796/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6396 - val_loss: 1.1711\n",
            "Epoch 1797/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6393 - val_loss: 1.1725\n",
            "Epoch 1798/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6390 - val_loss: 1.1714\n",
            "Epoch 1799/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6386 - val_loss: 1.1695\n",
            "Epoch 1800/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6381 - val_loss: 1.1693\n",
            "Epoch 1801/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6378 - val_loss: 1.1694\n",
            "Epoch 1802/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6375 - val_loss: 1.1710\n",
            "Epoch 1803/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6373 - val_loss: 1.1693\n",
            "Epoch 1804/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6367 - val_loss: 1.1694\n",
            "Epoch 1805/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6365 - val_loss: 1.1694\n",
            "Epoch 1806/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6361 - val_loss: 1.1677\n",
            "Epoch 1807/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6362 - val_loss: 1.1698\n",
            "Epoch 1808/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6357 - val_loss: 1.1665\n",
            "Epoch 1809/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6353 - val_loss: 1.1675\n",
            "Epoch 1810/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6347 - val_loss: 1.1663\n",
            "Epoch 1811/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6345 - val_loss: 1.1669\n",
            "Epoch 1812/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6343 - val_loss: 1.1658\n",
            "Epoch 1813/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6339 - val_loss: 1.1643\n",
            "Epoch 1814/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6337 - val_loss: 1.1661\n",
            "Epoch 1815/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6334 - val_loss: 1.1668\n",
            "Epoch 1816/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6328 - val_loss: 1.1650\n",
            "Epoch 1817/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6325 - val_loss: 1.1634\n",
            "Epoch 1818/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6323 - val_loss: 1.1628\n",
            "Epoch 1819/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6320 - val_loss: 1.1632\n",
            "Epoch 1820/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6316 - val_loss: 1.1634\n",
            "Epoch 1821/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6314 - val_loss: 1.1619\n",
            "Epoch 1822/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6311 - val_loss: 1.1605\n",
            "Epoch 1823/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6308 - val_loss: 1.1617\n",
            "Epoch 1824/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6300 - val_loss: 1.1614\n",
            "Epoch 1825/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6303 - val_loss: 1.1623\n",
            "Epoch 1826/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6300 - val_loss: 1.1604\n",
            "Epoch 1827/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6294 - val_loss: 1.1599\n",
            "Epoch 1828/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6290 - val_loss: 1.1608\n",
            "Epoch 1829/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6286 - val_loss: 1.1599\n",
            "Epoch 1830/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6282 - val_loss: 1.1595\n",
            "Epoch 1831/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6283 - val_loss: 1.1592\n",
            "Epoch 1832/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6278 - val_loss: 1.1585\n",
            "Epoch 1833/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6275 - val_loss: 1.1586\n",
            "Epoch 1834/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6275 - val_loss: 1.1579\n",
            "Epoch 1835/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6269 - val_loss: 1.1586\n",
            "Epoch 1836/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6272 - val_loss: 1.1598\n",
            "Epoch 1837/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6262 - val_loss: 1.1565\n",
            "Epoch 1838/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6260 - val_loss: 1.1563\n",
            "Epoch 1839/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6261 - val_loss: 1.1572\n",
            "Epoch 1840/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6260 - val_loss: 1.1544\n",
            "Epoch 1841/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6250 - val_loss: 1.1555\n",
            "Epoch 1842/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6249 - val_loss: 1.1544\n",
            "Epoch 1843/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6244 - val_loss: 1.1549\n",
            "Epoch 1844/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6245 - val_loss: 1.1536\n",
            "Epoch 1845/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6238 - val_loss: 1.1538\n",
            "Epoch 1846/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6235 - val_loss: 1.1535\n",
            "Epoch 1847/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6236 - val_loss: 1.1518\n",
            "Epoch 1848/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6230 - val_loss: 1.1541\n",
            "Epoch 1849/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6230 - val_loss: 1.1523\n",
            "Epoch 1850/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6227 - val_loss: 1.1537\n",
            "Epoch 1851/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6225 - val_loss: 1.1541\n",
            "Epoch 1852/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6219 - val_loss: 1.1523\n",
            "Epoch 1853/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6216 - val_loss: 1.1509\n",
            "Epoch 1854/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6210 - val_loss: 1.1512\n",
            "Epoch 1855/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6209 - val_loss: 1.1526\n",
            "Epoch 1856/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6208 - val_loss: 1.1515\n",
            "Epoch 1857/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6204 - val_loss: 1.1498\n",
            "Epoch 1858/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6201 - val_loss: 1.1504\n",
            "Epoch 1859/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6198 - val_loss: 1.1507\n",
            "Epoch 1860/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6195 - val_loss: 1.1490\n",
            "Epoch 1861/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6197 - val_loss: 1.1483\n",
            "Epoch 1862/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6191 - val_loss: 1.1476\n",
            "Epoch 1863/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6185 - val_loss: 1.1478\n",
            "Epoch 1864/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6184 - val_loss: 1.1494\n",
            "Epoch 1865/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6180 - val_loss: 1.1478\n",
            "Epoch 1866/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6178 - val_loss: 1.1478\n",
            "Epoch 1867/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6177 - val_loss: 1.1470\n",
            "Epoch 1868/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6173 - val_loss: 1.1465\n",
            "Epoch 1869/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6170 - val_loss: 1.1463\n",
            "Epoch 1870/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6169 - val_loss: 1.1475\n",
            "Epoch 1871/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6166 - val_loss: 1.1491\n",
            "Epoch 1872/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6163 - val_loss: 1.1456\n",
            "Epoch 1873/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6163 - val_loss: 1.1476\n",
            "Epoch 1874/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6155 - val_loss: 1.1461\n",
            "Epoch 1875/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6153 - val_loss: 1.1450\n",
            "Epoch 1876/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6153 - val_loss: 1.1462\n",
            "Epoch 1877/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6148 - val_loss: 1.1446\n",
            "Epoch 1878/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6152 - val_loss: 1.1421\n",
            "Epoch 1879/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6142 - val_loss: 1.1435\n",
            "Epoch 1880/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6143 - val_loss: 1.1428\n",
            "Epoch 1881/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6144 - val_loss: 1.1447\n",
            "Epoch 1882/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6135 - val_loss: 1.1442\n",
            "Epoch 1883/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6134 - val_loss: 1.1429\n",
            "Epoch 1884/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6131 - val_loss: 1.1422\n",
            "Epoch 1885/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6126 - val_loss: 1.1420\n",
            "Epoch 1886/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6125 - val_loss: 1.1411\n",
            "Epoch 1887/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6125 - val_loss: 1.1419\n",
            "Epoch 1888/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6122 - val_loss: 1.1425\n",
            "Epoch 1889/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6119 - val_loss: 1.1416\n",
            "Epoch 1890/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6115 - val_loss: 1.1423\n",
            "Epoch 1891/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6113 - val_loss: 1.1416\n",
            "Epoch 1892/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6108 - val_loss: 1.1403\n",
            "Epoch 1893/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6113 - val_loss: 1.1385\n",
            "Epoch 1894/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6108 - val_loss: 1.1385\n",
            "Epoch 1895/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6101 - val_loss: 1.1393\n",
            "Epoch 1896/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6099 - val_loss: 1.1392\n",
            "Epoch 1897/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6096 - val_loss: 1.1395\n",
            "Epoch 1898/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6097 - val_loss: 1.1380\n",
            "Epoch 1899/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6094 - val_loss: 1.1385\n",
            "Epoch 1900/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6089 - val_loss: 1.1374\n",
            "Epoch 1901/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6087 - val_loss: 1.1373\n",
            "Epoch 1902/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6082 - val_loss: 1.1375\n",
            "Epoch 1903/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6082 - val_loss: 1.1383\n",
            "Epoch 1904/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6078 - val_loss: 1.1376\n",
            "Epoch 1905/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6080 - val_loss: 1.1349\n",
            "Epoch 1906/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6073 - val_loss: 1.1361\n",
            "Epoch 1907/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6072 - val_loss: 1.1362\n",
            "Epoch 1908/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6069 - val_loss: 1.1364\n",
            "Epoch 1909/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6068 - val_loss: 1.1344\n",
            "Epoch 1910/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6064 - val_loss: 1.1345\n",
            "Epoch 1911/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6062 - val_loss: 1.1358\n",
            "Epoch 1912/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6059 - val_loss: 1.1353\n",
            "Epoch 1913/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6061 - val_loss: 1.1339\n",
            "Epoch 1914/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6056 - val_loss: 1.1341\n",
            "Epoch 1915/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6054 - val_loss: 1.1330\n",
            "Epoch 1916/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6051 - val_loss: 1.1331\n",
            "Epoch 1917/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6047 - val_loss: 1.1325\n",
            "Epoch 1918/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6046 - val_loss: 1.1315\n",
            "Epoch 1919/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6044 - val_loss: 1.1341\n",
            "Epoch 1920/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6041 - val_loss: 1.1338\n",
            "Epoch 1921/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6038 - val_loss: 1.1332\n",
            "Epoch 1922/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6037 - val_loss: 1.1340\n",
            "Epoch 1923/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6036 - val_loss: 1.1324\n",
            "Epoch 1924/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6031 - val_loss: 1.1324\n",
            "Epoch 1925/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6029 - val_loss: 1.1326\n",
            "Epoch 1926/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6026 - val_loss: 1.1325\n",
            "Epoch 1927/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6023 - val_loss: 1.1315\n",
            "Epoch 1928/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6024 - val_loss: 1.1326\n",
            "Epoch 1929/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6020 - val_loss: 1.1311\n",
            "Epoch 1930/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6022 - val_loss: 1.1319\n",
            "Epoch 1931/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6020 - val_loss: 1.1285\n",
            "Epoch 1932/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6015 - val_loss: 1.1292\n",
            "Epoch 1933/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6012 - val_loss: 1.1296\n",
            "Epoch 1934/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6009 - val_loss: 1.1303\n",
            "Epoch 1935/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6007 - val_loss: 1.1297\n",
            "Epoch 1936/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6004 - val_loss: 1.1292\n",
            "Epoch 1937/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6008 - val_loss: 1.1271\n",
            "Epoch 1938/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6000 - val_loss: 1.1283\n",
            "Epoch 1939/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5997 - val_loss: 1.1285\n",
            "Epoch 1940/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5995 - val_loss: 1.1268\n",
            "Epoch 1941/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5993 - val_loss: 1.1278\n",
            "Epoch 1942/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5992 - val_loss: 1.1270\n",
            "Epoch 1943/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5989 - val_loss: 1.1272\n",
            "Epoch 1944/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5986 - val_loss: 1.1271\n",
            "Epoch 1945/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5983 - val_loss: 1.1270\n",
            "Epoch 1946/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5981 - val_loss: 1.1275\n",
            "Epoch 1947/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5980 - val_loss: 1.1261\n",
            "Epoch 1948/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5978 - val_loss: 1.1260\n",
            "Epoch 1949/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5976 - val_loss: 1.1260\n",
            "Epoch 1950/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5975 - val_loss: 1.1269\n",
            "Epoch 1951/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5974 - val_loss: 1.1275\n",
            "Epoch 1952/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5972 - val_loss: 1.1241\n",
            "Epoch 1953/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5968 - val_loss: 1.1241\n",
            "Epoch 1954/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5965 - val_loss: 1.1251\n",
            "Epoch 1955/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5966 - val_loss: 1.1231\n",
            "Epoch 1956/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5963 - val_loss: 1.1256\n",
            "Epoch 1957/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5959 - val_loss: 1.1242\n",
            "Epoch 1958/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5958 - val_loss: 1.1258\n",
            "Epoch 1959/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5954 - val_loss: 1.1242\n",
            "Epoch 1960/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5953 - val_loss: 1.1239\n",
            "Epoch 1961/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5954 - val_loss: 1.1224\n",
            "Epoch 1962/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5948 - val_loss: 1.1229\n",
            "Epoch 1963/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5945 - val_loss: 1.1242\n",
            "Epoch 1964/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5946 - val_loss: 1.1223\n",
            "Epoch 1965/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5947 - val_loss: 1.1216\n",
            "Epoch 1966/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5943 - val_loss: 1.1238\n",
            "Epoch 1967/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5942 - val_loss: 1.1226\n",
            "Epoch 1968/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5937 - val_loss: 1.1217\n",
            "Epoch 1969/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5933 - val_loss: 1.1216\n",
            "Epoch 1970/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5931 - val_loss: 1.1221\n",
            "Epoch 1971/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5929 - val_loss: 1.1208\n",
            "Epoch 1972/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5928 - val_loss: 1.1215\n",
            "Epoch 1973/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5925 - val_loss: 1.1209\n",
            "Epoch 1974/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5928 - val_loss: 1.1218\n",
            "Epoch 1975/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5920 - val_loss: 1.1207\n",
            "Epoch 1976/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5921 - val_loss: 1.1193\n",
            "Epoch 1977/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5918 - val_loss: 1.1192\n",
            "Epoch 1978/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5918 - val_loss: 1.1200\n",
            "Epoch 1979/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5915 - val_loss: 1.1202\n",
            "Epoch 1980/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5913 - val_loss: 1.1185\n",
            "Epoch 1981/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5913 - val_loss: 1.1197\n",
            "Epoch 1982/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5907 - val_loss: 1.1199\n",
            "Epoch 1983/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5909 - val_loss: 1.1184\n",
            "Epoch 1984/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5903 - val_loss: 1.1178\n",
            "Epoch 1985/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5903 - val_loss: 1.1187\n",
            "Epoch 1986/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5900 - val_loss: 1.1180\n",
            "Epoch 1987/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5901 - val_loss: 1.1187\n",
            "Epoch 1988/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5895 - val_loss: 1.1172\n",
            "Epoch 1989/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5894 - val_loss: 1.1174\n",
            "Epoch 1990/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5893 - val_loss: 1.1163\n",
            "Epoch 1991/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5896 - val_loss: 1.1145\n",
            "Epoch 1992/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5887 - val_loss: 1.1158\n",
            "Epoch 1993/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5887 - val_loss: 1.1175\n",
            "Epoch 1994/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5884 - val_loss: 1.1169\n",
            "Epoch 1995/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5883 - val_loss: 1.1157\n",
            "Epoch 1996/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5884 - val_loss: 1.1167\n",
            "Epoch 1997/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5882 - val_loss: 1.1148\n",
            "Epoch 1998/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5882 - val_loss: 1.1168\n",
            "Epoch 1999/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5878 - val_loss: 1.1144\n",
            "Epoch 2000/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5875 - val_loss: 1.1161\n",
            "Epoch 2001/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5874 - val_loss: 1.1168\n",
            "Epoch 2002/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5869 - val_loss: 1.1156\n",
            "Epoch 2003/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5867 - val_loss: 1.1152\n",
            "Epoch 2004/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5868 - val_loss: 1.1129\n",
            "Epoch 2005/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5864 - val_loss: 1.1148\n",
            "Epoch 2006/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5863 - val_loss: 1.1143\n",
            "Epoch 2007/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5860 - val_loss: 1.1149\n",
            "Epoch 2008/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5858 - val_loss: 1.1135\n",
            "Epoch 2009/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5857 - val_loss: 1.1123\n",
            "Epoch 2010/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5856 - val_loss: 1.1141\n",
            "Epoch 2011/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5860 - val_loss: 1.1111\n",
            "Epoch 2012/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5851 - val_loss: 1.1124\n",
            "Epoch 2013/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5850 - val_loss: 1.1139\n",
            "Epoch 2014/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5847 - val_loss: 1.1120\n",
            "Epoch 2015/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5844 - val_loss: 1.1121\n",
            "Epoch 2016/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5848 - val_loss: 1.1123\n",
            "Epoch 2017/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5847 - val_loss: 1.1109\n",
            "Epoch 2018/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5839 - val_loss: 1.1119\n",
            "Epoch 2019/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5838 - val_loss: 1.1114\n",
            "Epoch 2020/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5838 - val_loss: 1.1131\n",
            "Epoch 2021/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5835 - val_loss: 1.1122\n",
            "Epoch 2022/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5834 - val_loss: 1.1121\n",
            "Epoch 2023/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5833 - val_loss: 1.1121\n",
            "Epoch 2024/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5829 - val_loss: 1.1104\n",
            "Epoch 2025/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5827 - val_loss: 1.1110\n",
            "Epoch 2026/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5828 - val_loss: 1.1106\n",
            "Epoch 2027/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5826 - val_loss: 1.1107\n",
            "Epoch 2028/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5824 - val_loss: 1.1095\n",
            "Epoch 2029/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5822 - val_loss: 1.1101\n",
            "Epoch 2030/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5820 - val_loss: 1.1089\n",
            "Epoch 2031/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5820 - val_loss: 1.1101\n",
            "Epoch 2032/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5815 - val_loss: 1.1095\n",
            "Epoch 2033/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5815 - val_loss: 1.1086\n",
            "Epoch 2034/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5815 - val_loss: 1.1073\n",
            "Epoch 2035/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5815 - val_loss: 1.1093\n",
            "Epoch 2036/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5809 - val_loss: 1.1078\n",
            "Epoch 2037/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5807 - val_loss: 1.1084\n",
            "Epoch 2038/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5807 - val_loss: 1.1081\n",
            "Epoch 2039/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5804 - val_loss: 1.1072\n",
            "Epoch 2040/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5803 - val_loss: 1.1075\n",
            "Epoch 2041/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5799 - val_loss: 1.1079\n",
            "Epoch 2042/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5800 - val_loss: 1.1082\n",
            "Epoch 2043/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5797 - val_loss: 1.1072\n",
            "Epoch 2044/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5795 - val_loss: 1.1066\n",
            "Epoch 2045/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5795 - val_loss: 1.1089\n",
            "Epoch 2046/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5793 - val_loss: 1.1091\n",
            "Epoch 2047/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5791 - val_loss: 1.1073\n",
            "Epoch 2048/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5792 - val_loss: 1.1052\n",
            "Epoch 2049/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5791 - val_loss: 1.1070\n",
            "Epoch 2050/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5786 - val_loss: 1.1072\n",
            "Epoch 2051/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5790 - val_loss: 1.1083\n",
            "Epoch 2052/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5781 - val_loss: 1.1069\n",
            "Epoch 2053/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5783 - val_loss: 1.1072\n",
            "Epoch 2054/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5779 - val_loss: 1.1052\n",
            "Epoch 2055/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5779 - val_loss: 1.1041\n",
            "Epoch 2056/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5776 - val_loss: 1.1042\n",
            "Epoch 2057/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5775 - val_loss: 1.1050\n",
            "Epoch 2058/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5774 - val_loss: 1.1044\n",
            "Epoch 2059/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5771 - val_loss: 1.1048\n",
            "Epoch 2060/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5771 - val_loss: 1.1047\n",
            "Epoch 2061/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5772 - val_loss: 1.1052\n",
            "Epoch 2062/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5767 - val_loss: 1.1051\n",
            "Epoch 2063/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5766 - val_loss: 1.1043\n",
            "Epoch 2064/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5768 - val_loss: 1.1044\n",
            "Epoch 2065/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5764 - val_loss: 1.1037\n",
            "Epoch 2066/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5764 - val_loss: 1.1054\n",
            "Epoch 2067/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5759 - val_loss: 1.1051\n",
            "Epoch 2068/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5761 - val_loss: 1.1041\n",
            "Epoch 2069/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5761 - val_loss: 1.1019\n",
            "Epoch 2070/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5755 - val_loss: 1.1026\n",
            "Epoch 2071/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5754 - val_loss: 1.1034\n",
            "Epoch 2072/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5760 - val_loss: 1.1068\n",
            "Epoch 2073/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5753 - val_loss: 1.1033\n",
            "Epoch 2074/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5752 - val_loss: 1.1014\n",
            "Epoch 2075/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5750 - val_loss: 1.1008\n",
            "Epoch 2076/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5746 - val_loss: 1.1014\n",
            "Epoch 2077/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5745 - val_loss: 1.1028\n",
            "Epoch 2078/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5742 - val_loss: 1.1018\n",
            "Epoch 2079/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5739 - val_loss: 1.1028\n",
            "Epoch 2080/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5736 - val_loss: 1.1029\n",
            "Epoch 2081/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5732 - val_loss: 1.1029\n",
            "Epoch 2082/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5729 - val_loss: 1.1016\n",
            "Epoch 2083/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5728 - val_loss: 1.1021\n",
            "Epoch 2084/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5727 - val_loss: 1.1013\n",
            "Epoch 2085/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5728 - val_loss: 1.1027\n",
            "Epoch 2086/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5721 - val_loss: 1.1014\n",
            "Epoch 2087/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5717 - val_loss: 1.1019\n",
            "Epoch 2088/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5720 - val_loss: 1.1027\n",
            "Epoch 2089/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5713 - val_loss: 1.1014\n",
            "Epoch 2090/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5714 - val_loss: 1.1003\n",
            "Epoch 2091/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5711 - val_loss: 1.0999\n",
            "Epoch 2092/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5711 - val_loss: 1.1024\n",
            "Epoch 2093/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5707 - val_loss: 1.1014\n",
            "Epoch 2094/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5707 - val_loss: 1.1019\n",
            "Epoch 2095/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5703 - val_loss: 1.1013\n",
            "Epoch 2096/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5700 - val_loss: 1.1016\n",
            "Epoch 2097/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5700 - val_loss: 1.1006\n",
            "Epoch 2098/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5698 - val_loss: 1.1010\n",
            "Epoch 2099/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5694 - val_loss: 1.1007\n",
            "Epoch 2100/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5693 - val_loss: 1.1003\n",
            "Epoch 2101/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5692 - val_loss: 1.1009\n",
            "Epoch 2102/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5687 - val_loss: 1.1002\n",
            "Epoch 2103/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5686 - val_loss: 1.0997\n",
            "Epoch 2104/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5684 - val_loss: 1.0993\n",
            "Epoch 2105/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5684 - val_loss: 1.1010\n",
            "Epoch 2106/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5681 - val_loss: 1.0993\n",
            "Epoch 2107/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5681 - val_loss: 1.0991\n",
            "Epoch 2108/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5676 - val_loss: 1.0996\n",
            "Epoch 2109/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5676 - val_loss: 1.0997\n",
            "Epoch 2110/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5674 - val_loss: 1.0994\n",
            "Epoch 2111/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5673 - val_loss: 1.1009\n",
            "Epoch 2112/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5671 - val_loss: 1.0987\n",
            "Epoch 2113/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5671 - val_loss: 1.0989\n",
            "Epoch 2114/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5668 - val_loss: 1.0981\n",
            "Epoch 2115/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5666 - val_loss: 1.0984\n",
            "Epoch 2116/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5663 - val_loss: 1.0997\n",
            "Epoch 2117/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5663 - val_loss: 1.1001\n",
            "Epoch 2118/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5663 - val_loss: 1.0980\n",
            "Epoch 2119/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5662 - val_loss: 1.1003\n",
            "Epoch 2120/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5658 - val_loss: 1.0993\n",
            "Epoch 2121/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5656 - val_loss: 1.0977\n",
            "Epoch 2122/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5654 - val_loss: 1.0972\n",
            "Epoch 2123/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5654 - val_loss: 1.0978\n",
            "Epoch 2124/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5653 - val_loss: 1.0987\n",
            "Epoch 2125/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5649 - val_loss: 1.0980\n",
            "Epoch 2126/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5646 - val_loss: 1.0972\n",
            "Epoch 2127/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5648 - val_loss: 1.0978\n",
            "Epoch 2128/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5646 - val_loss: 1.0963\n",
            "Epoch 2129/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5645 - val_loss: 1.0988\n",
            "Epoch 2130/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5643 - val_loss: 1.0968\n",
            "Epoch 2131/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5639 - val_loss: 1.0965\n",
            "Epoch 2132/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5638 - val_loss: 1.0974\n",
            "Epoch 2133/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5643 - val_loss: 1.0949\n",
            "Epoch 2134/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5635 - val_loss: 1.0955\n",
            "Epoch 2135/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5634 - val_loss: 1.0952\n",
            "Epoch 2136/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5633 - val_loss: 1.0951\n",
            "Epoch 2137/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5630 - val_loss: 1.0970\n",
            "Epoch 2138/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5628 - val_loss: 1.0974\n",
            "Epoch 2139/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5631 - val_loss: 1.0969\n",
            "Epoch 2140/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5627 - val_loss: 1.0961\n",
            "Epoch 2141/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5626 - val_loss: 1.0971\n",
            "Epoch 2142/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5622 - val_loss: 1.0963\n",
            "Epoch 2143/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5621 - val_loss: 1.0954\n",
            "Epoch 2144/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5619 - val_loss: 1.0951\n",
            "Epoch 2145/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5621 - val_loss: 1.0966\n",
            "Epoch 2146/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5619 - val_loss: 1.0959\n",
            "Epoch 2147/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5616 - val_loss: 1.0953\n",
            "Epoch 2148/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5615 - val_loss: 1.0954\n",
            "Epoch 2149/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5614 - val_loss: 1.0961\n",
            "Epoch 2150/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5612 - val_loss: 1.0949\n",
            "Epoch 2151/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5611 - val_loss: 1.0951\n",
            "Epoch 2152/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5610 - val_loss: 1.0950\n",
            "Epoch 2153/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5608 - val_loss: 1.0946\n",
            "Epoch 2154/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5607 - val_loss: 1.0951\n",
            "Epoch 2155/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5605 - val_loss: 1.0938\n",
            "Epoch 2156/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5604 - val_loss: 1.0929\n",
            "Epoch 2157/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5604 - val_loss: 1.0924\n",
            "Epoch 2158/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5601 - val_loss: 1.0929\n",
            "Epoch 2159/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5601 - val_loss: 1.0943\n",
            "Epoch 2160/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5599 - val_loss: 1.0951\n",
            "Epoch 2161/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5597 - val_loss: 1.0937\n",
            "Epoch 2162/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5595 - val_loss: 1.0946\n",
            "Epoch 2163/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5595 - val_loss: 1.0926\n",
            "Epoch 2164/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5593 - val_loss: 1.0930\n",
            "Epoch 2165/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5592 - val_loss: 1.0932\n",
            "Epoch 2166/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5592 - val_loss: 1.0941\n",
            "Epoch 2167/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5589 - val_loss: 1.0938\n",
            "Epoch 2168/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5589 - val_loss: 1.0934\n",
            "Epoch 2169/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5590 - val_loss: 1.0935\n",
            "Epoch 2170/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5591 - val_loss: 1.0917\n",
            "Epoch 2171/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5583 - val_loss: 1.0935\n",
            "Epoch 2172/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5583 - val_loss: 1.0943\n",
            "Epoch 2173/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5582 - val_loss: 1.0919\n",
            "Epoch 2174/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5584 - val_loss: 1.0943\n",
            "Epoch 2175/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5577 - val_loss: 1.0934\n",
            "Epoch 2176/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5578 - val_loss: 1.0938\n",
            "Epoch 2177/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5575 - val_loss: 1.0929\n",
            "Epoch 2178/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5574 - val_loss: 1.0931\n",
            "Epoch 2179/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5573 - val_loss: 1.0913\n",
            "Epoch 2180/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5574 - val_loss: 1.0911\n",
            "Epoch 2181/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5574 - val_loss: 1.0921\n",
            "Epoch 2182/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5570 - val_loss: 1.0924\n",
            "Epoch 2183/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5567 - val_loss: 1.0915\n",
            "Epoch 2184/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5567 - val_loss: 1.0915\n",
            "Epoch 2185/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5566 - val_loss: 1.0916\n",
            "Epoch 2186/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5568 - val_loss: 1.0921\n",
            "Epoch 2187/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5565 - val_loss: 1.0905\n",
            "Epoch 2188/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5564 - val_loss: 1.0913\n",
            "Epoch 2189/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5563 - val_loss: 1.0919\n",
            "Epoch 2190/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5561 - val_loss: 1.0913\n",
            "Epoch 2191/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5562 - val_loss: 1.0918\n",
            "Epoch 2192/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5558 - val_loss: 1.0904\n",
            "Epoch 2193/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5559 - val_loss: 1.0894\n",
            "Epoch 2194/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5554 - val_loss: 1.0910\n",
            "Epoch 2195/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5553 - val_loss: 1.0910\n",
            "Epoch 2196/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5554 - val_loss: 1.0902\n",
            "Epoch 2197/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5552 - val_loss: 1.0900\n",
            "Epoch 2198/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5551 - val_loss: 1.0910\n",
            "Epoch 2199/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5550 - val_loss: 1.0917\n",
            "Epoch 2200/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5549 - val_loss: 1.0915\n",
            "Epoch 2201/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5551 - val_loss: 1.0912\n",
            "Epoch 2202/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5551 - val_loss: 1.0891\n",
            "Epoch 2203/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5546 - val_loss: 1.0883\n",
            "Epoch 2204/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5544 - val_loss: 1.0901\n",
            "Epoch 2205/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5542 - val_loss: 1.0912\n",
            "Epoch 2206/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5541 - val_loss: 1.0902\n",
            "Epoch 2207/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5541 - val_loss: 1.0913\n",
            "Epoch 2208/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5541 - val_loss: 1.0888\n",
            "Epoch 2209/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5539 - val_loss: 1.0879\n",
            "Epoch 2210/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5536 - val_loss: 1.0888\n",
            "Epoch 2211/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5537 - val_loss: 1.0895\n",
            "Epoch 2212/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5535 - val_loss: 1.0893\n",
            "Epoch 2213/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5535 - val_loss: 1.0901\n",
            "Epoch 2214/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5535 - val_loss: 1.0883\n",
            "Epoch 2215/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5535 - val_loss: 1.0910\n",
            "Epoch 2216/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5531 - val_loss: 1.0896\n",
            "Epoch 2217/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5528 - val_loss: 1.0885\n",
            "Epoch 2218/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5531 - val_loss: 1.0883\n",
            "Epoch 2219/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5527 - val_loss: 1.0891\n",
            "Epoch 2220/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5527 - val_loss: 1.0893\n",
            "Epoch 2221/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5526 - val_loss: 1.0877\n",
            "Epoch 2222/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5526 - val_loss: 1.0885\n",
            "Epoch 2223/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5524 - val_loss: 1.0890\n",
            "Epoch 2224/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5522 - val_loss: 1.0876\n",
            "Epoch 2225/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5520 - val_loss: 1.0879\n",
            "Epoch 2226/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5518 - val_loss: 1.0869\n",
            "Epoch 2227/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5518 - val_loss: 1.0867\n",
            "Epoch 2228/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5519 - val_loss: 1.0891\n",
            "Epoch 2229/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5517 - val_loss: 1.0868\n",
            "Epoch 2230/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5518 - val_loss: 1.0887\n",
            "Epoch 2231/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5514 - val_loss: 1.0874\n",
            "Epoch 2232/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5514 - val_loss: 1.0875\n",
            "Epoch 2233/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5513 - val_loss: 1.0869\n",
            "Epoch 2234/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5512 - val_loss: 1.0868\n",
            "Epoch 2235/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5510 - val_loss: 1.0863\n",
            "Epoch 2236/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5513 - val_loss: 1.0893\n",
            "Epoch 2237/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5510 - val_loss: 1.0895\n",
            "Epoch 2238/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5508 - val_loss: 1.0874\n",
            "Epoch 2239/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5510 - val_loss: 1.0865\n",
            "Epoch 2240/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5506 - val_loss: 1.0879\n",
            "Epoch 2241/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5504 - val_loss: 1.0887\n",
            "Epoch 2242/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5503 - val_loss: 1.0885\n",
            "Epoch 2243/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5503 - val_loss: 1.0876\n",
            "Epoch 2244/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5502 - val_loss: 1.0853\n",
            "Epoch 2245/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5501 - val_loss: 1.0849\n",
            "Epoch 2246/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5499 - val_loss: 1.0864\n",
            "Epoch 2247/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5501 - val_loss: 1.0871\n",
            "Epoch 2248/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5498 - val_loss: 1.0877\n",
            "Epoch 2249/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5496 - val_loss: 1.0858\n",
            "Epoch 2250/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5495 - val_loss: 1.0864\n",
            "Epoch 2251/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5493 - val_loss: 1.0865\n",
            "Epoch 2252/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5493 - val_loss: 1.0862\n",
            "Epoch 2253/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5494 - val_loss: 1.0856\n",
            "Epoch 2254/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5490 - val_loss: 1.0853\n",
            "Epoch 2255/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5490 - val_loss: 1.0853\n",
            "Epoch 2256/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5492 - val_loss: 1.0839\n",
            "Epoch 2257/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5489 - val_loss: 1.0853\n",
            "Epoch 2258/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5486 - val_loss: 1.0854\n",
            "Epoch 2259/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5486 - val_loss: 1.0848\n",
            "Epoch 2260/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5485 - val_loss: 1.0861\n",
            "Epoch 2261/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5484 - val_loss: 1.0843\n",
            "Epoch 2262/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5485 - val_loss: 1.0850\n",
            "Epoch 2263/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5482 - val_loss: 1.0851\n",
            "Epoch 2264/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5482 - val_loss: 1.0861\n",
            "Epoch 2265/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5481 - val_loss: 1.0850\n",
            "Epoch 2266/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5481 - val_loss: 1.0863\n",
            "Epoch 2267/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5482 - val_loss: 1.0841\n",
            "Epoch 2268/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5476 - val_loss: 1.0841\n",
            "Epoch 2269/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5478 - val_loss: 1.0834\n",
            "Epoch 2270/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5479 - val_loss: 1.0870\n",
            "Epoch 2271/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5479 - val_loss: 1.0840\n",
            "Epoch 2272/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5474 - val_loss: 1.0835\n",
            "Epoch 2273/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5477 - val_loss: 1.0853\n",
            "Epoch 2274/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5472 - val_loss: 1.0847\n",
            "Epoch 2275/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5471 - val_loss: 1.0847\n",
            "Epoch 2276/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5471 - val_loss: 1.0844\n",
            "Epoch 2277/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5470 - val_loss: 1.0855\n",
            "Epoch 2278/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5468 - val_loss: 1.0848\n",
            "Epoch 2279/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5468 - val_loss: 1.0843\n",
            "Epoch 2280/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5467 - val_loss: 1.0832\n",
            "Epoch 2281/5000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5467 - val_loss: 1.0829\n",
            "Epoch 2282/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5466 - val_loss: 1.0851\n",
            "Epoch 2283/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5462 - val_loss: 1.0848\n",
            "Epoch 2284/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5462 - val_loss: 1.0840\n",
            "Epoch 2285/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5464 - val_loss: 1.0849\n",
            "Epoch 2286/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5462 - val_loss: 1.0852\n",
            "Epoch 2287/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5459 - val_loss: 1.0835\n",
            "Epoch 2288/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5459 - val_loss: 1.0840\n",
            "Epoch 2289/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5459 - val_loss: 1.0838\n",
            "Epoch 2290/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5459 - val_loss: 1.0835\n",
            "Epoch 2291/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5458 - val_loss: 1.0834\n",
            "Epoch 2292/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5457 - val_loss: 1.0828\n",
            "Epoch 2293/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5455 - val_loss: 1.0831\n",
            "Epoch 2294/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5454 - val_loss: 1.0838\n",
            "Epoch 2295/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5454 - val_loss: 1.0824\n",
            "Epoch 2296/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5452 - val_loss: 1.0833\n",
            "Epoch 2297/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5454 - val_loss: 1.0813\n",
            "Epoch 2298/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5459 - val_loss: 1.0838\n",
            "Epoch 2299/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5451 - val_loss: 1.0823\n",
            "Epoch 2300/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5449 - val_loss: 1.0824\n",
            "Epoch 2301/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5450 - val_loss: 1.0841\n",
            "Epoch 2302/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5446 - val_loss: 1.0828\n",
            "Epoch 2303/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5446 - val_loss: 1.0822\n",
            "Epoch 2304/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5446 - val_loss: 1.0817\n",
            "Epoch 2305/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5445 - val_loss: 1.0845\n",
            "Epoch 2306/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5443 - val_loss: 1.0826\n",
            "Epoch 2307/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5442 - val_loss: 1.0824\n",
            "Epoch 2308/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5444 - val_loss: 1.0809\n",
            "Epoch 2309/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5441 - val_loss: 1.0820\n",
            "Epoch 2310/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5441 - val_loss: 1.0835\n",
            "Epoch 2311/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5441 - val_loss: 1.0825\n",
            "Epoch 2312/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5438 - val_loss: 1.0825\n",
            "Epoch 2313/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5438 - val_loss: 1.0831\n",
            "Epoch 2314/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5440 - val_loss: 1.0810\n",
            "Epoch 2315/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5436 - val_loss: 1.0825\n",
            "Epoch 2316/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5437 - val_loss: 1.0828\n",
            "Epoch 2317/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5435 - val_loss: 1.0812\n",
            "Epoch 2318/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5435 - val_loss: 1.0822\n",
            "Epoch 2319/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5434 - val_loss: 1.0821\n",
            "Epoch 2320/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5438 - val_loss: 1.0798\n",
            "Epoch 2321/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5431 - val_loss: 1.0823\n",
            "Epoch 2322/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5433 - val_loss: 1.0827\n",
            "Epoch 2323/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5429 - val_loss: 1.0833\n",
            "Epoch 2324/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5427 - val_loss: 1.0821\n",
            "Epoch 2325/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5429 - val_loss: 1.0816\n",
            "Epoch 2326/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5428 - val_loss: 1.0819\n",
            "Epoch 2327/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5426 - val_loss: 1.0822\n",
            "Epoch 2328/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5426 - val_loss: 1.0809\n",
            "Epoch 2329/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5425 - val_loss: 1.0803\n",
            "Epoch 2330/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5423 - val_loss: 1.0809\n",
            "Epoch 2331/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5422 - val_loss: 1.0818\n",
            "Epoch 2332/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5424 - val_loss: 1.0831\n",
            "Epoch 2333/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5423 - val_loss: 1.0806\n",
            "Epoch 2334/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5420 - val_loss: 1.0806\n",
            "Epoch 2335/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5420 - val_loss: 1.0809\n",
            "Epoch 2336/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5418 - val_loss: 1.0803\n",
            "Epoch 2337/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5418 - val_loss: 1.0812\n",
            "Epoch 2338/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5420 - val_loss: 1.0826\n",
            "Epoch 2339/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5418 - val_loss: 1.0818\n",
            "Epoch 2340/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5414 - val_loss: 1.0815\n",
            "Epoch 2341/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5414 - val_loss: 1.0819\n",
            "Epoch 2342/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5416 - val_loss: 1.0813\n",
            "Epoch 2343/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5413 - val_loss: 1.0805\n",
            "Epoch 2344/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5412 - val_loss: 1.0799\n",
            "Epoch 2345/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5413 - val_loss: 1.0790\n",
            "Epoch 2346/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5412 - val_loss: 1.0810\n",
            "Epoch 2347/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5410 - val_loss: 1.0808\n",
            "Epoch 2348/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5409 - val_loss: 1.0818\n",
            "Epoch 2349/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5407 - val_loss: 1.0817\n",
            "Epoch 2350/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5410 - val_loss: 1.0794\n",
            "Epoch 2351/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5409 - val_loss: 1.0823\n",
            "Epoch 2352/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5407 - val_loss: 1.0810\n",
            "Epoch 2353/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5405 - val_loss: 1.0804\n",
            "Epoch 2354/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5404 - val_loss: 1.0800\n",
            "Epoch 2355/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5403 - val_loss: 1.0800\n",
            "Epoch 2356/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5407 - val_loss: 1.0789\n",
            "Epoch 2357/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5405 - val_loss: 1.0821\n",
            "Epoch 2358/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5402 - val_loss: 1.0819\n",
            "Epoch 2359/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5403 - val_loss: 1.0832\n",
            "Epoch 2360/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5402 - val_loss: 1.0799\n",
            "Epoch 2361/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5401 - val_loss: 1.0808\n",
            "Epoch 2362/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5399 - val_loss: 1.0798\n",
            "Epoch 2363/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5398 - val_loss: 1.0807\n",
            "Epoch 2364/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5396 - val_loss: 1.0803\n",
            "Epoch 2365/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5397 - val_loss: 1.0807\n",
            "Epoch 2366/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5398 - val_loss: 1.0798\n",
            "Epoch 2367/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5396 - val_loss: 1.0795\n",
            "Epoch 2368/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5397 - val_loss: 1.0817\n",
            "Epoch 2369/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5393 - val_loss: 1.0815\n",
            "Epoch 2370/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5393 - val_loss: 1.0806\n",
            "Epoch 2371/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5393 - val_loss: 1.0790\n",
            "Epoch 2372/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5392 - val_loss: 1.0790\n",
            "Epoch 2373/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5391 - val_loss: 1.0804\n",
            "Epoch 2374/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5389 - val_loss: 1.0786\n",
            "Epoch 2375/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5389 - val_loss: 1.0790\n",
            "Epoch 2376/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5388 - val_loss: 1.0782\n",
            "Epoch 2377/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5388 - val_loss: 1.0794\n",
            "Epoch 2378/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5392 - val_loss: 1.0824\n",
            "Epoch 2379/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5390 - val_loss: 1.0786\n",
            "Epoch 2380/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5387 - val_loss: 1.0785\n",
            "Epoch 2381/5000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5385 - val_loss: 1.0780\n",
            "Epoch 2382/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5385 - val_loss: 1.0791\n",
            "Epoch 2383/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5382 - val_loss: 1.0796\n",
            "Epoch 2384/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5382 - val_loss: 1.0797\n",
            "Epoch 2385/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5384 - val_loss: 1.0800\n",
            "Epoch 2386/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5384 - val_loss: 1.0778\n",
            "Epoch 2387/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5380 - val_loss: 1.0792\n",
            "Epoch 2388/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5380 - val_loss: 1.0780\n",
            "Epoch 2389/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5379 - val_loss: 1.0790\n",
            "Epoch 2390/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5379 - val_loss: 1.0781\n",
            "Epoch 2391/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5378 - val_loss: 1.0790\n",
            "Epoch 2392/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5379 - val_loss: 1.0797\n",
            "Epoch 2393/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5376 - val_loss: 1.0784\n",
            "Epoch 2394/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5375 - val_loss: 1.0794\n",
            "Epoch 2395/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5375 - val_loss: 1.0785\n",
            "Epoch 2396/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5377 - val_loss: 1.0796\n",
            "Epoch 2397/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5372 - val_loss: 1.0791\n",
            "Epoch 2398/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5372 - val_loss: 1.0794\n",
            "Epoch 2399/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5377 - val_loss: 1.0772\n",
            "Epoch 2400/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5372 - val_loss: 1.0776\n",
            "Epoch 2401/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5372 - val_loss: 1.0802\n",
            "Epoch 2402/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5369 - val_loss: 1.0790\n",
            "Epoch 2403/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5371 - val_loss: 1.0806\n",
            "Epoch 2404/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5368 - val_loss: 1.0795\n",
            "Epoch 2405/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5367 - val_loss: 1.0794\n",
            "Epoch 2406/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5369 - val_loss: 1.0778\n",
            "Epoch 2407/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5366 - val_loss: 1.0784\n",
            "Epoch 2408/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5366 - val_loss: 1.0781\n",
            "Epoch 2409/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5365 - val_loss: 1.0777\n",
            "Epoch 2410/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5366 - val_loss: 1.0789\n",
            "Epoch 2411/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5366 - val_loss: 1.0767\n",
            "Epoch 2412/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5366 - val_loss: 1.0789\n",
            "Epoch 2413/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5363 - val_loss: 1.0784\n",
            "Epoch 2414/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5361 - val_loss: 1.0789\n",
            "Epoch 2415/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5362 - val_loss: 1.0790\n",
            "Epoch 2416/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5367 - val_loss: 1.0760\n",
            "Epoch 2417/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5363 - val_loss: 1.0785\n",
            "Epoch 2418/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5360 - val_loss: 1.0797\n",
            "Epoch 2419/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5358 - val_loss: 1.0787\n",
            "Epoch 2420/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5361 - val_loss: 1.0772\n",
            "Epoch 2421/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5357 - val_loss: 1.0775\n",
            "Epoch 2422/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5360 - val_loss: 1.0796\n",
            "Epoch 2423/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5358 - val_loss: 1.0779\n",
            "Epoch 2424/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5357 - val_loss: 1.0772\n",
            "Epoch 2425/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5355 - val_loss: 1.0768\n",
            "Epoch 2426/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5356 - val_loss: 1.0771\n",
            "Epoch 2427/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5352 - val_loss: 1.0783\n",
            "Epoch 2428/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5355 - val_loss: 1.0796\n",
            "Epoch 2429/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5353 - val_loss: 1.0775\n",
            "Epoch 2430/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5352 - val_loss: 1.0769\n",
            "Epoch 2431/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5350 - val_loss: 1.0774\n",
            "Epoch 2432/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5352 - val_loss: 1.0795\n",
            "Epoch 2433/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5350 - val_loss: 1.0789\n",
            "Epoch 2434/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5349 - val_loss: 1.0789\n",
            "Epoch 2435/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5348 - val_loss: 1.0787\n",
            "Epoch 2436/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5348 - val_loss: 1.0782\n",
            "Epoch 2437/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5348 - val_loss: 1.0771\n",
            "Epoch 2438/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5346 - val_loss: 1.0775\n",
            "Epoch 2439/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5347 - val_loss: 1.0788\n",
            "Epoch 2440/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5350 - val_loss: 1.0766\n",
            "Epoch 2441/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5345 - val_loss: 1.0778\n",
            "Epoch 2442/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5348 - val_loss: 1.0764\n",
            "Epoch 2443/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5344 - val_loss: 1.0780\n",
            "Epoch 2444/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5344 - val_loss: 1.0793\n",
            "Epoch 2445/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5342 - val_loss: 1.0793\n",
            "Epoch 2446/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5342 - val_loss: 1.0789\n",
            "Epoch 2447/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5343 - val_loss: 1.0766\n",
            "Epoch 2448/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5342 - val_loss: 1.0768\n",
            "Epoch 2449/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5339 - val_loss: 1.0765\n",
            "Epoch 2450/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5339 - val_loss: 1.0762\n",
            "Epoch 2451/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5340 - val_loss: 1.0783\n",
            "Epoch 2452/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5338 - val_loss: 1.0795\n",
            "Epoch 2453/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5338 - val_loss: 1.0794\n",
            "Epoch 2454/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5341 - val_loss: 1.0759\n",
            "Epoch 2455/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5337 - val_loss: 1.0770\n",
            "Epoch 2456/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5336 - val_loss: 1.0766\n",
            "Epoch 2457/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5335 - val_loss: 1.0760\n",
            "Epoch 2458/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5334 - val_loss: 1.0767\n",
            "Epoch 2459/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5333 - val_loss: 1.0772\n",
            "Epoch 2460/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5333 - val_loss: 1.0768\n",
            "Epoch 2461/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5336 - val_loss: 1.0763\n",
            "Epoch 2462/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5332 - val_loss: 1.0767\n",
            "Epoch 2463/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5332 - val_loss: 1.0760\n",
            "Epoch 2464/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5331 - val_loss: 1.0770\n",
            "Epoch 2465/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5331 - val_loss: 1.0775\n",
            "Epoch 2466/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5332 - val_loss: 1.0769\n",
            "Epoch 2467/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5330 - val_loss: 1.0782\n",
            "Epoch 2468/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5327 - val_loss: 1.0766\n",
            "Epoch 2469/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5328 - val_loss: 1.0770\n",
            "Epoch 2470/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5327 - val_loss: 1.0767\n",
            "Epoch 2471/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5328 - val_loss: 1.0779\n",
            "Epoch 2472/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5326 - val_loss: 1.0768\n",
            "Epoch 2473/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5327 - val_loss: 1.0766\n",
            "Epoch 2474/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5325 - val_loss: 1.0767\n",
            "Epoch 2475/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5325 - val_loss: 1.0776\n",
            "Epoch 2476/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5324 - val_loss: 1.0757\n",
            "Epoch 2477/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5324 - val_loss: 1.0773\n",
            "Epoch 2478/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5323 - val_loss: 1.0771\n",
            "Epoch 2479/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5322 - val_loss: 1.0766\n",
            "Epoch 2480/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5322 - val_loss: 1.0760\n",
            "Epoch 2481/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5323 - val_loss: 1.0751\n",
            "Epoch 2482/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5321 - val_loss: 1.0753\n",
            "Epoch 2483/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5321 - val_loss: 1.0774\n",
            "Epoch 2484/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5319 - val_loss: 1.0774\n",
            "Epoch 2485/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5319 - val_loss: 1.0762\n",
            "Epoch 2486/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5321 - val_loss: 1.0751\n",
            "Epoch 2487/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5319 - val_loss: 1.0771\n",
            "Epoch 2488/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5319 - val_loss: 1.0752\n",
            "Epoch 2489/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5317 - val_loss: 1.0757\n",
            "Epoch 2490/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5314 - val_loss: 1.0772\n",
            "Epoch 2491/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5314 - val_loss: 1.0771\n",
            "Epoch 2492/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5314 - val_loss: 1.0773\n",
            "Epoch 2493/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5315 - val_loss: 1.0780\n",
            "Epoch 2494/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5316 - val_loss: 1.0755\n",
            "Epoch 2495/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5314 - val_loss: 1.0777\n",
            "Epoch 2496/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5314 - val_loss: 1.0760\n",
            "Epoch 2497/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5312 - val_loss: 1.0763\n",
            "Epoch 2498/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5314 - val_loss: 1.0756\n",
            "Epoch 2499/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5310 - val_loss: 1.0758\n",
            "Epoch 2500/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5310 - val_loss: 1.0765\n",
            "Epoch 2501/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5312 - val_loss: 1.0774\n",
            "Epoch 2502/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5309 - val_loss: 1.0764\n",
            "Epoch 2503/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5308 - val_loss: 1.0768\n",
            "Epoch 2504/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5307 - val_loss: 1.0764\n",
            "Epoch 2505/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5307 - val_loss: 1.0756\n",
            "Epoch 2506/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5306 - val_loss: 1.0759\n",
            "Epoch 2507/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5307 - val_loss: 1.0765\n",
            "Epoch 2508/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5306 - val_loss: 1.0754\n",
            "Epoch 2509/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5307 - val_loss: 1.0748\n",
            "Epoch 2510/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5305 - val_loss: 1.0761\n",
            "Epoch 2511/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5308 - val_loss: 1.0775\n",
            "Epoch 2512/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5305 - val_loss: 1.0766\n",
            "Epoch 2513/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5303 - val_loss: 1.0750\n",
            "Epoch 2514/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5304 - val_loss: 1.0763\n",
            "Epoch 2515/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5301 - val_loss: 1.0760\n",
            "Epoch 2516/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5301 - val_loss: 1.0754\n",
            "Epoch 2517/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5305 - val_loss: 1.0737\n",
            "Epoch 2518/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5302 - val_loss: 1.0761\n",
            "Epoch 2519/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5303 - val_loss: 1.0770\n",
            "Epoch 2520/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5302 - val_loss: 1.0746\n",
            "Epoch 2521/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5302 - val_loss: 1.0757\n",
            "Epoch 2522/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5303 - val_loss: 1.0768\n",
            "Epoch 2523/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5298 - val_loss: 1.0754\n",
            "Epoch 2524/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5300 - val_loss: 1.0761\n",
            "Epoch 2525/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5299 - val_loss: 1.0744\n",
            "Epoch 2526/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5297 - val_loss: 1.0750\n",
            "Epoch 2527/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5296 - val_loss: 1.0750\n",
            "Epoch 2528/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5295 - val_loss: 1.0750\n",
            "Epoch 2529/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5296 - val_loss: 1.0758\n",
            "Epoch 2530/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5294 - val_loss: 1.0752\n",
            "Epoch 2531/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5298 - val_loss: 1.0748\n",
            "Epoch 2532/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5295 - val_loss: 1.0741\n",
            "Epoch 2533/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5294 - val_loss: 1.0751\n",
            "Epoch 2534/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5294 - val_loss: 1.0762\n",
            "Epoch 2535/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5293 - val_loss: 1.0742\n",
            "Epoch 2536/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5292 - val_loss: 1.0756\n",
            "Epoch 2537/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5292 - val_loss: 1.0740\n",
            "Epoch 2538/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5294 - val_loss: 1.0757\n",
            "Epoch 2539/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5293 - val_loss: 1.0763\n",
            "Epoch 2540/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5298 - val_loss: 1.0725\n",
            "Epoch 2541/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5293 - val_loss: 1.0748\n",
            "Epoch 2542/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5289 - val_loss: 1.0742\n",
            "Epoch 2543/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5290 - val_loss: 1.0741\n",
            "Epoch 2544/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5289 - val_loss: 1.0759\n",
            "Epoch 2545/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5289 - val_loss: 1.0743\n",
            "Epoch 2546/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5290 - val_loss: 1.0757\n",
            "Epoch 2547/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5289 - val_loss: 1.0759\n",
            "Epoch 2548/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5288 - val_loss: 1.0738\n",
            "Epoch 2549/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5287 - val_loss: 1.0751\n",
            "Epoch 2550/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5286 - val_loss: 1.0747\n",
            "Epoch 2551/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5287 - val_loss: 1.0764\n",
            "Epoch 2552/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5285 - val_loss: 1.0750\n",
            "Epoch 2553/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5285 - val_loss: 1.0756\n",
            "Epoch 2554/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5286 - val_loss: 1.0746\n",
            "Epoch 2555/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5284 - val_loss: 1.0752\n",
            "Epoch 2556/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5284 - val_loss: 1.0739\n",
            "Epoch 2557/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5284 - val_loss: 1.0761\n",
            "Epoch 2558/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5283 - val_loss: 1.0755\n",
            "Epoch 2559/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5283 - val_loss: 1.0741\n",
            "Epoch 2560/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5285 - val_loss: 1.0771\n",
            "Epoch 2561/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5283 - val_loss: 1.0760\n",
            "Epoch 2562/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5283 - val_loss: 1.0735\n",
            "Epoch 2563/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5280 - val_loss: 1.0733\n",
            "Epoch 2564/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5281 - val_loss: 1.0746\n",
            "Epoch 2565/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5279 - val_loss: 1.0745\n",
            "Epoch 2566/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5280 - val_loss: 1.0755\n",
            "Epoch 2567/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5279 - val_loss: 1.0743\n",
            "Epoch 2568/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5277 - val_loss: 1.0743\n",
            "Epoch 2569/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5277 - val_loss: 1.0740\n",
            "Epoch 2570/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5277 - val_loss: 1.0735\n",
            "Epoch 2571/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5277 - val_loss: 1.0751\n",
            "Epoch 2572/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5275 - val_loss: 1.0738\n",
            "Epoch 2573/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5276 - val_loss: 1.0741\n",
            "Epoch 2574/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5275 - val_loss: 1.0735\n",
            "Epoch 2575/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5278 - val_loss: 1.0742\n",
            "Epoch 2576/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5277 - val_loss: 1.0746\n",
            "Epoch 2577/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5273 - val_loss: 1.0751\n",
            "Epoch 2578/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5274 - val_loss: 1.0756\n",
            "Epoch 2579/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5274 - val_loss: 1.0730\n",
            "Epoch 2580/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5275 - val_loss: 1.0751\n",
            "Epoch 2581/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5271 - val_loss: 1.0741\n",
            "Epoch 2582/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5281 - val_loss: 1.0776\n",
            "Epoch 2583/5000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5280 - val_loss: 1.0720\n",
            "Epoch 2584/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5270 - val_loss: 1.0727\n",
            "Epoch 2585/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5270 - val_loss: 1.0741\n",
            "Epoch 2586/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5271 - val_loss: 1.0726\n",
            "Epoch 2587/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5269 - val_loss: 1.0733\n",
            "Epoch 2588/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5268 - val_loss: 1.0737\n",
            "Epoch 2589/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5270 - val_loss: 1.0725\n",
            "Epoch 2590/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5270 - val_loss: 1.0752\n",
            "Epoch 2591/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5271 - val_loss: 1.0730\n",
            "Epoch 2592/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5270 - val_loss: 1.0727\n",
            "Epoch 2593/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5271 - val_loss: 1.0749\n",
            "Epoch 2594/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5266 - val_loss: 1.0754\n",
            "Epoch 2595/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5267 - val_loss: 1.0740\n",
            "Epoch 2596/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5265 - val_loss: 1.0752\n",
            "Epoch 2597/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5267 - val_loss: 1.0735\n",
            "Epoch 2598/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5268 - val_loss: 1.0751\n",
            "Epoch 2599/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5263 - val_loss: 1.0738\n",
            "Epoch 2600/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5266 - val_loss: 1.0758\n",
            "Epoch 2601/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5264 - val_loss: 1.0738\n",
            "Epoch 2602/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5262 - val_loss: 1.0733\n",
            "Epoch 2603/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5262 - val_loss: 1.0743\n",
            "Epoch 2604/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5264 - val_loss: 1.0750\n",
            "Epoch 2605/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5261 - val_loss: 1.0738\n",
            "Epoch 2606/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5260 - val_loss: 1.0742\n",
            "Epoch 2607/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5259 - val_loss: 1.0736\n",
            "Epoch 2608/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5259 - val_loss: 1.0735\n",
            "Epoch 2609/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5261 - val_loss: 1.0757\n",
            "Epoch 2610/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5259 - val_loss: 1.0734\n",
            "Epoch 2611/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5258 - val_loss: 1.0734\n",
            "Epoch 2612/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5259 - val_loss: 1.0726\n",
            "Epoch 2613/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5257 - val_loss: 1.0735\n",
            "Epoch 2614/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5259 - val_loss: 1.0733\n",
            "Epoch 2615/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5260 - val_loss: 1.0722\n",
            "Epoch 2616/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5257 - val_loss: 1.0739\n",
            "Epoch 2617/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5258 - val_loss: 1.0756\n",
            "Epoch 2618/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5259 - val_loss: 1.0730\n",
            "Epoch 2619/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5260 - val_loss: 1.0711\n",
            "Epoch 2620/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5257 - val_loss: 1.0735\n",
            "Epoch 2621/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5254 - val_loss: 1.0742\n",
            "Epoch 2622/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5256 - val_loss: 1.0753\n",
            "Epoch 2623/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5254 - val_loss: 1.0737\n",
            "Epoch 2624/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5253 - val_loss: 1.0738\n",
            "Epoch 2625/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5253 - val_loss: 1.0725\n",
            "Epoch 2626/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5254 - val_loss: 1.0745\n",
            "Epoch 2627/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5252 - val_loss: 1.0736\n",
            "Epoch 2628/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5251 - val_loss: 1.0729\n",
            "Epoch 2629/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5251 - val_loss: 1.0731\n",
            "Epoch 2630/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5253 - val_loss: 1.0729\n",
            "Epoch 2631/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5253 - val_loss: 1.0734\n",
            "Epoch 2632/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5248 - val_loss: 1.0733\n",
            "Epoch 2633/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5249 - val_loss: 1.0735\n",
            "Epoch 2634/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5249 - val_loss: 1.0741\n",
            "Epoch 2635/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5249 - val_loss: 1.0729\n",
            "Epoch 2636/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5250 - val_loss: 1.0720\n",
            "Epoch 2637/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5249 - val_loss: 1.0723\n",
            "Epoch 2638/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5247 - val_loss: 1.0744\n",
            "Epoch 2639/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5249 - val_loss: 1.0727\n",
            "Epoch 2640/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5250 - val_loss: 1.0753\n",
            "Epoch 2641/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5246 - val_loss: 1.0742\n",
            "Epoch 2642/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5246 - val_loss: 1.0739\n",
            "Epoch 2643/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5246 - val_loss: 1.0745\n",
            "Epoch 2644/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5249 - val_loss: 1.0765\n",
            "Epoch 2645/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5247 - val_loss: 1.0726\n",
            "Epoch 2646/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5245 - val_loss: 1.0740\n",
            "Epoch 2647/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5244 - val_loss: 1.0732\n",
            "Epoch 2648/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5249 - val_loss: 1.0758\n",
            "Epoch 2649/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5246 - val_loss: 1.0730\n",
            "Epoch 2650/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5245 - val_loss: 1.0731\n",
            "Epoch 2651/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5244 - val_loss: 1.0727\n",
            "Epoch 2652/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5243 - val_loss: 1.0717\n",
            "Epoch 2653/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5241 - val_loss: 1.0729\n",
            "Epoch 2654/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5242 - val_loss: 1.0745\n",
            "Epoch 2655/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5243 - val_loss: 1.0729\n",
            "Epoch 2656/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5243 - val_loss: 1.0725\n",
            "Epoch 2657/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5240 - val_loss: 1.0741\n",
            "Epoch 2658/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5239 - val_loss: 1.0737\n",
            "Epoch 2659/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5240 - val_loss: 1.0730\n",
            "Epoch 2660/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5239 - val_loss: 1.0736\n",
            "Epoch 2661/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5238 - val_loss: 1.0733\n",
            "Epoch 2662/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5239 - val_loss: 1.0731\n",
            "Epoch 2663/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5242 - val_loss: 1.0718\n",
            "Epoch 2664/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5236 - val_loss: 1.0730\n",
            "Epoch 2665/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5241 - val_loss: 1.0762\n",
            "Epoch 2666/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5236 - val_loss: 1.0756\n",
            "Epoch 2667/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5236 - val_loss: 1.0759\n",
            "Epoch 2668/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5236 - val_loss: 1.0751\n",
            "Epoch 2669/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5234 - val_loss: 1.0738\n",
            "Epoch 2670/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5234 - val_loss: 1.0736\n",
            "Epoch 2671/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5240 - val_loss: 1.0713\n",
            "Epoch 2672/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5233 - val_loss: 1.0723\n",
            "Epoch 2673/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5235 - val_loss: 1.0720\n",
            "Epoch 2674/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5233 - val_loss: 1.0734\n",
            "Epoch 2675/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5233 - val_loss: 1.0739\n",
            "Epoch 2676/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5234 - val_loss: 1.0729\n",
            "Epoch 2677/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5231 - val_loss: 1.0729\n",
            "Epoch 2678/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5232 - val_loss: 1.0722\n",
            "Epoch 2679/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5230 - val_loss: 1.0731\n",
            "Epoch 2680/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5236 - val_loss: 1.0748\n",
            "Epoch 2681/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5232 - val_loss: 1.0740\n",
            "Epoch 2682/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5230 - val_loss: 1.0730\n",
            "Epoch 2683/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5233 - val_loss: 1.0728\n",
            "Epoch 2684/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5230 - val_loss: 1.0741\n",
            "Epoch 2685/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5233 - val_loss: 1.0727\n",
            "Epoch 2686/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5228 - val_loss: 1.0744\n",
            "Epoch 2687/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5228 - val_loss: 1.0726\n",
            "Epoch 2688/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5229 - val_loss: 1.0738\n",
            "Epoch 2689/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5232 - val_loss: 1.0726\n",
            "Epoch 2690/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5227 - val_loss: 1.0729\n",
            "Epoch 2691/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5228 - val_loss: 1.0735\n",
            "Epoch 2692/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5228 - val_loss: 1.0717\n",
            "Epoch 2693/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5225 - val_loss: 1.0724\n",
            "Epoch 2694/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5226 - val_loss: 1.0719\n",
            "Epoch 2695/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5227 - val_loss: 1.0732\n",
            "Epoch 2696/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5224 - val_loss: 1.0731\n",
            "Epoch 2697/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5226 - val_loss: 1.0744\n",
            "Epoch 2698/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5227 - val_loss: 1.0755\n",
            "Epoch 2699/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5228 - val_loss: 1.0719\n",
            "Epoch 2700/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5224 - val_loss: 1.0723\n",
            "Epoch 2701/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5224 - val_loss: 1.0746\n",
            "Epoch 2702/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5223 - val_loss: 1.0728\n",
            "Epoch 2703/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5226 - val_loss: 1.0734\n",
            "Epoch 2704/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5223 - val_loss: 1.0725\n",
            "Epoch 2705/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5223 - val_loss: 1.0713\n",
            "Epoch 2706/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5223 - val_loss: 1.0745\n",
            "Epoch 2707/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5222 - val_loss: 1.0736\n",
            "Epoch 2708/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5221 - val_loss: 1.0740\n",
            "Epoch 2709/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5222 - val_loss: 1.0726\n",
            "Epoch 2710/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5219 - val_loss: 1.0725\n",
            "Epoch 2711/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5223 - val_loss: 1.0747\n",
            "Epoch 2712/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5222 - val_loss: 1.0717\n",
            "Epoch 2713/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5221 - val_loss: 1.0743\n",
            "Epoch 2714/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5220 - val_loss: 1.0727\n",
            "Epoch 2715/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5217 - val_loss: 1.0731\n",
            "Epoch 2716/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5218 - val_loss: 1.0739\n",
            "Epoch 2717/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5219 - val_loss: 1.0754\n",
            "Epoch 2718/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5217 - val_loss: 1.0722\n",
            "Epoch 2719/5000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.3476Restoring model weights from the end of the best epoch: 2619.\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5217 - val_loss: 1.0722\n",
            "Epoch 2719: early stopping\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjoAAAHHCAYAAAC2rPKaAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABp7ElEQVR4nO3dd3hUVf7H8fdkkpn0RkJCCS3UANJBigISpYliL6iAXbFixd21r6ioiyXWXUF37SjqT4oUKQqIVOk9hJoECOk9c39/XDIQE2CATCbl83qeeZLce+bOd64T8vHcc861GIZhICIiIlILeXm6ABERERF3UdARERGRWktBR0RERGotBR0RERGptRR0REREpNZS0BEREZFaS0FHREREai0FHREREam1FHRERESk1lLQEalmdu/ejcViYerUqZ4u5YwNGDCAAQMGeLoMpzFjxhAYGHjadmdTd3V7r9WFxWLh2WefPePnufq5X7hwIRaLhYULF55VfVL3KOiIiIhIraWgIyIiIrWWgo7UKg6Hg/z8fE+XUS3k5+fjcDg8XYaIiEcp6Ei1tHDhQrp3746vry+xsbF88MEHPPvss1gsljLtLBYL9913H5999hnt27fHbrcze/ZsANasWcPQoUMJDg4mMDCQQYMG8fvvv5d5fkXHBJg6dSoWi4Xdu3c7tzVr1oxLL72UOXPm0LlzZ3x9fYmLi+O7774r9/z09HQeeughYmJisNvttGzZkldeeaVc8EhPT2fMmDGEhIQQGhrK6NGjSU9PP6vzZbFY+PLLL/n73/9Oo0aN8Pf3JzMzk7S0NB599FE6duxIYGAgwcHBDB06lD///LPCY3z99df885//pHHjxvj6+jJo0CB27NhR7jU//PBDYmNj8fPzo2fPnvz6668V1paamsptt91GVFQUvr6+dOrUiU8++aRMm9LxGa+99hoJCQm0aNECf39/LrnkEvbu3YthGLzwwgs0btwYPz8/Lr/8ctLS0s74PAGsXbuWyMhIBgwYQHZ29lkd42Rcea8AX375Jd26dSMoKIjg4GA6duzIm2++6dxfVFTEc889R6tWrfD19aVevXr069ePuXPnnvL1Sz+3v/32Gw888ACRkZGEhoZy1113UVhYSHp6OrfccgthYWGEhYXx+OOPYxhGmWPk5OTwyCOPOD+7bdq04bXXXivXrqCggIcffpjIyEiCgoK47LLL2LdvX4V17d+/n1tvvZWoqCjsdjvt27fn448/dvW0uuSbb76hW7du+Pn5ERERwU033cT+/fvLtElOTmbs2LE0btwYu91OgwYNuPzyy8v8nq9cuZLBgwcTERGBn58fzZs359Zbb63UWqVqeXu6AJG/WrNmDUOGDKFBgwY899xzlJSU8PzzzxMZGVlh+19++YWvv/6a++67j4iICJo1a8bGjRu54IILCA4O5vHHH8fHx4cPPviAAQMGsGjRInr16nVWtW3fvp3rrruOu+++m9GjRzNlyhSuueYaZs+ezcUXXwxAbm4u/fv3Z//+/dx11100adKEpUuXMmHCBA4ePMjkyZMBMAyDyy+/nN9++427776bdu3aMX36dEaPHn1WtQG88MIL2Gw2Hn30UQoKCrDZbGzatInvv/+ea665hubNm5OSksIHH3xA//792bRpEw0bNixzjJdffhkvLy8effRRMjIyePXVVxk1ahTLly93tvnPf/7DXXfdRZ8+fXjooYfYtWsXl112GeHh4cTExDjb5eXlMWDAAHbs2MF9991H8+bN+eabbxgzZgzp6ek8+OCDZV77s88+o7CwkPvvv5+0tDReffVVrr32Wi666CIWLlzIE088wY4dO3j77bd59NFHz/iP5YoVKxg8eDDdu3fnhx9+wM/P7yzOcsVcfa9z587lhhtuYNCgQbzyyisAbN68mSVLljjbPPvss0ycOJHbb7+dnj17kpmZycqVK1m9erXzc3Yq999/P9HR0Tz33HP8/vvvfPjhh4SGhrJ06VKaNGnCSy+9xMyZM5k0aRIdOnTglltuAczP5GWXXcaCBQu47bbb6Ny5Mz///DOPPfYY+/fv51//+pfzNW6//Xb+97//ceONN9KnTx9++eUXhg8fXq6WlJQUzj//fOf/lERGRjJr1ixuu+02MjMzeeihh8711DN16lTGjh1Ljx49mDhxIikpKbz55pssWbKENWvWEBoaCsBVV13Fxo0buf/++2nWrBmpqanMnTuXPXv2OH++5JJLiIyM5MknnyQ0NJTdu3dX+D8zUoMYItXMiBEjDH9/f2P//v3Obdu3bze8vb2Nv35kAcPLy8vYuHFjme0jR440bDabsXPnTue2AwcOGEFBQcaFF17o3PbMM8+UO6ZhGMaUKVMMwEhMTHRua9q0qQEY3377rXNbRkaG0aBBA6NLly7ObS+88IIREBBgbNu2rcwxn3zyScNqtRp79uwxDMMwvv/+ewMwXn31VWeb4uJi44ILLjAAY8qUKac6TWUsWLDAAIwWLVoYubm5Zfbl5+cbJSUlZbYlJiYadrvdeP7558sdo127dkZBQYFz+5tvvmkAxvr16w3DMIzCwkKjfv36RufOncu0+/DDDw3A6N+/v3Pb5MmTDcD43//+59xWWFho9O7d2wgMDDQyMzOd9QBGZGSkkZ6e7mw7YcIEAzA6depkFBUVObffcMMNhs1mM/Lz8095XkaPHm0EBAQYhmEYv/32mxEcHGwMHz683PP69+9fpm5X/PU5rr7XBx980AgODjaKi4tPeuxOnToZw4cPP6N6DOP453bw4MGGw+Fwbu/du7dhsViMu+++27mtuLjYaNy4cZn3UPqZfPHFF8sc9+qrrzYsFouxY8cOwzAMY+3atQZg3HvvvWXa3XjjjQZgPPPMM85tt912m9GgQQPj8OHDZdpef/31RkhIiPPzWvoZON3nvvRzumDBAsMwjn8eO3ToYOTl5Tnb/fTTTwZgPP3004ZhGMbRo0cNwJg0adJJjz19+nQDMFasWHHKGqRm0aUrqVZKSkqYN28eI0eOLNPT0LJlS4YOHVrhc/r3709cXFyZY8yZM4eRI0fSokUL5/YGDRpw44038ttvv5GZmXlW9TVs2JArrrjC+XNwcDC33HILa9asITk5GTC70C+44ALCwsI4fPiw8xEfH09JSQmLFy8GYObMmXh7e3PPPfc4j2e1Wrn//vvPqjaA0aNHl+ulsNvteHmZv+olJSUcOXKEwMBA2rRpw+rVq8sdY+zYsdhsNufPF1xwAQC7du0CzK791NRU7r777jLtSi/BnWjmzJlER0dzww03OLf5+PjwwAMPkJ2dzaJFi8q0v+aaa8oco7Tn7aabbsLb27vM9sLCwnKXJk5mwYIFDB48mEGDBvHdd99ht9tdet6ZcPW9hoaGkpOTc8rLUKGhoWzcuJHt27efVS233XZbmUuyvXr1wjAMbrvtNuc2q9VK9+7dnf9dS9+D1WrlgQceKHO8Rx55BMMwmDVrlrMdUK7dX3tnDMPg22+/ZcSIERiGUeb3YfDgwWRkZFT4GTwTpZ/He++9F19fX+f24cOH07ZtW2bMmAGAn58fNpuNhQsXcvTo0QqPVdrz89NPP1FUVHROdUn1oaAj1Upqaip5eXm0bNmy3L6KtgE0b968zM+HDh0iNzeXNm3alGvbrl07HA4He/fuPav6WrZsWW5MT+vWrQGc1/m3b9/O7NmziYyMLPOIj48HzPcIkJSURIMGDcqt81JR3a7667kAc4D2v/71L1q1aoXdbiciIoLIyEjWrVtHRkZGufZNmjQp83NYWBiA849DUlISAK1atSrTzsfHp0ywLG3bqlUrZ9Aq1a5duzLHOtlrl4aeEy+Hnbj9ZH+wTpSfn8/w4cPp0qULX3/9dZlwVplcfa/33nsvrVu3ZujQoTRu3Jhbb73VOa6s1PPPP096ejqtW7emY8eOPPbYY6xbt87lWs7kPJ54DpOSkmjYsCFBQUGnfA9JSUl4eXkRGxtbpt1fP7uHDh0iPT2dDz/8sNzvw9ixY4Hjvw9nq7Smin5v2rZt69xvt9t55ZVXmDVrFlFRUVx44YW8+uqrzv9BAfN/mq666iqee+45IiIiuPzyy5kyZQoFBQXnVKN4loKO1HjnMs6iooHIYPZ8nC2Hw8HFF1/M3LlzK3xcddVVZ33s06noXLz00kuMHz+eCy+8kP/973/8/PPPzJ07l/bt21c4K8tqtVZ4bOMvg1Hd4WSvfS412e12hg8fzvLly8sFCk+oX78+a9eu5ccff3SOhxk6dGiZsVkXXnghO3fu5OOPP6ZDhw78+9//pmvXrvz73/926TXO5Dy6879r6efrpptuOunvQ9++fd32+n/10EMPsW3bNiZOnIivry//+Mc/aNeuHWvWrAHMfw+mTZvGsmXLuO+++5yDqLt161bpA9el6ijoSLVSv359fH19K5zlU9G2ikRGRuLv78/WrVvL7duyZQteXl7O/7Mt7a3460ynv/Y0nFjDX/8wbNu2DTBnZQHExsaSnZ1NfHx8hY/S/9tu2rQpBw8eLPcPaEV1n4tp06YxcOBA/vOf/3D99ddzySWXEB8ff1azu8CsGyh3WaWoqIjExMRybbdv314uUG3ZsqXMsdzJYrHw2WefMWjQIK655hq3rah7Ju/VZrMxYsQI3n33XXbu3Mldd93Fp59+WuYzHh4eztixY/niiy/Yu3cv55133lmtOHym7+HAgQNkZWWd8j00bdoUh8PBzp07y7T762e3dEZWSUnJSX8f6tevf841V/Tapdv++hmLjY3lkUceYc6cOWzYsIHCwkJef/31Mm3OP/98/vnPf7Jy5Uo+++wzNm7cyJdffnlOdYrnKOhItWK1WomPj+f777/nwIEDzu07duxwjg9w5RiXXHIJP/zwQ5lpoykpKXz++ef069eP4OBgAGfXe+m4GTCn11Y0JRjgwIEDTJ8+3flzZmYmn376KZ07dyY6OhqAa6+9lmXLlvHzzz+Xe356ejrFxcUADBs2jOLiYt577z3n/pKSEt5++22X3qerrFZruXD2zTffuDy+5a+6d+9OZGQk77//PoWFhc7tU6dOLReehg0bRnJyMl999ZVzW3FxMW+//TaBgYH079//rGo4Uzabje+++44ePXowYsQI/vjjj0p/DVff65EjR8o8z8vLi/POOw/AeYnkr20CAwNp2bKl2y+hDBs2jJKSEt55550y2//1r39hsVic4+RKv7711ltl2pXOKCxltVq56qqr+Pbbb9mwYUO51zt06NA519y9e3fq16/P+++/X+b8zJo1i82bNztnguXm5pZbYys2NpagoCDn844ePVrud6Vz584AunxVg2l6uVQ7zz77LHPmzKFv377cc889zn94O3TowNq1a106xosvvsjcuXPp168f9957L97e3nzwwQcUFBTw6quvOttdcsklNGnShNtuu43HHnsMq9XKxx9/TGRkJHv27Cl33NatW3PbbbexYsUKoqKi+Pjjj0lJSWHKlCnONo899hg//vgjl156KWPGjKFbt27k5OSwfv16pk2bxu7du4mIiGDEiBH07duXJ598kt27dzvX5Klo3My5uPTSS3n++ecZO3Ysffr0Yf369Xz22WflxtO4ysfHhxdffJG77rqLiy66iOuuu47ExESmTJlS7ph33nknH3zwAWPGjGHVqlU0a9aMadOmsWTJEiZPnlxuLIg7+fn58dNPP3HRRRcxdOhQFi1aRIcOHSrt+K6+19tvv520tDQuuugiGjduTFJSEm+//TadO3d2joWJi4tjwIABdOvWjfDwcFauXMm0adO47777Kq3eiowYMYKBAwfyt7/9jd27d9OpUyfmzJnDDz/8wEMPPeT8H4POnTtzww038O6775KRkUGfPn2YP39+hb2uL7/8MgsWLKBXr17ccccdxMXFkZaWxurVq5k3b95Zr4dUysfHh1deeYWxY8fSv39/brjhBuf08mbNmvHwww8DZs/roEGDuPbaa4mLi8Pb25vp06eTkpLC9ddfD8Ann3zCu+++yxVXXEFsbCxZWVl89NFHBAcHM2zYsHOqUzzIU9O9RE5l/vz5RpcuXQybzWbExsYa//73v41HHnnE8PX1LdMOMMaNG1fhMVavXm0MHjzYCAwMNPz9/Y2BAwcaS5cuLddu1apVRq9evQybzWY0adLEeOONN046vXz48OHGzz//bJx33nmG3W432rZta3zzzTfljpmVlWVMmDDBaNmypWGz2YyIiAijT58+xmuvvWYUFhY62x05csS4+eabjeDgYCMkJMS4+eabjTVr1pz19PKKasnPzzceeeQRo0GDBoafn5/Rt29fY9myZeWmR5/sGCeb9vvuu+8azZs3N+x2u9G9e3dj8eLFFU7TTklJMcaOHWtEREQYNpvN6NixY7ljlb7GX6f+nqym0v8+p5sGfOL08lKHDx824uLijOjoaGP79u2GYVTO9HLDcO29Tps2zbjkkkuM+vXrOz9zd911l3Hw4EFnmxdffNHo2bOnERoaavj5+Rlt27Y1/vnPf5b57FTkZOeldBmFQ4cOldle0fnJysoyHn74YaNhw4aGj4+P0apVK2PSpEllpqsbhmHk5eUZDzzwgFGvXj0jICDAGDFihLF3795y08tLz8u4ceOMmJgYw8fHx4iOjjYGDRpkfPjhh842Zzu9vNRXX31ldOnSxbDb7UZ4eLgxatQoY9++fc79hw8fNsaNG2e0bdvWCAgIMEJCQoxevXoZX3/9tbPN6tWrjRtuuMFo0qSJYbfbjfr16xuXXnqpsXLlylPWJNWbxTCqYIShSCUYOXLkOU25PVfNmjWjQ4cO/PTTTx55fREROXMaoyPVUl5eXpmft2/fzsyZMxkwYIBnChIRkRpJY3SkWmrRogVjxoyhRYsWJCUl8d5772Gz2Xj88cc9XVqVKiwsPO0YhpCQkEq9lUFdd+jQoVMuL2Cz2QgPD6/CikTkXCjoSLU0ZMgQvvjiC5KTk7Hb7fTu3ZuXXnqp3CJ1td3SpUsZOHDgKdtMmTKFMWPGVE1BdUCPHj1OurwAmIvKuWuKuohUPo3REanGjh49yqpVq07Zpn379jRo0KCKKqr9lixZUu7S6YnCwsLo1q1bFVYkIudCQUdERERqLQ1GFhERkVqrzo/RcTgcHDhwgKCgoJPe90hERESqF8MwyMrKomHDhuVupnuiOh90Dhw4UO6OviIiIlIz7N27l8aNG590f50POqXLsu/du9d5/yMRERGp3jIzM4mJiTntrWTqfNApvVwVHBysoCMiIlLDnG7YiQYji4iISK2loCMiIiK1loKOiIiI1Fp1foyOKxwOB4WFhZ4uQ07g4+OD1Wr1dBkiIlLNKeicRmFhIYmJiTgcDk+XIn8RGhpKdHS01j8SEZGTUtA5BcMwOHjwIFarlZiYmFMuSCRVxzAMcnNzSU1NBdB9nkRE5KQUdE6huLiY3NxcGjZsiL+/v6fLkRP4+fkBkJqaSv369XUZS0REKqQuilMoKSkBwGazebgSqUhp+CwqKvJwJSIiUl0p6LhAY0CqJ/13ERGR01HQERERkVpLQacWGjBgAA899JCnyxAREfE4BR0RERGptTTryk0Kix2AgbfVCy+NJREREfGIOtujk5CQQFxcHD169HDL8benZrElOetY4PGco0ePcssttxAWFoa/vz9Dhw5l+/btzv1JSUmMGDGCsLAwAgICaN++PTNnznQ+d9SoUURGRuLn50erVq2YMmWKp96KiIjIGauzPTrjxo1j3LhxZGZmEhIS4tJzDMMgr6jEpbb5RSWUOAxyC4txGMa5lAqAn4/1rGYZjRkzhu3bt/Pjjz8SHBzME088wbBhw9i0aRM+Pj6MGzeOwsJCFi9eTEBAAJs2bSIwMBCAf/zjH2zatIlZs2YRERHBjh07yMvLO+f3IiIiUlXqbNA5G3lFJcQ9/bNHXnvT84Pxt53Zf67SgLNkyRL69OkDwGeffUZMTAzff/8911xzDXv27OGqq66iY8eOALRo0cL5/D179tClSxe6d+8OQLNmzSrnzYiIiFSROnvpqi7YvHkz3t7e9OrVy7mtXr16tGnThs2bNwPwwAMP8OKLL9K3b1+eeeYZ1q1b52x7zz338OWXX9K5c2cef/xxli5dWuXvQURE5FyoR+cM+PlY2fT8YJfabjmYSbHDoGX9QHx9zv32BH6VcIyK3H777QwePJgZM2YwZ84cJk6cyOuvv87999/P0KFDSUpKYubMmcydO5dBgwYxbtw4XnvtNbfUIiIiUtnUo3MGLBYL/jZvlx6+Pt74+lhdbn+6x9mMz2nXrh3FxcUsX77cue3IkSNs3bqVuLg457aYmBjuvvtuvvvuOx555BE++ugj577IyEhGjx7N//73PyZPnsyHH354bidRRESkCqlHpxZr1aoVl19+OXfccQcffPABQUFBPPnkkzRq1IjLL78cgIceeoihQ4fSunVrjh49yoIFC2jXrh0ATz/9NN26daN9+/YUFBTw008/OfeJiIjUBOrRqeWmTJlCt27duPTSS+nduzeGYTBz5kx8fHwA88al48aNo127dgwZMoTWrVvz7rvvAubNTCdMmMB5553HhRdeiNVq5csvv/Tk2xERETkjFsOohLnPNVjp9PKMjAyCg4PL7MvPzycxMZHmzZvj6+t7RsfddCCTYoeDVlFBbhtfU9edy38fERGp2U719/tE6tERERGRWktBx93qdH+ZiIiIZynoiIiISK2loCMiIiK1loKOu+iG5SIiIh6noON2GqQjIiLiKQo6bqIOHREREc9T0BEREZFaS0FHREREai0FHSmnWbNmTJ482aW2FouF77//3q31iIiInC0FHREREam1FHRERESk1lLQcbOqnlz+4Ycf0rBhQxwOR5ntl19+Obfeeis7d+7k8ssvJyoqisDAQHr06MG8efMq7fXXr1/PRRddhJ+fH/Xq1ePOO+8kOzvbuX/hwoX07NmTgIAAQkND6du3L0lJSQD8+eefDBw4kKCgIIKDg+nWrRsrV66stNpERKTuqfFBJz09ne7du9O5c2c6dOjARx995L4XMwwozHHpYSnKxVKU63L70z5cvMn8Nddcw5EjR1iwYIFzW1paGrNnz2bUqFFkZ2czbNgw5s+fz5o1axgyZAgjRoxgz54953x6cnJyGDx4MGFhYaxYsYJvvvmGefPmcd999wFQXFzMyJEj6d+/P+vWrWPZsmXceeedWCzmZPxRo0bRuHFjVqxYwapVq3jyySfx8fE557pERKTu8vZ0AecqKCiIxYsX4+/vT05ODh06dODKK6+kXr16lf9iRbnwUkOXmrat7Nd+6gDYAk7bLCwsjKFDh/L5558zaNAgAKZNm0ZERAQDBw7Ey8uLTp06Odu/8MILTJ8+nR9//NEZSM7W559/Tn5+Pp9++ikBAWat77zzDiNGjOCVV17Bx8eHjIwMLr30UmJjYwFo166d8/l79uzhscceo21b8+y1atXqnOoRERGp8T06VqsVf39/AAoKCjAMA8PF3o/aatSoUXz77bcUFBQA8Nlnn3H99dfj5eVFdnY2jz76KO3atSM0NJTAwEA2b95cKT06mzdvplOnTs6QA9C3b18cDgdbt24lPDycMWPGMHjwYEaMGMGbb77JwYMHnW3Hjx/P7bffTnx8PC+//DI7d+4855pERKRu83iPzuLFi5k0aRKrVq3i4MGDTJ8+nZEjR5Zpk5CQwKRJk0hOTqZTp068/fbb9OzZ07k/PT2d/v37s337diZNmkRERIR7ivXxN3tWXLAlOYuiEgexkQH42yrhNPv4u9x0xIgRGIbBjBkz6NGjB7/++iv/+te/AHj00UeZO3cur732Gi1btsTPz4+rr76awsLCc6/RBVOmTOGBBx5g9uzZfPXVV/z9739n7ty5nH/++Tz77LPceOONzJgxg1mzZvHMM8/w5ZdfcsUVV1RJbSIiUvt4vEcnJyeHTp06kZCQUOH+r776ivHjx/PMM8+wevVqOnXqxODBg0lNTXW2CQ0N5c8//yQxMZHPP/+clJQU9xRrsZiXj1x5+Phj+Pi73v50D4vrN5Xw9fXlyiuv5LPPPuOLL76gTZs2dO3aFYAlS5YwZswYrrjiCjp27Eh0dDS7d++ulNPTrl07/vzzT3JycpzblixZgpeXF23atHFu69KlCxMmTGDp0qV06NCBzz//3LmvdevWPPzww8yZM4crr7ySKVOmVEptIiJSN3k86AwdOpQXX3zxpP/X/sYbb3DHHXcwduxY4uLieP/99/H39+fjjz8u1zYqKopOnTrx66+/nvT1CgoKyMzMLPOojUaNGsWMGTP4+OOPGTVqlHN7q1at+O6771i7di1//vknN954Y7kZWufymr6+vowePZoNGzawYMEC7r//fm6++WaioqJITExkwoQJLFu2jKSkJObMmcP27dtp164deXl53HfffSxcuJCkpCSWLFnCihUryozhEREROVMeDzqnUlhYyKpVq4iPj3du8/LyIj4+nmXLlgGQkpJCVlYWABkZGSxevLhM78FfTZw4kZCQEOcjJibGvW/CQy666CLCw8PZunUrN954o3P7G2+8QVhYGH369GHEiBEMHjzY2dtzrvz9/fn5559JS0ujR48eXH311QwaNIh33nnHuX/Lli1cddVVtG7dmjvvvJNx48Zx1113YbVaOXLkCLfccgutW7fm2muvZejQoTz33HOVUpuIiNRNHh+jcyqHDx+mpKSEqKioMtujoqLYsmULAElJSdx5553OQcj3338/HTt2POkxJ0yYwPjx450/Z2ZmujfseGhctJeXFwcOlB9P1KxZM3755Zcy28aNG1fm5zO5lPXXgd8dO3Ysd/xSUVFRTJ8+vcJ9NpuNL774wuXXFRERcUW1Djqu6NmzJ2vXrnW5vd1ux263u68gERERqTaq9aWriIgIrFZrucHFKSkpREdHe6iqM1OTJ7p/9tlnBAYGVvho3769p8sTERE5rWrdo2Oz2ejWrRvz5893Tjl3OBzMnz//nBe3S0hIICEhgZKSkkqotAKuT5Kqti677DJ69epV4T6tWCwiIjWBx4NOdnY2O3bscP6cmJjI2rVrCQ8Pp0mTJowfP57Ro0fTvXt3evbsyeTJk8nJyWHs2LHn9Lrjxo1j3LhxZGZmEhIScq5vo1YKCgoiKCjI02WIiIicNY8HnZUrVzJw4EDnz6UDhUePHs3UqVO57rrrOHToEE8//TTJycl07tyZ2bNnlxug7E51faXl6kr/XURE5HQ8HnQGDBhw2j9Y99133zlfqjobVqsVMKe5+/n5Vfnry6nl5uYCuowmIiIn5/GgU515e3vj7+/PoUOH8PHxwcvL9bHbjqJCjBIHBQX5WA2d5spkGAa5ubmkpqYSGhrqDKQiIiJ/VWf/ArsyGNlisdCgQQMSExNJSko6o+OnZORT7DAgy47Nu1pPbquxQkNDa8zsOxER8QyLUccHOpQORs7IyCA4OLjCNg6H44xvennzf5ZzID2PN6/vTIdGoZVQqZzIx8dHPTkiInWYK3+/oQ736JwJLy8vfH19z+g5h3Id7M8qAavtjJ8rIiIilUPXVNysTneXiYiIeJiCjptYLLVgxUAREZEars4GnYSEBOLi4ujRo4dbX6duj4ASERHxrDobdMaNG8emTZtYsWKFW46v/hwRERHPq7NBp6rU8UltIiIiHqWg4y7q0hEREfE4BR03U3+OiIiI5yjouIk6dERERDxPQUdERERqrTobdDS9XEREpPars0HH7dPLtWCgiIiIx9XZoFNVDA1HFhER8RgFHTdRf46IiIjnKei4mzp0REREPEZBx000REdERMTzFHTcTB06IiIinlNng467p5dbNEpHRETE4+ps0HH39PJSWkdHRETEc+ps0HE3jdERERHxPAUdN9M6OiIiIp6joCMiIiK1loKOm2mMjoiIiOco6LiJ7nUlIiLieQo6IiIiUmsp6LiZrlyJiIh4Tp0NOu5fMFBEREQ8rc4GnapbMFB9OiIiIp5SZ4OOu2kssoiIiOcp6LiZ+nNEREQ8R0HHTdSjIyIi4nkKOu6mLh0RERGPUdBxE4vmXYmIiHicgo6b6aaeIiIinqOg4yYaoyMiIuJ5CjpupmV0REREPEdBx03UoSMiIuJ5Cjpuph4dERERz6mzQcfd97rSIB0RERHPq7NBp6rudSUiIiKeU2eDTlXRlSsRERHPUdBxE124EhER8TwFHTczNBpZRETEYxR03ERjkUVERDxPQcfN1J8jIiLiOQo6bqIOHREREc9T0HEzDdERERHxHAUdN7FokI6IiIjHKei4nbp0REREPEVBx03UnyMiIuJ5CjpupjE6IiIinqOg4yYaoiMiIuJ5Cjpupg4dERERz1HQcZPSWVe6dCUiIuI5Cjpu4nXs0lWJko6IiIjH1Nmgk5CQQFxcHD169HDL8a3Hko7DoaAjIiLiKXU26IwbN45NmzaxYsUKtxzf69ilK4d6dERERDymzgYddysNOiXq0REREfEYBR03Kb10pQ4dERERz1HQcRNnj46SjoiIiMco6LhJ6awrjdERERHxHAUdN9GsKxEREc9T0HGT47OuPFyIiIhIHaag4yZeXpp1JSIi4mkKOm5i1RgdERERj1PQcRMtGCgiIuJ5CjpucvzSlYcLERERqcMUdNxE08tFREQ8T0HHTTS9XERExPMUdNykNOgUKeiIiIh4jIKOm/h6WwEoKC7xcCUiIiJ1l4KOm9h9zFNbUKTRyCIiIp6ioOMmdvXoiIiIeJyCjpv4HuvRyVePjoiIiMco6LhJiJ8PAIezCzxciYiISN2loOMmLesHArAjNdvDlYiIiNRdCjpu0rJ+EAAHM/LJzC/ycDUiIiJ1U40POnv37mXAgAHExcVx3nnn8c0333i6JMC8dNUo1A+AGz783cPViIiI1E3eni7gXHl7ezN58mQ6d+5McnIy3bp1Y9iwYQQEBHi6NCKC7OxPz2PjgUzyi0rw9bF6uiQREZE6pcb36DRo0IDOnTsDEB0dTUREBGlpaZ4t6pjre8Q4v0/N1KBkERGRqubxoLN48WJGjBhBw4YNsVgsfP/99+XaJCQk0KxZM3x9fenVqxd//PFHhcdatWoVJSUlxMTEVLi/qp0YdJIz8z1YiYiISN3k8aCTk5NDp06dSEhIqHD/V199xfjx43nmmWdYvXo1nTp1YvDgwaSmppZpl5aWxi233MKHH35YFWW7xGKxMKBNJACrko56uBoREZG6x+NBZ+jQobz44otcccUVFe5/4403uOOOOxg7dixxcXG8//77+Pv78/HHHzvbFBQUMHLkSJ588kn69OlzytcrKCggMzOzzMOdLomLBmDG+gNufR0REREpz+NB51QKCwtZtWoV8fHxzm1eXl7Ex8ezbNkyAAzDYMyYMVx00UXcfPPNpz3mxIkTCQkJcT7cfZlrcPsovL0sbNifydbkLLe+loiIiJRVrYPO4cOHKSkpISoqqsz2qKgokpOTAViyZAlfffUV33//PZ07d6Zz586sX7/+pMecMGECGRkZzsfevXvd+h7qBdqJb2fW/9/fd7v1tURERKSsGj+9vF+/fjgcrt9Pym63Y7fb3VhRebf0acrsjcl8t3o/jw9pS7CvT5W+voiISF1VrXt0IiIisFqtpKSklNmekpJCdHS0h6o6c71b1KN1VCC5hSVMW7nP0+WIiIjUGdU66NhsNrp168b8+fOd2xwOB/Pnz6d3797ndOyEhATi4uLo0aPHuZZ5WhaLhVt6NwPg02W7cTgMt7+miIiIVIOgk52dzdq1a1m7di0AiYmJrF27lj179gAwfvx4PvroIz755BM2b97MPffcQ05ODmPHjj2n1x03bhybNm1ixYoV5/oWXHJFl0YE+Xqz+0gui7cfqpLXFBERqes8PkZn5cqVDBw40Pnz+PHjARg9ejRTp07luuuu49ChQzz99NMkJyfTuXNnZs+eXW6AcnUXYPfmqq6Nmbp0N9NW7WNAm/qeLklERKTWsxiGUaevo2RmZhISEkJGRgbBwcFufa31+zIY8c5v2L29WPn3eII0KFlEROSsuPr32+OXruqSDo2CiY0MoKDYwU/rDnq6HBERkVqvzgadqhyMXMpisXBDzyYAfLosiTremSYiIuJ2dTboVPVg5FLXdIvB18eLzQczWan7X4mIiLhVnQ06nhLi78PIzo0A+Pi3RA9XIyIiUrsp6HjArf2aAzB7YzK7DmV7uBoREZHaS0HHA1pHBRHfrj6GAR8s2uXpckRERGotBR0PuWdASwC+W7OPgxl5Hq5GRESkdqqzQccTs65O1K1pGL2ah1NUYvDOLzs8UoOIiEhtpwUDq3DBwL9avusI1334Oz5WCwseHUDjMP8qfX0REZGaSgsG1gC9WtSjb8t66tURERFxEwUdDxt/cWsAvlm1j4zcIg9XIyIiUrso6HhYt6bhNAjxpcRhkHgkx9PliIiI1CoKOtVA4zA/APYdzfVwJSIiIrVLnQ06np51daLSQcj7jmqauYiISGWqs0HHU/e6qkijUPXoiIiIuEOdDTrVSWSQHYC0nEIPVyIiIlK7KOhUA2EBNkBBR0REpLIp6FQD4f5m0Dmao+nlIiIilUlBpxoI9fcB4GiuenREREQqk4JONRB+7NLV0dxC6vgdOURERCpVnQ061Wl6edixS1dFJQY5hSUerkZERKT2qLNBpzpNL/ezWQm0ewOQnJHv4WpERERqjzobdKqbmHBz0cC9WktHRESk0ijoVBNNws1FA/ccUdARERGpLAo61USTYz06e9IUdERERCqLgk41oaAjIiJS+RR0qokm9QIA2KugIyIiUmkUdKqJE3t0tJaOiIhI5VDQcQfDgL1/wOJJLj+lUagfXhbILSzhcLZWSBYREakMZxV0PvnkE2bMmOH8+fHHHyc0NJQ+ffqQlJRUacW5k1sXDMw7ClOGwS8vQupml55i8/aiQcixmVe6fCUiIlIpzirovPTSS/j5mX+Uly1bRkJCAq+++ioRERE8/PDDlVqgu7h1wUD/cGgZb36//huXn1Z6+UrjdERERCrHWQWdvXv30rJlSwC+//57rrrqKu68804mTpzIr7/+WqkF1lgdrjS/bpvj8lNKg06S1tIRERGpFGcVdAIDAzly5AgAc+bM4eKLLwbA19eXvLy8yquuJmsx0Pyash6yU116SrMIc+bVttQsd1UlIiJSp5xV0Ln44ou5/fbbuf3229m2bRvDhg0DYOPGjTRr1qwy66u5AiMhqqP5/a5FLj2lU+MQANbuSXdTUSIiInXLWQWdhIQEevfuzaFDh/j222+pV68eAKtWreKGG26o1AJrtNgB5tddC1xq3ikmFC8L7E/PIyVTN/cUERE5Vxajji/akpmZSUhICBkZGQQHB1fuwXf+Av+9AoIawvhNYLGc9inD3vyVTQczeW9UV4Z2bFC59YiIiNQSrv79PqsendmzZ/Pbb785f05ISKBz587ceOONHD169GwOWTs16Q1WO2QdgMPbXHpK16ahAKxK0nkUERE5V2cVdB577DEyMzMBWL9+PY888gjDhg0jMTGR8ePHV2qBNZqPHzTtbX6/07XLV12bhAGweo+CjoiIyLk6q6CTmJhIXFwcAN9++y2XXnopL730EgkJCcyaNatSC6zxSmdf7fzFpealQWfD/kzyi0rcVZWIiEidcFZBx2azkZtrrvUyb948LrnkEgDCw8OdPT1yTCtz6j27FkJe+mmbN63nT/0gO4UlDl2+EhEROUdnFXT69evH+PHjeeGFF/jjjz8YPnw4ANu2baNx48aVWmCNVz8OIttCSQFs+em0zS0WCxe2jgRg8bZD7q5ORESkVjuroPPOO+/g7e3NtGnTeO+992jUqBEAs2bNYsiQIZVaoLu49V5XJ7JYoOPV5vcu3g6i/7GgM3+LawsNioiISMU0vdyd08tLpSXCW53B4gXjt0BQ1CmbZ+QV0e2FuRQ7DBY+OsC5YrKIiIiY3Dq9HKCkpIRvv/2WF198kRdffJHp06dTUqLBsxUKbw6Ne4DhgI3TT9s8xM+Hns3DAZi1Idnd1YmIiNRaZxV0duzYQbt27bjlllv47rvv+O6777jpppto3749O3furOwaa4cOxy5fbZjmUvPLOjUE4NvV+6jjnW4iIiJn7ayCzgMPPEBsbCx79+5l9erVrF69mj179tC8eXMeeOCByq6xdmh/hXnpat8K2L/qtM2Hn9cAXx8vdqRms1r3vhIRETkrZxV0Fi1axKuvvkp4eLhzW7169Xj55ZdZtMi1G1jWOUFR0PFa8/tFk07f3NeH4R3NXp0v/tjjzspERERqrbMKOna7naysrHLbs7Ozsdls51xUrdXvYfPrtlmQuuW0zW/s1QSA//vzAOm5he6sTEREpFY6q6Bz6aWXcuedd7J8+XIMw8AwDH7//XfuvvtuLrvsssqusfao3xbamGsO8etrp23etUko7RoEU1Ds4JuV+9xcnIiISO1zVkHnrbfeIjY2lt69e+Pr64uvry99+vShZcuWTJ48uZJLrGUGPGF+Xf8NHFhzyqYWi4XRvZsC8O/fdumWECIiImforIJOaGgoP/zwA9u2bWPatGlMmzaNbdu2MX36dEJDQyu5xFqmQafjY3Xm/ANOM6Pqiq6NaBDiS0pmAd+s3FsFBYqIiNQeLi8YeCZ3JX/jjTfOuqCqViULBv7V0SR4pzuUFMKw16DnHads/umy3Tz9w0Yahviy8LGB2LzPevkjERGRWsHVv9/erh5wzZpTX2YpZbFYXD1k3RXWFDpdD6s/hV/fgM6jwOZ/0ubXdo/hnV92cCAjn29X7+OGnk2qsFgREZGaS7eA8ESPDkBBFrwRBwWZEDcSrv3klM3//esuXpyxmZhwP+aPH6BeHRERqdPcfgsIOUf2IBh+7BLfpu9hx/xTNh/VqykRgXb2puXx2fIk99cnIiJSCyjoeFLHq6H1sbu9T78L8tJP2tTPZuXhi1sB8Ob87VpXR0RExAUKOp5kscDVH0NwI8g5BN/decpZWNd1j6FNVBDpuUW8MntrFRYqIiJSMynoeJotAK6ZClYbbP8Zfnr4pE29rV48f3l7wLwtxMrdaVVUpIiISM1UZ4NOQkICcXFx9OjRw9OlQExPGPGW+f2qKbDy45M27dWiHld3awzA49PWUVCsRQRFRERORrOuPDXrqiK/vgHznwMvb7jpW2gxoMJmmflFXPTaIg5nF3DnhS14ali7qq1TRETEwzTrqibq9zC0vxIcxfDFDZCyqcJmwb4+TLyyIwAfLt7Fb9sPV2WVIiIiNYaCTnViscDl70CDzlCUC5+MMFdRrsDFcVGMOnZ38/FfryUtR7OwRERE/kpBp7qxBcCNX0FIDOQehqmXwtHdFTb9+/A4WtYPJDWrgMenraOOX4UUEREpR0GnOgqKhtvmQFgzyNgD/46HtMRyzfxsVt66vgs2qxfzNqfw39+1kKCIiMiJFHSqq+CGcMuPENrUXGPn08sgbVe5ZnENg3l8SBsAXvhpE6uSNOVcRESklIJOdRbWFG792byMlb7HvIx1aFu5Zrf1a86wjtEUlRjc9d9V7E/P80CxIiIi1Y+CTnUX3ABunQ0RrSFzP3w8GJLXl2lisViYdHUn2kYHcTi7kNumriArv8hDBYuIiFQfCjo1QUhjGDsLGnaBvDT4z2DYtbBMkwC7N/8e3Z2IQDtbkrO4+3+rKCx2eKZeERGRakJBp6YIiICbvoPGPaAoBz67FrbMKNOkcZg/U8b0wN9mZcmOIzzxrWZiiYhI3aagU5P4h8OYGdBmOJQUwFc3w+r/lmnSsXEI747qitXLwvQ1+3XzTxERqdMUdGoabztc+yl0uhGMEvjxPvjxfnAcv0w1oE19Xj62cvL7i3by1vztnqpWRETEoxR0aiKrN4x8F7rfav68+lOYNgYKspxNrukew5ND2wLwxtxtvDlPYUdEROoeBZ2aymKBS/8FA/8OWGDTD/DhAEjZ6Gxyd/9Ynhhihp1/zdvG5Hnlp6aLiIjUZgo6NV3/x8y1doIbwZEd8NEgWPOZc/c9A2KdPTuT521X2BERkTpFQac2aNIL7voVYgdBcR78cC9MuxUKsgGzZ2fCCWHnX3MVdkREpG5Q0KktAurBqGnmpSyLF2z4Ft7vC4mLAbirfyxPDTPDzpvzt/Paz1s19VxERGo9BZ3axMvLvJQ1+ifzthFHd8MnI2DWE1CUx50XxvK3Ye0AeGfBDp6avp7iEi0qKCIitZeCTm3UrC/cs/T4rKzl78MHF8KBNdxxYQteHNkBLwt88cde7vh0JTkFxZ6tV0RExE0UdGor32BzVtaobyEwGg5vg3/Hw4KJ3NSjIe/d1A27txcLth7i+g9/JzUr39MVi4iIVDoFndquVTzcuwziRoKjGBa9DG93Y3DQbr6483zCA2ys35/BFQlL2XQg09PVioiIVKpaEXSuuOIKwsLCuPrqqz1dSvXkHw7XTIUrPwJbEKQnwZShdN06mel3dKF5RAD70/O4+v2l/Lwx2dPVioiIVJpaEXQefPBBPv30U0+XUb1ZLHDetfDwBmh/JRgOWDKZpl8O5KeLM+gXW4/cwhLu+u8qJs/bhsOhGVkiIlLz1YqgM2DAAIKCgjxdRs3gFwrXTIHrPjMXGUzfQ8D0W/jU91Ue6mYHzLV27vh0JRl5RZ6tVURE5Bx5POgsXryYESNG0LBhQywWC99//325NgkJCTRr1gxfX1969erFH3/8UfWF1jbtLoX7VkC/8eDlg9fO+Ty07RZmdPyVUO9C5m9J5bJ3ftO4HRERqdE8HnRycnLo1KkTCQkJFe7/6quvGD9+PM888wyrV6+mU6dODB48mNTU1CqutBayBUD8M3DXYojpBUU5tN/+HisDH+HuwF/ZcySbke8u4X+/J2lxQRERqZE8HnSGDh3Kiy++yBVXXFHh/jfeeIM77riDsWPHEhcXx/vvv4+/vz8ff/zxWb1eQUEBmZmZZR51XlSceb+sa6ZCaBO884/wZPF7zAmZSPuSrfz9+w08+OVasvJ1KUtERGoWjwedUyksLGTVqlXEx8c7t3l5eREfH8+yZcvO6pgTJ04kJCTE+YiJiamscms2iwXaXwH3Lof4Z8Hbj1YFG5luf4Z3bW/y57rVXPr2b6zbl+7pSkVERFxWrYPO4cOHKSkpISoqqsz2qKgokpOPT4OOj4/nmmuuYebMmTRu3PiUIWjChAlkZGQ4H3v37nVb/TWSzR/6PQz3r4IuNwEWhnktZ579ccZkvMft783m37/u0qUsERGpEbw9XUBlmDdvnstt7XY7drvdjdXUEiGN4PIEOP9emPs0PjvmMdb7Z64yFvPe7Mu5a9tN/PPankQG6VyKiEj1Va17dCIiIrBaraSkpJTZnpKSQnR0tIeqqmOi2sNN38LN32NEdyTYkscTPl/y7J5beOeN55mzfp+nKxQRETmpah10bDYb3bp1Y/78+c5tDoeD+fPn07t373M6dkJCAnFxcfTo0eNcy6wbYgdiuXMxXPEBRYENaWhJ4znjHWK/iefTj94gI0f3yhIRkerHYnh4sEV2djY7duwAoEuXLrzxxhsMHDiQ8PBwmjRpwldffcXo0aP54IMP6NmzJ5MnT+brr79my5Yt5cbunI3MzExCQkLIyMggODj4nI9XJxTlU7zsPQoX/wv/4gwAkmhIdp/HaB8/BryqdX4WEZFawNW/3x4POgsXLmTgwIHlto8ePZqpU6cC8M477zBp0iSSk5Pp3Lkzb731Fr169aqU11fQOQcFWRyY9Sqhaz/EH7NH54BvS8IueQy/zteAl9XDBYqISG1VY4KOpynonLu8rHSWf/EiXff/j2BLHgA5wS0JGPostL3UnLouIiJSiVz9+61rDHLO/IJCGXDna+y4fgn/9rmBDMOfgMwd8NVNFL/XD7b9DHU7T4uIiIfU2aCjwciVr2u7WG587B0+7DKd94pHkG/44J26AT6/FqYMhaSzW+RRRETkbOnSlS5ducWqpKO88s1CBqV/w2jrHHwtx24f0WowDHoaojt4tkAREanRdOlKPKpb0zD++9BlZF/4DIOKJvN58UUU4wXbf8Z4vx98ewekJXq6TBERqeXUo6MeHbfbeCCDx6etI/fgVsZ7f8MI6+/mDi8f6DYGLnwMgs59qQAREak7NOvKRQo6VaOoxMGHi3fx5vzttCrZyQTb1/Sz/Gnu9PaD7mOh/xPgF+rROkVEpGZQ0HGRgk7V2pGazRPfrmNV0lF6e23kuYBptC7aau70DYE+95v317IFeLZQERGp1hR0TiMhIYGEhARKSkrYtm2bgk4VKnEYfLpsN5N+3kpuYTGXWNfwUvC3ROQdG7MTGAX9H4euo8Hq49liRUSkWlLQcZF6dDznQHoeT/+wkXmbU/DCwa0hq3nU5xt8s/eaDcJjYdA/IG6kFh0UEZEyFHRcpKDjWYZhMHtDMk//uJFDWQX4UMyrzVdzecb/8Mo9bDZq2BUufg6aX+jZYkVEpNpQ0HGRgk71kJFXxCuzt/D58j0AxPiX8GGr32m7ayqWohyzUewgiH8WGpznuUJFRKRaUNBxkYJO9bJydxoTvlvP9tRsAIa3sDIxYjbBG/4LjmKzUcdr4aK/QVgzzxUqIiIepaDjIgWd6qew2MGHi3fy1i87KCx2YPf24u99fLkx+1Osm74zG3n5QI/b4cJHISDCswWLiEiVU9A5Dc26qv52H87hb9+vZ8mOIwC0qh/IGxcYdNz8L9i10GxkC4K+D0JvTUkXEalLFHRcpB6d6s0wDH5Ye4AXftrEkZxCAC49rwHPtU+l3rJ/QvI6s2FAfRjwhKaki4jUEQo6LlLQqRnScwuZ9PNWPv9jD4YBvj5e3HNhC+6J/BPbon/C0d1mQ01JFxGpExR0XKSgU7NsPJDBcz9u4o/daQA0CvXj70NjGZI/G8uiV0FT0kVE6gQFHRcp6NQ8hmHw07qDTJy5mQMZ+QCc3yKc5wY3pc2uT2Dp21A6Jb1lPFz0D2jY2XMFi4hIpVPQcZGCTs2VV1jCe4t28sGinRQUO/CywHU9mvBY31DCV74Jq6Ycn5Iedzlc9DREtPRs0SIiUikUdFykoFPz7Tuay8SZW5ix/iAAQb7ePHBRK25pW4L911dhwzQwHGCxQtdbYMCTEBTt4apFRORcKOi4SEGn9vgjMY3n/m8jGw9kAhAT7scTQ9oyvH4alvnPw/afzYbefnD+PdD3AfAL82DFIiJythR0TkPr6NROJQ6Db1ft47U5W0nNKgCgS5NQ/nFpHF2NzTD3Gdj3h9nYHgJ974de94A90INVi4jImVLQcZF6dGqn3MJiPly8iw8W7SKvqASAEZ0a8tjFrWlyeCH88iKkbjIb+0fABeOh+23g4+u5okVExGUKOi5S0KndUjPzeW3OVr5ZtQ/DAB+rhVt6N+OBgbGE7Po/WPBPSNtlNg5qCP0fhy43adFBEZFqTkHHRQo6dcPGAxm8PGsLv24319kJ9ffhwUGtGNW9IbYNX8KiVyFzn9k4rDkMmAAdrwYvqwerFhGRk1HQcZGCTt2yaNshXvxpk/Pu6M3q+fPEkLYMaRuKZdUn8OtrkHPIbBzZDgY+Be1GaJVlEZFqRkHHRQo6dU9xiYOvV+7jjbnbOJxtDlju1jSMvw1vR9doGyx/H5a8CfkZ5hMadoGL/g6xgxR4RESqCQUdFyno1F3ZBcV8uGgnH/2aWGbA8uOD2xDjVwjL3oFl7x5fZblJH/M+Wk37eLBqEREBBR2XKehIckY+r8/ZyrTV5oBlm7cXt/Vrzr0DYgkqToff/gUr/g0lZu8PsYPMwNOwi0frFhGpyxR0XKSgI6U2HsjgnzM2s3TnEQDqBdgYf0lrruseg3f2QVg8Cdb89/htJdqNgIF/g/rtPFi1iEjdpKBzGlowUCpiGAbzN6fy0qzN7DpkXrJqVT+Qp4a1Y0CbSCxHE2Hhy7Dua8AALHDeteZtJcJbeLR2EZG6REHHRerRkYoUlTj4fPkeJs/bxtHcIgD6tYzgqWHtiGsYDKmbzTV4Nv+f+QQvb+hys7kOT3BDD1YuIlI3KOi4SEFHTiUjr4h3F+xgypLdFJY4sFjgmm6NefSSNtQP9oX9q81VlnfON5/g5QOdb4Q+D+hO6SIibqSg4yIFHXHF3rRcXpm9hZ/WmXdI97dZuad/LLdf0AI/mxWSlsL852HPMvMJFi/oeA1c8AhEtvFg5SIitZOCjosUdORMrEo6ygs/bWLt3nQAGoT48tjgNozs3AgvC5C4GJYlHL9TOhaIu9zs4WnczVNli4jUOgo6LlLQkTNlGAb/t+4gr8zawv70PADaNwxmwtB29GsVYTY6sAYWvwZbfjr+xJYXm4OWG3f3QNUiIrWLgo6LFHTkbOUXlfDxkkTeW7CTrAJzyvmANpE8MaQt7Roc+yylbISlb5uztAxzUUJizjcDT4sBWmlZROQsKei4SEFHzlVaTiFvzd/O/35Pothh4GWB63rE8PDFrakf5Gs2OrITfn0D1n6GOS0dqN8e+j0E7a/Q3dJFRM6Qgo6LFHSksiQezuG1n7cyY705YDnAZuWu/rHcfkFz/G3eZqP0PbD0HVjzv+O3lgiJgd7joOtosPl7qHoRkZpFQcdFCjpS2VbuTuOFGZv589iA5ahgO49c3IarujXG6nXsUlVeOqz4CJZ/cPxu6X7h0OUmOP8ercUjInIaCjouUtARd3A4DH5af5BXZ29h31FzwHKbqCCeHNrWXGG5dGxOUT78+Tn8NhnSk8xtVju0Hwl97ofojh6pX0SkulPQOQ3dAkKqQkFxCf9dlsTbv+wgI89cYblX83D+cWkcHRqFHG9YUgzb58CSN2Hv78e3N+kN598LbYZqHI+IyAkUdFykHh2pCum5hby7cCefLN1NQbG5wvLIzo145JLWNA47YVyOYcCe3+H3d2HrzOM3EA1uDH0fhE7Xg68+pyIiCjouUtCRqnQgPY9XZm/hh7UHALBZvbi1X3Puu6glgXbvso2zks0xPCv+DQWZ5jZbIJx3HXQbAw3Oq9riRUSqEQUdFynoiCes35fBxFmbWbrzCAARgTYevrg113WPwdvqVbZxQTas/dwcvHx42/HtrQZDj9ugZTx4WauwehERz1PQcZGCjniKYRjM35zKP2duJvGwOdU8NjKAJ4e2I75d/eMDlo8/4dgtJt4xx/OUCmkCPW83757uH16F70BExHMUdFykoCOeVljs4LPlSbw1fztHc80By71b1ONvw9uVHbB8osM7YOXH5gKE+enmNqsd4i4zL2s17atVl0WkVlPQcZGCjlQXmflFvLdwJ//5LZHCYwOWr+jSiEcvaUPDUL+Kn1SUB+unwR8fQPL649vrtYSut0CnGyEwsmregIhIFVLQcZGCjlQ3+47m8ursrfz4pzlg2e7txW39mnP3gFiCfU8yxdww4MBqWPUJbPgWCrPN7V4+0HaY2cvTfAB4eVX8fBGRGkZBx0UKOlJdrd2bzkszN/NHYhoA4QE2HhzUiht7NcHnrwOWT1SQBRu+g1VTzfBTKrSp2cvT5WYIinJv8SIibqag4yIFHanODMNg3uZUJs7azK5D5oDl5hEBPDGkLYPbR5UfsPxXyevNXp51X0NBhrnNYjUXIOx6C8QOAqv3qY8hIlINKei4SEFHaoKiEgdfrtjLm/O2cTi7EIDuTcN4ang7ujYJO/0BCnNh0/dmL8/e5ce3B0ZBx2ug+61QL9YttYuIuIOCjosUdKQmyS4o5oNFO/no113kFzkAGN6xAY8PaUPTegGuHSR1C6z5L/z5BeQeOb69UTdofyV0ugEC6rmhehGRyqOg4yIFHamJkjPyeWPuVr5ZtQ/DAB+rhRt7NuHegS2JCvZ17SDFhbDzF3Mhwl0Lj99uwssHWg+GzjdCy4vB2+a29yEicrYUdFykoCM12eaDmUyctYXF2w4B4Odj5a7+Lbjzwhb4285g7E12Kmz6wRzPk3LCNHX/ehB3uXnbicY9NWtLRKoNBR0XKehIbbBkx2Fem7OVNXvSAYgItPPgoJZc16MJNu8zDCcpG83LWuu+huyU49uDG0P7keaNRaM6aEFCEfEoBR0XKehIbWEYBjPXJ/PK7C3sScsFoGk9fx4f3JZhHaNPP0Prr0qKIXEhrP8WNv8fFGYd3xfWzFyMsMOVENGq0t6DiIirFHRcpKAjtU1hsYMvV+zhrfk7OJxdAEDHRiE8MaQt/VpFnN1Bi/JhxzxY/zVsmQmOouP76rc3e3raX6HQIyJVRkHnNBISEkhISKCkpIRt27Yp6Eitk1NQzEe/7uKjxbvIKSwBoG/Lejw+uC2dYkLP/sCFObDpR9j4nTmYuXQQM0D9OGh3mTmup347Xd4SEbdR0HGRenSktjuSXcA7C3bw2e97KCwxp6RfEhfFk0Pb0iIy8NwOnpsGW36CjdPNO6ufGHrCW0CbYeaU9UZdFXpEpFIp6LhIQUfqir1puUyet53pa/bhMMDby8KNvZrw4KBW1Au0n/sL5KbBtp9h84+wYz6UFBzfFxJjhp42Q807q2vKuoicIwUdFynoSF2zPSWLl2dtYf6WVAAC7d7cMyCW2/o1x9fHWjkvUpAFW2eZj22zoSj3+D57MDS7AJpfYIafsKaV85oiUqco6LhIQUfqqqU7D/PSzM1s2J8JQMMQXx65pA1XdGmEl1clXmYqyjMXJNzyE2ybAzmpZfdHdYSWg8xHkz6695aIuERBx0UKOlKXORwGP/y5n9d+3sb+9DwAOjQK5qmh7ejT8ixnaJ36Bc07qq//Bg6shX1/gOE4vt/bD2J6mD0+sYOgYRctUigiFVLQcZGCjgjkF5UwZclu3l2wg6wCc0DxgDaRPD64LXEN3fh7kXPYnLm1Yz5snwN5aWX32wKhaR9zVeaWgyCqPXhXwngiEanxFHRcpKAjctyR7ALemr+dz5bvodhh/tNweeeGjL+4tes3DT1bjhI4vA2SlpiXunYtgoLMsm0sVmjSG1peBI17QKPuYPN3b10iUi0p6LhIQUekvMTDObw+Zys/rTsIgNXLwjXdGnP/oFY0CvWrmiJKiiB5Pexdbk5d37MM8o6WbePtC9HnQct4aNrbvAO7zc2BTESqBQUdFynoiJzchv0ZTPp5K4uO3TTUZvXihp4xjBvYkvqu3iW9shiGeR+u3b/C7t/MS14nzuYCs8cnuiPE9IImvaBhVwhtqnE+IrWQgo6LFHRETm/l7jTemLuNpTuPAGD39uLm85tyV/9YIoM8NGbGMODITti1wLzctXcFZO4r384v3Bzn07SPGXyiO4L9HBdKFBGPU9BxkYKOiOuW7jjMpBPuku7r48UNPZtwd/9Yoqq6h6ciGfvMS117lsPe3yF1M5QUlm1j8YKINuZqzY17mF/rx4HVxzM1i8hZUdBxkYKOyJkxDINF2w7xr3nb+XNvOmBe0rquRwx3D4itujE8rigpMqexJy2BpKWQsgEy95dvZ7VBVAdo1g8adDKDT71YzfASqcYUdFykoCNydgzD4Nfth3n7l+2s2G0OEvaxWriqa2Pu7h9Ls4hqOig4K8Vcy2ffSnMdn4N/Qn5G+XZWG4THmuv6RHWEqDgzAPmHV33NIlKOgo6LFHREzo1hGPy+K4235m9n2S5zDI+XBYZ1bMDd/WPp0CjEwxWehsMBqRvN4JO8zgw+yRvK3qvrREENzMATFQf125tfI9qATzW4dCdShyjouEhBR6TyrNydxjsLdrBw6yHntgtbR3JP/1jObxGOpabcwdww4PB2OLjWHOeTutkMQ+l7Km5vsUJYs+PjfcJbQHBDc2Vnjf0RcQsFHRcp6IhUvk0HMvlg8U7+788DHFt3kM4xodwzIJaL20VV7r20qlJ+5vHQk7IJUjeZU97z0ytub7VDeHMz+IQ2NW9gGtUBQhpr2rvIOVLQcZGCjoj77DmSy0e/7uLrlXspKDbvadUiIoBb+zXnqq6N8bNV0t3SPckwIOsgHFxnXvo6sgMObTEXOzzxPl7lWI71/jQ3e4PCm0PYse9Dm6gnSOQ0FHRcpKAj4n6HsgqYujSRT5clkZVv3ksr1N+Hm3o15ZbeTat+8cGq4CgxL3Wl7TIfqZvg0FZzCnzG3tOEIMzQE9rk+CMkxlz/p7R3SGsBSR2noOMiBR2RqpNdUMw3K/fy8ZJE9qaZd0v3sVq4rFMjbuvX3L03EK1OigsgLdEMQkd3w9FE8+eju81Hcd7pj+EbCsGNzLFA4S0gKMpcHDGsKQQ3hsD64Bfq1rch4kkKOi5S0BGpeiUOg7mbkvn3r4msTDp+/6q+Letxe78W9G8dWXPH8Zwrw4CsZPMSWMY+Mwxl7IGjSZCdCjmp5e/5dTLevualMP965rT4gPoQEAkBEebPvqHmeCEfPwiMMqfU15QB41LnKei4SEFHxLPW7DnKf35LZNaGZEqOjVyOjQzgtn4tuLJrI3x9asE4nsqWnwmZB8xbXqTvNXuEjuyEwmxznaDM/eXv/O4Ke7AZePzDzd4hvzBze2iMGZB8Q8EeZI4f8g0x2/lHmNsUkKSK1amg89NPP/HII4/gcDh44oknuP32211+roKOSPWw72gunyzdzZd/7CWrwBzHE+Lnw5VdGzGmTzOa1qumCxBWV/mZZm9QziGzByjnMOQeNn/OOWT2GuWmmb1EhVnn9lpWG9gCwTcYvHzM8UO2QDMIefuaPUa2QDMo2QLA5m/+bAsAn9Lv/Y/tCzS3edsVnuSU6kzQKS4uJi4ujgULFhASEkK3bt1YunQp9erVc+n5Cjoi1UtWfhFfr9zHlCWJ7DtqjlWxWOCCVpHc2DOGQe2i8LFqWnalKik2w05WyvFglHvEfBTmHAtKh8wVpAuzIecIYJhBqSjHPTVZrMdCj5+5eKNPAATUAyxmCPK2m9P3S7/39jUDl7cveNsq3mf1Me94bzs2kLt0n/mC5gBxeyAU5ZuX9/IzzHFQPr7mPdIsVvOr17GvpQ/nzyfuV0hztzoTdJYuXcqkSZOYPn06AA899BC9evXihhtucOn5Cjoi1VOJw+DX7YeYunR3mQUIIwJtXN0thht7NqFJPX8PVigAFOYeC0TZkJduDqQuyDJDUEkRFOebPUklRWZoKswxw0Zh9rGfc499zTa3F+d7+h1VngrD0bEQdLJwVGF7L3PNJcMBWI71oPmbM/usPmYwwzD3WSzHvnodD1ul2wyHeTmypMj8bxIUbR6rpNAMrz5+5sPLavaqYTHXiLIHmXU4isyeQFugOdjd4mVeIrUHm8dwFJvPz0s3v89LN39u2ge6jj4WVCuPq3+/vSv1Vc/C4sWLmTRpEqtWreLgwYNMnz6dkSNHlmmTkJDApEmTSE5OplOnTrz99tv07NkTgAMHDtCoUSNn20aNGrF/fwU37RORGsXqZWFAm/oMaFOfpCM5fPHHXqat2sfh7ALeX7ST9xftpFfzcK7pHsOwjtH42zz+z1ndZPM3H5WlpNjsJXIGoCzzMpzFywxCWMwwVFJofi0uMB8lBSd8f5J9JUVmL05pmCrMMf8gG4YZAgqyzD/mhmFuz0o+3uNjlJhtHCWYocIFhuP4MgIllXeKapwdc6H9FZUedFzl8X8ZcnJy6NSpE7feeitXXnlluf1fffUV48eP5/3336dXr15MnjyZwYMHs3XrVurXr++BikWkqjWtF8CTQ9vyyCWtmb85lc+WJ/HbjsMsT0xjeWIaz/64kUvPa8CVXRvTvWlY3Z2xVRtYvcEaYg52rq5Kg1Fp8DEcZYOQYRz/uVwb4yTPcVTQ/sQ2x77Pz8DZc2PxMkOdj7/5s2EAxglfHce+xwx3BVnHe5SsNijKM9tkJ8O+VdCsn9kDU9oTlJ9h1mIPNMdeeXmbi2GGNjWP7yg2x1UV5po9S17ex3rwjpgz/dISza9Gibkgpod4POgMHTqUoUOHnnT/G2+8wR133MHYsWMBeP/995kxYwYff/wxTz75JA0bNizTg7N//35nb09FCgoKKCg4frO+zMyzmJkgIh7hY/ViSIdohnSIZn96HtNX7+PrlfvYk5bLlyv28uWKvTQJ9+eKLo24qmtjXdoS9yi9xIRVK1jXANV6RF9hYSGrVq0iPj7euc3Ly4v4+HiWLVsGQM+ePdmwYQP79+8nOzubWbNmMXjw4JMec+LEiYSEhDgfMTExbn8fIlL5GoX6cd9FrVj46AC+vPN8ru7WmEC7N3vScnlz/nYunLSAkQlL+Pi3RFIza9G4DxE5Ix7v0TmVw4cPU1JSQlRUVJntUVFRbNmyBQBvb29ef/11Bg4ciMPh4PHHHz/ljKsJEyYwfvx458+ZmZkKOyI1mJeXhfNb1OP8FvV4/vL2/Lwxme9W72fJjsOs3ZvO2r3pvDhjEz2bhzP8vIYMaR9NZJDd02WLSBWp1kHHVZdddhmXXXaZS23tdjt2u/6RE6mN/G3eXNGlMVd0aUxqVj4z1x3khz8PsGZPOr/vSuP3XWk888MGzm9Rj6EdGzCobX0ahvp5umwRcaNqHXQiIiKwWq2kpKSU2Z6SkkJ0dLSHqhKRmqB+kC9j+jZnTN/m7E3LZdaGg8xYd5A/92WwdOcRlu48wj+AzjGhDOkQTXy7KGIjA7Bo/RORWqVaBx2bzUa3bt2YP3++c8q5w+Fg/vz53HfffZ4tTkRqjJhwf+68MJY7L4xlb1ouP607yPzNKazac9R5eevlWVtoHhHAxXFRxLeLokuTUC1MKFILeDzoZGdns2PHDufPiYmJrF27lvDwcJo0acL48eMZPXo03bt3p2fPnkyePJmcnBznLKyzlZCQQEJCAiUldXlxA5G6Jybcn3sGxHLPgFhSs/L5eWMK8zalsGznERIP5/Dh4l18uHgXQXZvBrStT3y7+lzQKpLwAJunSxeRs+DxlZEXLlzIwIEDy20fPXo0U6dOBeCdd95xLhjYuXNn3nrrLXr16lUpr6+VkUUEILugmEVbDzFnUzKLtx3iaG6Rc5/FAp0ahzKwTX0uaB1Bx0Yh6u0R8bA6cwuIc6WgIyJ/5XAYrNmbztxNKSzcmsqW5LI3vQywWenbMoKBbevTNzaCmHA/je0RqWIKOi5S0BGR00nOyGfRtlR+2ZLK8sQ00k/o7QFzTZ9eLcLpfWyae0y4FioUcTcFndM4cYzOtm3bFHRExCUOh8HGA5ks2JrK4m2HWLs3nWJH2X9GG4X6HVvbJ5zesfVoHKbgI1LZFHRcpB4dETkXuYXFrEo6yrKdR/h91xHW7csoF3wahvjSvVk43ZuF0alxKO0aBGPz1hgfkXOhoOMiBR0RqUw5BceCz64jLNt5hA37ywcfu7cX7RsG071ZOF2bhNK1SRiRQXaN8xE5Awo6LlLQERF3yi0sZu2edFYmHWXF7jTW788oN8YHICLQRueYMDo2CuG8mBA6NgohIlCruIucjIKOixR0RKQqORwGiUdyWLMnndV7jrI66ShbU7Ko6F/iqGA7cQ2Cad8whI6NQ+jWNEzhR+QYBR0XKeiIiKflF5Wwbl8GG/ZnsG5fOuv3Z7DrcE6F4adFZAA9m4XTp2UE5zcP1yUvqbMUdE5Ds65EpDrLLihmy8FMNh7IZOOBDNbuTWdbSna5duEBNtpEBdG2QRBto4NoGx1M66gg/GxWD1QtUnUUdFykHh0RqSmO5hSyKukoyxOP8Ov2w2xLycJRwb/gFgs0qxdAy/qBtI4KpHlEIM0j/GkeEUiYv496gKRWUNBxkYKOiNRU+UUlbE/JZnNyJluTs9iSnMmWg1kcySk86XOCfb1pHhFAs4gAYsL8iQn3o3GYPzFh/jQI9dWtLaTGUNBxkYKOiNQ2h7IK2JqcxfbULHakZrP7SA67D+eyPz3vlM/zskCDED8ahfkRE+ZPo1BfGoT6ER3iS8MQPxqE+hJk91aPkFQLCjouUtARkboiv6iEpCO5JB7OZveRXPam5bLvaB57j5pfC4sdpz1GoN2b6BBfGhx7hAXYiAryJSrYl+gQO/WDfKkfbMfurTFC4l6u/v32rsKaRETEg3x9rLSJDqJNdFC5fQ6HweHsAvYezWPfUTMEHcjI52B6Hgcz8knOzCc9t4jsgmJ2pGazI7X8wOgTBft6ExFoNx9BNiID7UQG2akXaCc8wEaYv43wAB9C/W2E+vngrUtm4iZ1NuicOOtKRKSu8/KyUD/Yl/rBvnRrGlZhm9zCYjP0ZORzID2P5Ix80nILSc0sICUzn5SsfFIyCygsdpCZX0xmfjG7Due49Pph/j7OABR6LASVfh/s502Qrw/h/jYCfb2dbYN8fSrzFEgtpUtXunQlIlJpDMMgPbeIIzkFHM4u5HB2AYeyzMfhbHPb0dxCjuYUcjS3iIy88qtEuyrQ7k29QBsRgXbqBdioF2gj2M+HED8fIgPtZjgKsBHk633s4UOQ3RsvL40xqg106UpERKqcxWIhLMBGWICNlvVP3764xEF6XhGHswtIyykkPbeIo7nHvp4QhjLzzK/ZBcWk5RSSV1RCdkEx2QXFJB3JPaMaA+3eZcKPv81qfm/3IcDujb/Nir/dSoDNmwC7Nz5WC8G+PvjZrOY+mxV/mzcBNm98bV7YrF4aoF2NKeiIiIjHeFu9nGN5zkROQTEpmfkcySnkSHYBh7ILScsuJDPfDEqHswvJyi8iPbeIrPwiMvOLnYOtSwPSwYzKeQ9WLwt+PlZ8faz42bzw87GaD9vxr77Httm9rdh9vLB7e2Hz9jJ/9vbC18eKr4/5XG+rFz5WC/42b7y9LPj6HG9n8/Zy7lfAco2CjoiI1DgBdm9aRAbSItL15xQUl5CVX3zsUeT8PudY8MnKLyKnsIS8whJyCorJKTT3F5U4yC4oJveEfbmFJc670pc4DGd4qkoWC9isx0OTzWqGIO9jIcjbasHbywxF3l7mzz7HQpK31QsfL4szNJntSved8DzrCdudxzi+3+fYa5Yey9tqwcfLCx/vsseIDvbF6qFLhgo6IiJSJ9i9rdgDrZV2Y9TCYgf5xSXkF5aYIajIfOQf+750W36RGZByC0soLHFQWOygoLiEgiIHBcUO8otKnF/zi0ooKjEoKC4hv8hRtn2xo8z9zwwDCorNY1R3q/9xMeEBNo+8toKOiIjIWbAd60kJrqLZX4ZhUFRi4DCMYwHHDEulYaioxEFRiUHxsa9FDgfFpT87DIqKHRQ7jrcpdhgUlpRt43zuse3OYzgcFBabX4tL9x9rX3jC8ZzPK3Gc0MbA2+q5S2wKOiIiIjWAxWLB5m0GBl8fK6Dp9a6osys0JSQkEBcXR48ePTxdioiIiLiJ1tHROjoiIiI1jqt/v+tsj46IiIjUfgo6IiIiUmsp6IiIiEitpaAjIiIitZaCjoiIiNRaCjoiIiJSaynoiIiISK1VZ4OOFgwUERGp/bRgoBYMFBERqXG0YKCIiIjUeQo6IiIiUmsp6IiIiEit5e3pAjytdIhSZmamhysRERERV5X+3T7dUOM6H3SysrIAiImJ8XAlIiIicqaysrIICQk56f46P+vK4XBw4MABgoKCsFgslXbczMxMYmJi2Lt3r2ZznSOdy8qjc1l5dC4rj85l5alL59IwDLKysmjYsCFeXicfiVPne3S8vLxo3Lix244fHBxc6z9sVUXnsvLoXFYencvKo3NZeerKuTxVT04pDUYWERGRWktBR0RERGotBR03sdvtPPPMM9jtdk+XUuPpXFYencvKo3NZeXQuK4/OZXl1fjCyiIiI1F7q0REREZFaS0FHREREai0FHREREam1FHRERESk1lLQcZOEhASaNWuGr68vvXr14o8//vB0SdXKs88+i8ViKfNo27atc39+fj7jxo2jXr16BAYGctVVV5GSklLmGHv27GH48OH4+/tTv359HnvsMYqLi6v6rVS5xYsXM2LECBo2bIjFYuH7778vs98wDJ5++mkaNGiAn58f8fHxbN++vUybtLQ0Ro0aRXBwMKGhodx2221kZ2eXabNu3TouuOACfH19iYmJ4dVXX3X3W6typzuXY8aMKfc5HTJkSJk2OpcwceJEevToQVBQEPXr12fkyJFs3bq1TJvK+p1euHAhXbt2xW6307JlS6ZOnerut1elXDmXAwYMKPe5vPvuu8u00bk8gSGV7ssvvzRsNpvx8ccfGxs3bjTuuOMOIzQ01EhJSfF0adXGM888Y7Rv3944ePCg83Ho0CHn/rvvvtuIiYkx5s+fb6xcudI4//zzjT59+jj3FxcXGx06dDDi4+ONNWvWGDNnzjQiIiKMCRMmeOLtVKmZM2caf/vb34zvvvvOAIzp06eX2f/yyy8bISEhxvfff2/8+eefxmWXXWY0b97cyMvLc7YZMmSI0alTJ+P33383fv31V6Nly5bGDTfc4NyfkZFhREVFGaNGjTI2bNhgfPHFF4afn5/xwQcfVNXbrBKnO5ejR482hgwZUuZzmpaWVqaNzqVhDB482JgyZYqxYcMGY+3atcawYcOMJk2aGNnZ2c42lfE7vWvXLsPf398YP368sWnTJuPtt982rFarMXv27Cp9v+7kyrns37+/cccdd5T5XGZkZDj361yWpaDjBj179jTGjRvn/LmkpMRo2LChMXHiRA9WVb0888wzRqdOnSrcl56ebvj4+BjffPONc9vmzZsNwFi2bJlhGOYfKC8vLyM5OdnZ5r333jOCg4ONgoICt9Zenfz1j7PD4TCio6ONSZMmObelp6cbdrvd+OKLLwzDMIxNmzYZgLFixQpnm1mzZhkWi8XYv3+/YRiG8e677xphYWFlzuUTTzxhtGnTxs3vyHNOFnQuv/zykz5H57JiqampBmAsWrTIMIzK+51+/PHHjfbt25d5reuuu84YPHiwu9+Sx/z1XBqGGXQefPDBkz5H57IsXbqqZIWFhaxatYr4+HjnNi8vL+Lj41m2bJkHK6t+tm/fTsOGDWnRogWjRo1iz549AKxatYqioqIy57Bt27Y0adLEeQ6XLVtGx44diYqKcrYZPHgwmZmZbNy4sWrfSDWSmJhIcnJymXMXEhJCr169ypy70NBQunfv7mwTHx+Pl5cXy5cvd7a58MILsdlszjaDBw9m69atHD16tIreTfWwcOFC6tevT5s2bbjnnns4cuSIc5/OZcUyMjIACA8PByrvd3rZsmVljlHapjb/2/rXc1nqs88+IyIigg4dOjBhwgRyc3Od+3Quy6rzN/WsbIcPH6akpKTMBwwgKiqKLVu2eKiq6qdXr15MnTqVNm3acPDgQZ577jkuuOACNmzYQHJyMjabjdDQ0DLPiYqKIjk5GYDk5OQKz3Hpvrqq9L1XdG5OPHf169cvs9/b25vw8PAybZo3b17uGKX7wsLC3FJ/dTNkyBCuvPJKmjdvzs6dO3nqqacYOnQoy5Ytw2q16lxWwOFw8NBDD9G3b186dOgAUGm/0ydrk5mZSV5eHn5+fu54Sx5T0bkEuPHGG2natCkNGzZk3bp1PPHEE2zdupXvvvsO0Ln8KwUd8YihQ4c6vz/vvPPo1asXTZs25euvv65Vv2BSs11//fXO7zt27Mh5551HbGwsCxcuZNCgQR6srPoaN24cGzZs4LfffvN0KTXeyc7lnXfe6fy+Y8eONGjQgEGDBrFz505iY2OrusxqT5euKllERARWq7XcbIKUlBSio6M9VFX1FxoaSuvWrdmxYwfR0dEUFhaSnp5eps2J5zA6OrrCc1y6r64qfe+n+vxFR0eTmppaZn9xcTFpaWk6v6fRokULIiIi2LFjB6Bz+Vf33XcfP/30EwsWLKBx48bO7ZX1O32yNsHBwbXuf5BOdi4r0qtXL4Ayn0udy+MUdCqZzWajW7duzJ8/37nN4XAwf/58evfu7cHKqrfs7Gx27txJgwYN6NatGz4+PmXO4datW9mzZ4/zHPbu3Zv169eX+SMzd+5cgoODiYuLq/L6q4vmzZsTHR1d5txlZmayfPnyMucuPT2dVatWOdv88ssvOBwO5z+YvXv3ZvHixRQVFTnbzJ07lzZt2tS6Sy1nYt++fRw5coQGDRoAOpelDMPgvvvuY/r06fzyyy/lLtVV1u907969yxyjtE1t+rf1dOeyImvXrgUo87nUuTyBp0dD10ZffvmlYbfbjalTpxqbNm0y7rzzTiM0NLTMCPi67pFHHjEWLlxoJCYmGkuWLDHi4+ONiIgIIzU11TAMcypqkyZNjF9++cVYuXKl0bt3b6N3797O55dOn7zkkkuMtWvXGrNnzzYiIyPrxPTyrKwsY82aNcaaNWsMwHjjjTeMNWvWGElJSYZhmNPLQ0NDjR9++MFYt26dcfnll1c4vbxLly7G8uXLjd9++81o1apVmSnR6enpRlRUlHHzzTcbGzZsML788kvD39+/Vk2JNoxTn8usrCzj0UcfNZYtW2YkJiYa8+bNM7p27Wq0atXKyM/Pdx5D59Iw7rnnHiMkJMRYuHBhmSnPubm5zjaV8TtdOiX6scceMzZv3mwkJCTUuinRpzuXO3bsMJ5//nlj5cqVRmJiovHDDz8YLVq0MC688ELnMXQuy1LQcZO3337baNKkiWGz2YyePXsav//+u6dLqlauu+46o0GDBobNZjMaNWpkXHfddcaOHTuc+/Py8ox7773XCAsLM/z9/Y0rrrjCOHjwYJlj7N692xg6dKjh5+dnREREGI888ohRVFRU1W+lyi1YsMAAyj1Gjx5tGIY5xfwf//iHERUVZdjtdmPQoEHG1q1byxzjyJEjxg033GAEBgYawcHBxtixY42srKwybf7880+jX79+ht1uNxo1amS8/PLLVfUWq8ypzmVubq5xySWXGJGRkYaPj4/RtGlT44477ij3Pyw6l0aF5xAwpkyZ4mxTWb/TCxYsMDp37mzYbDajRYsWZV6jNjjdudyzZ49x4YUXGuHh4YbdbjdatmxpPPbYY2XW0TEMncsTWQzDMKqu/0hERESk6miMjoiIiNRaCjoiIiJSaynoiIiISK2loCMiIiK1loKOiIiI1FoKOiIiIlJrKeiIiIhIraWgIyJygoULF2KxWMrdl0lEaiYFHREREam1FHRERESk1lLQEZFqxeFwMHHiRJo3b46fnx+dOnVi2rRpwPHLSjNmzOC8887D19eX888/nw0bNpQ5xrfffkv79u2x2+00a9aM119/vcz+goICnnjiCWJiYrDb7bRs2ZL//Oc/ZdqsWrWK7t274+/vT58+fdi6dat737iIuIWCjohUKxMnTuTTTz/l/fffZ+PGjTz88MPcdNNNLFq0yNnmscce4/XXX2fFihVERkYyYsQIioqKADOgXHvttVx//fWsX7+eZ599ln/84x9MnTrV+fxbbrmFL774grfeeovNmzfzwQcfEBgYWKaOv/3tb7z++uusXLkSb29vbr311ip5/yJSuXRTTxGpNgoKCggPD2fevHn07t3buf32228nNzeXO++8k4EDB/Lll19y3XXXAZCWlkbjxo2ZOnUq1157LaNGjeLQoUPMmTPH+fzHH3+cGTNmsHHjRrZt20abNm2YO3cu8fHx5WpYuHAhAwcOZN68eQwaNAiAmTNnMnz4cPLy8vD19XXzWRCRyqQeHRGpNnbs2EFubi4XX3wxgYGBzsenn37Kzp07ne1ODEHh4eG0adOGzZs3A7B582b69u1b5rh9+/Zl+/btlJSUsHbtWqxWK/379z9lLeedd57z+wYNGgCQmpp6zu9RRKqWt6cLEBEplZ2dDcCMGTNo1KhRmX12u71M2Dlbfn5+LrXz8fFxfm+xWABz/JCI1Czq0RGRaiMuLg673c6ePXto2bJlmUdMTIyz3e+//+78/ujRo2zbto127doB0K5dO5YsWVLmuEuWLKF169ZYrVY6duyIw+EoM+ZHRGov9eiISLURFBTEo48+ysMPP4zD4aBfv35kZGSwZMkSgoODadq0KQDPP/889erVIyoqir/97W9EREQwcuRIAB555BF69OjBCy+8wHXXXceyZct45513ePfddwFo1qwZo0eP5tZbb+Wtt96iU6dOJCUlkZqayrXXXuupty4ibqKgIyLVygsvvEBkZCQTJ05k165dhIaG0rVrV5566innpaOXX36ZBx98kO3bt9O5c2f+7//+D5vNBkDXrl35+uuvefrpp3nhhRdo0KABzz//PGPGjHG+xnvvvcdTTz3Fvffey5EjR2jSpAlPPfWUJ96uiLiZZl2JSI1ROiPq6NGjhIaGerocEakBNEZHREREai0FHREREam1dOlKREREai316IiIiEitpaAjIiIitZaCjoiIiNRaCjoiIiJSaynoiIiISK2loCMiIiK1loKOiIiI1FoKOiIiIlJrKeiIiIhIrfX/2NJutCGvlXgAAAAASUVORK5CYII="
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 18ms/step - loss: 1.3383\n",
            "EXPECTED:\n",
            "   d18O_cel_mean  d18O_cel_variance\n",
            "0      25.882000           0.233670\n",
            "1      25.654000           0.334480\n",
            "2      27.207456           1.041823\n",
            "3      25.163333           0.807832\n",
            "4      24.030630           0.579233\n",
            "5      26.040923           0.222859\n",
            "\n",
            "PREDICTED:\n",
            "   d18O_cel_mean  d18O_cel_variance\n",
            "0      25.313137           1.562158\n",
            "1      25.312395           1.559743\n",
            "2      26.195196           1.306455\n",
            "3      24.725636           0.186979\n",
            "4      24.725636           0.186979\n",
            "5      24.838568           0.214695\n",
            "   d18O_cel_mean  d18O_cel_variance\n",
            "0         23.682            0.53942\n",
            "1         22.850            0.80135\n",
            "2         24.782            0.19207\n",
            "3         26.202            0.11327\n",
            "4         25.882            0.23367\n",
            "[[25.27832    1.6189595]\n",
            " [25.281507   1.6255202]\n",
            " [25.282274   1.6262794]\n",
            " [25.312395   1.5597427]\n",
            " [25.313137   1.5621579]]\n",
            "RMSE: 0.7730068369992796\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2023-07-21 15:18:59.919062: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype double and shape [6,12]\n",
            "\t [[{{node Placeholder/_0}}]]\n",
            "2023-07-21 15:18:59.963905: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype double and shape [5,12]\n",
            "\t [[{{node Placeholder/_0}}]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4) Grouped, fixed"
      ],
      "metadata": {
        "id": "opmE3xc0vcY0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "grouped_fixed = {\n",
        "    'TRAIN': os.path.join(FP_ROOT, \"amazon_sample_data/uc_davis_2023_08_12_train_fixed_grouped.csv\"),\n",
        "    'TEST': os.path.join(FP_ROOT, \"amazon_sample_data/uc_davis_2023_08_12_test_fixed_grouped.csv\"),\n",
        "    'VALIDATION': os.path.join(FP_ROOT, \"amazon_sample_data/uc_davis_2023_08_12_validation_fixed_grouped.csv\"),\n",
        "}\n",
        "\n",
        "grouped_fixed_scaled = load_and_scale(grouped_fixed)\n",
        "train_and_evaluate(grouped_fixed_scaled, \"grouped_fixed\", training_batch_size=3)"
      ],
      "metadata": {
        "id": "KCebsA7XvfRH",
        "outputId": "cf6feba6-4e8d-4872-c75c-3f173f959982",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Epoch 990/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 9.4498 - val_loss: 5.5411\n",
            "Epoch 991/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 9.4333 - val_loss: 5.5380\n",
            "Epoch 992/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 9.4155 - val_loss: 5.5348\n",
            "Epoch 993/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 9.3964 - val_loss: 5.5327\n",
            "Epoch 994/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 9.3811 - val_loss: 5.5300\n",
            "Epoch 995/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 9.3639 - val_loss: 5.5288\n",
            "Epoch 996/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 9.3477 - val_loss: 5.5248\n",
            "Epoch 997/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 9.3308 - val_loss: 5.5233\n",
            "Epoch 998/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 9.3137 - val_loss: 5.5208\n",
            "Epoch 999/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 9.2969 - val_loss: 5.5185\n",
            "Epoch 1000/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 9.2818 - val_loss: 5.5145\n",
            "Epoch 1001/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 9.2642 - val_loss: 5.5127\n",
            "Epoch 1002/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 9.2483 - val_loss: 5.5090\n",
            "Epoch 1003/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 9.2314 - val_loss: 5.5061\n",
            "Epoch 1004/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 9.2160 - val_loss: 5.5031\n",
            "Epoch 1005/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 9.1998 - val_loss: 5.5004\n",
            "Epoch 1006/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 9.1842 - val_loss: 5.4998\n",
            "Epoch 1007/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 9.1667 - val_loss: 5.4981\n",
            "Epoch 1008/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 9.1532 - val_loss: 5.4939\n",
            "Epoch 1009/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 9.1346 - val_loss: 5.4915\n",
            "Epoch 1010/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 9.1213 - val_loss: 5.4905\n",
            "Epoch 1011/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 9.1076 - val_loss: 5.4848\n",
            "Epoch 1012/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 9.0895 - val_loss: 5.4813\n",
            "Epoch 1013/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 9.0723 - val_loss: 5.4786\n",
            "Epoch 1014/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 9.0566 - val_loss: 5.4773\n",
            "Epoch 1015/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 9.0425 - val_loss: 5.4736\n",
            "Epoch 1016/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 9.0254 - val_loss: 5.4708\n",
            "Epoch 1017/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 9.0108 - val_loss: 5.4680\n",
            "Epoch 1018/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 8.9960 - val_loss: 5.4671\n",
            "Epoch 1019/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 8.9816 - val_loss: 5.4618\n",
            "Epoch 1020/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 8.9656 - val_loss: 5.4580\n",
            "Epoch 1021/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 8.9496 - val_loss: 5.4562\n",
            "Epoch 1022/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 8.9351 - val_loss: 5.4537\n",
            "Epoch 1023/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 8.9186 - val_loss: 5.4520\n",
            "Epoch 1024/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 8.9050 - val_loss: 5.4498\n",
            "Epoch 1025/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 8.8886 - val_loss: 5.4476\n",
            "Epoch 1026/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 8.8750 - val_loss: 5.4441\n",
            "Epoch 1027/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 8.8596 - val_loss: 5.4430\n",
            "Epoch 1028/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 8.8444 - val_loss: 5.4398\n",
            "Epoch 1029/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 8.8299 - val_loss: 5.4377\n",
            "Epoch 1030/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 8.8160 - val_loss: 5.4353\n",
            "Epoch 1031/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 8.8010 - val_loss: 5.4314\n",
            "Epoch 1032/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 8.7858 - val_loss: 5.4302\n",
            "Epoch 1033/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 8.7712 - val_loss: 5.4281\n",
            "Epoch 1034/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 8.7557 - val_loss: 5.4243\n",
            "Epoch 1035/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 8.7428 - val_loss: 5.4224\n",
            "Epoch 1036/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 8.7277 - val_loss: 5.4191\n",
            "Epoch 1037/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 8.7126 - val_loss: 5.4165\n",
            "Epoch 1038/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 8.6982 - val_loss: 5.4137\n",
            "Epoch 1039/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 8.6859 - val_loss: 5.4128\n",
            "Epoch 1040/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 8.6698 - val_loss: 5.4078\n",
            "Epoch 1041/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 8.6563 - val_loss: 5.4055\n",
            "Epoch 1042/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 8.6405 - val_loss: 5.4019\n",
            "Epoch 1043/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 8.6272 - val_loss: 5.3998\n",
            "Epoch 1044/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 8.6122 - val_loss: 5.3974\n",
            "Epoch 1045/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 8.5985 - val_loss: 5.3952\n",
            "Epoch 1046/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 8.5839 - val_loss: 5.3926\n",
            "Epoch 1047/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 8.5713 - val_loss: 5.3900\n",
            "Epoch 1048/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 8.5567 - val_loss: 5.3868\n",
            "Epoch 1049/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 8.5431 - val_loss: 5.3836\n",
            "Epoch 1050/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 8.5305 - val_loss: 5.3818\n",
            "Epoch 1051/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 8.5160 - val_loss: 5.3796\n",
            "Epoch 1052/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 8.5032 - val_loss: 5.3759\n",
            "Epoch 1053/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 8.4913 - val_loss: 5.3754\n",
            "Epoch 1054/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 8.4750 - val_loss: 5.3726\n",
            "Epoch 1055/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 8.4622 - val_loss: 5.3711\n",
            "Epoch 1056/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 8.4474 - val_loss: 5.3685\n",
            "Epoch 1057/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 8.4359 - val_loss: 5.3650\n",
            "Epoch 1058/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 8.4213 - val_loss: 5.3621\n",
            "Epoch 1059/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 8.4089 - val_loss: 5.3584\n",
            "Epoch 1060/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 8.3948 - val_loss: 5.3561\n",
            "Epoch 1061/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 8.3828 - val_loss: 5.3528\n",
            "Epoch 1062/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 8.3688 - val_loss: 5.3522\n",
            "Epoch 1063/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 8.3556 - val_loss: 5.3490\n",
            "Epoch 1064/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 8.3432 - val_loss: 5.3456\n",
            "Epoch 1065/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 8.3303 - val_loss: 5.3427\n",
            "Epoch 1066/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 8.3182 - val_loss: 5.3418\n",
            "Epoch 1067/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 8.3041 - val_loss: 5.3382\n",
            "Epoch 1068/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 8.2917 - val_loss: 5.3369\n",
            "Epoch 1069/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 8.2787 - val_loss: 5.3354\n",
            "Epoch 1070/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 8.2653 - val_loss: 5.3332\n",
            "Epoch 1071/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 8.2537 - val_loss: 5.3294\n",
            "Epoch 1072/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 8.2406 - val_loss: 5.3273\n",
            "Epoch 1073/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 8.2272 - val_loss: 5.3242\n",
            "Epoch 1074/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 8.2150 - val_loss: 5.3222\n",
            "Epoch 1075/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 8.2011 - val_loss: 5.3196\n",
            "Epoch 1076/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 8.1885 - val_loss: 5.3167\n",
            "Epoch 1077/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 8.1754 - val_loss: 5.3151\n",
            "Epoch 1078/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 8.1652 - val_loss: 5.3136\n",
            "Epoch 1079/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 8.1495 - val_loss: 5.3128\n",
            "Epoch 1080/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 8.1380 - val_loss: 5.3078\n",
            "Epoch 1081/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 8.1244 - val_loss: 5.3045\n",
            "Epoch 1082/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 8.1118 - val_loss: 5.3032\n",
            "Epoch 1083/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 8.0997 - val_loss: 5.3000\n",
            "Epoch 1084/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 8.0863 - val_loss: 5.2980\n",
            "Epoch 1085/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 8.0739 - val_loss: 5.2960\n",
            "Epoch 1086/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 8.0614 - val_loss: 5.2926\n",
            "Epoch 1087/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 8.0490 - val_loss: 5.2909\n",
            "Epoch 1088/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 8.0360 - val_loss: 5.2893\n",
            "Epoch 1089/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 8.0236 - val_loss: 5.2866\n",
            "Epoch 1090/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 8.0129 - val_loss: 5.2842\n",
            "Epoch 1091/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 7.9992 - val_loss: 5.2820\n",
            "Epoch 1092/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 7.9877 - val_loss: 5.2795\n",
            "Epoch 1093/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 7.9749 - val_loss: 5.2784\n",
            "Epoch 1094/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 7.9628 - val_loss: 5.2750\n",
            "Epoch 1095/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 7.9515 - val_loss: 5.2714\n",
            "Epoch 1096/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 7.9394 - val_loss: 5.2694\n",
            "Epoch 1097/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 7.9273 - val_loss: 5.2676\n",
            "Epoch 1098/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 7.9145 - val_loss: 5.2662\n",
            "Epoch 1099/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 7.9042 - val_loss: 5.2639\n",
            "Epoch 1100/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 7.8932 - val_loss: 5.2624\n",
            "Epoch 1101/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 7.8805 - val_loss: 5.2580\n",
            "Epoch 1102/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 7.8680 - val_loss: 5.2550\n",
            "Epoch 1103/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 7.8567 - val_loss: 5.2539\n",
            "Epoch 1104/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 7.8470 - val_loss: 5.2505\n",
            "Epoch 1105/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 7.8358 - val_loss: 5.2488\n",
            "Epoch 1106/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 7.8233 - val_loss: 5.2486\n",
            "Epoch 1107/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 7.8124 - val_loss: 5.2441\n",
            "Epoch 1108/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 7.8004 - val_loss: 5.2413\n",
            "Epoch 1109/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 7.7891 - val_loss: 5.2396\n",
            "Epoch 1110/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 7.7768 - val_loss: 5.2369\n",
            "Epoch 1111/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 7.7658 - val_loss: 5.2354\n",
            "Epoch 1112/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 7.7547 - val_loss: 5.2346\n",
            "Epoch 1113/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 7.7442 - val_loss: 5.2325\n",
            "Epoch 1114/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 7.7319 - val_loss: 5.2304\n",
            "Epoch 1115/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 7.7216 - val_loss: 5.2300\n",
            "Epoch 1116/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 7.7095 - val_loss: 5.2279\n",
            "Epoch 1117/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 7.6983 - val_loss: 5.2247\n",
            "Epoch 1118/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 7.6878 - val_loss: 5.2238\n",
            "Epoch 1119/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 7.6771 - val_loss: 5.2213\n",
            "Epoch 1120/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 7.6663 - val_loss: 5.2187\n",
            "Epoch 1121/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 7.6542 - val_loss: 5.2178\n",
            "Epoch 1122/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 7.6432 - val_loss: 5.2163\n",
            "Epoch 1123/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 7.6321 - val_loss: 5.2138\n",
            "Epoch 1124/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 7.6215 - val_loss: 5.2119\n",
            "Epoch 1125/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 7.6101 - val_loss: 5.2101\n",
            "Epoch 1126/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 7.5990 - val_loss: 5.2076\n",
            "Epoch 1127/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 7.5876 - val_loss: 5.2067\n",
            "Epoch 1128/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 7.5768 - val_loss: 5.2058\n",
            "Epoch 1129/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 7.5661 - val_loss: 5.2037\n",
            "Epoch 1130/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 7.5557 - val_loss: 5.2017\n",
            "Epoch 1131/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 7.5457 - val_loss: 5.1988\n",
            "Epoch 1132/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 7.5336 - val_loss: 5.1968\n",
            "Epoch 1133/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 7.5227 - val_loss: 5.1957\n",
            "Epoch 1134/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 7.5130 - val_loss: 5.1944\n",
            "Epoch 1135/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 7.5024 - val_loss: 5.1911\n",
            "Epoch 1136/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 7.4903 - val_loss: 5.1890\n",
            "Epoch 1137/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 7.4798 - val_loss: 5.1874\n",
            "Epoch 1138/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 7.4689 - val_loss: 5.1854\n",
            "Epoch 1139/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 7.4577 - val_loss: 5.1839\n",
            "Epoch 1140/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 7.4477 - val_loss: 5.1822\n",
            "Epoch 1141/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 7.4378 - val_loss: 5.1804\n",
            "Epoch 1142/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 7.4265 - val_loss: 5.1794\n",
            "Epoch 1143/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 7.4170 - val_loss: 5.1761\n",
            "Epoch 1144/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 7.4054 - val_loss: 5.1741\n",
            "Epoch 1145/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 7.3949 - val_loss: 5.1720\n",
            "Epoch 1146/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 7.3842 - val_loss: 5.1710\n",
            "Epoch 1147/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 7.3747 - val_loss: 5.1678\n",
            "Epoch 1148/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 7.3661 - val_loss: 5.1672\n",
            "Epoch 1149/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 7.3536 - val_loss: 5.1651\n",
            "Epoch 1150/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 7.3419 - val_loss: 5.1628\n",
            "Epoch 1151/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 7.3325 - val_loss: 5.1602\n",
            "Epoch 1152/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 7.3213 - val_loss: 5.1580\n",
            "Epoch 1153/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 7.3117 - val_loss: 5.1570\n",
            "Epoch 1154/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 7.3005 - val_loss: 5.1555\n",
            "Epoch 1155/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 7.2910 - val_loss: 5.1523\n",
            "Epoch 1156/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 7.2804 - val_loss: 5.1501\n",
            "Epoch 1157/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 7.2701 - val_loss: 5.1482\n",
            "Epoch 1158/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 7.2601 - val_loss: 5.1476\n",
            "Epoch 1159/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 7.2495 - val_loss: 5.1472\n",
            "Epoch 1160/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 7.2389 - val_loss: 5.1436\n",
            "Epoch 1161/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 7.2291 - val_loss: 5.1407\n",
            "Epoch 1162/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 7.2178 - val_loss: 5.1382\n",
            "Epoch 1163/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 7.2092 - val_loss: 5.1368\n",
            "Epoch 1164/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 7.1975 - val_loss: 5.1349\n",
            "Epoch 1165/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 7.1881 - val_loss: 5.1325\n",
            "Epoch 1166/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 7.1765 - val_loss: 5.1324\n",
            "Epoch 1167/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 7.1671 - val_loss: 5.1290\n",
            "Epoch 1168/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 7.1558 - val_loss: 5.1270\n",
            "Epoch 1169/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 7.1470 - val_loss: 5.1267\n",
            "Epoch 1170/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 7.1360 - val_loss: 5.1241\n",
            "Epoch 1171/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 7.1265 - val_loss: 5.1218\n",
            "Epoch 1172/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 7.1155 - val_loss: 5.1196\n",
            "Epoch 1173/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 7.1078 - val_loss: 5.1189\n",
            "Epoch 1174/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 7.0960 - val_loss: 5.1165\n",
            "Epoch 1175/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 7.0855 - val_loss: 5.1152\n",
            "Epoch 1176/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 7.0757 - val_loss: 5.1135\n",
            "Epoch 1177/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 7.0658 - val_loss: 5.1109\n",
            "Epoch 1178/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 7.0557 - val_loss: 5.1104\n",
            "Epoch 1179/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 7.0461 - val_loss: 5.1080\n",
            "Epoch 1180/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 7.0366 - val_loss: 5.1058\n",
            "Epoch 1181/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 7.0258 - val_loss: 5.1043\n",
            "Epoch 1182/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 7.0164 - val_loss: 5.1026\n",
            "Epoch 1183/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 7.0068 - val_loss: 5.1003\n",
            "Epoch 1184/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 6.9969 - val_loss: 5.0987\n",
            "Epoch 1185/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 6.9881 - val_loss: 5.0981\n",
            "Epoch 1186/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 6.9775 - val_loss: 5.0967\n",
            "Epoch 1187/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 6.9669 - val_loss: 5.0944\n",
            "Epoch 1188/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 6.9586 - val_loss: 5.0929\n",
            "Epoch 1189/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 6.9482 - val_loss: 5.0902\n",
            "Epoch 1190/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 6.9388 - val_loss: 5.0874\n",
            "Epoch 1191/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 6.9291 - val_loss: 5.0860\n",
            "Epoch 1192/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 6.9189 - val_loss: 5.0843\n",
            "Epoch 1193/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 6.9104 - val_loss: 5.0817\n",
            "Epoch 1194/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 6.9007 - val_loss: 5.0815\n",
            "Epoch 1195/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 6.8909 - val_loss: 5.0796\n",
            "Epoch 1196/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 6.8818 - val_loss: 5.0776\n",
            "Epoch 1197/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 6.8711 - val_loss: 5.0761\n",
            "Epoch 1198/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 6.8615 - val_loss: 5.0752\n",
            "Epoch 1199/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 6.8525 - val_loss: 5.0727\n",
            "Epoch 1200/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 6.8427 - val_loss: 5.0718\n",
            "Epoch 1201/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 6.8336 - val_loss: 5.0699\n",
            "Epoch 1202/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 6.8245 - val_loss: 5.0681\n",
            "Epoch 1203/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 6.8142 - val_loss: 5.0665\n",
            "Epoch 1204/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 6.8057 - val_loss: 5.0636\n",
            "Epoch 1205/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 6.7954 - val_loss: 5.0622\n",
            "Epoch 1206/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 6.7863 - val_loss: 5.0602\n",
            "Epoch 1207/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 6.7771 - val_loss: 5.0589\n",
            "Epoch 1208/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 6.7672 - val_loss: 5.0579\n",
            "Epoch 1209/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 6.7575 - val_loss: 5.0574\n",
            "Epoch 1210/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 6.7480 - val_loss: 5.0557\n",
            "Epoch 1211/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 6.7396 - val_loss: 5.0527\n",
            "Epoch 1212/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 6.7306 - val_loss: 5.0516\n",
            "Epoch 1213/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 6.7190 - val_loss: 5.0506\n",
            "Epoch 1214/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 6.7111 - val_loss: 5.0486\n",
            "Epoch 1215/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 6.7019 - val_loss: 5.0468\n",
            "Epoch 1216/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 6.6928 - val_loss: 5.0462\n",
            "Epoch 1217/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 6.6835 - val_loss: 5.0436\n",
            "Epoch 1218/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 6.6754 - val_loss: 5.0429\n",
            "Epoch 1219/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 6.6648 - val_loss: 5.0401\n",
            "Epoch 1220/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 6.6549 - val_loss: 5.0378\n",
            "Epoch 1221/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 6.6473 - val_loss: 5.0349\n",
            "Epoch 1222/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 6.6381 - val_loss: 5.0339\n",
            "Epoch 1223/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 6.6286 - val_loss: 5.0335\n",
            "Epoch 1224/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 6.6214 - val_loss: 5.0296\n",
            "Epoch 1225/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 6.6109 - val_loss: 5.0277\n",
            "Epoch 1226/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 6.6010 - val_loss: 5.0257\n",
            "Epoch 1227/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 6.5928 - val_loss: 5.0246\n",
            "Epoch 1228/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 6.5829 - val_loss: 5.0231\n",
            "Epoch 1229/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 6.5738 - val_loss: 5.0219\n",
            "Epoch 1230/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 6.5646 - val_loss: 5.0209\n",
            "Epoch 1231/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 6.5562 - val_loss: 5.0196\n",
            "Epoch 1232/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 6.5488 - val_loss: 5.0156\n",
            "Epoch 1233/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 6.5392 - val_loss: 5.0136\n",
            "Epoch 1234/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 6.5300 - val_loss: 5.0126\n",
            "Epoch 1235/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 6.5197 - val_loss: 5.0110\n",
            "Epoch 1236/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 6.5123 - val_loss: 5.0102\n",
            "Epoch 1237/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 6.5024 - val_loss: 5.0073\n",
            "Epoch 1238/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 6.4940 - val_loss: 5.0051\n",
            "Epoch 1239/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 6.4858 - val_loss: 5.0028\n",
            "Epoch 1240/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 6.4768 - val_loss: 5.0005\n",
            "Epoch 1241/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 6.4673 - val_loss: 4.9990\n",
            "Epoch 1242/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 6.4598 - val_loss: 4.9985\n",
            "Epoch 1243/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 6.4511 - val_loss: 4.9976\n",
            "Epoch 1244/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 6.4410 - val_loss: 4.9951\n",
            "Epoch 1245/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 6.4325 - val_loss: 4.9934\n",
            "Epoch 1246/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 6.4238 - val_loss: 4.9918\n",
            "Epoch 1247/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 6.4158 - val_loss: 4.9912\n",
            "Epoch 1248/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 6.4072 - val_loss: 4.9896\n",
            "Epoch 1249/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 6.3989 - val_loss: 4.9881\n",
            "Epoch 1250/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 6.3898 - val_loss: 4.9864\n",
            "Epoch 1251/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 6.3816 - val_loss: 4.9861\n",
            "Epoch 1252/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 6.3720 - val_loss: 4.9850\n",
            "Epoch 1253/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 6.3645 - val_loss: 4.9820\n",
            "Epoch 1254/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 6.3565 - val_loss: 4.9821\n",
            "Epoch 1255/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 6.3483 - val_loss: 4.9793\n",
            "Epoch 1256/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 6.3385 - val_loss: 4.9786\n",
            "Epoch 1257/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 6.3305 - val_loss: 4.9772\n",
            "Epoch 1258/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 6.3225 - val_loss: 4.9753\n",
            "Epoch 1259/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 6.3138 - val_loss: 4.9737\n",
            "Epoch 1260/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 6.3055 - val_loss: 4.9728\n",
            "Epoch 1261/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 6.2977 - val_loss: 4.9724\n",
            "Epoch 1262/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 6.2899 - val_loss: 4.9713\n",
            "Epoch 1263/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 6.2811 - val_loss: 4.9697\n",
            "Epoch 1264/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 6.2727 - val_loss: 4.9678\n",
            "Epoch 1265/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 6.2645 - val_loss: 4.9668\n",
            "Epoch 1266/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 6.2566 - val_loss: 4.9657\n",
            "Epoch 1267/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 6.2478 - val_loss: 4.9626\n",
            "Epoch 1268/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 6.2399 - val_loss: 4.9607\n",
            "Epoch 1269/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 6.2321 - val_loss: 4.9582\n",
            "Epoch 1270/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 6.2232 - val_loss: 4.9568\n",
            "Epoch 1271/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 6.2156 - val_loss: 4.9552\n",
            "Epoch 1272/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 6.2065 - val_loss: 4.9545\n",
            "Epoch 1273/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 6.1987 - val_loss: 4.9522\n",
            "Epoch 1274/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 6.1907 - val_loss: 4.9514\n",
            "Epoch 1275/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 6.1815 - val_loss: 4.9499\n",
            "Epoch 1276/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 6.1741 - val_loss: 4.9478\n",
            "Epoch 1277/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 6.1666 - val_loss: 4.9482\n",
            "Epoch 1278/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 6.1579 - val_loss: 4.9450\n",
            "Epoch 1279/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 6.1497 - val_loss: 4.9431\n",
            "Epoch 1280/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 6.1412 - val_loss: 4.9413\n",
            "Epoch 1281/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 6.1334 - val_loss: 4.9408\n",
            "Epoch 1282/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 6.1252 - val_loss: 4.9385\n",
            "Epoch 1283/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 6.1174 - val_loss: 4.9386\n",
            "Epoch 1284/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 6.1095 - val_loss: 4.9368\n",
            "Epoch 1285/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 6.1021 - val_loss: 4.9330\n",
            "Epoch 1286/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 6.0925 - val_loss: 4.9321\n",
            "Epoch 1287/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 6.0849 - val_loss: 4.9301\n",
            "Epoch 1288/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 6.0764 - val_loss: 4.9290\n",
            "Epoch 1289/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 6.0689 - val_loss: 4.9282\n",
            "Epoch 1290/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 6.0602 - val_loss: 4.9270\n",
            "Epoch 1291/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 6.0520 - val_loss: 4.9249\n",
            "Epoch 1292/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 6.0440 - val_loss: 4.9233\n",
            "Epoch 1293/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 6.0373 - val_loss: 4.9222\n",
            "Epoch 1294/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 6.0286 - val_loss: 4.9206\n",
            "Epoch 1295/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 6.0204 - val_loss: 4.9195\n",
            "Epoch 1296/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 6.0132 - val_loss: 4.9183\n",
            "Epoch 1297/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 6.0053 - val_loss: 4.9167\n",
            "Epoch 1298/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 5.9973 - val_loss: 4.9155\n",
            "Epoch 1299/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 5.9901 - val_loss: 4.9135\n",
            "Epoch 1300/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 5.9818 - val_loss: 4.9130\n",
            "Epoch 1301/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 5.9736 - val_loss: 4.9122\n",
            "Epoch 1302/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 5.9674 - val_loss: 4.9100\n",
            "Epoch 1303/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 5.9585 - val_loss: 4.9090\n",
            "Epoch 1304/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 5.9513 - val_loss: 4.9060\n",
            "Epoch 1305/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 5.9426 - val_loss: 4.9047\n",
            "Epoch 1306/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 5.9358 - val_loss: 4.9027\n",
            "Epoch 1307/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 5.9278 - val_loss: 4.9013\n",
            "Epoch 1308/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 5.9202 - val_loss: 4.8993\n",
            "Epoch 1309/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 5.9124 - val_loss: 4.8993\n",
            "Epoch 1310/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 5.9050 - val_loss: 4.8962\n",
            "Epoch 1311/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 5.8972 - val_loss: 4.8937\n",
            "Epoch 1312/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 5.8902 - val_loss: 4.8926\n",
            "Epoch 1313/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 5.8812 - val_loss: 4.8905\n",
            "Epoch 1314/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 5.8745 - val_loss: 4.8889\n",
            "Epoch 1315/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 5.8658 - val_loss: 4.8868\n",
            "Epoch 1316/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 5.8588 - val_loss: 4.8869\n",
            "Epoch 1317/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 5.8515 - val_loss: 4.8854\n",
            "Epoch 1318/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 5.8442 - val_loss: 4.8837\n",
            "Epoch 1319/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 5.8359 - val_loss: 4.8814\n",
            "Epoch 1320/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 5.8290 - val_loss: 4.8803\n",
            "Epoch 1321/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 5.8206 - val_loss: 4.8792\n",
            "Epoch 1322/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 5.8138 - val_loss: 4.8769\n",
            "Epoch 1323/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 5.8065 - val_loss: 4.8749\n",
            "Epoch 1324/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 5.7983 - val_loss: 4.8734\n",
            "Epoch 1325/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 5.7923 - val_loss: 4.8721\n",
            "Epoch 1326/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 5.7832 - val_loss: 4.8709\n",
            "Epoch 1327/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 5.7759 - val_loss: 4.8703\n",
            "Epoch 1328/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 5.7682 - val_loss: 4.8683\n",
            "Epoch 1329/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 5.7610 - val_loss: 4.8657\n",
            "Epoch 1330/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 5.7537 - val_loss: 4.8643\n",
            "Epoch 1331/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 5.7465 - val_loss: 4.8625\n",
            "Epoch 1332/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 5.7388 - val_loss: 4.8611\n",
            "Epoch 1333/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 5.7314 - val_loss: 4.8608\n",
            "Epoch 1334/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 5.7236 - val_loss: 4.8575\n",
            "Epoch 1335/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 5.7176 - val_loss: 4.8551\n",
            "Epoch 1336/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 5.7101 - val_loss: 4.8547\n",
            "Epoch 1337/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 5.7007 - val_loss: 4.8534\n",
            "Epoch 1338/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 5.6948 - val_loss: 4.8513\n",
            "Epoch 1339/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 5.6869 - val_loss: 4.8489\n",
            "Epoch 1340/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 5.6792 - val_loss: 4.8473\n",
            "Epoch 1341/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 5.6717 - val_loss: 4.8464\n",
            "Epoch 1342/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 5.6648 - val_loss: 4.8446\n",
            "Epoch 1343/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 5.6576 - val_loss: 4.8440\n",
            "Epoch 1344/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 5.6510 - val_loss: 4.8405\n",
            "Epoch 1345/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 5.6429 - val_loss: 4.8386\n",
            "Epoch 1346/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 5.6348 - val_loss: 4.8378\n",
            "Epoch 1347/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 5.6284 - val_loss: 4.8349\n",
            "Epoch 1348/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 5.6204 - val_loss: 4.8333\n",
            "Epoch 1349/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 5.6133 - val_loss: 4.8317\n",
            "Epoch 1350/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 5.6062 - val_loss: 4.8300\n",
            "Epoch 1351/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 5.5986 - val_loss: 4.8286\n",
            "Epoch 1352/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 5.5926 - val_loss: 4.8280\n",
            "Epoch 1353/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 5.5837 - val_loss: 4.8268\n",
            "Epoch 1354/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 5.5772 - val_loss: 4.8255\n",
            "Epoch 1355/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 5.5698 - val_loss: 4.8237\n",
            "Epoch 1356/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 5.5622 - val_loss: 4.8225\n",
            "Epoch 1357/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 5.5553 - val_loss: 4.8212\n",
            "Epoch 1358/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 5.5491 - val_loss: 4.8186\n",
            "Epoch 1359/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 5.5412 - val_loss: 4.8177\n",
            "Epoch 1360/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 5.5343 - val_loss: 4.8160\n",
            "Epoch 1361/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 5.5263 - val_loss: 4.8149\n",
            "Epoch 1362/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 5.5197 - val_loss: 4.8132\n",
            "Epoch 1363/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 5.5134 - val_loss: 4.8107\n",
            "Epoch 1364/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 5.5064 - val_loss: 4.8094\n",
            "Epoch 1365/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 5.4986 - val_loss: 4.8077\n",
            "Epoch 1366/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 5.4912 - val_loss: 4.8058\n",
            "Epoch 1367/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 5.4844 - val_loss: 4.8057\n",
            "Epoch 1368/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 5.4769 - val_loss: 4.8027\n",
            "Epoch 1369/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 5.4700 - val_loss: 4.8008\n",
            "Epoch 1370/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 5.4631 - val_loss: 4.7991\n",
            "Epoch 1371/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 5.4555 - val_loss: 4.7977\n",
            "Epoch 1372/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 5.4484 - val_loss: 4.7964\n",
            "Epoch 1373/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 5.4415 - val_loss: 4.7957\n",
            "Epoch 1374/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 5.4351 - val_loss: 4.7944\n",
            "Epoch 1375/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 5.4273 - val_loss: 4.7930\n",
            "Epoch 1376/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 5.4206 - val_loss: 4.7919\n",
            "Epoch 1377/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 5.4131 - val_loss: 4.7905\n",
            "Epoch 1378/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 5.4063 - val_loss: 4.7890\n",
            "Epoch 1379/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 5.3998 - val_loss: 4.7878\n",
            "Epoch 1380/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 5.3918 - val_loss: 4.7858\n",
            "Epoch 1381/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 5.3864 - val_loss: 4.7830\n",
            "Epoch 1382/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 5.3791 - val_loss: 4.7826\n",
            "Epoch 1383/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 5.3718 - val_loss: 4.7809\n",
            "Epoch 1384/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 5.3644 - val_loss: 4.7796\n",
            "Epoch 1385/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 5.3585 - val_loss: 4.7774\n",
            "Epoch 1386/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 5.3508 - val_loss: 4.7770\n",
            "Epoch 1387/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 5.3445 - val_loss: 4.7753\n",
            "Epoch 1388/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 5.3380 - val_loss: 4.7750\n",
            "Epoch 1389/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 5.3306 - val_loss: 4.7743\n",
            "Epoch 1390/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 5.3245 - val_loss: 4.7726\n",
            "Epoch 1391/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 5.3174 - val_loss: 4.7709\n",
            "Epoch 1392/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 5.3115 - val_loss: 4.7708\n",
            "Epoch 1393/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 5.3037 - val_loss: 4.7690\n",
            "Epoch 1394/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 5.2976 - val_loss: 4.7665\n",
            "Epoch 1395/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 5.2900 - val_loss: 4.7651\n",
            "Epoch 1396/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 5.2840 - val_loss: 4.7637\n",
            "Epoch 1397/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 5.2765 - val_loss: 4.7632\n",
            "Epoch 1398/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 5.2703 - val_loss: 4.7616\n",
            "Epoch 1399/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 5.2637 - val_loss: 4.7605\n",
            "Epoch 1400/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 5.2564 - val_loss: 4.7594\n",
            "Epoch 1401/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 5.2501 - val_loss: 4.7574\n",
            "Epoch 1402/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 5.2434 - val_loss: 4.7560\n",
            "Epoch 1403/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 5.2358 - val_loss: 4.7550\n",
            "Epoch 1404/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 5.2301 - val_loss: 4.7541\n",
            "Epoch 1405/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 5.2230 - val_loss: 4.7527\n",
            "Epoch 1406/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 5.2169 - val_loss: 4.7515\n",
            "Epoch 1407/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 5.2100 - val_loss: 4.7507\n",
            "Epoch 1408/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 5.2038 - val_loss: 4.7500\n",
            "Epoch 1409/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 5.1965 - val_loss: 4.7470\n",
            "Epoch 1410/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 5.1905 - val_loss: 4.7447\n",
            "Epoch 1411/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 5.1830 - val_loss: 4.7434\n",
            "Epoch 1412/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 5.1776 - val_loss: 4.7434\n",
            "Epoch 1413/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 5.1692 - val_loss: 4.7419\n",
            "Epoch 1414/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 5.1625 - val_loss: 4.7394\n",
            "Epoch 1415/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 5.1568 - val_loss: 4.7374\n",
            "Epoch 1416/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 5.1493 - val_loss: 4.7355\n",
            "Epoch 1417/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 5.1440 - val_loss: 4.7347\n",
            "Epoch 1418/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 5.1372 - val_loss: 4.7325\n",
            "Epoch 1419/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 5.1306 - val_loss: 4.7315\n",
            "Epoch 1420/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 5.1248 - val_loss: 4.7309\n",
            "Epoch 1421/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 5.1171 - val_loss: 4.7289\n",
            "Epoch 1422/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 5.1109 - val_loss: 4.7274\n",
            "Epoch 1423/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 5.1048 - val_loss: 4.7257\n",
            "Epoch 1424/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 5.0976 - val_loss: 4.7241\n",
            "Epoch 1425/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 5.0916 - val_loss: 4.7227\n",
            "Epoch 1426/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 5.0854 - val_loss: 4.7216\n",
            "Epoch 1427/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 5.0790 - val_loss: 4.7211\n",
            "Epoch 1428/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 5.0731 - val_loss: 4.7200\n",
            "Epoch 1429/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 5.0669 - val_loss: 4.7192\n",
            "Epoch 1430/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 5.0613 - val_loss: 4.7188\n",
            "Epoch 1431/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 5.0549 - val_loss: 4.7185\n",
            "Epoch 1432/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 5.0489 - val_loss: 4.7167\n",
            "Epoch 1433/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 5.0433 - val_loss: 4.7159\n",
            "Epoch 1434/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 5.0370 - val_loss: 4.7141\n",
            "Epoch 1435/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 5.0311 - val_loss: 4.7123\n",
            "Epoch 1436/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 5.0253 - val_loss: 4.7115\n",
            "Epoch 1437/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 5.0194 - val_loss: 4.7110\n",
            "Epoch 1438/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 5.0133 - val_loss: 4.7104\n",
            "Epoch 1439/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 5.0076 - val_loss: 4.7090\n",
            "Epoch 1440/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 5.0013 - val_loss: 4.7079\n",
            "Epoch 1441/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.9963 - val_loss: 4.7075\n",
            "Epoch 1442/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.9897 - val_loss: 4.7072\n",
            "Epoch 1443/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.9840 - val_loss: 4.7060\n",
            "Epoch 1444/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 4.9779 - val_loss: 4.7047\n",
            "Epoch 1445/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.9719 - val_loss: 4.7036\n",
            "Epoch 1446/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.9677 - val_loss: 4.7034\n",
            "Epoch 1447/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.9608 - val_loss: 4.7020\n",
            "Epoch 1448/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.9543 - val_loss: 4.7005\n",
            "Epoch 1449/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 4.9485 - val_loss: 4.6991\n",
            "Epoch 1450/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.9428 - val_loss: 4.6985\n",
            "Epoch 1451/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.9367 - val_loss: 4.6978\n",
            "Epoch 1452/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 4.9315 - val_loss: 4.6958\n",
            "Epoch 1453/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.9256 - val_loss: 4.6956\n",
            "Epoch 1454/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.9193 - val_loss: 4.6940\n",
            "Epoch 1455/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.9133 - val_loss: 4.6926\n",
            "Epoch 1456/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 4.9077 - val_loss: 4.6908\n",
            "Epoch 1457/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.9018 - val_loss: 4.6903\n",
            "Epoch 1458/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.8961 - val_loss: 4.6902\n",
            "Epoch 1459/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.8914 - val_loss: 4.6882\n",
            "Epoch 1460/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.8854 - val_loss: 4.6870\n",
            "Epoch 1461/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.8792 - val_loss: 4.6863\n",
            "Epoch 1462/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.8734 - val_loss: 4.6855\n",
            "Epoch 1463/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 4.8681 - val_loss: 4.6835\n",
            "Epoch 1464/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.8620 - val_loss: 4.6825\n",
            "Epoch 1465/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.8564 - val_loss: 4.6822\n",
            "Epoch 1466/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.8508 - val_loss: 4.6806\n",
            "Epoch 1467/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.8460 - val_loss: 4.6796\n",
            "Epoch 1468/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 4.8392 - val_loss: 4.6792\n",
            "Epoch 1469/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.8342 - val_loss: 4.6786\n",
            "Epoch 1470/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.8279 - val_loss: 4.6774\n",
            "Epoch 1471/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.8233 - val_loss: 4.6766\n",
            "Epoch 1472/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.8173 - val_loss: 4.6758\n",
            "Epoch 1473/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.8117 - val_loss: 4.6739\n",
            "Epoch 1474/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.8061 - val_loss: 4.6736\n",
            "Epoch 1475/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 4.8006 - val_loss: 4.6723\n",
            "Epoch 1476/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.7952 - val_loss: 4.6713\n",
            "Epoch 1477/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.7890 - val_loss: 4.6710\n",
            "Epoch 1478/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.7840 - val_loss: 4.6700\n",
            "Epoch 1479/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.7781 - val_loss: 4.6689\n",
            "Epoch 1480/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.7721 - val_loss: 4.6679\n",
            "Epoch 1481/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.7673 - val_loss: 4.6664\n",
            "Epoch 1482/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.7617 - val_loss: 4.6657\n",
            "Epoch 1483/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.7565 - val_loss: 4.6642\n",
            "Epoch 1484/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.7504 - val_loss: 4.6630\n",
            "Epoch 1485/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.7456 - val_loss: 4.6625\n",
            "Epoch 1486/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.7394 - val_loss: 4.6617\n",
            "Epoch 1487/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.7340 - val_loss: 4.6602\n",
            "Epoch 1488/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.7289 - val_loss: 4.6599\n",
            "Epoch 1489/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.7234 - val_loss: 4.6593\n",
            "Epoch 1490/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.7175 - val_loss: 4.6577\n",
            "Epoch 1491/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 4.7122 - val_loss: 4.6563\n",
            "Epoch 1492/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.7067 - val_loss: 4.6553\n",
            "Epoch 1493/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 4.7015 - val_loss: 4.6544\n",
            "Epoch 1494/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.6963 - val_loss: 4.6533\n",
            "Epoch 1495/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.6903 - val_loss: 4.6525\n",
            "Epoch 1496/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 4.6855 - val_loss: 4.6519\n",
            "Epoch 1497/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 4.6797 - val_loss: 4.6513\n",
            "Epoch 1498/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.6743 - val_loss: 4.6503\n",
            "Epoch 1499/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.6690 - val_loss: 4.6491\n",
            "Epoch 1500/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.6631 - val_loss: 4.6485\n",
            "Epoch 1501/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.6581 - val_loss: 4.6481\n",
            "Epoch 1502/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.6530 - val_loss: 4.6465\n",
            "Epoch 1503/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.6473 - val_loss: 4.6447\n",
            "Epoch 1504/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.6423 - val_loss: 4.6443\n",
            "Epoch 1505/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 4.6368 - val_loss: 4.6421\n",
            "Epoch 1506/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.6304 - val_loss: 4.6410\n",
            "Epoch 1507/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 4.6262 - val_loss: 4.6399\n",
            "Epoch 1508/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 4.6207 - val_loss: 4.6377\n",
            "Epoch 1509/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.6149 - val_loss: 4.6362\n",
            "Epoch 1510/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.6093 - val_loss: 4.6348\n",
            "Epoch 1511/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.6039 - val_loss: 4.6330\n",
            "Epoch 1512/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.5983 - val_loss: 4.6324\n",
            "Epoch 1513/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 4.5933 - val_loss: 4.6312\n",
            "Epoch 1514/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.5879 - val_loss: 4.6304\n",
            "Epoch 1515/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.5819 - val_loss: 4.6290\n",
            "Epoch 1516/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 4.5767 - val_loss: 4.6281\n",
            "Epoch 1517/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 4.5713 - val_loss: 4.6274\n",
            "Epoch 1518/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.5663 - val_loss: 4.6263\n",
            "Epoch 1519/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.5605 - val_loss: 4.6254\n",
            "Epoch 1520/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.5554 - val_loss: 4.6232\n",
            "Epoch 1521/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.5500 - val_loss: 4.6219\n",
            "Epoch 1522/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.5449 - val_loss: 4.6205\n",
            "Epoch 1523/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.5394 - val_loss: 4.6198\n",
            "Epoch 1524/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.5344 - val_loss: 4.6186\n",
            "Epoch 1525/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 4.5291 - val_loss: 4.6174\n",
            "Epoch 1526/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 4.5233 - val_loss: 4.6168\n",
            "Epoch 1527/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.5183 - val_loss: 4.6163\n",
            "Epoch 1528/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 4.5136 - val_loss: 4.6142\n",
            "Epoch 1529/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.5084 - val_loss: 4.6126\n",
            "Epoch 1530/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.5032 - val_loss: 4.6120\n",
            "Epoch 1531/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.4979 - val_loss: 4.6109\n",
            "Epoch 1532/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.4928 - val_loss: 4.6098\n",
            "Epoch 1533/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 4.4878 - val_loss: 4.6079\n",
            "Epoch 1534/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.4823 - val_loss: 4.6062\n",
            "Epoch 1535/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.4773 - val_loss: 4.6058\n",
            "Epoch 1536/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.4725 - val_loss: 4.6044\n",
            "Epoch 1537/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.4668 - val_loss: 4.6033\n",
            "Epoch 1538/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.4623 - val_loss: 4.6024\n",
            "Epoch 1539/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 4.4562 - val_loss: 4.6008\n",
            "Epoch 1540/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.4518 - val_loss: 4.6001\n",
            "Epoch 1541/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.4466 - val_loss: 4.5991\n",
            "Epoch 1542/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.4419 - val_loss: 4.5976\n",
            "Epoch 1543/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.4366 - val_loss: 4.5958\n",
            "Epoch 1544/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.4310 - val_loss: 4.5951\n",
            "Epoch 1545/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 4.4261 - val_loss: 4.5939\n",
            "Epoch 1546/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 4.4215 - val_loss: 4.5922\n",
            "Epoch 1547/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.4160 - val_loss: 4.5906\n",
            "Epoch 1548/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 4.4109 - val_loss: 4.5900\n",
            "Epoch 1549/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 4.4061 - val_loss: 4.5890\n",
            "Epoch 1550/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 4.4008 - val_loss: 4.5890\n",
            "Epoch 1551/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 4.3952 - val_loss: 4.5873\n",
            "Epoch 1552/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.3914 - val_loss: 4.5845\n",
            "Epoch 1553/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.3853 - val_loss: 4.5830\n",
            "Epoch 1554/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.3801 - val_loss: 4.5825\n",
            "Epoch 1555/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.3755 - val_loss: 4.5810\n",
            "Epoch 1556/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.3700 - val_loss: 4.5797\n",
            "Epoch 1557/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.3611 - val_loss: 4.5775\n",
            "Epoch 1558/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.3531 - val_loss: 4.5769\n",
            "Epoch 1559/5000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 4.3449 - val_loss: 4.5752\n",
            "Epoch 1560/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.3361 - val_loss: 4.5744\n",
            "Epoch 1561/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.3286 - val_loss: 4.5725\n",
            "Epoch 1562/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.3217 - val_loss: 4.5691\n",
            "Epoch 1563/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 4.3144 - val_loss: 4.5671\n",
            "Epoch 1564/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.3065 - val_loss: 4.5657\n",
            "Epoch 1565/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.2992 - val_loss: 4.5646\n",
            "Epoch 1566/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.2931 - val_loss: 4.5628\n",
            "Epoch 1567/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 4.2866 - val_loss: 4.5612\n",
            "Epoch 1568/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.2795 - val_loss: 4.5603\n",
            "Epoch 1569/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 4.2731 - val_loss: 4.5583\n",
            "Epoch 1570/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.2657 - val_loss: 4.5577\n",
            "Epoch 1571/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.2603 - val_loss: 4.5549\n",
            "Epoch 1572/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.2526 - val_loss: 4.5534\n",
            "Epoch 1573/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.2461 - val_loss: 4.5520\n",
            "Epoch 1574/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.2394 - val_loss: 4.5507\n",
            "Epoch 1575/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.2321 - val_loss: 4.5504\n",
            "Epoch 1576/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.2262 - val_loss: 4.5470\n",
            "Epoch 1577/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 4.2195 - val_loss: 4.5457\n",
            "Epoch 1578/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.2127 - val_loss: 4.5449\n",
            "Epoch 1579/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.2068 - val_loss: 4.5436\n",
            "Epoch 1580/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.2005 - val_loss: 4.5408\n",
            "Epoch 1581/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.1940 - val_loss: 4.5385\n",
            "Epoch 1582/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.1878 - val_loss: 4.5379\n",
            "Epoch 1583/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.1816 - val_loss: 4.5368\n",
            "Epoch 1584/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.1754 - val_loss: 4.5357\n",
            "Epoch 1585/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.1683 - val_loss: 4.5333\n",
            "Epoch 1586/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.1627 - val_loss: 4.5309\n",
            "Epoch 1587/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.1571 - val_loss: 4.5294\n",
            "Epoch 1588/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.1503 - val_loss: 4.5278\n",
            "Epoch 1589/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.1447 - val_loss: 4.5264\n",
            "Epoch 1590/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.1383 - val_loss: 4.5249\n",
            "Epoch 1591/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.1329 - val_loss: 4.5241\n",
            "Epoch 1592/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 4.1262 - val_loss: 4.5216\n",
            "Epoch 1593/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.1206 - val_loss: 4.5192\n",
            "Epoch 1594/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.1139 - val_loss: 4.5187\n",
            "Epoch 1595/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.1088 - val_loss: 4.5163\n",
            "Epoch 1596/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 4.1021 - val_loss: 4.5161\n",
            "Epoch 1597/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.0969 - val_loss: 4.5143\n",
            "Epoch 1598/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.0910 - val_loss: 4.5129\n",
            "Epoch 1599/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.0860 - val_loss: 4.5116\n",
            "Epoch 1600/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 4.0797 - val_loss: 4.5096\n",
            "Epoch 1601/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.0744 - val_loss: 4.5076\n",
            "Epoch 1602/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.0683 - val_loss: 4.5066\n",
            "Epoch 1603/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.0629 - val_loss: 4.5047\n",
            "Epoch 1604/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.0577 - val_loss: 4.5036\n",
            "Epoch 1605/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.0518 - val_loss: 4.5028\n",
            "Epoch 1606/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.0466 - val_loss: 4.5011\n",
            "Epoch 1607/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.0419 - val_loss: 4.4995\n",
            "Epoch 1608/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.0355 - val_loss: 4.4981\n",
            "Epoch 1609/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.0299 - val_loss: 4.4966\n",
            "Epoch 1610/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.0241 - val_loss: 4.4948\n",
            "Epoch 1611/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.0190 - val_loss: 4.4930\n",
            "Epoch 1612/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.0135 - val_loss: 4.4914\n",
            "Epoch 1613/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.0086 - val_loss: 4.4903\n",
            "Epoch 1614/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.0029 - val_loss: 4.4893\n",
            "Epoch 1615/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 3.9974 - val_loss: 4.4879\n",
            "Epoch 1616/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.9919 - val_loss: 4.4862\n",
            "Epoch 1617/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.9870 - val_loss: 4.4845\n",
            "Epoch 1618/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.9821 - val_loss: 4.4835\n",
            "Epoch 1619/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.9768 - val_loss: 4.4816\n",
            "Epoch 1620/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.9713 - val_loss: 4.4803\n",
            "Epoch 1621/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.9657 - val_loss: 4.4785\n",
            "Epoch 1622/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.9604 - val_loss: 4.4769\n",
            "Epoch 1623/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.9554 - val_loss: 4.4760\n",
            "Epoch 1624/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.9506 - val_loss: 4.4747\n",
            "Epoch 1625/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 3.9453 - val_loss: 4.4731\n",
            "Epoch 1626/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 3.9400 - val_loss: 4.4710\n",
            "Epoch 1627/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 3.9349 - val_loss: 4.4707\n",
            "Epoch 1628/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 3.9299 - val_loss: 4.4688\n",
            "Epoch 1629/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 3.9245 - val_loss: 4.4676\n",
            "Epoch 1630/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.9193 - val_loss: 4.4663\n",
            "Epoch 1631/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 3.9138 - val_loss: 4.4650\n",
            "Epoch 1632/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 3.9091 - val_loss: 4.4637\n",
            "Epoch 1633/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.9038 - val_loss: 4.4625\n",
            "Epoch 1634/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 3.8997 - val_loss: 4.4607\n",
            "Epoch 1635/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.8942 - val_loss: 4.4592\n",
            "Epoch 1636/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.8887 - val_loss: 4.4578\n",
            "Epoch 1637/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.8834 - val_loss: 4.4561\n",
            "Epoch 1638/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.8787 - val_loss: 4.4555\n",
            "Epoch 1639/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.8741 - val_loss: 4.4537\n",
            "Epoch 1640/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 3.8686 - val_loss: 4.4521\n",
            "Epoch 1641/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 3.8636 - val_loss: 4.4511\n",
            "Epoch 1642/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.8592 - val_loss: 4.4495\n",
            "Epoch 1643/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.8539 - val_loss: 4.4491\n",
            "Epoch 1644/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.8495 - val_loss: 4.4471\n",
            "Epoch 1645/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.8440 - val_loss: 4.4456\n",
            "Epoch 1646/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.8396 - val_loss: 4.4434\n",
            "Epoch 1647/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.8344 - val_loss: 4.4423\n",
            "Epoch 1648/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.8292 - val_loss: 4.4410\n",
            "Epoch 1649/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.8244 - val_loss: 4.4402\n",
            "Epoch 1650/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.8202 - val_loss: 4.4388\n",
            "Epoch 1651/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.8154 - val_loss: 4.4377\n",
            "Epoch 1652/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.8102 - val_loss: 4.4353\n",
            "Epoch 1653/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.8051 - val_loss: 4.4345\n",
            "Epoch 1654/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.8006 - val_loss: 4.4328\n",
            "Epoch 1655/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.7957 - val_loss: 4.4312\n",
            "Epoch 1656/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.7914 - val_loss: 4.4299\n",
            "Epoch 1657/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 3.7861 - val_loss: 4.4288\n",
            "Epoch 1658/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.7820 - val_loss: 4.4281\n",
            "Epoch 1659/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.7765 - val_loss: 4.4265\n",
            "Epoch 1660/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 3.7719 - val_loss: 4.4253\n",
            "Epoch 1661/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 3.7674 - val_loss: 4.4235\n",
            "Epoch 1662/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.7629 - val_loss: 4.4220\n",
            "Epoch 1663/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.7583 - val_loss: 4.4206\n",
            "Epoch 1664/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.7533 - val_loss: 4.4192\n",
            "Epoch 1665/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 3.7491 - val_loss: 4.4194\n",
            "Epoch 1666/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 3.7452 - val_loss: 4.4166\n",
            "Epoch 1667/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.7398 - val_loss: 4.4147\n",
            "Epoch 1668/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.7351 - val_loss: 4.4142\n",
            "Epoch 1669/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.7304 - val_loss: 4.4122\n",
            "Epoch 1670/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 3.7260 - val_loss: 4.4098\n",
            "Epoch 1671/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 3.7217 - val_loss: 4.4088\n",
            "Epoch 1672/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.7165 - val_loss: 4.4070\n",
            "Epoch 1673/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.7121 - val_loss: 4.4063\n",
            "Epoch 1674/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.7074 - val_loss: 4.4052\n",
            "Epoch 1675/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.7033 - val_loss: 4.4035\n",
            "Epoch 1676/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.6984 - val_loss: 4.4020\n",
            "Epoch 1677/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.6943 - val_loss: 4.4009\n",
            "Epoch 1678/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 3.6901 - val_loss: 4.3997\n",
            "Epoch 1679/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 3.6851 - val_loss: 4.3982\n",
            "Epoch 1680/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.6812 - val_loss: 4.3974\n",
            "Epoch 1681/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 3.6769 - val_loss: 4.3956\n",
            "Epoch 1682/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 3.6717 - val_loss: 4.3937\n",
            "Epoch 1683/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.6677 - val_loss: 4.3911\n",
            "Epoch 1684/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.6635 - val_loss: 4.3891\n",
            "Epoch 1685/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.6588 - val_loss: 4.3879\n",
            "Epoch 1686/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.6545 - val_loss: 4.3859\n",
            "Epoch 1687/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.6506 - val_loss: 4.3849\n",
            "Epoch 1688/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.6464 - val_loss: 4.3835\n",
            "Epoch 1689/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.6416 - val_loss: 4.3825\n",
            "Epoch 1690/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.6380 - val_loss: 4.3809\n",
            "Epoch 1691/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.6337 - val_loss: 4.3795\n",
            "Epoch 1692/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.6301 - val_loss: 4.3788\n",
            "Epoch 1693/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.6255 - val_loss: 4.3778\n",
            "Epoch 1694/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.6210 - val_loss: 4.3776\n",
            "Epoch 1695/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.6167 - val_loss: 4.3758\n",
            "Epoch 1696/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.6127 - val_loss: 4.3732\n",
            "Epoch 1697/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.6081 - val_loss: 4.3716\n",
            "Epoch 1698/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.6043 - val_loss: 4.3711\n",
            "Epoch 1699/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.5996 - val_loss: 4.3697\n",
            "Epoch 1700/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.5956 - val_loss: 4.3684\n",
            "Epoch 1701/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.5914 - val_loss: 4.3671\n",
            "Epoch 1702/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.5874 - val_loss: 4.3656\n",
            "Epoch 1703/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.5830 - val_loss: 4.3641\n",
            "Epoch 1704/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.5787 - val_loss: 4.3630\n",
            "Epoch 1705/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.5746 - val_loss: 4.3616\n",
            "Epoch 1706/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.5710 - val_loss: 4.3608\n",
            "Epoch 1707/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.5666 - val_loss: 4.3587\n",
            "Epoch 1708/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.5626 - val_loss: 4.3571\n",
            "Epoch 1709/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.5581 - val_loss: 4.3563\n",
            "Epoch 1710/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.5544 - val_loss: 4.3542\n",
            "Epoch 1711/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.5504 - val_loss: 4.3535\n",
            "Epoch 1712/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 3.5467 - val_loss: 4.3524\n",
            "Epoch 1713/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 3.5424 - val_loss: 4.3500\n",
            "Epoch 1714/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.5384 - val_loss: 4.3484\n",
            "Epoch 1715/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.5344 - val_loss: 4.3466\n",
            "Epoch 1716/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.5303 - val_loss: 4.3447\n",
            "Epoch 1717/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.5263 - val_loss: 4.3430\n",
            "Epoch 1718/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.5224 - val_loss: 4.3421\n",
            "Epoch 1719/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 3.5189 - val_loss: 4.3415\n",
            "Epoch 1720/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.5144 - val_loss: 4.3397\n",
            "Epoch 1721/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.5107 - val_loss: 4.3386\n",
            "Epoch 1722/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 3.5067 - val_loss: 4.3369\n",
            "Epoch 1723/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 3.5028 - val_loss: 4.3358\n",
            "Epoch 1724/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 3.4986 - val_loss: 4.3355\n",
            "Epoch 1725/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 3.4945 - val_loss: 4.3344\n",
            "Epoch 1726/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.4906 - val_loss: 4.3316\n",
            "Epoch 1727/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 3.4864 - val_loss: 4.3297\n",
            "Epoch 1728/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 3.4830 - val_loss: 4.3279\n",
            "Epoch 1729/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 3.4790 - val_loss: 4.3272\n",
            "Epoch 1730/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.4748 - val_loss: 4.3248\n",
            "Epoch 1731/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 3.4714 - val_loss: 4.3233\n",
            "Epoch 1732/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 3.4676 - val_loss: 4.3223\n",
            "Epoch 1733/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.4636 - val_loss: 4.3206\n",
            "Epoch 1734/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 3.4598 - val_loss: 4.3194\n",
            "Epoch 1735/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 3.4561 - val_loss: 4.3188\n",
            "Epoch 1736/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.4519 - val_loss: 4.3178\n",
            "Epoch 1737/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 3.4484 - val_loss: 4.3164\n",
            "Epoch 1738/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 3.4444 - val_loss: 4.3148\n",
            "Epoch 1739/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.4415 - val_loss: 4.3145\n",
            "Epoch 1740/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 3.4377 - val_loss: 4.3131\n",
            "Epoch 1741/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 3.4332 - val_loss: 4.3119\n",
            "Epoch 1742/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.4292 - val_loss: 4.3116\n",
            "Epoch 1743/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.4257 - val_loss: 4.3102\n",
            "Epoch 1744/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.4224 - val_loss: 4.3079\n",
            "Epoch 1745/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.4188 - val_loss: 4.3073\n",
            "Epoch 1746/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.4153 - val_loss: 4.3054\n",
            "Epoch 1747/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.4112 - val_loss: 4.3049\n",
            "Epoch 1748/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.4076 - val_loss: 4.3033\n",
            "Epoch 1749/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.4043 - val_loss: 4.3023\n",
            "Epoch 1750/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.4010 - val_loss: 4.3013\n",
            "Epoch 1751/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.3972 - val_loss: 4.2997\n",
            "Epoch 1752/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.3937 - val_loss: 4.2981\n",
            "Epoch 1753/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.3904 - val_loss: 4.2976\n",
            "Epoch 1754/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.3864 - val_loss: 4.2967\n",
            "Epoch 1755/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.3831 - val_loss: 4.2954\n",
            "Epoch 1756/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.3799 - val_loss: 4.2937\n",
            "Epoch 1757/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.3763 - val_loss: 4.2918\n",
            "Epoch 1758/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 3.3728 - val_loss: 4.2906\n",
            "Epoch 1759/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.3691 - val_loss: 4.2897\n",
            "Epoch 1760/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.3661 - val_loss: 4.2884\n",
            "Epoch 1761/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 3.3622 - val_loss: 4.2872\n",
            "Epoch 1762/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 3.3590 - val_loss: 4.2854\n",
            "Epoch 1763/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.3553 - val_loss: 4.2832\n",
            "Epoch 1764/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.3520 - val_loss: 4.2822\n",
            "Epoch 1765/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.3490 - val_loss: 4.2813\n",
            "Epoch 1766/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.3452 - val_loss: 4.2804\n",
            "Epoch 1767/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.3421 - val_loss: 4.2786\n",
            "Epoch 1768/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.3383 - val_loss: 4.2779\n",
            "Epoch 1769/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 3.3357 - val_loss: 4.2765\n",
            "Epoch 1770/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.3314 - val_loss: 4.2742\n",
            "Epoch 1771/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.3281 - val_loss: 4.2727\n",
            "Epoch 1772/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 3.3254 - val_loss: 4.2713\n",
            "Epoch 1773/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.3216 - val_loss: 4.2683\n",
            "Epoch 1774/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 3.3181 - val_loss: 4.2668\n",
            "Epoch 1775/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.3145 - val_loss: 4.2653\n",
            "Epoch 1776/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.3112 - val_loss: 4.2642\n",
            "Epoch 1777/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.3079 - val_loss: 4.2627\n",
            "Epoch 1778/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 3.3045 - val_loss: 4.2615\n",
            "Epoch 1779/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.3013 - val_loss: 4.2601\n",
            "Epoch 1780/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.2978 - val_loss: 4.2591\n",
            "Epoch 1781/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 3.2949 - val_loss: 4.2583\n",
            "Epoch 1782/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 3.2916 - val_loss: 4.2563\n",
            "Epoch 1783/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.2882 - val_loss: 4.2558\n",
            "Epoch 1784/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.2850 - val_loss: 4.2549\n",
            "Epoch 1785/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.2817 - val_loss: 4.2539\n",
            "Epoch 1786/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.2788 - val_loss: 4.2519\n",
            "Epoch 1787/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.2757 - val_loss: 4.2509\n",
            "Epoch 1788/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 3.2729 - val_loss: 4.2489\n",
            "Epoch 1789/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 3.2693 - val_loss: 4.2476\n",
            "Epoch 1790/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.2658 - val_loss: 4.2472\n",
            "Epoch 1791/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.2631 - val_loss: 4.2459\n",
            "Epoch 1792/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.2595 - val_loss: 4.2452\n",
            "Epoch 1793/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.2565 - val_loss: 4.2440\n",
            "Epoch 1794/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.2531 - val_loss: 4.2429\n",
            "Epoch 1795/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 3.2500 - val_loss: 4.2414\n",
            "Epoch 1796/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.2471 - val_loss: 4.2408\n",
            "Epoch 1797/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 3.2434 - val_loss: 4.2403\n",
            "Epoch 1798/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.2414 - val_loss: 4.2395\n",
            "Epoch 1799/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.2381 - val_loss: 4.2388\n",
            "Epoch 1800/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 3.2347 - val_loss: 4.2372\n",
            "Epoch 1801/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.2313 - val_loss: 4.2356\n",
            "Epoch 1802/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.2282 - val_loss: 4.2355\n",
            "Epoch 1803/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.2253 - val_loss: 4.2342\n",
            "Epoch 1804/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.2224 - val_loss: 4.2340\n",
            "Epoch 1805/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.2198 - val_loss: 4.2330\n",
            "Epoch 1806/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 3.2161 - val_loss: 4.2331\n",
            "Epoch 1807/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.2132 - val_loss: 4.2318\n",
            "Epoch 1808/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.2102 - val_loss: 4.2308\n",
            "Epoch 1809/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.2070 - val_loss: 4.2306\n",
            "Epoch 1810/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.2036 - val_loss: 4.2291\n",
            "Epoch 1811/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.2012 - val_loss: 4.2276\n",
            "Epoch 1812/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.1980 - val_loss: 4.2258\n",
            "Epoch 1813/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 3.1945 - val_loss: 4.2250\n",
            "Epoch 1814/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.1914 - val_loss: 4.2238\n",
            "Epoch 1815/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.1883 - val_loss: 4.2229\n",
            "Epoch 1816/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.1851 - val_loss: 4.2220\n",
            "Epoch 1817/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.1820 - val_loss: 4.2212\n",
            "Epoch 1818/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.1790 - val_loss: 4.2196\n",
            "Epoch 1819/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.1757 - val_loss: 4.2194\n",
            "Epoch 1820/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.1726 - val_loss: 4.2187\n",
            "Epoch 1821/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.1697 - val_loss: 4.2168\n",
            "Epoch 1822/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.1668 - val_loss: 4.2164\n",
            "Epoch 1823/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.1634 - val_loss: 4.2160\n",
            "Epoch 1824/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.1609 - val_loss: 4.2152\n",
            "Epoch 1825/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.1575 - val_loss: 4.2145\n",
            "Epoch 1826/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.1547 - val_loss: 4.2138\n",
            "Epoch 1827/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.1515 - val_loss: 4.2122\n",
            "Epoch 1828/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.1486 - val_loss: 4.2114\n",
            "Epoch 1829/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.1456 - val_loss: 4.2099\n",
            "Epoch 1830/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.1431 - val_loss: 4.2079\n",
            "Epoch 1831/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.1401 - val_loss: 4.2075\n",
            "Epoch 1832/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.1370 - val_loss: 4.2066\n",
            "Epoch 1833/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.1343 - val_loss: 4.2065\n",
            "Epoch 1834/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.1312 - val_loss: 4.2060\n",
            "Epoch 1835/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.1278 - val_loss: 4.2045\n",
            "Epoch 1836/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.1253 - val_loss: 4.2035\n",
            "Epoch 1837/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 3.1220 - val_loss: 4.2029\n",
            "Epoch 1838/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.1195 - val_loss: 4.2010\n",
            "Epoch 1839/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.1163 - val_loss: 4.2010\n",
            "Epoch 1840/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 3.1136 - val_loss: 4.1999\n",
            "Epoch 1841/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.1105 - val_loss: 4.1995\n",
            "Epoch 1842/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 3.1076 - val_loss: 4.1987\n",
            "Epoch 1843/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.1048 - val_loss: 4.1979\n",
            "Epoch 1844/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.1023 - val_loss: 4.1975\n",
            "Epoch 1845/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.0986 - val_loss: 4.1970\n",
            "Epoch 1846/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.0962 - val_loss: 4.1954\n",
            "Epoch 1847/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.0929 - val_loss: 4.1942\n",
            "Epoch 1848/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.0900 - val_loss: 4.1930\n",
            "Epoch 1849/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.0875 - val_loss: 4.1921\n",
            "Epoch 1850/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.0844 - val_loss: 4.1915\n",
            "Epoch 1851/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.0819 - val_loss: 4.1909\n",
            "Epoch 1852/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 3.0789 - val_loss: 4.1906\n",
            "Epoch 1853/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.0761 - val_loss: 4.1895\n",
            "Epoch 1854/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.0736 - val_loss: 4.1883\n",
            "Epoch 1855/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.0708 - val_loss: 4.1874\n",
            "Epoch 1856/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.0676 - val_loss: 4.1872\n",
            "Epoch 1857/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.0644 - val_loss: 4.1860\n",
            "Epoch 1858/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 3.0618 - val_loss: 4.1848\n",
            "Epoch 1859/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.0593 - val_loss: 4.1843\n",
            "Epoch 1860/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.0557 - val_loss: 4.1841\n",
            "Epoch 1861/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 3.0535 - val_loss: 4.1816\n",
            "Epoch 1862/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.0501 - val_loss: 4.1808\n",
            "Epoch 1863/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.0473 - val_loss: 4.1799\n",
            "Epoch 1864/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 3.0442 - val_loss: 4.1789\n",
            "Epoch 1865/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.0421 - val_loss: 4.1779\n",
            "Epoch 1866/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.0393 - val_loss: 4.1768\n",
            "Epoch 1867/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.0368 - val_loss: 4.1759\n",
            "Epoch 1868/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.0338 - val_loss: 4.1739\n",
            "Epoch 1869/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 3.0305 - val_loss: 4.1728\n",
            "Epoch 1870/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.0280 - val_loss: 4.1722\n",
            "Epoch 1871/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 3.0253 - val_loss: 4.1714\n",
            "Epoch 1872/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 3.0223 - val_loss: 4.1715\n",
            "Epoch 1873/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 3.0194 - val_loss: 4.1703\n",
            "Epoch 1874/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 3.0169 - val_loss: 4.1684\n",
            "Epoch 1875/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.0142 - val_loss: 4.1677\n",
            "Epoch 1876/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 3.0119 - val_loss: 4.1671\n",
            "Epoch 1877/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.0087 - val_loss: 4.1661\n",
            "Epoch 1878/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.0060 - val_loss: 4.1645\n",
            "Epoch 1879/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.0034 - val_loss: 4.1642\n",
            "Epoch 1880/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.0003 - val_loss: 4.1640\n",
            "Epoch 1881/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 2.9979 - val_loss: 4.1625\n",
            "Epoch 1882/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.9950 - val_loss: 4.1619\n",
            "Epoch 1883/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.9930 - val_loss: 4.1605\n",
            "Epoch 1884/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 2.9898 - val_loss: 4.1595\n",
            "Epoch 1885/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.9865 - val_loss: 4.1586\n",
            "Epoch 1886/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 2.9842 - val_loss: 4.1578\n",
            "Epoch 1887/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 2.9818 - val_loss: 4.1567\n",
            "Epoch 1888/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.9783 - val_loss: 4.1553\n",
            "Epoch 1889/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.9757 - val_loss: 4.1544\n",
            "Epoch 1890/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 2.9732 - val_loss: 4.1524\n",
            "Epoch 1891/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 2.9702 - val_loss: 4.1508\n",
            "Epoch 1892/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 2.9675 - val_loss: 4.1502\n",
            "Epoch 1893/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.9648 - val_loss: 4.1493\n",
            "Epoch 1894/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.9624 - val_loss: 4.1491\n",
            "Epoch 1895/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.9601 - val_loss: 4.1486\n",
            "Epoch 1896/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.9569 - val_loss: 4.1482\n",
            "Epoch 1897/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 2.9542 - val_loss: 4.1471\n",
            "Epoch 1898/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 2.9515 - val_loss: 4.1460\n",
            "Epoch 1899/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.9494 - val_loss: 4.1441\n",
            "Epoch 1900/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 2.9463 - val_loss: 4.1424\n",
            "Epoch 1901/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.9432 - val_loss: 4.1416\n",
            "Epoch 1902/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 2.9407 - val_loss: 4.1411\n",
            "Epoch 1903/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.9380 - val_loss: 4.1402\n",
            "Epoch 1904/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.9354 - val_loss: 4.1389\n",
            "Epoch 1905/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 2.9326 - val_loss: 4.1377\n",
            "Epoch 1906/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 2.9300 - val_loss: 4.1370\n",
            "Epoch 1907/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.9276 - val_loss: 4.1364\n",
            "Epoch 1908/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 2.9249 - val_loss: 4.1354\n",
            "Epoch 1909/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.9220 - val_loss: 4.1349\n",
            "Epoch 1910/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.9196 - val_loss: 4.1343\n",
            "Epoch 1911/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 2.9171 - val_loss: 4.1329\n",
            "Epoch 1912/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.9141 - val_loss: 4.1316\n",
            "Epoch 1913/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 2.9117 - val_loss: 4.1308\n",
            "Epoch 1914/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 2.9091 - val_loss: 4.1301\n",
            "Epoch 1915/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.9063 - val_loss: 4.1294\n",
            "Epoch 1916/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 2.9037 - val_loss: 4.1285\n",
            "Epoch 1917/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 2.9016 - val_loss: 4.1272\n",
            "Epoch 1918/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.8985 - val_loss: 4.1267\n",
            "Epoch 1919/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 2.8960 - val_loss: 4.1260\n",
            "Epoch 1920/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.8935 - val_loss: 4.1257\n",
            "Epoch 1921/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.8911 - val_loss: 4.1234\n",
            "Epoch 1922/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.8885 - val_loss: 4.1220\n",
            "Epoch 1923/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.8860 - val_loss: 4.1215\n",
            "Epoch 1924/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.8829 - val_loss: 4.1212\n",
            "Epoch 1925/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.8805 - val_loss: 4.1203\n",
            "Epoch 1926/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.8779 - val_loss: 4.1198\n",
            "Epoch 1927/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 2.8754 - val_loss: 4.1186\n",
            "Epoch 1928/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.8731 - val_loss: 4.1179\n",
            "Epoch 1929/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.8702 - val_loss: 4.1172\n",
            "Epoch 1930/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.8674 - val_loss: 4.1166\n",
            "Epoch 1931/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 2.8651 - val_loss: 4.1148\n",
            "Epoch 1932/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.8622 - val_loss: 4.1138\n",
            "Epoch 1933/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 2.8599 - val_loss: 4.1124\n",
            "Epoch 1934/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.8577 - val_loss: 4.1114\n",
            "Epoch 1935/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.8549 - val_loss: 4.1102\n",
            "Epoch 1936/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.8517 - val_loss: 4.1086\n",
            "Epoch 1937/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.8491 - val_loss: 4.1073\n",
            "Epoch 1938/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.8468 - val_loss: 4.1066\n",
            "Epoch 1939/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.8447 - val_loss: 4.1058\n",
            "Epoch 1940/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.8417 - val_loss: 4.1048\n",
            "Epoch 1941/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 2.8396 - val_loss: 4.1041\n",
            "Epoch 1942/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 2.8368 - val_loss: 4.1034\n",
            "Epoch 1943/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.8344 - val_loss: 4.1020\n",
            "Epoch 1944/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.8319 - val_loss: 4.1011\n",
            "Epoch 1945/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.8295 - val_loss: 4.1008\n",
            "Epoch 1946/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.8270 - val_loss: 4.1002\n",
            "Epoch 1947/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 2.8242 - val_loss: 4.0992\n",
            "Epoch 1948/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.8218 - val_loss: 4.0987\n",
            "Epoch 1949/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.8193 - val_loss: 4.0968\n",
            "Epoch 1950/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.8167 - val_loss: 4.0957\n",
            "Epoch 1951/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.8146 - val_loss: 4.0942\n",
            "Epoch 1952/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 2.8116 - val_loss: 4.0945\n",
            "Epoch 1953/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.8095 - val_loss: 4.0932\n",
            "Epoch 1954/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.8066 - val_loss: 4.0924\n",
            "Epoch 1955/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.8040 - val_loss: 4.0916\n",
            "Epoch 1956/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.8018 - val_loss: 4.0913\n",
            "Epoch 1957/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.7992 - val_loss: 4.0908\n",
            "Epoch 1958/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.7970 - val_loss: 4.0895\n",
            "Epoch 1959/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.7942 - val_loss: 4.0881\n",
            "Epoch 1960/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.7918 - val_loss: 4.0878\n",
            "Epoch 1961/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.7895 - val_loss: 4.0867\n",
            "Epoch 1962/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 2.7869 - val_loss: 4.0868\n",
            "Epoch 1963/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.7847 - val_loss: 4.0855\n",
            "Epoch 1964/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.7820 - val_loss: 4.0849\n",
            "Epoch 1965/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.7795 - val_loss: 4.0837\n",
            "Epoch 1966/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.7773 - val_loss: 4.0824\n",
            "Epoch 1967/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.7747 - val_loss: 4.0812\n",
            "Epoch 1968/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 2.7720 - val_loss: 4.0803\n",
            "Epoch 1969/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.7697 - val_loss: 4.0796\n",
            "Epoch 1970/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.7675 - val_loss: 4.0786\n",
            "Epoch 1971/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.7650 - val_loss: 4.0780\n",
            "Epoch 1972/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.7628 - val_loss: 4.0770\n",
            "Epoch 1973/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.7602 - val_loss: 4.0759\n",
            "Epoch 1974/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.7573 - val_loss: 4.0750\n",
            "Epoch 1975/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 2.7555 - val_loss: 4.0739\n",
            "Epoch 1976/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.7535 - val_loss: 4.0729\n",
            "Epoch 1977/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.7506 - val_loss: 4.0717\n",
            "Epoch 1978/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.7484 - val_loss: 4.0709\n",
            "Epoch 1979/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 2.7456 - val_loss: 4.0699\n",
            "Epoch 1980/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.7433 - val_loss: 4.0687\n",
            "Epoch 1981/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 2.7409 - val_loss: 4.0674\n",
            "Epoch 1982/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 2.7384 - val_loss: 4.0658\n",
            "Epoch 1983/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 2.7362 - val_loss: 4.0656\n",
            "Epoch 1984/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 2.7339 - val_loss: 4.0647\n",
            "Epoch 1985/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 2.7314 - val_loss: 4.0652\n",
            "Epoch 1986/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 2.7291 - val_loss: 4.0644\n",
            "Epoch 1987/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 2.7267 - val_loss: 4.0637\n",
            "Epoch 1988/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 2.7242 - val_loss: 4.0620\n",
            "Epoch 1989/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 2.7217 - val_loss: 4.0608\n",
            "Epoch 1990/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 2.7200 - val_loss: 4.0610\n",
            "Epoch 1991/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.7173 - val_loss: 4.0594\n",
            "Epoch 1992/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 2.7145 - val_loss: 4.0594\n",
            "Epoch 1993/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.7124 - val_loss: 4.0588\n",
            "Epoch 1994/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.7098 - val_loss: 4.0581\n",
            "Epoch 1995/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 2.7080 - val_loss: 4.0568\n",
            "Epoch 1996/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 2.7052 - val_loss: 4.0559\n",
            "Epoch 1997/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 2.7030 - val_loss: 4.0550\n",
            "Epoch 1998/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 2.7008 - val_loss: 4.0540\n",
            "Epoch 1999/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.6984 - val_loss: 4.0538\n",
            "Epoch 2000/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.6960 - val_loss: 4.0529\n",
            "Epoch 2001/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 2.6938 - val_loss: 4.0517\n",
            "Epoch 2002/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.6914 - val_loss: 4.0512\n",
            "Epoch 2003/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 2.6892 - val_loss: 4.0507\n",
            "Epoch 2004/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 2.6868 - val_loss: 4.0493\n",
            "Epoch 2005/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 2.6846 - val_loss: 4.0488\n",
            "Epoch 2006/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.6824 - val_loss: 4.0479\n",
            "Epoch 2007/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.6800 - val_loss: 4.0475\n",
            "Epoch 2008/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.6778 - val_loss: 4.0474\n",
            "Epoch 2009/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.6755 - val_loss: 4.0472\n",
            "Epoch 2010/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.6733 - val_loss: 4.0455\n",
            "Epoch 2011/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 2.6709 - val_loss: 4.0444\n",
            "Epoch 2012/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 2.6689 - val_loss: 4.0426\n",
            "Epoch 2013/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 2.6661 - val_loss: 4.0420\n",
            "Epoch 2014/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 2.6642 - val_loss: 4.0415\n",
            "Epoch 2015/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 2.6618 - val_loss: 4.0409\n",
            "Epoch 2016/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.6596 - val_loss: 4.0401\n",
            "Epoch 2017/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.6567 - val_loss: 4.0392\n",
            "Epoch 2018/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 2.6550 - val_loss: 4.0378\n",
            "Epoch 2019/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 2.6526 - val_loss: 4.0370\n",
            "Epoch 2020/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 2.6502 - val_loss: 4.0358\n",
            "Epoch 2021/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.6481 - val_loss: 4.0355\n",
            "Epoch 2022/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 2.6461 - val_loss: 4.0354\n",
            "Epoch 2023/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.6441 - val_loss: 4.0346\n",
            "Epoch 2024/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.6418 - val_loss: 4.0338\n",
            "Epoch 2025/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.6390 - val_loss: 4.0329\n",
            "Epoch 2026/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.6368 - val_loss: 4.0314\n",
            "Epoch 2027/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.6347 - val_loss: 4.0302\n",
            "Epoch 2028/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.6325 - val_loss: 4.0302\n",
            "Epoch 2029/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.6305 - val_loss: 4.0299\n",
            "Epoch 2030/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.6280 - val_loss: 4.0289\n",
            "Epoch 2031/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.6260 - val_loss: 4.0289\n",
            "Epoch 2032/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.6237 - val_loss: 4.0276\n",
            "Epoch 2033/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.6215 - val_loss: 4.0269\n",
            "Epoch 2034/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.6192 - val_loss: 4.0258\n",
            "Epoch 2035/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.6170 - val_loss: 4.0250\n",
            "Epoch 2036/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 2.6147 - val_loss: 4.0248\n",
            "Epoch 2037/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 2.6126 - val_loss: 4.0235\n",
            "Epoch 2038/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.6106 - val_loss: 4.0228\n",
            "Epoch 2039/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.6084 - val_loss: 4.0220\n",
            "Epoch 2040/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 2.6060 - val_loss: 4.0215\n",
            "Epoch 2041/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 2.6039 - val_loss: 4.0196\n",
            "Epoch 2042/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 2.6015 - val_loss: 4.0185\n",
            "Epoch 2043/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.5995 - val_loss: 4.0178\n",
            "Epoch 2044/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 2.5973 - val_loss: 4.0174\n",
            "Epoch 2045/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 2.5949 - val_loss: 4.0170\n",
            "Epoch 2046/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 2.5931 - val_loss: 4.0170\n",
            "Epoch 2047/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 2.5908 - val_loss: 4.0160\n",
            "Epoch 2048/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.5887 - val_loss: 4.0159\n",
            "Epoch 2049/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.5865 - val_loss: 4.0155\n",
            "Epoch 2050/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.5844 - val_loss: 4.0142\n",
            "Epoch 2051/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.5823 - val_loss: 4.0136\n",
            "Epoch 2052/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 2.5799 - val_loss: 4.0125\n",
            "Epoch 2053/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.5779 - val_loss: 4.0123\n",
            "Epoch 2054/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 2.5757 - val_loss: 4.0122\n",
            "Epoch 2055/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 2.5735 - val_loss: 4.0111\n",
            "Epoch 2056/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 2.5717 - val_loss: 4.0109\n",
            "Epoch 2057/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.5696 - val_loss: 4.0100\n",
            "Epoch 2058/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 2.5669 - val_loss: 4.0091\n",
            "Epoch 2059/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 2.5655 - val_loss: 4.0070\n",
            "Epoch 2060/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.5628 - val_loss: 4.0060\n",
            "Epoch 2061/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 2.5607 - val_loss: 4.0049\n",
            "Epoch 2062/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.5586 - val_loss: 4.0046\n",
            "Epoch 2063/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 2.5566 - val_loss: 4.0047\n",
            "Epoch 2064/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.5546 - val_loss: 4.0040\n",
            "Epoch 2065/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 2.5523 - val_loss: 4.0037\n",
            "Epoch 2066/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.5503 - val_loss: 4.0034\n",
            "Epoch 2067/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.5480 - val_loss: 4.0019\n",
            "Epoch 2068/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.5460 - val_loss: 4.0009\n",
            "Epoch 2069/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.5439 - val_loss: 4.0004\n",
            "Epoch 2070/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 2.5417 - val_loss: 3.9994\n",
            "Epoch 2071/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.5398 - val_loss: 3.9976\n",
            "Epoch 2072/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.5377 - val_loss: 3.9970\n",
            "Epoch 2073/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 2.5355 - val_loss: 3.9961\n",
            "Epoch 2074/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.5336 - val_loss: 3.9956\n",
            "Epoch 2075/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 2.5310 - val_loss: 3.9954\n",
            "Epoch 2076/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.5291 - val_loss: 3.9947\n",
            "Epoch 2077/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.5271 - val_loss: 3.9943\n",
            "Epoch 2078/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 2.5250 - val_loss: 3.9936\n",
            "Epoch 2079/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 2.5230 - val_loss: 3.9929\n",
            "Epoch 2080/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.5211 - val_loss: 3.9928\n",
            "Epoch 2081/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.5188 - val_loss: 3.9916\n",
            "Epoch 2082/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 2.5165 - val_loss: 3.9911\n",
            "Epoch 2083/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 2.5146 - val_loss: 3.9907\n",
            "Epoch 2084/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 2.5127 - val_loss: 3.9894\n",
            "Epoch 2085/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 2.5107 - val_loss: 3.9884\n",
            "Epoch 2086/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 2.5081 - val_loss: 3.9880\n",
            "Epoch 2087/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 2.5063 - val_loss: 3.9870\n",
            "Epoch 2088/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.5043 - val_loss: 3.9858\n",
            "Epoch 2089/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 2.5023 - val_loss: 3.9839\n",
            "Epoch 2090/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.5000 - val_loss: 3.9839\n",
            "Epoch 2091/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.4989 - val_loss: 3.9834\n",
            "Epoch 2092/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.4961 - val_loss: 3.9825\n",
            "Epoch 2093/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 2.4938 - val_loss: 3.9819\n",
            "Epoch 2094/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 2.4916 - val_loss: 3.9812\n",
            "Epoch 2095/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.4896 - val_loss: 3.9805\n",
            "Epoch 2096/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 2.4879 - val_loss: 3.9794\n",
            "Epoch 2097/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 2.4854 - val_loss: 3.9791\n",
            "Epoch 2098/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 2.4838 - val_loss: 3.9777\n",
            "Epoch 2099/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 2.4816 - val_loss: 3.9771\n",
            "Epoch 2100/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 2.4795 - val_loss: 3.9764\n",
            "Epoch 2101/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.4776 - val_loss: 3.9755\n",
            "Epoch 2102/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 2.4756 - val_loss: 3.9750\n",
            "Epoch 2103/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.4735 - val_loss: 3.9744\n",
            "Epoch 2104/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.4717 - val_loss: 3.9739\n",
            "Epoch 2105/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 2.4695 - val_loss: 3.9729\n",
            "Epoch 2106/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.4676 - val_loss: 3.9723\n",
            "Epoch 2107/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 2.4655 - val_loss: 3.9714\n",
            "Epoch 2108/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.4638 - val_loss: 3.9709\n",
            "Epoch 2109/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 2.4614 - val_loss: 3.9702\n",
            "Epoch 2110/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 2.4593 - val_loss: 3.9691\n",
            "Epoch 2111/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.4581 - val_loss: 3.9684\n",
            "Epoch 2112/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 2.4555 - val_loss: 3.9685\n",
            "Epoch 2113/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 2.4534 - val_loss: 3.9685\n",
            "Epoch 2114/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.4517 - val_loss: 3.9670\n",
            "Epoch 2115/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 2.4494 - val_loss: 3.9657\n",
            "Epoch 2116/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.4473 - val_loss: 3.9650\n",
            "Epoch 2117/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 2.4453 - val_loss: 3.9644\n",
            "Epoch 2118/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.4433 - val_loss: 3.9642\n",
            "Epoch 2119/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 2.4412 - val_loss: 3.9638\n",
            "Epoch 2120/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 2.4392 - val_loss: 3.9628\n",
            "Epoch 2121/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 2.4376 - val_loss: 3.9618\n",
            "Epoch 2122/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.4356 - val_loss: 3.9613\n",
            "Epoch 2123/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 2.4334 - val_loss: 3.9614\n",
            "Epoch 2124/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.4317 - val_loss: 3.9597\n",
            "Epoch 2125/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.4291 - val_loss: 3.9596\n",
            "Epoch 2126/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 2.4273 - val_loss: 3.9586\n",
            "Epoch 2127/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 2.4251 - val_loss: 3.9584\n",
            "Epoch 2128/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.4233 - val_loss: 3.9568\n",
            "Epoch 2129/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 2.4214 - val_loss: 3.9559\n",
            "Epoch 2130/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 2.4192 - val_loss: 3.9558\n",
            "Epoch 2131/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 2.4174 - val_loss: 3.9553\n",
            "Epoch 2132/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.4152 - val_loss: 3.9544\n",
            "Epoch 2133/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.4132 - val_loss: 3.9541\n",
            "Epoch 2134/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.4116 - val_loss: 3.9535\n",
            "Epoch 2135/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.4096 - val_loss: 3.9522\n",
            "Epoch 2136/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.4073 - val_loss: 3.9522\n",
            "Epoch 2137/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.4060 - val_loss: 3.9520\n",
            "Epoch 2138/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.4036 - val_loss: 3.9514\n",
            "Epoch 2139/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.4017 - val_loss: 3.9508\n",
            "Epoch 2140/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.3998 - val_loss: 3.9498\n",
            "Epoch 2141/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.3976 - val_loss: 3.9492\n",
            "Epoch 2142/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.3958 - val_loss: 3.9484\n",
            "Epoch 2143/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.3942 - val_loss: 3.9479\n",
            "Epoch 2144/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.3925 - val_loss: 3.9478\n",
            "Epoch 2145/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 2.3904 - val_loss: 3.9468\n",
            "Epoch 2146/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 2.3882 - val_loss: 3.9463\n",
            "Epoch 2147/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.3864 - val_loss: 3.9448\n",
            "Epoch 2148/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 2.3844 - val_loss: 3.9439\n",
            "Epoch 2149/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 2.3825 - val_loss: 3.9442\n",
            "Epoch 2150/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 2.3807 - val_loss: 3.9442\n",
            "Epoch 2151/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.3785 - val_loss: 3.9427\n",
            "Epoch 2152/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 2.3766 - val_loss: 3.9432\n",
            "Epoch 2153/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 2.3750 - val_loss: 3.9411\n",
            "Epoch 2154/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 2.3728 - val_loss: 3.9413\n",
            "Epoch 2155/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 2.3707 - val_loss: 3.9409\n",
            "Epoch 2156/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.3692 - val_loss: 3.9389\n",
            "Epoch 2157/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.3669 - val_loss: 3.9383\n",
            "Epoch 2158/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 2.3651 - val_loss: 3.9375\n",
            "Epoch 2159/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 2.3632 - val_loss: 3.9364\n",
            "Epoch 2160/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 2.3613 - val_loss: 3.9356\n",
            "Epoch 2161/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.3593 - val_loss: 3.9352\n",
            "Epoch 2162/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.3574 - val_loss: 3.9344\n",
            "Epoch 2163/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 2.3556 - val_loss: 3.9350\n",
            "Epoch 2164/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 2.3535 - val_loss: 3.9349\n",
            "Epoch 2165/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 2.3519 - val_loss: 3.9345\n",
            "Epoch 2166/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.3497 - val_loss: 3.9339\n",
            "Epoch 2167/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.3478 - val_loss: 3.9326\n",
            "Epoch 2168/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.3460 - val_loss: 3.9322\n",
            "Epoch 2169/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.3441 - val_loss: 3.9317\n",
            "Epoch 2170/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 2.3425 - val_loss: 3.9316\n",
            "Epoch 2171/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 2.3405 - val_loss: 3.9309\n",
            "Epoch 2172/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.3386 - val_loss: 3.9305\n",
            "Epoch 2173/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 2.3366 - val_loss: 3.9302\n",
            "Epoch 2174/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 2.3350 - val_loss: 3.9292\n",
            "Epoch 2175/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.3328 - val_loss: 3.9286\n",
            "Epoch 2176/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 2.3311 - val_loss: 3.9275\n",
            "Epoch 2177/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 2.3292 - val_loss: 3.9271\n",
            "Epoch 2178/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 2.3275 - val_loss: 3.9264\n",
            "Epoch 2179/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 2.3257 - val_loss: 3.9261\n",
            "Epoch 2180/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 2.3239 - val_loss: 3.9254\n",
            "Epoch 2181/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.3221 - val_loss: 3.9241\n",
            "Epoch 2182/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 2.3203 - val_loss: 3.9240\n",
            "Epoch 2183/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 2.3184 - val_loss: 3.9219\n",
            "Epoch 2184/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 2.3164 - val_loss: 3.9212\n",
            "Epoch 2185/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 2.3146 - val_loss: 3.9201\n",
            "Epoch 2186/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 2.3125 - val_loss: 3.9197\n",
            "Epoch 2187/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 2.3109 - val_loss: 3.9192\n",
            "Epoch 2188/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 2.3094 - val_loss: 3.9188\n",
            "Epoch 2189/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.3071 - val_loss: 3.9184\n",
            "Epoch 2190/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.3056 - val_loss: 3.9177\n",
            "Epoch 2191/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 2.3036 - val_loss: 3.9168\n",
            "Epoch 2192/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.3016 - val_loss: 3.9168\n",
            "Epoch 2193/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 2.2998 - val_loss: 3.9158\n",
            "Epoch 2194/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.2982 - val_loss: 3.9149\n",
            "Epoch 2195/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 2.2963 - val_loss: 3.9148\n",
            "Epoch 2196/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 2.2947 - val_loss: 3.9139\n",
            "Epoch 2197/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 2.2931 - val_loss: 3.9144\n",
            "Epoch 2198/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 2.2908 - val_loss: 3.9139\n",
            "Epoch 2199/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.2891 - val_loss: 3.9137\n",
            "Epoch 2200/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 2.2876 - val_loss: 3.9117\n",
            "Epoch 2201/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.2854 - val_loss: 3.9107\n",
            "Epoch 2202/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.2835 - val_loss: 3.9103\n",
            "Epoch 2203/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.2817 - val_loss: 3.9094\n",
            "Epoch 2204/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 2.2800 - val_loss: 3.9086\n",
            "Epoch 2205/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 2.2782 - val_loss: 3.9088\n",
            "Epoch 2206/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 2.2764 - val_loss: 3.9085\n",
            "Epoch 2207/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.2750 - val_loss: 3.9067\n",
            "Epoch 2208/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.2728 - val_loss: 3.9062\n",
            "Epoch 2209/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 2.2710 - val_loss: 3.9052\n",
            "Epoch 2210/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 2.2692 - val_loss: 3.9045\n",
            "Epoch 2211/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.2675 - val_loss: 3.9039\n",
            "Epoch 2212/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.2655 - val_loss: 3.9035\n",
            "Epoch 2213/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.2638 - val_loss: 3.9029\n",
            "Epoch 2214/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.2622 - val_loss: 3.9024\n",
            "Epoch 2215/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.2602 - val_loss: 3.9015\n",
            "Epoch 2216/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.2583 - val_loss: 3.9009\n",
            "Epoch 2217/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.2565 - val_loss: 3.9004\n",
            "Epoch 2218/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.2553 - val_loss: 3.9001\n",
            "Epoch 2219/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 2.2535 - val_loss: 3.8995\n",
            "Epoch 2220/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 2.2513 - val_loss: 3.8988\n",
            "Epoch 2221/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.2497 - val_loss: 3.8971\n",
            "Epoch 2222/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.2477 - val_loss: 3.8965\n",
            "Epoch 2223/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 2.2460 - val_loss: 3.8957\n",
            "Epoch 2224/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 2.2441 - val_loss: 3.8955\n",
            "Epoch 2225/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.2427 - val_loss: 3.8954\n",
            "Epoch 2226/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 2.2406 - val_loss: 3.8959\n",
            "Epoch 2227/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 2.2390 - val_loss: 3.8956\n",
            "Epoch 2228/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.2373 - val_loss: 3.8948\n",
            "Epoch 2229/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.2356 - val_loss: 3.8939\n",
            "Epoch 2230/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 2.2338 - val_loss: 3.8937\n",
            "Epoch 2231/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.2321 - val_loss: 3.8929\n",
            "Epoch 2232/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 2.2300 - val_loss: 3.8927\n",
            "Epoch 2233/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.2285 - val_loss: 3.8919\n",
            "Epoch 2234/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.2269 - val_loss: 3.8905\n",
            "Epoch 2235/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 2.2252 - val_loss: 3.8900\n",
            "Epoch 2236/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 2.2234 - val_loss: 3.8901\n",
            "Epoch 2237/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.2216 - val_loss: 3.8890\n",
            "Epoch 2238/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 2.2200 - val_loss: 3.8890\n",
            "Epoch 2239/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.2181 - val_loss: 3.8887\n",
            "Epoch 2240/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.2164 - val_loss: 3.8878\n",
            "Epoch 2241/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.2147 - val_loss: 3.8876\n",
            "Epoch 2242/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.2129 - val_loss: 3.8869\n",
            "Epoch 2243/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.2111 - val_loss: 3.8864\n",
            "Epoch 2244/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.2096 - val_loss: 3.8852\n",
            "Epoch 2245/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 2.2075 - val_loss: 3.8852\n",
            "Epoch 2246/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 2.2060 - val_loss: 3.8850\n",
            "Epoch 2247/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.2046 - val_loss: 3.8839\n",
            "Epoch 2248/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.2025 - val_loss: 3.8831\n",
            "Epoch 2249/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.2008 - val_loss: 3.8822\n",
            "Epoch 2250/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.1990 - val_loss: 3.8815\n",
            "Epoch 2251/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.1972 - val_loss: 3.8811\n",
            "Epoch 2252/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.1955 - val_loss: 3.8805\n",
            "Epoch 2253/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.1941 - val_loss: 3.8803\n",
            "Epoch 2254/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 2.1921 - val_loss: 3.8795\n",
            "Epoch 2255/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.1905 - val_loss: 3.8793\n",
            "Epoch 2256/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.1887 - val_loss: 3.8789\n",
            "Epoch 2257/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.1873 - val_loss: 3.8783\n",
            "Epoch 2258/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.1857 - val_loss: 3.8781\n",
            "Epoch 2259/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.1839 - val_loss: 3.8779\n",
            "Epoch 2260/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.1819 - val_loss: 3.8775\n",
            "Epoch 2261/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.1805 - val_loss: 3.8762\n",
            "Epoch 2262/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.1787 - val_loss: 3.8762\n",
            "Epoch 2263/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 2.1770 - val_loss: 3.8760\n",
            "Epoch 2264/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 2.1750 - val_loss: 3.8755\n",
            "Epoch 2265/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 2.1737 - val_loss: 3.8750\n",
            "Epoch 2266/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 2.1719 - val_loss: 3.8748\n",
            "Epoch 2267/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.1704 - val_loss: 3.8737\n",
            "Epoch 2268/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.1686 - val_loss: 3.8728\n",
            "Epoch 2269/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 2.1669 - val_loss: 3.8720\n",
            "Epoch 2270/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.1653 - val_loss: 3.8719\n",
            "Epoch 2271/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.1637 - val_loss: 3.8712\n",
            "Epoch 2272/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.1621 - val_loss: 3.8709\n",
            "Epoch 2273/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 2.1603 - val_loss: 3.8710\n",
            "Epoch 2274/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.1588 - val_loss: 3.8705\n",
            "Epoch 2275/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.1571 - val_loss: 3.8699\n",
            "Epoch 2276/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 2.1554 - val_loss: 3.8702\n",
            "Epoch 2277/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.1540 - val_loss: 3.8694\n",
            "Epoch 2278/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.1520 - val_loss: 3.8691\n",
            "Epoch 2279/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.1507 - val_loss: 3.8679\n",
            "Epoch 2280/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.1486 - val_loss: 3.8673\n",
            "Epoch 2281/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.1472 - val_loss: 3.8672\n",
            "Epoch 2282/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.1454 - val_loss: 3.8662\n",
            "Epoch 2283/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.1440 - val_loss: 3.8661\n",
            "Epoch 2284/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.1424 - val_loss: 3.8647\n",
            "Epoch 2285/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.1407 - val_loss: 3.8646\n",
            "Epoch 2286/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.1386 - val_loss: 3.8639\n",
            "Epoch 2287/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.1369 - val_loss: 3.8630\n",
            "Epoch 2288/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.1354 - val_loss: 3.8617\n",
            "Epoch 2289/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.1335 - val_loss: 3.8613\n",
            "Epoch 2290/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.1321 - val_loss: 3.8610\n",
            "Epoch 2291/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.1303 - val_loss: 3.8605\n",
            "Epoch 2292/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.1287 - val_loss: 3.8599\n",
            "Epoch 2293/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.1272 - val_loss: 3.8595\n",
            "Epoch 2294/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.1257 - val_loss: 3.8592\n",
            "Epoch 2295/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.1243 - val_loss: 3.8587\n",
            "Epoch 2296/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.1225 - val_loss: 3.8584\n",
            "Epoch 2297/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.1210 - val_loss: 3.8582\n",
            "Epoch 2298/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 2.1192 - val_loss: 3.8583\n",
            "Epoch 2299/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 2.1178 - val_loss: 3.8585\n",
            "Epoch 2300/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 2.1166 - val_loss: 3.8583\n",
            "Epoch 2301/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 2.1149 - val_loss: 3.8580\n",
            "Epoch 2302/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.1131 - val_loss: 3.8571\n",
            "Epoch 2303/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.1116 - val_loss: 3.8557\n",
            "Epoch 2304/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.1099 - val_loss: 3.8552\n",
            "Epoch 2305/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 2.1084 - val_loss: 3.8544\n",
            "Epoch 2306/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 2.1069 - val_loss: 3.8546\n",
            "Epoch 2307/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 2.1051 - val_loss: 3.8545\n",
            "Epoch 2308/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.1037 - val_loss: 3.8543\n",
            "Epoch 2309/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.1020 - val_loss: 3.8538\n",
            "Epoch 2310/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.1006 - val_loss: 3.8528\n",
            "Epoch 2311/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 2.0988 - val_loss: 3.8531\n",
            "Epoch 2312/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 2.0973 - val_loss: 3.8528\n",
            "Epoch 2313/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 2.0962 - val_loss: 3.8534\n",
            "Epoch 2314/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 2.0941 - val_loss: 3.8536\n",
            "Epoch 2315/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 2.0927 - val_loss: 3.8533\n",
            "Epoch 2316/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 2.0912 - val_loss: 3.8515\n",
            "Epoch 2317/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.0899 - val_loss: 3.8510\n",
            "Epoch 2318/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.0881 - val_loss: 3.8510\n",
            "Epoch 2319/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 2.0862 - val_loss: 3.8510\n",
            "Epoch 2320/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.0848 - val_loss: 3.8504\n",
            "Epoch 2321/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.0836 - val_loss: 3.8489\n",
            "Epoch 2322/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.0816 - val_loss: 3.8484\n",
            "Epoch 2323/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 2.0803 - val_loss: 3.8487\n",
            "Epoch 2324/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.0785 - val_loss: 3.8481\n",
            "Epoch 2325/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 2.0769 - val_loss: 3.8477\n",
            "Epoch 2326/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.0754 - val_loss: 3.8472\n",
            "Epoch 2327/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 2.0737 - val_loss: 3.8474\n",
            "Epoch 2328/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 2.0723 - val_loss: 3.8466\n",
            "Epoch 2329/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.0710 - val_loss: 3.8463\n",
            "Epoch 2330/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.0693 - val_loss: 3.8458\n",
            "Epoch 2331/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.0678 - val_loss: 3.8454\n",
            "Epoch 2332/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.0662 - val_loss: 3.8446\n",
            "Epoch 2333/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.0645 - val_loss: 3.8443\n",
            "Epoch 2334/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 2.0630 - val_loss: 3.8444\n",
            "Epoch 2335/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 2.0615 - val_loss: 3.8442\n",
            "Epoch 2336/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.0602 - val_loss: 3.8439\n",
            "Epoch 2337/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.0584 - val_loss: 3.8429\n",
            "Epoch 2338/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 2.0568 - val_loss: 3.8430\n",
            "Epoch 2339/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.0556 - val_loss: 3.8423\n",
            "Epoch 2340/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.0539 - val_loss: 3.8418\n",
            "Epoch 2341/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 2.0524 - val_loss: 3.8419\n",
            "Epoch 2342/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 2.0507 - val_loss: 3.8420\n",
            "Epoch 2343/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.0496 - val_loss: 3.8416\n",
            "Epoch 2344/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 2.0478 - val_loss: 3.8416\n",
            "Epoch 2345/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.0462 - val_loss: 3.8404\n",
            "Epoch 2346/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 2.0447 - val_loss: 3.8400\n",
            "Epoch 2347/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.0432 - val_loss: 3.8399\n",
            "Epoch 2348/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.0416 - val_loss: 3.8395\n",
            "Epoch 2349/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.0404 - val_loss: 3.8387\n",
            "Epoch 2350/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 2.0385 - val_loss: 3.8387\n",
            "Epoch 2351/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.0370 - val_loss: 3.8385\n",
            "Epoch 2352/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.0354 - val_loss: 3.8376\n",
            "Epoch 2353/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.0340 - val_loss: 3.8370\n",
            "Epoch 2354/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 2.0324 - val_loss: 3.8372\n",
            "Epoch 2355/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 2.0309 - val_loss: 3.8362\n",
            "Epoch 2356/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.0295 - val_loss: 3.8360\n",
            "Epoch 2357/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.0280 - val_loss: 3.8356\n",
            "Epoch 2358/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.0266 - val_loss: 3.8353\n",
            "Epoch 2359/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 2.0249 - val_loss: 3.8356\n",
            "Epoch 2360/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 2.0234 - val_loss: 3.8359\n",
            "Epoch 2361/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.0220 - val_loss: 3.8353\n",
            "Epoch 2362/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 2.0204 - val_loss: 3.8349\n",
            "Epoch 2363/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.0191 - val_loss: 3.8346\n",
            "Epoch 2364/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.0174 - val_loss: 3.8342\n",
            "Epoch 2365/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.0159 - val_loss: 3.8340\n",
            "Epoch 2366/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 2.0144 - val_loss: 3.8331\n",
            "Epoch 2367/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.0129 - val_loss: 3.8330\n",
            "Epoch 2368/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 2.0117 - val_loss: 3.8334\n",
            "Epoch 2369/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 2.0099 - val_loss: 3.8336\n",
            "Epoch 2370/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 2.0087 - val_loss: 3.8335\n",
            "Epoch 2371/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 2.0070 - val_loss: 3.8341\n",
            "Epoch 2372/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.0061 - val_loss: 3.8329\n",
            "Epoch 2373/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.0043 - val_loss: 3.8319\n",
            "Epoch 2374/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 2.0026 - val_loss: 3.8326\n",
            "Epoch 2375/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 2.0014 - val_loss: 3.8323\n",
            "Epoch 2376/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.9998 - val_loss: 3.8319\n",
            "Epoch 2377/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.9985 - val_loss: 3.8321\n",
            "Epoch 2378/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.9971 - val_loss: 3.8321\n",
            "Epoch 2379/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.9955 - val_loss: 3.8320\n",
            "Epoch 2380/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.9945 - val_loss: 3.8317\n",
            "Epoch 2381/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.9933 - val_loss: 3.8308\n",
            "Epoch 2382/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.9917 - val_loss: 3.8307\n",
            "Epoch 2383/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.9902 - val_loss: 3.8307\n",
            "Epoch 2384/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.9887 - val_loss: 3.8301\n",
            "Epoch 2385/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.9871 - val_loss: 3.8295\n",
            "Epoch 2386/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.9859 - val_loss: 3.8297\n",
            "Epoch 2387/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.9849 - val_loss: 3.8300\n",
            "Epoch 2388/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.9832 - val_loss: 3.8298\n",
            "Epoch 2389/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.9817 - val_loss: 3.8296\n",
            "Epoch 2390/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.9802 - val_loss: 3.8291\n",
            "Epoch 2391/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.9788 - val_loss: 3.8288\n",
            "Epoch 2392/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.9773 - val_loss: 3.8286\n",
            "Epoch 2393/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.9760 - val_loss: 3.8287\n",
            "Epoch 2394/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.9745 - val_loss: 3.8287\n",
            "Epoch 2395/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.9731 - val_loss: 3.8279\n",
            "Epoch 2396/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.9717 - val_loss: 3.8277\n",
            "Epoch 2397/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.9704 - val_loss: 3.8282\n",
            "Epoch 2398/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.9689 - val_loss: 3.8279\n",
            "Epoch 2399/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.9675 - val_loss: 3.8281\n",
            "Epoch 2400/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.9662 - val_loss: 3.8271\n",
            "Epoch 2401/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.9648 - val_loss: 3.8271\n",
            "Epoch 2402/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.9633 - val_loss: 3.8273\n",
            "Epoch 2403/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.9619 - val_loss: 3.8272\n",
            "Epoch 2404/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.9607 - val_loss: 3.8279\n",
            "Epoch 2405/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.9593 - val_loss: 3.8274\n",
            "Epoch 2406/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.9581 - val_loss: 3.8271\n",
            "Epoch 2407/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.9568 - val_loss: 3.8271\n",
            "Epoch 2408/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.9553 - val_loss: 3.8278\n",
            "Epoch 2409/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.9539 - val_loss: 3.8274\n",
            "Epoch 2410/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.9525 - val_loss: 3.8264\n",
            "Epoch 2411/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.9512 - val_loss: 3.8268\n",
            "Epoch 2412/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.9496 - val_loss: 3.8265\n",
            "Epoch 2413/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.9486 - val_loss: 3.8259\n",
            "Epoch 2414/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.9469 - val_loss: 3.8263\n",
            "Epoch 2415/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.9455 - val_loss: 3.8265\n",
            "Epoch 2416/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.9443 - val_loss: 3.8266\n",
            "Epoch 2417/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.9428 - val_loss: 3.8256\n",
            "Epoch 2418/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.9415 - val_loss: 3.8258\n",
            "Epoch 2419/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.9403 - val_loss: 3.8253\n",
            "Epoch 2420/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.9387 - val_loss: 3.8255\n",
            "Epoch 2421/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.9374 - val_loss: 3.8252\n",
            "Epoch 2422/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.9361 - val_loss: 3.8251\n",
            "Epoch 2423/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.9349 - val_loss: 3.8248\n",
            "Epoch 2424/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.9333 - val_loss: 3.8236\n",
            "Epoch 2425/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.9322 - val_loss: 3.8237\n",
            "Epoch 2426/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.9310 - val_loss: 3.8238\n",
            "Epoch 2427/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.9290 - val_loss: 3.8240\n",
            "Epoch 2428/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.9278 - val_loss: 3.8237\n",
            "Epoch 2429/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.9265 - val_loss: 3.8241\n",
            "Epoch 2430/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.9251 - val_loss: 3.8235\n",
            "Epoch 2431/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.9239 - val_loss: 3.8233\n",
            "Epoch 2432/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.9226 - val_loss: 3.8237\n",
            "Epoch 2433/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.9212 - val_loss: 3.8232\n",
            "Epoch 2434/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.9197 - val_loss: 3.8234\n",
            "Epoch 2435/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.9187 - val_loss: 3.8240\n",
            "Epoch 2436/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.9171 - val_loss: 3.8239\n",
            "Epoch 2437/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.9158 - val_loss: 3.8233\n",
            "Epoch 2438/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.9147 - val_loss: 3.8230\n",
            "Epoch 2439/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.9136 - val_loss: 3.8240\n",
            "Epoch 2440/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.9120 - val_loss: 3.8240\n",
            "Epoch 2441/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.9107 - val_loss: 3.8244\n",
            "Epoch 2442/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.9094 - val_loss: 3.8243\n",
            "Epoch 2443/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.9079 - val_loss: 3.8241\n",
            "Epoch 2444/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.9068 - val_loss: 3.8233\n",
            "Epoch 2445/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.9054 - val_loss: 3.8232\n",
            "Epoch 2446/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.9042 - val_loss: 3.8231\n",
            "Epoch 2447/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.9028 - val_loss: 3.8230\n",
            "Epoch 2448/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.9015 - val_loss: 3.8226\n",
            "Epoch 2449/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.9003 - val_loss: 3.8226\n",
            "Epoch 2450/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.8989 - val_loss: 3.8229\n",
            "Epoch 2451/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.8976 - val_loss: 3.8231\n",
            "Epoch 2452/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.8964 - val_loss: 3.8232\n",
            "Epoch 2453/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.8951 - val_loss: 3.8233\n",
            "Epoch 2454/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.8939 - val_loss: 3.8230\n",
            "Epoch 2455/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.8925 - val_loss: 3.8230\n",
            "Epoch 2456/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.8915 - val_loss: 3.8223\n",
            "Epoch 2457/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.8899 - val_loss: 3.8227\n",
            "Epoch 2458/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.8885 - val_loss: 3.8225\n",
            "Epoch 2459/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.8873 - val_loss: 3.8221\n",
            "Epoch 2460/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.8860 - val_loss: 3.8219\n",
            "Epoch 2461/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.8846 - val_loss: 3.8222\n",
            "Epoch 2462/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.8837 - val_loss: 3.8222\n",
            "Epoch 2463/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.8822 - val_loss: 3.8225\n",
            "Epoch 2464/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.8810 - val_loss: 3.8229\n",
            "Epoch 2465/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.8797 - val_loss: 3.8218\n",
            "Epoch 2466/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.8783 - val_loss: 3.8226\n",
            "Epoch 2467/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.8769 - val_loss: 3.8229\n",
            "Epoch 2468/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.8759 - val_loss: 3.8230\n",
            "Epoch 2469/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.8746 - val_loss: 3.8230\n",
            "Epoch 2470/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.8732 - val_loss: 3.8222\n",
            "Epoch 2471/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.8720 - val_loss: 3.8221\n",
            "Epoch 2472/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.8707 - val_loss: 3.8221\n",
            "Epoch 2473/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.8694 - val_loss: 3.8225\n",
            "Epoch 2474/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.8683 - val_loss: 3.8226\n",
            "Epoch 2475/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.8670 - val_loss: 3.8230\n",
            "Epoch 2476/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.8657 - val_loss: 3.8224\n",
            "Epoch 2477/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.8643 - val_loss: 3.8226\n",
            "Epoch 2478/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.8630 - val_loss: 3.8224\n",
            "Epoch 2479/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.8619 - val_loss: 3.8230\n",
            "Epoch 2480/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.8606 - val_loss: 3.8225\n",
            "Epoch 2481/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.8593 - val_loss: 3.8219\n",
            "Epoch 2482/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.8581 - val_loss: 3.8226\n",
            "Epoch 2483/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.8569 - val_loss: 3.8229\n",
            "Epoch 2484/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.8557 - val_loss: 3.8229\n",
            "Epoch 2485/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.8542 - val_loss: 3.8232\n",
            "Epoch 2486/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.8533 - val_loss: 3.8224\n",
            "Epoch 2487/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.8519 - val_loss: 3.8223\n",
            "Epoch 2488/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.8505 - val_loss: 3.8216\n",
            "Epoch 2489/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.8492 - val_loss: 3.8216\n",
            "Epoch 2490/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.8482 - val_loss: 3.8224\n",
            "Epoch 2491/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.8468 - val_loss: 3.8221\n",
            "Epoch 2492/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.8454 - val_loss: 3.8216\n",
            "Epoch 2493/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.8442 - val_loss: 3.8216\n",
            "Epoch 2494/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.8431 - val_loss: 3.8219\n",
            "Epoch 2495/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.8420 - val_loss: 3.8219\n",
            "Epoch 2496/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.8404 - val_loss: 3.8217\n",
            "Epoch 2497/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.8391 - val_loss: 3.8213\n",
            "Epoch 2498/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.8378 - val_loss: 3.8211\n",
            "Epoch 2499/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.8366 - val_loss: 3.8215\n",
            "Epoch 2500/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.8353 - val_loss: 3.8216\n",
            "Epoch 2501/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.8342 - val_loss: 3.8219\n",
            "Epoch 2502/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.8328 - val_loss: 3.8216\n",
            "Epoch 2503/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.8316 - val_loss: 3.8214\n",
            "Epoch 2504/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.8304 - val_loss: 3.8227\n",
            "Epoch 2505/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.8294 - val_loss: 3.8227\n",
            "Epoch 2506/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.8280 - val_loss: 3.8226\n",
            "Epoch 2507/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.8268 - val_loss: 3.8230\n",
            "Epoch 2508/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.8256 - val_loss: 3.8233\n",
            "Epoch 2509/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.8243 - val_loss: 3.8231\n",
            "Epoch 2510/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.8234 - val_loss: 3.8223\n",
            "Epoch 2511/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.8220 - val_loss: 3.8228\n",
            "Epoch 2512/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.8206 - val_loss: 3.8229\n",
            "Epoch 2513/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.8197 - val_loss: 3.8224\n",
            "Epoch 2514/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.8184 - val_loss: 3.8226\n",
            "Epoch 2515/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.8171 - val_loss: 3.8227\n",
            "Epoch 2516/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.8158 - val_loss: 3.8232\n",
            "Epoch 2517/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.8144 - val_loss: 3.8230\n",
            "Epoch 2518/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.8132 - val_loss: 3.8219\n",
            "Epoch 2519/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.8122 - val_loss: 3.8218\n",
            "Epoch 2520/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.8109 - val_loss: 3.8223\n",
            "Epoch 2521/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.8097 - val_loss: 3.8224\n",
            "Epoch 2522/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.8085 - val_loss: 3.8222\n",
            "Epoch 2523/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.8071 - val_loss: 3.8225\n",
            "Epoch 2524/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.8060 - val_loss: 3.8216\n",
            "Epoch 2525/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.8048 - val_loss: 3.8212\n",
            "Epoch 2526/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.8035 - val_loss: 3.8225\n",
            "Epoch 2527/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.8024 - val_loss: 3.8223\n",
            "Epoch 2528/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.8011 - val_loss: 3.8223\n",
            "Epoch 2529/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.8000 - val_loss: 3.8223\n",
            "Epoch 2530/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.7988 - val_loss: 3.8220\n",
            "Epoch 2531/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.7974 - val_loss: 3.8221\n",
            "Epoch 2532/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.7966 - val_loss: 3.8219\n",
            "Epoch 2533/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.7951 - val_loss: 3.8223\n",
            "Epoch 2534/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.7939 - val_loss: 3.8215\n",
            "Epoch 2535/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.7927 - val_loss: 3.8216\n",
            "Epoch 2536/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.7917 - val_loss: 3.8224\n",
            "Epoch 2537/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.7904 - val_loss: 3.8224\n",
            "Epoch 2538/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.7891 - val_loss: 3.8219\n",
            "Epoch 2539/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.7881 - val_loss: 3.8216\n",
            "Epoch 2540/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.7869 - val_loss: 3.8215\n",
            "Epoch 2541/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.7855 - val_loss: 3.8221\n",
            "Epoch 2542/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.7844 - val_loss: 3.8223\n",
            "Epoch 2543/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.7832 - val_loss: 3.8225\n",
            "Epoch 2544/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.7821 - val_loss: 3.8219\n",
            "Epoch 2545/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.7811 - val_loss: 3.8213\n",
            "Epoch 2546/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.7797 - val_loss: 3.8216\n",
            "Epoch 2547/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.7785 - val_loss: 3.8213\n",
            "Epoch 2548/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.7773 - val_loss: 3.8211\n",
            "Epoch 2549/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.7763 - val_loss: 3.8217\n",
            "Epoch 2550/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.7750 - val_loss: 3.8216\n",
            "Epoch 2551/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.7739 - val_loss: 3.8217\n",
            "Epoch 2552/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.7728 - val_loss: 3.8228\n",
            "Epoch 2553/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.7715 - val_loss: 3.8233\n",
            "Epoch 2554/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.7704 - val_loss: 3.8232\n",
            "Epoch 2555/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.7692 - val_loss: 3.8223\n",
            "Epoch 2556/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.7681 - val_loss: 3.8233\n",
            "Epoch 2557/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.7670 - val_loss: 3.8227\n",
            "Epoch 2558/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.7656 - val_loss: 3.8225\n",
            "Epoch 2559/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.7645 - val_loss: 3.8230\n",
            "Epoch 2560/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.7632 - val_loss: 3.8229\n",
            "Epoch 2561/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.7620 - val_loss: 3.8223\n",
            "Epoch 2562/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.7611 - val_loss: 3.8226\n",
            "Epoch 2563/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.7599 - val_loss: 3.8227\n",
            "Epoch 2564/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.7586 - val_loss: 3.8230\n",
            "Epoch 2565/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.7575 - val_loss: 3.8227\n",
            "Epoch 2566/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.7562 - val_loss: 3.8222\n",
            "Epoch 2567/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.7550 - val_loss: 3.8219\n",
            "Epoch 2568/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.7540 - val_loss: 3.8223\n",
            "Epoch 2569/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.7527 - val_loss: 3.8225\n",
            "Epoch 2570/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.7517 - val_loss: 3.8234\n",
            "Epoch 2571/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.7505 - val_loss: 3.8236\n",
            "Epoch 2572/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.7492 - val_loss: 3.8230\n",
            "Epoch 2573/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.7481 - val_loss: 3.8231\n",
            "Epoch 2574/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.7470 - val_loss: 3.8226\n",
            "Epoch 2575/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.7461 - val_loss: 3.8223\n",
            "Epoch 2576/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.7449 - val_loss: 3.8224\n",
            "Epoch 2577/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.7436 - val_loss: 3.8239\n",
            "Epoch 2578/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.7426 - val_loss: 3.8242\n",
            "Epoch 2579/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.7415 - val_loss: 3.8233\n",
            "Epoch 2580/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.7402 - val_loss: 3.8232\n",
            "Epoch 2581/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.7390 - val_loss: 3.8239\n",
            "Epoch 2582/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.7379 - val_loss: 3.8233\n",
            "Epoch 2583/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.7367 - val_loss: 3.8227\n",
            "Epoch 2584/5000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.7355 - val_loss: 3.8222\n",
            "Epoch 2585/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.7344 - val_loss: 3.8220\n",
            "Epoch 2586/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.7333 - val_loss: 3.8217\n",
            "Epoch 2587/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.7322 - val_loss: 3.8218\n",
            "Epoch 2588/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.7309 - val_loss: 3.8215\n",
            "Epoch 2589/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.7297 - val_loss: 3.8214\n",
            "Epoch 2590/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.7287 - val_loss: 3.8231\n",
            "Epoch 2591/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.7275 - val_loss: 3.8236\n",
            "Epoch 2592/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.7264 - val_loss: 3.8238\n",
            "Epoch 2593/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.7254 - val_loss: 3.8233\n",
            "Epoch 2594/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.7243 - val_loss: 3.8227\n",
            "Epoch 2595/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.7230 - val_loss: 3.8225\n",
            "Epoch 2596/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.7221 - val_loss: 3.8231\n",
            "Epoch 2597/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.7208 - val_loss: 3.8231\n",
            "Epoch 2598/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.7198 - val_loss: 3.8234\n",
            "Epoch 2599/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.7187 - val_loss: 3.8231\n",
            "Epoch 2600/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.7175 - val_loss: 3.8232\n",
            "Epoch 2601/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.7164 - val_loss: 3.8231\n",
            "Epoch 2602/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.7153 - val_loss: 3.8234\n",
            "Epoch 2603/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.7142 - val_loss: 3.8232\n",
            "Epoch 2604/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.7131 - val_loss: 3.8235\n",
            "Epoch 2605/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.7119 - val_loss: 3.8238\n",
            "Epoch 2606/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.7110 - val_loss: 3.8248\n",
            "Epoch 2607/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.7097 - val_loss: 3.8253\n",
            "Epoch 2608/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.7087 - val_loss: 3.8244\n",
            "Epoch 2609/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.7074 - val_loss: 3.8243\n",
            "Epoch 2610/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.7064 - val_loss: 3.8245\n",
            "Epoch 2611/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.7054 - val_loss: 3.8250\n",
            "Epoch 2612/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.7042 - val_loss: 3.8252\n",
            "Epoch 2613/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.7030 - val_loss: 3.8254\n",
            "Epoch 2614/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.7019 - val_loss: 3.8257\n",
            "Epoch 2615/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.7008 - val_loss: 3.8251\n",
            "Epoch 2616/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.6999 - val_loss: 3.8252\n",
            "Epoch 2617/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.6985 - val_loss: 3.8256\n",
            "Epoch 2618/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.6976 - val_loss: 3.8252\n",
            "Epoch 2619/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.6962 - val_loss: 3.8250\n",
            "Epoch 2620/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.6951 - val_loss: 3.8255\n",
            "Epoch 2621/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.6941 - val_loss: 3.8261\n",
            "Epoch 2622/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.6929 - val_loss: 3.8262\n",
            "Epoch 2623/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.6918 - val_loss: 3.8262\n",
            "Epoch 2624/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.6908 - val_loss: 3.8268\n",
            "Epoch 2625/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.6896 - val_loss: 3.8268\n",
            "Epoch 2626/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.6885 - val_loss: 3.8271\n",
            "Epoch 2627/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.6875 - val_loss: 3.8266\n",
            "Epoch 2628/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.6864 - val_loss: 3.8263\n",
            "Epoch 2629/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.6854 - val_loss: 3.8269\n",
            "Epoch 2630/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.6843 - val_loss: 3.8269\n",
            "Epoch 2631/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.6830 - val_loss: 3.8280\n",
            "Epoch 2632/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.6821 - val_loss: 3.8284\n",
            "Epoch 2633/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.6809 - val_loss: 3.8287\n",
            "Epoch 2634/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.6798 - val_loss: 3.8283\n",
            "Epoch 2635/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.6786 - val_loss: 3.8292\n",
            "Epoch 2636/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.6777 - val_loss: 3.8300\n",
            "Epoch 2637/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.6766 - val_loss: 3.8292\n",
            "Epoch 2638/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.6756 - val_loss: 3.8295\n",
            "Epoch 2639/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.6747 - val_loss: 3.8295\n",
            "Epoch 2640/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.6732 - val_loss: 3.8307\n",
            "Epoch 2641/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.6722 - val_loss: 3.8302\n",
            "Epoch 2642/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.6711 - val_loss: 3.8303\n",
            "Epoch 2643/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.6699 - val_loss: 3.8303\n",
            "Epoch 2644/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.6691 - val_loss: 3.8300\n",
            "Epoch 2645/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.6677 - val_loss: 3.8297\n",
            "Epoch 2646/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.6667 - val_loss: 3.8303\n",
            "Epoch 2647/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.6658 - val_loss: 3.8308\n",
            "Epoch 2648/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.6646 - val_loss: 3.8308\n",
            "Epoch 2649/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.6636 - val_loss: 3.8305\n",
            "Epoch 2650/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.6626 - val_loss: 3.8315\n",
            "Epoch 2651/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.6615 - val_loss: 3.8315\n",
            "Epoch 2652/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.6603 - val_loss: 3.8308\n",
            "Epoch 2653/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.6592 - val_loss: 3.8304\n",
            "Epoch 2654/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.6582 - val_loss: 3.8305\n",
            "Epoch 2655/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.6571 - val_loss: 3.8308\n",
            "Epoch 2656/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.6561 - val_loss: 3.8310\n",
            "Epoch 2657/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.6551 - val_loss: 3.8308\n",
            "Epoch 2658/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.6540 - val_loss: 3.8311\n",
            "Epoch 2659/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.6531 - val_loss: 3.8320\n",
            "Epoch 2660/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.6521 - val_loss: 3.8323\n",
            "Epoch 2661/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.6507 - val_loss: 3.8306\n",
            "Epoch 2662/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.6496 - val_loss: 3.8302\n",
            "Epoch 2663/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.6486 - val_loss: 3.8304\n",
            "Epoch 2664/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.6476 - val_loss: 3.8312\n",
            "Epoch 2665/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.6466 - val_loss: 3.8323\n",
            "Epoch 2666/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.6457 - val_loss: 3.8329\n",
            "Epoch 2667/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.6444 - val_loss: 3.8329\n",
            "Epoch 2668/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.6435 - val_loss: 3.8315\n",
            "Epoch 2669/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.6425 - val_loss: 3.8311\n",
            "Epoch 2670/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.6413 - val_loss: 3.8324\n",
            "Epoch 2671/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.6404 - val_loss: 3.8331\n",
            "Epoch 2672/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.6392 - val_loss: 3.8333\n",
            "Epoch 2673/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.6385 - val_loss: 3.8335\n",
            "Epoch 2674/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.6372 - val_loss: 3.8331\n",
            "Epoch 2675/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.6363 - val_loss: 3.8331\n",
            "Epoch 2676/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.6352 - val_loss: 3.8329\n",
            "Epoch 2677/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.6341 - val_loss: 3.8334\n",
            "Epoch 2678/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.6330 - val_loss: 3.8331\n",
            "Epoch 2679/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.6321 - val_loss: 3.8340\n",
            "Epoch 2680/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.6311 - val_loss: 3.8346\n",
            "Epoch 2681/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.6300 - val_loss: 3.8341\n",
            "Epoch 2682/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.6290 - val_loss: 3.8344\n",
            "Epoch 2683/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.6280 - val_loss: 3.8335\n",
            "Epoch 2684/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.6269 - val_loss: 3.8335\n",
            "Epoch 2685/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.6259 - val_loss: 3.8344\n",
            "Epoch 2686/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.6249 - val_loss: 3.8345\n",
            "Epoch 2687/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.6239 - val_loss: 3.8343\n",
            "Epoch 2688/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.6228 - val_loss: 3.8349\n",
            "Epoch 2689/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.6219 - val_loss: 3.8357\n",
            "Epoch 2690/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.6211 - val_loss: 3.8365\n",
            "Epoch 2691/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.6198 - val_loss: 3.8361\n",
            "Epoch 2692/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.6189 - val_loss: 3.8361\n",
            "Epoch 2693/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.6178 - val_loss: 3.8364\n",
            "Epoch 2694/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.6168 - val_loss: 3.8375\n",
            "Epoch 2695/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.6157 - val_loss: 3.8390\n",
            "Epoch 2696/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.6147 - val_loss: 3.8384\n",
            "Epoch 2697/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.6137 - val_loss: 3.8397\n",
            "Epoch 2698/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.6125 - val_loss: 3.8402\n",
            "Epoch 2699/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.6116 - val_loss: 3.8396\n",
            "Epoch 2700/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.6107 - val_loss: 3.8400\n",
            "Epoch 2701/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.6096 - val_loss: 3.8400\n",
            "Epoch 2702/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.6088 - val_loss: 3.8403\n",
            "Epoch 2703/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.6079 - val_loss: 3.8400\n",
            "Epoch 2704/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.6068 - val_loss: 3.8399\n",
            "Epoch 2705/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.6058 - val_loss: 3.8402\n",
            "Epoch 2706/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.6048 - val_loss: 3.8406\n",
            "Epoch 2707/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.6039 - val_loss: 3.8411\n",
            "Epoch 2708/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.6027 - val_loss: 3.8414\n",
            "Epoch 2709/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.6019 - val_loss: 3.8411\n",
            "Epoch 2710/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.6008 - val_loss: 3.8417\n",
            "Epoch 2711/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.5999 - val_loss: 3.8421\n",
            "Epoch 2712/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.5989 - val_loss: 3.8422\n",
            "Epoch 2713/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.5980 - val_loss: 3.8425\n",
            "Epoch 2714/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.5972 - val_loss: 3.8432\n",
            "Epoch 2715/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.5961 - val_loss: 3.8437\n",
            "Epoch 2716/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.5953 - val_loss: 3.8432\n",
            "Epoch 2717/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.5945 - val_loss: 3.8440\n",
            "Epoch 2718/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.5934 - val_loss: 3.8448\n",
            "Epoch 2719/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.5925 - val_loss: 3.8444\n",
            "Epoch 2720/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.5915 - val_loss: 3.8450\n",
            "Epoch 2721/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.5905 - val_loss: 3.8459\n",
            "Epoch 2722/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.5902 - val_loss: 3.8457\n",
            "Epoch 2723/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.5886 - val_loss: 3.8468\n",
            "Epoch 2724/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.5877 - val_loss: 3.8466\n",
            "Epoch 2725/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.5867 - val_loss: 3.8463\n",
            "Epoch 2726/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.5858 - val_loss: 3.8470\n",
            "Epoch 2727/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.5849 - val_loss: 3.8473\n",
            "Epoch 2728/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.5840 - val_loss: 3.8482\n",
            "Epoch 2729/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.5829 - val_loss: 3.8488\n",
            "Epoch 2730/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.5821 - val_loss: 3.8498\n",
            "Epoch 2731/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.5814 - val_loss: 3.8506\n",
            "Epoch 2732/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.5803 - val_loss: 3.8517\n",
            "Epoch 2733/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.5793 - val_loss: 3.8520\n",
            "Epoch 2734/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.5782 - val_loss: 3.8515\n",
            "Epoch 2735/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.5776 - val_loss: 3.8514\n",
            "Epoch 2736/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.5766 - val_loss: 3.8526\n",
            "Epoch 2737/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.5756 - val_loss: 3.8527\n",
            "Epoch 2738/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.5746 - val_loss: 3.8523\n",
            "Epoch 2739/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.5737 - val_loss: 3.8524\n",
            "Epoch 2740/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.5727 - val_loss: 3.8530\n",
            "Epoch 2741/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.5719 - val_loss: 3.8538\n",
            "Epoch 2742/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.5711 - val_loss: 3.8546\n",
            "Epoch 2743/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.5698 - val_loss: 3.8548\n",
            "Epoch 2744/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.5689 - val_loss: 3.8557\n",
            "Epoch 2745/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.5681 - val_loss: 3.8565\n",
            "Epoch 2746/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.5672 - val_loss: 3.8570\n",
            "Epoch 2747/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.5662 - val_loss: 3.8569\n",
            "Epoch 2748/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.5652 - val_loss: 3.8578\n",
            "Epoch 2749/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.5644 - val_loss: 3.8585\n",
            "Epoch 2750/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.5634 - val_loss: 3.8596\n",
            "Epoch 2751/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.5625 - val_loss: 3.8601\n",
            "Epoch 2752/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.5617 - val_loss: 3.8607\n",
            "Epoch 2753/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.5611 - val_loss: 3.8615\n",
            "Epoch 2754/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.5599 - val_loss: 3.8623\n",
            "Epoch 2755/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.5589 - val_loss: 3.8623\n",
            "Epoch 2756/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.5581 - val_loss: 3.8611\n",
            "Epoch 2757/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.5571 - val_loss: 3.8614\n",
            "Epoch 2758/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.5562 - val_loss: 3.8624\n",
            "Epoch 2759/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.5553 - val_loss: 3.8631\n",
            "Epoch 2760/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.5544 - val_loss: 3.8636\n",
            "Epoch 2761/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.5534 - val_loss: 3.8634\n",
            "Epoch 2762/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.5525 - val_loss: 3.8640\n",
            "Epoch 2763/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.5517 - val_loss: 3.8642\n",
            "Epoch 2764/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.5508 - val_loss: 3.8649\n",
            "Epoch 2765/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.5499 - val_loss: 3.8660\n",
            "Epoch 2766/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.5490 - val_loss: 3.8661\n",
            "Epoch 2767/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.5482 - val_loss: 3.8662\n",
            "Epoch 2768/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.5473 - val_loss: 3.8679\n",
            "Epoch 2769/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.5464 - val_loss: 3.8685\n",
            "Epoch 2770/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.5454 - val_loss: 3.8693\n",
            "Epoch 2771/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.5445 - val_loss: 3.8701\n",
            "Epoch 2772/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.5436 - val_loss: 3.8708\n",
            "Epoch 2773/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.5428 - val_loss: 3.8707\n",
            "Epoch 2774/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.5418 - val_loss: 3.8704\n",
            "Epoch 2775/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.5409 - val_loss: 3.8721\n",
            "Epoch 2776/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.5402 - val_loss: 3.8734\n",
            "Epoch 2777/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.5392 - val_loss: 3.8736\n",
            "Epoch 2778/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.5383 - val_loss: 3.8746\n",
            "Epoch 2779/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.5374 - val_loss: 3.8749\n",
            "Epoch 2780/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.5367 - val_loss: 3.8757\n",
            "Epoch 2781/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.5357 - val_loss: 3.8763\n",
            "Epoch 2782/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.5352 - val_loss: 3.8763\n",
            "Epoch 2783/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.5338 - val_loss: 3.8778\n",
            "Epoch 2784/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.5329 - val_loss: 3.8781\n",
            "Epoch 2785/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.5322 - val_loss: 3.8782\n",
            "Epoch 2786/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.5313 - val_loss: 3.8789\n",
            "Epoch 2787/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.5305 - val_loss: 3.8794\n",
            "Epoch 2788/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.5295 - val_loss: 3.8792\n",
            "Epoch 2789/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.5285 - val_loss: 3.8789\n",
            "Epoch 2790/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.5280 - val_loss: 3.8791\n",
            "Epoch 2791/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.5269 - val_loss: 3.8803\n",
            "Epoch 2792/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.5260 - val_loss: 3.8816\n",
            "Epoch 2793/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.5253 - val_loss: 3.8818\n",
            "Epoch 2794/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.5242 - val_loss: 3.8825\n",
            "Epoch 2795/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.5234 - val_loss: 3.8831\n",
            "Epoch 2796/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.5226 - val_loss: 3.8852\n",
            "Epoch 2797/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.5217 - val_loss: 3.8849\n",
            "Epoch 2798/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.5207 - val_loss: 3.8852\n",
            "Epoch 2799/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.5199 - val_loss: 3.8858\n",
            "Epoch 2800/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.5192 - val_loss: 3.8872\n",
            "Epoch 2801/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.5182 - val_loss: 3.8875\n",
            "Epoch 2802/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.5173 - val_loss: 3.8880\n",
            "Epoch 2803/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.5165 - val_loss: 3.8889\n",
            "Epoch 2804/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.5156 - val_loss: 3.8898\n",
            "Epoch 2805/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.5149 - val_loss: 3.8906\n",
            "Epoch 2806/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.5138 - val_loss: 3.8918\n",
            "Epoch 2807/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.5128 - val_loss: 3.8915\n",
            "Epoch 2808/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.5121 - val_loss: 3.8912\n",
            "Epoch 2809/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.5112 - val_loss: 3.8927\n",
            "Epoch 2810/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.5102 - val_loss: 3.8938\n",
            "Epoch 2811/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.5095 - val_loss: 3.8940\n",
            "Epoch 2812/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.5085 - val_loss: 3.8947\n",
            "Epoch 2813/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.5078 - val_loss: 3.8960\n",
            "Epoch 2814/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.5068 - val_loss: 3.8968\n",
            "Epoch 2815/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.5061 - val_loss: 3.8977\n",
            "Epoch 2816/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.5051 - val_loss: 3.8987\n",
            "Epoch 2817/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.5045 - val_loss: 3.8991\n",
            "Epoch 2818/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.5040 - val_loss: 3.8996\n",
            "Epoch 2819/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.5028 - val_loss: 3.9000\n",
            "Epoch 2820/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.5019 - val_loss: 3.9010\n",
            "Epoch 2821/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.5010 - val_loss: 3.9014\n",
            "Epoch 2822/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.5002 - val_loss: 3.9021\n",
            "Epoch 2823/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.4993 - val_loss: 3.9026\n",
            "Epoch 2824/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.4986 - val_loss: 3.9030\n",
            "Epoch 2825/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.4975 - val_loss: 3.9038\n",
            "Epoch 2826/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.4967 - val_loss: 3.9042\n",
            "Epoch 2827/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.4960 - val_loss: 3.9047\n",
            "Epoch 2828/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.4952 - val_loss: 3.9057\n",
            "Epoch 2829/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.4942 - val_loss: 3.9065\n",
            "Epoch 2830/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.4935 - val_loss: 3.9074\n",
            "Epoch 2831/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.4926 - val_loss: 3.9070\n",
            "Epoch 2832/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.4917 - val_loss: 3.9080\n",
            "Epoch 2833/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.4909 - val_loss: 3.9087\n",
            "Epoch 2834/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.4901 - val_loss: 3.9093\n",
            "Epoch 2835/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.4893 - val_loss: 3.9100\n",
            "Epoch 2836/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.4885 - val_loss: 3.9111\n",
            "Epoch 2837/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.4878 - val_loss: 3.9112\n",
            "Epoch 2838/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.4867 - val_loss: 3.9112\n",
            "Epoch 2839/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.4860 - val_loss: 3.9117\n",
            "Epoch 2840/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.4853 - val_loss: 3.9135\n",
            "Epoch 2841/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.4843 - val_loss: 3.9147\n",
            "Epoch 2842/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.4836 - val_loss: 3.9159\n",
            "Epoch 2843/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.4828 - val_loss: 3.9159\n",
            "Epoch 2844/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.4819 - val_loss: 3.9159\n",
            "Epoch 2845/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.4811 - val_loss: 3.9161\n",
            "Epoch 2846/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.4803 - val_loss: 3.9176\n",
            "Epoch 2847/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.4795 - val_loss: 3.9178\n",
            "Epoch 2848/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.4787 - val_loss: 3.9191\n",
            "Epoch 2849/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.4781 - val_loss: 3.9195\n",
            "Epoch 2850/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.4771 - val_loss: 3.9203\n",
            "Epoch 2851/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.4764 - val_loss: 3.9209\n",
            "Epoch 2852/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.4755 - val_loss: 3.9211\n",
            "Epoch 2853/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.4747 - val_loss: 3.9219\n",
            "Epoch 2854/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.4739 - val_loss: 3.9235\n",
            "Epoch 2855/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.4731 - val_loss: 3.9242\n",
            "Epoch 2856/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.4723 - val_loss: 3.9257\n",
            "Epoch 2857/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.4716 - val_loss: 3.9254\n",
            "Epoch 2858/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.4706 - val_loss: 3.9262\n",
            "Epoch 2859/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.4699 - val_loss: 3.9269\n",
            "Epoch 2860/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.4691 - val_loss: 3.9281\n",
            "Epoch 2861/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.4684 - val_loss: 3.9289\n",
            "Epoch 2862/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.4675 - val_loss: 3.9292\n",
            "Epoch 2863/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.4668 - val_loss: 3.9301\n",
            "Epoch 2864/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.4659 - val_loss: 3.9302\n",
            "Epoch 2865/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.4651 - val_loss: 3.9315\n",
            "Epoch 2866/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.4644 - val_loss: 3.9319\n",
            "Epoch 2867/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.4637 - val_loss: 3.9322\n",
            "Epoch 2868/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.4630 - val_loss: 3.9337\n",
            "Epoch 2869/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.4620 - val_loss: 3.9340\n",
            "Epoch 2870/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.4612 - val_loss: 3.9334\n",
            "Epoch 2871/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.4606 - val_loss: 3.9337\n",
            "Epoch 2872/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.4598 - val_loss: 3.9348\n",
            "Epoch 2873/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.4589 - val_loss: 3.9351\n",
            "Epoch 2874/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.4582 - val_loss: 3.9361\n",
            "Epoch 2875/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.4573 - val_loss: 3.9368\n",
            "Epoch 2876/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.4567 - val_loss: 3.9371\n",
            "Epoch 2877/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.4558 - val_loss: 3.9370\n",
            "Epoch 2878/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.4553 - val_loss: 3.9379\n",
            "Epoch 2879/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.4543 - val_loss: 3.9391\n",
            "Epoch 2880/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.4535 - val_loss: 3.9400\n",
            "Epoch 2881/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.4528 - val_loss: 3.9397\n",
            "Epoch 2882/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.4520 - val_loss: 3.9392\n",
            "Epoch 2883/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.4512 - val_loss: 3.9404\n",
            "Epoch 2884/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.4504 - val_loss: 3.9413\n",
            "Epoch 2885/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.4498 - val_loss: 3.9417\n",
            "Epoch 2886/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.4489 - val_loss: 3.9431\n",
            "Epoch 2887/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.4482 - val_loss: 3.9428\n",
            "Epoch 2888/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.4473 - val_loss: 3.9425\n",
            "Epoch 2889/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.4466 - val_loss: 3.9431\n",
            "Epoch 2890/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.4458 - val_loss: 3.9434\n",
            "Epoch 2891/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.4451 - val_loss: 3.9443\n",
            "Epoch 2892/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.4443 - val_loss: 3.9447\n",
            "Epoch 2893/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.4436 - val_loss: 3.9446\n",
            "Epoch 2894/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.4430 - val_loss: 3.9448\n",
            "Epoch 2895/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.4419 - val_loss: 3.9454\n",
            "Epoch 2896/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.4413 - val_loss: 3.9454\n",
            "Epoch 2897/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.4405 - val_loss: 3.9457\n",
            "Epoch 2898/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.4397 - val_loss: 3.9464\n",
            "Epoch 2899/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.4391 - val_loss: 3.9470\n",
            "Epoch 2900/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.4382 - val_loss: 3.9479\n",
            "Epoch 2901/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.4374 - val_loss: 3.9484\n",
            "Epoch 2902/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.4367 - val_loss: 3.9493\n",
            "Epoch 2903/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.4359 - val_loss: 3.9503\n",
            "Epoch 2904/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.4351 - val_loss: 3.9499\n",
            "Epoch 2905/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.4343 - val_loss: 3.9501\n",
            "Epoch 2906/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.4337 - val_loss: 3.9502\n",
            "Epoch 2907/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.4328 - val_loss: 3.9507\n",
            "Epoch 2908/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.4321 - val_loss: 3.9514\n",
            "Epoch 2909/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.4314 - val_loss: 3.9522\n",
            "Epoch 2910/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.4306 - val_loss: 3.9527\n",
            "Epoch 2911/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.4299 - val_loss: 3.9535\n",
            "Epoch 2912/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.4291 - val_loss: 3.9542\n",
            "Epoch 2913/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.4284 - val_loss: 3.9549\n",
            "Epoch 2914/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.4276 - val_loss: 3.9545\n",
            "Epoch 2915/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.4269 - val_loss: 3.9561\n",
            "Epoch 2916/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.4260 - val_loss: 3.9558\n",
            "Epoch 2917/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.4253 - val_loss: 3.9570\n",
            "Epoch 2918/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.4246 - val_loss: 3.9576\n",
            "Epoch 2919/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.4238 - val_loss: 3.9590\n",
            "Epoch 2920/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.4232 - val_loss: 3.9590\n",
            "Epoch 2921/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.4223 - val_loss: 3.9597\n",
            "Epoch 2922/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.4216 - val_loss: 3.9597\n",
            "Epoch 2923/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.4208 - val_loss: 3.9606\n",
            "Epoch 2924/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.4200 - val_loss: 3.9615\n",
            "Epoch 2925/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.4193 - val_loss: 3.9610\n",
            "Epoch 2926/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.4185 - val_loss: 3.9594\n",
            "Epoch 2927/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.4176 - val_loss: 3.9583\n",
            "Epoch 2928/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.4169 - val_loss: 3.9598\n",
            "Epoch 2929/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.4161 - val_loss: 3.9596\n",
            "Epoch 2930/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.4154 - val_loss: 3.9594\n",
            "Epoch 2931/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.4146 - val_loss: 3.9597\n",
            "Epoch 2932/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.4139 - val_loss: 3.9598\n",
            "Epoch 2933/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.4131 - val_loss: 3.9598\n",
            "Epoch 2934/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.4124 - val_loss: 3.9603\n",
            "Epoch 2935/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.4115 - val_loss: 3.9616\n",
            "Epoch 2936/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.4109 - val_loss: 3.9615\n",
            "Epoch 2937/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.4101 - val_loss: 3.9605\n",
            "Epoch 2938/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.4095 - val_loss: 3.9619\n",
            "Epoch 2939/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.4086 - val_loss: 3.9619\n",
            "Epoch 2940/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.4078 - val_loss: 3.9620\n",
            "Epoch 2941/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.4069 - val_loss: 3.9613\n",
            "Epoch 2942/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.4062 - val_loss: 3.9613\n",
            "Epoch 2943/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.4055 - val_loss: 3.9614\n",
            "Epoch 2944/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.4046 - val_loss: 3.9611\n",
            "Epoch 2945/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.4040 - val_loss: 3.9614\n",
            "Epoch 2946/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.4031 - val_loss: 3.9624\n",
            "Epoch 2947/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.4025 - val_loss: 3.9622\n",
            "Epoch 2948/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.4017 - val_loss: 3.9622\n",
            "Epoch 2949/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.4010 - val_loss: 3.9622\n",
            "Epoch 2950/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.4003 - val_loss: 3.9627\n",
            "Epoch 2951/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.3995 - val_loss: 3.9622\n",
            "Epoch 2952/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.3987 - val_loss: 3.9623\n",
            "Epoch 2953/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.3980 - val_loss: 3.9626\n",
            "Epoch 2954/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.3972 - val_loss: 3.9636\n",
            "Epoch 2955/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.3966 - val_loss: 3.9635\n",
            "Epoch 2956/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.3957 - val_loss: 3.9630\n",
            "Epoch 2957/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.3950 - val_loss: 3.9635\n",
            "Epoch 2958/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.3943 - val_loss: 3.9639\n",
            "Epoch 2959/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.3935 - val_loss: 3.9636\n",
            "Epoch 2960/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.3927 - val_loss: 3.9639\n",
            "Epoch 2961/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.3920 - val_loss: 3.9646\n",
            "Epoch 2962/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.3913 - val_loss: 3.9650\n",
            "Epoch 2963/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.3907 - val_loss: 3.9651\n",
            "Epoch 2964/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.3898 - val_loss: 3.9647\n",
            "Epoch 2965/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.3890 - val_loss: 3.9649\n",
            "Epoch 2966/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.3885 - val_loss: 3.9646\n",
            "Epoch 2967/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.3877 - val_loss: 3.9659\n",
            "Epoch 2968/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.3869 - val_loss: 3.9659\n",
            "Epoch 2969/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.3862 - val_loss: 3.9657\n",
            "Epoch 2970/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.3854 - val_loss: 3.9663\n",
            "Epoch 2971/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.3847 - val_loss: 3.9664\n",
            "Epoch 2972/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.3840 - val_loss: 3.9669\n",
            "Epoch 2973/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.3833 - val_loss: 3.9676\n",
            "Epoch 2974/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.3827 - val_loss: 3.9675\n",
            "Epoch 2975/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.3818 - val_loss: 3.9679\n",
            "Epoch 2976/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.3812 - val_loss: 3.9682\n",
            "Epoch 2977/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.3804 - val_loss: 3.9685\n",
            "Epoch 2978/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.3796 - val_loss: 3.9689\n",
            "Epoch 2979/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.3790 - val_loss: 3.9687\n",
            "Epoch 2980/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.3782 - val_loss: 3.9692\n",
            "Epoch 2981/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.3774 - val_loss: 3.9686\n",
            "Epoch 2982/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.3766 - val_loss: 3.9690\n",
            "Epoch 2983/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.3759 - val_loss: 3.9691\n",
            "Epoch 2984/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.3752 - val_loss: 3.9699\n",
            "Epoch 2985/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.3745 - val_loss: 3.9696\n",
            "Epoch 2986/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.3737 - val_loss: 3.9696\n",
            "Epoch 2987/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.3730 - val_loss: 3.9703\n",
            "Epoch 2988/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.3722 - val_loss: 3.9701\n",
            "Epoch 2989/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.3717 - val_loss: 3.9700\n",
            "Epoch 2990/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.3710 - val_loss: 3.9718\n",
            "Epoch 2991/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.3702 - val_loss: 3.9725\n",
            "Epoch 2992/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.3694 - val_loss: 3.9720\n",
            "Epoch 2993/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.3688 - val_loss: 3.9713\n",
            "Epoch 2994/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.3680 - val_loss: 3.9720\n",
            "Epoch 2995/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.3675 - val_loss: 3.9721\n",
            "Epoch 2996/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.3670 - val_loss: 3.9732\n",
            "Epoch 2997/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.3660 - val_loss: 3.9744\n",
            "Epoch 2998/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.3653 - val_loss: 3.9730\n",
            "Epoch 2999/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.3645 - val_loss: 3.9723\n",
            "Epoch 3000/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.3637 - val_loss: 3.9718\n",
            "Epoch 3001/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.3631 - val_loss: 3.9721\n",
            "Epoch 3002/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.3623 - val_loss: 3.9728\n",
            "Epoch 3003/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.3618 - val_loss: 3.9740\n",
            "Epoch 3004/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.3610 - val_loss: 3.9742\n",
            "Epoch 3005/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.3603 - val_loss: 3.9742\n",
            "Epoch 3006/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.3596 - val_loss: 3.9745\n",
            "Epoch 3007/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.3589 - val_loss: 3.9754\n",
            "Epoch 3008/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.3581 - val_loss: 3.9756\n",
            "Epoch 3009/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.3575 - val_loss: 3.9752\n",
            "Epoch 3010/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.3567 - val_loss: 3.9757\n",
            "Epoch 3011/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.3561 - val_loss: 3.9759\n",
            "Epoch 3012/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.3553 - val_loss: 3.9763\n",
            "Epoch 3013/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.3546 - val_loss: 3.9770\n",
            "Epoch 3014/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.3540 - val_loss: 3.9770\n",
            "Epoch 3015/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.3533 - val_loss: 3.9771\n",
            "Epoch 3016/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.3525 - val_loss: 3.9783\n",
            "Epoch 3017/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.3519 - val_loss: 3.9779\n",
            "Epoch 3018/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.3512 - val_loss: 3.9773\n",
            "Epoch 3019/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.3504 - val_loss: 3.9781\n",
            "Epoch 3020/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.3497 - val_loss: 3.9786\n",
            "Epoch 3021/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.3491 - val_loss: 3.9789\n",
            "Epoch 3022/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.3484 - val_loss: 3.9793\n",
            "Epoch 3023/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.3477 - val_loss: 3.9789\n",
            "Epoch 3024/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.3470 - val_loss: 3.9788\n",
            "Epoch 3025/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.3463 - val_loss: 3.9779\n",
            "Epoch 3026/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.3456 - val_loss: 3.9783\n",
            "Epoch 3027/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.3449 - val_loss: 3.9789\n",
            "Epoch 3028/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.3441 - val_loss: 3.9793\n",
            "Epoch 3029/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.3435 - val_loss: 3.9789\n",
            "Epoch 3030/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.3429 - val_loss: 3.9794\n",
            "Epoch 3031/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.3420 - val_loss: 3.9800\n",
            "Epoch 3032/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.3414 - val_loss: 3.9797\n",
            "Epoch 3033/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.3408 - val_loss: 3.9798\n",
            "Epoch 3034/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.3400 - val_loss: 3.9802\n",
            "Epoch 3035/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.3394 - val_loss: 3.9807\n",
            "Epoch 3036/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.3386 - val_loss: 3.9806\n",
            "Epoch 3037/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.3379 - val_loss: 3.9800\n",
            "Epoch 3038/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.3373 - val_loss: 3.9810\n",
            "Epoch 3039/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.3365 - val_loss: 3.9816\n",
            "Epoch 3040/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.3359 - val_loss: 3.9815\n",
            "Epoch 3041/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.3351 - val_loss: 3.9815\n",
            "Epoch 3042/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.3344 - val_loss: 3.9821\n",
            "Epoch 3043/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.3338 - val_loss: 3.9829\n",
            "Epoch 3044/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.3331 - val_loss: 3.9832\n",
            "Epoch 3045/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.3324 - val_loss: 3.9832\n",
            "Epoch 3046/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.3317 - val_loss: 3.9838\n",
            "Epoch 3047/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.3311 - val_loss: 3.9833\n",
            "Epoch 3048/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.3303 - val_loss: 3.9837\n",
            "Epoch 3049/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.3297 - val_loss: 3.9844\n",
            "Epoch 3050/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.3289 - val_loss: 3.9845\n",
            "Epoch 3051/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.3283 - val_loss: 3.9857\n",
            "Epoch 3052/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.3276 - val_loss: 3.9862\n",
            "Epoch 3053/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.3269 - val_loss: 3.9862\n",
            "Epoch 3054/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.3263 - val_loss: 3.9868\n",
            "Epoch 3055/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.3256 - val_loss: 3.9869\n",
            "Epoch 3056/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.3250 - val_loss: 3.9874\n",
            "Epoch 3057/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.3243 - val_loss: 3.9890\n",
            "Epoch 3058/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.3235 - val_loss: 3.9892\n",
            "Epoch 3059/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.3230 - val_loss: 3.9884\n",
            "Epoch 3060/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.3222 - val_loss: 3.9890\n",
            "Epoch 3061/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.3216 - val_loss: 3.9899\n",
            "Epoch 3062/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.3209 - val_loss: 3.9905\n",
            "Epoch 3063/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.3202 - val_loss: 3.9908\n",
            "Epoch 3064/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.3196 - val_loss: 3.9908\n",
            "Epoch 3065/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.3189 - val_loss: 3.9911\n",
            "Epoch 3066/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.3182 - val_loss: 3.9916\n",
            "Epoch 3067/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.3175 - val_loss: 3.9916\n",
            "Epoch 3068/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.3169 - val_loss: 3.9914\n",
            "Epoch 3069/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.3161 - val_loss: 3.9922\n",
            "Epoch 3070/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.3154 - val_loss: 3.9930\n",
            "Epoch 3071/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.3149 - val_loss: 3.9928\n",
            "Epoch 3072/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.3142 - val_loss: 3.9930\n",
            "Epoch 3073/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.3135 - val_loss: 3.9928\n",
            "Epoch 3074/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.3129 - val_loss: 3.9927\n",
            "Epoch 3075/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.3120 - val_loss: 3.9935\n",
            "Epoch 3076/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.3114 - val_loss: 3.9933\n",
            "Epoch 3077/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.3108 - val_loss: 3.9933\n",
            "Epoch 3078/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.3101 - val_loss: 3.9931\n",
            "Epoch 3079/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.3093 - val_loss: 3.9943\n",
            "Epoch 3080/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.3087 - val_loss: 3.9950\n",
            "Epoch 3081/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.3080 - val_loss: 3.9947\n",
            "Epoch 3082/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.3073 - val_loss: 3.9946\n",
            "Epoch 3083/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.3067 - val_loss: 3.9950\n",
            "Epoch 3084/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.3061 - val_loss: 3.9951\n",
            "Epoch 3085/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.3055 - val_loss: 3.9957\n",
            "Epoch 3086/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.3048 - val_loss: 3.9961\n",
            "Epoch 3087/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.3041 - val_loss: 3.9960\n",
            "Epoch 3088/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.3034 - val_loss: 3.9959\n",
            "Epoch 3089/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.3027 - val_loss: 3.9965\n",
            "Epoch 3090/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.3021 - val_loss: 3.9965\n",
            "Epoch 3091/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.3013 - val_loss: 3.9968\n",
            "Epoch 3092/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.3008 - val_loss: 3.9965\n",
            "Epoch 3093/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.3001 - val_loss: 3.9969\n",
            "Epoch 3094/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2994 - val_loss: 3.9964\n",
            "Epoch 3095/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2987 - val_loss: 3.9971\n",
            "Epoch 3096/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2982 - val_loss: 3.9972\n",
            "Epoch 3097/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2975 - val_loss: 3.9972\n",
            "Epoch 3098/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2968 - val_loss: 3.9976\n",
            "Epoch 3099/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2962 - val_loss: 3.9984\n",
            "Epoch 3100/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2955 - val_loss: 3.9991\n",
            "Epoch 3101/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2950 - val_loss: 3.9981\n",
            "Epoch 3102/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2942 - val_loss: 3.9986\n",
            "Epoch 3103/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2936 - val_loss: 3.9998\n",
            "Epoch 3104/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2929 - val_loss: 4.0000\n",
            "Epoch 3105/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2923 - val_loss: 3.9991\n",
            "Epoch 3106/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2916 - val_loss: 3.9990\n",
            "Epoch 3107/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2911 - val_loss: 3.9994\n",
            "Epoch 3108/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.2904 - val_loss: 3.9994\n",
            "Epoch 3109/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2896 - val_loss: 3.9994\n",
            "Epoch 3110/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.2890 - val_loss: 4.0001\n",
            "Epoch 3111/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.2886 - val_loss: 4.0021\n",
            "Epoch 3112/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.2878 - val_loss: 4.0027\n",
            "Epoch 3113/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.2871 - val_loss: 4.0022\n",
            "Epoch 3114/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.2864 - val_loss: 4.0018\n",
            "Epoch 3115/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2858 - val_loss: 4.0018\n",
            "Epoch 3116/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2852 - val_loss: 4.0024\n",
            "Epoch 3117/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.2846 - val_loss: 4.0032\n",
            "Epoch 3118/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2839 - val_loss: 4.0033\n",
            "Epoch 3119/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2832 - val_loss: 4.0039\n",
            "Epoch 3120/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2827 - val_loss: 4.0042\n",
            "Epoch 3121/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2820 - val_loss: 4.0051\n",
            "Epoch 3122/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2814 - val_loss: 4.0053\n",
            "Epoch 3123/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.2808 - val_loss: 4.0058\n",
            "Epoch 3124/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.2801 - val_loss: 4.0054\n",
            "Epoch 3125/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2794 - val_loss: 4.0057\n",
            "Epoch 3126/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2789 - val_loss: 4.0072\n",
            "Epoch 3127/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.2783 - val_loss: 4.0069\n",
            "Epoch 3128/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.2775 - val_loss: 4.0063\n",
            "Epoch 3129/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2769 - val_loss: 4.0068\n",
            "Epoch 3130/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.2764 - val_loss: 4.0082\n",
            "Epoch 3131/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2756 - val_loss: 4.0087\n",
            "Epoch 3132/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2750 - val_loss: 4.0089\n",
            "Epoch 3133/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2745 - val_loss: 4.0091\n",
            "Epoch 3134/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2738 - val_loss: 4.0099\n",
            "Epoch 3135/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2732 - val_loss: 4.0093\n",
            "Epoch 3136/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2725 - val_loss: 4.0096\n",
            "Epoch 3137/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2719 - val_loss: 4.0097\n",
            "Epoch 3138/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2712 - val_loss: 4.0098\n",
            "Epoch 3139/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2707 - val_loss: 4.0098\n",
            "Epoch 3140/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2701 - val_loss: 4.0106\n",
            "Epoch 3141/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2693 - val_loss: 4.0112\n",
            "Epoch 3142/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2687 - val_loss: 4.0115\n",
            "Epoch 3143/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2682 - val_loss: 4.0113\n",
            "Epoch 3144/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2676 - val_loss: 4.0117\n",
            "Epoch 3145/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.2669 - val_loss: 4.0117\n",
            "Epoch 3146/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2665 - val_loss: 4.0115\n",
            "Epoch 3147/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2659 - val_loss: 4.0134\n",
            "Epoch 3148/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2652 - val_loss: 4.0136\n",
            "Epoch 3149/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2645 - val_loss: 4.0130\n",
            "Epoch 3150/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2638 - val_loss: 4.0130\n",
            "Epoch 3151/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2632 - val_loss: 4.0129\n",
            "Epoch 3152/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2628 - val_loss: 4.0135\n",
            "Epoch 3153/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2620 - val_loss: 4.0145\n",
            "Epoch 3154/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2613 - val_loss: 4.0159\n",
            "Epoch 3155/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2607 - val_loss: 4.0160\n",
            "Epoch 3156/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2601 - val_loss: 4.0150\n",
            "Epoch 3157/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.2595 - val_loss: 4.0154\n",
            "Epoch 3158/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.2588 - val_loss: 4.0161\n",
            "Epoch 3159/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.2583 - val_loss: 4.0161\n",
            "Epoch 3160/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.2579 - val_loss: 4.0164\n",
            "Epoch 3161/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2570 - val_loss: 4.0163\n",
            "Epoch 3162/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2564 - val_loss: 4.0163\n",
            "Epoch 3163/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2557 - val_loss: 4.0169\n",
            "Epoch 3164/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2552 - val_loss: 4.0173\n",
            "Epoch 3165/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2545 - val_loss: 4.0178\n",
            "Epoch 3166/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2539 - val_loss: 4.0176\n",
            "Epoch 3167/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.2531 - val_loss: 4.0176\n",
            "Epoch 3168/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2526 - val_loss: 4.0176\n",
            "Epoch 3169/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2521 - val_loss: 4.0182\n",
            "Epoch 3170/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2514 - val_loss: 4.0192\n",
            "Epoch 3171/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.2506 - val_loss: 4.0195\n",
            "Epoch 3172/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2501 - val_loss: 4.0190\n",
            "Epoch 3173/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.2496 - val_loss: 4.0199\n",
            "Epoch 3174/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2490 - val_loss: 4.0207\n",
            "Epoch 3175/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2483 - val_loss: 4.0207\n",
            "Epoch 3176/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2477 - val_loss: 4.0211\n",
            "Epoch 3177/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2471 - val_loss: 4.0215\n",
            "Epoch 3178/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2464 - val_loss: 4.0223\n",
            "Epoch 3179/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2459 - val_loss: 4.0225\n",
            "Epoch 3180/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2453 - val_loss: 4.0224\n",
            "Epoch 3181/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2447 - val_loss: 4.0234\n",
            "Epoch 3182/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2441 - val_loss: 4.0239\n",
            "Epoch 3183/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2436 - val_loss: 4.0239\n",
            "Epoch 3184/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.2429 - val_loss: 4.0249\n",
            "Epoch 3185/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.2423 - val_loss: 4.0246\n",
            "Epoch 3186/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.2417 - val_loss: 4.0246\n",
            "Epoch 3187/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.2412 - val_loss: 4.0247\n",
            "Epoch 3188/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.2405 - val_loss: 4.0252\n",
            "Epoch 3189/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.2400 - val_loss: 4.0250\n",
            "Epoch 3190/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2393 - val_loss: 4.0254\n",
            "Epoch 3191/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2387 - val_loss: 4.0260\n",
            "Epoch 3192/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2382 - val_loss: 4.0262\n",
            "Epoch 3193/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.2376 - val_loss: 4.0286\n",
            "Epoch 3194/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2370 - val_loss: 4.0290\n",
            "Epoch 3195/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2363 - val_loss: 4.0286\n",
            "Epoch 3196/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.2358 - val_loss: 4.0288\n",
            "Epoch 3197/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.2351 - val_loss: 4.0288\n",
            "Epoch 3198/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2345 - val_loss: 4.0294\n",
            "Epoch 3199/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2340 - val_loss: 4.0295\n",
            "Epoch 3200/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2333 - val_loss: 4.0297\n",
            "Epoch 3201/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2328 - val_loss: 4.0303\n",
            "Epoch 3202/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2321 - val_loss: 4.0307\n",
            "Epoch 3203/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2315 - val_loss: 4.0310\n",
            "Epoch 3204/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2310 - val_loss: 4.0312\n",
            "Epoch 3205/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2304 - val_loss: 4.0317\n",
            "Epoch 3206/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2296 - val_loss: 4.0319\n",
            "Epoch 3207/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2291 - val_loss: 4.0319\n",
            "Epoch 3208/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.2286 - val_loss: 4.0328\n",
            "Epoch 3209/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.2281 - val_loss: 4.0340\n",
            "Epoch 3210/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2274 - val_loss: 4.0342\n",
            "Epoch 3211/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2267 - val_loss: 4.0346\n",
            "Epoch 3212/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2262 - val_loss: 4.0356\n",
            "Epoch 3213/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2258 - val_loss: 4.0364\n",
            "Epoch 3214/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2251 - val_loss: 4.0361\n",
            "Epoch 3215/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2244 - val_loss: 4.0360\n",
            "Epoch 3216/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2240 - val_loss: 4.0360\n",
            "Epoch 3217/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2234 - val_loss: 4.0362\n",
            "Epoch 3218/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2228 - val_loss: 4.0370\n",
            "Epoch 3219/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2222 - val_loss: 4.0386\n",
            "Epoch 3220/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.2217 - val_loss: 4.0390\n",
            "Epoch 3221/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2210 - val_loss: 4.0400\n",
            "Epoch 3222/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2206 - val_loss: 4.0403\n",
            "Epoch 3223/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2200 - val_loss: 4.0420\n",
            "Epoch 3224/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2194 - val_loss: 4.0418\n",
            "Epoch 3225/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2187 - val_loss: 4.0413\n",
            "Epoch 3226/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2184 - val_loss: 4.0415\n",
            "Epoch 3227/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2176 - val_loss: 4.0423\n",
            "Epoch 3228/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2170 - val_loss: 4.0429\n",
            "Epoch 3229/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2165 - val_loss: 4.0426\n",
            "Epoch 3230/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2159 - val_loss: 4.0434\n",
            "Epoch 3231/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2155 - val_loss: 4.0433\n",
            "Epoch 3232/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2147 - val_loss: 4.0444\n",
            "Epoch 3233/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2141 - val_loss: 4.0449\n",
            "Epoch 3234/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2136 - val_loss: 4.0447\n",
            "Epoch 3235/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2131 - val_loss: 4.0450\n",
            "Epoch 3236/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2124 - val_loss: 4.0464\n",
            "Epoch 3237/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2120 - val_loss: 4.0462\n",
            "Epoch 3238/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2113 - val_loss: 4.0464\n",
            "Epoch 3239/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2107 - val_loss: 4.0472\n",
            "Epoch 3240/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2102 - val_loss: 4.0475\n",
            "Epoch 3241/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2096 - val_loss: 4.0480\n",
            "Epoch 3242/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2090 - val_loss: 4.0482\n",
            "Epoch 3243/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.2087 - val_loss: 4.0482\n",
            "Epoch 3244/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2078 - val_loss: 4.0494\n",
            "Epoch 3245/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2073 - val_loss: 4.0495\n",
            "Epoch 3246/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2068 - val_loss: 4.0504\n",
            "Epoch 3247/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.2062 - val_loss: 4.0511\n",
            "Epoch 3248/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.2056 - val_loss: 4.0507\n",
            "Epoch 3249/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2052 - val_loss: 4.0505\n",
            "Epoch 3250/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2046 - val_loss: 4.0514\n",
            "Epoch 3251/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.2040 - val_loss: 4.0523\n",
            "Epoch 3252/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2035 - val_loss: 4.0531\n",
            "Epoch 3253/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2028 - val_loss: 4.0530\n",
            "Epoch 3254/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2024 - val_loss: 4.0531\n",
            "Epoch 3255/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2017 - val_loss: 4.0540\n",
            "Epoch 3256/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2012 - val_loss: 4.0537\n",
            "Epoch 3257/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2007 - val_loss: 4.0547\n",
            "Epoch 3258/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.2001 - val_loss: 4.0554\n",
            "Epoch 3259/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1995 - val_loss: 4.0559\n",
            "Epoch 3260/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1989 - val_loss: 4.0568\n",
            "Epoch 3261/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1985 - val_loss: 4.0574\n",
            "Epoch 3262/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1979 - val_loss: 4.0578\n",
            "Epoch 3263/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1975 - val_loss: 4.0592\n",
            "Epoch 3264/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.1968 - val_loss: 4.0586\n",
            "Epoch 3265/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1961 - val_loss: 4.0583\n",
            "Epoch 3266/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.1957 - val_loss: 4.0594\n",
            "Epoch 3267/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1950 - val_loss: 4.0600\n",
            "Epoch 3268/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1945 - val_loss: 4.0602\n",
            "Epoch 3269/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.1940 - val_loss: 4.0606\n",
            "Epoch 3270/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.1934 - val_loss: 4.0609\n",
            "Epoch 3271/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.1927 - val_loss: 4.0614\n",
            "Epoch 3272/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1924 - val_loss: 4.0618\n",
            "Epoch 3273/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1917 - val_loss: 4.0628\n",
            "Epoch 3274/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1912 - val_loss: 4.0633\n",
            "Epoch 3275/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1906 - val_loss: 4.0634\n",
            "Epoch 3276/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1901 - val_loss: 4.0626\n",
            "Epoch 3277/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1895 - val_loss: 4.0636\n",
            "Epoch 3278/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1889 - val_loss: 4.0640\n",
            "Epoch 3279/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1883 - val_loss: 4.0644\n",
            "Epoch 3280/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1878 - val_loss: 4.0649\n",
            "Epoch 3281/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1875 - val_loss: 4.0654\n",
            "Epoch 3282/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1868 - val_loss: 4.0663\n",
            "Epoch 3283/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.1862 - val_loss: 4.0656\n",
            "Epoch 3284/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.1856 - val_loss: 4.0662\n",
            "Epoch 3285/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.1852 - val_loss: 4.0666\n",
            "Epoch 3286/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.1845 - val_loss: 4.0672\n",
            "Epoch 3287/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1840 - val_loss: 4.0678\n",
            "Epoch 3288/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1834 - val_loss: 4.0677\n",
            "Epoch 3289/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1829 - val_loss: 4.0682\n",
            "Epoch 3290/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1824 - val_loss: 4.0686\n",
            "Epoch 3291/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1818 - val_loss: 4.0693\n",
            "Epoch 3292/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1812 - val_loss: 4.0691\n",
            "Epoch 3293/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1807 - val_loss: 4.0702\n",
            "Epoch 3294/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1802 - val_loss: 4.0712\n",
            "Epoch 3295/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.1797 - val_loss: 4.0711\n",
            "Epoch 3296/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1792 - val_loss: 4.0720\n",
            "Epoch 3297/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1785 - val_loss: 4.0717\n",
            "Epoch 3298/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1779 - val_loss: 4.0721\n",
            "Epoch 3299/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1775 - val_loss: 4.0729\n",
            "Epoch 3300/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1768 - val_loss: 4.0729\n",
            "Epoch 3301/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1763 - val_loss: 4.0731\n",
            "Epoch 3302/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1757 - val_loss: 4.0742\n",
            "Epoch 3303/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1751 - val_loss: 4.0746\n",
            "Epoch 3304/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1747 - val_loss: 4.0746\n",
            "Epoch 3305/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1741 - val_loss: 4.0757\n",
            "Epoch 3306/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1736 - val_loss: 4.0763\n",
            "Epoch 3307/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.1729 - val_loss: 4.0764\n",
            "Epoch 3308/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1725 - val_loss: 4.0757\n",
            "Epoch 3309/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1719 - val_loss: 4.0756\n",
            "Epoch 3310/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.1714 - val_loss: 4.0766\n",
            "Epoch 3311/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.1708 - val_loss: 4.0777\n",
            "Epoch 3312/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.1703 - val_loss: 4.0774\n",
            "Epoch 3313/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1698 - val_loss: 4.0785\n",
            "Epoch 3314/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1692 - val_loss: 4.0800\n",
            "Epoch 3315/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1687 - val_loss: 4.0802\n",
            "Epoch 3316/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1681 - val_loss: 4.0803\n",
            "Epoch 3317/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1676 - val_loss: 4.0810\n",
            "Epoch 3318/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.1670 - val_loss: 4.0818\n",
            "Epoch 3319/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1667 - val_loss: 4.0818\n",
            "Epoch 3320/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.1661 - val_loss: 4.0823\n",
            "Epoch 3321/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.1655 - val_loss: 4.0838\n",
            "Epoch 3322/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1650 - val_loss: 4.0836\n",
            "Epoch 3323/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1647 - val_loss: 4.0831\n",
            "Epoch 3324/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.1638 - val_loss: 4.0840\n",
            "Epoch 3325/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1636 - val_loss: 4.0842\n",
            "Epoch 3326/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.1630 - val_loss: 4.0860\n",
            "Epoch 3327/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1623 - val_loss: 4.0856\n",
            "Epoch 3328/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1618 - val_loss: 4.0852\n",
            "Epoch 3329/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1612 - val_loss: 4.0851\n",
            "Epoch 3330/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1607 - val_loss: 4.0858\n",
            "Epoch 3331/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1601 - val_loss: 4.0867\n",
            "Epoch 3332/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1596 - val_loss: 4.0882\n",
            "Epoch 3333/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1591 - val_loss: 4.0880\n",
            "Epoch 3334/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.1585 - val_loss: 4.0886\n",
            "Epoch 3335/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.1581 - val_loss: 4.0888\n",
            "Epoch 3336/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1575 - val_loss: 4.0900\n",
            "Epoch 3337/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1570 - val_loss: 4.0905\n",
            "Epoch 3338/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.1565 - val_loss: 4.0907\n",
            "Epoch 3339/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1559 - val_loss: 4.0911\n",
            "Epoch 3340/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1554 - val_loss: 4.0922\n",
            "Epoch 3341/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1549 - val_loss: 4.0921\n",
            "Epoch 3342/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1545 - val_loss: 4.0928\n",
            "Epoch 3343/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1539 - val_loss: 4.0934\n",
            "Epoch 3344/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1533 - val_loss: 4.0934\n",
            "Epoch 3345/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1531 - val_loss: 4.0948\n",
            "Epoch 3346/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1523 - val_loss: 4.0950\n",
            "Epoch 3347/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1518 - val_loss: 4.0953\n",
            "Epoch 3348/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1513 - val_loss: 4.0955\n",
            "Epoch 3349/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1509 - val_loss: 4.0962\n",
            "Epoch 3350/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1503 - val_loss: 4.0968\n",
            "Epoch 3351/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1498 - val_loss: 4.0973\n",
            "Epoch 3352/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1493 - val_loss: 4.0976\n",
            "Epoch 3353/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1488 - val_loss: 4.0973\n",
            "Epoch 3354/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1482 - val_loss: 4.0981\n",
            "Epoch 3355/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1478 - val_loss: 4.0989\n",
            "Epoch 3356/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1473 - val_loss: 4.0997\n",
            "Epoch 3357/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1467 - val_loss: 4.0990\n",
            "Epoch 3358/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1463 - val_loss: 4.0997\n",
            "Epoch 3359/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.1457 - val_loss: 4.1005\n",
            "Epoch 3360/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1452 - val_loss: 4.1009\n",
            "Epoch 3361/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1447 - val_loss: 4.1019\n",
            "Epoch 3362/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1442 - val_loss: 4.1025\n",
            "Epoch 3363/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1437 - val_loss: 4.1025\n",
            "Epoch 3364/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1433 - val_loss: 4.1035\n",
            "Epoch 3365/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1427 - val_loss: 4.1046\n",
            "Epoch 3366/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1421 - val_loss: 4.1050\n",
            "Epoch 3367/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1416 - val_loss: 4.1052\n",
            "Epoch 3368/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1412 - val_loss: 4.1059\n",
            "Epoch 3369/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1406 - val_loss: 4.1063\n",
            "Epoch 3370/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1402 - val_loss: 4.1076\n",
            "Epoch 3371/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1397 - val_loss: 4.1081\n",
            "Epoch 3372/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1392 - val_loss: 4.1088\n",
            "Epoch 3373/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1387 - val_loss: 4.1089\n",
            "Epoch 3374/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1383 - val_loss: 4.1092\n",
            "Epoch 3375/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1380 - val_loss: 4.1116\n",
            "Epoch 3376/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1373 - val_loss: 4.1122\n",
            "Epoch 3377/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1367 - val_loss: 4.1121\n",
            "Epoch 3378/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1362 - val_loss: 4.1115\n",
            "Epoch 3379/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1357 - val_loss: 4.1117\n",
            "Epoch 3380/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.1352 - val_loss: 4.1116\n",
            "Epoch 3381/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.1347 - val_loss: 4.1130\n",
            "Epoch 3382/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1341 - val_loss: 4.1132\n",
            "Epoch 3383/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1337 - val_loss: 4.1135\n",
            "Epoch 3384/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1333 - val_loss: 4.1158\n",
            "Epoch 3385/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1327 - val_loss: 4.1164\n",
            "Epoch 3386/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1321 - val_loss: 4.1167\n",
            "Epoch 3387/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1317 - val_loss: 4.1163\n",
            "Epoch 3388/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1312 - val_loss: 4.1165\n",
            "Epoch 3389/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1305 - val_loss: 4.1169\n",
            "Epoch 3390/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1301 - val_loss: 4.1184\n",
            "Epoch 3391/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1295 - val_loss: 4.1181\n",
            "Epoch 3392/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1291 - val_loss: 4.1190\n",
            "Epoch 3393/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.1287 - val_loss: 4.1194\n",
            "Epoch 3394/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.1280 - val_loss: 4.1204\n",
            "Epoch 3395/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1276 - val_loss: 4.1203\n",
            "Epoch 3396/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1271 - val_loss: 4.1208\n",
            "Epoch 3397/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1266 - val_loss: 4.1214\n",
            "Epoch 3398/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.1262 - val_loss: 4.1226\n",
            "Epoch 3399/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1256 - val_loss: 4.1240\n",
            "Epoch 3400/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1251 - val_loss: 4.1250\n",
            "Epoch 3401/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1246 - val_loss: 4.1260\n",
            "Epoch 3402/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1242 - val_loss: 4.1265\n",
            "Epoch 3403/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1236 - val_loss: 4.1269\n",
            "Epoch 3404/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1231 - val_loss: 4.1278\n",
            "Epoch 3405/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1227 - val_loss: 4.1283\n",
            "Epoch 3406/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1221 - val_loss: 4.1283\n",
            "Epoch 3407/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1217 - val_loss: 4.1292\n",
            "Epoch 3408/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1211 - val_loss: 4.1298\n",
            "Epoch 3409/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1207 - val_loss: 4.1304\n",
            "Epoch 3410/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1202 - val_loss: 4.1311\n",
            "Epoch 3411/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1196 - val_loss: 4.1316\n",
            "Epoch 3412/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1192 - val_loss: 4.1327\n",
            "Epoch 3413/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1187 - val_loss: 4.1333\n",
            "Epoch 3414/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.1182 - val_loss: 4.1335\n",
            "Epoch 3415/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1177 - val_loss: 4.1339\n",
            "Epoch 3416/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1173 - val_loss: 4.1346\n",
            "Epoch 3417/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1167 - val_loss: 4.1349\n",
            "Epoch 3418/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1163 - val_loss: 4.1348\n",
            "Epoch 3419/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1158 - val_loss: 4.1362\n",
            "Epoch 3420/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1153 - val_loss: 4.1373\n",
            "Epoch 3421/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1148 - val_loss: 4.1374\n",
            "Epoch 3422/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1145 - val_loss: 4.1374\n",
            "Epoch 3423/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1139 - val_loss: 4.1378\n",
            "Epoch 3424/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1134 - val_loss: 4.1386\n",
            "Epoch 3425/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1129 - val_loss: 4.1392\n",
            "Epoch 3426/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1124 - val_loss: 4.1392\n",
            "Epoch 3427/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1119 - val_loss: 4.1398\n",
            "Epoch 3428/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1114 - val_loss: 4.1408\n",
            "Epoch 3429/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.1110 - val_loss: 4.1416\n",
            "Epoch 3430/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1105 - val_loss: 4.1419\n",
            "Epoch 3431/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1100 - val_loss: 4.1428\n",
            "Epoch 3432/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1095 - val_loss: 4.1436\n",
            "Epoch 3433/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1091 - val_loss: 4.1440\n",
            "Epoch 3434/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.1087 - val_loss: 4.1439\n",
            "Epoch 3435/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.1082 - val_loss: 4.1451\n",
            "Epoch 3436/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1076 - val_loss: 4.1460\n",
            "Epoch 3437/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1072 - val_loss: 4.1468\n",
            "Epoch 3438/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1067 - val_loss: 4.1479\n",
            "Epoch 3439/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1063 - val_loss: 4.1488\n",
            "Epoch 3440/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1058 - val_loss: 4.1487\n",
            "Epoch 3441/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1052 - val_loss: 4.1479\n",
            "Epoch 3442/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1047 - val_loss: 4.1484\n",
            "Epoch 3443/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1042 - val_loss: 4.1496\n",
            "Epoch 3444/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.1039 - val_loss: 4.1501\n",
            "Epoch 3445/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1033 - val_loss: 4.1514\n",
            "Epoch 3446/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1029 - val_loss: 4.1512\n",
            "Epoch 3447/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1023 - val_loss: 4.1517\n",
            "Epoch 3448/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1018 - val_loss: 4.1527\n",
            "Epoch 3449/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1014 - val_loss: 4.1540\n",
            "Epoch 3450/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1009 - val_loss: 4.1548\n",
            "Epoch 3451/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1005 - val_loss: 4.1560\n",
            "Epoch 3452/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1000 - val_loss: 4.1570\n",
            "Epoch 3453/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0996 - val_loss: 4.1569\n",
            "Epoch 3454/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0991 - val_loss: 4.1573\n",
            "Epoch 3455/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0986 - val_loss: 4.1593\n",
            "Epoch 3456/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0982 - val_loss: 4.1596\n",
            "Epoch 3457/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0976 - val_loss: 4.1592\n",
            "Epoch 3458/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0972 - val_loss: 4.1601\n",
            "Epoch 3459/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0967 - val_loss: 4.1606\n",
            "Epoch 3460/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.0963 - val_loss: 4.1613\n",
            "Epoch 3461/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0959 - val_loss: 4.1635\n",
            "Epoch 3462/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0954 - val_loss: 4.1638\n",
            "Epoch 3463/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0948 - val_loss: 4.1644\n",
            "Epoch 3464/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0944 - val_loss: 4.1643\n",
            "Epoch 3465/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0940 - val_loss: 4.1647\n",
            "Epoch 3466/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0934 - val_loss: 4.1654\n",
            "Epoch 3467/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0931 - val_loss: 4.1674\n",
            "Epoch 3468/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0926 - val_loss: 4.1675\n",
            "Epoch 3469/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0921 - val_loss: 4.1672\n",
            "Epoch 3470/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0916 - val_loss: 4.1678\n",
            "Epoch 3471/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0912 - val_loss: 4.1689\n",
            "Epoch 3472/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0907 - val_loss: 4.1702\n",
            "Epoch 3473/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.0902 - val_loss: 4.1705\n",
            "Epoch 3474/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.0897 - val_loss: 4.1705\n",
            "Epoch 3475/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0892 - val_loss: 4.1711\n",
            "Epoch 3476/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0888 - val_loss: 4.1719\n",
            "Epoch 3477/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0884 - val_loss: 4.1730\n",
            "Epoch 3478/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.0879 - val_loss: 4.1733\n",
            "Epoch 3479/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.0874 - val_loss: 4.1738\n",
            "Epoch 3480/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.0870 - val_loss: 4.1748\n",
            "Epoch 3481/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0866 - val_loss: 4.1756\n",
            "Epoch 3482/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.0861 - val_loss: 4.1775\n",
            "Epoch 3483/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.0856 - val_loss: 4.1776\n",
            "Epoch 3484/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0852 - val_loss: 4.1783\n",
            "Epoch 3485/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0847 - val_loss: 4.1786\n",
            "Epoch 3486/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0842 - val_loss: 4.1793\n",
            "Epoch 3487/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0838 - val_loss: 4.1797\n",
            "Epoch 3488/5000\n",
            " 1/10 [==>...........................] - ETA: 0s - loss: 1.1352Restoring model weights from the end of the best epoch: 2488.\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0833 - val_loss: 4.1808\n",
            "Epoch 3488: early stopping\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 20ms/step - loss: 3.3000\n",
            "EXPECTED:\n",
            "   d18O_cel_mean  d18O_cel_variance\n",
            "0      27.559140           0.780698\n",
            "1      27.260748           0.830341\n",
            "2      24.777670           0.736571\n",
            "3      25.987815           5.280825\n",
            "4      25.551850           0.312355\n",
            "5      25.115885           0.033519\n",
            "6      24.132031           0.389042\n",
            "7      25.120750           0.844007\n",
            "\n",
            "PREDICTED:\n",
            "   d18O_cel_mean  d18O_cel_variance\n",
            "0      25.202263           0.318272\n",
            "1      25.202454           0.318020\n",
            "2      25.879833           0.509196\n",
            "3      25.510090           0.606823\n",
            "4      25.565777           0.605048\n",
            "5      25.566076           0.604238\n",
            "6      25.565681           0.605090\n",
            "7      26.469984           0.313916\n",
            "RMSE: 1.3835227509138748\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2023-07-20 14:04:12.818905: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype double and shape [8,12]\n",
            "\t [[{{node Placeholder/_0}}]]\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}