{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tnc-br/ddf-isoscapes/blob/new_kl/dnn/new_kl_results.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Variational model\n",
        "\n",
        "Find the mean/variance of O18 ratios (as well as N15 and C13 in the future) at a particular lat/lon across Brazil. At the bottom of the colab, train and evaluate 4 different versions of the model with different data partitioning strategies."
      ],
      "metadata": {
        "id": "-0IfT3kGwgK6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "henIPlAPCb4i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73a15a04-3900-4b7d-9d49-3fdf26976af4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2023-07-26 22:35:49.942281: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2023-07-26 22:35:49.979323: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2023-07-26 22:35:49.980064: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-07-26 22:35:50.722983: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        }
      ],
      "source": [
        "from collections import defaultdict\n",
        "import math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import datetime\n",
        "import os\n",
        "from typing import List, Tuple, Dict\n",
        "from dataclasses import dataclass\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, regularizers\n",
        "from matplotlib import pyplot as plt\n",
        "from tensorflow.python.ops import math_ops\n",
        "from sklearn.preprocessing import StandardScaler, Normalizer, MinMaxScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "\n",
        "#@title Debugging\n",
        "# See https://zohaib.me/debugging-in-google-collab-notebook/ for tips,\n",
        "# as well as docs for pdb and ipdb.\n",
        "DEBUG = False #@param {type:\"boolean\"}\n",
        "USE_LOCAL_DRIVE = True #@param {type:\"boolean\"}\n",
        "LOCAL_DIR = \"/usr/local/google/home/ruru/Downloads/amazon_sample_data-20230712T203059Z-001\" #@param\n",
        "GDRIVE_DIR = \"MyDrive/amazon_rainforest_files/\" #@param\n",
        "FP_ROOT = LOCAL_DIR\n",
        "\n",
        "def get_model_save_location(filename) -> str:\n",
        "  root = '' if USE_LOCAL_DRIVE else '/content/drive'\n",
        "  return os.path.join(root, GDRIVE_DIR,'variational/model', filename)\n",
        "\n",
        "# Access data stored on Google Drive if not reading data locally.\n",
        "if not USE_LOCAL_DRIVE:\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive')\n",
        "  global FP_ROOT\n",
        "  FP_ROOT = os.path.join('/content/drive', GDRIVE_DIR)\n",
        "\n",
        "if DEBUG:\n",
        "    %pip install -Uqq ipdb\n",
        "    import ipdb\n",
        "    %pdb on"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GQrEv57zCb4q"
      },
      "source": [
        "# Data preparation\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_dataset(path: str):\n",
        "  df = pd.read_csv(path, encoding=\"ISO-8859-1\", sep=',')\n",
        "  df = df[df['d18O_cel_variance'].notna()]\n",
        "\n",
        "  # Family is too sparse. Too many families exist in validation/test that won't\n",
        "  # exist in train, so drop it.\n",
        "  X = df.drop([\"d18O_cel_mean\", \"d18O_cel_variance\",\n",
        "               \"Code\", \"Family\", \"Unnamed: 0\"], axis=1)\n",
        "  Y = df[[\"d18O_cel_mean\", \"d18O_cel_variance\"]]\n",
        "  return X, Y"
      ],
      "metadata": {
        "id": "6XMee1aHfcik"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Standardization"
      ],
      "metadata": {
        "id": "DtkKhMOtb6cS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@dataclass\n",
        "class FeaturesToLabels:\n",
        "  def __init__(self, X: pd.DataFrame, Y: pd.DataFrame):\n",
        "    self.X = X\n",
        "    self.Y = Y\n",
        "\n",
        "  def as_tuple(self):\n",
        "    return (self.X, self.Y)\n",
        "\n",
        "\n",
        "def create_feature_scaler(X: pd.DataFrame) -> ColumnTransformer:\n",
        "  columns_to_normalize = ['lat', 'long', 'VPD', 'RH', 'PET', 'DEM', 'PA',\n",
        "                          'Mean Annual Temperature',\n",
        "                          'Mean Annual Precipitation']\n",
        "  columns_to_standardize = ['isoscape_fullmodel_d18O_prec_REGRESSION',\n",
        "                            'Iso_Oxi_Stack_mean_TERZER',\n",
        "                            'predkrig_br_lat_ISORG',]\n",
        "  feature_scaler = ColumnTransformer([\n",
        "      ('feature_normalizer', Normalizer(), columns_to_normalize),\n",
        "      ('feature_standardizer', StandardScaler(), columns_to_standardize)],\n",
        "      remainder='passthrough')\n",
        "  feature_scaler.fit(X)\n",
        "  return feature_scaler\n",
        "\n",
        "def create_label_scaler(Y: pd.DataFrame) -> ColumnTransformer:\n",
        "  label_scaler = ColumnTransformer([\n",
        "      ('mean_std_scaler', StandardScaler(), ['d18O_cel_mean']),\n",
        "      ('var_minmax_scaler', MinMaxScaler(), ['d18O_cel_variance'])],\n",
        "      remainder='passthrough')\n",
        "  label_scaler.fit(Y)\n",
        "  return label_scaler\n",
        "\n",
        "def scale(X: pd.DataFrame, Y: pd.DataFrame, feature_scaler, label_scaler):\n",
        "  # transform() outputs numpy arrays :(  need to convert back to DataFrame.\n",
        "  X_standardized = pd.DataFrame(feature_scaler.transform(X),\n",
        "                        index=X.index, columns=X.columns)\n",
        "  # Y_standardized = pd.DataFrame(label_scaler.transform(Y),\n",
        "  #                                     index=Y.index, columns=Y.columns)\n",
        "  # FOR NOW, DO NOT SCALE Y.\n",
        "  return FeaturesToLabels(X_standardized, Y)"
      ],
      "metadata": {
        "id": "XSDwdvMkb7w8"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Just a class organization, holds each scaled dataset and the scaler used.\n",
        "# Useful for unscaling predictions.\n",
        "@dataclass\n",
        "class ScaledPartitions():\n",
        "  def __init__(self,\n",
        "               feature_scaler: ColumnTransformer,\n",
        "               label_scaler: ColumnTransformer,\n",
        "               train: FeaturesToLabels, val: FeaturesToLabels,\n",
        "               test: FeaturesToLabels):\n",
        "    self.feature_scaler = feature_scaler\n",
        "    self.label_scaler = label_scaler\n",
        "    self.train = train\n",
        "    self.val = val\n",
        "    self.test = test\n",
        "\n",
        "\n",
        "def load_and_scale(config: Dict) -> ScaledPartitions:\n",
        "  X_train, Y_train = load_dataset(config['TRAIN'])\n",
        "  X_val, Y_val = load_dataset(config['VALIDATION'])\n",
        "  X_test, Y_test = load_dataset(config['TEST'])\n",
        "\n",
        "  feature_scaler = create_feature_scaler(X_train)\n",
        "  label_scaler = create_label_scaler(Y_train)\n",
        "  train = scale(X_train, Y_train, feature_scaler, label_scaler)\n",
        "  val = scale(X_val, Y_val, feature_scaler, label_scaler)\n",
        "  test = scale(X_test, Y_test, feature_scaler, label_scaler)\n",
        "  return ScaledPartitions(feature_scaler, label_scaler, train, val, test)\n"
      ],
      "metadata": {
        "id": "_kf2e_fKon2P"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Definition\n",
        "\n"
      ],
      "metadata": {
        "id": "usGznR593LZc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The KL Loss function:"
      ],
      "metadata": {
        "id": "khK7C8WvU8ZR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install tensorflow-probability\n",
        "import tensorflow_probability as tfp\n",
        "\n",
        "def _sample_normal_distribution(\n",
        "    mean: tf.Tensor,\n",
        "    stdev: tf.Tensor,\n",
        "    n: int) -> tf.Tensor:\n",
        "    '''\n",
        "    Given a batch of normal distributions described by a mean and stdev in\n",
        "    a tf.Tensor, sample n elements from each distribution and return the mean\n",
        "    and standard deviation per sample.\n",
        "    '''\n",
        "    batch_size = tf.shape(mean)[0]\n",
        "    # Output tensor is (n, batch_size, 1)\n",
        "\n",
        "    sample_values = tfp.distributions.Normal(\n",
        "        loc=mean,\n",
        "        scale=tf.math.log(1 + tf.exp(stdev))).sample(\n",
        "            sample_shape=n)\n",
        "    # Reshaped tensor will be (batch_size, n)\n",
        "    sample_values = tf.transpose(sample_values)\n",
        "\n",
        "    # Get the mean per sample in the batch.\n",
        "    sample_mean = tf.math.reduce_mean(sample_values, 2)\n",
        "    sample_stdev = tf.math.reduce_std(sample_values, 2)\n",
        "\n",
        "    # Reshape from (batch_size,) to (batch_size, 1) otherwise kl_loss\n",
        "    # value takes on (batch_size, batch_size) which is incorrect.\n",
        "    sample_mean = tf.reshape(sample_mean, [batch_size, 1])\n",
        "    sample_stdev = tf.reshape(sample_stdev, [batch_size, 1])\n",
        "\n",
        "    return sample_mean, sample_stdev\n",
        "\n",
        "# log(σ2/σ1) + ( σ1^2+(μ1−μ2)^2 ) / 2* σ^2   − 1/2\n",
        "def kl_divergence(real, predicted, sample):\n",
        "    '''\n",
        "    real: tf.Tensor of the real mean and standard deviation of sample to compare\n",
        "    predicted: tf.Tensor of the predicted mean and standard deviation to compare\n",
        "    sample: Whether or not to sample the predicted distribution to get a new\n",
        "            mean and standard deviation.\n",
        "    '''\n",
        "    if real.shape != predicted.shape:\n",
        "      raise ValueError(\n",
        "          f\"real.shape {real.shape} != predicted.shape {predicted.shape}\")\n",
        "\n",
        "    real_mean = real[:,0:1]\n",
        "    real_std = tf.math.sqrt(real[:,1:2])\n",
        "\n",
        "    predicted_mean = predicted[:,0:1]\n",
        "    predicted_std = tf.math.sqrt(predicted[:,1:2])\n",
        "\n",
        "    # If true, sample from the distribution defined by the predicted mean and\n",
        "    # standard deviation to use for mean and stdev used in KL divergence loss.\n",
        "    if sample:\n",
        "      predicted_mean, predicted_std = _sample_normal_distribution(\n",
        "          mean=predicted_mean, stdev=predicted_std, n=5)\n",
        "\n",
        "    kl_loss = -0.5 + tf.math.log(predicted_std/real_std) + \\\n",
        "     (tf.square(real_std) + tf.square(real_mean - predicted_mean))/ \\\n",
        "     (2*tf.square(predicted_std))\n",
        "\n",
        "    return tf.math.reduce_mean(kl_loss)\n",
        "\n",
        "def kl_divergence_helper(real, predicted):\n",
        "  return kl_divergence(real, predicted, True)"
      ],
      "metadata": {
        "id": "urGjYNNnemX6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "705820a1-f7e7-429e-d851-863029ace4e4"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow-probability in ./.venv/lib/python3.11/site-packages (0.20.1)\r\n",
            "Requirement already satisfied: absl-py in ./.venv/lib/python3.11/site-packages (from tensorflow-probability) (1.4.0)\r\n",
            "Requirement already satisfied: six>=1.10.0 in ./.venv/lib/python3.11/site-packages (from tensorflow-probability) (1.16.0)\r\n",
            "Requirement already satisfied: numpy>=1.13.3 in ./.venv/lib/python3.11/site-packages (from tensorflow-probability) (1.23.5)\r\n",
            "Requirement already satisfied: decorator in ./.venv/lib/python3.11/site-packages (from tensorflow-probability) (5.1.1)\r\n",
            "Requirement already satisfied: cloudpickle>=1.3 in ./.venv/lib/python3.11/site-packages (from tensorflow-probability) (2.2.1)\r\n",
            "Requirement already satisfied: gast>=0.3.2 in ./.venv/lib/python3.11/site-packages (from tensorflow-probability) (0.4.0)\r\n",
            "Requirement already satisfied: dm-tree in ./.venv/lib/python3.11/site-packages (from tensorflow-probability) (0.1.8)\r\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test the loss function:"
      ],
      "metadata": {
        "id": "fJzBFWQVeqNE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install pytest\n",
        "tf.random.set_seed(1871)\n",
        "import pytest\n",
        "test_real = tf.convert_to_tensor(np.array([[1, 0.02]]))\n",
        "test_pred = tf.convert_to_tensor(np.array([[0.98, 0.021]]))\n",
        "\n",
        "# https://screenshot.googleplex.com/BWoJ83rSgWkDqkB\n",
        "assert float(kl_divergence(test_real, test_pred, True)) == pytest.approx(1.262810312622552, 1e-5)\n",
        "\n",
        "test_neg_real = tf.convert_to_tensor(np.array([[32.32, 0.0344]]))\n",
        "test_neg_pred = tf.convert_to_tensor(np.array([[32.01, -0.322]]))\n",
        "\n",
        "# Negative variance causes NaN\n",
        "assert tf.math.is_nan(kl_divergence(test_neg_real, test_neg_pred, True))\n",
        "\n",
        "test_real_2d = tf.convert_to_tensor(np.array(\n",
        "    [[1.00, 0.020],\n",
        "     [1.01, 0.042],\n",
        "     [0.99, 0.015]]))\n",
        "test_pred_2d = tf.convert_to_tensor(np.array(\n",
        "    [[0.98, 0.021],\n",
        "     [0.99, 0.012],\n",
        "     [0.99, 0.015]]))\n",
        "\n",
        "# Should reduce to the average loss of all rows.\n",
        "assert float( kl_divergence(test_real_2d, test_pred_2d, True)) == pytest.approx(\n",
        "    sum([1.48400935, 0.83452761])/2, 1e-5)"
      ],
      "metadata": {
        "id": "48TaPd70erSk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "outputId": "385cef7a-4545-4960-d4c7-ba04a1320b53"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pytest in ./.venv/lib/python3.11/site-packages (7.4.0)\r\n",
            "Requirement already satisfied: iniconfig in ./.venv/lib/python3.11/site-packages (from pytest) (2.0.0)\r\n",
            "Requirement already satisfied: packaging in ./.venv/lib/python3.11/site-packages (from pytest) (23.1)\r\n",
            "Requirement already satisfied: pluggy<2.0,>=0.12 in ./.venv/lib/python3.11/site-packages (from pytest) (1.2.0)\r\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AssertionError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[105], line 26\u001b[0m\n\u001b[1;32m     20\u001b[0m test_pred_2d \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mconvert_to_tensor(np\u001b[38;5;241m.\u001b[39marray(\n\u001b[1;32m     21\u001b[0m     [[\u001b[38;5;241m0.98\u001b[39m, \u001b[38;5;241m0.021\u001b[39m],\n\u001b[1;32m     22\u001b[0m      [\u001b[38;5;241m0.99\u001b[39m, \u001b[38;5;241m0.012\u001b[39m], \n\u001b[1;32m     23\u001b[0m      [\u001b[38;5;241m0.99\u001b[39m, \u001b[38;5;241m0.015\u001b[39m]]))\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# Should reduce to the average loss of all rows.\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mfloat\u001b[39m( kl_divergence(test_real_2d, test_pred_2d, \u001b[38;5;28;01mTrue\u001b[39;00m)) \u001b[38;5;241m==\u001b[39m pytest\u001b[38;5;241m.\u001b[39mapprox(\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;28msum\u001b[39m([\u001b[38;5;241m1.48400935\u001b[39m, \u001b[38;5;241m0.83452761\u001b[39m])\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1e-5\u001b[39m)\n",
            "\u001b[0;31mAssertionError\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model definition"
      ],
      "metadata": {
        "id": "8rI6qPRh7oO7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "\n",
        "def get_early_stopping_callback():\n",
        "  return EarlyStopping(monitor='val_loss', patience=1000, min_delta=0.001,\n",
        "                       verbose=1, restore_best_weights=True, start_from_epoch=40000)\n",
        "\n",
        "tf.keras.utils.set_random_seed(18731)\n",
        "\n",
        "# I was experimenting with models that took longer to train, and used this\n",
        "# checkpointing callback to periodically save the model. It's optional.\n",
        "def get_checkpoint_callback(model_file):\n",
        "  return ModelCheckpoint(\n",
        "      get_model_save_location(model_file),\n",
        "      monitor='val_loss', verbose=0, save_best_only=True, mode='min')\n",
        "\n",
        "def train_or_update_variational_model(\n",
        "        sp: ScaledPartitions,\n",
        "        hidden_layers: List[int],\n",
        "        epochs: int,\n",
        "        batch_size: int,\n",
        "        lr: float,\n",
        "        model_file=None,\n",
        "        use_checkpoint=False):\n",
        "  callbacks_list = [get_early_stopping_callback(),\n",
        "                    get_checkpoint_callback(model_file)]\n",
        "  if not use_checkpoint:\n",
        "    inputs = keras.Input(shape=(sp.train.X.shape[1],))\n",
        "    x = inputs\n",
        "    for layer_size in hidden_layers:\n",
        "      x = keras.layers.Dense(\n",
        "          layer_size, activation='relu')(x)\n",
        "    mean_output = keras.layers.Dense(\n",
        "        1, name='mean_output')(x)\n",
        "\n",
        "    # We can not have negative variance. Apply very little variance.\n",
        "    var_output = keras.layers.Dense(\n",
        "        1, name='var_output')(x)\n",
        "\n",
        "    # Invert the normalization on our outputs\n",
        "    mean_scaler = sp.label_scaler.named_transformers_['mean_std_scaler']\n",
        "    untransformed_mean = mean_output * mean_scaler.var_ + mean_scaler.mean_\n",
        "\n",
        "    var_scaler = sp.label_scaler.named_transformers_['var_minmax_scaler']\n",
        "    untransformed_var = var_output * var_scaler.scale_ + var_scaler.min_\n",
        "\n",
        "    untransformed_abs_var = keras.layers.Lambda(lambda t: tf.abs(t))(untransformed_var)\n",
        "\n",
        "    # Output mean, |variance| tuples.\n",
        "    outputs = keras.layers.concatenate([untransformed_mean, untransformed_abs_var])\n",
        "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "    # Later epochs seem to benefit from lower learning rate... but it takes\n",
        "    # a while to get there.\n",
        "    decay = keras.optimizers.schedules.ExponentialDecay(\n",
        "       lr, decay_steps=100, decay_rate=0.5, staircase=True)\n",
        "\n",
        "    optimizer = keras.optimizers.Adam(learning_rate=lr)\n",
        "    model.compile(optimizer=optimizer, loss=kl_divergence_helper)\n",
        "    model.summary()\n",
        "  else:\n",
        "    model = keras.models.load_model(\n",
        "        get_model_save_location(model_file),\n",
        "        custom_objects={\"kl_divergence\": kl_divergence_helper})\n",
        "  history = model.fit(sp.train.X, sp.train.Y, verbose=1, epochs=epochs, batch_size=batch_size,\n",
        "                      validation_data=sp.val.as_tuple(),\n",
        "                      shuffle=True, callbacks=callbacks_list)\n",
        "  return history, model"
      ],
      "metadata": {
        "id": "HCkGSPUo3KqY"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "def render_plot_loss(history, name):\n",
        "  plt.plot(history.history['loss'])\n",
        "  plt.plot(history.history['val_loss'])\n",
        "  plt.title(name + ' model loss')\n",
        "  plt.ylabel('loss')\n",
        "  plt.yscale(\"log\")\n",
        "  plt.ylim((0, 10))\n",
        "  plt.xlabel('epoch')\n",
        "  plt.legend(['loss', 'val_loss'], loc='upper left')\n",
        "  plt.show()\n",
        "\n",
        "def destandardize(sd: ScaledPartitions, df: pd.DataFrame):\n",
        "  means = pd.DataFrame(\n",
        "      sd.label_scaler.named_transformers_['var_std_scaler'].inverse_transform(df[['d18O_cel_mean']]),\n",
        "      index=df.index, columns=['d18O_cel_mean'])\n",
        "  vars = df['d18O_cel_variance']\n",
        "  return means.join(vars)\n",
        "\n",
        "def train_and_evaluate(sp: ScaledPartitions, run_id: str, training_batch_size=5):\n",
        "  print(\"==================\")\n",
        "  print(run_id)\n",
        "  history, model = train_or_update_variational_model(\n",
        "      sp, hidden_layers=[20, 20], epochs=50000, batch_size=training_batch_size,\n",
        "      lr=0.0001, model_file=run_id+\".h5\", use_checkpoint=False)\n",
        "  model.save(get_model_save_location(run_id+\".h5\"), save_format=\"h5\")\n",
        "\n",
        "  render_plot_loss(history, run_id+\" kl_loss\")\n",
        "  best_epoch_index = history.history['val_loss'].index(min(history.history['val_loss']))\n",
        "  print('Val loss:', history.history['val_loss'][best_epoch_index])\n",
        "  print('Train loss:', history.history['loss'][best_epoch_index])\n",
        "  print('Test loss:', model.evaluate(x=sp.test.X, y=sp.test.Y, verbose=0))\n",
        "\n",
        "  predictions = model.predict_on_batch(sp.test.X)\n",
        "  predictions = pd.DataFrame(predictions, columns=['d18O_cel_mean', 'd18O_cel_variance'])\n",
        "  rmse = np.sqrt(mean_squared_error(sp.test.Y['d18O_cel_mean'], predictions['d18O_cel_mean']))\n",
        "  print(\"dO18 RMSE: \"+ str(rmse))\n",
        "  print(\"EXPECTED:\")\n",
        "  print(sp.test.Y.to_string())\n",
        "  print()\n",
        "  print(\"PREDICTED:\")\n",
        "  print(predictions.to_string())\n"
      ],
      "metadata": {
        "id": "DALuUm8UOgNu"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load and evaluate the model with each set of data.\n",
        "\n",
        "Use the same model configured the same way for every run, with the exception of the training batch size setting, which is 1 for grouped and 5 for ungrouped."
      ],
      "metadata": {
        "id": "WF_1T_zZtK0T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1) Ungrouped, random"
      ],
      "metadata": {
        "id": "q6vAjessuMSM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ungrouped_random = {\n",
        "    'TRAIN' : os.path.join(FP_ROOT, \"amazon_sample_data/uc_davis_2023_08_12_train_random_ungrouped.csv\"),\n",
        "    'TEST' : os.path.join(FP_ROOT, \"amazon_sample_data/uc_davis_2023_08_12_test_random_ungrouped.csv\"),\n",
        "    'VALIDATION' : os.path.join(FP_ROOT, \"amazon_sample_data/uc_davis_2023_08_12_validation_random_ungrouped.csv\"),\n",
        "}\n",
        "\n",
        "ungrouped_random_scaled = load_and_scale(ungrouped_random)\n",
        "train_and_evaluate(ungrouped_random_scaled, \"ungrouped_random\", training_batch_size=3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "qM5zP9M9tQqE",
        "outputId": "3d5eb945-c428-41bf-9275-fe78e1020c96"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================\n",
            "ungrouped_random\n",
            "Model: \"model_27\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_28 (InputLayer)          [(None, 10)]         0           []                               \n",
            "                                                                                                  \n",
            " dense_54 (Dense)               (None, 20)           220         ['input_28[0][0]']               \n",
            "                                                                                                  \n",
            " dense_55 (Dense)               (None, 20)           420         ['dense_54[0][0]']               \n",
            "                                                                                                  \n",
            " var_output (Dense)             (None, 1)            21          ['dense_55[0][0]']               \n",
            "                                                                                                  \n",
            " mean_output (Dense)            (None, 1)            21          ['dense_55[0][0]']               \n",
            "                                                                                                  \n",
            " tf.math.multiply_55 (TFOpLambd  (None, 1)           0           ['var_output[0][0]']             \n",
            " a)                                                                                               \n",
            "                                                                                                  \n",
            " tf.math.multiply_54 (TFOpLambd  (None, 1)           0           ['mean_output[0][0]']            \n",
            " a)                                                                                               \n",
            "                                                                                                  \n",
            " tf.__operators__.add_55 (TFOpL  (None, 1)           0           ['tf.math.multiply_55[0][0]']    \n",
            " ambda)                                                                                           \n",
            "                                                                                                  \n",
            " tf.__operators__.add_54 (TFOpL  (None, 1)           0           ['tf.math.multiply_54[0][0]']    \n",
            " ambda)                                                                                           \n",
            "                                                                                                  \n",
            " lambda_27 (Lambda)             (None, 1)            0           ['tf.__operators__.add_55[0][0]']\n",
            "                                                                                                  \n",
            " concatenate_27 (Concatenate)   (None, 2)            0           ['tf.__operators__.add_54[0][0]',\n",
            "                                                                  'lambda_27[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 682\n",
            "Trainable params: 682\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Restoring model weights from the end of the best epoch: 1302.\n",
            "Epoch 2302: early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_2030896/902123805.py:9: UserWarning: Attempt to set non-positive ylim on a log-scaled axis will be ignored.\n",
            "  plt.ylim((0, 10))\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjoAAAHHCAYAAAC2rPKaAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAByZklEQVR4nO3dd3iTVfsH8G92ugctlAJlr7K3gAoIsqeoiKhMZ1GRoeKrAuorbnEUxJ8K+jpQUVHZQ4YiIHsVgUIpu0DpXmmT8/vjNGnSprt50vH9XFevJE+ePM9J0jZ37nOfc1RCCAEiIiKiakjt7gYQERERuQoDHSIiIqq2GOgQERFRtcVAh4iIiKotBjpERERUbTHQISIiomqLgQ4RERFVWwx0iIiIqNpioENERETVFgMdoirs3LlzUKlUWL58ububUmp9+/ZF37593d0Mm0mTJsHb27vY/crS7sr2XCsLlUqF+fPnl/pxJf2937ZtG1QqFbZt21am9lH1wECHiIiIqi0GOkRERFRtMdChGstisSAzM9PdzagUMjMzYbFY3N0MIqIKx0CHFDNp0iQ0atSowPb58+dDpVI5bFOpVJg+fTpWrVqFtm3bwmAwoE2bNli/fn2Bx2/btg1du3aF0WhE06ZNsXTp0iKP+c0336BNmzYwGAy24x08eBBDhgyBr68vvL290b9/f+zevbvYdgLA8uXLoVKpcO7cOdu2Ro0aYfjw4di4cSM6duwIo9GI8PBw/PzzzwUen5iYiBkzZqBBgwYwGAxo1qwZ3nzzzQKBR2JiIiZNmgQ/Pz/4+/tj4sSJSExMLHC84ljrFlasWIEXX3wR9erVg6enJ5KTk3Hz5k3Mnj0b7dq1g7e3N3x9fTFkyBAcPnzY6TF++OEH/Pe//0X9+vVhNBrRv39/REdHFzjnp59+iqZNm8LDwwPdu3fHn3/+6bRt165dw9SpU1GnTh0YjUZ06NABX375pcM+1vqMd955B5GRkWjSpAk8PT0xcOBAXLhwAUIIvPrqq6hfvz48PDwwatQo3Lx5s9SvEwAcOnQIwcHB6Nu3L1JTU8t0jMKU5LkCwIoVK9ClSxf4+PjA19cX7dq1wwcffGC7Pzs7GwsWLEDz5s1hNBpRq1Yt3Hrrrdi0aVOR57f+3v7111946qmnEBwcDH9/fzz66KMwmUxITEzEQw89hICAAAQEBODZZ5+FEMLhGGlpaZg1a5btd7dly5Z45513CuyXlZWFZ555BsHBwfDx8cHIkSNx8eJFp+26dOkSpkyZgjp16tj+7r/44ouSvqwl8uOPP6JLly7w8PBAUFAQHnjgAVy6dMlhn6tXr2Ly5MmoX78+DAYD6tati1GjRjn8ne/btw+DBg1CUFAQPDw80LhxY0yZMqVC20rlp3V3A4gK89dff+Hnn3/GE088AR8fH3z44YcYO3Yszp8/j1q1agGQAcrgwYNRt25dLFiwAGazGa+88gqCg4OdHvOPP/7ADz/8gOnTpyMoKAiNGjXC8ePHcdttt8HX1xfPPvssdDodli5dir59+2L79u3o0aNHmdp/+vRpjBs3Do899hgmTpyIZcuW4Z577sH69etx5513AgDS09PRp08fXLp0CY8++ijCwsLw999/Y+7cubhy5QoWLVoEABBCYNSoUfjrr7/w2GOPoXXr1vjll18wceLEMrUNAF599VXo9XrMnj0bWVlZ0Ov1iIqKwqpVq3DPPfegcePGiIuLw9KlS9GnTx9ERUUhNDTU4RhvvPEG1Go1Zs+ejaSkJLz11luYMGEC9uzZY9vn888/x6OPPopevXphxowZOHv2LEaOHInAwEA0aNDAtl9GRgb69u2L6OhoTJ8+HY0bN8aPP/6ISZMmITExEU8//bTDub/55huYTCY8+eSTuHnzJt566y3ce++9uOOOO7Bt2zY899xziI6OxkcffYTZs2eX+sNy7969GDRoELp27Ypff/0VHh4eZXiVnSvpc920aRPGjx+P/v3748033wQAnDhxAjt37rTtM3/+fCxcuBDTpk1D9+7dkZycjH379uHAgQO237OiPPnkkwgJCcGCBQuwe/dufPrpp/D398fff/+NsLAwvP7661i7di3efvtttG3bFg899BAA+Ts5cuRIbN26FVOnTkXHjh2xYcMGzJkzB5cuXcL7779vO8e0adPw9ddf4/7770evXr3wxx9/YNiwYQXaEhcXh1tuucX2pSQ4OBjr1q3D1KlTkZycjBkzZpT3pcfy5csxefJkdOvWDQsXLkRcXBw++OAD7Ny5EwcPHoS/vz8AYOzYsTh+/DiefPJJNGrUCNeuXcOmTZtw/vx52+2BAwciODgYzz//PPz9/XHu3DmnX2bIzQSRQiZOnCgaNmxYYPu8efNE/l9FAEKv14vo6GjbtsOHDwsA4qOPPrJtGzFihPD09BSXLl2ybTt9+rTQarVOj6lWq8Xx48cdto8ePVro9Xpx5swZ27bLly8LHx8fcfvttxfZTiGEWLZsmQAgYmJibNsaNmwoAIiffvrJti0pKUnUrVtXdOrUybbt1VdfFV5eXuLUqVMOx3z++eeFRqMR58+fF0IIsWrVKgFAvPXWW7Z9cnJyxG233SYAiGXLlhVoV2G2bt0qAIgmTZqI9PR0h/syMzOF2Wx22BYTEyMMBoN45ZVXChyjdevWIisry7b9gw8+EADE0aNHhRBCmEwmUbt2bdGxY0eH/T799FMBQPTp08e2bdGiRQKA+Prrr23bTCaT6Nmzp/D29hbJycm29gAQwcHBIjEx0bbv3LlzBQDRoUMHkZ2dbds+fvx4odfrRWZmZpGvy8SJE4WXl5cQQoi//vpL+Pr6imHDhhV4XJ8+fRzaXRL5H1PS5/r0008LX19fkZOTU+ixO3ToIIYNG1aq9giR93s7aNAgYbFYbNt79uwpVCqVeOyxx2zbcnJyRP369R2eg/V38rXXXnM47t133y1UKpXtb/fQoUMCgHjiiScc9rv//vsFADFv3jzbtqlTp4q6deuKGzduOOx73333CT8/P9vvq/V3oLjfe+vv6datW4UQeb+Pbdu2FRkZGbb9Vq9eLQCIl19+WQghREJCggAg3n777UKP/csvvwgAYu/evUW2gdyPXVdUaQ0YMABNmza13W7fvj18fX1x9uxZAIDZbMbmzZsxevRoh0xDs2bNMGTIEKfH7NOnD8LDw223zWYzNm7ciNGjR6NJkya27XXr1sX999+Pv/76C8nJyWVqf2hoKMaMGWO77evri4ceeggHDx7E1atXAcgU+m233YaAgADcuHHD9jNgwACYzWbs2LEDALB27VpotVo8/vjjtuNpNBo8+eSTZWobAEycOLFAlsJgMECtlv8WzGYz4uPj4e3tjZYtW+LAgQMFjjF58mTo9Xrb7dtuuw0AbO/Rvn37cO3aNTz22GMO+1m74OytXbsWISEhGD9+vG2bTqfDU089hdTUVGzfvt1h/3vuucfhGNbM2wMPPACtVuuw3WQyFeiaKMzWrVsxaNAg9O/fHz///DMMBkOJHlcaJX2u/v7+SEtLK7Ibyt/fH8ePH8fp06fL1JapU6c6dMn26NEDQghMnTrVtk2j0aBr166299X6HDQaDZ566imH482aNQtCCKxbt862H4AC++XPzggh8NNPP2HEiBEQQjj8PQwaNAhJSUlOfwdLw/r7+MQTT8BoNNq2Dxs2DK1atcKaNWsAAB4eHtDr9di2bRsSEhKcHsua+Vm9ejWys7PL1S5yLQY6VGmFhYUV2BYQEGD7x3Pt2jVkZGSgWbNmBfZztg0AGjdu7HD7+vXrSE9PR8uWLQvs27p1a1gsFly4cKEszUezZs0K1PS0aNECAGz9/KdPn8b69esRHBzs8DNgwAAA8jkCQGxsLOrWrVtgnhdn7S6p/K8FIAu033//fTRv3hwGgwFBQUEIDg7GkSNHkJSUVGD//O9RQEAAANjeo9jYWABA8+bNHfbT6XQOgaV13+bNm9sCLavWrVs7HKuwc1uDHvvuMPvthX1g2cvMzMSwYcPQqVMn/PDDDw7BWUUq6XN94okn0KJFCwwZMgT169fHlClTCtSpvfLKK0hMTESLFi3Qrl07zJkzB0eOHClxW0rzOtq/hrGxsQgNDYWPj0+RzyE2NhZqtdrhSwtQ8Hf3+vXrSExMxKefflrg72Hy5MkA8v4eysraJmd/N61atbLdbzAY8Oabb2LdunWoU6cObr/9drz11lu2LyiA/NI0duxYLFiwAEFBQRg1ahSWLVuGrKyscrWRKh4DHVKMs0JeQGYOnNFoNE63i3yFjqVRnjqL0ra/JCwWC+68805s2rTJ6c/YsWPLfOziOHstXn/9dcycORO33347vv76a2zYsAGbNm1CmzZtnI7KcsV7VFKFnbs8bTIYDBg2bBj27NnjtPBdabVr18ahQ4fw22+/2ephhgwZ4lCbdfvtt+PMmTP44osv0LZtW3z22Wfo3LkzPvvssxKdozSvoyvfV+vv1wMPPFDo30Pv3r1ddv78ZsyYgVOnTmHhwoUwGo146aWX0Lp1axw8eBCA/H+wcuVK7Nq1C9OnT7cVUXfp0qXCC9epfBjokGICAgKcjhLK/029pGrXrg2j0eh0lI+zbc4EBwfD09MTJ0+eLHDfv//+C7Vabftma81W5H8OhbU/Ojq6wAfDqVOnAMA2+qxp06ZITU3FgAEDnP5Yv203bNgQV65cKfAP1Fm7y2PlypXo168fPv/8c9x3330YOHAgBgwYUKbRXYBsN4AC3SrZ2dmIiYkpsO/p06cLBFT//vuvw7FcSaVS4ZtvvkH//v1xzz33uGxG3dI8V71ejxEjRmDx4sU4c+YMHn30UXz11VcOv+OBgYGYPHkyvvvuO1y4cAHt27cv04zDpX0Oly9fRkpKSpHPoWHDhrBYLDhz5ozDfvl/d60jssxmc6F/D7Vr1y53m52d27ot/+9Y06ZNMWvWLGzcuBHHjh2DyWTCu+++67DPLbfcgv/+97/Yt28fvvnmGxw/fhwrVqwoVzupYjHQIcU0bdoUSUlJDmn1K1eu4JdffinT8TQaDQYMGIBVq1bh8uXLtu3R0dG2+oCSHGPgwIH49ddfHYaNxsXF4dtvv8Wtt94KX19fW/sB2OpmADm81tmQYAC4fPmyw3NLTk7GV199hY4dOyIkJAQAcO+992LXrl3YsGFDgccnJiYiJycHADB06FDk5ORgyZIltvvNZjM++uijEj3PktJoNAWCsx9//LHE9S35de3aFcHBwfjkk09gMpls25cvX14geBo6dCiuXr2K77//3rYtJycHH330Eby9vdGnT58ytaG09Ho9fv75Z3Tr1g0jRozAP//8U+HnKOlzjY+Pd3icWq1G+/btAcDWRZJ/H29vbzRr1szlXShDhw6F2WzGxx9/7LD9/fffh0qlstXJWS8//PBDh/2sIwqtNBoNxo4di59++gnHjh0rcL7r16+Xu81du3ZF7dq18cknnzi8PuvWrcOJEydsI8HS09MLzLHVtGlT+Pj42B6XkJBQ4G+lY8eOAMDuq0qGw8tJMffddx+ee+45jBkzBk899RTS09OxZMkStGjRosxFhvPnz8fGjRvRu3dvPP7447Z/vG3btsWhQ4dKdIzXXnsNmzZtwq233oonnngCWq0WS5cuRVZWFt566y3bfgMHDkRYWBimTp2KOXPmQKPR4IsvvkBwcDDOnz9f4LgtWrTA1KlTsXfvXtSpUwdffPEF4uLisGzZMts+c+bMwW+//Ybhw4dj0qRJ6NKlC9LS0nD06FGsXLkS586dQ1BQEEaMGIHevXvj+eefx7lz52xz8jirmymP4cOH45VXXsHkyZPRq1cvHD16FN98802BepqS0ul0eO211/Doo4/ijjvuwLhx4xATE4Nly5YVOOYjjzyCpUuXYtKkSdi/fz8aNWqElStXYufOnVi0aFGBWhBX8vDwwOrVq3HHHXdgyJAh2L59O9q2bVthxy/pc502bRpu3ryJO+64A/Xr10dsbCw++ugjdOzY0VYLEx4ejr59+6JLly4IDAzEvn37sHLlSkyfPr3C2uvMiBEj0K9fP/znP//BuXPn0KFDB2zcuBG//vorZsyYYfti0LFjR4wfPx6LFy9GUlISevXqhS1btjjNur7xxhvYunUrevTogYcffhjh4eG4efMmDhw4gM2bN5d5PiQrnU6HN998E5MnT0afPn0wfvx42/DyRo0a4ZlnngEgM6/9+/fHvffei/DwcGi1Wvzyyy+Ii4vDfffdBwD48ssvsXjxYowZMwZNmzZFSkoK/u///g++vr4YOnRoudpJFcxNo72ohtq4caNo27at0Ov1omXLluLrr78udHh5REREgcc3bNhQTJw40WHbli1bRKdOnYRerxdNmzYVn332mZg1a5YwGo0lOqYQQhw4cEAMGjRIeHt7C09PT9GvXz/x999/F9hv//79okePHkKv14uwsDDx3nvvFTq8fNiwYWLDhg2iffv2wmAwiFatWokff/yxwDFTUlLE3LlzRbNmzYRerxdBQUGiV69e4p133hEmk8m2X3x8vHjwwQeFr6+v8PPzEw8++KA4ePBgmYeXO2tLZmammDVrlqhbt67w8PAQvXv3Frt27SowPLqwYxQ27Hfx4sWicePGwmAwiK5du4odO3Y4HaYdFxcnJk+eLIKCgoRerxft2rUrcCzrOfIP/S2sTdb3p7hhwPbDy61u3LghwsPDRUhIiDh9+rQQomKGlwtRsue6cuVKMXDgQFG7dm3b79yjjz4qrly5YtvntddeE927dxf+/v7Cw8NDtGrVSvz3v/91+N1xprDXxfr3eP36dYftzl6flJQU8cwzz4jQ0FCh0+lE8+bNxdtvv+0wXF0IITIyMsRTTz0latWqJby8vMSIESPEhQsXCgwvt74uERERokGDBkKn04mQkBDRv39/8emnn9r2Kevwcqvvv/9edOrUSRgMBhEYGCgmTJggLl68aLv/xo0bIiIiQrRq1Up4eXkJPz8/0aNHD/HDDz/Y9jlw4IAYP368CAsLEwaDQdSuXVsMHz5c7Nu3r8g2kfJUQihQNUiksNGjR5dryG15NWrUCG3btsXq1avdcn4iIpJYo0NVXkZGhsPt06dPY+3atejbt697GkRERJVGtajRGTNmDLZt24b+/ftj5cqV7m4OKaxJkyaYNGkSmjRpgtjYWCxZsgR6vR7PPvusu5umKJPJVGwNg5+fX4UuZVDTXb9+vcjpBfR6PQIDAxVsERHlVy0CnaeffhpTpkwpdPQLVW+DBw/Gd999h6tXr8JgMKBnz554/fXXC0xSV939/fff6NevX5H7LFu2DJMmTVKmQTVAt27dipweoU+fPi4bok5EJVNtanS2bduGjz/+mBkdqrESEhKwf//+Ivdp06YN6tatq1CLqr+dO3cW6Dq1FxAQgC5duijYIiLKz+0ZnR07duDtt9/G/v37bXOqjB492mGfyMhIvP3227h69So6dOiAjz76CN27d3dPg4kqqYCAANvSEaQMJWfqJaKycXsxclpaGjp06IDIyEin93///feYOXMm5s2bhwMHDqBDhw4YNGhQudc8ISIiourP7RmdIUOGFLrSNAC89957ePjhh22Lun3yySdYs2YNvvjiCzz//POlPl9WVpbDrJUWiwU3b95ErVq1Cl3LiIiIiCoXIQRSUlIQGhpaYIFce24PdIpiMpmwf/9+zJ0717ZNrVZjwIAB2LVrV5mOuXDhQixYsKCimkhERERudOHCBdSvX7/Q+yt1oHPjxg2YzWbUqVPHYXudOnVsC8cBwIABA3D48GGkpaWhfv36+PHHH9GzZ0+nx5w7dy5mzpxpu52UlISwsDBcuHDBtqZRRTDlWND51U0AgJ3P3wE/D12FHZuIiKimS05ORoMGDYpdHqZSBzoltXnz5hLvazAYYDAYCmz39fWt0EDHbBFQGzwBAN7ePvD10lfYsYmIiEgqruzE7cXIRQkKCoJGo0FcXJzD9ri4ONvqz5WV2u51N1ePEfxERERVTqUOdPR6Pbp06YItW7bYtlksFmzZsqXQrqnKQqVS2YIdi4WBDhERkTu4vesqNTUV0dHRttsxMTE4dOgQAgMDERYWhpkzZ2LixIno2rUrunfvjkWLFiEtLc02Cqsy06hVsJgFMzpERERu4vZAZ9++fQ7T1lsLhSdOnIjly5dj3LhxuH79Ol5++WVcvXoVHTt2xPr16wsUKLuSxWKByWQq9ePq+2hhMluQlZmJTAOHrlcknU4HjUbj7mYQEVElV22WgCir5ORk+Pn5ISkpyWkxsslkQkxMDCwWS6mPfTkxAxYBhPgaoNVU6l7CKsnf3x8hISGc/4iIqAYq7vPbyu0ZncpMCIErV65Ao9GgQYMGRU5I5ExOXAosQqBhLS/odcw+VBQhBNLT022zY3PtJiIiKgwDnSLk5OQgPT0doaGh8PT0LPXj1bosCIuA3miEkYFOhfLw8AAAXLt2DbVr12Y3FhEROVVj+1MiIyMRHh6Obt26FbqP2WwGIEd/lYUK7FJxJWvwmZ2d7eaWEBFRZVVjA52IiAhERUVh7969xe5b3hqQml0F5TqszSEiouLU2EBHCXmfw4x0iIiI3IGBjgKUDnP69u2LGTNmKHxWIiKiyoeBjgsxoUNEROReDHRcKTfSYZxDRETkHgx0XKgyjLpKSEjAQw89hICAAHh6emLIkCE4ffq07f7Y2FiMGDECAQEB8PLyQps2bbB27VrbYydMmIDg4GB4eHigefPmWLZsmbueChERUalxHp1SEEIgI9tc4v0zs83IyjEjzZSD8g4Q8tBpyjTKaNKkSTh9+jR+++03+Pr64rnnnsPQoUMRFRUFnU6HiIgImEwm7NixA15eXoiKioK3tzcA4KWXXkJUVBTWrVuHoKAgREdHIyMjo3xPhIiISEEMdEohI9uM8Jc3uOXcUa8Mgqe+dG+XNcDZuXMnevXqBQD45ptv0KBBA6xatQr33HMPzp8/j7Fjx6Jdu3YAgCZNmtgef/78eXTq1Aldu3YFADRq1KhingwREZFC2HVVjZ04cQJarRY9evSwbatVqxZatmyJEydOAACeeuopvPbaa+jduzfmzZuHI0eO2PZ9/PHHsWLFCnTs2BHPPvss/v77b8WfAxERUXkwo1MKHjoNol4ZVOL9o6+lIjPbjIa1POFj1JX73K4wbdo0DBo0CGvWrMHGjRuxcOFCvPvuu3jyyScxZMgQxMbGYu3atdi0aRP69++PiIgIvPPOOy5pCxERUUWrsRmdkiwBkZ9KpYKnXlviHw+9BkadBh66kj+msJ+y1Oe0bt0aOTk52LNnj21bfHw8Tp48ifDwcNu2Bg0a4LHHHsPPP/+MWbNm4f/+7/9s9wUHB2PixIn4+uuvsWjRInz66aelbgcREZG71NiMTkREBCIiImzLvLuCu0ddNW/eHKNGjcLDDz+MpUuXwsfHB88//zzq1auHUaNGAQBmzJiBIUOGoEWLFkhISMDWrVvRunVrAMDLL7+MLl26oE2bNsjKysLq1att9xEREVUFNTajoyR3zqOzbNkydOnSBcOHD0fPnj0hhMDatWuh08muNLPZjIiICLRu3RqDBw9GixYtsHjxYgByMdO5c+eiffv2uP3226HRaLBixQo3PhsiIqLSUQlRs5ectGZ0kpKS4Ovr63BfZmYmYmJi0LhxYxiNxlIf+8y1VKSZctAw0BN+nmVbAZ0KV973h4iIqq6iPr/tMaPjSpwZmYiIyK0Y6LiQ++dFJiIiqtkY6CigZncOEhERuQ8DHReyDglnnENEROQeDHRcKK/riqEOERGROzDQUQC7roiIiNyDgY4LlXfFciIiIiofBjoKYEKHiIjIPWpsoFOWta5KiwkdIiIi96qxgU5ERASioqKwd+9e153EOuqqiqV0GjVqhEWLFpVoX5VKhVWrVrm0PURERGVVYwMdJXDUFRERkXsx0FEAwxwiIiL3YKDjQraMjoKRzqefforQ0FBYLBaH7aNGjcKUKVNw5swZjBo1CnXq1IG3tze6deuGzZs3V9j5jx49ijvuuAMeHh6oVasWHnnkEaSmptru37ZtG7p37w4vLy/4+/ujd+/eiI2NBQAcPnwY/fr1g4+PD3x9fdGlSxfs27evwtpGREQ1DwOd0hACMKWV7OfaCdRKi4Y+Oxkiu4SPKeqnhIU+99xzD+Lj47F161bbtps3b2L9+vWYMGECUlNTMXToUGzZsgUHDx7E4MGDMWLECJw/f77cL09aWhoGDRqEgIAA7N27Fz/++CM2b96M6dOnAwBycnIwevRo9OnTB0eOHMGuXbvwyCOP2GaQnjBhAurXr4+9e/di//79eP7556HT6crdLiIiqrm07m5AlZKdDrweWuLdPQC0qqhzv3AZ0HsVu1tAQACGDBmCb7/9Fv379wcArFy5EkFBQejXrx/UajU6dOhg2//VV1/FL7/8gt9++80WkJTVt99+i8zMTHz11Vfw8pJt/fjjjzFixAi8+eab0Ol0SEpKwvDhw9G0aVMAQOvWrW2PP3/+PObMmYNWreSr1rx583K1h4iIiBmdamjChAn46aefkJWVBQD45ptvcN9990GtViM1NRWzZ89G69at4e/vD29vb5w4caJCMjonTpxAhw4dbEEOAPTu3RsWiwUnT55EYGAgJk2ahEGDBmHEiBH44IMPcOXKFdu+M2fOxLRp0zBgwAC88cYbOHPmTLnbRERENRszOqWh85SZlZKIOw5YcnDaEgpfH2/U8fUo/7lLaMSIERBCYM2aNejWrRv+/PNPvP/++wCA2bNnY9OmTXjnnXfQrFkzeHh44O6774bJZCpf+0po2bJleOqpp7B+/Xp8//33ePHFF7Fp0ybccsstmD9/Pu6//36sWbMG69atw7x587BixQqMGTNGkbYREVH1w0CnNFSqEnUfAZCBiSUbwuIJi84L0Jcz0CkFo9GIu+66C9988w2io6PRsmVLdO7cGQCwc+dOTJo0yRY8pKam4ty5cxVy3tatW2P58uVIS0uzZXV27twJtVqNli1b2vbr1KkTOnXqhLlz56Jnz5749ttvccsttwAAWrRogRYtWuCZZ57B+PHjsWzZMgY6RERUZuy6cjEV4Jbx5RMmTMCaNWvwxRdfYMKECbbtzZs3x88//4xDhw7h8OHDuP/++wuM0CrPOY1GIyZOnIhjx45h69atePLJJ/Hggw+iTp06iImJwdy5c7Fr1y7ExsZi48aNOH36NFq3bo2MjAxMnz4d27ZtQ2xsLHbu3Im9e/c61PAQERGVFjM6CnDHPDp33HEHAgMDcfLkSdx///227e+99x6mTJmCXr16ISgoCM899xySk5Mr5Jyenp7YsGEDnn76aXTr1g2enp4YO3Ys3nvvPdv9//77L7788kvEx8ejbt26iIiIwKOPPoqcnBzEx8fjoYceQlxcHIKCgnDXXXdhwYIFFdI2IiKqmVRCVLUFCipWcnIy/Pz8kJSUBF9fX4f7MjMzERMTg8aNG8NoNJbuwHHHAbMJpy2h8PL2Rai/cl1XNUW53h8iIqrSivr8tseuKxdToeqtdUVERFRd1NhAR4nVy61EFV0E4ptvvoG3t7fTnzZt2ri7eURERMWqsTU6ERERiIiIsKW+Kp6q+F0quZEjR6JHjx5O7+OMxUREVBXU2EBHKSqIKruqp4+PD3x8fNzdDCIiojKrsV1XpVGmem27hE4VjXMqvRpeR09ERCXAQKcIGo0GAMo4a3DV77qq7NLT0wGwG42IiArHrqsiaLVaeHp64vr169DpdFCrSxEXZlsAs4DFko3srCxkZjKmrChCCKSnp+PatWvw9/e3BaRERET5MdApgkqlQt26dRETE4PY2NjSPTjlGmA24YYwQa33QFai3jWNrMH8/f0REhLi7mYQEVElxkCnGHq9Hs2bNy9999WK/wA3TmFJ9sPwbHor5o9sWfxjqMR0Oh0zOUREVCwGOiWgVqtLP/Nu1g0g9QKSTGnIzBScuZeIiMgNWDjiKir50qpggYWjg4iIiNyCgY7LyFFXagiYLQx0iIiI3IGBjqvYMjoCZsY5REREbsFAx1VyAx2Z0bG4uTFEREQ1EwMdV7ELdHKY0iEiInILBjquYtd1lcMaHSIiIrdgoOMqtoyOBTlmdl0RERG5AwMdV1HljbpiRoeIiMg9amygExkZifDwcHTr1s01J2CNDhERkdvV2EAnIiICUVFR2Lt3r2tOYDdhYDZHXREREblFjQ10XI4ZHSIiIrdjoOMqDoEOMzpERETuwEDHVayBjsrCYmQiIiI3YaDjKpxHh4iIyO0Y6LiKXddVNruuiIiI3IKBjqvYz6PDYmQiIiK3YKDjKrmBjuy6YkaHiIjIHRjouAprdIiIiNyOgY6r2K11JQRgZrBDRESkOAY6rmJXjAyABclERERuwEDHVfIFOuy+IiIiUh4DHVexW+sKAGdHJiIicgMGOq7CjA4REZHbMdBxldxAR6vKDXQ4lw4REZHiGOi4Su48OtrcV5jFyERERMpjoOMq+TM67LoiIiJSHAMdV7EGOrmvMIuRiYiIlMdAx1VyAx0NMzpERERuw0DHVViMTERE5HY1NtCJjIxEeHg4unXr5qIz5BYj5wY62VzYk4iISHE1NtCJiIhAVFQU9u7d65oT2LquZMDDjA4REZHyamyg43LWQEdt7bpiRoeIiEhpDHRchcXIREREbsdAx1VUjjU6OazRISIiUhwDHVexZXTkzWzW6BARESmOgY6r2IaXW1cvZ6BDRESkNAY6rqLWAGDXFRERkTsx0HEVlQx0NGBGh4iIyF0Y6LiKLaOTG+gwo0NERKQ4BjquYg10kDszMjM6REREimOg4yoqa0bHDIATBhIREbkDAx1XUVtrdDhhIBERkbsw0HEVazGyrUaHgQ4REZHSGOi4ijr/qCt2XRERESmNgY6r5MvosBiZiIhIeQx0XEWduwSEbdQVMzpERERKY6DjKmotAEAL1ugQERG5CwMdV7HNjCyHl5tymNEhIiJSGgMdV7EWI+eudWVi1xUREZHiGOi4Sr6MTjYzOkRERIpjoOMquRkdNYuRiYiI3IaBjquorKOuOLyciIjIXRjouIotoyMDHdboEBERKY+BjqvkDi/Py+gw0CEiIlIaAx1XyS1GVgsOLyciInKXGhvoREZGIjw8HN26dXPNCWxdV7mjrpjRISIiUlyNDXQiIiIQFRWFvXv3uuYEucXIeTU6LEYmIiJSWo0NdFzOmtERuTU67LoiIiJSHAMdV8mt0VGxGJmIiMhtGOi4itqxGJmBDhERkfIY6LhK7vBya0aHo66IiIiUx0DHVaxdV5bc4eUsRiYiIlIcAx1XUVtHXbHrioiIyF0Y6LiKNaMjWIxMRETkLgx0XCW3GBksRiYiInIbBjquUiCjIyAE63SIiIiUxEDHVdSOxcgAVzAnIiJSGgMdV8nXdQXIrA4REREph4GOq+R2XcEuo8NlIIiIiJTFQMdVrF1XwgyNWgWABclERERKY6DjKnYZHZ1GBjqs0SEiIlIWAx1XsavR0Wnky8waHSIiImUx0HEVa0YHgCH3VeZ6V0RERMpioOMq6ryX1pAb87BGh4iISFkMdFwld/VyADBqZZcVa3SIiIiUxUDHVey6rowaGehweDkREZGyGOi4itquRsfWdcViZCIiIiUx0HEVh4yOvGSNDhERkbIY6LiKQ0ZHZnKy2HVFRESkKAY6rqJSAZATBerVuTU6zOgQEREpioGOK+Vmdazz6DDQISIiUhYDHVfKHWJuG3XFQIeIiEhRDHRcKbcg2VqjY+KoKyIiIkUx0HGl3K4rvbXrisXIREREimKg40oq+fJai5E5MzIREZGyGOi4kjWjY+26YkaHiIhIUQx0XCm3RsfIUVdERERuwUDHldSOxcicMJCIiEhZDHRcKXd4uSG3Ricr2+zO1hAREdU4DHRcyVqMzIwOERGRWzDQcaV8MyMz0CEiIlIWAx1XUjmOusrKYdcVERGRkhjouJIto2Ot0WFGh4iISEk1NtCJjIxEeHg4unXr5rqTWDM6atboEBERuUONDXQiIiIQFRWFvXv3uu4kaseZkdl1RUREpKwaG+goInd4uV4jMznM6BARESmLgY4rWbuuVPIma3SIiIiUxUDHlXKLkXVc1JOIiMgtGOi4ksox0OHMyERERMpioONK1tXLVTLAYY0OERGRshjouJLWAADQgYEOERGROzDQcSWNHgCgQw4ADi8nIiJSGgMdV9LoAOQFOtlmAbNFuLNFRERENQoDHVfKzehoRI5tk4ndV0RERIphoONKuYGOFtm2Tey+IiIiUg4DHVfK7brSWHKgUctZA1mQTEREpBwGOq6Um9GBOQsGrXypOTsyERGRchjouJIt0DHlBTrsuiIiIlIMAx1Xyu26gjkbBq2cPJBdV0RERMphoONK9hkdHTM6RERESmOg40rOuq5Yo0NERKQYBjquZAt07LquuII5ERGRYhjouBIzOkRERG7FQMeVbMXIrNEhIiJyBwY6ruSs64qjroiIiBTDQMeVrIFOjt2EgQx0iIiIFMNAx5Uc5tGx1uiw64qIiEgpDHRcya4YWc+MDhERkeIY6LiSw6gr1ugQEREprUyBzpdffok1a9bYbj/77LPw9/dHr169EBsbW2GNq/KcdV1x1BUREZFiyhTovP766/Dw8AAA7Nq1C5GRkXjrrbcQFBSEZ555pkIbWKVpDfLSfng559EhIiJSjLYsD7pw4QKaNWsGAFi1ahXGjh2LRx55BL1790bfvn0rsn1VG7uuiIiI3KpMGR1vb2/Ex8cDADZu3Ig777wTAGA0GpGRkVFxravq2HVFRETkVmXK6Nx5552YNm0aOnXqhFOnTmHo0KEAgOPHj6NRo0YV2b6qzZbRyeISEERERG5QpoxOZGQkevbsievXr+Onn35CrVq1AAD79+/H+PHjK7SBVZrWKC9zsmDUWbuumNEhIiJSSpkyOv7+/vj4448LbF+wYEG5G1St6GTBNrLTYczN6GQyo0NERKSYMmV01q9fj7/++st2OzIyEh07dsT999+PhISECmtclWcNdIQFHhoZ4GRwZmQiIiLFlCnQmTNnDpKTkwEAR48exaxZszB06FDExMRg5syZFdrAKk3nabvqpc4CAGQy0CEiIlJMmbquYmJiEB4eDgD46aefMHz4cLz++us4cOCArTCZIEddqTSAMMNTlQ2AGR0iIiIllSmjo9frkZ6eDgDYvHkzBg4cCAAIDAy0ZXooV25Wx0NlAsBRV0REREoqU0bn1ltvxcyZM9G7d2/8888/+P777wEAp06dQv369Su0gVWezgMwpcBDJbuumNEhIiJSTpkyOh9//DG0Wi1WrlyJJUuWoF69egCAdevWYfDgwRXawCovtyDZKGRGhzU6REREyilTRicsLAyrV68usP39998vd4OqndxAx4C8jI4QAiqVyp2tIiIiqhHKFOgAgNlsxqpVq3DixAkAQJs2bTBy5EhoNJoKa1y1YA10hAx0hABMZott7SsiIiJynTIFOtHR0Rg6dCguXbqEli1bAgAWLlyIBg0aYM2aNWjatGmFNrJKyy1G1ossAHI180wTAx0iIiIllKlG56mnnkLTpk1x4cIFHDhwAAcOHMD58+fRuHFjPPXUUxXdxqotN6OjNWdCo5bdVZlcBoKIiEgRZcrobN++Hbt370ZgYKBtW61atfDGG2+gd+/eFda4asG63lV2BozaQKSZzMgwMdAhIiJSQpkyOgaDASkpKQW2p6amQq/Xl7tR1Yp1duTsDHjoZXcVMzpERETKKFOgM3z4cDzyyCPYs2cPhBAQQmD37t147LHHMHLkyIpuY9VmW9gzw1aXw4wOERGRMsoU6Hz44Ydo2rQpevbsCaPRCKPRiF69eqFZs2ZYtGhRBTexirNbwdyW0eHsyERERIooU42Ov78/fv31V0RHR9uGl7du3RrNmjWr0MZVC9ZAJycTRp2MKzlpIBERkTJKHOgUtyr51q1bbdffe++9sreourHV6KTDQ2fN6DDQISIiUkKJA52DBw+WaD/O+JuPXY2OMTfQ4XpXREREyihxoGOfsaFSsA0vT7cFOqzRISIiUkaZipGpFKxdV6Z0ZnSIiIgUxkDH1Qw+8tKUCg8WIxMRESmKgY6rGbzlZVaqLaOTxUCHiIhIEQx0XE1vzeik2EZdseuKiIhIGQx0XM3adZWVAgOLkYmIiBTFQMfV7LquPLTy5WZGh4iISBkMdFzNmtGxZMNLkwOAxchERERKqRaBzurVq9GyZUs0b94cn332mbub40jvbbvqo8oEwECHiIhIKWVa66oyycnJwcyZM7F161b4+fmhS5cuGDNmDGrVquXupklqjZw0MCcTnmoTANboEBERKaXKZ3T++ecftGnTBvXq1YO3tzeGDBmCjRs3urtZjnJnR/ZUZQNgjQ4REZFS3B7o7NixAyNGjEBoaChUKhVWrVpVYJ/IyEg0atQIRqMRPXr0wD///GO77/Lly6hXr57tdr169XDp0iUlml5yubMje6isGR0GOkREREpwe6CTlpaGDh06IDIy0un933//PWbOnIl58+bhwIED6NChAwYNGoRr164p3NJy0MmMjjXQyTAx0CEiIlKC2wOdIUOG4LXXXsOYMWOc3v/ee+/h4YcfxuTJkxEeHo5PPvkEnp6e+OKLLwAAoaGhDhmcS5cuITQ0tNDzZWVlITk52eHH5bRyBXNP5AY6zOgQEREpwu2BTlFMJhP279+PAQMG2Lap1WoMGDAAu3btAgB0794dx44dw6VLl5Camop169Zh0KBBhR5z4cKF8PPzs/00aNDA5c8DOhnoGHJrdNKyclx/TiIiIqrcgc6NGzdgNptRp04dh+116tTB1atXAQBarRbvvvsu+vXrh44dO2LWrFlFjriaO3cukpKSbD8XLlxw6XMAYAt0PFRZAJjRISIiUkqVH14OACNHjsTIkSNLtK/BYIDBYHBxi/LJHXVlELLrKtssYMqxQK+t1HEmERFRlVepP2mDgoKg0WgQFxfnsD0uLg4hISFualUZWLuukGXblG5i9xUREZGrVepAR6/Xo0uXLtiyZYttm8ViwZYtW9CzZ083tqyUcgMdjTkLeo18ydM58oqIiMjl3N51lZqaiujoaNvtmJgYHDp0CIGBgQgLC8PMmTMxceJEdO3aFd27d8eiRYuQlpaGyZMnu7HVpZTbdYXsDHjoNTBlWJjRISIiUoDbA519+/ahX79+ttszZ84EAEycOBHLly/HuHHjcP36dbz88su4evUqOnbsiPXr1xcoUK7UcicMRHYGvPQaJGVkM6NDRESkALcHOn379oUQosh9pk+fjunTpyvUIhfInTAQOZnw0GsAAGlZDHSIiIhcrVLX6FQbuRMGIjsdXgYZW2Zks+uKiIjI1RjoKEFnDXQy4aFjRoeIiEgpNTbQiYyMRHh4OLp16+b6k1kDnZyMvIwOa3SIiIhcrsYGOhEREYiKisLevXtdf7J8o64AII2jroiIiFyuxgY6irJ1XclRVwDn0SEiIlICAx0l2LquMuGpl11XnEeHiIjI9RjoKMGu68qTw8uJiIgUw0BHCfYTBrIYmYiISDEMdJSgsytG1rEYmYiISCkMdJRgzejkZMDLIAMdZnSIiIhcj4GOEuy6rjxyi5GZ0SEiInI9BjpKsGV0MuGlUwFgRoeIiEgJNTbQccvMyAC81CYAQBoDHSIiIpersYGOW2ZGBuCjzgbAjA4REZESamygoyi12raCuafKmtFhjQ4REZGrMdBRSm73lWdu11U6JwwkIiJyOQY6SsktSPaEDHRMZguyzRZ3toiIiKjaY6CjlNyMjocqy7YpLYvdV0RERK7EQEcpuYGO1pwFo06+7CmZDHSIiIhciYGOUmyTBqbD26ADAKQyo0NERORSDHSUYp1LJzsDPkY5OzIzOkRERK7FQEcpDhkdGeikZmW7sUFERETVHwMdpejz1rtiRoeIiEgZDHSUYuu6ss/oMNAhIiJyJQY6SrFbwdw7N6OTyowOERGRS9XYQEfRRT0Bh4yODzM6REREiqixgY6ii3oCjsXIrNEhIiJSRI0NdBTnMLxczqPDQIeIiMi1GOgoxWkxMoeXExERuRIDHaXoCg4vZ40OERGRazHQUYpd15Uto8OuKyIiIpdioKMUJzMjs0aHiIjItRjoKMVZMTK7roiIiFyKgY5S7DI6PpwwkIiISBEMdJTipBg5I9uMbLPFjY0iIiKq3hjoKMVJ1xUAJGdwiDkREZGrMNBRil3XlUYF2zIQiQx0iIiIXIaBjlKsGR1hAcwm+HrIrE4SAx0iIiKXYaCjFGugAwCmNPgx0CEiInK5GhvoKL56uUYHqHNrc7IzbIEOa3SIiIhcp8YGOoqvXg44jLzy92RGh4iIyNVqbKDjFnYLe9q6rtIZ6BAREbkKAx0l2Q0xZ40OERGR6zHQUZLdEHOOuiIiInI9BjpKYkaHiIhIUQx0lOSsRoeBDhERkcsw0FGS3kteMqNDRESkCAY6SmLXFRERkaIY6CjJrhiZgQ4REZHrMdBRkl1GJ8BLDwBIN5mRmW12Y6OIiIiqLwY6SrIrRvY1aqHXyJf/RmqWGxtFRERUfTHQUZJd15VKpUItb5nVuZFqcmOjiIiIqi8GOkqy67oCgCBvAwDgRgozOkRERK7AQEdJdhkdAAiyZXQY6BAREbkCAx0lFZbRYaBDRETkEgx0lJQ/o+NjDXRYo0NEROQKNTbQiYyMRHh4OLp166bcSZnRISIiUlSNDXQiIiIQFRWFvXv3KnfSAoEOa3SIiIhcqcYGOm6hs651ZS1GZtcVERGRKzHQURK7roiIiBTFQEdJ+YqRQ/yMAIDE9Gykm3Lc1SoiIqJqi4GOkvJldPw8dPAxagEAlxIy3NUqIiKiaouBjpKsgY7ZBJhlBqd+gMzyXExkoENERFTRGOgoydp1BQA5MrCpHyCDn4vM6BAREVU4BjpK0hoAqOR1k6zTyQt00t3UKCIiouqLgY6SVKoCBcn1/JnRISIichUGOkrLV5BsrdFhMTIREVHFY6CjNFtGx7FG58JNdl0RERFVNAY6SrNldGRg0zhIzpYcn2bCzTTOkExERFSRGOgoLV/XlZdBi7BAmeU5eTXFcV8hgFMbgaSL8joRERGVitbdDahx9I7rXQFAizo+OH8zHSevJqNn01py4+VDwFejgMzEvMf2nQvcOA20HQv4hwFBLQCtXrGmExERVTUMdJSWL6MDAK1CfLD5RBxOxuVmdEzpwKd9Cj5220J5eWylvOz+KNB+HBDQEPAKAq6fAqI3Ad2m5Q5lL0bqdcCzFqBmYo+IiKonBjpKy1ejAwCt6/oCAA5dSAIsZmBR25Id65+l8gcAWg0H/l0tr2/4DzAvQQ5nt2cxA18MBnxCgMa3A2tnAx0fAEZHyvu3vyVnbe73n4KPJSIiqoIY6Cgt36grAOjWOAAA8O/VZGRsew8e6fGlP641yAEACGCBv7w6YAGw7wsgMdZx/xO/yctDXwMZCbIrbM+SvLb1fR44+A1w7k95jKBmpW8TERGRmzHQUZqTrqvaPkY0q+2N89cS4LHjtYo93+Z5xe9zco3j7V0fyx+rf1cDDW4BjH7A/d8DlhzgZgwQ1JyZHyIiqtQY6Cgt38zIVj2b1EL6tXMF9x/9CdCgO6A1Ans+ATpOAJbeDpizXN9Wexd2y8sF/kCTvsDZbUC3h4HQTkCdNoCHPxDQSNk2ERERFaPGBjqRkZGIjIyE2WxW9sROanQAYHDbEBzZk+i474vXHUdVDXxVXr50TV4mnpf1OFePAAnn8vYLbg1cP1GhzXZwdpu83Pt/jtvnJ7nunERERGVQY4fbREREICoqCnv37lX2xNZAx5TmsLlH40A097ILfjo/VPzQcf8wYNz/gOn7gYa3Am3GyGAjYjcwLxHwC3Pcf/z3edfrtAOevyCHqlcUcw6QmQRcPVpxx7Q684cM7IiIiEqhxmZ03MbgJy8zHbMfWo0az3r8BqQA6TDC0mcBvEt6TI0WmJyvzkalAh7ZKkdR+YbmbZ+XCFw+CAQ2AYy+wJilQKthQN2OwM+PAC2HAMGtgO8nlP65/fs78OMkeX3c10DrEYXvm5Eou+N0xuKPe3Y78L8x8jqzRkREVAo1NqPjNt7B8jLtuuP2ywdROyUKAPB7zi14fOVpZJjK2a3mFeQY5AAyAKrXWdbUAIBGJ7M6tZoCD28Bbp8NtB4OTPsj7zFqHRDSrvjzWYMcAPj+AWDPUjni6/JB4ONuwMIw4MiPwMl1wJsNgf/WAU5vlvvnZAGnNxXIdCF2F7D19bzbFotDIbdNZjJwagOQw2U0iIgoDzM6SvMMkpdpNxy3p17Lu67R4s/TNzD0wz/x/riO6NjAX7Hm2dTvAjx9BPCpK7vQhADijgOf9C75MdY9W3Dbz9Mcb38zFnh0hyywBoCWQ4Hx38nrFjOwbLDj/t/eC1zaBzx1EPAIyNv+3Xgg9i/g1pnAgBKMNCMiohqBGR2lGXzkpSnVcfuhb21Xw+9+ET5GLWJupGF05E6MityJL/8+h4sJCq9wHtAwr05IpQJC2gIv3QDuXgYMfQeo1xWYshGo16V857EGOQBwcq3sqkq/KbM8+UVvkvP+nN+dty0nSwY5AHDgq/K1hYiIqhVmdJRmDXSy7BbwtFiAqFXyul8DtGvXCVsaZuKNdf9i1aFLOHwhEYcvJGLeb8fRKsQHfVvWRu9mtdCraRA0aoXnsdHogLZ3yevdH5aXUzYArwZV3Dm+GikvJ60pfJ/4aNnVlRoH/Dq94s5NRO5z6Du5hl/9cn55cgch5AjYoBZ5g06oUlAJUbOXxU5OToafnx+SkpLg6+vr+hOmXgfeyZ1l+OUEuc5U8mXgvdZyW0Bj4OlDtt0vJ2bg98OXseXENeyLvQmL3bsV4mvEXZ3r4Z6uDdA4yMv1bS9KRgLwZiP3tgEAPAKB52Lc3QoiKq1zO4HlQ+X14gYdCCFHdwa3LHxdv4v7gJgdQO+nAbWmYtvqzOEVwC+PAmE9gSnry3esoyvll7ieERXTtmqqpJ/fzOgozZrRAWT3ldEXSLyQt230YofdQ/098Gifpni0T1MkpJmw/dR1rD5yGX9F38DV5Ews3nYGi7edQbdGAbinSwMMbV8X3gY3vK0eAbJL68CXct2ttbOVbwMAZNwErh6TtUQBjYHpe2UWqsB+ibKtbe8G/Oop3kwiyufGqZLvu+8LYM1MoMVgOVu7M5/1l5ce/kDXKeVunlNC5M0Ob+02P7+r/Mf9aaq8bDZABnNULgx0lKY1yFFMlmzZfWX0BZJyA52wXkDDXoU+NMBLj9Gd6mF0p3rIyjHjjxPX8MO+C9h+6jr2nkvA3nMJWPD7cdzTtQHu7lIfbev5KfSkcrW9K69bq9s0YN1zeYuOKslaMJ0QA2x4QdbwtLsbOPYzcO2EHGW2bo7c5+DXMhgiIvdytpxM0iU5cjT/fbtzvxCeKkHm5Nq/JTt/WjwQs11Ot1FYlih/2z7rD3SZJNcGtP9ClZEoM/V1wkt27sJkJJbv8SWVdgM48gPQfhzgVUuZcyqIxchKU6lkkAMAsX/LS2ug49+gxIcxaDUY0q4ulk3ujl1z++PZwS3RJMgLaSYzlv99DsM/+gt3Ld6J/+06h3RTTgU/iRJQqYChb8mRW/aMfsDdXwC3OxmR5Qr/fCozN1+OAPYvk0tZWIMcoHTfIonIhfIFMwf+B7wfDmx8sZzHLaQ6I3oL8PuMvCktlg8DVk4Gtr1R/CEtZmDLAiDlCrBtodymsZvg9YMOwJKewKX98rY5G9i9pGRBl301iX2XmxByrrN1zxd/jJIyZwMxfwJfjwU2zAV+nFiy9v31vpzOo4pgoONOx3+Wswlvni9vl3GtqDq+RjzRtxm2zOqDr6Z0x7D2daHTqHDgfCJe+vU4evx3C+b/dhxnrqcWf7CKFtAQGPhfWTvzxG7guViZUbEfGp5f49sLv08p107I4fREVPH+XQssH+7Yba+y+zgSAlg/V163X2C4LAorQ/36LvnlZ+eH8rZ12RzrwBB7aTfyjvPbk8ArgcCRfF1m9oFOZqK8PLVRXu75BFj/PLC4h+NjLu4H3mkpsylWFrv50+wzWTdOyXPuWVL4czq7DdjxTuH357fxJeDL4cCVQ/L2uT+Lf0zMdvmZ9e29JTtHJcBAxx3a3i0vPQKAi3bdJm3uKtdhVSoVbm8RjMj7O2Pn83dgzqCWaBDogZSsHCz/+xz6v7sdD36+B5ui4mC2KFiD3ms68OxZoHbrvD/ctoU817odgId+A+acBaZuLnh/54dc08acLCDlau51E7D4FmBJL8Ck8JB+osog4Rzwx2ty8IQrrBgvP1TXzpZdQEtvl8W8Vr89CZhSCn98qdj9r7t6TAZYF/7J25Z80XF3db6KjjNbgbebAr88JgOTwqawyP84ABC5QUv0FueP+XESkHoV+PnhvG0Wuwz85gV5k6DaT7chLM6P99Uo4I9X5WStaTeAhFgZMCbEOt9/zxLn24uSfLn0j3EzBjruYM1YpN0ALh+Q1w1+QO1WFXaK2j5GRPRrhu2z++HLKd3Rv1VtqFTAn6dv4OGv9uH2t7ZiybYzuJmm0EzC+fvYfUKAGcfybj/0G9BzOjDxd7mvVy2gQTdgZL5vcwMWVHzbEi/I0RLvtpSzNmcl591nf70kLh+S/0gv7q/QJlYrafHApQPubgUV5YshwI63HT+AK0JGAhBt9wUm7Qaw8T/AlcN5c2EBwMH/FXzsjWhZhGzOgUM3V0IskHTRMRBIvpJ3fe9nchTT/8bI+r1zfwKf35l3f/4ARZVvhNaf78rLIyuAz+4o/LlpnKxNaDHLzPDZrc4fY3FSVmC/LWa7bL8QeSUOALC4p+xyKsz652Rw9kF7Wc/01ci8ZYcsCi9kXQmwGNkdvHLnnEmPl8sjAECvJ11yKrVahT4tgtGnRTAu3EzH17tj8f2+C7iUmIE31/+L9zefwoj2oZjYqyHa1/d3SRsK5d8A6PWUTFk36SN/8ms1DPgtd56c1iMBz8CKb8eitnnXv7sv3512/1CFALb+V64T1vF+58daPlx+E/18ADAvocKbWmmc3y0/YDqMK/1jF7UFstPl/Etht+Rtv3wICGoO6N08VQIBKbnf2ovqyhBCrqVXWOHujWg5ytSnTt62DzrmdetYpccX354zf+Std2cxA/Gn7Y7ZXl5qDMDskzJTvmGu4+Oto5icUetkoGSlUsvn9vvTcuFkbQnW4wPkZKb5CbOszSmMykmuIX/wkxAD/BoBHPomb9uNk7LLqaRr/yWcA94IAx78BVjxAHDnAjkPmkpdeHbIKvmKLLT2KsVcaclXAO/aygzrLwFmdNzBM7eqPeUKcPRHeV2BIYQNAj0xd2hr7J7bH2/d3R5t6/nClGPBTwcuYuTHcgbmH/ZdQHyqkxmJXWXgq/KPrjD2/2RGflTw/jFLgTGfln925sLcPAN8cw/wy+Ny2OiOt4FVjzvfN8eUl24v7p9HVffFIOCXR2SKvLQjQ7JzuwPt0/lRvwKf9pFrpBVHCFlD5Wzm7KKc2SoLTS3V/L2pSEX9Hq+fC7zR0HmBbcpV4OMuwLst8r7MAQWDnEu5c90UxxrkAIUHDuYs4GTuKCz7JXWKo9YC77fJu21KBd5pIQcx/PGqDBKKY86R2ar8hKXg9BbrXwCifpPX7QOdvxbJy/wZl6RLjkGOPeuAlpL63xggO012GcYddx5o2TOlA++1ktmhwup+Tm0AtryS93cV86d8zHfjS9c2F2JGxx2sgU7ypYLbFGDUaXBv1wa4p0t9HLyQiP/tisWaI1dsMzADQM8mtTCoTR0Max+KYJ8SDLV0Fb2nnJ/HYs5biLTvC8CZLcCEH+UoLgBod48c/bDjLXn7vu9kHUB5LRuSdz3MrpDQfv4MqyU9y3++qmbds/KDx26SS6eyM2UKvoXd2mX2/2S3vy0vz9gtJmuxADvfBxr0ABrdmrc96lc5OiSsFzBlneN5hJC1FP5hwB3/cbzvf6PlZa1mcroBKp6wAFmpsou9YW/Hb+jW+o7VM/ImyDu5TmZFezyWt9+nfQGfULlgcEW4eabw+1Y9ltsNtrPkx8ufdUjMV89inz0qTNJ559tjdgB6H8dtuyPlz/wkx8WdN8+T03Lk7x47WcQM8cuGyGV50m6UfgTpksKnMrGxb19mYsFBJL88DhzOXb6odrj8u9rzibx9uvKMymKg4w4+IQW3eddWvBkqlQqdwwLQOSwA/xnWGt/vvYDVR67gxJVk7Dobj11n4/HK6ih0DgtAr6a1cFuLYLSr5wejTuF0ZP7C5b7PyR97arWcA2LHW/KDsdVQ4OWbcnRERbH21QPAAn+g0W1yAVLrJJDx0Y77x5+Rq8JbpV6T/eyhnZ3PGVKZZGcC5/+WH275uybMTlLrzljMeR8if74r35uNdsGH/WuQ5SQFf+wn+U0RcEzR7/tcXp538m1244uylgIA+jwHaJz8i7t51nl7q7OkizLQ7PZw8RNk5s94fXOPfK0HzAdufUZui7cLNlKuyveq5dC8rl/rh51tn8tygj8llLbAtryjugC5Np8zVw4X/pgbp4GcDMdtbzWW3YGlUZHL71hlJOYGuXY1iqnXZdCWYlf/ZA1yACAxN9hzNkGrmzHQcQeDT8FtQc2Vb4f96b0NiOjXDBH9miH6WgpWH7mClfsv4mJCBvbFJmBfbAI+/CMaWrUKzev4oF09X7Sr54c29fwQXtdX+eDH6ZNoBsw6KYeyA/JDVueZ11XiTLt78roPi5OY71vbuT+BFRNk9uDEbwX3/6hz3gf0zRjgw47y+rD3gG5F1AxUBr89CRz9Aeg8ERj5Yd52IeSQ3KKYc+TjD38rC8wHLMjLtNmzz+jYB0+nNgAtBjl+Q7XPoDlLoQshv9Xaf2ilXQd86xbc11kBqMP9lrxZy6uLb+4BrkXJQuDH7Ip+444D1/+VUz4Asktl1ROOj7UGlPu/lIFO9GY574pVQgywcor8W6qpStLlmt/HXQtuK22Q4woWC/DJrY7Fz4CcgyyyW+GP27IAuG2mrHmyWnIr0PspoL17h6Iz0HGXx3bKmoQGtwAP/eru1jhoVtsHMwb4YMaAFriYkI5tJ69jT8xN7Iy+gZtpJpy4kowTV5Lxwz5ZwKdRq9A02Ashfh5oFuyNUH8j6vl7oE2oH0L9jdBqFCwFy58tKyrI8a0vp4YvaaDjTMz2ku138Ou867uXVP5A52juvB4HvnQMdE785nx5j7PbgCZ95fUjK/K+6e36uIh5kewyOvbBx7f3AvMS8ybWBIDPBwJTN+ZOuGlXw2DNmq2ZlZfpsW9Tx9zuS/tv3DF/Av1yr6del92j9gXQy4fJD/cZx0o1iWeZ/fQwkJMJ3PuV6zJ916Lk5dWjjtut3ReeQXIwwA8PFn6MhBj5AZj/GFbl+Tuq6uyzHFXdH68UDHIA+eWlOEI4jj6LOypH7jHQqaFC2sp/pB7+ztPrlUT9AE88cEtDPHBLQwghcDkpE8cuJeHYpSQczb28kWrCqbhUnIpLxY5TjvNuqFVAgKcevh4yym8V4oPaPgYY9Rp46bWoH+CBbLMFXgYtGtXyglGnhqdeCx+jFhq1Ch46DVTl+eff9wVg2+vyutFPDh3NyP3Qa3aH64uGM5Nkute+DqC4jEJldnab8+1fjQKeiQK8guViivYKCzZVKpnJObAcSMtXPLp8mGOdxcV/ZDCg83B8z+LPyFFw+YMcQNZrdBwvA5svh+dtt2Yo0uLlArtaI/BiXMH7j/8iv41apVx13u1cHqa0vKAy6WLFBlZCyOxYSDvH7SlxjiOhALnqtrNRj/kVFuRQ9fHX+2V/7JLeeRMvViKV9xO2JnCWVq/EVCoV6vl7oJ6/Bwa1kf/whRCIS87CiavJiEvKxOlrqTh7PRUXEzIQezMdphwL4tNMiM+dryfmRlopzwnoNWoEeOrhqddAo1ZBr1XDQyevG3Ua+Bi10GvV8DXqoFWr4KHXQKtWw99TB61xHOr06wGDTgdt7ZbwMGihu3YMteJ2IjH8QdRTX4eTjsSK80aYvLQvNi8s0MlMAr4YLBdFzV9I607ZGTLAAIoO0g5/KyeZy2/nhwW3AXKW18AmMhuTn7NiUnN2bqBjl9HJTAS+LWKIuxDO2wQAbzeRlzmZzu+3r03a8Y4cgTNoIdDzCef7l4V9N1xFB93Hf5FLGhj9Hbe/2wJ4/oJj19zGF/O6r4jK6lohs8lfOQLUba9sW+ww0KFyUalUCPEzIsSv4FwTFovAjdQsnL+ZjrPX0yAgkJltQVxyJuKSsxCfloWrSZk4F58Gb4MW2WYBi0UgI9uMnNyZm4UAsnIsuJpcyIdRqeyxu94W2CGHvT6uuQ9XRCDG67ajh8rxD3WJx8NI8G2NF+LKWUhpP1eIqZBgb98y2cVwLar4QCcrVda46D3L166S2PNJXhFqUZONFRZQWCfFzO/GKeDP90rejhX3A33nOtYx5GQVPbojO6Nk838IIfe1fz3tiyr/eFVebpgrA50rh2VdRv95BUdw5WTJIK5JvxJkaEQh1yvAsZ/kZf4h3YAsnK/X2XFbZI+C+xFVhKW3lXzOHxdgoEMuo1arUNvXiNq+RnRtVPLRT0IImMwW5JgF0kw5SErPxo1UE9QqwCwEsrItuJ6SJUs8BJCSlYPMbDOuJWfCoNMgJTMbSRnZ8rPLbEFyZg6yss1IM5mRnpWDm+nygzLHLJBjEVhiHgkAWJXVG0cN0+CjyhsJsSihN7IS9Giv64Hhmj3Omlt6GTdx9J2hOFrvPugz4nD3+dewrsv/wff6FeSuu46Ur8YjY/Qy+HvqodeqYbEIqNW5XXjmbGBhPTn/x4vXSj8pl8UCrH4aCO0ka5SKk3xZPmbPJ3IuoYoUV4qukHN/Asv/lMNYrayTSRYm4ybw7+qC20/87nh71eMyOHnSbkZrTRHTKqycIovTf5paMND58z1g+xtytvO5hQw7tnLI6JQx0Pl9hgxcHvrV8Xchs6gPFifnKu0s4ERVBAMdqnRUKhUMWg0MWsDLoEVtHyOa1yn+cWWRlWNGamYOzEIgLcuM2KyT0J5ag1bbH8ehkLsxo1V76DQqXL/8MHDCMdC5rq2L4JyyFSG2S92JdifzumeG7Hecat/n7Fp8/OYMLDWPsG3TqFWwCIHb65jwJQBYcvD2b/uRpvaCXqtG02AvpJvMaBTkhUBPPQw6NRrV8oJBq3asczq9Qa7Xc+CrvEDHYpHT7tfvBtQJd2gLtEZZhJx/tll3sRbWloT9RHD28o+SOfydvPyf3VQGag2wa7HjHD5WhWXlgLwZcu2HzAvhfB4S++6qsnZdWUfBnd8lpwOIPwMENi76MQoudUcEwPncYwphoEM1mkGrgcE791uwtVin3v1A94Ho6FkLHa1/mBduAPY1dg9vRXBoJzmfjovM1X2HpebhAFQYr9mCYCThQ8tdOHk1BcjtKfzf7nNIRsmWTDDq1LAI4DH/vbB2xL21/l/4GbXoePlb9Dgl5wmKmX4ZDh+TWmPJJk2rDuznBDr8XeHF10VlX/IHLBYzsLSPzF498BPQbEDh++aXkyWH66rtRi6m3ZDF2h3uy+tSBGSX3sGvZZar1fBilm+wKD+fUFALua5c/rljSip8dMGVxTUGOSMyVX75u4YVxECHyJn8dR32S0y0GFKwvsFFzgbOQOKAdxD4mxxV5NFhDOqFtAJyJxAe3zUUF7I8kG4yI8Nkxp6YmwgL9ER8ahbSTI71NJnZ8kP1ws10IHcE6OJtZ/CS9n/ooc2bYfiN997CUrsRoh/8cRqent6o4OUdK7+4IjJH9gFKdiagMzq/D5BdWdYuuj9eyxfoFNF1lZkEvNdG/q5NtJunaeciOffN5vlAPbu5WOyXSXDWXWdv62tyhmglBTSSwU5xbctvxAdAl0lyKYTky3IEnpXeE8hQONBpOazo2YrJuawUBjpKi4yMRGRkJMzmmreSK5WBWiNHpRz7Cej9tHKnTb+OwN8m2m4/3rM24F3HFujMHdS84FDhXFk5ZlxPyULU5WSoVSokZ2bj+OVkdE48BeRO4vxG0+O475LjMgpL9Yscbj+t/QWoBPOYVS52Qcmhr4EuU+QcNLWaFQx0di8u4jD2+9od80a0nKDNlFJwrib7iSvth82XxtlthWerXKXlELkwrxByOHvTfnJRX2cT59lrnzuqzq8eMG2THMIcd0xu6/4IsP3Nwh/bZbLzCS77vSiDvbLoPi0v0Jl7EVhY3/F+3/pyDqjUuIKPtddmjBwZVxrD3lNuhumK5obZ/61q7KKeERERiIqKwt69e93dFKoq7voMmH0aaGi3ptWj+RYkbHSba9ugUjsO8f56rJwXxQmDVoP6AZ4YiN0YoDuCuzrXx0vDwzGsXahtn/su/de17a3KiupWss++mNLlwpX/rpbZFvu5Zha1y5u3yd7Gl4DvH3QcKm8d0XZmq1wQ89eIvPv+tcsgRFWuCUZL5IGfgc6TZKZ0/LfAM8fkIr32M8I3u9PxMe3HAb1n5E1tYGWdmFLnCdz+LNCpiEkO248DnrcLDMN6AtP3A33mAE8WMhrQXmCTgtu8Q2TAMXqJ81nuTSlwmAyzMPcsL36f/Moy0WjLobIw3t3cuOxNjc3oEJWaWl3wW0ndDnKZA+vSA83vLLo2orzijgOnN9rdPirnRXkmquAaRnFR8kP2x9yM0Es3KuU6NJWWKCTb++19QPqNvNvx0cCml5zvm3/ZkMsHgUPfAX/nzi3U4b68+35/Gmg+ALjuZHHGFfcDTx9xXGSxqhj6DtCsf/H75V9T7a5Pne/X7z+AXwOg5WA52eqoj+XEq39/lLfP2M+BOm2B2q0cH9vubrlUDOC4Dp0zdy+TdUGv5Csg9w0tOuDIMQFaj8LvL6tnSlGEb6/bNFkfc3ZrxbanCqmxGR2iCmM/82xWimvP9ftTzmsc8v8TS74sV1NfPixv2+b5wNGVlX9B0UoiK7uQyRFP5Vsx/cCXpTvwKruVve3nJbqwW9bw2Neg2Nv1MfDlCOf3KWGIk/XKnHku3+rfnsVMLXH7HEDnJeckstIVUWCv9wRueUzW/Fj1nwdMtntffEMLBjlA0UXk1kyRVdu7HIvAAblOmId/4ccw+AL3feP8vhcuy1GNZWX9ItNmTNH75adSAcPeBWrlW0+xPG2pYhjoEJVXu3uBwW8Aj2zLG4rsWUsu8dHgFmXaYDHL+XU+6gLM9wM+7Vdwn10fy3lfqEQMOS4OWgHncyAlnHO+78l1Ra/d5mo9HnWy7TFg5r+O2zz8HYMWVTHzPN3xouxeCm5h95hSBuMaHdCwl+xS6vG47KJyJn+gM+ZTGVQ98JPjmoNBdm15ZJvs/on4p+ByGoDs0rZePhcrs1f26z1N2SgDJL2X44KXZRVayECI/DNgWzXuI7NXT9otzVKvKzBtMzBpbfnbU5hZJ1137FJi1xVReanVwC2Py+tCABN/l5PaeQUBUzfI0SLCDJz5Q3ZPFCp3BsSy+P0p+WOVerWY89QwHoHOa2XcbMuvX6IEnTqSs4UW3eWR7YB/mJwXSKWSBbjJF/Puv22mXM0aKNmElgXW+yvj72ixNSz5/r46jJPdWfnbqLLLAYR2AsZ/V/gh298DhI907Hq7Zznw3X3AwFeBMLsZp/MHcJPXASsmlO53s8djzrtKp2wAvhvnGCiP+MD5699ikLxs1BvoOAE4VEgWyqosfz/268Lp3DPayooZHaKKpFLJ1brth6f71ZMfCl0mFSxetjf7tKwrcDVTasUf89ZngEGv590Obl3yxzbsXfw+pdXvP4BfWN7tib8BUzdV/HnKqX9GEctXVEaP/gmMXwGEdpRdUtYP7rs/l4vXDl9U8DHFZXTsDX5DXo79v/K21DlnXVdOA7FSBlr564vqdwFmn3KswXJ23Ia9gOdiZP3c3IsoEa0eaG3Xhfn4LmDaH7Kr7unD+U5XyEe8faG9ffdpl8lyKg2tB9DRblLN/AXhVg9vBZ7YLWumitLx/qLvdzFmdIiUVLdD3vWAxnkT1GmNgHcw8PhO4PIh4NMSrCRdVqtnVPwxb5sFpN8ENrwg0/sPbwVezQ32WgwBojfLIbfOjF4MfNDB+X1l1edZWfvxZiM5I3FgU1k0TGX24qqj0Ko1CAtshVPHjqBJsBe6NQqEXqtGtqoVfKceh9Ggh0+mfJ+t45Eyzbb5LZFjtkCrkR++yZnZ8DFoHWftvuVxOVt3/sChwhSTMR3yFrDlVWB0ZPlP5az7rbAuOY3O+UCB1iPkqvb5R6Q16SuXMVHrCs5k7nhC55sd5m+yC3RGLJKXFrMMAA99LW87ez/8G+bNJ6b3dn4evzAg6bws6nYjBjpESpt9Ws5uu/HFvEDnQbv5NEI7AlM3A58PcPrwSuGWCGC33YeBwUf+zDkDGP0c/2m3GQOM+1qm1D/uUuBQhdYtBDYFbp4pextVKlknYDbJAlZn6fOnDgEQwIedyn6eGmCHuR2+3l3Mul35nMuNbvr8Lx5xWANvgxapWQULvLs3DsSxS0lIN5kxtF0ILBYgyEeP9Cwzfj54Cff3CMPemJtoX98fTYK9oFIBFxMycGd4HUAAORYBo06Nm2kmtK/vD2+DFpnZZsTcSEPjIC/U9jXA+jFttlhQZH6px6NylFJp148rqWHvAsuGALeWcC6cJn1le/LrkrsqfVgxNYCFTdBXWEbHKv/zd/Y3ar+4bv4Rita5jx7fCSTGOq9tUhADHSKledeWPx3vB85sAULayxS2Pd9Q54+tLHzrOt/udKVwIWswgpo57+tXa+G0Pmnc/4Al+V4XZzqMz1urCpBpfCudMW/WYmcriVvXhGp6h6yhquayW4/Gv40not1aOXIn0bsp/FPzgsmo4CEIv76uwOPeq7MQ9VKzcSkxAz0aB+LwxURkZlsQ4mvE1eRMAIBaJddjyzbL97FL5hL4qtIRBznqylmQAwD/xOT9Pqw9WrC27Ns9MsA6fS3V6faSsAZd89ecwv9+c5zV2EOnQb0AD2SYzEhINyEs0BPpJjMsQmBK78ZIzszGkYtJaFHHB5cSM9C4licCvfTYdCIORq0Gj/dtastK+XlokZVjgY9BB2+jFmaLQC0vPdRqFcwWAVWtFlDPOVN8sbVnLaD/y4XPEaTWFFxM1pnWIwu5w+5vrWEv4PjPRR/HJwS4ka+4OCfL+fWJvwP1u8vrRl+3BzkAAx0i92k7Vg6RDW5Z8D5vF61iWlFUajk/ytrZzusyCuMsPa/WAs/HAm+E5du3kO6LO16Uw7ABOUHjmE8cAx1nrycg0+/PXwDWPy+LL1sMzrtv+PtyCQWl139SmC6sB9p16gnkDrbxv3cx8MUg2/3hwQYg/1Q9Iz/Cqs5FT4RpyrFAr5VdUimZ2VCrVLiZZoIQQEK6CbE30yGEgIdOg8uJGdBrNdh9Nh4Na3nCU69FSmY2riRlwqjTwGIR8PfSIfZGOmJupEGlAv69KkfANQj0QFa2BddSslDXzwi1SoW43EArx1J4t9RHOaPRT30IK823F7gvI9uMaLsgynouAHhldd7cNX/8e83psbcUst1e4yAvxNzIWwhWp5ELF1uDv8ZBXmhf3w8f5N5/IKM2tt/shawNpxGfmoV1x66iUZAnRnYIhYdei5upJrQJ9UWaKQcBnnrsPhuP21sEQ6dRo2HYEASdX4d/Or+JjDOJ6FjfHwDg66F13pHVZbIcEeZspNqElXJ+olEfy8kv7dkHN/bZncYFX2N3Y6BD5C4qFVC/kOnvC4xCqQTu/Qr44SF5Xa0Fuj8sU9RG36IfZz9fh7MUuEYru7ucbc/v4a2yLqD9OLmAZbfcFbjsp/ovqtvB6CuDmvBRjkXQAY3kSKI3iimqrOq6PyyDzR6PyUnkwm6RyyGc+FUOj/7j1bx97/1KTk7Z7t5iD2sNcgDAxyjfYy+DfP/CanmiQwP/Ao+5v0dYgW3lIYRARrYZKqhgyrEgK8eMCwkZSMvKgUrVHdfMFsy+kY7fDl1C4yAv1PE14maaCf6eOvzfnzHo1igArev6IvpaKqKuJCPUzwOBXnpYhEBsfDq8DVqcjEvJfY5apGQ6ZqgMWjW0alWBNeYAOAQ5AJBtFsg25zjcH3MjDR8Y8+7/YIvjQrrHLiXj2KXkQp//4m0yM6fB/aivuhOxf4cAfzvOyfScdgRGav7G8I1NkbDRPrPlhybBsUjPOov6AR7wNGix45Q14n0UYz0S0CmnP9qqz6GjWp4nOzsL0/+3DxuOx+GQIQX+uVHUD/su4N8rKdBpVBjVsR5Ss3Kg16oRXtfX4fdESSohippBqfpLTk6Gn58fkpKS4OtbzD9sIiWlXpNr+oR2kkW1+T3ws+xusc7K7Grzk+QcPYBMTxf3zS31mqxFsi+W/KCj4wrhgJxITe8FvF7PcUTYM8eB99vk3e45HRhUyJIVcVFygkSg7DNA52QBr5VwPR6VpvCZkyurdvcWP5rpxmmZ4en1FHDrDEWaVVUJIaBSqRwKrIUQSM3KwY1UE4w6NTKzZcCVkpmD7BwLzsWn48D5BITX9cXus/E4fjkZAV46tArxRbCPAc/tlkPRD2na4fNmHyHY24D9sTdx+GISAKBViA9yLAIxN9Jg0KoR7GPAzVQTUgrpFiyk5SjPFBPnjHIE1WURiF5Z8n/PXsNjCFbJIKxR5rdOH7f/xQGo5V2xReYl/fyuhF8biQhAbi3PHfL6gPnAnqVAyhV5u9Ftsq7ElctNOPPwH8D1kyVLT1trkewFtyoY6FiHwE7ZACy9La9QUp3v31NhQQ7gOGdHaYYz29MagAdXyW6wI98XvL9WcyA+91t2SDtZY7Xu2bKdSyn1ugK9ngT2fQ4MLMEilkHNZUE5Z88ulrUuxxrkWLf5GHW2rFZ+vZrlZbKm3Nq44A675UXHsAB8NL7kBfJCCKSbzPDKLcTOsQiYzQKJGSboNGqYcizYF5uAuORMXEzIQKcG/oiJT4O/hw4nr6bAy6BFWKAndBoVkjJyYLZY8NlfMUg3maHXqtGvZTD+PhOPlMwc3J31MubofsCC7Ids53/M9Awi9R9iQfZDUKnyBnVp1CrU8tJDp1HDU+++cIOBDlFVcOsz8mfH24ApTQY+gJwN2VVumwWc2ijX07Kq10X+lNWIRcAGL+DYyrxt1jk6QtrKidas3WP2Q1aLq1nyDJSTr2kMBaftL42m/eTP2e0FJ10Mbinrgf58VwYNtZrmBTp+YcDQt+Vz+aqQAtCKLniu3w24WMyixJYcoM1o+VNSDHLcr7D5bwrbXaWydRUadXmBvp9nXsDVKKiIZTWcmDmwkFo3DAMwC2sLbJuJJbm3rNmuyoITBhJVJbfPyQtygIKBTvOBwIAF5TvH1M1An+fkuSqaT4icXO75C3JI/UvxjvfbD3U1eAP3fQu0Gi5rc4rTsJecqK0i2BdX2qvfVc6Sm39BSLVGLjLpV9/543zry+c7dbPsiixMaabkH/d18e9RVeteI6mUgU5lU5mCHICBDlHVZs5yvO1Zq+jaisZ9gLmXZL3NzH/lrKZ3vCSLea1COwH9XpDZiTtelNsKG+ZaVkZfmeHIX3Ccf06PVsPkIon5V2Z3tdJmyqwF0PZrHNmz/uNv0E2unVSY2qWYUdonRL4/o3O/RzvLtDmbI4Uqvyoe6FQ27Loiqsq87WpT6rSTQYsz85MKbvOtK39qtwYSLzgftdRyMDA7upD5cVzAfiIzd+r3ArBhLtB5YslWJ1cVE+jkV7sNcO2447Y67ZwvzHj3MmClXSA6arFjVqjj/XJSxv1fApf2Oz7WfoVvqjr8K3ZEWk3HQIeoKuv1pJx5NHwU0HJI2Y/j3wAYtFBmWvKnnb2Dy9fG0ghqrty5inLL43IV6lrN8gKdogaoWr+BFzraK99rOm0z8HrupItdp8r6HqBgfdG9/5PLANgHOp0mFDx8/rWIJq8H9n5WdAE3VT4P/gIc/l5OFkgVhoEOUVVm8JYFshWh5xMVc5zyqNdZzt/i39C97VCpCp940Blb11UhgY51dmYrvaesr9n/JXD77MLn/mnaT7al99PAzg+KXiy143jg7w9lgNawp/yhqqXpHfKHKhQDHaLqbsyn7m5B6YSPcncLSs+6ZId919U9XwJ/vQ8kngfGfl7wMXe8KFdZL6xws8Etcv0wQE7qF9pZTitQGKMfMONY+UadEVVDDHSIqjPPWkCHce5uRTXhpOtqwkpg9xI52zLgOPOzfwPg0e1FH7Ko0SlaveP1kgwRZ5BDVAD/Koiqo57T5eWg193bjuogLHdh0S6TCt7X/E7gwZ/zhpXbBxrOCotLI6R9+R5PRAC4BASXgKDqSQgg7XrBmYmp9HJMQNKFgnPnFObIj0D6DVnQXBZXDgNRvwK3zpQ1WETkVEk/vxnoMNAhIiKqckr6+c2uKyIiIqq2GOgQERFRtcVAh4iIiKotBjpERERUbTHQISIiomqLgQ4RERFVWwx0iIiIqNpioENERETVFgMdIiIiqrYY6BAREVG1xUCHiIiIqi0GOkRERFRt1dhAJzIyEuHh4ejWrZu7m0JEREQuwtXLuXo5ERFRlcPVy4mIiKjGY6BDRERE1RYDHSIiIqq2GOgQERFRtcVAh4iIiKotBjpERERUbWnd3QB3s46uT05OdnNLiIiIqKSsn9vFzZJT4wOdlJQUAECDBg3c3BIiIiIqrZSUFPj5+RV6f42fMNBiseDy5cvw8fGBSqWqsOMmJyejQYMGuHDhAicidCO+D5UD34fKge9D5cD3oWIIIZCSkoLQ0FCo1YVX4tT4jI5arUb9+vVddnxfX1/+IlcCfB8qB74PlQPfh8qB70P5FZXJsWIxMhEREVVbDHSIiIio2mKg4yIGgwHz5s2DwWBwd1NqNL4PlQPfh8qB70PlwPdBWTW+GJmIiIiqL2Z0iIiIqNpioENERETVFgMdIiIiqrYY6BAREVG1xUDHRSIjI9GoUSMYjUb06NED//zzj7ubVG3Mnz8fKpXK4adVq1a2+zMzMxEREYFatWrB29sbY8eORVxcnMMxzp8/j2HDhsHT0xO1a9fGnDlzkJOTo/RTqVJ27NiBESNGIDQ0FCqVCqtWrXK4XwiBl19+GXXr1oWHhwcGDBiA06dPO+xz8+ZNTJgwAb6+vvD398fUqVORmprqsM+RI0dw2223wWg0okGDBnjrrbdc/dSqlOLeh0mTJhX4+xg8eLDDPnwfym/hwoXo1q0bfHx8ULt2bYwePRonT5502Kei/hdt27YNnTt3hsFgQLNmzbB8+XJXP71qhYGOC3z//feYOXMm5s2bhwMHDqBDhw4YNGgQrl275u6mVRtt2rTBlStXbD9//fWX7b5nnnkGv//+O3788Uds374dly9fxl133WW732w2Y9iwYTCZTPj777/x5ZdfYvny5Xj55Zfd8VSqjLS0NHTo0AGRkZFO73/rrbfw4Ycf4pNPPsGePXvg5eWFQYMGITMz07bPhAkTcPz4cWzatAmrV6/Gjh078Mgjj9juT05OxsCBA9GwYUPs378fb7/9NubPn49PP/3U5c+vqijufQCAwYMHO/x9fPfddw73830ov+3btyMiIgK7d+/Gpk2bkJ2djYEDByItLc22T0X8L4qJicGwYcPQr18/HDp0CDNmzMC0adOwYcMGRZ9vlSaownXv3l1ERETYbpvNZhEaGioWLlzoxlZVH/PmzRMdOnRwel9iYqLQ6XTixx9/tG07ceKEACB27dolhBBi7dq1Qq1Wi6tXr9r2WbJkifD19RVZWVkubXt1AUD88ssvttsWi0WEhISIt99+27YtMTFRGAwG8d133wkhhIiKihIAxN69e237rFu3TqhUKnHp0iUhhBCLFy8WAQEBDu/Dc889J1q2bOniZ1Q15X8fhBBi4sSJYtSoUYU+hu+Da1y7dk0AENu3bxdCVNz/omeffVa0adPG4Vzjxo0TgwYNcvVTqjaY0algJpMJ+/fvx4ABA2zb1Go1BgwYgF27drmxZdXL6dOnERoaiiZNmmDChAk4f/48AGD//v3Izs52eP1btWqFsLAw2+u/a9cutGvXDnXq1LHtM2jQICQnJ+P48ePKPpFqIiYmBlevXnV43f38/NCjRw+H193f3x9du3a17TNgwACo1Wrs2bPHts/tt98OvV5v22fQoEE4efIkEhISFHo2Vd+2bdtQu3ZttGzZEo8//jji4+Nt9/F9cI2kpCQAQGBgIICK+1+0a9cuh2NY9+HnSckx0KlgN27cgNlsdvjFBYA6derg6tWrbmpV9dKjRw8sX74c69evx5IlSxATE4PbbrsNKSkpuHr1KvR6Pfz9/R0eY//6X7161en7Y72PSs/6uhX1e3/16lXUrl3b4X6tVovAwEC+NxVo8ODB+Oqrr7Blyxa8+eab2L59O4YMGQKz2QyA74MrWCwWzJgxA71790bbtm0BoML+FxW2T3JyMjIyMlzxdKqdGr96OVU9Q4YMsV1v3749evTogYYNG+KHH36Ah4eHG1tG5H733Xef7Xq7du3Qvn17NG3aFNu2bUP//v3d2LLqKyIiAseOHXOoFaTKgxmdChYUFASNRlOgsj4uLg4hISFualX15u/vjxYtWiA6OhohISEwmUxITEx02Mf+9Q8JCXH6/ljvo9Kzvm5F/d6HhIQUKMjPycnBzZs3+d64UJMmTRAUFITo6GgAfB8q2vTp07F69Wps3boV9evXt22vqP9Fhe3j6+vLL3YlxECngun1enTp0gVbtmyxbbNYLNiyZQt69uzpxpZVX6mpqThz5gzq1q2LLl26QKfTObz+J0+exPnz522vf8+ePXH06FGHf/abNm2Cr68vwsPDFW9/ddC4cWOEhIQ4vO7JycnYs2ePw+uemJiI/fv32/b5448/YLFY0KNHD9s+O3bsQHZ2tm2fTZs2oWXLlggICFDo2VQvFy9eRHx8POrWrQuA70NFEUJg+vTp+OWXX/DHH3+gcePGDvdX1P+inj17OhzDug8/T0rB3dXQ1dGKFSuEwWAQy5cvF1FRUeKRRx4R/v7+DpX1VHazZs0S27ZtEzExMWLnzp1iwIABIigoSFy7dk0IIcRjjz0mwsLCxB9//CH27dsnevbsKXr27Gl7fE5Ojmjbtq0YOHCgOHTokFi/fr0IDg4Wc+fOdddTqhJSUlLEwYMHxcGDBwUA8d5774mDBw+K2NhYIYQQb7zxhvD39xe//vqrOHLkiBg1apRo3LixyMjIsB1j8ODBolOnTmLPnj3ir7/+Es2bNxfjx4+33Z+YmCjq1KkjHnzwQXHs2DGxYsUK4enpKZYuXar4862sinofUlJSxOzZs8WuXbtETEyM2Lx5s+jcubNo3ry5yMzMtB2D70P5Pf7448LPz09s27ZNXLlyxfaTnp5u26ci/hedPXtWeHp6ijlz5ogTJ06IyMhIodFoxPr16xV9vlUZAx0X+eijj0RYWJjQ6/Wie/fuYvfu3e5uUrUxbtw4UbduXaHX60W9evXEuHHjRHR0tO3+jIwM8cQTT4iAgADh6ekpxowZI65cueJwjHPnzokhQ4YIDw8PERQUJGbNmiWys7OVfipVytatWwWAAj8TJ04UQsgh5i+99JKoU6eOMBgMon///uLkyZMOx4iPjxfjx48X3t7ewtfXV0yePFmkpKQ47HP48GFx6623CoPBIOrVqyfeeOMNpZ5ilVDU+5Ceni4GDhwogoODhU6nEw0bNhQPP/xwgS9ZfB/Kz9l7AEAsW7bMtk9F/S/aunWr6Nixo9Dr9aJJkyYO56DiqYQQQuksEhEREZESWKNDRERE1RYDHSIiIqq2GOgQERFRtcVAh4iIiKotBjpERERUbTHQISIiomqLgQ4RERFVWwx0iIjsbNu2DSqVqsAaRURUNTHQISIiomqLgQ4RERFVWwx0iKhSsVgsWLhwIRo3bgwPDw906NABK1euBJDXrbRmzRq0b98eRqMRt9xyC44dO+ZwjJ9++glt2rSBwWBAo0aN8O677zrcn5WVheeeew4NGjSAwWBAs2bN8Pnnnzvss3//fnTt2hWenp7o1asXTp486donTkQuwUCHiCqVhQsX4quvvsInn3yC48eP45lnnsEDDzyA7du32/aZM2cO3n33XezduxfBwcEYMWIEsrOzAcgA5d5778V9992Ho0ePYv78+XjppZewfPly2+MfeughfPfdd/jwww9x4sQJLF26FN7e3g7t+M9//oN3330X+/btg1arxZQpUxR5/kRUsbioJxFVGllZWQgMDMTmzZvRs2dP2/Zp06YhPT0djzzyCPr164cVK1Zg3LhxAICbN2+ifv36WL58Oe69915MmDAB169fx8aNG22Pf/bZZ7FmzRocP34cp06dQsuWLbFp0yYMGDCgQBu2bduGfv36YfPmzejfvz8AYO3atRg2bBgyMjJgNBpd/CoQUUViRoeIKo3o6Gikp6fjzjvvhLe3t+3nq6++wpkzZ2z72QdBgYGBaNmyJU6cOAEAOHHiBHr37u1w3N69e+P06dMwm804dOgQNBoN+vTpU2Rb2rdvb7tet25dAMC1a9fK/RyJSFladzeAiMgqNTUVALBmzRrUq1fP4T6DweAQ7JSVh4dHifbT6XS26yqVCoCsHyKiqoUZHSKqNMLDw2EwGHD+/Hk0a9bM4adBgwa2/Xbv3m27npCQgFOnTqF169YAgNatW2Pnzp0Ox925cydatGgBjUaDdu3awWKxONT8EFH1xYwOEVUaPj4+mD17Np555hlYLBbceuutSEpKws6dO+Hr64uGDRsCAF555RXUqlULderUwX/+8x8EBQVh9OjRAIBZs2ahW7duePXVVzFu3Djs2rULH3/8MRYvXgwAaNSoESZOnIgpU6bgww8/RIcOHRAbG4tr167h3nvvdddTJyIXYaBDRJXKq6++iuDgYCxcuBBnz56Fv78/OnfujBdeeMHWdfTGG2/g6aefxunTp9GxY0f8/vvv0Ov1AIDOnTvjhx9+wMsvv4xXX30VdevWxSuvvIJJkybZzrFkyRK88MILeOKJJxAfH4+wsDC88MIL7ni6RORiHHVFRFWGdURUQkIC/P393d0cIqoCWKNDRERE1RYDHSIiIqq22HVFRERE1RYzOkRERFRtMdAhIiKiaouBDhEREVVbDHSIiIio2mKgQ0RERNUWAx0iIiKqthjoEBERUbXFQIeIiIiqLQY6REREVG39P2LYYB59WsrzAAAAAElFTkSuQmCC"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val loss: 0.2349768877029419\n",
            "Train loss: 0.28193721175193787\n",
            "Test loss: 1.531461477279663\n",
            "dO18 RMSE: 2.036725930861386\n",
            "EXPECTED:\n",
            "    d18O_cel_mean  d18O_cel_variance\n",
            "0       26.663818           0.574594\n",
            "1       26.663818           0.574594\n",
            "2       26.663818           0.574594\n",
            "3       27.559140           0.780698\n",
            "4       27.559140           0.780698\n",
            "5       27.559140           0.780698\n",
            "6       27.559140           0.780698\n",
            "7       27.559140           0.780698\n",
            "8       27.559140           0.780698\n",
            "9       27.559140           0.780698\n",
            "10      27.559140           0.780698\n",
            "11      27.559140           0.780698\n",
            "12      27.559140           0.780698\n",
            "13      27.260748           0.830341\n",
            "14      27.260748           0.830341\n",
            "15      27.260748           0.830341\n",
            "16      27.260748           0.830341\n",
            "17      27.260748           0.830341\n",
            "18      27.260748           0.830341\n",
            "19      27.260748           0.830341\n",
            "20      27.260748           0.830341\n",
            "21      27.260748           0.830341\n",
            "22      27.260748           0.830341\n",
            "23      27.260748           0.830341\n",
            "24      27.260748           0.830341\n",
            "25      27.260748           0.830341\n",
            "26      27.260748           0.830341\n",
            "27      27.260748           0.830341\n",
            "28      27.260748           0.830341\n",
            "29      27.260748           0.830341\n",
            "30      27.260748           0.830341\n",
            "31      27.260748           0.830341\n",
            "32      27.260748           0.830341\n",
            "33      27.260748           0.830341\n",
            "34      27.260748           0.830341\n",
            "35      27.260748           0.830341\n",
            "36      27.260748           0.830341\n",
            "37      27.260748           0.830341\n",
            "38      27.260748           0.830341\n",
            "39      27.260748           0.830341\n",
            "40      27.260748           0.830341\n",
            "41      27.260748           0.830341\n",
            "42      27.260748           0.830341\n",
            "43      27.260748           0.830341\n",
            "44      27.260748           0.830341\n",
            "45      27.260748           0.830341\n",
            "46      27.260748           0.830341\n",
            "47      27.260748           0.830341\n",
            "48      24.964000           0.108138\n",
            "49      24.964000           0.108138\n",
            "50      24.964000           0.108138\n",
            "51      24.964000           0.108138\n",
            "52      24.964000           0.108138\n",
            "53      24.964000           0.108138\n",
            "54      24.964000           0.108138\n",
            "55      24.964000           0.108138\n",
            "56      24.964000           0.108138\n",
            "57      24.964000           0.108138\n",
            "58      23.752000           0.524370\n",
            "59      23.752000           0.524370\n",
            "60      23.752000           0.524370\n",
            "61      23.752000           0.524370\n",
            "62      23.752000           0.524370\n",
            "\n",
            "PREDICTED:\n",
            "    d18O_cel_mean  d18O_cel_variance\n",
            "0       26.023191           1.137545\n",
            "1       26.023191           1.137545\n",
            "2       26.023191           1.137545\n",
            "3       25.019957           1.693757\n",
            "4       25.019957           1.693757\n",
            "5       25.019957           1.693757\n",
            "6       25.019957           1.693757\n",
            "7       25.019957           1.693757\n",
            "8       25.019957           1.693757\n",
            "9       25.019957           1.693757\n",
            "10      25.019957           1.693757\n",
            "11      25.019957           1.693757\n",
            "12      25.019957           1.693757\n",
            "13      25.029905           1.684182\n",
            "14      25.029905           1.684182\n",
            "15      25.029905           1.684182\n",
            "16      25.029905           1.684182\n",
            "17      25.029905           1.684182\n",
            "18      25.029905           1.684182\n",
            "19      25.029905           1.684182\n",
            "20      25.029905           1.684182\n",
            "21      25.029905           1.684182\n",
            "22      25.029905           1.684182\n",
            "23      25.029905           1.684182\n",
            "24      25.029905           1.684182\n",
            "25      25.029905           1.684182\n",
            "26      25.029905           1.684182\n",
            "27      25.029905           1.684182\n",
            "28      25.029905           1.684182\n",
            "29      25.029905           1.684182\n",
            "30      25.029905           1.684182\n",
            "31      25.029905           1.684182\n",
            "32      25.029905           1.684182\n",
            "33      25.029905           1.684182\n",
            "34      25.029905           1.684182\n",
            "35      25.029905           1.684182\n",
            "36      25.029905           1.684182\n",
            "37      25.029905           1.684182\n",
            "38      25.029905           1.684182\n",
            "39      25.029905           1.684182\n",
            "40      25.029905           1.684182\n",
            "41      25.029905           1.684182\n",
            "42      25.029905           1.684182\n",
            "43      25.029905           1.684182\n",
            "44      25.029905           1.684182\n",
            "45      25.029905           1.684182\n",
            "46      25.029905           1.684182\n",
            "47      25.029905           1.684182\n",
            "48      23.850878           6.289482\n",
            "49      23.850878           6.289482\n",
            "50      23.850878           6.289482\n",
            "51      23.850878           6.289482\n",
            "52      23.850878           6.289482\n",
            "53      23.850878           6.289482\n",
            "54      23.850878           6.289482\n",
            "55      23.850878           6.289482\n",
            "56      23.850878           6.289482\n",
            "57      23.850878           6.289482\n",
            "58      25.098158           1.759950\n",
            "59      25.098158           1.759950\n",
            "60      25.098160           1.759950\n",
            "61      25.098160           1.759950\n",
            "62      25.098160           1.759950\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2023-07-24 19:01:36.770474: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype double and shape [63,10]\n",
            "\t [[{{node Placeholder/_0}}]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2) Ungrouped, fixed"
      ],
      "metadata": {
        "id": "yIQGGzsIup_d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ungrouped_fixed = {\n",
        "    'TRAIN' : os.path.join(FP_ROOT, \"amazon_sample_data/uc_davis_2023_08_12_train_fixed_ungrouped.csv\"),\n",
        "    'TEST' : os.path.join(FP_ROOT, \"amazon_sample_data/uc_davis_2023_08_12_test_fixed_ungrouped.csv\"),\n",
        "    'VALIDATION' : os.path.join(FP_ROOT, \"amazon_sample_data/uc_davis_2023_08_12_validation_fixed_ungrouped.csv\"),\n",
        "}\n",
        "\n",
        "ungrouped_fixed_scaled = load_and_scale(ungrouped_fixed)\n",
        "train_and_evaluate(ungrouped_fixed_scaled, \"ungrouped_fixed\", training_batch_size=3)"
      ],
      "metadata": {
        "id": "-TkJGJ9Xux24",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e824514c-9614-48a8-aa24-443af6ff05ac"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================\n",
            "ungrouped_fixed\n",
            "Model: \"model_28\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_29 (InputLayer)          [(None, 10)]         0           []                               \n",
            "                                                                                                  \n",
            " dense_56 (Dense)               (None, 20)           220         ['input_29[0][0]']               \n",
            "                                                                                                  \n",
            " dense_57 (Dense)               (None, 20)           420         ['dense_56[0][0]']               \n",
            "                                                                                                  \n",
            " var_output (Dense)             (None, 1)            21          ['dense_57[0][0]']               \n",
            "                                                                                                  \n",
            " mean_output (Dense)            (None, 1)            21          ['dense_57[0][0]']               \n",
            "                                                                                                  \n",
            " tf.math.multiply_57 (TFOpLambd  (None, 1)           0           ['var_output[0][0]']             \n",
            " a)                                                                                               \n",
            "                                                                                                  \n",
            " tf.math.multiply_56 (TFOpLambd  (None, 1)           0           ['mean_output[0][0]']            \n",
            " a)                                                                                               \n",
            "                                                                                                  \n",
            " tf.__operators__.add_57 (TFOpL  (None, 1)           0           ['tf.math.multiply_57[0][0]']    \n",
            " ambda)                                                                                           \n",
            "                                                                                                  \n",
            " tf.__operators__.add_56 (TFOpL  (None, 1)           0           ['tf.math.multiply_56[0][0]']    \n",
            " ambda)                                                                                           \n",
            "                                                                                                  \n",
            " lambda_28 (Lambda)             (None, 1)            0           ['tf.__operators__.add_57[0][0]']\n",
            "                                                                                                  \n",
            " concatenate_28 (Concatenate)   (None, 2)            0           ['tf.__operators__.add_56[0][0]',\n",
            "                                                                  'lambda_28[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 682\n",
            "Trainable params: 682\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Restoring model weights from the end of the best epoch: 67.\n",
            "Epoch 1067: early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_2030896/902123805.py:9: UserWarning: Attempt to set non-positive ylim on a log-scaled axis will be ignored.\n",
            "  plt.ylim((0, 10))\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val loss: 0.504311740398407\n",
            "Train loss: 1.283324956893921\n",
            "Test loss: 0.9471877217292786\n",
            "dO18 RMSE: 1.5715835294817118\n",
            "EXPECTED:\n",
            "     d18O_cel_mean  d18O_cel_variance\n",
            "0        25.120750           0.844007\n",
            "1        25.120750           0.844007\n",
            "2        25.120750           0.844007\n",
            "3        25.120750           0.844007\n",
            "4        25.120750           0.844007\n",
            "5        25.120750           0.844007\n",
            "6        25.120750           0.844007\n",
            "7        25.120750           0.844007\n",
            "8        25.120750           0.844007\n",
            "9        25.120750           0.844007\n",
            "10       25.120750           0.844007\n",
            "11       25.120750           0.844007\n",
            "12       25.120750           0.844007\n",
            "13       25.120750           0.844007\n",
            "14       25.120750           0.844007\n",
            "15       25.120750           0.844007\n",
            "16       25.120750           0.844007\n",
            "17       25.120750           0.844007\n",
            "18       25.120750           0.844007\n",
            "19       25.120750           0.844007\n",
            "20       25.120750           0.844007\n",
            "21       25.120750           0.844007\n",
            "22       25.120750           0.844007\n",
            "23       25.120750           0.844007\n",
            "24       25.120750           0.844007\n",
            "25       25.120750           0.844007\n",
            "26       25.120750           0.844007\n",
            "27       25.120750           0.844007\n",
            "28       25.120750           0.844007\n",
            "29       25.120750           0.844007\n",
            "30       25.120750           0.844007\n",
            "31       25.120750           0.844007\n",
            "32       25.120750           0.844007\n",
            "33       25.120750           0.844007\n",
            "34       25.120750           0.844007\n",
            "35       25.120750           0.844007\n",
            "36       25.120750           0.844007\n",
            "37       25.120750           0.844007\n",
            "38       25.120750           0.844007\n",
            "39       25.120750           0.844007\n",
            "40       24.777670           0.736571\n",
            "41       24.777670           0.736571\n",
            "42       24.777670           0.736571\n",
            "43       24.777670           0.736571\n",
            "44       24.777670           0.736571\n",
            "45       25.551850           0.312355\n",
            "46       25.551850           0.312355\n",
            "47       25.551850           0.312355\n",
            "48       25.551850           0.312355\n",
            "49       25.551850           0.312355\n",
            "50       25.115885           0.033519\n",
            "51       25.115885           0.033519\n",
            "52       25.115885           0.033519\n",
            "53       25.115885           0.033519\n",
            "54       25.115885           0.033519\n",
            "55       25.987815           5.280825\n",
            "56       25.987815           5.280825\n",
            "57       25.987815           5.280825\n",
            "58       25.987815           5.280825\n",
            "59       25.987815           5.280825\n",
            "60       24.132031           0.389042\n",
            "61       24.132031           0.389042\n",
            "62       24.132031           0.389042\n",
            "63       24.132031           0.389042\n",
            "64       27.559140           0.780698\n",
            "65       27.559140           0.780698\n",
            "66       27.559140           0.780698\n",
            "67       27.559140           0.780698\n",
            "68       27.559140           0.780698\n",
            "69       27.559140           0.780698\n",
            "70       27.559140           0.780698\n",
            "71       27.559140           0.780698\n",
            "72       27.559140           0.780698\n",
            "73       27.559140           0.780698\n",
            "74       27.260748           0.830341\n",
            "75       27.260748           0.830341\n",
            "76       27.260748           0.830341\n",
            "77       27.260748           0.830341\n",
            "78       27.260748           0.830341\n",
            "79       27.260748           0.830341\n",
            "80       27.260748           0.830341\n",
            "81       27.260748           0.830341\n",
            "82       27.260748           0.830341\n",
            "83       27.260748           0.830341\n",
            "84       27.260748           0.830341\n",
            "85       27.260748           0.830341\n",
            "86       27.260748           0.830341\n",
            "87       27.260748           0.830341\n",
            "88       27.260748           0.830341\n",
            "89       27.260748           0.830341\n",
            "90       27.260748           0.830341\n",
            "91       27.260748           0.830341\n",
            "92       27.260748           0.830341\n",
            "93       27.260748           0.830341\n",
            "94       27.260748           0.830341\n",
            "95       27.260748           0.830341\n",
            "96       27.260748           0.830341\n",
            "97       27.260748           0.830341\n",
            "98       27.260748           0.830341\n",
            "99       27.260748           0.830341\n",
            "100      27.260748           0.830341\n",
            "101      27.260748           0.830341\n",
            "102      27.260748           0.830341\n",
            "103      27.260748           0.830341\n",
            "104      27.260748           0.830341\n",
            "105      27.260748           0.830341\n",
            "106      27.260748           0.830341\n",
            "107      27.260748           0.830341\n",
            "108      27.260748           0.830341\n",
            "\n",
            "PREDICTED:\n",
            "     d18O_cel_mean  d18O_cel_variance\n",
            "0        24.589785           3.246181\n",
            "1        24.589785           3.246181\n",
            "2        24.589785           3.246181\n",
            "3        24.589785           3.246181\n",
            "4        24.589785           3.246181\n",
            "5        24.589785           3.246181\n",
            "6        24.589785           3.246181\n",
            "7        24.589785           3.246181\n",
            "8        24.589785           3.246181\n",
            "9        24.589785           3.246181\n",
            "10       24.589785           3.246181\n",
            "11       24.589785           3.246181\n",
            "12       24.589785           3.246181\n",
            "13       24.589785           3.246181\n",
            "14       24.589785           3.246181\n",
            "15       24.589785           3.246181\n",
            "16       24.589785           3.246181\n",
            "17       24.589785           3.246181\n",
            "18       24.589785           3.246181\n",
            "19       24.589785           3.246181\n",
            "20       24.589785           3.246181\n",
            "21       24.589785           3.246181\n",
            "22       24.589785           3.246181\n",
            "23       24.589785           3.246181\n",
            "24       24.589785           3.246181\n",
            "25       24.589785           3.246181\n",
            "26       24.589785           3.246181\n",
            "27       24.589785           3.246181\n",
            "28       24.589785           3.246181\n",
            "29       24.589785           3.246181\n",
            "30       24.589785           3.246181\n",
            "31       24.589785           3.246181\n",
            "32       24.589785           3.246181\n",
            "33       24.589785           3.246181\n",
            "34       24.589785           3.246181\n",
            "35       24.589785           3.246181\n",
            "36       24.589785           3.246181\n",
            "37       24.589785           3.246181\n",
            "38       24.589785           3.246181\n",
            "39       24.589785           3.246181\n",
            "40       24.214325           4.211122\n",
            "41       24.214325           4.211122\n",
            "42       24.214325           4.211122\n",
            "43       24.214325           4.211122\n",
            "44       24.214325           4.211122\n",
            "45       23.808029           5.216791\n",
            "46       23.808029           5.216791\n",
            "47       23.808029           5.216791\n",
            "48       23.808029           5.216791\n",
            "49       23.808029           5.216791\n",
            "50       23.808031           5.216742\n",
            "51       23.808031           5.216742\n",
            "52       23.808031           5.216742\n",
            "53       23.808031           5.216742\n",
            "54       23.808031           5.216742\n",
            "55       23.808025           5.216877\n",
            "56       23.808025           5.216877\n",
            "57       23.808025           5.216877\n",
            "58       23.808025           5.216877\n",
            "59       23.808025           5.216877\n",
            "60       23.808027           5.216773\n",
            "61       23.808027           5.216773\n",
            "62       23.808027           5.216773\n",
            "63       23.808027           5.216773\n",
            "64       25.178406           1.770477\n",
            "65       25.178406           1.770477\n",
            "66       25.178406           1.770477\n",
            "67       25.178406           1.770477\n",
            "68       25.178406           1.770477\n",
            "69       25.178406           1.770477\n",
            "70       25.178406           1.770477\n",
            "71       25.178406           1.770477\n",
            "72       25.178406           1.770477\n",
            "73       25.178406           1.770477\n",
            "74       25.178583           1.770164\n",
            "75       25.178583           1.770164\n",
            "76       25.178583           1.770164\n",
            "77       25.178583           1.770164\n",
            "78       25.178583           1.770164\n",
            "79       25.178583           1.770164\n",
            "80       25.178583           1.770164\n",
            "81       25.178583           1.770164\n",
            "82       25.178583           1.770164\n",
            "83       25.178583           1.770164\n",
            "84       25.178583           1.770164\n",
            "85       25.178583           1.770164\n",
            "86       25.178583           1.770164\n",
            "87       25.178583           1.770164\n",
            "88       25.178583           1.770164\n",
            "89       25.178583           1.770164\n",
            "90       25.178583           1.770164\n",
            "91       25.178583           1.770164\n",
            "92       25.178583           1.770164\n",
            "93       25.178583           1.770164\n",
            "94       25.178583           1.770164\n",
            "95       25.178583           1.770164\n",
            "96       25.178583           1.770164\n",
            "97       25.178583           1.770164\n",
            "98       25.178583           1.770164\n",
            "99       25.178583           1.770164\n",
            "100      25.178583           1.770164\n",
            "101      25.178583           1.770164\n",
            "102      25.178583           1.770164\n",
            "103      25.178583           1.770164\n",
            "104      25.178583           1.770164\n",
            "105      25.178583           1.770164\n",
            "106      25.178583           1.770164\n",
            "107      25.178583           1.770164\n",
            "108      25.178583           1.770164\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2023-07-24 19:04:15.676865: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype double and shape [109,10]\n",
            "\t [[{{node Placeholder/_0}}]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3) Grouped, random"
      ],
      "metadata": {
        "id": "n8pNR1CrvF2a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "grouped_random = {\n",
        "    'TRAIN' : os.path.join(FP_ROOT, 'amazon_sample_data/uc_davis_2023_08_12_train_random_grouped.csv'),\n",
        "    'TEST' : os.path.join(FP_ROOT, 'amazon_sample_data/uc_davis_2023_08_12_test_random_grouped.csv'),\n",
        "    'VALIDATION' : os.path.join(FP_ROOT, 'amazon_sample_data/uc_davis_2023_08_12_validation_random_grouped.csv'),\n",
        "}\n",
        "\n",
        "grouped_random_scaled = load_and_scale(grouped_random)\n",
        "train_and_evaluate(grouped_random_scaled, \"grouped_random\", training_batch_size=3)"
      ],
      "metadata": {
        "id": "rPONfgkjvJWz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a2a8dc44-43d4-4754-aa96-ec6c62b44783"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9615 - val_loss: 1.0036\n",
            "Epoch 2502/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6450 - val_loss: 1.4829\n",
            "Epoch 2503/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0006 - val_loss: 1.4755\n",
            "Epoch 2504/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8627 - val_loss: 8.9585\n",
            "Epoch 2505/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9313 - val_loss: 1.6722\n",
            "Epoch 2506/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8761 - val_loss: 1.1751\n",
            "Epoch 2507/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7877 - val_loss: 0.9548\n",
            "Epoch 2508/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8122 - val_loss: 2.3682\n",
            "Epoch 2509/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.2317 - val_loss: 1.9313\n",
            "Epoch 2510/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.6257 - val_loss: 1.0498\n",
            "Epoch 2511/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7855 - val_loss: 1.2591\n",
            "Epoch 2512/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8369 - val_loss: 0.9785\n",
            "Epoch 2513/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.1647 - val_loss: 0.6858\n",
            "Epoch 2514/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0008 - val_loss: 1.3071\n",
            "Epoch 2515/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9517 - val_loss: 0.9793\n",
            "Epoch 2516/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8146 - val_loss: 0.8351\n",
            "Epoch 2517/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.1547 - val_loss: 1.4202\n",
            "Epoch 2518/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7197 - val_loss: 1.0658\n",
            "Epoch 2519/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7407 - val_loss: 1.1650\n",
            "Epoch 2520/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.8911 - val_loss: 1.8288\n",
            "Epoch 2521/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6342 - val_loss: 2.4414\n",
            "Epoch 2522/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8411 - val_loss: 1.1635\n",
            "Epoch 2523/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2.0460 - val_loss: 0.8042\n",
            "Epoch 2524/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0689 - val_loss: 1.2996\n",
            "Epoch 2525/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 3.3639 - val_loss: 1.1566\n",
            "Epoch 2526/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9175 - val_loss: 1.2902\n",
            "Epoch 2527/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9686 - val_loss: 1.1370\n",
            "Epoch 2528/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9571 - val_loss: 1.1899\n",
            "Epoch 2529/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.2202 - val_loss: 1.3376\n",
            "Epoch 2530/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9284 - val_loss: 1.3359\n",
            "Epoch 2531/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0923 - val_loss: 1.0992\n",
            "Epoch 2532/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.4379 - val_loss: 1.2326\n",
            "Epoch 2533/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7506 - val_loss: 2.8035\n",
            "Epoch 2534/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8887 - val_loss: 1.7046\n",
            "Epoch 2535/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7951 - val_loss: 1.3240\n",
            "Epoch 2536/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8940 - val_loss: 1.0889\n",
            "Epoch 2537/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9146 - val_loss: 1.2506\n",
            "Epoch 2538/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8222 - val_loss: 1.0737\n",
            "Epoch 2539/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8124 - val_loss: 0.8108\n",
            "Epoch 2540/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8294 - val_loss: 2.7225\n",
            "Epoch 2541/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7907 - val_loss: 1.1559\n",
            "Epoch 2542/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6794 - val_loss: 1.1572\n",
            "Epoch 2543/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.1581 - val_loss: 1.3332\n",
            "Epoch 2544/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8274 - val_loss: 2.6912\n",
            "Epoch 2545/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0756 - val_loss: 1.9454\n",
            "Epoch 2546/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7603 - val_loss: 1.6232\n",
            "Epoch 2547/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9421 - val_loss: 1.3940\n",
            "Epoch 2548/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9422 - val_loss: 0.7892\n",
            "Epoch 2549/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9463 - val_loss: 1.1140\n",
            "Epoch 2550/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8433 - val_loss: 0.9840\n",
            "Epoch 2551/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8778 - val_loss: 3.3501\n",
            "Epoch 2552/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8677 - val_loss: 1.4943\n",
            "Epoch 2553/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7143 - val_loss: 1.5000\n",
            "Epoch 2554/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8342 - val_loss: 1.2983\n",
            "Epoch 2555/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8534 - val_loss: 1.9877\n",
            "Epoch 2556/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7412 - val_loss: 4.3279\n",
            "Epoch 2557/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7664 - val_loss: 1.1006\n",
            "Epoch 2558/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8521 - val_loss: 0.9116\n",
            "Epoch 2559/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6562 - val_loss: 0.9340\n",
            "Epoch 2560/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2.0918 - val_loss: 1.4575\n",
            "Epoch 2561/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9857 - val_loss: 0.9774\n",
            "Epoch 2562/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.7518 - val_loss: 0.8198\n",
            "Epoch 2563/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9025 - val_loss: 1.5310\n",
            "Epoch 2564/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8829 - val_loss: 1.7195\n",
            "Epoch 2565/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8038 - val_loss: 1.3757\n",
            "Epoch 2566/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.1374 - val_loss: 0.8943\n",
            "Epoch 2567/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0986 - val_loss: 1.3663\n",
            "Epoch 2568/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8016 - val_loss: 1.9344\n",
            "Epoch 2569/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8705 - val_loss: 2.3237\n",
            "Epoch 2570/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8426 - val_loss: 1.9865\n",
            "Epoch 2571/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9234 - val_loss: 1.1109\n",
            "Epoch 2572/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8220 - val_loss: 2.2945\n",
            "Epoch 2573/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8707 - val_loss: 1.3176\n",
            "Epoch 2574/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9112 - val_loss: 0.9619\n",
            "Epoch 2575/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0683 - val_loss: 1.1504\n",
            "Epoch 2576/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7560 - val_loss: 1.3885\n",
            "Epoch 2577/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8819 - val_loss: 1.5308\n",
            "Epoch 2578/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0550 - val_loss: 0.9652\n",
            "Epoch 2579/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8523 - val_loss: 1.4155\n",
            "Epoch 2580/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.1375 - val_loss: 1.5031\n",
            "Epoch 2581/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7979 - val_loss: 1.2691\n",
            "Epoch 2582/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9114 - val_loss: 1.3404\n",
            "Epoch 2583/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7497 - val_loss: 1.4687\n",
            "Epoch 2584/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6974 - val_loss: 0.9400\n",
            "Epoch 2585/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6669 - val_loss: 2.5355\n",
            "Epoch 2586/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8173 - val_loss: 1.6736\n",
            "Epoch 2587/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7786 - val_loss: 1.0148\n",
            "Epoch 2588/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9123 - val_loss: 1.0148\n",
            "Epoch 2589/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7347 - val_loss: 1.1744\n",
            "Epoch 2590/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.1051 - val_loss: 2.0836\n",
            "Epoch 2591/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.2559 - val_loss: 1.9781\n",
            "Epoch 2592/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.4768 - val_loss: 2.0452\n",
            "Epoch 2593/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8399 - val_loss: 1.9440\n",
            "Epoch 2594/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6777 - val_loss: 0.9505\n",
            "Epoch 2595/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9408 - val_loss: 1.1997\n",
            "Epoch 2596/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2.2688 - val_loss: 1.0920\n",
            "Epoch 2597/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0680 - val_loss: 1.8545\n",
            "Epoch 2598/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7850 - val_loss: 0.8358\n",
            "Epoch 2599/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8649 - val_loss: 1.5140\n",
            "Epoch 2600/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0205 - val_loss: 1.5273\n",
            "Epoch 2601/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0354 - val_loss: 1.1105\n",
            "Epoch 2602/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7888 - val_loss: 0.9401\n",
            "Epoch 2603/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7169 - val_loss: 1.1476\n",
            "Epoch 2604/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7940 - val_loss: 1.0158\n",
            "Epoch 2605/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7226 - val_loss: 2.1518\n",
            "Epoch 2606/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0658 - val_loss: 1.1224\n",
            "Epoch 2607/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7026 - val_loss: 1.3195\n",
            "Epoch 2608/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0517 - val_loss: 1.1897\n",
            "Epoch 2609/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7449 - val_loss: 2.4660\n",
            "Epoch 2610/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8769 - val_loss: 1.5620\n",
            "Epoch 2611/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.3477 - val_loss: 1.2674\n",
            "Epoch 2612/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.1157 - val_loss: 1.4161\n",
            "Epoch 2613/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.2586 - val_loss: 1.2097\n",
            "Epoch 2614/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8955 - val_loss: 1.0202\n",
            "Epoch 2615/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.3565 - val_loss: 0.9538\n",
            "Epoch 2616/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7495 - val_loss: 1.7245\n",
            "Epoch 2617/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8330 - val_loss: 0.9697\n",
            "Epoch 2618/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.7196 - val_loss: 1.7862\n",
            "Epoch 2619/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8880 - val_loss: 1.5580\n",
            "Epoch 2620/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7275 - val_loss: 1.1901\n",
            "Epoch 2621/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9234 - val_loss: 0.9255\n",
            "Epoch 2622/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7981 - val_loss: 0.7655\n",
            "Epoch 2623/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7098 - val_loss: 1.3316\n",
            "Epoch 2624/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.1911 - val_loss: 2.6547\n",
            "Epoch 2625/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9100 - val_loss: 0.7927\n",
            "Epoch 2626/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6596 - val_loss: 1.4706\n",
            "Epoch 2627/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9363 - val_loss: 0.9257\n",
            "Epoch 2628/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9608 - val_loss: 1.5164\n",
            "Epoch 2629/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.2579 - val_loss: 1.1457\n",
            "Epoch 2630/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6969 - val_loss: 1.0309\n",
            "Epoch 2631/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2.0587 - val_loss: 1.1406\n",
            "Epoch 2632/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.2906 - val_loss: 1.3089\n",
            "Epoch 2633/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9619 - val_loss: 0.9050\n",
            "Epoch 2634/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9920 - val_loss: 1.1026\n",
            "Epoch 2635/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9933 - val_loss: 1.0934\n",
            "Epoch 2636/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8816 - val_loss: 1.4608\n",
            "Epoch 2637/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8998 - val_loss: 0.8886\n",
            "Epoch 2638/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8155 - val_loss: 0.8662\n",
            "Epoch 2639/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8439 - val_loss: 1.5405\n",
            "Epoch 2640/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9204 - val_loss: 1.7132\n",
            "Epoch 2641/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9048 - val_loss: 1.1957\n",
            "Epoch 2642/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0886 - val_loss: 1.0633\n",
            "Epoch 2643/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 9.4554 - val_loss: 1.3124\n",
            "Epoch 2644/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8462 - val_loss: 2.1875\n",
            "Epoch 2645/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8985 - val_loss: 1.0868\n",
            "Epoch 2646/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9069 - val_loss: 1.3949\n",
            "Epoch 2647/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9594 - val_loss: 1.2866\n",
            "Epoch 2648/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7746 - val_loss: 3.0686\n",
            "Epoch 2649/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8227 - val_loss: 1.2212\n",
            "Epoch 2650/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0427 - val_loss: 1.6404\n",
            "Epoch 2651/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8394 - val_loss: 1.2859\n",
            "Epoch 2652/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0305 - val_loss: 1.4462\n",
            "Epoch 2653/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8696 - val_loss: 1.2322\n",
            "Epoch 2654/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.1558 - val_loss: 1.4379\n",
            "Epoch 2655/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8049 - val_loss: 2.1164\n",
            "Epoch 2656/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7694 - val_loss: 1.1867\n",
            "Epoch 2657/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8333 - val_loss: 2.0704\n",
            "Epoch 2658/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9845 - val_loss: 1.3411\n",
            "Epoch 2659/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0419 - val_loss: 1.8201\n",
            "Epoch 2660/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7718 - val_loss: 0.9652\n",
            "Epoch 2661/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.9375 - val_loss: 1.1821\n",
            "Epoch 2662/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9079 - val_loss: 1.4938\n",
            "Epoch 2663/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9084 - val_loss: 1.5825\n",
            "Epoch 2664/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0087 - val_loss: 1.9054\n",
            "Epoch 2665/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9596 - val_loss: 1.5611\n",
            "Epoch 2666/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7749 - val_loss: 12.6885\n",
            "Epoch 2667/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8578 - val_loss: 1.1006\n",
            "Epoch 2668/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7377 - val_loss: 1.0037\n",
            "Epoch 2669/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6982 - val_loss: 1.3468\n",
            "Epoch 2670/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8401 - val_loss: 1.1272\n",
            "Epoch 2671/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7756 - val_loss: 1.8796\n",
            "Epoch 2672/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6625 - val_loss: 1.0684\n",
            "Epoch 2673/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.3678 - val_loss: 1.1305\n",
            "Epoch 2674/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8448 - val_loss: 1.4144\n",
            "Epoch 2675/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0300 - val_loss: 1.3578\n",
            "Epoch 2676/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8189 - val_loss: 1.2304\n",
            "Epoch 2677/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9756 - val_loss: 1.0151\n",
            "Epoch 2678/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0238 - val_loss: 1.0806\n",
            "Epoch 2679/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9408 - val_loss: 2.1391\n",
            "Epoch 2680/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.1082 - val_loss: 1.5427\n",
            "Epoch 2681/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.4166 - val_loss: 1.4549\n",
            "Epoch 2682/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9822 - val_loss: 1.8766\n",
            "Epoch 2683/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7892 - val_loss: 1.0300\n",
            "Epoch 2684/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.9756 - val_loss: 0.9025\n",
            "Epoch 2685/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7551 - val_loss: 3.6367\n",
            "Epoch 2686/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8772 - val_loss: 1.2212\n",
            "Epoch 2687/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0760 - val_loss: 2.2650\n",
            "Epoch 2688/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.2440 - val_loss: 0.9120\n",
            "Epoch 2689/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7708 - val_loss: 1.6241\n",
            "Epoch 2690/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.2009 - val_loss: 0.7113\n",
            "Epoch 2691/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6963 - val_loss: 1.1228\n",
            "Epoch 2692/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.1058 - val_loss: 1.2566\n",
            "Epoch 2693/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0127 - val_loss: 1.4315\n",
            "Epoch 2694/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9765 - val_loss: 1.2464\n",
            "Epoch 2695/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7662 - val_loss: 1.5977\n",
            "Epoch 2696/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8395 - val_loss: 1.0694\n",
            "Epoch 2697/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9662 - val_loss: 0.8770\n",
            "Epoch 2698/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.1929 - val_loss: 0.9737\n",
            "Epoch 2699/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9766 - val_loss: 0.9717\n",
            "Epoch 2700/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9465 - val_loss: 1.4682\n",
            "Epoch 2701/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7749 - val_loss: 0.7889\n",
            "Epoch 2702/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7542 - val_loss: 1.2900\n",
            "Epoch 2703/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9252 - val_loss: 1.6656\n",
            "Epoch 2704/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.3641 - val_loss: 1.0950\n",
            "Epoch 2705/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9198 - val_loss: 1.1197\n",
            "Epoch 2706/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0758 - val_loss: 1.1287\n",
            "Epoch 2707/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.3788 - val_loss: 1.0400\n",
            "Epoch 2708/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8044 - val_loss: 1.0929\n",
            "Epoch 2709/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8555 - val_loss: 1.2051\n",
            "Epoch 2710/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0070 - val_loss: 1.3602\n",
            "Epoch 2711/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0587 - val_loss: 0.9872\n",
            "Epoch 2712/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6829 - val_loss: 1.9139\n",
            "Epoch 2713/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9516 - val_loss: 1.4480\n",
            "Epoch 2714/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7007 - val_loss: 1.2637\n",
            "Epoch 2715/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8601 - val_loss: 1.3306\n",
            "Epoch 2716/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7694 - val_loss: 1.0316\n",
            "Epoch 2717/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9824 - val_loss: 0.9637\n",
            "Epoch 2718/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6663 - val_loss: 1.0229\n",
            "Epoch 2719/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8113 - val_loss: 1.0796\n",
            "Epoch 2720/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.1580 - val_loss: 2.7246\n",
            "Epoch 2721/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9431 - val_loss: 1.4730\n",
            "Epoch 2722/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2.1298 - val_loss: 2.4474\n",
            "Epoch 2723/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8704 - val_loss: 1.9175\n",
            "Epoch 2724/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0850 - val_loss: 1.0388\n",
            "Epoch 2725/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9196 - val_loss: 0.8850\n",
            "Epoch 2726/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.8125 - val_loss: 1.1226\n",
            "Epoch 2727/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8046 - val_loss: 1.9742\n",
            "Epoch 2728/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9856 - val_loss: 3.6205\n",
            "Epoch 2729/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.8643 - val_loss: 1.3441\n",
            "Epoch 2730/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9503 - val_loss: 2.0064\n",
            "Epoch 2731/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7187 - val_loss: 1.4835\n",
            "Epoch 2732/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0036 - val_loss: 1.4725\n",
            "Epoch 2733/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8508 - val_loss: 0.9812\n",
            "Epoch 2734/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0999 - val_loss: 1.0949\n",
            "Epoch 2735/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2.7234 - val_loss: 1.0859\n",
            "Epoch 2736/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9125 - val_loss: 1.4605\n",
            "Epoch 2737/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.8126 - val_loss: 1.0172\n",
            "Epoch 2738/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8718 - val_loss: 1.1762\n",
            "Epoch 2739/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8170 - val_loss: 3.2212\n",
            "Epoch 2740/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8812 - val_loss: 2.0235\n",
            "Epoch 2741/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9293 - val_loss: 0.9764\n",
            "Epoch 2742/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0952 - val_loss: 1.7595\n",
            "Epoch 2743/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.2504 - val_loss: 1.3752\n",
            "Epoch 2744/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0675 - val_loss: 1.2530\n",
            "Epoch 2745/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.2128 - val_loss: 1.0403\n",
            "Epoch 2746/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8641 - val_loss: 1.7451\n",
            "Epoch 2747/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7342 - val_loss: 0.9717\n",
            "Epoch 2748/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9577 - val_loss: 3.3187\n",
            "Epoch 2749/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9205 - val_loss: 1.0016\n",
            "Epoch 2750/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9712 - val_loss: 1.2123\n",
            "Epoch 2751/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6982 - val_loss: 1.4550\n",
            "Epoch 2752/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0679 - val_loss: 0.9957\n",
            "Epoch 2753/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8406 - val_loss: 1.2304\n",
            "Epoch 2754/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7482 - val_loss: 1.1794\n",
            "Epoch 2755/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.1696 - val_loss: 1.3794\n",
            "Epoch 2756/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9371 - val_loss: 0.9157\n",
            "Epoch 2757/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7494 - val_loss: 1.0473\n",
            "Epoch 2758/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.3369 - val_loss: 1.2124\n",
            "Epoch 2759/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0213 - val_loss: 1.0278\n",
            "Epoch 2760/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7755 - val_loss: 2.4455\n",
            "Epoch 2761/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7497 - val_loss: 1.0345\n",
            "Epoch 2762/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8256 - val_loss: 1.2093\n",
            "Epoch 2763/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8547 - val_loss: 2.1852\n",
            "Epoch 2764/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9455 - val_loss: 1.4928\n",
            "Epoch 2765/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9682 - val_loss: 2.6272\n",
            "Epoch 2766/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0603 - val_loss: 0.9175\n",
            "Epoch 2767/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7590 - val_loss: 1.7938\n",
            "Epoch 2768/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.2238 - val_loss: 1.4224\n",
            "Epoch 2769/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.2962 - val_loss: 2.3886\n",
            "Epoch 2770/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9620 - val_loss: 1.7162\n",
            "Epoch 2771/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7903 - val_loss: 1.1035\n",
            "Epoch 2772/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.3744 - val_loss: 1.1194\n",
            "Epoch 2773/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.8871 - val_loss: 0.8634\n",
            "Epoch 2774/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8471 - val_loss: 1.6626\n",
            "Epoch 2775/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9158 - val_loss: 1.1205\n",
            "Epoch 2776/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7155 - val_loss: 1.2311\n",
            "Epoch 2777/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.1861 - val_loss: 1.0073\n",
            "Epoch 2778/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8155 - val_loss: 1.0331\n",
            "Epoch 2779/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6947 - val_loss: 1.2592\n",
            "Epoch 2780/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0804 - val_loss: 1.4943\n",
            "Epoch 2781/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8324 - val_loss: 3.1246\n",
            "Epoch 2782/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7935 - val_loss: 1.3739\n",
            "Epoch 2783/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0993 - val_loss: 1.1519\n",
            "Epoch 2784/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8730 - val_loss: 1.3912\n",
            "Epoch 2785/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7571 - val_loss: 1.0688\n",
            "Epoch 2786/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7806 - val_loss: 2.0243\n",
            "Epoch 2787/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9834 - val_loss: 1.4320\n",
            "Epoch 2788/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7783 - val_loss: 2.1517\n",
            "Epoch 2789/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7016 - val_loss: 1.1900\n",
            "Epoch 2790/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8784 - val_loss: 1.2736\n",
            "Epoch 2791/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9430 - val_loss: 1.2175\n",
            "Epoch 2792/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9918 - val_loss: 1.2280\n",
            "Epoch 2793/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9886 - val_loss: 2.0222\n",
            "Epoch 2794/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9506 - val_loss: 1.3745\n",
            "Epoch 2795/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0642 - val_loss: 5.1299\n",
            "Epoch 2796/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0735 - val_loss: 1.0437\n",
            "Epoch 2797/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8310 - val_loss: 1.0135\n",
            "Epoch 2798/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8340 - val_loss: 3.5468\n",
            "Epoch 2799/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7195 - val_loss: 1.8230\n",
            "Epoch 2800/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0209 - val_loss: 1.3991\n",
            "Epoch 2801/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8527 - val_loss: 1.9781\n",
            "Epoch 2802/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8436 - val_loss: 1.1628\n",
            "Epoch 2803/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.1960 - val_loss: 2.0888\n",
            "Epoch 2804/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.1925 - val_loss: 1.4002\n",
            "Epoch 2805/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8320 - val_loss: 1.5192\n",
            "Epoch 2806/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9480 - val_loss: 1.4116\n",
            "Epoch 2807/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9725 - val_loss: 1.6688\n",
            "Epoch 2808/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9554 - val_loss: 1.0753\n",
            "Epoch 2809/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8521 - val_loss: 1.2474\n",
            "Epoch 2810/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9404 - val_loss: 5.1733\n",
            "Epoch 2811/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9886 - val_loss: 1.3830\n",
            "Epoch 2812/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.2445 - val_loss: 1.7829\n",
            "Epoch 2813/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.2793 - val_loss: 1.6993\n",
            "Epoch 2814/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7318 - val_loss: 0.7818\n",
            "Epoch 2815/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6703 - val_loss: 1.0562\n",
            "Epoch 2816/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9580 - val_loss: 1.0902\n",
            "Epoch 2817/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.1769 - val_loss: 2.1168\n",
            "Epoch 2818/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9339 - val_loss: 1.4048\n",
            "Epoch 2819/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.3028 - val_loss: 1.7322\n",
            "Epoch 2820/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9321 - val_loss: 1.4706\n",
            "Epoch 2821/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7620 - val_loss: 1.0699\n",
            "Epoch 2822/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8307 - val_loss: 2.0064\n",
            "Epoch 2823/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8801 - val_loss: 0.9235\n",
            "Epoch 2824/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6448 - val_loss: 1.0852\n",
            "Epoch 2825/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.3034 - val_loss: 0.9128\n",
            "Epoch 2826/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7600 - val_loss: 1.0301\n",
            "Epoch 2827/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8884 - val_loss: 1.2515\n",
            "Epoch 2828/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7215 - val_loss: 0.8711\n",
            "Epoch 2829/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8402 - val_loss: 1.1192\n",
            "Epoch 2830/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9918 - val_loss: 0.9714\n",
            "Epoch 2831/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8581 - val_loss: 0.9708\n",
            "Epoch 2832/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0588 - val_loss: 5.3455\n",
            "Epoch 2833/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0255 - val_loss: 1.4837\n",
            "Epoch 2834/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8105 - val_loss: 0.9813\n",
            "Epoch 2835/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7369 - val_loss: 0.8567\n",
            "Epoch 2836/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8406 - val_loss: 0.9499\n",
            "Epoch 2837/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9310 - val_loss: 1.0844\n",
            "Epoch 2838/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7292 - val_loss: 1.4630\n",
            "Epoch 2839/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7015 - val_loss: 1.3714\n",
            "Epoch 2840/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0915 - val_loss: 2.2929\n",
            "Epoch 2841/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0107 - val_loss: 1.3129\n",
            "Epoch 2842/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7625 - val_loss: 1.4124\n",
            "Epoch 2843/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9903 - val_loss: 1.5330\n",
            "Epoch 2844/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.3939 - val_loss: 1.3216\n",
            "Epoch 2845/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.5296 - val_loss: 1.2975\n",
            "Epoch 2846/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9314 - val_loss: 3.6694\n",
            "Epoch 2847/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0486 - val_loss: 1.2023\n",
            "Epoch 2848/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8511 - val_loss: 3.9650\n",
            "Epoch 2849/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9060 - val_loss: 1.3386\n",
            "Epoch 2850/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0876 - val_loss: 1.4587\n",
            "Epoch 2851/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8079 - val_loss: 2.3100\n",
            "Epoch 2852/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9578 - val_loss: 5.5324\n",
            "Epoch 2853/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0519 - val_loss: 1.1913\n",
            "Epoch 2854/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7212 - val_loss: 0.9505\n",
            "Epoch 2855/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9954 - val_loss: 1.2758\n",
            "Epoch 2856/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9672 - val_loss: 2.2046\n",
            "Epoch 2857/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9920 - val_loss: 1.3597\n",
            "Epoch 2858/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8657 - val_loss: 1.3821\n",
            "Epoch 2859/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7836 - val_loss: 1.0359\n",
            "Epoch 2860/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 3.1197 - val_loss: 1.4518\n",
            "Epoch 2861/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9387 - val_loss: 1.1350\n",
            "Epoch 2862/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9197 - val_loss: 0.5370\n",
            "Epoch 2863/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8061 - val_loss: 2.2560\n",
            "Epoch 2864/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2.0255 - val_loss: 1.0268\n",
            "Epoch 2865/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.7960 - val_loss: 0.9650\n",
            "Epoch 2866/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6967 - val_loss: 1.0395\n",
            "Epoch 2867/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9698 - val_loss: 1.6315\n",
            "Epoch 2868/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.1070 - val_loss: 1.2041\n",
            "Epoch 2869/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9680 - val_loss: 1.2033\n",
            "Epoch 2870/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0151 - val_loss: 1.3065\n",
            "Epoch 2871/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8212 - val_loss: 1.3346\n",
            "Epoch 2872/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0282 - val_loss: 1.8209\n",
            "Epoch 2873/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9158 - val_loss: 1.5128\n",
            "Epoch 2874/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.2031 - val_loss: 1.8115\n",
            "Epoch 2875/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8254 - val_loss: 1.9371\n",
            "Epoch 2876/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9148 - val_loss: 2.5478\n",
            "Epoch 2877/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7776 - val_loss: 4.5822\n",
            "Epoch 2878/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9993 - val_loss: 0.7323\n",
            "Epoch 2879/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8213 - val_loss: 2.1379\n",
            "Epoch 2880/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9367 - val_loss: 1.5106\n",
            "Epoch 2881/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0430 - val_loss: 1.0019\n",
            "Epoch 2882/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9637 - val_loss: 2.1189\n",
            "Epoch 2883/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9205 - val_loss: 0.9744\n",
            "Epoch 2884/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7576 - val_loss: 2.5873\n",
            "Epoch 2885/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9016 - val_loss: 1.0052\n",
            "Epoch 2886/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8249 - val_loss: 1.3491\n",
            "Epoch 2887/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0147 - val_loss: 1.7678\n",
            "Epoch 2888/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8884 - val_loss: 1.2514\n",
            "Epoch 2889/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9674 - val_loss: 0.8272\n",
            "Epoch 2890/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9736 - val_loss: 4.2745\n",
            "Epoch 2891/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8010 - val_loss: 1.2864\n",
            "Epoch 2892/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8954 - val_loss: 1.0693\n",
            "Epoch 2893/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0905 - val_loss: 0.9097\n",
            "Epoch 2894/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7316 - val_loss: 1.0246\n",
            "Epoch 2895/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2.1871 - val_loss: 1.4605\n",
            "Epoch 2896/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9647 - val_loss: 0.7995\n",
            "Epoch 2897/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.2354 - val_loss: 1.2491\n",
            "Epoch 2898/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7280 - val_loss: 1.7191\n",
            "Epoch 2899/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8707 - val_loss: 1.4438\n",
            "Epoch 2900/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8477 - val_loss: 1.6948\n",
            "Epoch 2901/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6949 - val_loss: 1.7383\n",
            "Epoch 2902/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7468 - val_loss: 2.6300\n",
            "Epoch 2903/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9472 - val_loss: 2.0488\n",
            "Epoch 2904/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6804 - val_loss: 1.2212\n",
            "Epoch 2905/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9933 - val_loss: 1.0336\n",
            "Epoch 2906/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6652 - val_loss: 1.2150\n",
            "Epoch 2907/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8876 - val_loss: 1.1482\n",
            "Epoch 2908/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.3933 - val_loss: 1.0021\n",
            "Epoch 2909/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0612 - val_loss: 1.6815\n",
            "Epoch 2910/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8740 - val_loss: 1.1151\n",
            "Epoch 2911/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8796 - val_loss: 1.1610\n",
            "Epoch 2912/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.1210 - val_loss: 1.7749\n",
            "Epoch 2913/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8613 - val_loss: 1.3394\n",
            "Epoch 2914/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9611 - val_loss: 1.1224\n",
            "Epoch 2915/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9438 - val_loss: 1.5434\n",
            "Epoch 2916/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9688 - val_loss: 1.2517\n",
            "Epoch 2917/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7935 - val_loss: 1.0374\n",
            "Epoch 2918/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8097 - val_loss: 1.0188\n",
            "Epoch 2919/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.2671 - val_loss: 1.6048\n",
            "Epoch 2920/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0663 - val_loss: 1.2849\n",
            "Epoch 2921/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.8375 - val_loss: 4.5479\n",
            "Epoch 2922/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.2991 - val_loss: 1.1529\n",
            "Epoch 2923/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9050 - val_loss: 4.3958\n",
            "Epoch 2924/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8149 - val_loss: 1.0320\n",
            "Epoch 2925/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.1066 - val_loss: 0.7126\n",
            "Epoch 2926/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0774 - val_loss: 1.6268\n",
            "Epoch 2927/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7561 - val_loss: 1.1321\n",
            "Epoch 2928/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9089 - val_loss: 1.4767\n",
            "Epoch 2929/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8367 - val_loss: 1.5128\n",
            "Epoch 2930/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8128 - val_loss: 1.6350\n",
            "Epoch 2931/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7093 - val_loss: 1.0852\n",
            "Epoch 2932/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.4014 - val_loss: 1.1601\n",
            "Epoch 2933/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9552 - val_loss: 1.1511\n",
            "Epoch 2934/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7361 - val_loss: 1.3716\n",
            "Epoch 2935/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9354 - val_loss: 1.1549\n",
            "Epoch 2936/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8639 - val_loss: 1.0515\n",
            "Epoch 2937/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.7644 - val_loss: 1.0043\n",
            "Epoch 2938/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8397 - val_loss: 1.4102\n",
            "Epoch 2939/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8810 - val_loss: 0.9366\n",
            "Epoch 2940/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9728 - val_loss: 1.1735\n",
            "Epoch 2941/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7455 - val_loss: 1.5197\n",
            "Epoch 2942/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7399 - val_loss: 1.0348\n",
            "Epoch 2943/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.4570 - val_loss: 1.1443\n",
            "Epoch 2944/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8940 - val_loss: 1.0763\n",
            "Epoch 2945/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8167 - val_loss: 0.8862\n",
            "Epoch 2946/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.1934 - val_loss: 2.1978\n",
            "Epoch 2947/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8792 - val_loss: 1.4403\n",
            "Epoch 2948/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0629 - val_loss: 0.9652\n",
            "Epoch 2949/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7902 - val_loss: 1.3482\n",
            "Epoch 2950/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6900 - val_loss: 0.9430\n",
            "Epoch 2951/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7543 - val_loss: 0.8493\n",
            "Epoch 2952/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8080 - val_loss: 1.4645\n",
            "Epoch 2953/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9006 - val_loss: 1.4590\n",
            "Epoch 2954/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0219 - val_loss: 0.8689\n",
            "Epoch 2955/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6924 - val_loss: 1.1940\n",
            "Epoch 2956/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7141 - val_loss: 1.1309\n",
            "Epoch 2957/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6021 - val_loss: 1.4324\n",
            "Epoch 2958/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.2053 - val_loss: 1.2881\n",
            "Epoch 2959/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9382 - val_loss: 1.3377\n",
            "Epoch 2960/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8626 - val_loss: 1.0883\n",
            "Epoch 2961/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.3531 - val_loss: 1.0797\n",
            "Epoch 2962/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8329 - val_loss: 1.2228\n",
            "Epoch 2963/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8471 - val_loss: 0.8756\n",
            "Epoch 2964/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9714 - val_loss: 1.3604\n",
            "Epoch 2965/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9465 - val_loss: 1.2168\n",
            "Epoch 2966/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9870 - val_loss: 0.8898\n",
            "Epoch 2967/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7260 - val_loss: 1.2915\n",
            "Epoch 2968/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7415 - val_loss: 0.9784\n",
            "Epoch 2969/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7694 - val_loss: 1.1821\n",
            "Epoch 2970/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.1434 - val_loss: 2.3812\n",
            "Epoch 2971/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8255 - val_loss: 1.9659\n",
            "Epoch 2972/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8376 - val_loss: 1.0519\n",
            "Epoch 2973/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7433 - val_loss: 2.4878\n",
            "Epoch 2974/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7515 - val_loss: 1.6054\n",
            "Epoch 2975/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9927 - val_loss: 1.2087\n",
            "Epoch 2976/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8302 - val_loss: 1.0027\n",
            "Epoch 2977/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7450 - val_loss: 1.1895\n",
            "Epoch 2978/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0112 - val_loss: 1.1237\n",
            "Epoch 2979/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.5445 - val_loss: 1.1229\n",
            "Epoch 2980/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9876 - val_loss: 6.2029\n",
            "Epoch 2981/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7617 - val_loss: 1.3109\n",
            "Epoch 2982/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8193 - val_loss: 0.9866\n",
            "Epoch 2983/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7247 - val_loss: 1.2399\n",
            "Epoch 2984/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8515 - val_loss: 1.0748\n",
            "Epoch 2985/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8077 - val_loss: 1.1706\n",
            "Epoch 2986/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9922 - val_loss: 1.2134\n",
            "Epoch 2987/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.3490 - val_loss: 1.3370\n",
            "Epoch 2988/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0019 - val_loss: 3.8702\n",
            "Epoch 2989/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8313 - val_loss: 1.5613\n",
            "Epoch 2990/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8791 - val_loss: 1.0010\n",
            "Epoch 2991/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.2012 - val_loss: 1.3367\n",
            "Epoch 2992/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9585 - val_loss: 1.6148\n",
            "Epoch 2993/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8086 - val_loss: 1.9423\n",
            "Epoch 2994/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.3071 - val_loss: 0.9742\n",
            "Epoch 2995/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.1267 - val_loss: 0.8540\n",
            "Epoch 2996/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8226 - val_loss: 1.2243\n",
            "Epoch 2997/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.1887 - val_loss: 2.3329\n",
            "Epoch 2998/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7773 - val_loss: 1.1868\n",
            "Epoch 2999/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.2614 - val_loss: 1.1303\n",
            "Epoch 3000/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.5267 - val_loss: 1.1188\n",
            "Epoch 3001/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0182 - val_loss: 1.0223\n",
            "Epoch 3002/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0256 - val_loss: 1.2091\n",
            "Epoch 3003/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6869 - val_loss: 2.7277\n",
            "Epoch 3004/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8688 - val_loss: 1.0023\n",
            "Epoch 3005/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8125 - val_loss: 1.0577\n",
            "Epoch 3006/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7219 - val_loss: 2.6232\n",
            "Epoch 3007/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7547 - val_loss: 2.4688\n",
            "Epoch 3008/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7161 - val_loss: 0.9329\n",
            "Epoch 3009/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8933 - val_loss: 1.0101\n",
            "Epoch 3010/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9689 - val_loss: 1.0072\n",
            "Epoch 3011/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6987 - val_loss: 1.4773\n",
            "Epoch 3012/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0131 - val_loss: 1.2049\n",
            "Epoch 3013/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9072 - val_loss: 1.1194\n",
            "Epoch 3014/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8182 - val_loss: 1.2420\n",
            "Epoch 3015/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8876 - val_loss: 1.5006\n",
            "Epoch 3016/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8679 - val_loss: 3.1388\n",
            "Epoch 3017/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7607 - val_loss: 1.9999\n",
            "Epoch 3018/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8391 - val_loss: 1.2612\n",
            "Epoch 3019/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9602 - val_loss: 3.3875\n",
            "Epoch 3020/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.3639 - val_loss: 1.8353\n",
            "Epoch 3021/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0613 - val_loss: 1.1055\n",
            "Epoch 3022/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9206 - val_loss: 1.5119\n",
            "Epoch 3023/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6255 - val_loss: 2.5022\n",
            "Epoch 3024/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6978 - val_loss: 0.7328\n",
            "Epoch 3025/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8228 - val_loss: 1.4408\n",
            "Epoch 3026/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8429 - val_loss: 2.0084\n",
            "Epoch 3027/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0153 - val_loss: 1.2690\n",
            "Epoch 3028/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2.1879 - val_loss: 1.1476\n",
            "Epoch 3029/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6984 - val_loss: 0.9228\n",
            "Epoch 3030/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0582 - val_loss: 1.1585\n",
            "Epoch 3031/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7569 - val_loss: 0.9081\n",
            "Epoch 3032/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7569 - val_loss: 0.8980\n",
            "Epoch 3033/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.7304 - val_loss: 1.5017\n",
            "Epoch 3034/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8283 - val_loss: 1.1073\n",
            "Epoch 3035/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0041 - val_loss: 1.0501\n",
            "Epoch 3036/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9908 - val_loss: 1.0660\n",
            "Epoch 3037/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.1704 - val_loss: 2.9622\n",
            "Epoch 3038/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8417 - val_loss: 0.9416\n",
            "Epoch 3039/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8097 - val_loss: 1.0504\n",
            "Epoch 3040/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8751 - val_loss: 2.4260\n",
            "Epoch 3041/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8910 - val_loss: 1.5730\n",
            "Epoch 3042/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0073 - val_loss: 2.0821\n",
            "Epoch 3043/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9179 - val_loss: 0.8934\n",
            "Epoch 3044/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7673 - val_loss: 1.1394\n",
            "Epoch 3045/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7874 - val_loss: 1.2294\n",
            "Epoch 3046/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.1689 - val_loss: 1.3081\n",
            "Epoch 3047/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7794 - val_loss: 1.4074\n",
            "Epoch 3048/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6889 - val_loss: 1.4572\n",
            "Epoch 3049/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9577 - val_loss: 1.5973\n",
            "Epoch 3050/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9863 - val_loss: 1.4343\n",
            "Epoch 3051/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6231 - val_loss: 1.3350\n",
            "Epoch 3052/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0110 - val_loss: 0.8871\n",
            "Epoch 3053/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8300 - val_loss: 1.1374\n",
            "Epoch 3054/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8733 - val_loss: 1.4590\n",
            "Epoch 3055/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9473 - val_loss: 2.3923\n",
            "Epoch 3056/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.4214 - val_loss: 1.2801\n",
            "Epoch 3057/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8662 - val_loss: 3.3943\n",
            "Epoch 3058/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.3927 - val_loss: 0.9312\n",
            "Epoch 3059/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7444 - val_loss: 1.5266\n",
            "Epoch 3060/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9570 - val_loss: 1.3796\n",
            "Epoch 3061/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8878 - val_loss: 1.1341\n",
            "Epoch 3062/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7460 - val_loss: 1.4433\n",
            "Epoch 3063/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.3485 - val_loss: 0.8506\n",
            "Epoch 3064/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.6345 - val_loss: 1.4391\n",
            "Epoch 3065/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8750 - val_loss: 4.1503\n",
            "Epoch 3066/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0164 - val_loss: 2.0075\n",
            "Epoch 3067/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7353 - val_loss: 1.5479\n",
            "Epoch 3068/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.2225 - val_loss: 1.0968\n",
            "Epoch 3069/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8780 - val_loss: 4.9188\n",
            "Epoch 3070/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8746 - val_loss: 1.8931\n",
            "Epoch 3071/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9122 - val_loss: 1.1733\n",
            "Epoch 3072/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9173 - val_loss: 0.9559\n",
            "Epoch 3073/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8569 - val_loss: 0.8938\n",
            "Epoch 3074/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9127 - val_loss: 1.1797\n",
            "Epoch 3075/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9545 - val_loss: 1.3067\n",
            "Epoch 3076/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0503 - val_loss: 1.3034\n",
            "Epoch 3077/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.1108 - val_loss: 1.4513\n",
            "Epoch 3078/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8265 - val_loss: 1.3339\n",
            "Epoch 3079/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9318 - val_loss: 1.4385\n",
            "Epoch 3080/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 1.4803\n",
            "Epoch 3081/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9080 - val_loss: 4.4415\n",
            "Epoch 3082/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9182 - val_loss: 1.0330\n",
            "Epoch 3083/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.2797 - val_loss: 1.0258\n",
            "Epoch 3084/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8517 - val_loss: 1.1162\n",
            "Epoch 3085/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7303 - val_loss: 2.2147\n",
            "Epoch 3086/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8217 - val_loss: 0.9822\n",
            "Epoch 3087/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8244 - val_loss: 1.0572\n",
            "Epoch 3088/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7936 - val_loss: 1.2539\n",
            "Epoch 3089/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9901 - val_loss: 1.6151\n",
            "Epoch 3090/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0175 - val_loss: 1.3495\n",
            "Epoch 3091/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8595 - val_loss: 0.9676\n",
            "Epoch 3092/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9641 - val_loss: 1.0072\n",
            "Epoch 3093/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7310 - val_loss: 5.5993\n",
            "Epoch 3094/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7707 - val_loss: 0.9874\n",
            "Epoch 3095/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7820 - val_loss: 1.1451\n",
            "Epoch 3096/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9176 - val_loss: 1.3850\n",
            "Epoch 3097/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7445 - val_loss: 1.6550\n",
            "Epoch 3098/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.2388 - val_loss: 1.0608\n",
            "Epoch 3099/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0964 - val_loss: 1.2984\n",
            "Epoch 3100/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9386 - val_loss: 1.9008\n",
            "Epoch 3101/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8263 - val_loss: 1.0659\n",
            "Epoch 3102/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8752 - val_loss: 1.2266\n",
            "Epoch 3103/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9515 - val_loss: 2.0036\n",
            "Epoch 3104/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8050 - val_loss: 1.1412\n",
            "Epoch 3105/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9161 - val_loss: 1.5006\n",
            "Epoch 3106/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7590 - val_loss: 0.9083\n",
            "Epoch 3107/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8351 - val_loss: 1.3097\n",
            "Epoch 3108/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7795 - val_loss: 1.4793\n",
            "Epoch 3109/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6294 - val_loss: 1.2382\n",
            "Epoch 3110/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7681 - val_loss: 2.5125\n",
            "Epoch 3111/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0178 - val_loss: 1.3565\n",
            "Epoch 3112/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.7210 - val_loss: 1.3156\n",
            "Epoch 3113/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8257 - val_loss: 1.3492\n",
            "Epoch 3114/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0338 - val_loss: 1.2852\n",
            "Epoch 3115/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8214 - val_loss: 1.4055\n",
            "Epoch 3116/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0137 - val_loss: 1.2214\n",
            "Epoch 3117/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8844 - val_loss: 1.2341\n",
            "Epoch 3118/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9760 - val_loss: 1.6163\n",
            "Epoch 3119/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.1119 - val_loss: 1.2646\n",
            "Epoch 3120/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0006 - val_loss: 1.1137\n",
            "Epoch 3121/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.8510 - val_loss: 1.8917\n",
            "Epoch 3122/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.1417 - val_loss: 1.7481\n",
            "Epoch 3123/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8289 - val_loss: 0.9703\n",
            "Epoch 3124/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8739 - val_loss: 2.1128\n",
            "Epoch 3125/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9120 - val_loss: 1.1515\n",
            "Epoch 3126/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0775 - val_loss: 1.2897\n",
            "Epoch 3127/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9831 - val_loss: 1.3513\n",
            "Epoch 3128/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8447 - val_loss: 1.1347\n",
            "Epoch 3129/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7795 - val_loss: 1.6877\n",
            "Epoch 3130/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7570 - val_loss: 1.3058\n",
            "Epoch 3131/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0921 - val_loss: 1.1917\n",
            "Epoch 3132/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8641 - val_loss: 2.2143\n",
            "Epoch 3133/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6714 - val_loss: 1.0580\n",
            "Epoch 3134/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8118 - val_loss: 2.9187\n",
            "Epoch 3135/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8030 - val_loss: 1.1443\n",
            "Epoch 3136/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8430 - val_loss: 1.7761\n",
            "Epoch 3137/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8648 - val_loss: 1.3744\n",
            "Epoch 3138/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7920 - val_loss: 1.8822\n",
            "Epoch 3139/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.1674 - val_loss: 0.9816\n",
            "Epoch 3140/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7668 - val_loss: 1.2026\n",
            "Epoch 3141/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8706 - val_loss: 1.1958\n",
            "Epoch 3142/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0145 - val_loss: 1.6196\n",
            "Epoch 3143/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9132 - val_loss: 3.0103\n",
            "Epoch 3144/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7068 - val_loss: 1.8793\n",
            "Epoch 3145/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9919 - val_loss: 0.9843\n",
            "Epoch 3146/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9662 - val_loss: 1.4108\n",
            "Epoch 3147/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9498 - val_loss: 0.9959\n",
            "Epoch 3148/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8600 - val_loss: 1.1668\n",
            "Epoch 3149/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8251 - val_loss: 3.9247\n",
            "Epoch 3150/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6890 - val_loss: 1.5312\n",
            "Epoch 3151/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.2870 - val_loss: 1.0688\n",
            "Epoch 3152/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8833 - val_loss: 1.0492\n",
            "Epoch 3153/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7792 - val_loss: 0.8631\n",
            "Epoch 3154/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7699 - val_loss: 2.1500\n",
            "Epoch 3155/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8582 - val_loss: 0.8865\n",
            "Epoch 3156/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8903 - val_loss: 0.6197\n",
            "Epoch 3157/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6531 - val_loss: 2.4416\n",
            "Epoch 3158/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8372 - val_loss: 1.3749\n",
            "Epoch 3159/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7458 - val_loss: 0.9846\n",
            "Epoch 3160/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.8894 - val_loss: 1.0201\n",
            "Epoch 3161/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7430 - val_loss: 0.9936\n",
            "Epoch 3162/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8175 - val_loss: 1.3169\n",
            "Epoch 3163/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9927 - val_loss: 1.3320\n",
            "Epoch 3164/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9465 - val_loss: 1.8085\n",
            "Epoch 3165/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7029 - val_loss: 1.2537\n",
            "Epoch 3166/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8986 - val_loss: 1.1678\n",
            "Epoch 3167/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8510 - val_loss: 0.9400\n",
            "Epoch 3168/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8332 - val_loss: 0.9563\n",
            "Epoch 3169/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8580 - val_loss: 1.2878\n",
            "Epoch 3170/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8886 - val_loss: 1.3767\n",
            "Epoch 3171/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9105 - val_loss: 1.3121\n",
            "Epoch 3172/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0477 - val_loss: 1.5094\n",
            "Epoch 3173/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7628 - val_loss: 1.1597\n",
            "Epoch 3174/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8551 - val_loss: 5.7217\n",
            "Epoch 3175/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9984 - val_loss: 1.6567\n",
            "Epoch 3176/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7609 - val_loss: 0.8869\n",
            "Epoch 3177/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.1714 - val_loss: 1.2676\n",
            "Epoch 3178/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0612 - val_loss: 1.4499\n",
            "Epoch 3179/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.1322 - val_loss: 1.2678\n",
            "Epoch 3180/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8031 - val_loss: 1.4514\n",
            "Epoch 3181/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.3372 - val_loss: 1.9588\n",
            "Epoch 3182/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9026 - val_loss: 1.0718\n",
            "Epoch 3183/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9296 - val_loss: 1.3162\n",
            "Epoch 3184/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7608 - val_loss: 0.8426\n",
            "Epoch 3185/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8260 - val_loss: 1.7927\n",
            "Epoch 3186/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7704 - val_loss: 1.1787\n",
            "Epoch 3187/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9360 - val_loss: 1.4048\n",
            "Epoch 3188/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.2831 - val_loss: 1.1689\n",
            "Epoch 3189/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8772 - val_loss: 0.9120\n",
            "Epoch 3190/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8552 - val_loss: 2.9624\n",
            "Epoch 3191/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9562 - val_loss: 1.1939\n",
            "Epoch 3192/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8280 - val_loss: 0.9070\n",
            "Epoch 3193/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9186 - val_loss: 1.7048\n",
            "Epoch 3194/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9329 - val_loss: 0.9307\n",
            "Epoch 3195/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7598 - val_loss: 1.6405\n",
            "Epoch 3196/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0587 - val_loss: 1.5909\n",
            "Epoch 3197/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9266 - val_loss: 0.8692\n",
            "Epoch 3198/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9449 - val_loss: 1.4174\n",
            "Epoch 3199/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.9715 - val_loss: 0.9980\n",
            "Epoch 3200/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7400 - val_loss: 1.5309\n",
            "Epoch 3201/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7144 - val_loss: 2.7239\n",
            "Epoch 3202/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7435 - val_loss: 1.3444\n",
            "Epoch 3203/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9183 - val_loss: 1.7747\n",
            "Epoch 3204/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2.2865 - val_loss: 9.2907\n",
            "Epoch 3205/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8317 - val_loss: 0.8236\n",
            "Epoch 3206/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7042 - val_loss: 0.7656\n",
            "Epoch 3207/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9788 - val_loss: 1.6766\n",
            "Epoch 3208/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.3981 - val_loss: 1.4454\n",
            "Epoch 3209/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8029 - val_loss: 0.9289\n",
            "Epoch 3210/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8265 - val_loss: 1.3434\n",
            "Epoch 3211/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7125 - val_loss: 1.8125\n",
            "Epoch 3212/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9164 - val_loss: 1.8386\n",
            "Epoch 3213/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0274 - val_loss: 1.1875\n",
            "Epoch 3214/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.1299 - val_loss: 1.6213\n",
            "Epoch 3215/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.9075 - val_loss: 0.9238\n",
            "Epoch 3216/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9441 - val_loss: 1.1848\n",
            "Epoch 3217/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9910 - val_loss: 2.3702\n",
            "Epoch 3218/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.1128 - val_loss: 1.4932\n",
            "Epoch 3219/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0242 - val_loss: 0.9853\n",
            "Epoch 3220/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8350 - val_loss: 1.0869\n",
            "Epoch 3221/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7374 - val_loss: 1.1091\n",
            "Epoch 3222/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7581 - val_loss: 1.3295\n",
            "Epoch 3223/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9282 - val_loss: 1.5595\n",
            "Epoch 3224/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.1923 - val_loss: 1.6894\n",
            "Epoch 3225/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8557 - val_loss: 1.7593\n",
            "Epoch 3226/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9848 - val_loss: 0.8227\n",
            "Epoch 3227/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8359 - val_loss: 1.1760\n",
            "Epoch 3228/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6757 - val_loss: 0.9929\n",
            "Epoch 3229/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0492 - val_loss: 0.7794\n",
            "Epoch 3230/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 6.4572 - val_loss: 1.4888\n",
            "Epoch 3231/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8446 - val_loss: 1.3555\n",
            "Epoch 3232/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8577 - val_loss: 1.3242\n",
            "Epoch 3233/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.4608 - val_loss: 3.8033\n",
            "Epoch 3234/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8730 - val_loss: 2.7036\n",
            "Epoch 3235/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8296 - val_loss: 1.1493\n",
            "Epoch 3236/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8146 - val_loss: 1.1303\n",
            "Epoch 3237/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.9113 - val_loss: 1.2205\n",
            "Epoch 3238/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8810 - val_loss: 0.9554\n",
            "Epoch 3239/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7520 - val_loss: 2.6465\n",
            "Epoch 3240/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7887 - val_loss: 1.2066\n",
            "Epoch 3241/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.2741 - val_loss: 1.9978\n",
            "Epoch 3242/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8520 - val_loss: 0.9101\n",
            "Epoch 3243/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.9430 - val_loss: 1.1790\n",
            "Epoch 3244/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8799 - val_loss: 2.4699\n",
            "Epoch 3245/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9873 - val_loss: 1.4925\n",
            "Epoch 3246/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0843 - val_loss: 1.2354\n",
            "Epoch 3247/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7717 - val_loss: 0.8963\n",
            "Epoch 3248/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7223 - val_loss: 0.8540\n",
            "Epoch 3249/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7947 - val_loss: 1.4542\n",
            "Epoch 3250/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8339 - val_loss: 2.7740\n",
            "Epoch 3251/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8057 - val_loss: 1.3681\n",
            "Epoch 3252/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7819 - val_loss: 0.7898\n",
            "Epoch 3253/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9061 - val_loss: 0.9718\n",
            "Epoch 3254/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8579 - val_loss: 1.4581\n",
            "Epoch 3255/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7381 - val_loss: 1.1581\n",
            "Epoch 3256/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.1035 - val_loss: 0.9839\n",
            "Epoch 3257/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7375 - val_loss: 1.0763\n",
            "Epoch 3258/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.4142 - val_loss: 2.0498\n",
            "Epoch 3259/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7143 - val_loss: 1.1701\n",
            "Epoch 3260/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0453 - val_loss: 1.1780\n",
            "Epoch 3261/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7366 - val_loss: 1.0159\n",
            "Epoch 3262/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7072 - val_loss: 1.2085\n",
            "Epoch 3263/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0858 - val_loss: 1.2370\n",
            "Epoch 3264/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7581 - val_loss: 1.5116\n",
            "Epoch 3265/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9397 - val_loss: 1.3880\n",
            "Epoch 3266/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.1765 - val_loss: 4.5275\n",
            "Epoch 3267/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.3000 - val_loss: 1.7737\n",
            "Epoch 3268/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7539 - val_loss: 1.1776\n",
            "Epoch 3269/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8009 - val_loss: 2.0707\n",
            "Epoch 3270/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7682 - val_loss: 1.4564\n",
            "Epoch 3271/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9327 - val_loss: 1.0099\n",
            "Epoch 3272/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.8072 - val_loss: 1.5134\n",
            "Epoch 3273/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9475 - val_loss: 0.8476\n",
            "Epoch 3274/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.1173 - val_loss: 1.2265\n",
            "Epoch 3275/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8686 - val_loss: 1.6150\n",
            "Epoch 3276/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.7962 - val_loss: 1.1631\n",
            "Epoch 3277/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7967 - val_loss: 1.3484\n",
            "Epoch 3278/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.1567 - val_loss: 1.0724\n",
            "Epoch 3279/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0496 - val_loss: 1.1285\n",
            "Epoch 3280/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9125 - val_loss: 1.2848\n",
            "Epoch 3281/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7176 - val_loss: 1.4853\n",
            "Epoch 3282/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9116 - val_loss: 1.3888\n",
            "Epoch 3283/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9006 - val_loss: 2.0167\n",
            "Epoch 3284/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.1136 - val_loss: 1.1427\n",
            "Epoch 3285/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8498 - val_loss: 1.4488\n",
            "Epoch 3286/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8796 - val_loss: 1.8772\n",
            "Epoch 3287/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9642 - val_loss: 1.3032\n",
            "Epoch 3288/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0049 - val_loss: 1.4157\n",
            "Epoch 3289/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8032 - val_loss: 1.2552\n",
            "Epoch 3290/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0838 - val_loss: 1.0552\n",
            "Epoch 3291/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7087 - val_loss: 1.4003\n",
            "Epoch 3292/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0134 - val_loss: 1.1703\n",
            "Epoch 3293/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6485 - val_loss: 2.5050\n",
            "Epoch 3294/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0585 - val_loss: 1.2918\n",
            "Epoch 3295/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8837 - val_loss: 1.1097\n",
            "Epoch 3296/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9467 - val_loss: 1.6273\n",
            "Epoch 3297/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8273 - val_loss: 1.2268\n",
            "Epoch 3298/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0076 - val_loss: 2.2002\n",
            "Epoch 3299/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7364 - val_loss: 1.1437\n",
            "Epoch 3300/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.4703 - val_loss: 1.3789\n",
            "Epoch 3301/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0693 - val_loss: 1.8916\n",
            "Epoch 3302/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7971 - val_loss: 1.1681\n",
            "Epoch 3303/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9018 - val_loss: 1.3845\n",
            "Epoch 3304/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9099 - val_loss: 1.3259\n",
            "Epoch 3305/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8684 - val_loss: 1.7049\n",
            "Epoch 3306/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6940 - val_loss: 1.2413\n",
            "Epoch 3307/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9299 - val_loss: 0.9698\n",
            "Epoch 3308/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7624 - val_loss: 1.7629\n",
            "Epoch 3309/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7068 - val_loss: 1.2163\n",
            "Epoch 3310/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9242 - val_loss: 1.1454\n",
            "Epoch 3311/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8540 - val_loss: 2.2873\n",
            "Epoch 3312/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9291 - val_loss: 1.9479\n",
            "Epoch 3313/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7982 - val_loss: 1.1487\n",
            "Epoch 3314/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.2248 - val_loss: 1.4205\n",
            "Epoch 3315/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2.6371 - val_loss: 1.2381\n",
            "Epoch 3316/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7610 - val_loss: 1.4519\n",
            "Epoch 3317/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9518 - val_loss: 1.1592\n",
            "Epoch 3318/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.1262 - val_loss: 0.8516\n",
            "Epoch 3319/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8377 - val_loss: 1.1132\n",
            "Epoch 3320/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9819 - val_loss: 0.9185\n",
            "Epoch 3321/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0359 - val_loss: 1.0687\n",
            "Epoch 3322/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8383 - val_loss: 1.7843\n",
            "Epoch 3323/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2.3537 - val_loss: 2.7749\n",
            "Epoch 3324/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6672 - val_loss: 1.1133\n",
            "Epoch 3325/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9754 - val_loss: 1.1938\n",
            "Epoch 3326/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0481 - val_loss: 4.0816\n",
            "Epoch 3327/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8457 - val_loss: 1.0298\n",
            "Epoch 3328/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7187 - val_loss: 1.7331\n",
            "Epoch 3329/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.1915 - val_loss: 2.8486\n",
            "Epoch 3330/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0134 - val_loss: 1.3275\n",
            "Epoch 3331/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7675 - val_loss: 1.8786\n",
            "Epoch 3332/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8579 - val_loss: 1.0221\n",
            "Epoch 3333/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8316 - val_loss: 1.3373\n",
            "Epoch 3334/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8138 - val_loss: 1.6872\n",
            "Epoch 3335/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.2038 - val_loss: 0.8801\n",
            "Epoch 3336/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9728 - val_loss: 1.1163\n",
            "Epoch 3337/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.1292 - val_loss: 1.5899\n",
            "Epoch 3338/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7981 - val_loss: 1.2001\n",
            "Epoch 3339/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.3016 - val_loss: 1.3841\n",
            "Epoch 3340/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0225 - val_loss: 1.3439\n",
            "Epoch 3341/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8029 - val_loss: 2.2945\n",
            "Epoch 3342/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7235 - val_loss: 1.5613\n",
            "Epoch 3343/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.3751 - val_loss: 1.2041\n",
            "Epoch 3344/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7402 - val_loss: 2.1595\n",
            "Epoch 3345/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7122 - val_loss: 0.8827\n",
            "Epoch 3346/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.1862 - val_loss: 1.6692\n",
            "Epoch 3347/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7346 - val_loss: 1.0214\n",
            "Epoch 3348/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7572 - val_loss: 1.8631\n",
            "Epoch 3349/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9397 - val_loss: 0.9327\n",
            "Epoch 3350/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8612 - val_loss: 1.3547\n",
            "Epoch 3351/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9368 - val_loss: 1.2699\n",
            "Epoch 3352/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7909 - val_loss: 1.2352\n",
            "Epoch 3353/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2.0846 - val_loss: 2.4106\n",
            "Epoch 3354/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6881 - val_loss: 4.3856\n",
            "Epoch 3355/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7112 - val_loss: 1.2973\n",
            "Epoch 3356/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7708 - val_loss: 1.5110\n",
            "Epoch 3357/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9770 - val_loss: 1.3898\n",
            "Epoch 3358/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8785 - val_loss: 1.1215\n",
            "Epoch 3359/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8154 - val_loss: 2.3275\n",
            "Epoch 3360/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8260 - val_loss: 14.6054\n",
            "Epoch 3361/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7365 - val_loss: 1.1432\n",
            "Epoch 3362/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8536 - val_loss: 1.0382\n",
            "Epoch 3363/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7426 - val_loss: 0.9985\n",
            "Epoch 3364/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.4293 - val_loss: 0.9755\n",
            "Epoch 3365/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9618 - val_loss: 1.3374\n",
            "Epoch 3366/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.6778 - val_loss: 0.9367\n",
            "Epoch 3367/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8997 - val_loss: 0.7288\n",
            "Epoch 3368/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9433 - val_loss: 1.1890\n",
            "Epoch 3369/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8151 - val_loss: 3.0069\n",
            "Epoch 3370/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0901 - val_loss: 1.0870\n",
            "Epoch 3371/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0118 - val_loss: 1.5607\n",
            "Epoch 3372/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9627 - val_loss: 1.8695\n",
            "Epoch 3373/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6991 - val_loss: 1.2125\n",
            "Epoch 3374/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8761 - val_loss: 3.0676\n",
            "Epoch 3375/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7919 - val_loss: 1.6765\n",
            "Epoch 3376/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9318 - val_loss: 1.0366\n",
            "Epoch 3377/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0497 - val_loss: 0.9391\n",
            "Epoch 3378/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7386 - val_loss: 1.2573\n",
            "Epoch 3379/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8100 - val_loss: 4.3783\n",
            "Epoch 3380/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0048 - val_loss: 1.3625\n",
            "Epoch 3381/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8339 - val_loss: 1.0649\n",
            "Epoch 3382/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8748 - val_loss: 1.0043\n",
            "Epoch 3383/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9129 - val_loss: 1.2889\n",
            "Epoch 3384/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7423 - val_loss: 1.0758\n",
            "Epoch 3385/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.2203 - val_loss: 1.5389\n",
            "Epoch 3386/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.5003 - val_loss: 1.9004\n",
            "Epoch 3387/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.1391 - val_loss: 1.2459\n",
            "Epoch 3388/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7996 - val_loss: 1.7184\n",
            "Epoch 3389/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.5266 - val_loss: 1.6625\n",
            "Epoch 3390/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.3857 - val_loss: 1.6380\n",
            "Epoch 3391/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9770 - val_loss: 1.3691\n",
            "Epoch 3392/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7529 - val_loss: 1.2263\n",
            "Epoch 3393/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.3556 - val_loss: 2.1310\n",
            "Epoch 3394/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8257 - val_loss: 1.2081\n",
            "Epoch 3395/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.8853 - val_loss: 1.3155\n",
            "Epoch 3396/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8882 - val_loss: 1.2863\n",
            "Epoch 3397/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.1263 - val_loss: 1.8881\n",
            "Epoch 3398/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7346 - val_loss: 1.7794\n",
            "Epoch 3399/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6757 - val_loss: 1.0482\n",
            "Epoch 3400/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9654 - val_loss: 1.1276\n",
            "Epoch 3401/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8220 - val_loss: 1.0028\n",
            "Epoch 3402/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6974 - val_loss: 0.9968\n",
            "Epoch 3403/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7473 - val_loss: 2.5800\n",
            "Epoch 3404/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8286 - val_loss: 1.3766\n",
            "Epoch 3405/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7159 - val_loss: 2.3424\n",
            "Epoch 3406/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8874 - val_loss: 1.4607\n",
            "Epoch 3407/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7120 - val_loss: 1.8569\n",
            "Epoch 3408/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.1929 - val_loss: 0.7556\n",
            "Epoch 3409/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8692 - val_loss: 1.2126\n",
            "Epoch 3410/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7697 - val_loss: 0.8525\n",
            "Epoch 3411/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7575 - val_loss: 1.0807\n",
            "Epoch 3412/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0134 - val_loss: 0.9527\n",
            "Epoch 3413/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9764 - val_loss: 1.5563\n",
            "Epoch 3414/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7943 - val_loss: 1.2069\n",
            "Epoch 3415/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0555 - val_loss: 2.0356\n",
            "Epoch 3416/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8728 - val_loss: 1.0539\n",
            "Epoch 3417/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.2673 - val_loss: 1.3340\n",
            "Epoch 3418/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0435 - val_loss: 1.2649\n",
            "Epoch 3419/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.1066 - val_loss: 1.2104\n",
            "Epoch 3420/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7863 - val_loss: 1.1252\n",
            "Epoch 3421/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7598 - val_loss: 1.2147\n",
            "Epoch 3422/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9801 - val_loss: 1.1113\n",
            "Epoch 3423/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.7960 - val_loss: 1.4357\n",
            "Epoch 3424/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9854 - val_loss: 1.0668\n",
            "Epoch 3425/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.2126 - val_loss: 1.2074\n",
            "Epoch 3426/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.1013 - val_loss: 1.1174\n",
            "Epoch 3427/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8440 - val_loss: 1.6964\n",
            "Epoch 3428/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0349 - val_loss: 1.1342\n",
            "Epoch 3429/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0420 - val_loss: 1.1821\n",
            "Epoch 3430/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0184 - val_loss: 1.0368\n",
            "Epoch 3431/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.1210 - val_loss: 1.5899\n",
            "Epoch 3432/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6649 - val_loss: 1.5614\n",
            "Epoch 3433/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.1147 - val_loss: 1.2734\n",
            "Epoch 3434/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7814 - val_loss: 1.3749\n",
            "Epoch 3435/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0743 - val_loss: 0.8983\n",
            "Epoch 3436/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.1701 - val_loss: 1.5249\n",
            "Epoch 3437/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7695 - val_loss: 1.7633\n",
            "Epoch 3438/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.1216 - val_loss: 1.4618\n",
            "Epoch 3439/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7461 - val_loss: 0.9462\n",
            "Epoch 3440/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8899 - val_loss: 1.7198\n",
            "Epoch 3441/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.3498 - val_loss: 1.1709\n",
            "Epoch 3442/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8857 - val_loss: 2.0645\n",
            "Epoch 3443/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9492 - val_loss: 1.3053\n",
            "Epoch 3444/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.2353 - val_loss: 1.3362\n",
            "Epoch 3445/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8871 - val_loss: 1.0792\n",
            "Epoch 3446/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0735 - val_loss: 1.3745\n",
            "Epoch 3447/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0285 - val_loss: 1.5424\n",
            "Epoch 3448/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7982 - val_loss: 1.0710\n",
            "Epoch 3449/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.2344 - val_loss: 1.1770\n",
            "Epoch 3450/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8202 - val_loss: 0.7572\n",
            "Epoch 3451/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.1214 - val_loss: 0.9332\n",
            "Epoch 3452/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9384 - val_loss: 1.7874\n",
            "Epoch 3453/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.3114 - val_loss: 1.5119\n",
            "Epoch 3454/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0844 - val_loss: 1.1446\n",
            "Epoch 3455/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7918 - val_loss: 1.0004\n",
            "Epoch 3456/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9109 - val_loss: 1.7360\n",
            "Epoch 3457/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9178 - val_loss: 1.3462\n",
            "Epoch 3458/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0106 - val_loss: 1.1892\n",
            "Epoch 3459/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9478 - val_loss: 1.1572\n",
            "Epoch 3460/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9384 - val_loss: 1.5291\n",
            "Epoch 3461/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9121 - val_loss: 12.0890\n",
            "Epoch 3462/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8213 - val_loss: 1.3238\n",
            "Epoch 3463/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6828 - val_loss: 8.0119\n",
            "Epoch 3464/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9178 - val_loss: 1.0691\n",
            "Epoch 3465/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8821 - val_loss: 1.4610\n",
            "Epoch 3466/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7635 - val_loss: 1.1417\n",
            "Epoch 3467/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7213 - val_loss: 1.0406\n",
            "Epoch 3468/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9792 - val_loss: 0.7630\n",
            "Epoch 3469/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0048 - val_loss: 1.2246\n",
            "Epoch 3470/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.6903 - val_loss: 0.9868\n",
            "Epoch 3471/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9461 - val_loss: 1.0951\n",
            "Epoch 3472/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0413 - val_loss: 1.8741\n",
            "Epoch 3473/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9614 - val_loss: 1.1672\n",
            "Epoch 3474/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0123 - val_loss: 0.9255\n",
            "Epoch 3475/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9766 - val_loss: 0.9180\n",
            "Epoch 3476/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0298 - val_loss: 1.5949\n",
            "Epoch 3477/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7150 - val_loss: 1.4690\n",
            "Epoch 3478/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.9629 - val_loss: 1.1209\n",
            "Epoch 3479/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6865 - val_loss: 1.0168\n",
            "Epoch 3480/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7409 - val_loss: 1.8220\n",
            "Epoch 3481/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0349 - val_loss: 1.4333\n",
            "Epoch 3482/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7736 - val_loss: 1.2226\n",
            "Epoch 3483/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7941 - val_loss: 1.9394\n",
            "Epoch 3484/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8109 - val_loss: 1.0650\n",
            "Epoch 3485/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8533 - val_loss: 2.0642\n",
            "Epoch 3486/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9013 - val_loss: 2.2002\n",
            "Epoch 3487/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7394 - val_loss: 3.2618\n",
            "Epoch 3488/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6835 - val_loss: 3.7884\n",
            "Epoch 3489/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.1687 - val_loss: 0.9093\n",
            "Epoch 3490/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9848 - val_loss: 0.9766\n",
            "Epoch 3491/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.3852 - val_loss: 1.1531\n",
            "Epoch 3492/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0875 - val_loss: 1.0538\n",
            "Epoch 3493/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8067 - val_loss: 1.2382\n",
            "Epoch 3494/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8573 - val_loss: 1.6359\n",
            "Epoch 3495/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9884 - val_loss: 0.9535\n",
            "Epoch 3496/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.6129 - val_loss: 1.3548\n",
            "Epoch 3497/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8395 - val_loss: 1.4560\n",
            "Epoch 3498/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9552 - val_loss: 1.1923\n",
            "Epoch 3499/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9724 - val_loss: 0.9114\n",
            "Epoch 3500/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8171 - val_loss: 1.3625\n",
            "Epoch 3501/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.2206 - val_loss: 0.6777\n",
            "Epoch 3502/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8259 - val_loss: 2.3460\n",
            "Epoch 3503/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.5297 - val_loss: 1.3625\n",
            "Epoch 3504/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2.6447 - val_loss: 1.1795\n",
            "Epoch 3505/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.3846 - val_loss: 2.1015\n",
            "Epoch 3506/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.6556 - val_loss: 0.9632\n",
            "Epoch 3507/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8529 - val_loss: 1.0344\n",
            "Epoch 3508/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.1549 - val_loss: 1.2764\n",
            "Epoch 3509/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9574 - val_loss: 2.7543\n",
            "Epoch 3510/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.7651 - val_loss: 1.1846\n",
            "Epoch 3511/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8434 - val_loss: 1.3987\n",
            "Epoch 3512/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7594 - val_loss: 0.9853\n",
            "Epoch 3513/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.4379 - val_loss: 1.5358\n",
            "Epoch 3514/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0168 - val_loss: 1.1306\n",
            "Epoch 3515/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0545 - val_loss: 1.1531\n",
            "Epoch 3516/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0673 - val_loss: 1.2151\n",
            "Epoch 3517/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0938 - val_loss: 1.8128\n",
            "Epoch 3518/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6879 - val_loss: 1.1115\n",
            "Epoch 3519/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6504 - val_loss: 1.4255\n",
            "Epoch 3520/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.3104 - val_loss: 1.6185\n",
            "Epoch 3521/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6729 - val_loss: 1.2783\n",
            "Epoch 3522/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0125 - val_loss: 1.2596\n",
            "Epoch 3523/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8908 - val_loss: 1.0806\n",
            "Epoch 3524/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6894 - val_loss: 1.5639\n",
            "Epoch 3525/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 3.0382 - val_loss: 1.4016\n",
            "Epoch 3526/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8537 - val_loss: 1.0503\n",
            "Epoch 3527/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9268 - val_loss: 1.1123\n",
            "Epoch 3528/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8203 - val_loss: 1.3479\n",
            "Epoch 3529/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9618 - val_loss: 1.1841\n",
            "Epoch 3530/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7171 - val_loss: 0.9763\n",
            "Epoch 3531/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7511 - val_loss: 1.3946\n",
            "Epoch 3532/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9183 - val_loss: 1.0477\n",
            "Epoch 3533/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9661 - val_loss: 1.1558\n",
            "Epoch 3534/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6694 - val_loss: 1.0070\n",
            "Epoch 3535/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8289 - val_loss: 1.8520\n",
            "Epoch 3536/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8430 - val_loss: 0.9437\n",
            "Epoch 3537/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.3085 - val_loss: 0.8720\n",
            "Epoch 3538/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.3223 - val_loss: 1.4219\n",
            "Epoch 3539/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0346 - val_loss: 1.6605\n",
            "Epoch 3540/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7696 - val_loss: 1.5545\n",
            "Epoch 3541/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7357 - val_loss: 0.8590\n",
            "Epoch 3542/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8637 - val_loss: 1.0309\n",
            "Epoch 3543/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.1095 - val_loss: 0.9280\n",
            "Epoch 3544/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8417 - val_loss: 1.2757\n",
            "Epoch 3545/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0879 - val_loss: 1.3779\n",
            "Epoch 3546/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8802 - val_loss: 0.7046\n",
            "Epoch 3547/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8119 - val_loss: 1.0365\n",
            "Epoch 3548/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6549 - val_loss: 0.9024\n",
            "Epoch 3549/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8879 - val_loss: 3.8632\n",
            "Epoch 3550/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8477 - val_loss: 0.9959\n",
            "Epoch 3551/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.9424 - val_loss: 0.9223\n",
            "Epoch 3552/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8396 - val_loss: 1.5015\n",
            "Epoch 3553/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9359 - val_loss: 0.8853\n",
            "Epoch 3554/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8131 - val_loss: 2.0540\n",
            "Epoch 3555/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9307 - val_loss: 1.1476\n",
            "Epoch 3556/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7814 - val_loss: 1.3894\n",
            "Epoch 3557/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0594 - val_loss: 1.5272\n",
            "Epoch 3558/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0234 - val_loss: 1.3893\n",
            "Epoch 3559/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0140 - val_loss: 4.3868\n",
            "Epoch 3560/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6973 - val_loss: 1.6558\n",
            "Epoch 3561/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0984 - val_loss: 1.0856\n",
            "Epoch 3562/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9129 - val_loss: 1.0870\n",
            "Epoch 3563/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8356 - val_loss: 1.5349\n",
            "Epoch 3564/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.5938 - val_loss: 1.6427\n",
            "Epoch 3565/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 4.3729 - val_loss: 0.5626\n",
            "Epoch 3566/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7629 - val_loss: 1.1830\n",
            "Epoch 3567/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.4468 - val_loss: 1.1454\n",
            "Epoch 3568/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.4918 - val_loss: 1.2664\n",
            "Epoch 3569/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.4707 - val_loss: 0.9074\n",
            "Epoch 3570/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9375 - val_loss: 1.6921\n",
            "Epoch 3571/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0487 - val_loss: 1.8053\n",
            "Epoch 3572/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7638 - val_loss: 1.4285\n",
            "Epoch 3573/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9528 - val_loss: 1.9823\n",
            "Epoch 3574/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6910 - val_loss: 1.7506\n",
            "Epoch 3575/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7377 - val_loss: 0.9270\n",
            "Epoch 3576/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8495 - val_loss: 0.9301\n",
            "Epoch 3577/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.1493 - val_loss: 1.5571\n",
            "Epoch 3578/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7072 - val_loss: 0.6915\n",
            "Epoch 3579/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.9706 - val_loss: 1.3312\n",
            "Epoch 3580/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0324 - val_loss: 2.0965\n",
            "Epoch 3581/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.2508 - val_loss: 1.9265\n",
            "Epoch 3582/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7798 - val_loss: 1.5488\n",
            "Epoch 3583/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7747 - val_loss: 1.6504\n",
            "Epoch 3584/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7623 - val_loss: 1.1993\n",
            "Epoch 3585/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7787 - val_loss: 0.7143\n",
            "Epoch 3586/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.4285 - val_loss: 0.8040\n",
            "Epoch 3587/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9129 - val_loss: 1.6192\n",
            "Epoch 3588/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9193 - val_loss: 1.3178\n",
            "Epoch 3589/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.1731 - val_loss: 1.2370\n",
            "Epoch 3590/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8737 - val_loss: 1.1175\n",
            "Epoch 3591/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0529 - val_loss: 1.1963\n",
            "Epoch 3592/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9033 - val_loss: 1.3132\n",
            "Epoch 3593/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8233 - val_loss: 1.7110\n",
            "Epoch 3594/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8719 - val_loss: 1.6281\n",
            "Epoch 3595/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7592 - val_loss: 1.1075\n",
            "Epoch 3596/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8341 - val_loss: 2.2402\n",
            "Epoch 3597/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9014 - val_loss: 1.1739\n",
            "Epoch 3598/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0682 - val_loss: 1.0848\n",
            "Epoch 3599/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8629 - val_loss: 1.3084\n",
            "Epoch 3600/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8815 - val_loss: 1.9242\n",
            "Epoch 3601/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.1242 - val_loss: 1.3220\n",
            "Epoch 3602/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7943 - val_loss: 2.1627\n",
            "Epoch 3603/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7692 - val_loss: 1.3100\n",
            "Epoch 3604/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9722 - val_loss: 2.5860\n",
            "Epoch 3605/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8674 - val_loss: 0.7730\n",
            "Epoch 3606/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7231 - val_loss: 0.9920\n",
            "Epoch 3607/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0364 - val_loss: 1.8438\n",
            "Epoch 3608/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9468 - val_loss: 1.4471\n",
            "Epoch 3609/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8580 - val_loss: 0.9874\n",
            "Epoch 3610/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8288 - val_loss: 0.9643\n",
            "Epoch 3611/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8899 - val_loss: 4.4367\n",
            "Epoch 3612/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0139 - val_loss: 1.4194\n",
            "Epoch 3613/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7437 - val_loss: 1.7408\n",
            "Epoch 3614/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.3336 - val_loss: 1.5964\n",
            "Epoch 3615/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8301 - val_loss: 1.4110\n",
            "Epoch 3616/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.3393 - val_loss: 1.2483\n",
            "Epoch 3617/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6789 - val_loss: 1.2246\n",
            "Epoch 3618/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8123 - val_loss: 1.9763\n",
            "Epoch 3619/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0403 - val_loss: 2.0094\n",
            "Epoch 3620/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.3743 - val_loss: 1.3771\n",
            "Epoch 3621/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7780 - val_loss: 1.2533\n",
            "Epoch 3622/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7346 - val_loss: 0.7568\n",
            "Epoch 3623/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9152 - val_loss: 1.5269\n",
            "Epoch 3624/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7785 - val_loss: 1.2266\n",
            "Epoch 3625/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.2188 - val_loss: 1.4131\n",
            "Epoch 3626/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9030 - val_loss: 1.5775\n",
            "Epoch 3627/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8968 - val_loss: 1.0188\n",
            "Epoch 3628/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9427 - val_loss: 1.1209\n",
            "Epoch 3629/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0591 - val_loss: 1.1556\n",
            "Epoch 3630/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7339 - val_loss: 1.1492\n",
            "Epoch 3631/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.1577 - val_loss: 1.0664\n",
            "Epoch 3632/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9244 - val_loss: 0.9733\n",
            "Epoch 3633/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8468 - val_loss: 3.0855\n",
            "Epoch 3634/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8249 - val_loss: 1.1530\n",
            "Epoch 3635/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8570 - val_loss: 7.3351\n",
            "Epoch 3636/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0770 - val_loss: 1.7919\n",
            "Epoch 3637/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8396 - val_loss: 1.9872\n",
            "Epoch 3638/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.2800 - val_loss: 1.1331\n",
            "Epoch 3639/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6930 - val_loss: 1.0356\n",
            "Epoch 3640/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6991 - val_loss: 1.5335\n",
            "Epoch 3641/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7957 - val_loss: 1.3133\n",
            "Epoch 3642/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8772 - val_loss: 1.0291\n",
            "Epoch 3643/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.2909 - val_loss: 1.0022\n",
            "Epoch 3644/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8325 - val_loss: 1.9566\n",
            "Epoch 3645/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9596 - val_loss: 2.3437\n",
            "Epoch 3646/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7071 - val_loss: 1.4455\n",
            "Epoch 3647/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8298 - val_loss: 1.8509\n",
            "Epoch 3648/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7425 - val_loss: 0.5643\n",
            "Epoch 3649/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0215 - val_loss: 1.1474\n",
            "Epoch 3650/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8579 - val_loss: 0.8359\n",
            "Epoch 3651/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7956 - val_loss: 1.2172\n",
            "Epoch 3652/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.5563 - val_loss: 1.5086\n",
            "Epoch 3653/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8700 - val_loss: 1.1941\n",
            "Epoch 3654/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.1279 - val_loss: 1.1774\n",
            "Epoch 3655/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8541 - val_loss: 1.6239\n",
            "Epoch 3656/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.2117 - val_loss: 1.1660\n",
            "Epoch 3657/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.3338 - val_loss: 1.4124\n",
            "Epoch 3658/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7739 - val_loss: 1.9889\n",
            "Epoch 3659/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.1601 - val_loss: 1.4845\n",
            "Epoch 3660/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.9014 - val_loss: 2.7294\n",
            "Epoch 3661/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.2577 - val_loss: 2.2512\n",
            "Epoch 3662/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9799 - val_loss: 1.3214\n",
            "Epoch 3663/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0872 - val_loss: 1.6010\n",
            "Epoch 3664/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8287 - val_loss: 1.3599\n",
            "Epoch 3665/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8292 - val_loss: 1.6690\n",
            "Epoch 3666/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8548 - val_loss: 1.9970\n",
            "Epoch 3667/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9442 - val_loss: 1.1145\n",
            "Epoch 3668/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8578 - val_loss: 1.0396\n",
            "Epoch 3669/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8097 - val_loss: 1.1282\n",
            "Epoch 3670/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8061 - val_loss: 1.2470\n",
            "Epoch 3671/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8527 - val_loss: 3.8616\n",
            "Epoch 3672/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8231 - val_loss: 1.6470\n",
            "Epoch 3673/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0193 - val_loss: 1.8890\n",
            "Epoch 3674/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9443 - val_loss: 1.6434\n",
            "Epoch 3675/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8293 - val_loss: 0.9798\n",
            "Epoch 3676/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9639 - val_loss: 1.1525\n",
            "Epoch 3677/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7314 - val_loss: 0.8840\n",
            "Epoch 3678/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8322 - val_loss: 1.2504\n",
            "Epoch 3679/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8410 - val_loss: 2.5956\n",
            "Epoch 3680/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9225 - val_loss: 1.6190\n",
            "Epoch 3681/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9433 - val_loss: 1.2366\n",
            "Epoch 3682/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7480 - val_loss: 1.9312\n",
            "Epoch 3683/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9499 - val_loss: 1.1295\n",
            "Epoch 3684/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8350 - val_loss: 1.1662\n",
            "Epoch 3685/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9065 - val_loss: 0.7674\n",
            "Epoch 3686/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0857 - val_loss: 1.1578\n",
            "Epoch 3687/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0038 - val_loss: 2.0008\n",
            "Epoch 3688/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.1816 - val_loss: 1.7139\n",
            "Epoch 3689/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7934 - val_loss: 1.7069\n",
            "Epoch 3690/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6708 - val_loss: 1.8329\n",
            "Epoch 3691/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8332 - val_loss: 0.9932\n",
            "Epoch 3692/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7761 - val_loss: 3.2690\n",
            "Epoch 3693/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.1332 - val_loss: 1.2480\n",
            "Epoch 3694/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7956 - val_loss: 3.6868\n",
            "Epoch 3695/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8282 - val_loss: 1.5369\n",
            "Epoch 3696/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0916 - val_loss: 1.1749\n",
            "Epoch 3697/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.2375 - val_loss: 1.9611\n",
            "Epoch 3698/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6829 - val_loss: 1.0851\n",
            "Epoch 3699/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8879 - val_loss: 1.2479\n",
            "Epoch 3700/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.2594 - val_loss: 1.5556\n",
            "Epoch 3701/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9808 - val_loss: 1.3396\n",
            "Epoch 3702/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7764 - val_loss: 1.1299\n",
            "Epoch 3703/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7835 - val_loss: 1.2596\n",
            "Epoch 3704/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6430 - val_loss: 1.2823\n",
            "Epoch 3705/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0341 - val_loss: 1.3137\n",
            "Epoch 3706/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7925 - val_loss: 1.2385\n",
            "Epoch 3707/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7462 - val_loss: 0.9807\n",
            "Epoch 3708/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.5015 - val_loss: 2.7369\n",
            "Epoch 3709/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6930 - val_loss: 3.0108\n",
            "Epoch 3710/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.7554 - val_loss: 1.0710\n",
            "Epoch 3711/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9081 - val_loss: 1.4256\n",
            "Epoch 3712/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.2389 - val_loss: 0.8572\n",
            "Epoch 3713/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8639 - val_loss: 2.7707\n",
            "Epoch 3714/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.1404 - val_loss: 1.2158\n",
            "Epoch 3715/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8599 - val_loss: 1.1567\n",
            "Epoch 3716/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9332 - val_loss: 0.9070\n",
            "Epoch 3717/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8351 - val_loss: 4.3053\n",
            "Epoch 3718/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8714 - val_loss: 1.3716\n",
            "Epoch 3719/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0745 - val_loss: 1.1534\n",
            "Epoch 3720/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8864 - val_loss: 1.5107\n",
            "Epoch 3721/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7809 - val_loss: 1.6073\n",
            "Epoch 3722/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0491 - val_loss: 0.9412\n",
            "Epoch 3723/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7609 - val_loss: 3.1974\n",
            "Epoch 3724/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.4091 - val_loss: 1.4684\n",
            "Epoch 3725/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7058 - val_loss: 0.9757\n",
            "Epoch 3726/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7629 - val_loss: 1.2539\n",
            "Epoch 3727/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.8761 - val_loss: 0.9642\n",
            "Epoch 3728/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.1478 - val_loss: 1.6913\n",
            "Epoch 3729/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9505 - val_loss: 1.2215\n",
            "Epoch 3730/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8842 - val_loss: 1.8928\n",
            "Epoch 3731/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7905 - val_loss: 2.0581\n",
            "Epoch 3732/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7229 - val_loss: 1.6142\n",
            "Epoch 3733/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7773 - val_loss: 0.9956\n",
            "Epoch 3734/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0856 - val_loss: 0.9897\n",
            "Epoch 3735/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.5854 - val_loss: 1.1093\n",
            "Epoch 3736/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7839 - val_loss: 1.2863\n",
            "Epoch 3737/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.1486 - val_loss: 1.3852\n",
            "Epoch 3738/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9204 - val_loss: 0.8700\n",
            "Epoch 3739/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7387 - val_loss: 1.9588\n",
            "Epoch 3740/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9815 - val_loss: 1.6807\n",
            "Epoch 3741/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9749 - val_loss: 1.4474\n",
            "Epoch 3742/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9521 - val_loss: 1.8257\n",
            "Epoch 3743/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.2781 - val_loss: 0.8946\n",
            "Epoch 3744/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0451 - val_loss: 1.4073\n",
            "Epoch 3745/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7871 - val_loss: 1.6239\n",
            "Epoch 3746/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0107 - val_loss: 1.1299\n",
            "Epoch 3747/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7726 - val_loss: 2.0990\n",
            "Epoch 3748/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8177 - val_loss: 1.2636\n",
            "Epoch 3749/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9233 - val_loss: 1.7616\n",
            "Epoch 3750/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0466 - val_loss: 0.9772\n",
            "Epoch 3751/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.6820 - val_loss: 0.8512\n",
            "Epoch 3752/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9561 - val_loss: 2.4236\n",
            "Epoch 3753/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8481 - val_loss: 2.0980\n",
            "Epoch 3754/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.2007 - val_loss: 0.8755\n",
            "Epoch 3755/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8349 - val_loss: 1.2914\n",
            "Epoch 3756/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9446 - val_loss: 1.9524\n",
            "Epoch 3757/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8933 - val_loss: 1.6095\n",
            "Epoch 3758/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9462 - val_loss: 0.9138\n",
            "Epoch 3759/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7237 - val_loss: 1.3299\n",
            "Epoch 3760/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6209 - val_loss: 1.1695\n",
            "Epoch 3761/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7649 - val_loss: 1.3215\n",
            "Epoch 3762/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7442 - val_loss: 1.1206\n",
            "Epoch 3763/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8666 - val_loss: 1.0037\n",
            "Epoch 3764/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0259 - val_loss: 0.8728\n",
            "Epoch 3765/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8561 - val_loss: 0.9657\n",
            "Epoch 3766/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0250 - val_loss: 1.1018\n",
            "Epoch 3767/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8626 - val_loss: 1.0381\n",
            "Epoch 3768/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7825 - val_loss: 1.4877\n",
            "Epoch 3769/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7664 - val_loss: 2.8706\n",
            "Epoch 3770/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.3482 - val_loss: 1.3341\n",
            "Epoch 3771/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0197 - val_loss: 2.0312\n",
            "Epoch 3772/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0761 - val_loss: 1.3164\n",
            "Epoch 3773/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.1486 - val_loss: 1.1100\n",
            "Epoch 3774/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7916 - val_loss: 1.3250\n",
            "Epoch 3775/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0354 - val_loss: 1.0924\n",
            "Epoch 3776/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7261 - val_loss: 1.5940\n",
            "Epoch 3777/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7947 - val_loss: 0.9916\n",
            "Epoch 3778/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8001 - val_loss: 2.4209\n",
            "Epoch 3779/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7107 - val_loss: 2.6450\n",
            "Epoch 3780/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7917 - val_loss: 1.0713\n",
            "Epoch 3781/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8141 - val_loss: 0.7989\n",
            "Epoch 3782/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.1150 - val_loss: 1.3062\n",
            "Epoch 3783/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.3532 - val_loss: 1.5020\n",
            "Epoch 3784/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0372 - val_loss: 1.2369\n",
            "Epoch 3785/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8695 - val_loss: 2.5485\n",
            "Epoch 3786/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7571 - val_loss: 1.4056\n",
            "Epoch 3787/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7641 - val_loss: 1.5059\n",
            "Epoch 3788/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6297 - val_loss: 1.0037\n",
            "Epoch 3789/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0218 - val_loss: 1.1360\n",
            "Epoch 3790/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8712 - val_loss: 1.6672\n",
            "Epoch 3791/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7489 - val_loss: 3.4904\n",
            "Epoch 3792/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8430 - val_loss: 1.0369\n",
            "Epoch 3793/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8922 - val_loss: 0.8030\n",
            "Epoch 3794/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9933 - val_loss: 1.7002\n",
            "Epoch 3795/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9071 - val_loss: 1.4361\n",
            "Epoch 3796/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8576 - val_loss: 1.1942\n",
            "Epoch 3797/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8105 - val_loss: 1.5794\n",
            "Epoch 3798/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8467 - val_loss: 2.7621\n",
            "Epoch 3799/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7279 - val_loss: 1.1961\n",
            "Epoch 3800/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8651 - val_loss: 3.7639\n",
            "Epoch 3801/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0295 - val_loss: 1.2393\n",
            "Epoch 3802/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7910 - val_loss: 2.6609\n",
            "Epoch 3803/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.6056 - val_loss: 4.1467\n",
            "Epoch 3804/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8583 - val_loss: 1.1867\n",
            "Epoch 3805/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7532 - val_loss: 1.2264\n",
            "Epoch 3806/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0142 - val_loss: 2.5628\n",
            "Epoch 3807/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0429 - val_loss: 1.2185\n",
            "Epoch 3808/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6921 - val_loss: 2.5965\n",
            "Epoch 3809/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7073 - val_loss: 1.7407\n",
            "Epoch 3810/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8155 - val_loss: 1.5183\n",
            "Epoch 3811/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8413 - val_loss: 1.1711\n",
            "Epoch 3812/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8541 - val_loss: 1.2199\n",
            "Epoch 3813/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8128 - val_loss: 1.2704\n",
            "Epoch 3814/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0081 - val_loss: 1.4377\n",
            "Epoch 3815/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8772 - val_loss: 1.9220\n",
            "Epoch 3816/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7531 - val_loss: 1.3402\n",
            "Epoch 3817/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9190 - val_loss: 1.2903\n",
            "Epoch 3818/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.4440 - val_loss: 1.7884\n",
            "Epoch 3819/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8138 - val_loss: 1.4376\n",
            "Epoch 3820/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9239 - val_loss: 0.8659\n",
            "Epoch 3821/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8709 - val_loss: 8.0378\n",
            "Epoch 3822/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7967 - val_loss: 1.0654\n",
            "Epoch 3823/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8536 - val_loss: 0.9785\n",
            "Epoch 3824/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7519 - val_loss: 1.8582\n",
            "Epoch 3825/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8296 - val_loss: 1.7856\n",
            "Epoch 3826/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9060 - val_loss: 1.2342\n",
            "Epoch 3827/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0494 - val_loss: 1.6504\n",
            "Epoch 3828/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7541 - val_loss: 0.7902\n",
            "Epoch 3829/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7689 - val_loss: 1.0480\n",
            "Epoch 3830/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8865 - val_loss: 1.0264\n",
            "Epoch 3831/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8956 - val_loss: 1.5568\n",
            "Epoch 3832/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7392 - val_loss: 1.3374\n",
            "Epoch 3833/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.1293 - val_loss: 1.7006\n",
            "Epoch 3834/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.1108 - val_loss: 1.9574\n",
            "Epoch 3835/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.3703 - val_loss: 1.1736\n",
            "Epoch 3836/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7570 - val_loss: 1.7205\n",
            "Epoch 3837/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9120 - val_loss: 0.7842\n",
            "Epoch 3838/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7432 - val_loss: 1.0399\n",
            "Epoch 3839/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.5277 - val_loss: 1.7927\n",
            "Epoch 3840/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0214 - val_loss: 1.2769\n",
            "Epoch 3841/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0566 - val_loss: 2.5136\n",
            "Epoch 3842/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8555 - val_loss: 1.5979\n",
            "Epoch 3843/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.1647 - val_loss: 2.5403\n",
            "Epoch 3844/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7947 - val_loss: 0.8527\n",
            "Epoch 3845/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7951 - val_loss: 1.7148\n",
            "Epoch 3846/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7661 - val_loss: 0.8114\n",
            "Epoch 3847/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8237 - val_loss: 0.8457\n",
            "Epoch 3848/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5807 - val_loss: 3.2208\n",
            "Epoch 3849/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7809 - val_loss: 1.4223\n",
            "Epoch 3850/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7357 - val_loss: 1.8837\n",
            "Epoch 3851/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8303 - val_loss: 0.8917\n",
            "Epoch 3852/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9079 - val_loss: 1.3862\n",
            "Epoch 3853/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8209 - val_loss: 0.9309\n",
            "Epoch 3854/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7583 - val_loss: 1.0968\n",
            "Epoch 3855/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8431 - val_loss: 1.1033\n",
            "Epoch 3856/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8292 - val_loss: 0.9269\n",
            "Epoch 3857/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9585 - val_loss: 1.8095\n",
            "Epoch 3858/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9495 - val_loss: 1.1559\n",
            "Epoch 3859/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8812 - val_loss: 2.3719\n",
            "Epoch 3860/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8259 - val_loss: 1.0845\n",
            "Epoch 3861/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7008 - val_loss: 1.3041\n",
            "Epoch 3862/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0676 - val_loss: 2.2696\n",
            "Epoch 3863/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7770 - val_loss: 1.2309\n",
            "Epoch 3864/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9272 - val_loss: 1.0413\n",
            "Epoch 3865/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9431 - val_loss: 1.5504\n",
            "Epoch 3866/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8101 - val_loss: 1.3138\n",
            "Epoch 3867/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9942 - val_loss: 0.8516\n",
            "Epoch 3868/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8751 - val_loss: 1.0220\n",
            "Epoch 3869/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8193 - val_loss: 0.9697\n",
            "Epoch 3870/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.8700 - val_loss: 1.0103\n",
            "Epoch 3871/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9338 - val_loss: 1.2671\n",
            "Epoch 3872/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9267 - val_loss: 1.5324\n",
            "Epoch 3873/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0581 - val_loss: 2.0257\n",
            "Epoch 3874/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8012 - val_loss: 8.6637\n",
            "Epoch 3875/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8495 - val_loss: 1.2007\n",
            "Epoch 3876/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7815 - val_loss: 1.1660\n",
            "Epoch 3877/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7644 - val_loss: 1.1728\n",
            "Epoch 3878/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8156 - val_loss: 2.0997\n",
            "Epoch 3879/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8461 - val_loss: 0.9541\n",
            "Epoch 3880/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0724 - val_loss: 1.0878\n",
            "Epoch 3881/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9139 - val_loss: 1.4669\n",
            "Epoch 3882/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9197 - val_loss: 1.2474\n",
            "Epoch 3883/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2.3458 - val_loss: 0.7857\n",
            "Epoch 3884/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2.4640 - val_loss: 0.9417\n",
            "Epoch 3885/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.1758 - val_loss: 2.5136\n",
            "Epoch 3886/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9241 - val_loss: 1.1749\n",
            "Epoch 3887/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.2993 - val_loss: 1.3896\n",
            "Epoch 3888/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8490 - val_loss: 1.2764\n",
            "Epoch 3889/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9228 - val_loss: 1.5846\n",
            "Epoch 3890/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7520 - val_loss: 1.1712\n",
            "Epoch 3891/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7379 - val_loss: 2.0587\n",
            "Epoch 3892/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7881 - val_loss: 1.0277\n",
            "Epoch 3893/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7454 - val_loss: 1.1234\n",
            "Epoch 3894/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.2057 - val_loss: 0.9211\n",
            "Epoch 3895/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8650 - val_loss: 0.9589\n",
            "Epoch 3896/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.3461 - val_loss: 0.8623\n",
            "Epoch 3897/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0431 - val_loss: 1.1445\n",
            "Epoch 3898/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8162 - val_loss: 1.3519\n",
            "Epoch 3899/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5959 - val_loss: 1.6908\n",
            "Epoch 3900/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7091 - val_loss: 1.1250\n",
            "Epoch 3901/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.6163 - val_loss: 2.0037\n",
            "Epoch 3902/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7907 - val_loss: 1.1801\n",
            "Epoch 3903/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7082 - val_loss: 2.3464\n",
            "Epoch 3904/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8908 - val_loss: 1.0081\n",
            "Epoch 3905/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0250 - val_loss: 0.9462\n",
            "Epoch 3906/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.1360 - val_loss: 1.0967\n",
            "Epoch 3907/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6792 - val_loss: 1.5395\n",
            "Epoch 3908/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8012 - val_loss: 1.3797\n",
            "Epoch 3909/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.7089 - val_loss: 1.2506\n",
            "Epoch 3910/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.1780 - val_loss: 2.0763\n",
            "Epoch 3911/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.3657 - val_loss: 0.8569\n",
            "Epoch 3912/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8166 - val_loss: 2.3290\n",
            "Epoch 3913/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7849 - val_loss: 1.2679\n",
            "Epoch 3914/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8276 - val_loss: 1.2579\n",
            "Epoch 3915/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.1089 - val_loss: 1.0743\n",
            "Epoch 3916/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9404 - val_loss: 2.3565\n",
            "Epoch 3917/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.1514 - val_loss: 1.3504\n",
            "Epoch 3918/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.2395 - val_loss: 1.2356\n",
            "Epoch 3919/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7413 - val_loss: 0.8455\n",
            "Epoch 3920/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9053 - val_loss: 1.0463\n",
            "Epoch 3921/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9377 - val_loss: 0.9445\n",
            "Epoch 3922/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9810 - val_loss: 3.4121\n",
            "Epoch 3923/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8642 - val_loss: 0.9095\n",
            "Epoch 3924/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9588 - val_loss: 0.9993\n",
            "Epoch 3925/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8943 - val_loss: 0.9394\n",
            "Epoch 3926/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8461 - val_loss: 0.9801\n",
            "Epoch 3927/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8342 - val_loss: 1.3220\n",
            "Epoch 3928/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.3751 - val_loss: 1.4711\n",
            "Epoch 3929/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8647 - val_loss: 1.2928\n",
            "Epoch 3930/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.1780 - val_loss: 1.2083\n",
            "Epoch 3931/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0765 - val_loss: 0.9400\n",
            "Epoch 3932/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9700 - val_loss: 2.2221\n",
            "Epoch 3933/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.2330 - val_loss: 1.6915\n",
            "Epoch 3934/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8386 - val_loss: 1.5221\n",
            "Epoch 3935/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.2789 - val_loss: 1.8604\n",
            "Epoch 3936/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8581 - val_loss: 0.9562\n",
            "Epoch 3937/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0604 - val_loss: 0.9308\n",
            "Epoch 3938/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8415 - val_loss: 2.2679\n",
            "Epoch 3939/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7503 - val_loss: 0.7537\n",
            "Epoch 3940/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.2866 - val_loss: 1.8317\n",
            "Epoch 3941/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7315 - val_loss: 1.6513\n",
            "Epoch 3942/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9282 - val_loss: 1.0077\n",
            "Epoch 3943/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0025 - val_loss: 1.0450\n",
            "Epoch 3944/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7142 - val_loss: 0.8900\n",
            "Epoch 3945/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9346 - val_loss: 0.7243\n",
            "Epoch 3946/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7024 - val_loss: 1.0540\n",
            "Epoch 3947/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8604 - val_loss: 1.5260\n",
            "Epoch 3948/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7767 - val_loss: 1.7011\n",
            "Epoch 3949/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9172 - val_loss: 1.0525\n",
            "Epoch 3950/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8525 - val_loss: 0.8905\n",
            "Epoch 3951/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.9393 - val_loss: 1.5976\n",
            "Epoch 3952/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.1984 - val_loss: 1.1075\n",
            "Epoch 3953/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8605 - val_loss: 2.6011\n",
            "Epoch 3954/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8235 - val_loss: 1.4533\n",
            "Epoch 3955/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8925 - val_loss: 0.9717\n",
            "Epoch 3956/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.6844 - val_loss: 1.4667\n",
            "Epoch 3957/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7129 - val_loss: 2.5177\n",
            "Epoch 3958/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.1690 - val_loss: 1.7015\n",
            "Epoch 3959/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7205 - val_loss: 1.0879\n",
            "Epoch 3960/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.2944 - val_loss: 1.1286\n",
            "Epoch 3961/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0739 - val_loss: 1.1400\n",
            "Epoch 3962/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6847 - val_loss: 2.7486\n",
            "Epoch 3963/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2.5119 - val_loss: 1.6466\n",
            "Epoch 3964/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.2010 - val_loss: 3.9668\n",
            "Epoch 3965/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7829 - val_loss: 0.7632\n",
            "Epoch 3966/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.6471 - val_loss: 2.7212\n",
            "Epoch 3967/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8711 - val_loss: 2.0579\n",
            "Epoch 3968/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9273 - val_loss: 4.3376\n",
            "Epoch 3969/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9257 - val_loss: 1.0427\n",
            "Epoch 3970/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0042 - val_loss: 1.6172\n",
            "Epoch 3971/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.1851 - val_loss: 1.0722\n",
            "Epoch 3972/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7808 - val_loss: 2.7087\n",
            "Epoch 3973/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0036 - val_loss: 2.0308\n",
            "Epoch 3974/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8288 - val_loss: 1.0607\n",
            "Epoch 3975/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.1738 - val_loss: 1.7216\n",
            "Epoch 3976/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.1016 - val_loss: 0.9191\n",
            "Epoch 3977/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9848 - val_loss: 1.2936\n",
            "Epoch 3978/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.5808 - val_loss: 1.2306\n",
            "Epoch 3979/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7564 - val_loss: 1.4156\n",
            "Epoch 3980/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8165 - val_loss: 3.2160\n",
            "Epoch 3981/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9038 - val_loss: 1.5378\n",
            "Epoch 3982/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7312 - val_loss: 0.9430\n",
            "Epoch 3983/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8113 - val_loss: 1.2548\n",
            "Epoch 3984/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.5796 - val_loss: 1.4005\n",
            "Epoch 3985/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0349 - val_loss: 1.9594\n",
            "Epoch 3986/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7385 - val_loss: 1.0824\n",
            "Epoch 3987/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2.2356 - val_loss: 0.9109\n",
            "Epoch 3988/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9860 - val_loss: 1.4639\n",
            "Epoch 3989/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9572 - val_loss: 1.9279\n",
            "Epoch 3990/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.7098 - val_loss: 1.5939\n",
            "Epoch 3991/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.0930 - val_loss: 1.1820\n",
            "Epoch 3992/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7711 - val_loss: 1.2454\n",
            "Epoch 3993/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0016 - val_loss: 2.1249\n",
            "Epoch 3994/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.7183 - val_loss: 0.9232\n",
            "Epoch 3995/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7956 - val_loss: 1.3475\n",
            "Epoch 3996/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9757 - val_loss: 2.0602\n",
            "Epoch 3997/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8044 - val_loss: 1.3902\n",
            "Epoch 3998/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8636 - val_loss: 1.0212\n",
            "Epoch 3999/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6117 - val_loss: 1.3895\n",
            "Epoch 4000/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6718 - val_loss: 1.3995\n",
            "Epoch 4001/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6889 - val_loss: 1.0538\n",
            "Epoch 4002/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8781 - val_loss: 2.6286\n",
            "Epoch 4003/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8057 - val_loss: 2.0688\n",
            "Epoch 4004/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7064 - val_loss: 3.0464\n",
            "Epoch 4005/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0383 - val_loss: 1.2235\n",
            "Epoch 4006/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.1877 - val_loss: 1.4154\n",
            "Epoch 4007/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.8495 - val_loss: 1.4283\n",
            "Epoch 4008/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9570 - val_loss: 1.4677\n",
            "Epoch 4009/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.1609 - val_loss: 0.9678\n",
            "Epoch 4010/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9644 - val_loss: 1.0326\n",
            "Epoch 4011/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8738 - val_loss: 1.4240\n",
            "Epoch 4012/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0461 - val_loss: 0.9934\n",
            "Epoch 4013/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8404 - val_loss: 1.3884\n",
            "Epoch 4014/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7661 - val_loss: 1.1596\n",
            "Epoch 4015/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9336 - val_loss: 1.5282\n",
            "Epoch 4016/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9485 - val_loss: 2.0206\n",
            "Epoch 4017/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7821 - val_loss: 0.7517\n",
            "Epoch 4018/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0288 - val_loss: 1.1246\n",
            "Epoch 4019/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9274 - val_loss: 1.4127\n",
            "Epoch 4020/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8623 - val_loss: 1.3244\n",
            "Epoch 4021/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9538 - val_loss: 1.1675\n",
            "Epoch 4022/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9205 - val_loss: 3.2585\n",
            "Epoch 4023/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7242 - val_loss: 1.2723\n",
            "Epoch 4024/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8331 - val_loss: 1.2946\n",
            "Epoch 4025/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9471 - val_loss: 1.6953\n",
            "Epoch 4026/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8628 - val_loss: 1.2578\n",
            "Epoch 4027/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7556 - val_loss: 0.9128\n",
            "Epoch 4028/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8290 - val_loss: 0.8362\n",
            "Epoch 4029/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7542 - val_loss: 1.4938\n",
            "Epoch 4030/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8096 - val_loss: 1.0676\n",
            "Epoch 4031/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9099 - val_loss: 1.2209\n",
            "Epoch 4032/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7492 - val_loss: 0.8523\n",
            "Epoch 4033/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8903 - val_loss: 3.9264\n",
            "Epoch 4034/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8391 - val_loss: 1.3587\n",
            "Epoch 4035/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.3614 - val_loss: 1.4677\n",
            "Epoch 4036/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.6470 - val_loss: 1.7580\n",
            "Epoch 4037/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9126 - val_loss: 1.5930\n",
            "Epoch 4038/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9373 - val_loss: 2.4392\n",
            "Epoch 4039/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7942 - val_loss: 2.0496\n",
            "Epoch 4040/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.7540 - val_loss: 2.4256\n",
            "Epoch 4041/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0612 - val_loss: 2.0888\n",
            "Epoch 4042/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.8367 - val_loss: 1.8830\n",
            "Epoch 4043/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0606 - val_loss: 1.2861\n",
            "Epoch 4044/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9235 - val_loss: 1.4149\n",
            "Epoch 4045/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.2963 - val_loss: 0.9348\n",
            "Epoch 4046/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7149 - val_loss: 1.0636\n",
            "Epoch 4047/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8836 - val_loss: 1.4995\n",
            "Epoch 4048/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8455 - val_loss: 1.2779\n",
            "Epoch 4049/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0360 - val_loss: 1.2268\n",
            "Epoch 4050/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7645 - val_loss: 1.2786\n",
            "Epoch 4051/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.1468 - val_loss: 3.2190\n",
            "Epoch 4052/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8854 - val_loss: 3.7528\n",
            "Epoch 4053/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7723 - val_loss: 1.7011\n",
            "Epoch 4054/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9597 - val_loss: 1.0972\n",
            "Epoch 4055/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0664 - val_loss: 1.6933\n",
            "Epoch 4056/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.2179 - val_loss: 1.3160\n",
            "Epoch 4057/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7561 - val_loss: 4.7218\n",
            "Epoch 4058/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7596 - val_loss: 0.9654\n",
            "Epoch 4059/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7384 - val_loss: 1.1030\n",
            "Epoch 4060/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.4257 - val_loss: 0.9020\n",
            "Epoch 4061/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0963 - val_loss: 1.3414\n",
            "Epoch 4062/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.6319 - val_loss: 0.9442\n",
            "Epoch 4063/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7530 - val_loss: 1.7039\n",
            "Epoch 4064/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9084 - val_loss: 1.7969\n",
            "Epoch 4065/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0567 - val_loss: 1.4051\n",
            "Epoch 4066/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7094 - val_loss: 1.3624\n",
            "Epoch 4067/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0141 - val_loss: 1.0996\n",
            "Epoch 4068/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.1661 - val_loss: 1.1316\n",
            "Epoch 4069/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6800 - val_loss: 1.0490\n",
            "Epoch 4070/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9649 - val_loss: 0.7536\n",
            "Epoch 4071/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0986 - val_loss: 2.4465\n",
            "Epoch 4072/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7209 - val_loss: 1.3342\n",
            "Epoch 4073/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8277 - val_loss: 1.0590\n",
            "Epoch 4074/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9739 - val_loss: 2.3519\n",
            "Epoch 4075/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0442 - val_loss: 1.5443\n",
            "Epoch 4076/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6691 - val_loss: 1.2775\n",
            "Epoch 4077/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8276 - val_loss: 4.1052\n",
            "Epoch 4078/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6305 - val_loss: 1.0485\n",
            "Epoch 4079/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.3581 - val_loss: 1.3322\n",
            "Epoch 4080/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.2626 - val_loss: 1.2105\n",
            "Epoch 4081/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9139 - val_loss: 1.0265\n",
            "Epoch 4082/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8785 - val_loss: 1.6042\n",
            "Epoch 4083/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7225 - val_loss: 1.0711\n",
            "Epoch 4084/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8879 - val_loss: 1.4151\n",
            "Epoch 4085/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8524 - val_loss: 0.9181\n",
            "Epoch 4086/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7914 - val_loss: 1.4782\n",
            "Epoch 4087/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8852 - val_loss: 1.4333\n",
            "Epoch 4088/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9297 - val_loss: 1.3441\n",
            "Epoch 4089/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8223 - val_loss: 1.0597\n",
            "Epoch 4090/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0295 - val_loss: 1.4290\n",
            "Epoch 4091/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2.3037 - val_loss: 1.4123\n",
            "Epoch 4092/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9444 - val_loss: 1.2087\n",
            "Epoch 4093/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0672 - val_loss: 1.4285\n",
            "Epoch 4094/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6910 - val_loss: 1.1026\n",
            "Epoch 4095/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8559 - val_loss: 1.7729\n",
            "Epoch 4096/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6454 - val_loss: 1.1932\n",
            "Epoch 4097/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8387 - val_loss: 1.4306\n",
            "Epoch 4098/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7212 - val_loss: 1.0887\n",
            "Epoch 4099/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7249 - val_loss: 1.6028\n",
            "Epoch 4100/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8456 - val_loss: 1.6578\n",
            "Epoch 4101/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7113 - val_loss: 2.1883\n",
            "Epoch 4102/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8073 - val_loss: 1.1743\n",
            "Epoch 4103/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.1758 - val_loss: 0.9836\n",
            "Epoch 4104/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8573 - val_loss: 2.5415\n",
            "Epoch 4105/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.2286 - val_loss: 1.3270\n",
            "Epoch 4106/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8444 - val_loss: 1.7479\n",
            "Epoch 4107/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9876 - val_loss: 1.0342\n",
            "Epoch 4108/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0378 - val_loss: 1.0109\n",
            "Epoch 4109/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9059 - val_loss: 1.1303\n",
            "Epoch 4110/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8358 - val_loss: 1.7858\n",
            "Epoch 4111/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9304 - val_loss: 1.3834\n",
            "Epoch 4112/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7671 - val_loss: 2.2125\n",
            "Epoch 4113/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0380 - val_loss: 1.6293\n",
            "Epoch 4114/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0787 - val_loss: 1.0536\n",
            "Epoch 4115/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0905 - val_loss: 0.6576\n",
            "Epoch 4116/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9885 - val_loss: 2.4324\n",
            "Epoch 4117/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.1325 - val_loss: 1.0673\n",
            "Epoch 4118/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9999 - val_loss: 1.2781\n",
            "Epoch 4119/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9644 - val_loss: 3.7063\n",
            "Epoch 4120/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7823 - val_loss: 2.2734\n",
            "Epoch 4121/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7892 - val_loss: 1.0192\n",
            "Epoch 4122/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0868 - val_loss: 1.4071\n",
            "Epoch 4123/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0923 - val_loss: 1.1502\n",
            "Epoch 4124/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0415 - val_loss: 1.1315\n",
            "Epoch 4125/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9795 - val_loss: 0.7662\n",
            "Epoch 4126/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.3379 - val_loss: 1.2464\n",
            "Epoch 4127/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0684 - val_loss: 0.8230\n",
            "Epoch 4128/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9320 - val_loss: 1.0000\n",
            "Epoch 4129/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9762 - val_loss: 1.6048\n",
            "Epoch 4130/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6959 - val_loss: 1.2887\n",
            "Epoch 4131/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9206 - val_loss: 1.2035\n",
            "Epoch 4132/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9685 - val_loss: 1.0756\n",
            "Epoch 4133/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0089 - val_loss: 2.5811\n",
            "Epoch 4134/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0649 - val_loss: 1.4048\n",
            "Epoch 4135/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0992 - val_loss: 1.3539\n",
            "Epoch 4136/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0059 - val_loss: 1.4326\n",
            "Epoch 4137/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9524 - val_loss: 1.3485\n",
            "Epoch 4138/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.2007 - val_loss: 1.0214\n",
            "Epoch 4139/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8299 - val_loss: 1.8819\n",
            "Epoch 4140/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.2100 - val_loss: 1.1474\n",
            "Epoch 4141/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0694 - val_loss: 0.9835\n",
            "Epoch 4142/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9299 - val_loss: 1.2262\n",
            "Epoch 4143/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8884 - val_loss: 3.0316\n",
            "Epoch 4144/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7685 - val_loss: 1.1445\n",
            "Epoch 4145/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.1831 - val_loss: 1.4826\n",
            "Epoch 4146/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7896 - val_loss: 1.7698\n",
            "Epoch 4147/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6532 - val_loss: 1.3704\n",
            "Epoch 4148/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8734 - val_loss: 0.9111\n",
            "Epoch 4149/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9859 - val_loss: 1.8816\n",
            "Epoch 4150/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 11.3848 - val_loss: 1.2429\n",
            "Epoch 4151/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7802 - val_loss: 1.3203\n",
            "Epoch 4152/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8270 - val_loss: 1.2424\n",
            "Epoch 4153/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8935 - val_loss: 1.2089\n",
            "Epoch 4154/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7534 - val_loss: 1.8106\n",
            "Epoch 4155/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7597 - val_loss: 0.7975\n",
            "Epoch 4156/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.2177 - val_loss: 2.0375\n",
            "Epoch 4157/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0128 - val_loss: 1.4796\n",
            "Epoch 4158/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9018 - val_loss: 1.2224\n",
            "Epoch 4159/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7168 - val_loss: 1.3693\n",
            "Epoch 4160/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7436 - val_loss: 1.0120\n",
            "Epoch 4161/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9659 - val_loss: 2.1530\n",
            "Epoch 4162/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7310 - val_loss: 2.1918\n",
            "Epoch 4163/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8377 - val_loss: 1.7273\n",
            "Epoch 4164/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7500 - val_loss: 1.9389\n",
            "Epoch 4165/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8684 - val_loss: 0.8984\n",
            "Epoch 4166/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9895 - val_loss: 3.6500\n",
            "Epoch 4167/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0221 - val_loss: 1.0306\n",
            "Epoch 4168/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8517 - val_loss: 0.9772\n",
            "Epoch 4169/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.1556 - val_loss: 1.2291\n",
            "Epoch 4170/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7313 - val_loss: 1.5120\n",
            "Epoch 4171/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2.7087 - val_loss: 0.8872\n",
            "Epoch 4172/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8988 - val_loss: 1.9392\n",
            "Epoch 4173/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6881 - val_loss: 1.7867\n",
            "Epoch 4174/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9595 - val_loss: 2.9461\n",
            "Epoch 4175/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6969 - val_loss: 2.0487\n",
            "Epoch 4176/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8682 - val_loss: 0.7577\n",
            "Epoch 4177/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9690 - val_loss: 2.4852\n",
            "Epoch 4178/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8762 - val_loss: 1.1140\n",
            "Epoch 4179/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8106 - val_loss: 1.0686\n",
            "Epoch 4180/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7003 - val_loss: 1.2275\n",
            "Epoch 4181/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7506 - val_loss: 1.3838\n",
            "Epoch 4182/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.2461 - val_loss: 2.7372\n",
            "Epoch 4183/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7598 - val_loss: 1.6080\n",
            "Epoch 4184/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8621 - val_loss: 1.4838\n",
            "Epoch 4185/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8364 - val_loss: 1.5946\n",
            "Epoch 4186/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8222 - val_loss: 2.8184\n",
            "Epoch 4187/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.5134 - val_loss: 1.0724\n",
            "Epoch 4188/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9807 - val_loss: 1.4518\n",
            "Epoch 4189/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8166 - val_loss: 2.6954\n",
            "Epoch 4190/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9031 - val_loss: 1.2977\n",
            "Epoch 4191/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8963 - val_loss: 1.2693\n",
            "Epoch 4192/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.7492 - val_loss: 2.5046\n",
            "Epoch 4193/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8603 - val_loss: 1.1904\n",
            "Epoch 4194/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7796 - val_loss: 1.0210\n",
            "Epoch 4195/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8020 - val_loss: 1.5010\n",
            "Epoch 4196/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9837 - val_loss: 1.8975\n",
            "Epoch 4197/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0619 - val_loss: 0.8604\n",
            "Epoch 4198/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6950 - val_loss: 2.5503\n",
            "Epoch 4199/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9086 - val_loss: 1.4345\n",
            "Epoch 4200/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0301 - val_loss: 1.5717\n",
            "Epoch 4201/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9850 - val_loss: 1.5058\n",
            "Epoch 4202/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9297 - val_loss: 1.4794\n",
            "Epoch 4203/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8770 - val_loss: 3.1588\n",
            "Epoch 4204/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8179 - val_loss: 1.0520\n",
            "Epoch 4205/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9141 - val_loss: 1.6536\n",
            "Epoch 4206/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.1104 - val_loss: 1.1206\n",
            "Epoch 4207/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0582 - val_loss: 1.0488\n",
            "Epoch 4208/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8421 - val_loss: 1.2853\n",
            "Epoch 4209/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7760 - val_loss: 0.9305\n",
            "Epoch 4210/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7875 - val_loss: 1.0811\n",
            "Epoch 4211/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9861 - val_loss: 1.0404\n",
            "Epoch 4212/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8815 - val_loss: 0.9928\n",
            "Epoch 4213/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0581 - val_loss: 1.4715\n",
            "Epoch 4214/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.2279 - val_loss: 1.0360\n",
            "Epoch 4215/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7995 - val_loss: 1.1699\n",
            "Epoch 4216/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8303 - val_loss: 1.1139\n",
            "Epoch 4217/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0338 - val_loss: 0.8762\n",
            "Epoch 4218/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.1298 - val_loss: 1.0175\n",
            "Epoch 4219/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9336 - val_loss: 1.1484\n",
            "Epoch 4220/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9986 - val_loss: 1.0712\n",
            "Epoch 4221/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8386 - val_loss: 1.2475\n",
            "Epoch 4222/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9622 - val_loss: 0.8730\n",
            "Epoch 4223/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8797 - val_loss: 1.1534\n",
            "Epoch 4224/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.3728 - val_loss: 1.0464\n",
            "Epoch 4225/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7956 - val_loss: 1.7504\n",
            "Epoch 4226/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.2259 - val_loss: 1.1478\n",
            "Epoch 4227/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.2004 - val_loss: 1.3473\n",
            "Epoch 4228/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7973 - val_loss: 1.4893\n",
            "Epoch 4229/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8338 - val_loss: 1.4016\n",
            "Epoch 4230/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7402 - val_loss: 1.0292\n",
            "Epoch 4231/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9062 - val_loss: 2.9108\n",
            "Epoch 4232/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9020 - val_loss: 1.1346\n",
            "Epoch 4233/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8203 - val_loss: 1.0198\n",
            "Epoch 4234/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8293 - val_loss: 1.3847\n",
            "Epoch 4235/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9259 - val_loss: 1.1677\n",
            "Epoch 4236/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0184 - val_loss: 1.0474\n",
            "Epoch 4237/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.2278 - val_loss: 1.0108\n",
            "Epoch 4238/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0722 - val_loss: 1.3914\n",
            "Epoch 4239/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0069 - val_loss: 1.1496\n",
            "Epoch 4240/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9538 - val_loss: 1.2341\n",
            "Epoch 4241/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7154 - val_loss: 0.8743\n",
            "Epoch 4242/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6745 - val_loss: 1.1113\n",
            "Epoch 4243/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9658 - val_loss: 1.5619\n",
            "Epoch 4244/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6032 - val_loss: 1.0339\n",
            "Epoch 4245/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6720 - val_loss: 1.7893\n",
            "Epoch 4246/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8691 - val_loss: 1.5755\n",
            "Epoch 4247/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0571 - val_loss: 1.3046\n",
            "Epoch 4248/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8022 - val_loss: 2.0600\n",
            "Epoch 4249/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9477 - val_loss: 1.2866\n",
            "Epoch 4250/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0133 - val_loss: 1.0447\n",
            "Epoch 4251/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7417 - val_loss: 2.6855\n",
            "Epoch 4252/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8860 - val_loss: 0.9993\n",
            "Epoch 4253/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9717 - val_loss: 1.4568\n",
            "Epoch 4254/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7274 - val_loss: 1.0163\n",
            "Epoch 4255/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6412 - val_loss: 1.2771\n",
            "Epoch 4256/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7371 - val_loss: 1.6211\n",
            "Epoch 4257/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.1838 - val_loss: 2.1202\n",
            "Epoch 4258/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.2788 - val_loss: 1.2848\n",
            "Epoch 4259/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8221 - val_loss: 1.3685\n",
            "Epoch 4260/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7041 - val_loss: 10.0218\n",
            "Epoch 4261/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8769 - val_loss: 1.2708\n",
            "Epoch 4262/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8597 - val_loss: 1.0304\n",
            "Epoch 4263/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9939 - val_loss: 1.7653\n",
            "Epoch 4264/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7480 - val_loss: 1.3208\n",
            "Epoch 4265/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8958 - val_loss: 1.5269\n",
            "Epoch 4266/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9923 - val_loss: 2.2502\n",
            "Epoch 4267/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0057 - val_loss: 2.4810\n",
            "Epoch 4268/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7703 - val_loss: 0.9463\n",
            "Epoch 4269/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.1073 - val_loss: 1.3111\n",
            "Epoch 4270/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8664 - val_loss: 1.4576\n",
            "Epoch 4271/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7818 - val_loss: 2.1990\n",
            "Epoch 4272/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7085 - val_loss: 1.3067\n",
            "Epoch 4273/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7166 - val_loss: 1.0525\n",
            "Epoch 4274/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9800 - val_loss: 1.2490\n",
            "Epoch 4275/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0510 - val_loss: 1.2088\n",
            "Epoch 4276/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6947 - val_loss: 1.6017\n",
            "Epoch 4277/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9784 - val_loss: 1.1874\n",
            "Epoch 4278/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.6505 - val_loss: 1.3638\n",
            "Epoch 4279/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9940 - val_loss: 1.3311\n",
            "Epoch 4280/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0506 - val_loss: 1.0988\n",
            "Epoch 4281/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.1935 - val_loss: 1.1540\n",
            "Epoch 4282/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7888 - val_loss: 1.2987\n",
            "Epoch 4283/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9186 - val_loss: 0.9619\n",
            "Epoch 4284/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6940 - val_loss: 1.3579\n",
            "Epoch 4285/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0080 - val_loss: 0.8910\n",
            "Epoch 4286/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8432 - val_loss: 1.3724\n",
            "Epoch 4287/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9646 - val_loss: 1.6116\n",
            "Epoch 4288/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.1458 - val_loss: 2.1081\n",
            "Epoch 4289/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5795 - val_loss: 2.5492\n",
            "Epoch 4290/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7453 - val_loss: 1.3555\n",
            "Epoch 4291/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8298 - val_loss: 1.4887\n",
            "Epoch 4292/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8681 - val_loss: 1.5693\n",
            "Epoch 4293/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7167 - val_loss: 3.9111\n",
            "Epoch 4294/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8456 - val_loss: 2.1662\n",
            "Epoch 4295/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9430 - val_loss: 0.8759\n",
            "Epoch 4296/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9893 - val_loss: 1.7484\n",
            "Epoch 4297/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8138 - val_loss: 3.0333\n",
            "Epoch 4298/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7411 - val_loss: 1.1750\n",
            "Epoch 4299/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9370 - val_loss: 1.1054\n",
            "Epoch 4300/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7991 - val_loss: 1.2695\n",
            "Epoch 4301/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9433 - val_loss: 1.0478\n",
            "Epoch 4302/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7428 - val_loss: 1.1305\n",
            "Epoch 4303/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.2575 - val_loss: 1.5472\n",
            "Epoch 4304/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0303 - val_loss: 0.9253\n",
            "Epoch 4305/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7273 - val_loss: 0.9090\n",
            "Epoch 4306/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.2445 - val_loss: 1.5600\n",
            "Epoch 4307/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6291 - val_loss: 0.9324\n",
            "Epoch 4308/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.2413 - val_loss: 1.0112\n",
            "Epoch 4309/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9542 - val_loss: 1.6458\n",
            "Epoch 4310/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8588 - val_loss: 1.1638\n",
            "Epoch 4311/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8276 - val_loss: 3.3472\n",
            "Epoch 4312/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.2069 - val_loss: 0.9907\n",
            "Epoch 4313/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0504 - val_loss: 1.0774\n",
            "Epoch 4314/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7381 - val_loss: 1.1891\n",
            "Epoch 4315/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7341 - val_loss: 0.9723\n",
            "Epoch 4316/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0504 - val_loss: 1.3053\n",
            "Epoch 4317/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9461 - val_loss: 1.2071\n",
            "Epoch 4318/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8543 - val_loss: 0.9648\n",
            "Epoch 4319/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7686 - val_loss: 0.9799\n",
            "Epoch 4320/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8473 - val_loss: 1.9121\n",
            "Epoch 4321/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8583 - val_loss: 1.3783\n",
            "Epoch 4322/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.1475 - val_loss: 1.1983\n",
            "Epoch 4323/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8088 - val_loss: 1.5447\n",
            "Epoch 4324/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0421 - val_loss: 1.1133\n",
            "Epoch 4325/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0640 - val_loss: 1.4487\n",
            "Epoch 4326/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6932 - val_loss: 1.1252\n",
            "Epoch 4327/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.1683 - val_loss: 0.7763\n",
            "Epoch 4328/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8938 - val_loss: 1.3621\n",
            "Epoch 4329/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8013 - val_loss: 0.9407\n",
            "Epoch 4330/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8824 - val_loss: 4.3171\n",
            "Epoch 4331/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7960 - val_loss: 1.3573\n",
            "Epoch 4332/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.2778 - val_loss: 1.4059\n",
            "Epoch 4333/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.1919 - val_loss: 1.1442\n",
            "Epoch 4334/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9349 - val_loss: 1.7659\n",
            "Epoch 4335/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7770 - val_loss: 1.5937\n",
            "Epoch 4336/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9484 - val_loss: 1.8026\n",
            "Epoch 4337/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0772 - val_loss: 1.0355\n",
            "Epoch 4338/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0002 - val_loss: 1.1160\n",
            "Epoch 4339/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9183 - val_loss: 1.8094\n",
            "Epoch 4340/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8673 - val_loss: 0.8193\n",
            "Epoch 4341/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0712 - val_loss: 0.9536\n",
            "Epoch 4342/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8598 - val_loss: 1.3653\n",
            "Epoch 4343/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0330 - val_loss: 0.9930\n",
            "Epoch 4344/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7302 - val_loss: 1.7943\n",
            "Epoch 4345/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7830 - val_loss: 2.0261\n",
            "Epoch 4346/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0957 - val_loss: 1.1487\n",
            "Epoch 4347/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0485 - val_loss: 4.8778\n",
            "Epoch 4348/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8563 - val_loss: 1.4987\n",
            "Epoch 4349/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8996 - val_loss: 1.5896\n",
            "Epoch 4350/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8474 - val_loss: 1.1358\n",
            "Epoch 4351/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7778 - val_loss: 1.4598\n",
            "Epoch 4352/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.3795 - val_loss: 1.1948\n",
            "Epoch 4353/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0202 - val_loss: 1.7717\n",
            "Epoch 4354/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9143 - val_loss: 1.5081\n",
            "Epoch 4355/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8133 - val_loss: 2.0523\n",
            "Epoch 4356/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9348 - val_loss: 1.0228\n",
            "Epoch 4357/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7456 - val_loss: 1.5413\n",
            "Epoch 4358/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8467 - val_loss: 1.5343\n",
            "Epoch 4359/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7715 - val_loss: 0.9121\n",
            "Epoch 4360/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9053 - val_loss: 1.4569\n",
            "Epoch 4361/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0572 - val_loss: 0.9538\n",
            "Epoch 4362/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.1173 - val_loss: 1.1557\n",
            "Epoch 4363/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0048 - val_loss: 1.5101\n",
            "Epoch 4364/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.5534 - val_loss: 1.0402\n",
            "Epoch 4365/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9629 - val_loss: 0.8568\n",
            "Epoch 4366/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9198 - val_loss: 1.1551\n",
            "Epoch 4367/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.2925 - val_loss: 1.3433\n",
            "Epoch 4368/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8817 - val_loss: 1.0423\n",
            "Epoch 4369/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8003 - val_loss: 1.2390\n",
            "Epoch 4370/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8533 - val_loss: 3.0552\n",
            "Epoch 4371/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8124 - val_loss: 1.7228\n",
            "Epoch 4372/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6862 - val_loss: 1.7073\n",
            "Epoch 4373/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.1300 - val_loss: 3.3632\n",
            "Epoch 4374/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8307 - val_loss: 1.2370\n",
            "Epoch 4375/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7470 - val_loss: 0.8661\n",
            "Epoch 4376/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.2198 - val_loss: 0.9026\n",
            "Epoch 4377/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8815 - val_loss: 1.7903\n",
            "Epoch 4378/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8719 - val_loss: 1.6958\n",
            "Epoch 4379/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8053 - val_loss: 1.5018\n",
            "Epoch 4380/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8289 - val_loss: 1.3984\n",
            "Epoch 4381/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.4605 - val_loss: 2.2252\n",
            "Epoch 4382/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7973 - val_loss: 1.0850\n",
            "Epoch 4383/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.2203 - val_loss: 1.2686\n",
            "Epoch 4384/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9164 - val_loss: 0.9541\n",
            "Epoch 4385/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8789 - val_loss: 0.8328\n",
            "Epoch 4386/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0074 - val_loss: 1.1879\n",
            "Epoch 4387/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8611 - val_loss: 0.9782\n",
            "Epoch 4388/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.7917 - val_loss: 2.3206\n",
            "Epoch 4389/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.3399 - val_loss: 1.1515\n",
            "Epoch 4390/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8428 - val_loss: 1.5020\n",
            "Epoch 4391/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9334 - val_loss: 1.1181\n",
            "Epoch 4392/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.5354 - val_loss: 1.5163\n",
            "Epoch 4393/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.1263 - val_loss: 0.8039\n",
            "Epoch 4394/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7614 - val_loss: 1.2897\n",
            "Epoch 4395/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9414 - val_loss: 2.9665\n",
            "Epoch 4396/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7300 - val_loss: 0.8725\n",
            "Epoch 4397/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9497 - val_loss: 1.3322\n",
            "Epoch 4398/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0911 - val_loss: 1.0364\n",
            "Epoch 4399/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9386 - val_loss: 1.5453\n",
            "Epoch 4400/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6907 - val_loss: 1.5607\n",
            "Epoch 4401/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9192 - val_loss: 1.2047\n",
            "Epoch 4402/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.3572 - val_loss: 1.1598\n",
            "Epoch 4403/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9346 - val_loss: 4.6915\n",
            "Epoch 4404/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7432 - val_loss: 4.1164\n",
            "Epoch 4405/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2.1652 - val_loss: 0.9063\n",
            "Epoch 4406/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9885 - val_loss: 1.2948\n",
            "Epoch 4407/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.1911 - val_loss: 1.2789\n",
            "Epoch 4408/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8767 - val_loss: 1.0438\n",
            "Epoch 4409/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8749 - val_loss: 1.2002\n",
            "Epoch 4410/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7723 - val_loss: 1.8583\n",
            "Epoch 4411/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.1778 - val_loss: 1.2647\n",
            "Epoch 4412/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9259 - val_loss: 1.2907\n",
            "Epoch 4413/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0238 - val_loss: 1.2792\n",
            "Epoch 4414/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8028 - val_loss: 1.5704\n",
            "Epoch 4415/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7191 - val_loss: 0.6558\n",
            "Epoch 4416/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.3947 - val_loss: 1.3931\n",
            "Epoch 4417/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2.2551 - val_loss: 1.0252\n",
            "Epoch 4418/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0116 - val_loss: 1.5265\n",
            "Epoch 4419/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8405 - val_loss: 1.1250\n",
            "Epoch 4420/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9645 - val_loss: 1.0324\n",
            "Epoch 4421/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8732 - val_loss: 2.4494\n",
            "Epoch 4422/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8312 - val_loss: 1.3941\n",
            "Epoch 4423/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8721 - val_loss: 1.1407\n",
            "Epoch 4424/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.3398 - val_loss: 0.5859\n",
            "Epoch 4425/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6097 - val_loss: 2.0846\n",
            "Epoch 4426/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.1260 - val_loss: 1.1058\n",
            "Epoch 4427/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9628 - val_loss: 1.1776\n",
            "Epoch 4428/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6753 - val_loss: 0.9918\n",
            "Epoch 4429/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.3038 - val_loss: 2.6018\n",
            "Epoch 4430/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7658 - val_loss: 1.0049\n",
            "Epoch 4431/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0527 - val_loss: 1.7526\n",
            "Epoch 4432/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8796 - val_loss: 1.2629\n",
            "Epoch 4433/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7827 - val_loss: 1.0850\n",
            "Epoch 4434/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0310 - val_loss: 1.1637\n",
            "Epoch 4435/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.1032 - val_loss: 0.7374\n",
            "Epoch 4436/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8302 - val_loss: 1.2840\n",
            "Epoch 4437/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0890 - val_loss: 6.9007\n",
            "Epoch 4438/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.1308 - val_loss: 1.4149\n",
            "Epoch 4439/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0947 - val_loss: 0.9402\n",
            "Epoch 4440/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8097 - val_loss: 1.6069\n",
            "Epoch 4441/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0340 - val_loss: 1.8296\n",
            "Epoch 4442/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.1280 - val_loss: 0.9777\n",
            "Epoch 4443/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6977 - val_loss: 1.1345\n",
            "Epoch 4444/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.1215 - val_loss: 1.1083\n",
            "Epoch 4445/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.5510 - val_loss: 1.2783\n",
            "Epoch 4446/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0666 - val_loss: 2.0109\n",
            "Epoch 4447/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.5208 - val_loss: 1.1497\n",
            "Epoch 4448/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0633 - val_loss: 1.8524\n",
            "Epoch 4449/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7230 - val_loss: 2.1206\n",
            "Epoch 4450/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0268 - val_loss: 0.9409\n",
            "Epoch 4451/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7425 - val_loss: 2.0832\n",
            "Epoch 4452/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7484 - val_loss: 1.1787\n",
            "Epoch 4453/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.3525 - val_loss: 1.2607\n",
            "Epoch 4454/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7809 - val_loss: 1.0240\n",
            "Epoch 4455/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8790 - val_loss: 1.0153\n",
            "Epoch 4456/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9342 - val_loss: 1.2695\n",
            "Epoch 4457/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.1353 - val_loss: 1.1489\n",
            "Epoch 4458/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6730 - val_loss: 1.3570\n",
            "Epoch 4459/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8691 - val_loss: 4.5252\n",
            "Epoch 4460/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.1057 - val_loss: 1.5152\n",
            "Epoch 4461/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0229 - val_loss: 1.1663\n",
            "Epoch 4462/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8626 - val_loss: 0.8028\n",
            "Epoch 4463/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9941 - val_loss: 1.2641\n",
            "Epoch 4464/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8422 - val_loss: 1.5850\n",
            "Epoch 4465/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.1865 - val_loss: 1.2054\n",
            "Epoch 4466/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7018 - val_loss: 0.9936\n",
            "Epoch 4467/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.9643 - val_loss: 1.3389\n",
            "Epoch 4468/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8092 - val_loss: 1.0696\n",
            "Epoch 4469/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 3.2970 - val_loss: 1.1939\n",
            "Epoch 4470/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0767 - val_loss: 0.9744\n",
            "Epoch 4471/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.4254 - val_loss: 1.4683\n",
            "Epoch 4472/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.3962 - val_loss: 1.1284\n",
            "Epoch 4473/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8419 - val_loss: 1.1348\n",
            "Epoch 4474/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7999 - val_loss: 1.0027\n",
            "Epoch 4475/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0467 - val_loss: 1.1204\n",
            "Epoch 4476/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0234 - val_loss: 0.8646\n",
            "Epoch 4477/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7419 - val_loss: 2.6772\n",
            "Epoch 4478/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9924 - val_loss: 1.6194\n",
            "Epoch 4479/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9992 - val_loss: 1.1239\n",
            "Epoch 4480/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0094 - val_loss: 0.9969\n",
            "Epoch 4481/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8402 - val_loss: 1.2026\n",
            "Epoch 4482/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9949 - val_loss: 1.0681\n",
            "Epoch 4483/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8983 - val_loss: 0.8435\n",
            "Epoch 4484/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0731 - val_loss: 1.4197\n",
            "Epoch 4485/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9274 - val_loss: 0.8491\n",
            "Epoch 4486/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0716 - val_loss: 2.2573\n",
            "Epoch 4487/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6885 - val_loss: 1.7666\n",
            "Epoch 4488/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.2411 - val_loss: 1.0486\n",
            "Epoch 4489/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0389 - val_loss: 1.2484\n",
            "Epoch 4490/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8432 - val_loss: 1.3799\n",
            "Epoch 4491/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7079 - val_loss: 1.9722\n",
            "Epoch 4492/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7478 - val_loss: 1.1560\n",
            "Epoch 4493/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7983 - val_loss: 1.7900\n",
            "Epoch 4494/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8342 - val_loss: 1.2289\n",
            "Epoch 4495/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0386 - val_loss: 1.7896\n",
            "Epoch 4496/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8968 - val_loss: 1.0683\n",
            "Epoch 4497/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8158 - val_loss: 2.0302\n",
            "Epoch 4498/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8744 - val_loss: 1.2688\n",
            "Epoch 4499/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6545 - val_loss: 1.4621\n",
            "Epoch 4500/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8621 - val_loss: 1.7770\n",
            "Epoch 4501/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8759 - val_loss: 0.9007\n",
            "Epoch 4502/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9047 - val_loss: 1.2784\n",
            "Epoch 4503/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6147 - val_loss: 1.1517\n",
            "Epoch 4504/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7960 - val_loss: 0.8841\n",
            "Epoch 4505/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9779 - val_loss: 1.4623\n",
            "Epoch 4506/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6862 - val_loss: 0.8713\n",
            "Epoch 4507/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8274 - val_loss: 1.1905\n",
            "Epoch 4508/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2.2538 - val_loss: 1.1218\n",
            "Epoch 4509/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.0774 - val_loss: 1.7761\n",
            "Epoch 4510/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.7495 - val_loss: 1.4026\n",
            "Epoch 4511/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7596 - val_loss: 1.1862\n",
            "Epoch 4512/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0920 - val_loss: 1.2628\n",
            "Epoch 4513/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8423 - val_loss: 0.7409\n",
            "Epoch 4514/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8642 - val_loss: 1.7434\n",
            "Epoch 4515/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7833 - val_loss: 2.3295\n",
            "Epoch 4516/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0851 - val_loss: 1.5756\n",
            "Epoch 4517/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8418 - val_loss: 1.6581\n",
            "Epoch 4518/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7122 - val_loss: 0.9557\n",
            "Epoch 4519/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8610 - val_loss: 1.3046\n",
            "Epoch 4520/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.1859 - val_loss: 0.9771\n",
            "Epoch 4521/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0507 - val_loss: 1.5839\n",
            "Epoch 4522/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9030 - val_loss: 1.9004\n",
            "Epoch 4523/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9408 - val_loss: 1.4466\n",
            "Epoch 4524/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9793 - val_loss: 0.8845\n",
            "Epoch 4525/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9517 - val_loss: 1.7016\n",
            "Epoch 4526/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8085 - val_loss: 1.2306\n",
            "Epoch 4527/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7129 - val_loss: 1.0802\n",
            "Epoch 4528/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.3398 - val_loss: 1.1454\n",
            "Epoch 4529/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6427 - val_loss: 1.0915\n",
            "Epoch 4530/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7973 - val_loss: 1.1703\n",
            "Epoch 4531/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7790 - val_loss: 2.7903\n",
            "Epoch 4532/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0313 - val_loss: 4.8869\n",
            "Epoch 4533/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7426 - val_loss: 0.9237\n",
            "Epoch 4534/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8611 - val_loss: 1.3087\n",
            "Epoch 4535/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8595 - val_loss: 1.3408\n",
            "Epoch 4536/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7873 - val_loss: 3.9252\n",
            "Epoch 4537/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0813 - val_loss: 1.2647\n",
            "Epoch 4538/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8125 - val_loss: 1.0476\n",
            "Epoch 4539/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8260 - val_loss: 1.0087\n",
            "Epoch 4540/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0396 - val_loss: 1.1588\n",
            "Epoch 4541/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9743 - val_loss: 1.1067\n",
            "Epoch 4542/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7519 - val_loss: 1.1492\n",
            "Epoch 4543/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.1164 - val_loss: 1.6105\n",
            "Epoch 4544/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7975 - val_loss: 1.4972\n",
            "Epoch 4545/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7273 - val_loss: 1.2745\n",
            "Epoch 4546/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9345 - val_loss: 1.6880\n",
            "Epoch 4547/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8155 - val_loss: 1.1898\n",
            "Epoch 4548/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8971 - val_loss: 1.1949\n",
            "Epoch 4549/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9559 - val_loss: 0.8644\n",
            "Epoch 4550/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7914 - val_loss: 1.7609\n",
            "Epoch 4551/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7450 - val_loss: 1.0648\n",
            "Epoch 4552/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8303 - val_loss: 1.5231\n",
            "Epoch 4553/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9878 - val_loss: 1.3335\n",
            "Epoch 4554/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8822 - val_loss: 0.9224\n",
            "Epoch 4555/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9908 - val_loss: 0.9257\n",
            "Epoch 4556/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8443 - val_loss: 1.2006\n",
            "Epoch 4557/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8561 - val_loss: 2.3839\n",
            "Epoch 4558/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0803 - val_loss: 1.3326\n",
            "Epoch 4559/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9292 - val_loss: 1.3672\n",
            "Epoch 4560/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0735 - val_loss: 0.8074\n",
            "Epoch 4561/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7552 - val_loss: 1.1949\n",
            "Epoch 4562/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7763 - val_loss: 0.9364\n",
            "Epoch 4563/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7729 - val_loss: 1.5432\n",
            "Epoch 4564/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9262 - val_loss: 1.8993\n",
            "Epoch 4565/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0508 - val_loss: 0.7851\n",
            "Epoch 4566/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0333 - val_loss: 1.4185\n",
            "Epoch 4567/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7299 - val_loss: 3.3498\n",
            "Epoch 4568/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7418 - val_loss: 1.2310\n",
            "Epoch 4569/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8488 - val_loss: 0.8251\n",
            "Epoch 4570/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7793 - val_loss: 1.2892\n",
            "Epoch 4571/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6219 - val_loss: 1.0204\n",
            "Epoch 4572/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0053 - val_loss: 1.7125\n",
            "Epoch 4573/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8860 - val_loss: 1.2482\n",
            "Epoch 4574/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7954 - val_loss: 1.1918\n",
            "Epoch 4575/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.2691 - val_loss: 0.9739\n",
            "Epoch 4576/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7990 - val_loss: 1.3189\n",
            "Epoch 4577/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7789 - val_loss: 1.3420\n",
            "Epoch 4578/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6593 - val_loss: 1.4956\n",
            "Epoch 4579/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9573 - val_loss: 0.9793\n",
            "Epoch 4580/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0338 - val_loss: 1.1373\n",
            "Epoch 4581/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9886 - val_loss: 2.8173\n",
            "Epoch 4582/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8572 - val_loss: 1.2685\n",
            "Epoch 4583/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6487 - val_loss: 1.3208\n",
            "Epoch 4584/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9078 - val_loss: 1.8825\n",
            "Epoch 4585/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8668 - val_loss: 1.2705\n",
            "Epoch 4586/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7089 - val_loss: 3.1593\n",
            "Epoch 4587/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.2208 - val_loss: 2.3916\n",
            "Epoch 4588/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0504 - val_loss: 1.7968\n",
            "Epoch 4589/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.0468 - val_loss: 1.0120\n",
            "Epoch 4590/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7727 - val_loss: 2.1499\n",
            "Epoch 4591/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7601 - val_loss: 1.4564\n",
            "Epoch 4592/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0558 - val_loss: 2.4256\n",
            "Epoch 4593/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8473 - val_loss: 1.5357\n",
            "Epoch 4594/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8509 - val_loss: 1.4331\n",
            "Epoch 4595/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8495 - val_loss: 0.9881\n",
            "Epoch 4596/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.4954 - val_loss: 1.0200\n",
            "Epoch 4597/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0127 - val_loss: 3.2387\n",
            "Epoch 4598/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6968 - val_loss: 1.4805\n",
            "Epoch 4599/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0218 - val_loss: 1.8798\n",
            "Epoch 4600/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8236 - val_loss: 1.8136\n",
            "Epoch 4601/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0975 - val_loss: 1.6027\n",
            "Epoch 4602/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7883 - val_loss: 1.4360\n",
            "Epoch 4603/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9421 - val_loss: 1.1333\n",
            "Epoch 4604/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.1883 - val_loss: 1.8890\n",
            "Epoch 4605/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9499 - val_loss: 1.2176\n",
            "Epoch 4606/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0760 - val_loss: 1.2328\n",
            "Epoch 4607/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8114 - val_loss: 3.4872\n",
            "Epoch 4608/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9696 - val_loss: 1.2697\n",
            "Epoch 4609/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8491 - val_loss: 1.6865\n",
            "Epoch 4610/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7742 - val_loss: 1.3068\n",
            "Epoch 4611/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9823 - val_loss: 1.1906\n",
            "Epoch 4612/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8156 - val_loss: 1.5777\n",
            "Epoch 4613/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.1432 - val_loss: 1.3916\n",
            "Epoch 4614/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8078 - val_loss: 1.1566\n",
            "Epoch 4615/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.6801 - val_loss: 0.7017\n",
            "Epoch 4616/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8302 - val_loss: 1.2045\n",
            "Epoch 4617/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8289 - val_loss: 1.0060\n",
            "Epoch 4618/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.1481 - val_loss: 0.8479\n",
            "Epoch 4619/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7106 - val_loss: 0.9239\n",
            "Epoch 4620/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6419 - val_loss: 1.2120\n",
            "Epoch 4621/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9202 - val_loss: 1.8991\n",
            "Epoch 4622/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8858 - val_loss: 0.9255\n",
            "Epoch 4623/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9493 - val_loss: 1.9050\n",
            "Epoch 4624/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8619 - val_loss: 0.9706\n",
            "Epoch 4625/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9111 - val_loss: 1.4272\n",
            "Epoch 4626/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8656 - val_loss: 2.5856\n",
            "Epoch 4627/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9092 - val_loss: 1.1934\n",
            "Epoch 4628/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2.5169 - val_loss: 1.2296\n",
            "Epoch 4629/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2.0239 - val_loss: 0.8756\n",
            "Epoch 4630/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.4676 - val_loss: 1.0374\n",
            "Epoch 4631/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.7959 - val_loss: 0.8697\n",
            "Epoch 4632/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9713 - val_loss: 0.7181\n",
            "Epoch 4633/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8036 - val_loss: 1.0940\n",
            "Epoch 4634/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7151 - val_loss: 1.4552\n",
            "Epoch 4635/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9211 - val_loss: 0.9393\n",
            "Epoch 4636/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7189 - val_loss: 0.8667\n",
            "Epoch 4637/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0818 - val_loss: 1.9268\n",
            "Epoch 4638/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8828 - val_loss: 0.9742\n",
            "Epoch 4639/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8322 - val_loss: 2.1374\n",
            "Epoch 4640/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7625 - val_loss: 1.5481\n",
            "Epoch 4641/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7379 - val_loss: 1.0472\n",
            "Epoch 4642/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.6842 - val_loss: 1.0835\n",
            "Epoch 4643/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9805 - val_loss: 1.6009\n",
            "Epoch 4644/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0055 - val_loss: 1.0245\n",
            "Epoch 4645/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.2350 - val_loss: 1.1393\n",
            "Epoch 4646/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6502 - val_loss: 1.0037\n",
            "Epoch 4647/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0060 - val_loss: 2.9585\n",
            "Epoch 4648/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0326 - val_loss: 0.7253\n",
            "Epoch 4649/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.1546 - val_loss: 3.5543\n",
            "Epoch 4650/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8343 - val_loss: 1.0347\n",
            "Epoch 4651/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.3824 - val_loss: 0.9009\n",
            "Epoch 4652/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9296 - val_loss: 1.6599\n",
            "Epoch 4653/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7854 - val_loss: 3.0519\n",
            "Epoch 4654/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7961 - val_loss: 1.0508\n",
            "Epoch 4655/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9408 - val_loss: 0.9370\n",
            "Epoch 4656/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7521 - val_loss: 1.5007\n",
            "Epoch 4657/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6300 - val_loss: 3.0143\n",
            "Epoch 4658/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8457 - val_loss: 1.4015\n",
            "Epoch 4659/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7919 - val_loss: 1.1581\n",
            "Epoch 4660/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8369 - val_loss: 1.2647\n",
            "Epoch 4661/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.2472 - val_loss: 1.5009\n",
            "Epoch 4662/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8104 - val_loss: 4.9048\n",
            "Epoch 4663/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0821 - val_loss: 2.9650\n",
            "Epoch 4664/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9952 - val_loss: 1.7772\n",
            "Epoch 4665/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 5.4069 - val_loss: 1.2046\n",
            "Epoch 4666/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8674 - val_loss: 1.0304\n",
            "Epoch 4667/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8697 - val_loss: 1.2080\n",
            "Epoch 4668/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9292 - val_loss: 1.1922\n",
            "Epoch 4669/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8035 - val_loss: 1.1213\n",
            "Epoch 4670/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9016 - val_loss: 2.0229\n",
            "Epoch 4671/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8535 - val_loss: 2.5186\n",
            "Epoch 4672/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8662 - val_loss: 1.4116\n",
            "Epoch 4673/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8189 - val_loss: 0.9685\n",
            "Epoch 4674/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2.3865 - val_loss: 1.5194\n",
            "Epoch 4675/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0352 - val_loss: 1.2945\n",
            "Epoch 4676/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0875 - val_loss: 1.0166\n",
            "Epoch 4677/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9070 - val_loss: 1.2304\n",
            "Epoch 4678/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0943 - val_loss: 0.9975\n",
            "Epoch 4679/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9925 - val_loss: 1.3563\n",
            "Epoch 4680/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0033 - val_loss: 1.4286\n",
            "Epoch 4681/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.4416 - val_loss: 1.6383\n",
            "Epoch 4682/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0300 - val_loss: 1.1455\n",
            "Epoch 4683/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.1361 - val_loss: 1.9625\n",
            "Epoch 4684/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8395 - val_loss: 0.7836\n",
            "Epoch 4685/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6797 - val_loss: 1.3956\n",
            "Epoch 4686/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6409 - val_loss: 1.0361\n",
            "Epoch 4687/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7084 - val_loss: 3.0866\n",
            "Epoch 4688/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9266 - val_loss: 0.9656\n",
            "Epoch 4689/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8172 - val_loss: 0.8295\n",
            "Epoch 4690/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8219 - val_loss: 1.4917\n",
            "Epoch 4691/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7836 - val_loss: 1.7118\n",
            "Epoch 4692/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9572 - val_loss: 1.8102\n",
            "Epoch 4693/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7232 - val_loss: 1.0536\n",
            "Epoch 4694/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7782 - val_loss: 1.4773\n",
            "Epoch 4695/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0992 - val_loss: 1.6390\n",
            "Epoch 4696/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9387 - val_loss: 1.1330\n",
            "Epoch 4697/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8281 - val_loss: 1.2369\n",
            "Epoch 4698/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.1407 - val_loss: 1.1582\n",
            "Epoch 4699/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7337 - val_loss: 1.1443\n",
            "Epoch 4700/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8552 - val_loss: 1.1906\n",
            "Epoch 4701/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0739 - val_loss: 1.2854\n",
            "Epoch 4702/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7544 - val_loss: 1.6896\n",
            "Epoch 4703/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0774 - val_loss: 0.8515\n",
            "Epoch 4704/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7641 - val_loss: 1.1379\n",
            "Epoch 4705/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9978 - val_loss: 1.9449\n",
            "Epoch 4706/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7363 - val_loss: 1.3799\n",
            "Epoch 4707/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6417 - val_loss: 1.1751\n",
            "Epoch 4708/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8834 - val_loss: 1.0363\n",
            "Epoch 4709/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7381 - val_loss: 0.7558\n",
            "Epoch 4710/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9141 - val_loss: 1.3114\n",
            "Epoch 4711/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0340 - val_loss: 2.3236\n",
            "Epoch 4712/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.2934 - val_loss: 1.0057\n",
            "Epoch 4713/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0556 - val_loss: 0.8656\n",
            "Epoch 4714/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8177 - val_loss: 0.9499\n",
            "Epoch 4715/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8735 - val_loss: 1.5762\n",
            "Epoch 4716/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.4054 - val_loss: 1.6488\n",
            "Epoch 4717/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8338 - val_loss: 0.6711\n",
            "Epoch 4718/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7910 - val_loss: 1.6952\n",
            "Epoch 4719/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8906 - val_loss: 1.9294\n",
            "Epoch 4720/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9824 - val_loss: 0.9472\n",
            "Epoch 4721/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8449 - val_loss: 1.3504\n",
            "Epoch 4722/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9096 - val_loss: 2.2899\n",
            "Epoch 4723/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6613 - val_loss: 1.0553\n",
            "Epoch 4724/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0398 - val_loss: 1.0592\n",
            "Epoch 4725/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7223 - val_loss: 1.0987\n",
            "Epoch 4726/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8423 - val_loss: 1.3180\n",
            "Epoch 4727/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8646 - val_loss: 1.1857\n",
            "Epoch 4728/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0813 - val_loss: 1.0742\n",
            "Epoch 4729/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7470 - val_loss: 1.9276\n",
            "Epoch 4730/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8623 - val_loss: 1.2958\n",
            "Epoch 4731/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8827 - val_loss: 1.5255\n",
            "Epoch 4732/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.1712 - val_loss: 1.2692\n",
            "Epoch 4733/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8258 - val_loss: 1.2199\n",
            "Epoch 4734/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7574 - val_loss: 1.2652\n",
            "Epoch 4735/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0578 - val_loss: 0.9728\n",
            "Epoch 4736/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8376 - val_loss: 1.0553\n",
            "Epoch 4737/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7481 - val_loss: 1.0617\n",
            "Epoch 4738/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.6979 - val_loss: 3.0465\n",
            "Epoch 4739/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9796 - val_loss: 0.9676\n",
            "Epoch 4740/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.6357 - val_loss: 1.0246\n",
            "Epoch 4741/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.1057 - val_loss: 1.2597\n",
            "Epoch 4742/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.7194 - val_loss: 1.5325\n",
            "Epoch 4743/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8140 - val_loss: 0.9521\n",
            "Epoch 4744/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8292 - val_loss: 2.5957\n",
            "Epoch 4745/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.1400 - val_loss: 1.0669\n",
            "Epoch 4746/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9092 - val_loss: 1.7679\n",
            "Epoch 4747/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7305 - val_loss: 1.1096\n",
            "Epoch 4748/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7585 - val_loss: 1.1664\n",
            "Epoch 4749/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.2049 - val_loss: 1.3194\n",
            "Epoch 4750/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8903 - val_loss: 1.4612\n",
            "Epoch 4751/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7513 - val_loss: 1.4154\n",
            "Epoch 4752/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7147 - val_loss: 1.0867\n",
            "Epoch 4753/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.1247 - val_loss: 2.2092\n",
            "Epoch 4754/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0176 - val_loss: 1.1043\n",
            "Epoch 4755/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6716 - val_loss: 1.0472\n",
            "Epoch 4756/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7326 - val_loss: 1.7086\n",
            "Epoch 4757/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0755 - val_loss: 0.9013\n",
            "Epoch 4758/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7949 - val_loss: 0.9705\n",
            "Epoch 4759/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6931 - val_loss: 1.1094\n",
            "Epoch 4760/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8563 - val_loss: 0.7719\n",
            "Epoch 4761/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.4779 - val_loss: 2.2619\n",
            "Epoch 4762/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7779 - val_loss: 0.9621\n",
            "Epoch 4763/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8931 - val_loss: 1.1076\n",
            "Epoch 4764/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0908 - val_loss: 1.1776\n",
            "Epoch 4765/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8228 - val_loss: 1.5175\n",
            "Epoch 4766/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.6528 - val_loss: 4.4607\n",
            "Epoch 4767/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9876 - val_loss: 1.2611\n",
            "Epoch 4768/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9569 - val_loss: 1.0993\n",
            "Epoch 4769/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.3122 - val_loss: 1.1809\n",
            "Epoch 4770/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.2605 - val_loss: 1.1046\n",
            "Epoch 4771/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8098 - val_loss: 1.2128\n",
            "Epoch 4772/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0602 - val_loss: 1.4216\n",
            "Epoch 4773/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.2419 - val_loss: 3.2715\n",
            "Epoch 4774/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9007 - val_loss: 1.1334\n",
            "Epoch 4775/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.6719 - val_loss: 1.6124\n",
            "Epoch 4776/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7730 - val_loss: 1.1520\n",
            "Epoch 4777/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9496 - val_loss: 1.1537\n",
            "Epoch 4778/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6940 - val_loss: 1.1087\n",
            "Epoch 4779/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7988 - val_loss: 1.3448\n",
            "Epoch 4780/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8298 - val_loss: 0.7281\n",
            "Epoch 4781/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8357 - val_loss: 1.8584\n",
            "Epoch 4782/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8396 - val_loss: 1.6257\n",
            "Epoch 4783/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.9103 - val_loss: 1.3083\n",
            "Epoch 4784/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8195 - val_loss: 2.1946\n",
            "Epoch 4785/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8548 - val_loss: 1.7029\n",
            "Epoch 4786/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9745 - val_loss: 1.1593\n",
            "Epoch 4787/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0082 - val_loss: 1.5699\n",
            "Epoch 4788/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8711 - val_loss: 0.9903\n",
            "Epoch 4789/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.2582 - val_loss: 1.6189\n",
            "Epoch 4790/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9188 - val_loss: 1.4897\n",
            "Epoch 4791/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9075 - val_loss: 1.6279\n",
            "Epoch 4792/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9895 - val_loss: 2.3993\n",
            "Epoch 4793/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9704 - val_loss: 0.8780\n",
            "Epoch 4794/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8229 - val_loss: 1.0577\n",
            "Epoch 4795/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9794 - val_loss: 0.7572\n",
            "Epoch 4796/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8695 - val_loss: 1.5703\n",
            "Epoch 4797/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.1636 - val_loss: 1.4800\n",
            "Epoch 4798/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2.1185 - val_loss: 2.1588\n",
            "Epoch 4799/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8250 - val_loss: 1.9168\n",
            "Epoch 4800/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7511 - val_loss: 1.0769\n",
            "Epoch 4801/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7253 - val_loss: 1.0819\n",
            "Epoch 4802/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.2378 - val_loss: 1.6285\n",
            "Epoch 4803/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7903 - val_loss: 1.4323\n",
            "Epoch 4804/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7067 - val_loss: 1.2857\n",
            "Epoch 4805/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.3311 - val_loss: 1.3996\n",
            "Epoch 4806/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7687 - val_loss: 1.5357\n",
            "Epoch 4807/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.3564 - val_loss: 1.3875\n",
            "Epoch 4808/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6762 - val_loss: 1.0516\n",
            "Epoch 4809/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.1800 - val_loss: 3.3112\n",
            "Epoch 4810/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8692 - val_loss: 0.8135\n",
            "Epoch 4811/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9578 - val_loss: 1.5744\n",
            "Epoch 4812/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8142 - val_loss: 1.5171\n",
            "Epoch 4813/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8254 - val_loss: 1.2056\n",
            "Epoch 4814/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8359 - val_loss: 2.2058\n",
            "Epoch 4815/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8536 - val_loss: 3.3820\n",
            "Epoch 4816/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.9019 - val_loss: 0.8169\n",
            "Epoch 4817/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8211 - val_loss: 1.2284\n",
            "Epoch 4818/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8758 - val_loss: 1.0706\n",
            "Epoch 4819/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8527 - val_loss: 1.3072\n",
            "Epoch 4820/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8162 - val_loss: 1.5346\n",
            "Epoch 4821/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8450 - val_loss: 2.0392\n",
            "Epoch 4822/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6916 - val_loss: 0.9708\n",
            "Epoch 4823/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9031 - val_loss: 1.2267\n",
            "Epoch 4824/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9024 - val_loss: 1.1885\n",
            "Epoch 4825/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.3429 - val_loss: 1.3557\n",
            "Epoch 4826/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8209 - val_loss: 0.7263\n",
            "Epoch 4827/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8149 - val_loss: 1.0925\n",
            "Epoch 4828/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8896 - val_loss: 1.1918\n",
            "Epoch 4829/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.1553 - val_loss: 1.6058\n",
            "Epoch 4830/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0168 - val_loss: 1.5810\n",
            "Epoch 4831/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9519 - val_loss: 1.3409\n",
            "Epoch 4832/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.8009 - val_loss: 0.9704\n",
            "Epoch 4833/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7161 - val_loss: 1.1146\n",
            "Epoch 4834/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.1732 - val_loss: 1.0309\n",
            "Epoch 4835/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7988 - val_loss: 2.5192\n",
            "Epoch 4836/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6770 - val_loss: 1.2016\n",
            "Epoch 4837/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.4470 - val_loss: 1.3732\n",
            "Epoch 4838/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0337 - val_loss: 1.3853\n",
            "Epoch 4839/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8774 - val_loss: 1.7766\n",
            "Epoch 4840/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.3290 - val_loss: 1.2782\n",
            "Epoch 4841/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8565 - val_loss: 1.9794\n",
            "Epoch 4842/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8734 - val_loss: 1.6338\n",
            "Epoch 4843/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.5108 - val_loss: 1.6165\n",
            "Epoch 4844/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.6180 - val_loss: 1.0205\n",
            "Epoch 4845/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8678 - val_loss: 0.9423\n",
            "Epoch 4846/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8734 - val_loss: 1.6997\n",
            "Epoch 4847/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8241 - val_loss: 1.0836\n",
            "Epoch 4848/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8214 - val_loss: 1.2512\n",
            "Epoch 4849/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0752 - val_loss: 0.9932\n",
            "Epoch 4850/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8574 - val_loss: 1.6261\n",
            "Epoch 4851/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.1816 - val_loss: 0.8943\n",
            "Epoch 4852/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6821 - val_loss: 1.0430\n",
            "Epoch 4853/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8235 - val_loss: 2.8469\n",
            "Epoch 4854/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0289 - val_loss: 0.8393\n",
            "Epoch 4855/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9604 - val_loss: 1.9390\n",
            "Epoch 4856/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9946 - val_loss: 1.1682\n",
            "Epoch 4857/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0532 - val_loss: 1.0894\n",
            "Epoch 4858/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 4.0100 - val_loss: 1.0901\n",
            "Epoch 4859/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.4920 - val_loss: 0.9878\n",
            "Epoch 4860/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9892 - val_loss: 1.7310\n",
            "Epoch 4861/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9626 - val_loss: 1.0323\n",
            "Epoch 4862/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.8739 - val_loss: 4.7866\n",
            "Epoch 4863/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8214 - val_loss: 1.0939\n",
            "Epoch 4864/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7406 - val_loss: 1.0632\n",
            "Epoch 4865/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.2240 - val_loss: 1.4715\n",
            "Epoch 4866/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8572 - val_loss: 0.8825\n",
            "Epoch 4867/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7102 - val_loss: 1.5788\n",
            "Epoch 4868/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.5947 - val_loss: 1.4937\n",
            "Epoch 4869/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8637 - val_loss: 1.3890\n",
            "Epoch 4870/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7727 - val_loss: 1.1717\n",
            "Epoch 4871/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0347 - val_loss: 1.2080\n",
            "Epoch 4872/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2.2344 - val_loss: 1.4067\n",
            "Epoch 4873/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8871 - val_loss: 0.6765\n",
            "Epoch 4874/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7129 - val_loss: 1.3609\n",
            "Epoch 4875/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8296 - val_loss: 1.8319\n",
            "Epoch 4876/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6927 - val_loss: 1.2261\n",
            "Epoch 4877/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7862 - val_loss: 0.8023\n",
            "Epoch 4878/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8635 - val_loss: 2.1860\n",
            "Epoch 4879/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.4290 - val_loss: 1.0179\n",
            "Epoch 4880/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.2356 - val_loss: 2.1353\n",
            "Epoch 4881/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7248 - val_loss: 1.4258\n",
            "Epoch 4882/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8225 - val_loss: 1.1783\n",
            "Epoch 4883/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9225 - val_loss: 3.0028\n",
            "Epoch 4884/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7565 - val_loss: 1.0446\n",
            "Epoch 4885/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9991 - val_loss: 0.9356\n",
            "Epoch 4886/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8836 - val_loss: 1.0526\n",
            "Epoch 4887/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.5055 - val_loss: 2.6551\n",
            "Epoch 4888/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0126 - val_loss: 1.0974\n",
            "Epoch 4889/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.8659 - val_loss: 0.7941\n",
            "Epoch 4890/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7968 - val_loss: 1.4472\n",
            "Epoch 4891/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8158 - val_loss: 1.1411\n",
            "Epoch 4892/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7135 - val_loss: 1.1216\n",
            "Epoch 4893/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.2377 - val_loss: 1.0896\n",
            "Epoch 4894/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.1013 - val_loss: 3.2675\n",
            "Epoch 4895/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0614 - val_loss: 1.1906\n",
            "Epoch 4896/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2.2335 - val_loss: 1.0912\n",
            "Epoch 4897/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7198 - val_loss: 0.8864\n",
            "Epoch 4898/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0842 - val_loss: 0.9191\n",
            "Epoch 4899/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7830 - val_loss: 1.0396\n",
            "Epoch 4900/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.8925 - val_loss: 1.2147\n",
            "Epoch 4901/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0812 - val_loss: 1.3054\n",
            "Epoch 4902/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9364 - val_loss: 1.0174\n",
            "Epoch 4903/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8701 - val_loss: 1.1919\n",
            "Epoch 4904/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.1612 - val_loss: 2.4322\n",
            "Epoch 4905/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0484 - val_loss: 1.3905\n",
            "Epoch 4906/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9738 - val_loss: 1.8820\n",
            "Epoch 4907/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.1503 - val_loss: 0.9850\n",
            "Epoch 4908/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0193 - val_loss: 1.4434\n",
            "Epoch 4909/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7954 - val_loss: 1.1457\n",
            "Epoch 4910/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7223 - val_loss: 2.1765\n",
            "Epoch 4911/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8786 - val_loss: 0.7630\n",
            "Epoch 4912/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7762 - val_loss: 2.4884\n",
            "Epoch 4913/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8243 - val_loss: 1.6618\n",
            "Epoch 4914/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8207 - val_loss: 3.1414\n",
            "Epoch 4915/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8935 - val_loss: 1.7523\n",
            "Epoch 4916/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7940 - val_loss: 1.7228\n",
            "Epoch 4917/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8203 - val_loss: 1.2093\n",
            "Epoch 4918/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8834 - val_loss: 1.4663\n",
            "Epoch 4919/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0927 - val_loss: 1.0979\n",
            "Epoch 4920/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8363 - val_loss: 1.0816\n",
            "Epoch 4921/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.1476 - val_loss: 1.0132\n",
            "Epoch 4922/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9171 - val_loss: 1.2795\n",
            "Epoch 4923/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6899 - val_loss: 1.0721\n",
            "Epoch 4924/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9453 - val_loss: 1.1262\n",
            "Epoch 4925/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6766 - val_loss: 1.9677\n",
            "Epoch 4926/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0991 - val_loss: 1.1886\n",
            "Epoch 4927/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0784 - val_loss: 0.9724\n",
            "Epoch 4928/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9194 - val_loss: 1.1947\n",
            "Epoch 4929/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.1218 - val_loss: 1.0796\n",
            "Epoch 4930/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8650 - val_loss: 0.7808\n",
            "Epoch 4931/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8800 - val_loss: 1.4506\n",
            "Epoch 4932/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0480 - val_loss: 3.0785\n",
            "Epoch 4933/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8600 - val_loss: 1.4984\n",
            "Epoch 4934/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0500 - val_loss: 1.1455\n",
            "Epoch 4935/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8049 - val_loss: 1.2638\n",
            "Epoch 4936/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9374 - val_loss: 1.9684\n",
            "Epoch 4937/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0129 - val_loss: 1.0455\n",
            "Epoch 4938/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8316 - val_loss: 0.8803\n",
            "Epoch 4939/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7534 - val_loss: 1.4096\n",
            "Epoch 4940/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9797 - val_loss: 1.5853\n",
            "Epoch 4941/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0929 - val_loss: 1.0858\n",
            "Epoch 4942/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9419 - val_loss: 1.0605\n",
            "Epoch 4943/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7881 - val_loss: 1.7797\n",
            "Epoch 4944/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9098 - val_loss: 1.5120\n",
            "Epoch 4945/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8913 - val_loss: 1.1342\n",
            "Epoch 4946/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.1332 - val_loss: 1.4214\n",
            "Epoch 4947/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8803 - val_loss: 1.0156\n",
            "Epoch 4948/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9797 - val_loss: 1.2433\n",
            "Epoch 4949/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8425 - val_loss: 1.0874\n",
            "Epoch 4950/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8537 - val_loss: 1.3183\n",
            "Epoch 4951/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.3401 - val_loss: 2.0191\n",
            "Epoch 4952/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7224 - val_loss: 1.5495\n",
            "Epoch 4953/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8193 - val_loss: 1.3454\n",
            "Epoch 4954/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9248 - val_loss: 1.0334\n",
            "Epoch 4955/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8332 - val_loss: 1.0234\n",
            "Epoch 4956/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8630 - val_loss: 1.3045\n",
            "Epoch 4957/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0984 - val_loss: 1.3576\n",
            "Epoch 4958/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7999 - val_loss: 1.0811\n",
            "Epoch 4959/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7800 - val_loss: 1.2701\n",
            "Epoch 4960/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.4055 - val_loss: 1.2867\n",
            "Epoch 4961/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8356 - val_loss: 1.2901\n",
            "Epoch 4962/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9125 - val_loss: 0.8051\n",
            "Epoch 4963/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.5883 - val_loss: 0.8261\n",
            "Epoch 4964/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9635 - val_loss: 1.4079\n",
            "Epoch 4965/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7706 - val_loss: 1.1767\n",
            "Epoch 4966/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7918 - val_loss: 0.8007\n",
            "Epoch 4967/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0853 - val_loss: 1.6047\n",
            "Epoch 4968/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6969 - val_loss: 1.0914\n",
            "Epoch 4969/5000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6153 - val_loss: 2.4987\n",
            "Epoch 4970/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8190 - val_loss: 0.9852\n",
            "Epoch 4971/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9336 - val_loss: 1.3118\n",
            "Epoch 4972/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6266 - val_loss: 1.5654\n",
            "Epoch 4973/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9731 - val_loss: 0.9601\n",
            "Epoch 4974/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8111 - val_loss: 2.1015\n",
            "Epoch 4975/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8366 - val_loss: 1.6615\n",
            "Epoch 4976/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7878 - val_loss: 1.3498\n",
            "Epoch 4977/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0315 - val_loss: 1.3265\n",
            "Epoch 4978/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.9087 - val_loss: 1.3562\n",
            "Epoch 4979/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9252 - val_loss: 1.4699\n",
            "Epoch 4980/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7279 - val_loss: 1.4362\n",
            "Epoch 4981/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8896 - val_loss: 1.0097\n",
            "Epoch 4982/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0450 - val_loss: 1.3491\n",
            "Epoch 4983/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7647 - val_loss: 0.6635\n",
            "Epoch 4984/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9620 - val_loss: 1.2166\n",
            "Epoch 4985/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8842 - val_loss: 1.1718\n",
            "Epoch 4986/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9777 - val_loss: 0.9152\n",
            "Epoch 4987/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8451 - val_loss: 2.9158\n",
            "Epoch 4988/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9929 - val_loss: 1.1976\n",
            "Epoch 4989/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9108 - val_loss: 0.9820\n",
            "Epoch 4990/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8829 - val_loss: 0.9306\n",
            "Epoch 4991/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7976 - val_loss: 1.0227\n",
            "Epoch 4992/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7482 - val_loss: 0.7958\n",
            "Epoch 4993/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8585 - val_loss: 1.0567\n",
            "Epoch 4994/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0543 - val_loss: 1.6340\n",
            "Epoch 4995/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.1660 - val_loss: 1.2123\n",
            "Epoch 4996/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8805 - val_loss: 1.2714\n",
            "Epoch 4997/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.1023 - val_loss: 0.8663\n",
            "Epoch 4998/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8508 - val_loss: 1.3322\n",
            "Epoch 4999/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0552 - val_loss: 1.6281\n",
            "Epoch 5000/5000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.2695 - val_loss: 1.2707\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_1157772/719499732.py:9: UserWarning: Attempt to set non-positive ylim on a log-scaled axis will be ignored.\n",
            "  plt.ylim((0, 10))\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 20ms/step - loss: 0.7301\n",
            "EXPECTED:\n",
            "   d18O_cel_mean  d18O_cel_variance\n",
            "0      25.882000           0.233670\n",
            "1      25.654000           0.334480\n",
            "2      27.207456           1.041823\n",
            "3      25.163333           0.807832\n",
            "4      24.030630           0.579233\n",
            "5      26.040923           0.222859\n",
            "\n",
            "PREDICTED:\n",
            "   d18O_cel_mean  d18O_cel_variance\n",
            "0      25.142637           3.226653\n",
            "1      25.141504           3.224916\n",
            "2      26.287897           3.102115\n",
            "3      24.829914           3.617434\n",
            "4      24.829914           3.617433\n",
            "5      24.902723           3.573678\n",
            "RMSE: 0.785325622024773\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2023-07-27 15:20:28.160266: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype double and shape [6,12]\n",
            "\t [[{{node Placeholder/_0}}]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4) Grouped, fixed"
      ],
      "metadata": {
        "id": "opmE3xc0vcY0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "grouped_fixed = {\n",
        "    'TRAIN': os.path.join(FP_ROOT, \"amazon_sample_data/uc_davis_2023_08_12_train_fixed_grouped.csv\"),\n",
        "    'TEST': os.path.join(FP_ROOT, \"amazon_sample_data/uc_davis_2023_08_12_test_fixed_grouped.csv\"),\n",
        "    'VALIDATION': os.path.join(FP_ROOT, \"amazon_sample_data/uc_davis_2023_08_12_validation_fixed_grouped.csv\"),\n",
        "}\n",
        "\n",
        "grouped_fixed_scaled = load_and_scale(grouped_fixed)\n",
        "train_and_evaluate(grouped_fixed_scaled, \"grouped_fixed\", training_batch_size=3)"
      ],
      "metadata": {
        "id": "KCebsA7XvfRH",
        "outputId": "d914fd43-4af3-4060-c131-2b41969d84af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.8706 - val_loss: 2.0460\n",
            "Epoch 2502/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.0582 - val_loss: 2.9844\n",
            "Epoch 2503/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7398 - val_loss: 1.9924\n",
            "Epoch 2504/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7534 - val_loss: 3.2653\n",
            "Epoch 2505/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8399 - val_loss: 1.9887\n",
            "Epoch 2506/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8721 - val_loss: 1.9465\n",
            "Epoch 2507/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.3302 - val_loss: 2.8970\n",
            "Epoch 2508/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1969 - val_loss: 3.4159\n",
            "Epoch 2509/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.8237 - val_loss: 2.5898\n",
            "Epoch 2510/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.2722 - val_loss: 4.0509\n",
            "Epoch 2511/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9893 - val_loss: 2.2727\n",
            "Epoch 2512/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.1648 - val_loss: 4.0584\n",
            "Epoch 2513/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.8768 - val_loss: 2.0290\n",
            "Epoch 2514/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.3700 - val_loss: 1.6851\n",
            "Epoch 2515/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.9321 - val_loss: 1.8520\n",
            "Epoch 2516/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7951 - val_loss: 2.4264\n",
            "Epoch 2517/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8859 - val_loss: 2.1178\n",
            "Epoch 2518/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9416 - val_loss: 6.8309\n",
            "Epoch 2519/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9364 - val_loss: 2.3886\n",
            "Epoch 2520/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9517 - val_loss: 2.5331\n",
            "Epoch 2521/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9904 - val_loss: 4.5458\n",
            "Epoch 2522/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.8475 - val_loss: 5.9506\n",
            "Epoch 2523/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9758 - val_loss: 3.2447\n",
            "Epoch 2524/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.3092 - val_loss: 4.4811\n",
            "Epoch 2525/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8420 - val_loss: 6.0344\n",
            "Epoch 2526/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.7068 - val_loss: 2.7019\n",
            "Epoch 2527/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8288 - val_loss: 2.1027\n",
            "Epoch 2528/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1144 - val_loss: 1.8503\n",
            "Epoch 2529/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 3.7897 - val_loss: 2.5151\n",
            "Epoch 2530/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7474 - val_loss: 3.4265\n",
            "Epoch 2531/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1295 - val_loss: 3.7696\n",
            "Epoch 2532/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8489 - val_loss: 2.7369\n",
            "Epoch 2533/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7552 - val_loss: 1.8597\n",
            "Epoch 2534/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0217 - val_loss: 2.9964\n",
            "Epoch 2535/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.3766 - val_loss: 3.4104\n",
            "Epoch 2536/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.7201 - val_loss: 5.7094\n",
            "Epoch 2537/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.8520 - val_loss: 2.9236\n",
            "Epoch 2538/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8702 - val_loss: 3.5219\n",
            "Epoch 2539/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.9417 - val_loss: 9.4768\n",
            "Epoch 2540/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8322 - val_loss: 2.5200\n",
            "Epoch 2541/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9870 - val_loss: 2.9575\n",
            "Epoch 2542/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0833 - val_loss: 2.9214\n",
            "Epoch 2543/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2470 - val_loss: 3.9430\n",
            "Epoch 2544/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9062 - val_loss: 2.7348\n",
            "Epoch 2545/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0236 - val_loss: 3.8261\n",
            "Epoch 2546/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8560 - val_loss: 2.5420\n",
            "Epoch 2547/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9639 - val_loss: 2.8274\n",
            "Epoch 2548/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9299 - val_loss: 3.0369\n",
            "Epoch 2549/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.1714 - val_loss: 2.7027\n",
            "Epoch 2550/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.8497 - val_loss: 3.1933\n",
            "Epoch 2551/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2657 - val_loss: 2.6394\n",
            "Epoch 2552/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1655 - val_loss: 2.9866\n",
            "Epoch 2553/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9392 - val_loss: 2.8996\n",
            "Epoch 2554/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.5742 - val_loss: 2.8291\n",
            "Epoch 2555/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8711 - val_loss: 4.5966\n",
            "Epoch 2556/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9323 - val_loss: 2.1872\n",
            "Epoch 2557/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1322 - val_loss: 4.5728\n",
            "Epoch 2558/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9324 - val_loss: 2.6884\n",
            "Epoch 2559/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0075 - val_loss: 5.7649\n",
            "Epoch 2560/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.9971 - val_loss: 2.6120\n",
            "Epoch 2561/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8357 - val_loss: 4.7854\n",
            "Epoch 2562/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0583 - val_loss: 2.8022\n",
            "Epoch 2563/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8564 - val_loss: 2.1348\n",
            "Epoch 2564/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2999 - val_loss: 3.9952\n",
            "Epoch 2565/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8811 - val_loss: 4.9281\n",
            "Epoch 2566/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2975 - val_loss: 4.1526\n",
            "Epoch 2567/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1611 - val_loss: 2.6855\n",
            "Epoch 2568/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7797 - val_loss: 3.5546\n",
            "Epoch 2569/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9198 - val_loss: 4.1944\n",
            "Epoch 2570/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.7160 - val_loss: 4.4474\n",
            "Epoch 2571/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.9793 - val_loss: 90.1783\n",
            "Epoch 2572/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.7525 - val_loss: 3.5772\n",
            "Epoch 2573/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9971 - val_loss: 3.3470\n",
            "Epoch 2574/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2951 - val_loss: 5.0478\n",
            "Epoch 2575/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8338 - val_loss: 4.3046\n",
            "Epoch 2576/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2159 - val_loss: 5.2708\n",
            "Epoch 2577/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.7527 - val_loss: 2.0753\n",
            "Epoch 2578/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.7798 - val_loss: 3.3276\n",
            "Epoch 2579/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2350 - val_loss: 2.9649\n",
            "Epoch 2580/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1060 - val_loss: 2.6722\n",
            "Epoch 2581/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7337 - val_loss: 5.8960\n",
            "Epoch 2582/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7984 - val_loss: 2.5469\n",
            "Epoch 2583/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9340 - val_loss: 2.9176\n",
            "Epoch 2584/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.9085 - val_loss: 1.8208\n",
            "Epoch 2585/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8897 - val_loss: 4.5528\n",
            "Epoch 2586/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7256 - val_loss: 2.9588\n",
            "Epoch 2587/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7784 - val_loss: 4.2124\n",
            "Epoch 2588/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1111 - val_loss: 2.9570\n",
            "Epoch 2589/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 2.3821 - val_loss: 3.4980\n",
            "Epoch 2590/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0052 - val_loss: 2.2695\n",
            "Epoch 2591/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7372 - val_loss: 3.0498\n",
            "Epoch 2592/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8096 - val_loss: 3.2562\n",
            "Epoch 2593/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.9910 - val_loss: 3.2249\n",
            "Epoch 2594/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6991 - val_loss: 5.1324\n",
            "Epoch 2595/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8827 - val_loss: 4.5132\n",
            "Epoch 2596/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9555 - val_loss: 3.8507\n",
            "Epoch 2597/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7847 - val_loss: 5.1247\n",
            "Epoch 2598/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1291 - val_loss: 3.1452\n",
            "Epoch 2599/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0846 - val_loss: 2.8571\n",
            "Epoch 2600/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9747 - val_loss: 2.9336\n",
            "Epoch 2601/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0344 - val_loss: 3.5898\n",
            "Epoch 2602/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8807 - val_loss: 3.6063\n",
            "Epoch 2603/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7073 - val_loss: 4.3575\n",
            "Epoch 2604/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9502 - val_loss: 4.1290\n",
            "Epoch 2605/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0055 - val_loss: 3.1139\n",
            "Epoch 2606/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8075 - val_loss: 3.7912\n",
            "Epoch 2607/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0725 - val_loss: 1.8809\n",
            "Epoch 2608/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2095 - val_loss: 2.1584\n",
            "Epoch 2609/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0339 - val_loss: 3.1705\n",
            "Epoch 2610/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8851 - val_loss: 2.8175\n",
            "Epoch 2611/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9228 - val_loss: 3.9552\n",
            "Epoch 2612/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9397 - val_loss: 3.0148\n",
            "Epoch 2613/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9214 - val_loss: 12.3812\n",
            "Epoch 2614/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2862 - val_loss: 2.4172\n",
            "Epoch 2615/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7922 - val_loss: 2.8444\n",
            "Epoch 2616/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.3944 - val_loss: 2.7031\n",
            "Epoch 2617/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7834 - val_loss: 2.9065\n",
            "Epoch 2618/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8601 - val_loss: 6.5427\n",
            "Epoch 2619/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0863 - val_loss: 2.8986\n",
            "Epoch 2620/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9735 - val_loss: 6.3661\n",
            "Epoch 2621/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9724 - val_loss: 2.4876\n",
            "Epoch 2622/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1169 - val_loss: 2.1120\n",
            "Epoch 2623/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.3880 - val_loss: 7.4411\n",
            "Epoch 2624/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.3614 - val_loss: 3.8873\n",
            "Epoch 2625/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.8877 - val_loss: 3.2624\n",
            "Epoch 2626/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9474 - val_loss: 4.9536\n",
            "Epoch 2627/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0108 - val_loss: 3.1935\n",
            "Epoch 2628/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9452 - val_loss: 2.9835\n",
            "Epoch 2629/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2711 - val_loss: 4.2631\n",
            "Epoch 2630/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9867 - val_loss: 3.2714\n",
            "Epoch 2631/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9465 - val_loss: 3.4380\n",
            "Epoch 2632/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7841 - val_loss: 2.5610\n",
            "Epoch 2633/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1088 - val_loss: 2.7446\n",
            "Epoch 2634/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9754 - val_loss: 2.8781\n",
            "Epoch 2635/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8042 - val_loss: 4.4556\n",
            "Epoch 2636/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0153 - val_loss: 2.3239\n",
            "Epoch 2637/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0989 - val_loss: 2.0288\n",
            "Epoch 2638/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9807 - val_loss: 2.9676\n",
            "Epoch 2639/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8422 - val_loss: 3.3659\n",
            "Epoch 2640/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8470 - val_loss: 3.2326\n",
            "Epoch 2641/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1310 - val_loss: 3.9560\n",
            "Epoch 2642/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.5069 - val_loss: 3.3276\n",
            "Epoch 2643/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9794 - val_loss: 3.3144\n",
            "Epoch 2644/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0329 - val_loss: 2.8514\n",
            "Epoch 2645/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0125 - val_loss: 2.2979\n",
            "Epoch 2646/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 2.3654 - val_loss: 3.3649\n",
            "Epoch 2647/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9614 - val_loss: 2.6864\n",
            "Epoch 2648/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2176 - val_loss: 2.9208\n",
            "Epoch 2649/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8621 - val_loss: 3.5507\n",
            "Epoch 2650/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0696 - val_loss: 2.5349\n",
            "Epoch 2651/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8285 - val_loss: 3.5817\n",
            "Epoch 2652/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.2456 - val_loss: 3.4517\n",
            "Epoch 2653/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0443 - val_loss: 3.4279\n",
            "Epoch 2654/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.8557 - val_loss: 2.3825\n",
            "Epoch 2655/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.4174 - val_loss: 5.0560\n",
            "Epoch 2656/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.8402 - val_loss: 3.2141\n",
            "Epoch 2657/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8678 - val_loss: 2.1188\n",
            "Epoch 2658/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9623 - val_loss: 2.4831\n",
            "Epoch 2659/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.3897 - val_loss: 5.2308\n",
            "Epoch 2660/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9797 - val_loss: 4.2870\n",
            "Epoch 2661/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9093 - val_loss: 7.9484\n",
            "Epoch 2662/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9440 - val_loss: 2.0966\n",
            "Epoch 2663/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1134 - val_loss: 2.6392\n",
            "Epoch 2664/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9082 - val_loss: 4.1893\n",
            "Epoch 2665/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7952 - val_loss: 2.4101\n",
            "Epoch 2666/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9384 - val_loss: 3.8505\n",
            "Epoch 2667/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0135 - val_loss: 2.8394\n",
            "Epoch 2668/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2068 - val_loss: 4.9450\n",
            "Epoch 2669/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8582 - val_loss: 2.1601\n",
            "Epoch 2670/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7246 - val_loss: 2.8516\n",
            "Epoch 2671/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8612 - val_loss: 2.8773\n",
            "Epoch 2672/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9447 - val_loss: 5.0724\n",
            "Epoch 2673/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9342 - val_loss: 2.4938\n",
            "Epoch 2674/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9855 - val_loss: 3.2285\n",
            "Epoch 2675/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0545 - val_loss: 2.2373\n",
            "Epoch 2676/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7422 - val_loss: 1.9686\n",
            "Epoch 2677/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2739 - val_loss: 2.4878\n",
            "Epoch 2678/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1690 - val_loss: 9.3742\n",
            "Epoch 2679/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.9642 - val_loss: 2.2879\n",
            "Epoch 2680/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2915 - val_loss: 3.3993\n",
            "Epoch 2681/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.3280 - val_loss: 2.1989\n",
            "Epoch 2682/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8901 - val_loss: 3.6278\n",
            "Epoch 2683/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8448 - val_loss: 3.9109\n",
            "Epoch 2684/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 2.8718 - val_loss: 2.3251\n",
            "Epoch 2685/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8810 - val_loss: 3.2756\n",
            "Epoch 2686/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9307 - val_loss: 5.2599\n",
            "Epoch 2687/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2874 - val_loss: 2.4235\n",
            "Epoch 2688/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0295 - val_loss: 2.1936\n",
            "Epoch 2689/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8738 - val_loss: 3.3034\n",
            "Epoch 2690/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1616 - val_loss: 1.6973\n",
            "Epoch 2691/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7101 - val_loss: 20.9447\n",
            "Epoch 2692/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.9839 - val_loss: 4.3161\n",
            "Epoch 2693/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1238 - val_loss: 3.0618\n",
            "Epoch 2694/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1859 - val_loss: 2.6113\n",
            "Epoch 2695/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8760 - val_loss: 2.5361\n",
            "Epoch 2696/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.7498 - val_loss: 2.2572\n",
            "Epoch 2697/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.4021 - val_loss: 3.3841\n",
            "Epoch 2698/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8022 - val_loss: 2.5066\n",
            "Epoch 2699/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.7866 - val_loss: 4.2985\n",
            "Epoch 2700/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.8110 - val_loss: 3.6099\n",
            "Epoch 2701/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.9104 - val_loss: 4.7375\n",
            "Epoch 2702/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.7919 - val_loss: 2.6107\n",
            "Epoch 2703/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0509 - val_loss: 5.4528\n",
            "Epoch 2704/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.8372 - val_loss: 2.1371\n",
            "Epoch 2705/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.1072 - val_loss: 4.6114\n",
            "Epoch 2706/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.1196 - val_loss: 1.8940\n",
            "Epoch 2707/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7520 - val_loss: 2.2069\n",
            "Epoch 2708/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9048 - val_loss: 3.2541\n",
            "Epoch 2709/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1308 - val_loss: 3.9274\n",
            "Epoch 2710/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8529 - val_loss: 4.4404\n",
            "Epoch 2711/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6819 - val_loss: 5.9244\n",
            "Epoch 2712/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.3101 - val_loss: 3.1850\n",
            "Epoch 2713/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9899 - val_loss: 5.4110\n",
            "Epoch 2714/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8125 - val_loss: 2.0080\n",
            "Epoch 2715/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8351 - val_loss: 2.9257\n",
            "Epoch 2716/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8181 - val_loss: 3.1255\n",
            "Epoch 2717/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0020 - val_loss: 2.3701\n",
            "Epoch 2718/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0467 - val_loss: 2.6528\n",
            "Epoch 2719/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0410 - val_loss: 4.8995\n",
            "Epoch 2720/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9952 - val_loss: 2.2573\n",
            "Epoch 2721/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8488 - val_loss: 5.0538\n",
            "Epoch 2722/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.0216 - val_loss: 2.4304\n",
            "Epoch 2723/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.7148 - val_loss: 2.7996\n",
            "Epoch 2724/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7460 - val_loss: 2.4944\n",
            "Epoch 2725/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8526 - val_loss: 2.5085\n",
            "Epoch 2726/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9325 - val_loss: 2.7835\n",
            "Epoch 2727/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1461 - val_loss: 2.4391\n",
            "Epoch 2728/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7849 - val_loss: 5.2907\n",
            "Epoch 2729/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2856 - val_loss: 2.3955\n",
            "Epoch 2730/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.2324 - val_loss: 3.0744\n",
            "Epoch 2731/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.7407 - val_loss: 2.4082\n",
            "Epoch 2732/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0287 - val_loss: 7.7196\n",
            "Epoch 2733/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8313 - val_loss: 2.8594\n",
            "Epoch 2734/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.4109 - val_loss: 1.8931\n",
            "Epoch 2735/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 2.2032 - val_loss: 1.6323\n",
            "Epoch 2736/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9500 - val_loss: 2.6820\n",
            "Epoch 2737/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7090 - val_loss: 9.1260\n",
            "Epoch 2738/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1193 - val_loss: 3.0567\n",
            "Epoch 2739/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8614 - val_loss: 5.9282\n",
            "Epoch 2740/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0152 - val_loss: 1.8325\n",
            "Epoch 2741/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7063 - val_loss: 2.4952\n",
            "Epoch 2742/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.3737 - val_loss: 3.6880\n",
            "Epoch 2743/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7824 - val_loss: 3.3227\n",
            "Epoch 2744/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.8037 - val_loss: 8.8515\n",
            "Epoch 2745/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8738 - val_loss: 3.8048\n",
            "Epoch 2746/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.9897 - val_loss: 2.0424\n",
            "Epoch 2747/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1160 - val_loss: 2.1289\n",
            "Epoch 2748/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7647 - val_loss: 2.6397\n",
            "Epoch 2749/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7774 - val_loss: 6.1035\n",
            "Epoch 2750/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7609 - val_loss: 3.1805\n",
            "Epoch 2751/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2749 - val_loss: 2.3728\n",
            "Epoch 2752/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.4087 - val_loss: 3.0331\n",
            "Epoch 2753/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.7763 - val_loss: 2.1302\n",
            "Epoch 2754/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2299 - val_loss: 3.5637\n",
            "Epoch 2755/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1061 - val_loss: 2.4308\n",
            "Epoch 2756/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1778 - val_loss: 2.5287\n",
            "Epoch 2757/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9347 - val_loss: 2.3167\n",
            "Epoch 2758/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0526 - val_loss: 6.9228\n",
            "Epoch 2759/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0724 - val_loss: 2.8781\n",
            "Epoch 2760/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.0387 - val_loss: 2.3400\n",
            "Epoch 2761/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.5677 - val_loss: 2.7171\n",
            "Epoch 2762/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0503 - val_loss: 2.4747\n",
            "Epoch 2763/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8814 - val_loss: 2.3090\n",
            "Epoch 2764/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9603 - val_loss: 6.1694\n",
            "Epoch 2765/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8359 - val_loss: 3.5740\n",
            "Epoch 2766/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9579 - val_loss: 2.8769\n",
            "Epoch 2767/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0330 - val_loss: 4.3846\n",
            "Epoch 2768/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8773 - val_loss: 4.1390\n",
            "Epoch 2769/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0181 - val_loss: 2.6300\n",
            "Epoch 2770/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.8088 - val_loss: 2.4923\n",
            "Epoch 2771/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9307 - val_loss: 1.8673\n",
            "Epoch 2772/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6538 - val_loss: 2.7015\n",
            "Epoch 2773/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9013 - val_loss: 2.2220\n",
            "Epoch 2774/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.4071 - val_loss: 3.9232\n",
            "Epoch 2775/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8294 - val_loss: 2.8800\n",
            "Epoch 2776/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9952 - val_loss: 1.9796\n",
            "Epoch 2777/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0315 - val_loss: 4.0454\n",
            "Epoch 2778/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0510 - val_loss: 2.8290\n",
            "Epoch 2779/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0781 - val_loss: 2.2710\n",
            "Epoch 2780/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.8140 - val_loss: 3.7859\n",
            "Epoch 2781/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.2593 - val_loss: 5.2418\n",
            "Epoch 2782/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0729 - val_loss: 6.3104\n",
            "Epoch 2783/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2687 - val_loss: 2.9731\n",
            "Epoch 2784/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9622 - val_loss: 5.5350\n",
            "Epoch 2785/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1643 - val_loss: 2.7417\n",
            "Epoch 2786/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2019 - val_loss: 2.3621\n",
            "Epoch 2787/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.8576 - val_loss: 3.3712\n",
            "Epoch 2788/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8953 - val_loss: 2.7382\n",
            "Epoch 2789/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2919 - val_loss: 1.7349\n",
            "Epoch 2790/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.3074 - val_loss: 3.4132\n",
            "Epoch 2791/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.0640 - val_loss: 3.4721\n",
            "Epoch 2792/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0788 - val_loss: 4.1485\n",
            "Epoch 2793/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9339 - val_loss: 3.9115\n",
            "Epoch 2794/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7786 - val_loss: 3.1644\n",
            "Epoch 2795/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0736 - val_loss: 3.4565\n",
            "Epoch 2796/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8535 - val_loss: 4.2230\n",
            "Epoch 2797/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0124 - val_loss: 2.9935\n",
            "Epoch 2798/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7074 - val_loss: 2.6763\n",
            "Epoch 2799/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8210 - val_loss: 2.8573\n",
            "Epoch 2800/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.7994 - val_loss: 4.3233\n",
            "Epoch 2801/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7994 - val_loss: 2.0791\n",
            "Epoch 2802/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.7370 - val_loss: 3.2557\n",
            "Epoch 2803/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.9202 - val_loss: 6.8898\n",
            "Epoch 2804/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8512 - val_loss: 3.0529\n",
            "Epoch 2805/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.7306 - val_loss: 3.0271\n",
            "Epoch 2806/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0445 - val_loss: 2.4398\n",
            "Epoch 2807/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9565 - val_loss: 2.1402\n",
            "Epoch 2808/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1860 - val_loss: 2.8350\n",
            "Epoch 2809/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8429 - val_loss: 2.9583\n",
            "Epoch 2810/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8673 - val_loss: 2.7952\n",
            "Epoch 2811/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.8813 - val_loss: 2.6412\n",
            "Epoch 2812/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8862 - val_loss: 5.6411\n",
            "Epoch 2813/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.8868 - val_loss: 4.9571\n",
            "Epoch 2814/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8211 - val_loss: 3.0520\n",
            "Epoch 2815/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8166 - val_loss: 2.6724\n",
            "Epoch 2816/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.0345 - val_loss: 3.3015\n",
            "Epoch 2817/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0789 - val_loss: 2.9914\n",
            "Epoch 2818/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9547 - val_loss: 5.7601\n",
            "Epoch 2819/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 2.8903 - val_loss: 3.1713\n",
            "Epoch 2820/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2139 - val_loss: 2.6563\n",
            "Epoch 2821/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1396 - val_loss: 5.0734\n",
            "Epoch 2822/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8578 - val_loss: 4.1725\n",
            "Epoch 2823/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.8262 - val_loss: 3.2921\n",
            "Epoch 2824/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8685 - val_loss: 10.0879\n",
            "Epoch 2825/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.4378 - val_loss: 2.4048\n",
            "Epoch 2826/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7622 - val_loss: 4.1619\n",
            "Epoch 2827/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9685 - val_loss: 3.5382\n",
            "Epoch 2828/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9273 - val_loss: 4.3259\n",
            "Epoch 2829/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1118 - val_loss: 3.7053\n",
            "Epoch 2830/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7618 - val_loss: 3.1445\n",
            "Epoch 2831/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1126 - val_loss: 2.8909\n",
            "Epoch 2832/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 2.2607 - val_loss: 4.3620\n",
            "Epoch 2833/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1133 - val_loss: 3.5644\n",
            "Epoch 2834/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8287 - val_loss: 4.8209\n",
            "Epoch 2835/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2433 - val_loss: 11.7440\n",
            "Epoch 2836/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9113 - val_loss: 2.2092\n",
            "Epoch 2837/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8957 - val_loss: 2.7784\n",
            "Epoch 2838/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8578 - val_loss: 2.7687\n",
            "Epoch 2839/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9884 - val_loss: 6.5790\n",
            "Epoch 2840/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.3871 - val_loss: 3.3776\n",
            "Epoch 2841/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8146 - val_loss: 2.7043\n",
            "Epoch 2842/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9251 - val_loss: 2.1541\n",
            "Epoch 2843/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0341 - val_loss: 3.8590\n",
            "Epoch 2844/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1845 - val_loss: 2.4658\n",
            "Epoch 2845/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.7219 - val_loss: 3.6229\n",
            "Epoch 2846/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.9443 - val_loss: 4.0694\n",
            "Epoch 2847/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0036 - val_loss: 3.0940\n",
            "Epoch 2848/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.9740 - val_loss: 4.5979\n",
            "Epoch 2849/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7540 - val_loss: 2.5573\n",
            "Epoch 2850/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9797 - val_loss: 1.8748\n",
            "Epoch 2851/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0747 - val_loss: 2.5350\n",
            "Epoch 2852/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.9124 - val_loss: 3.6137\n",
            "Epoch 2853/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8627 - val_loss: 2.7152\n",
            "Epoch 2854/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8293 - val_loss: 9.5149\n",
            "Epoch 2855/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1732 - val_loss: 2.8988\n",
            "Epoch 2856/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.0982 - val_loss: 3.5168\n",
            "Epoch 2857/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.9276 - val_loss: 4.6560\n",
            "Epoch 2858/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.9108 - val_loss: 5.0937\n",
            "Epoch 2859/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8635 - val_loss: 3.9400\n",
            "Epoch 2860/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.8720 - val_loss: 5.5160\n",
            "Epoch 2861/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.4065 - val_loss: 2.0085\n",
            "Epoch 2862/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0307 - val_loss: 3.2526\n",
            "Epoch 2863/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9762 - val_loss: 4.1533\n",
            "Epoch 2864/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 2.2529 - val_loss: 2.3303\n",
            "Epoch 2865/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9312 - val_loss: 3.5742\n",
            "Epoch 2866/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0055 - val_loss: 2.2590\n",
            "Epoch 2867/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7981 - val_loss: 3.3246\n",
            "Epoch 2868/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8948 - val_loss: 2.1126\n",
            "Epoch 2869/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9647 - val_loss: 2.5216\n",
            "Epoch 2870/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7139 - val_loss: 3.7282\n",
            "Epoch 2871/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2067 - val_loss: 2.2293\n",
            "Epoch 2872/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8959 - val_loss: 5.1504\n",
            "Epoch 2873/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2233 - val_loss: 4.0672\n",
            "Epoch 2874/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0180 - val_loss: 2.8529\n",
            "Epoch 2875/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0401 - val_loss: 2.8659\n",
            "Epoch 2876/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8540 - val_loss: 6.5871\n",
            "Epoch 2877/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1205 - val_loss: 4.4462\n",
            "Epoch 2878/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7733 - val_loss: 3.0896\n",
            "Epoch 2879/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.7499 - val_loss: 5.3923\n",
            "Epoch 2880/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8234 - val_loss: 2.3360\n",
            "Epoch 2881/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9359 - val_loss: 4.3388\n",
            "Epoch 2882/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.2616 - val_loss: 5.1149\n",
            "Epoch 2883/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7842 - val_loss: 4.5885\n",
            "Epoch 2884/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8124 - val_loss: 7.8256\n",
            "Epoch 2885/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8764 - val_loss: 16.6852\n",
            "Epoch 2886/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.4200 - val_loss: 4.8351\n",
            "Epoch 2887/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9083 - val_loss: 3.6418\n",
            "Epoch 2888/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9496 - val_loss: 4.6198\n",
            "Epoch 2889/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.3481 - val_loss: 3.3270\n",
            "Epoch 2890/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1515 - val_loss: 3.1149\n",
            "Epoch 2891/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7926 - val_loss: 4.0572\n",
            "Epoch 2892/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7142 - val_loss: 3.3887\n",
            "Epoch 2893/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1988 - val_loss: 3.3251\n",
            "Epoch 2894/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8005 - val_loss: 7.5058\n",
            "Epoch 2895/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9684 - val_loss: 4.2444\n",
            "Epoch 2896/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.0179 - val_loss: 2.8054\n",
            "Epoch 2897/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0109 - val_loss: 3.3409\n",
            "Epoch 2898/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1403 - val_loss: 4.5842\n",
            "Epoch 2899/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6918 - val_loss: 3.9836\n",
            "Epoch 2900/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.9115 - val_loss: 2.5856\n",
            "Epoch 2901/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.9331 - val_loss: 3.0514\n",
            "Epoch 2902/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9141 - val_loss: 2.6181\n",
            "Epoch 2903/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.9913 - val_loss: 2.7869\n",
            "Epoch 2904/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8495 - val_loss: 2.9633\n",
            "Epoch 2905/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.7437 - val_loss: 2.3954\n",
            "Epoch 2906/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9102 - val_loss: 7.6292\n",
            "Epoch 2907/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8454 - val_loss: 2.0222\n",
            "Epoch 2908/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.0390 - val_loss: 5.4269\n",
            "Epoch 2909/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0885 - val_loss: 2.9577\n",
            "Epoch 2910/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.4598 - val_loss: 4.9007\n",
            "Epoch 2911/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.8624 - val_loss: 11.5641\n",
            "Epoch 2912/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0556 - val_loss: 2.2176\n",
            "Epoch 2913/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0401 - val_loss: 4.4210\n",
            "Epoch 2914/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8776 - val_loss: 5.0169\n",
            "Epoch 2915/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8662 - val_loss: 3.1952\n",
            "Epoch 2916/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.8362 - val_loss: 2.2769\n",
            "Epoch 2917/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.9643 - val_loss: 3.1392\n",
            "Epoch 2918/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0094 - val_loss: 7.2051\n",
            "Epoch 2919/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.3383 - val_loss: 6.2060\n",
            "Epoch 2920/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.4086 - val_loss: 2.6614\n",
            "Epoch 2921/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9175 - val_loss: 2.3281\n",
            "Epoch 2922/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8603 - val_loss: 3.2331\n",
            "Epoch 2923/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1058 - val_loss: 3.0862\n",
            "Epoch 2924/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9473 - val_loss: 2.3604\n",
            "Epoch 2925/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.9581 - val_loss: 3.2036\n",
            "Epoch 2926/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.3059 - val_loss: 3.3272\n",
            "Epoch 2927/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.8105 - val_loss: 3.3963\n",
            "Epoch 2928/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9631 - val_loss: 2.0837\n",
            "Epoch 2929/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1604 - val_loss: 2.6004\n",
            "Epoch 2930/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8175 - val_loss: 2.6593\n",
            "Epoch 2931/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9111 - val_loss: 2.6002\n",
            "Epoch 2932/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1690 - val_loss: 2.3874\n",
            "Epoch 2933/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7927 - val_loss: 3.9698\n",
            "Epoch 2934/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.5202 - val_loss: 3.9845\n",
            "Epoch 2935/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7548 - val_loss: 2.1568\n",
            "Epoch 2936/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2451 - val_loss: 3.4464\n",
            "Epoch 2937/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7440 - val_loss: 6.8781\n",
            "Epoch 2938/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1199 - val_loss: 4.1252\n",
            "Epoch 2939/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9839 - val_loss: 1.8534\n",
            "Epoch 2940/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.7804 - val_loss: 3.1508\n",
            "Epoch 2941/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7698 - val_loss: 4.9351\n",
            "Epoch 2942/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0198 - val_loss: 4.5185\n",
            "Epoch 2943/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8757 - val_loss: 1.9879\n",
            "Epoch 2944/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.0848 - val_loss: 3.6475\n",
            "Epoch 2945/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9791 - val_loss: 2.4506\n",
            "Epoch 2946/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9486 - val_loss: 3.8869\n",
            "Epoch 2947/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8265 - val_loss: 3.7405\n",
            "Epoch 2948/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8224 - val_loss: 4.5214\n",
            "Epoch 2949/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7043 - val_loss: 3.4997\n",
            "Epoch 2950/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1085 - val_loss: 3.2684\n",
            "Epoch 2951/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1470 - val_loss: 2.5744\n",
            "Epoch 2952/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8439 - val_loss: 4.6038\n",
            "Epoch 2953/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0615 - val_loss: 4.8088\n",
            "Epoch 2954/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0709 - val_loss: 3.1891\n",
            "Epoch 2955/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.4780 - val_loss: 2.5942\n",
            "Epoch 2956/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.3646 - val_loss: 3.7054\n",
            "Epoch 2957/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.9622 - val_loss: 4.7657\n",
            "Epoch 2958/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8106 - val_loss: 4.2916\n",
            "Epoch 2959/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2273 - val_loss: 4.5214\n",
            "Epoch 2960/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0587 - val_loss: 3.4458\n",
            "Epoch 2961/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8354 - val_loss: 3.4674\n",
            "Epoch 2962/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9064 - val_loss: 2.8298\n",
            "Epoch 2963/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0163 - val_loss: 2.2595\n",
            "Epoch 2964/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0008 - val_loss: 4.0606\n",
            "Epoch 2965/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8888 - val_loss: 3.8258\n",
            "Epoch 2966/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.8782 - val_loss: 3.8157\n",
            "Epoch 2967/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.8423 - val_loss: 3.5741\n",
            "Epoch 2968/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7716 - val_loss: 4.9108\n",
            "Epoch 2969/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0124 - val_loss: 2.9313\n",
            "Epoch 2970/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6964 - val_loss: 2.9703\n",
            "Epoch 2971/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.4765 - val_loss: 3.1815\n",
            "Epoch 2972/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7929 - val_loss: 2.6821\n",
            "Epoch 2973/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0216 - val_loss: 3.2318\n",
            "Epoch 2974/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9643 - val_loss: 3.9102\n",
            "Epoch 2975/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.9266 - val_loss: 4.3546\n",
            "Epoch 2976/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.8142 - val_loss: 4.2418\n",
            "Epoch 2977/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2729 - val_loss: 4.1209\n",
            "Epoch 2978/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1938 - val_loss: 1.8853\n",
            "Epoch 2979/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.7070 - val_loss: 3.5548\n",
            "Epoch 2980/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2495 - val_loss: 2.7455\n",
            "Epoch 2981/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9614 - val_loss: 3.0940\n",
            "Epoch 2982/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.8086 - val_loss: 2.4303\n",
            "Epoch 2983/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0352 - val_loss: 5.5399\n",
            "Epoch 2984/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.1328 - val_loss: 2.2393\n",
            "Epoch 2985/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7307 - val_loss: 6.3089\n",
            "Epoch 2986/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0603 - val_loss: 2.7465\n",
            "Epoch 2987/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9653 - val_loss: 2.0748\n",
            "Epoch 2988/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0011 - val_loss: 4.7038\n",
            "Epoch 2989/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8644 - val_loss: 3.1310\n",
            "Epoch 2990/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9103 - val_loss: 4.5991\n",
            "Epoch 2991/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9589 - val_loss: 2.9660\n",
            "Epoch 2992/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7782 - val_loss: 5.0802\n",
            "Epoch 2993/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8868 - val_loss: 3.9620\n",
            "Epoch 2994/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0282 - val_loss: 5.8490\n",
            "Epoch 2995/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.9893 - val_loss: 3.0099\n",
            "Epoch 2996/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.9617 - val_loss: 5.3965\n",
            "Epoch 2997/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7329 - val_loss: 4.0735\n",
            "Epoch 2998/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.8480 - val_loss: 4.2246\n",
            "Epoch 2999/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7454 - val_loss: 2.9185\n",
            "Epoch 3000/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.3472 - val_loss: 3.9446\n",
            "Epoch 3001/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7946 - val_loss: 1.9400\n",
            "Epoch 3002/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.8003 - val_loss: 3.1044\n",
            "Epoch 3003/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0108 - val_loss: 2.5049\n",
            "Epoch 3004/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.4915 - val_loss: 4.6084\n",
            "Epoch 3005/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8379 - val_loss: 4.1175\n",
            "Epoch 3006/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1541 - val_loss: 3.1000\n",
            "Epoch 3007/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.7244 - val_loss: 5.7271\n",
            "Epoch 3008/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9158 - val_loss: 3.6180\n",
            "Epoch 3009/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8113 - val_loss: 2.8423\n",
            "Epoch 3010/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.4196 - val_loss: 1.8969\n",
            "Epoch 3011/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2339 - val_loss: 2.7073\n",
            "Epoch 3012/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1283 - val_loss: 4.1841\n",
            "Epoch 3013/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.0970 - val_loss: 3.8974\n",
            "Epoch 3014/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.9104 - val_loss: 3.2934\n",
            "Epoch 3015/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.8404 - val_loss: 5.5853\n",
            "Epoch 3016/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.7219 - val_loss: 3.1037\n",
            "Epoch 3017/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2251 - val_loss: 3.5381\n",
            "Epoch 3018/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.4837 - val_loss: 2.8517\n",
            "Epoch 3019/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8741 - val_loss: 3.2328\n",
            "Epoch 3020/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0092 - val_loss: 2.4173\n",
            "Epoch 3021/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9222 - val_loss: 2.9576\n",
            "Epoch 3022/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0027 - val_loss: 3.2759\n",
            "Epoch 3023/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1977 - val_loss: 6.3473\n",
            "Epoch 3024/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8645 - val_loss: 2.3637\n",
            "Epoch 3025/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6865 - val_loss: 2.7281\n",
            "Epoch 3026/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7470 - val_loss: 3.5436\n",
            "Epoch 3027/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9097 - val_loss: 2.4949\n",
            "Epoch 3028/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8195 - val_loss: 2.1357\n",
            "Epoch 3029/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.7156 - val_loss: 10.0463\n",
            "Epoch 3030/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8268 - val_loss: 2.1235\n",
            "Epoch 3031/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1491 - val_loss: 2.7280\n",
            "Epoch 3032/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.8090 - val_loss: 4.3798\n",
            "Epoch 3033/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1564 - val_loss: 3.0670\n",
            "Epoch 3034/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.8053 - val_loss: 2.8898\n",
            "Epoch 3035/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.7248 - val_loss: 2.9352\n",
            "Epoch 3036/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.8017 - val_loss: 1.9602\n",
            "Epoch 3037/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.7590 - val_loss: 2.8330\n",
            "Epoch 3038/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.9922 - val_loss: 7.0467\n",
            "Epoch 3039/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.1282 - val_loss: 2.4232\n",
            "Epoch 3040/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.7494 - val_loss: 3.3566\n",
            "Epoch 3041/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.3327 - val_loss: 2.9059\n",
            "Epoch 3042/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.1059 - val_loss: 3.4467\n",
            "Epoch 3043/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.9948 - val_loss: 3.2990\n",
            "Epoch 3044/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.8376 - val_loss: 1.9532\n",
            "Epoch 3045/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.7102 - val_loss: 2.4983\n",
            "Epoch 3046/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8368 - val_loss: 5.7321\n",
            "Epoch 3047/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1765 - val_loss: 2.6665\n",
            "Epoch 3048/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.8116 - val_loss: 5.5290\n",
            "Epoch 3049/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.8191 - val_loss: 4.0293\n",
            "Epoch 3050/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.1198 - val_loss: 3.9964\n",
            "Epoch 3051/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.8215 - val_loss: 3.1426\n",
            "Epoch 3052/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7524 - val_loss: 2.8575\n",
            "Epoch 3053/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1403 - val_loss: 3.6899\n",
            "Epoch 3054/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6738 - val_loss: 8.4736\n",
            "Epoch 3055/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8292 - val_loss: 2.8717\n",
            "Epoch 3056/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9813 - val_loss: 8.4126\n",
            "Epoch 3057/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9794 - val_loss: 3.4764\n",
            "Epoch 3058/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0382 - val_loss: 2.3688\n",
            "Epoch 3059/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.3422 - val_loss: 4.2517\n",
            "Epoch 3060/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8806 - val_loss: 2.3306\n",
            "Epoch 3061/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.7599 - val_loss: 5.6807\n",
            "Epoch 3062/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9652 - val_loss: 4.1211\n",
            "Epoch 3063/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7125 - val_loss: 4.4178\n",
            "Epoch 3064/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0711 - val_loss: 3.3700\n",
            "Epoch 3065/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7069 - val_loss: 13.2655\n",
            "Epoch 3066/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0724 - val_loss: 4.3651\n",
            "Epoch 3067/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9549 - val_loss: 3.4637\n",
            "Epoch 3068/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.5170 - val_loss: 7.1982\n",
            "Epoch 3069/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6754 - val_loss: 3.8033\n",
            "Epoch 3070/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0422 - val_loss: 4.6623\n",
            "Epoch 3071/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.3123 - val_loss: 3.6624\n",
            "Epoch 3072/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.5764 - val_loss: 3.2740\n",
            "Epoch 3073/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0912 - val_loss: 3.4563\n",
            "Epoch 3074/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9307 - val_loss: 4.9918\n",
            "Epoch 3075/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.0596 - val_loss: 3.1509\n",
            "Epoch 3076/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0273 - val_loss: 3.2596\n",
            "Epoch 3077/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1904 - val_loss: 3.5462\n",
            "Epoch 3078/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.3235 - val_loss: 4.8588\n",
            "Epoch 3079/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8418 - val_loss: 2.6686\n",
            "Epoch 3080/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9367 - val_loss: 2.3171\n",
            "Epoch 3081/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7871 - val_loss: 3.0554\n",
            "Epoch 3082/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2867 - val_loss: 4.4958\n",
            "Epoch 3083/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7090 - val_loss: 2.5108\n",
            "Epoch 3084/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.0304 - val_loss: 8.7960\n",
            "Epoch 3085/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7870 - val_loss: 4.3265\n",
            "Epoch 3086/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7543 - val_loss: 4.2547\n",
            "Epoch 3087/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2532 - val_loss: 3.6778\n",
            "Epoch 3088/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7824 - val_loss: 4.9892\n",
            "Epoch 3089/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0703 - val_loss: 8.7015\n",
            "Epoch 3090/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.8928 - val_loss: 3.6276\n",
            "Epoch 3091/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.9111 - val_loss: 4.3848\n",
            "Epoch 3092/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.1224 - val_loss: 2.8742\n",
            "Epoch 3093/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.8802 - val_loss: 2.6813\n",
            "Epoch 3094/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.8927 - val_loss: 5.6546\n",
            "Epoch 3095/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.1370 - val_loss: 5.3020\n",
            "Epoch 3096/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.8820 - val_loss: 3.9627\n",
            "Epoch 3097/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7367 - val_loss: 2.7774\n",
            "Epoch 3098/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8098 - val_loss: 4.6751\n",
            "Epoch 3099/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9346 - val_loss: 3.0442\n",
            "Epoch 3100/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8545 - val_loss: 2.6099\n",
            "Epoch 3101/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8629 - val_loss: 2.6360\n",
            "Epoch 3102/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8543 - val_loss: 5.3570\n",
            "Epoch 3103/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0375 - val_loss: 3.2806\n",
            "Epoch 3104/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 2.2196 - val_loss: 3.0497\n",
            "Epoch 3105/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.9614 - val_loss: 2.3972\n",
            "Epoch 3106/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8418 - val_loss: 6.2768\n",
            "Epoch 3107/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1166 - val_loss: 5.6051\n",
            "Epoch 3108/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.1189 - val_loss: 5.0166\n",
            "Epoch 3109/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0417 - val_loss: 2.6534\n",
            "Epoch 3110/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.7626 - val_loss: 2.5189\n",
            "Epoch 3111/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0767 - val_loss: 2.3342\n",
            "Epoch 3112/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7684 - val_loss: 2.6659\n",
            "Epoch 3113/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.4345 - val_loss: 2.5544\n",
            "Epoch 3114/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7743 - val_loss: 2.3405\n",
            "Epoch 3115/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.3961 - val_loss: 3.2767\n",
            "Epoch 3116/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.7855 - val_loss: 1.9439\n",
            "Epoch 3117/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.3889 - val_loss: 3.2937\n",
            "Epoch 3118/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0983 - val_loss: 2.9174\n",
            "Epoch 3119/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1305 - val_loss: 3.1594\n",
            "Epoch 3120/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9339 - val_loss: 9.3320\n",
            "Epoch 3121/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1254 - val_loss: 2.9769\n",
            "Epoch 3122/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9920 - val_loss: 2.9962\n",
            "Epoch 3123/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 2.3646 - val_loss: 4.1893\n",
            "Epoch 3124/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0203 - val_loss: 2.2290\n",
            "Epoch 3125/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0403 - val_loss: 2.0506\n",
            "Epoch 3126/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8317 - val_loss: 4.6069\n",
            "Epoch 3127/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7017 - val_loss: 2.1312\n",
            "Epoch 3128/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.0115 - val_loss: 2.4428\n",
            "Epoch 3129/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9940 - val_loss: 5.9559\n",
            "Epoch 3130/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.8712 - val_loss: 2.6020\n",
            "Epoch 3131/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.4354 - val_loss: 9.1914\n",
            "Epoch 3132/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8971 - val_loss: 3.3112\n",
            "Epoch 3133/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7986 - val_loss: 2.6682\n",
            "Epoch 3134/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1738 - val_loss: 5.0890\n",
            "Epoch 3135/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.9336 - val_loss: 5.2335\n",
            "Epoch 3136/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.8305 - val_loss: 3.7629\n",
            "Epoch 3137/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8974 - val_loss: 4.7523\n",
            "Epoch 3138/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7986 - val_loss: 2.6048\n",
            "Epoch 3139/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.7708 - val_loss: 3.2267\n",
            "Epoch 3140/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1486 - val_loss: 3.0976\n",
            "Epoch 3141/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0386 - val_loss: 6.0636\n",
            "Epoch 3142/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0225 - val_loss: 2.4642\n",
            "Epoch 3143/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.7382 - val_loss: 3.8716\n",
            "Epoch 3144/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7780 - val_loss: 2.2530\n",
            "Epoch 3145/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8042 - val_loss: 4.0452\n",
            "Epoch 3146/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.3586 - val_loss: 5.3460\n",
            "Epoch 3147/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.9529 - val_loss: 1.6842\n",
            "Epoch 3148/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.0182 - val_loss: 2.5147\n",
            "Epoch 3149/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2755 - val_loss: 2.4296\n",
            "Epoch 3150/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.7007 - val_loss: 1.9962\n",
            "Epoch 3151/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.8012 - val_loss: 2.1504\n",
            "Epoch 3152/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8993 - val_loss: 3.6373\n",
            "Epoch 3153/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.8308 - val_loss: 4.4334\n",
            "Epoch 3154/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0534 - val_loss: 3.2288\n",
            "Epoch 3155/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.7909 - val_loss: 3.3198\n",
            "Epoch 3156/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.0571 - val_loss: 2.8293\n",
            "Epoch 3157/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0396 - val_loss: 3.0177\n",
            "Epoch 3158/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.9269 - val_loss: 2.3756\n",
            "Epoch 3159/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9445 - val_loss: 3.4326\n",
            "Epoch 3160/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6550 - val_loss: 2.5070\n",
            "Epoch 3161/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.8386 - val_loss: 6.6734\n",
            "Epoch 3162/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6667 - val_loss: 4.5280\n",
            "Epoch 3163/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8557 - val_loss: 11.9136\n",
            "Epoch 3164/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8506 - val_loss: 2.6168\n",
            "Epoch 3165/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9634 - val_loss: 2.4372\n",
            "Epoch 3166/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9349 - val_loss: 3.8254\n",
            "Epoch 3167/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.3643 - val_loss: 3.2367\n",
            "Epoch 3168/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.0206 - val_loss: 4.6476\n",
            "Epoch 3169/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7310 - val_loss: 2.5951\n",
            "Epoch 3170/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7680 - val_loss: 2.3499\n",
            "Epoch 3171/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8187 - val_loss: 4.6047\n",
            "Epoch 3172/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9701 - val_loss: 11.4329\n",
            "Epoch 3173/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9204 - val_loss: 6.6567\n",
            "Epoch 3174/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.3377 - val_loss: 5.1074\n",
            "Epoch 3175/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9251 - val_loss: 4.4268\n",
            "Epoch 3176/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8777 - val_loss: 7.7147\n",
            "Epoch 3177/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.3189 - val_loss: 2.5548\n",
            "Epoch 3178/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.7020 - val_loss: 5.4553\n",
            "Epoch 3179/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1121 - val_loss: 4.4934\n",
            "Epoch 3180/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0293 - val_loss: 3.5272\n",
            "Epoch 3181/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7819 - val_loss: 7.4643\n",
            "Epoch 3182/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8930 - val_loss: 2.5019\n",
            "Epoch 3183/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8116 - val_loss: 3.1123\n",
            "Epoch 3184/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8351 - val_loss: 2.1061\n",
            "Epoch 3185/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9096 - val_loss: 4.5353\n",
            "Epoch 3186/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1170 - val_loss: 2.7477\n",
            "Epoch 3187/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.3906 - val_loss: 3.0767\n",
            "Epoch 3188/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7961 - val_loss: 3.3332\n",
            "Epoch 3189/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9273 - val_loss: 3.1925\n",
            "Epoch 3190/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8428 - val_loss: 3.0721\n",
            "Epoch 3191/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.6297 - val_loss: 2.0371\n",
            "Epoch 3192/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6950 - val_loss: 6.4075\n",
            "Epoch 3193/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.0430 - val_loss: 3.1232\n",
            "Epoch 3194/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.9103 - val_loss: 2.9876\n",
            "Epoch 3195/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.0914 - val_loss: 2.7923\n",
            "Epoch 3196/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.9658 - val_loss: 2.5145\n",
            "Epoch 3197/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.0190 - val_loss: 2.7311\n",
            "Epoch 3198/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.7534 - val_loss: 3.8807\n",
            "Epoch 3199/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.4754 - val_loss: 6.6093\n",
            "Epoch 3200/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.0529 - val_loss: 3.3623\n",
            "Epoch 3201/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.8733 - val_loss: 8.8089\n",
            "Epoch 3202/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.4238 - val_loss: 2.8244\n",
            "Epoch 3203/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9115 - val_loss: 4.0912\n",
            "Epoch 3204/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9231 - val_loss: 4.6235\n",
            "Epoch 3205/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.8826 - val_loss: 2.3411\n",
            "Epoch 3206/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6819 - val_loss: 3.3984\n",
            "Epoch 3207/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 2.4313 - val_loss: 3.6434\n",
            "Epoch 3208/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2007 - val_loss: 4.5647\n",
            "Epoch 3209/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1789 - val_loss: 2.2006\n",
            "Epoch 3210/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0389 - val_loss: 2.5925\n",
            "Epoch 3211/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7647 - val_loss: 2.6742\n",
            "Epoch 3212/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.4804 - val_loss: 3.1916\n",
            "Epoch 3213/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8561 - val_loss: 2.8592\n",
            "Epoch 3214/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0102 - val_loss: 8.6511\n",
            "Epoch 3215/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7794 - val_loss: 6.0987\n",
            "Epoch 3216/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.7574 - val_loss: 5.4603\n",
            "Epoch 3217/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8342 - val_loss: 1.9384\n",
            "Epoch 3218/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1740 - val_loss: 2.8824\n",
            "Epoch 3219/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 2.1546 - val_loss: 3.0683\n",
            "Epoch 3220/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.3323 - val_loss: 4.6792\n",
            "Epoch 3221/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7517 - val_loss: 1.9531\n",
            "Epoch 3222/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.3079 - val_loss: 3.5155\n",
            "Epoch 3223/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 5.1378 - val_loss: 2.4272\n",
            "Epoch 3224/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8089 - val_loss: 3.0144\n",
            "Epoch 3225/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9704 - val_loss: 5.2889\n",
            "Epoch 3226/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6582 - val_loss: 2.6736\n",
            "Epoch 3227/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9703 - val_loss: 2.7169\n",
            "Epoch 3228/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0106 - val_loss: 3.6494\n",
            "Epoch 3229/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.1473 - val_loss: 3.4793\n",
            "Epoch 3230/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9909 - val_loss: 3.0598\n",
            "Epoch 3231/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0209 - val_loss: 2.9175\n",
            "Epoch 3232/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9457 - val_loss: 2.5613\n",
            "Epoch 3233/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.8367 - val_loss: 7.5449\n",
            "Epoch 3234/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8517 - val_loss: 5.4215\n",
            "Epoch 3235/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8429 - val_loss: 1.9050\n",
            "Epoch 3236/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.1230 - val_loss: 3.0406\n",
            "Epoch 3237/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9598 - val_loss: 3.8388\n",
            "Epoch 3238/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7431 - val_loss: 3.2822\n",
            "Epoch 3239/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.8850 - val_loss: 3.6411\n",
            "Epoch 3240/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0236 - val_loss: 3.0225\n",
            "Epoch 3241/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.5981 - val_loss: 2.3486\n",
            "Epoch 3242/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.8246 - val_loss: 4.5343\n",
            "Epoch 3243/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9022 - val_loss: 3.3699\n",
            "Epoch 3244/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2369 - val_loss: 5.8462\n",
            "Epoch 3245/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8325 - val_loss: 3.4679\n",
            "Epoch 3246/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9733 - val_loss: 3.7525\n",
            "Epoch 3247/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0334 - val_loss: 2.5759\n",
            "Epoch 3248/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.9226 - val_loss: 3.4148\n",
            "Epoch 3249/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.7662 - val_loss: 2.3686\n",
            "Epoch 3250/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9102 - val_loss: 3.5501\n",
            "Epoch 3251/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0450 - val_loss: 3.7684\n",
            "Epoch 3252/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9608 - val_loss: 4.3500\n",
            "Epoch 3253/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8802 - val_loss: 3.2583\n",
            "Epoch 3254/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.6506 - val_loss: 4.4541\n",
            "Epoch 3255/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.7283 - val_loss: 4.4213\n",
            "Epoch 3256/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7617 - val_loss: 4.3108\n",
            "Epoch 3257/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.4096 - val_loss: 6.3627\n",
            "Epoch 3258/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 3.5567 - val_loss: 2.3887\n",
            "Epoch 3259/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.4016 - val_loss: 2.4814\n",
            "Epoch 3260/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8871 - val_loss: 3.3459\n",
            "Epoch 3261/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8780 - val_loss: 2.8770\n",
            "Epoch 3262/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8424 - val_loss: 4.2326\n",
            "Epoch 3263/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7676 - val_loss: 4.0072\n",
            "Epoch 3264/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.8344 - val_loss: 2.1080\n",
            "Epoch 3265/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.6650 - val_loss: 3.6565\n",
            "Epoch 3266/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9724 - val_loss: 4.7950\n",
            "Epoch 3267/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0677 - val_loss: 2.9938\n",
            "Epoch 3268/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7971 - val_loss: 4.8889\n",
            "Epoch 3269/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.3649 - val_loss: 2.7428\n",
            "Epoch 3270/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8428 - val_loss: 2.6837\n",
            "Epoch 3271/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1539 - val_loss: 3.6446\n",
            "Epoch 3272/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9302 - val_loss: 2.6578\n",
            "Epoch 3273/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.2597 - val_loss: 2.5760\n",
            "Epoch 3274/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.0157 - val_loss: 2.3525\n",
            "Epoch 3275/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.5368 - val_loss: 9.1006\n",
            "Epoch 3276/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.5814 - val_loss: 2.5838\n",
            "Epoch 3277/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9136 - val_loss: 2.7545\n",
            "Epoch 3278/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.8124 - val_loss: 3.2021\n",
            "Epoch 3279/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 3.9232 - val_loss: 7.1466\n",
            "Epoch 3280/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.0497 - val_loss: 3.7684\n",
            "Epoch 3281/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8481 - val_loss: 4.5823\n",
            "Epoch 3282/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8119 - val_loss: 3.2202\n",
            "Epoch 3283/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9152 - val_loss: 7.5364\n",
            "Epoch 3284/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 3.6188 - val_loss: 2.4116\n",
            "Epoch 3285/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.3161 - val_loss: 4.1724\n",
            "Epoch 3286/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0796 - val_loss: 6.2953\n",
            "Epoch 3287/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0500 - val_loss: 2.0865\n",
            "Epoch 3288/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2998 - val_loss: 5.0556\n",
            "Epoch 3289/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1054 - val_loss: 3.5979\n",
            "Epoch 3290/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.9683 - val_loss: 7.9673\n",
            "Epoch 3291/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9001 - val_loss: 3.1445\n",
            "Epoch 3292/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9705 - val_loss: 2.7731\n",
            "Epoch 3293/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0675 - val_loss: 3.5049\n",
            "Epoch 3294/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7630 - val_loss: 5.5547\n",
            "Epoch 3295/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2681 - val_loss: 4.4552\n",
            "Epoch 3296/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7783 - val_loss: 4.6796\n",
            "Epoch 3297/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.3401 - val_loss: 3.1628\n",
            "Epoch 3298/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.0173 - val_loss: 1.9724\n",
            "Epoch 3299/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9762 - val_loss: 3.0555\n",
            "Epoch 3300/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8750 - val_loss: 2.4290\n",
            "Epoch 3301/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0670 - val_loss: 2.3282\n",
            "Epoch 3302/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.0647 - val_loss: 2.9041\n",
            "Epoch 3303/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7253 - val_loss: 3.2496\n",
            "Epoch 3304/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2569 - val_loss: 4.2987\n",
            "Epoch 3305/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9243 - val_loss: 5.1252\n",
            "Epoch 3306/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9108 - val_loss: 2.6767\n",
            "Epoch 3307/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8131 - val_loss: 2.6288\n",
            "Epoch 3308/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9762 - val_loss: 3.0032\n",
            "Epoch 3309/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8708 - val_loss: 3.8063\n",
            "Epoch 3310/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1032 - val_loss: 3.0194\n",
            "Epoch 3311/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9841 - val_loss: 8.7790\n",
            "Epoch 3312/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.9297 - val_loss: 3.0041\n",
            "Epoch 3313/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.1010 - val_loss: 4.8074\n",
            "Epoch 3314/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.8779 - val_loss: 2.2900\n",
            "Epoch 3315/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.2044 - val_loss: 4.6134\n",
            "Epoch 3316/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8003 - val_loss: 2.9579\n",
            "Epoch 3317/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9174 - val_loss: 28.5297\n",
            "Epoch 3318/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.8887 - val_loss: 2.9963\n",
            "Epoch 3319/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0135 - val_loss: 2.5791\n",
            "Epoch 3320/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9826 - val_loss: 3.0940\n",
            "Epoch 3321/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7318 - val_loss: 4.0948\n",
            "Epoch 3322/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1861 - val_loss: 2.7336\n",
            "Epoch 3323/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8088 - val_loss: 4.4605\n",
            "Epoch 3324/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0325 - val_loss: 2.8984\n",
            "Epoch 3325/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7395 - val_loss: 3.2586\n",
            "Epoch 3326/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9656 - val_loss: 3.3005\n",
            "Epoch 3327/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.1864 - val_loss: 9.0507\n",
            "Epoch 3328/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.6029 - val_loss: 3.1019\n",
            "Epoch 3329/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9374 - val_loss: 4.5820\n",
            "Epoch 3330/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.7909 - val_loss: 4.2962\n",
            "Epoch 3331/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7952 - val_loss: 3.4712\n",
            "Epoch 3332/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9063 - val_loss: 5.1307\n",
            "Epoch 3333/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.3178 - val_loss: 3.0925\n",
            "Epoch 3334/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.1455 - val_loss: 2.9481\n",
            "Epoch 3335/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8867 - val_loss: 3.3255\n",
            "Epoch 3336/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.1066 - val_loss: 4.8387\n",
            "Epoch 3337/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.9197 - val_loss: 3.3221\n",
            "Epoch 3338/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7435 - val_loss: 3.2042\n",
            "Epoch 3339/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0399 - val_loss: 2.3785\n",
            "Epoch 3340/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9215 - val_loss: 2.4843\n",
            "Epoch 3341/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9023 - val_loss: 2.0885\n",
            "Epoch 3342/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.3540 - val_loss: 2.0524\n",
            "Epoch 3343/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9823 - val_loss: 3.4275\n",
            "Epoch 3344/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9890 - val_loss: 3.1619\n",
            "Epoch 3345/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.9230 - val_loss: 2.0548\n",
            "Epoch 3346/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.9260 - val_loss: 2.9921\n",
            "Epoch 3347/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8662 - val_loss: 2.9084\n",
            "Epoch 3348/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9259 - val_loss: 2.5784\n",
            "Epoch 3349/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0488 - val_loss: 4.6964\n",
            "Epoch 3350/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8898 - val_loss: 4.3137\n",
            "Epoch 3351/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9700 - val_loss: 2.8660\n",
            "Epoch 3352/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1157 - val_loss: 4.5979\n",
            "Epoch 3353/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7934 - val_loss: 7.3413\n",
            "Epoch 3354/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.7409 - val_loss: 3.9078\n",
            "Epoch 3355/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.5039 - val_loss: 2.2843\n",
            "Epoch 3356/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.9623 - val_loss: 2.5774\n",
            "Epoch 3357/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.7370 - val_loss: 2.7634\n",
            "Epoch 3358/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1840 - val_loss: 5.0796\n",
            "Epoch 3359/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1460 - val_loss: 7.3168\n",
            "Epoch 3360/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1103 - val_loss: 5.8962\n",
            "Epoch 3361/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1193 - val_loss: 2.7834\n",
            "Epoch 3362/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.0639 - val_loss: 3.2620\n",
            "Epoch 3363/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0620 - val_loss: 2.1999\n",
            "Epoch 3364/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2242 - val_loss: 1.9296\n",
            "Epoch 3365/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 3.0458 - val_loss: 3.7444\n",
            "Epoch 3366/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 3.1877 - val_loss: 2.3086\n",
            "Epoch 3367/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1184 - val_loss: 2.0671\n",
            "Epoch 3368/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.3135 - val_loss: 2.5475\n",
            "Epoch 3369/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1663 - val_loss: 1.8122\n",
            "Epoch 3370/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0982 - val_loss: 2.7331\n",
            "Epoch 3371/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.9475 - val_loss: 3.5058\n",
            "Epoch 3372/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8738 - val_loss: 1.8487\n",
            "Epoch 3373/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8674 - val_loss: 2.8263\n",
            "Epoch 3374/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1485 - val_loss: 2.2324\n",
            "Epoch 3375/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.3196 - val_loss: 2.9097\n",
            "Epoch 3376/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2029 - val_loss: 5.3932\n",
            "Epoch 3377/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8173 - val_loss: 2.1885\n",
            "Epoch 3378/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0093 - val_loss: 4.1855\n",
            "Epoch 3379/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9535 - val_loss: 2.1144\n",
            "Epoch 3380/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8264 - val_loss: 2.0951\n",
            "Epoch 3381/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9759 - val_loss: 2.9553\n",
            "Epoch 3382/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8750 - val_loss: 2.6285\n",
            "Epoch 3383/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7890 - val_loss: 3.1859\n",
            "Epoch 3384/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1382 - val_loss: 2.5679\n",
            "Epoch 3385/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8059 - val_loss: 3.0615\n",
            "Epoch 3386/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.4265 - val_loss: 3.8551\n",
            "Epoch 3387/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9450 - val_loss: 2.4547\n",
            "Epoch 3388/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9242 - val_loss: 5.3001\n",
            "Epoch 3389/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7457 - val_loss: 2.5082\n",
            "Epoch 3390/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0165 - val_loss: 2.9456\n",
            "Epoch 3391/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.3718 - val_loss: 4.2587\n",
            "Epoch 3392/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.0580 - val_loss: 1.9173\n",
            "Epoch 3393/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.9149 - val_loss: 2.2749\n",
            "Epoch 3394/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1741 - val_loss: 3.7525\n",
            "Epoch 3395/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7914 - val_loss: 3.8292\n",
            "Epoch 3396/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8538 - val_loss: 3.2915\n",
            "Epoch 3397/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7793 - val_loss: 3.8542\n",
            "Epoch 3398/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8602 - val_loss: 1.9794\n",
            "Epoch 3399/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.0972 - val_loss: 1.8081\n",
            "Epoch 3400/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2220 - val_loss: 2.3512\n",
            "Epoch 3401/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7171 - val_loss: 2.3787\n",
            "Epoch 3402/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7715 - val_loss: 3.0184\n",
            "Epoch 3403/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8024 - val_loss: 2.0799\n",
            "Epoch 3404/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1572 - val_loss: 3.2108\n",
            "Epoch 3405/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.3811 - val_loss: 4.1859\n",
            "Epoch 3406/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0582 - val_loss: 2.2457\n",
            "Epoch 3407/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1959 - val_loss: 4.7273\n",
            "Epoch 3408/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9269 - val_loss: 2.0351\n",
            "Epoch 3409/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8059 - val_loss: 3.8431\n",
            "Epoch 3410/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9257 - val_loss: 2.1591\n",
            "Epoch 3411/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8482 - val_loss: 2.2840\n",
            "Epoch 3412/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7854 - val_loss: 3.4080\n",
            "Epoch 3413/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.4240 - val_loss: 1.7690\n",
            "Epoch 3414/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1385 - val_loss: 2.6366\n",
            "Epoch 3415/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9763 - val_loss: 2.3987\n",
            "Epoch 3416/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0312 - val_loss: 3.0435\n",
            "Epoch 3417/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8183 - val_loss: 2.1888\n",
            "Epoch 3418/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0953 - val_loss: 2.9598\n",
            "Epoch 3419/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7990 - val_loss: 3.4332\n",
            "Epoch 3420/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9707 - val_loss: 2.0830\n",
            "Epoch 3421/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9215 - val_loss: 2.2478\n",
            "Epoch 3422/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.4399 - val_loss: 4.5711\n",
            "Epoch 3423/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8410 - val_loss: 2.5004\n",
            "Epoch 3424/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2231 - val_loss: 2.4115\n",
            "Epoch 3425/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7651 - val_loss: 2.6002\n",
            "Epoch 3426/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8070 - val_loss: 3.0709\n",
            "Epoch 3427/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7324 - val_loss: 9.4643\n",
            "Epoch 3428/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1075 - val_loss: 2.3220\n",
            "Epoch 3429/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8091 - val_loss: 2.0736\n",
            "Epoch 3430/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8195 - val_loss: 2.5514\n",
            "Epoch 3431/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8764 - val_loss: 3.5588\n",
            "Epoch 3432/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.1677 - val_loss: 18.2097\n",
            "Epoch 3433/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8842 - val_loss: 2.4776\n",
            "Epoch 3434/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1284 - val_loss: 2.5050\n",
            "Epoch 3435/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 2.2564 - val_loss: 2.1979\n",
            "Epoch 3436/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.1211 - val_loss: 3.6316\n",
            "Epoch 3437/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7484 - val_loss: 5.2442\n",
            "Epoch 3438/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7272 - val_loss: 2.6398\n",
            "Epoch 3439/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8757 - val_loss: 3.4172\n",
            "Epoch 3440/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1327 - val_loss: 2.2695\n",
            "Epoch 3441/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8804 - val_loss: 3.5886\n",
            "Epoch 3442/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.3484 - val_loss: 2.3405\n",
            "Epoch 3443/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 2.3659 - val_loss: 3.7064\n",
            "Epoch 3444/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8636 - val_loss: 1.9498\n",
            "Epoch 3445/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9808 - val_loss: 2.1715\n",
            "Epoch 3446/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.6845 - val_loss: 2.5204\n",
            "Epoch 3447/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8900 - val_loss: 1.9157\n",
            "Epoch 3448/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.4654 - val_loss: 1.7911\n",
            "Epoch 3449/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7650 - val_loss: 5.4009\n",
            "Epoch 3450/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9626 - val_loss: 2.5248\n",
            "Epoch 3451/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9356 - val_loss: 7.0085\n",
            "Epoch 3452/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.7440 - val_loss: 2.0145\n",
            "Epoch 3453/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7099 - val_loss: 2.4383\n",
            "Epoch 3454/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9193 - val_loss: 4.7271\n",
            "Epoch 3455/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7556 - val_loss: 3.1466\n",
            "Epoch 3456/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8699 - val_loss: 6.3819\n",
            "Epoch 3457/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1446 - val_loss: 3.0509\n",
            "Epoch 3458/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9146 - val_loss: 2.2114\n",
            "Epoch 3459/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9558 - val_loss: 3.4467\n",
            "Epoch 3460/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8935 - val_loss: 3.3706\n",
            "Epoch 3461/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6949 - val_loss: 6.3129\n",
            "Epoch 3462/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8251 - val_loss: 2.6121\n",
            "Epoch 3463/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0860 - val_loss: 2.6517\n",
            "Epoch 3464/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.8837 - val_loss: 2.5853\n",
            "Epoch 3465/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1696 - val_loss: 2.1951\n",
            "Epoch 3466/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2409 - val_loss: 4.4673\n",
            "Epoch 3467/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1579 - val_loss: 3.2344\n",
            "Epoch 3468/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8085 - val_loss: 2.7286\n",
            "Epoch 3469/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7980 - val_loss: 5.8382\n",
            "Epoch 3470/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0629 - val_loss: 5.1936\n",
            "Epoch 3471/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.8647 - val_loss: 2.5021\n",
            "Epoch 3472/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.9195 - val_loss: 1.7773\n",
            "Epoch 3473/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8606 - val_loss: 2.4480\n",
            "Epoch 3474/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.4616 - val_loss: 2.9524\n",
            "Epoch 3475/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6775 - val_loss: 2.4126\n",
            "Epoch 3476/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1345 - val_loss: 6.3252\n",
            "Epoch 3477/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2169 - val_loss: 3.4744\n",
            "Epoch 3478/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9138 - val_loss: 2.7641\n",
            "Epoch 3479/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8708 - val_loss: 2.7383\n",
            "Epoch 3480/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9461 - val_loss: 4.1071\n",
            "Epoch 3481/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1463 - val_loss: 3.4996\n",
            "Epoch 3482/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.3080 - val_loss: 6.7058\n",
            "Epoch 3483/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9656 - val_loss: 4.8778\n",
            "Epoch 3484/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2626 - val_loss: 3.9565\n",
            "Epoch 3485/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9500 - val_loss: 3.2140\n",
            "Epoch 3486/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.9180 - val_loss: 3.4029\n",
            "Epoch 3487/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.8567 - val_loss: 3.1759\n",
            "Epoch 3488/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8159 - val_loss: 4.9716\n",
            "Epoch 3489/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2245 - val_loss: 4.6881\n",
            "Epoch 3490/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2745 - val_loss: 6.2869\n",
            "Epoch 3491/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.0562 - val_loss: 3.5855\n",
            "Epoch 3492/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.1756 - val_loss: 3.7776\n",
            "Epoch 3493/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7835 - val_loss: 4.0385\n",
            "Epoch 3494/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9364 - val_loss: 3.8836\n",
            "Epoch 3495/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.9631 - val_loss: 2.4970\n",
            "Epoch 3496/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2221 - val_loss: 2.3234\n",
            "Epoch 3497/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9313 - val_loss: 2.6936\n",
            "Epoch 3498/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8360 - val_loss: 2.7815\n",
            "Epoch 3499/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.5849 - val_loss: 5.4542\n",
            "Epoch 3500/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.6465 - val_loss: 3.0731\n",
            "Epoch 3501/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8175 - val_loss: 2.1421\n",
            "Epoch 3502/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.9279 - val_loss: 7.9772\n",
            "Epoch 3503/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2331 - val_loss: 3.3362\n",
            "Epoch 3504/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.9073 - val_loss: 3.7554\n",
            "Epoch 3505/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1906 - val_loss: 3.7036\n",
            "Epoch 3506/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8814 - val_loss: 4.1443\n",
            "Epoch 3507/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9284 - val_loss: 3.6001\n",
            "Epoch 3508/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9317 - val_loss: 3.9013\n",
            "Epoch 3509/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1659 - val_loss: 2.8940\n",
            "Epoch 3510/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.7846 - val_loss: 7.2508\n",
            "Epoch 3511/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.7166 - val_loss: 3.0315\n",
            "Epoch 3512/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8002 - val_loss: 3.2680\n",
            "Epoch 3513/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.9111 - val_loss: 4.4385\n",
            "Epoch 3514/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.8779 - val_loss: 2.6603\n",
            "Epoch 3515/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1243 - val_loss: 3.2339\n",
            "Epoch 3516/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.8374 - val_loss: 4.3967\n",
            "Epoch 3517/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.7576 - val_loss: 3.0118\n",
            "Epoch 3518/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7712 - val_loss: 4.6329\n",
            "Epoch 3519/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1492 - val_loss: 3.2595\n",
            "Epoch 3520/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0986 - val_loss: 2.9779\n",
            "Epoch 3521/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0518 - val_loss: 2.6145\n",
            "Epoch 3522/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1742 - val_loss: 3.5336\n",
            "Epoch 3523/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8383 - val_loss: 3.2049\n",
            "Epoch 3524/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1469 - val_loss: 4.1069\n",
            "Epoch 3525/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7656 - val_loss: 6.8453\n",
            "Epoch 3526/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.3693 - val_loss: 2.6602\n",
            "Epoch 3527/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6924 - val_loss: 4.3543\n",
            "Epoch 3528/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8128 - val_loss: 2.4415\n",
            "Epoch 3529/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.9702 - val_loss: 3.1043\n",
            "Epoch 3530/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.0201 - val_loss: 4.0565\n",
            "Epoch 3531/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7862 - val_loss: 3.9042\n",
            "Epoch 3532/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1545 - val_loss: 3.1476\n",
            "Epoch 3533/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8442 - val_loss: 3.2081\n",
            "Epoch 3534/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.0580 - val_loss: 2.4897\n",
            "Epoch 3535/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9330 - val_loss: 5.4089\n",
            "Epoch 3536/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.8943 - val_loss: 9.8407\n",
            "Epoch 3537/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9878 - val_loss: 2.1280\n",
            "Epoch 3538/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9224 - val_loss: 6.3022\n",
            "Epoch 3539/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9123 - val_loss: 3.0990\n",
            "Epoch 3540/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8113 - val_loss: 6.2298\n",
            "Epoch 3541/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7496 - val_loss: 4.0818\n",
            "Epoch 3542/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.4031 - val_loss: 2.9957\n",
            "Epoch 3543/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8731 - val_loss: 2.9507\n",
            "Epoch 3544/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9004 - val_loss: 2.9410\n",
            "Epoch 3545/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9279 - val_loss: 4.0010\n",
            "Epoch 3546/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1226 - val_loss: 3.4490\n",
            "Epoch 3547/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.9715 - val_loss: 2.2614\n",
            "Epoch 3548/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.9223 - val_loss: 3.6188\n",
            "Epoch 3549/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.2807 - val_loss: 2.7134\n",
            "Epoch 3550/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 2.0010 - val_loss: 2.9080\n",
            "Epoch 3551/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8529 - val_loss: 2.9277\n",
            "Epoch 3552/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9260 - val_loss: 9.9131\n",
            "Epoch 3553/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9444 - val_loss: 3.7946\n",
            "Epoch 3554/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9926 - val_loss: 5.0016\n",
            "Epoch 3555/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0045 - val_loss: 2.6775\n",
            "Epoch 3556/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 2.4192 - val_loss: 4.2039\n",
            "Epoch 3557/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8630 - val_loss: 6.4900\n",
            "Epoch 3558/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0219 - val_loss: 3.3538\n",
            "Epoch 3559/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9077 - val_loss: 2.9905\n",
            "Epoch 3560/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9312 - val_loss: 6.7773\n",
            "Epoch 3561/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0872 - val_loss: 2.3852\n",
            "Epoch 3562/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1152 - val_loss: 7.9981\n",
            "Epoch 3563/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9982 - val_loss: 2.6189\n",
            "Epoch 3564/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8487 - val_loss: 2.5814\n",
            "Epoch 3565/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9303 - val_loss: 2.8764\n",
            "Epoch 3566/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8504 - val_loss: 2.4695\n",
            "Epoch 3567/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9323 - val_loss: 3.3010\n",
            "Epoch 3568/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9804 - val_loss: 6.4471\n",
            "Epoch 3569/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9419 - val_loss: 2.2639\n",
            "Epoch 3570/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8388 - val_loss: 3.3584\n",
            "Epoch 3571/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0096 - val_loss: 5.8754\n",
            "Epoch 3572/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2814 - val_loss: 2.4720\n",
            "Epoch 3573/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 2.2082 - val_loss: 2.8181\n",
            "Epoch 3574/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.8662 - val_loss: 3.6972\n",
            "Epoch 3575/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8911 - val_loss: 2.9062\n",
            "Epoch 3576/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7346 - val_loss: 2.7388\n",
            "Epoch 3577/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.1182 - val_loss: 4.4236\n",
            "Epoch 3578/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8135 - val_loss: 5.1645\n",
            "Epoch 3579/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9502 - val_loss: 3.5768\n",
            "Epoch 3580/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9484 - val_loss: 2.7341\n",
            "Epoch 3581/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9049 - val_loss: 4.7106\n",
            "Epoch 3582/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8664 - val_loss: 2.9096\n",
            "Epoch 3583/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8170 - val_loss: 4.1011\n",
            "Epoch 3584/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.6769 - val_loss: 7.1603\n",
            "Epoch 3585/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1248 - val_loss: 5.5324\n",
            "Epoch 3586/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8208 - val_loss: 5.6416\n",
            "Epoch 3587/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0102 - val_loss: 4.7378\n",
            "Epoch 3588/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.3210 - val_loss: 3.3379\n",
            "Epoch 3589/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8155 - val_loss: 4.6222\n",
            "Epoch 3590/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8812 - val_loss: 2.6462\n",
            "Epoch 3591/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9990 - val_loss: 7.6925\n",
            "Epoch 3592/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0429 - val_loss: 3.7420\n",
            "Epoch 3593/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8704 - val_loss: 2.3422\n",
            "Epoch 3594/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6938 - val_loss: 6.6482\n",
            "Epoch 3595/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8533 - val_loss: 5.4765\n",
            "Epoch 3596/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9113 - val_loss: 3.8193\n",
            "Epoch 3597/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0141 - val_loss: 5.5907\n",
            "Epoch 3598/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8475 - val_loss: 2.7432\n",
            "Epoch 3599/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0070 - val_loss: 5.7933\n",
            "Epoch 3600/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7477 - val_loss: 2.1186\n",
            "Epoch 3601/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.0023 - val_loss: 5.5818\n",
            "Epoch 3602/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 2.1175 - val_loss: 2.4676\n",
            "Epoch 3603/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.9320 - val_loss: 3.1245\n",
            "Epoch 3604/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.0155 - val_loss: 3.9866\n",
            "Epoch 3605/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.4057 - val_loss: 3.9566\n",
            "Epoch 3606/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.8312 - val_loss: 4.2938\n",
            "Epoch 3607/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8855 - val_loss: 3.6143\n",
            "Epoch 3608/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9460 - val_loss: 3.3567\n",
            "Epoch 3609/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7833 - val_loss: 5.6527\n",
            "Epoch 3610/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9306 - val_loss: 3.3992\n",
            "Epoch 3611/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0779 - val_loss: 4.2399\n",
            "Epoch 3612/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8854 - val_loss: 2.3465\n",
            "Epoch 3613/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8631 - val_loss: 2.9133\n",
            "Epoch 3614/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0831 - val_loss: 6.1338\n",
            "Epoch 3615/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.2493 - val_loss: 2.7098\n",
            "Epoch 3616/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8868 - val_loss: 2.2083\n",
            "Epoch 3617/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0119 - val_loss: 2.4930\n",
            "Epoch 3618/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9546 - val_loss: 1.9584\n",
            "Epoch 3619/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.7385 - val_loss: 4.0792\n",
            "Epoch 3620/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8404 - val_loss: 3.2393\n",
            "Epoch 3621/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8412 - val_loss: 4.4404\n",
            "Epoch 3622/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8206 - val_loss: 2.5966\n",
            "Epoch 3623/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9769 - val_loss: 2.6418\n",
            "Epoch 3624/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.8639 - val_loss: 3.3426\n",
            "Epoch 3625/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0953 - val_loss: 3.2272\n",
            "Epoch 3626/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8573 - val_loss: 5.3736\n",
            "Epoch 3627/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8705 - val_loss: 3.5511\n",
            "Epoch 3628/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8523 - val_loss: 2.4828\n",
            "Epoch 3629/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.2653 - val_loss: 3.0256\n",
            "Epoch 3630/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.9864 - val_loss: 4.0825\n",
            "Epoch 3631/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0509 - val_loss: 2.8188\n",
            "Epoch 3632/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.9219 - val_loss: 10.8504\n",
            "Epoch 3633/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9248 - val_loss: 3.3605\n",
            "Epoch 3634/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8234 - val_loss: 2.1726\n",
            "Epoch 3635/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.4033 - val_loss: 4.2644\n",
            "Epoch 3636/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7380 - val_loss: 2.3060\n",
            "Epoch 3637/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1369 - val_loss: 3.0235\n",
            "Epoch 3638/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1779 - val_loss: 2.6467\n",
            "Epoch 3639/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9014 - val_loss: 3.9945\n",
            "Epoch 3640/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.8850 - val_loss: 2.3702\n",
            "Epoch 3641/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8669 - val_loss: 3.5868\n",
            "Epoch 3642/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.0056 - val_loss: 2.3416\n",
            "Epoch 3643/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8866 - val_loss: 2.1585\n",
            "Epoch 3644/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7369 - val_loss: 2.3689\n",
            "Epoch 3645/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.4442 - val_loss: 2.3571\n",
            "Epoch 3646/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 2.0181 - val_loss: 3.3360\n",
            "Epoch 3647/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9550 - val_loss: 6.8215\n",
            "Epoch 3648/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2742 - val_loss: 2.8240\n",
            "Epoch 3649/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8592 - val_loss: 3.3597\n",
            "Epoch 3650/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0718 - val_loss: 3.7655\n",
            "Epoch 3651/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8383 - val_loss: 2.8182\n",
            "Epoch 3652/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.7739 - val_loss: 2.4103\n",
            "Epoch 3653/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0115 - val_loss: 1.6923\n",
            "Epoch 3654/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.8367 - val_loss: 3.8483\n",
            "Epoch 3655/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9892 - val_loss: 6.1334\n",
            "Epoch 3656/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8344 - val_loss: 2.1991\n",
            "Epoch 3657/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9261 - val_loss: 2.9773\n",
            "Epoch 3658/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9123 - val_loss: 5.4693\n",
            "Epoch 3659/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8482 - val_loss: 4.0859\n",
            "Epoch 3660/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0779 - val_loss: 1.9112\n",
            "Epoch 3661/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8566 - val_loss: 2.4371\n",
            "Epoch 3662/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.7069 - val_loss: 2.2227\n",
            "Epoch 3663/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8447 - val_loss: 3.2699\n",
            "Epoch 3664/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9703 - val_loss: 3.0523\n",
            "Epoch 3665/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0022 - val_loss: 3.5648\n",
            "Epoch 3666/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.9264 - val_loss: 3.8546\n",
            "Epoch 3667/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9166 - val_loss: 2.5321\n",
            "Epoch 3668/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1797 - val_loss: 2.3459\n",
            "Epoch 3669/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0100 - val_loss: 2.5605\n",
            "Epoch 3670/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.0978 - val_loss: 2.3100\n",
            "Epoch 3671/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.9159 - val_loss: 4.1034\n",
            "Epoch 3672/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9501 - val_loss: 3.7713\n",
            "Epoch 3673/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1745 - val_loss: 4.7581\n",
            "Epoch 3674/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.1092 - val_loss: 2.8137\n",
            "Epoch 3675/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9311 - val_loss: 4.2501\n",
            "Epoch 3676/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9628 - val_loss: 2.9326\n",
            "Epoch 3677/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2869 - val_loss: 3.4053\n",
            "Epoch 3678/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8154 - val_loss: 2.7961\n",
            "Epoch 3679/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0892 - val_loss: 4.4365\n",
            "Epoch 3680/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1795 - val_loss: 2.8070\n",
            "Epoch 3681/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2709 - val_loss: 2.0359\n",
            "Epoch 3682/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0357 - val_loss: 4.7345\n",
            "Epoch 3683/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.1251 - val_loss: 2.8551\n",
            "Epoch 3684/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8311 - val_loss: 2.0166\n",
            "Epoch 3685/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8120 - val_loss: 2.2538\n",
            "Epoch 3686/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9164 - val_loss: 2.4587\n",
            "Epoch 3687/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.4516 - val_loss: 6.2143\n",
            "Epoch 3688/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.9767 - val_loss: 2.8849\n",
            "Epoch 3689/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0046 - val_loss: 2.1367\n",
            "Epoch 3690/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.0224 - val_loss: 4.8497\n",
            "Epoch 3691/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0778 - val_loss: 3.1261\n",
            "Epoch 3692/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.8511 - val_loss: 3.5259\n",
            "Epoch 3693/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.9287 - val_loss: 3.7195\n",
            "Epoch 3694/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8843 - val_loss: 3.3251\n",
            "Epoch 3695/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8483 - val_loss: 3.0792\n",
            "Epoch 3696/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2161 - val_loss: 2.6515\n",
            "Epoch 3697/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9173 - val_loss: 6.7864\n",
            "Epoch 3698/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0038 - val_loss: 1.9914\n",
            "Epoch 3699/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8382 - val_loss: 6.2500\n",
            "Epoch 3700/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8285 - val_loss: 3.3255\n",
            "Epoch 3701/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.3011 - val_loss: 3.6386\n",
            "Epoch 3702/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9360 - val_loss: 5.7045\n",
            "Epoch 3703/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8384 - val_loss: 3.7444\n",
            "Epoch 3704/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0742 - val_loss: 3.8123\n",
            "Epoch 3705/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 6.9438 - val_loss: 4.2597\n",
            "Epoch 3706/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9166 - val_loss: 5.7856\n",
            "Epoch 3707/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8887 - val_loss: 3.6970\n",
            "Epoch 3708/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.9782 - val_loss: 2.6688\n",
            "Epoch 3709/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8914 - val_loss: 2.4293\n",
            "Epoch 3710/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1028 - val_loss: 3.0124\n",
            "Epoch 3711/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8274 - val_loss: 2.2888\n",
            "Epoch 3712/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2568 - val_loss: 4.5177\n",
            "Epoch 3713/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.4814 - val_loss: 3.8694\n",
            "Epoch 3714/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 2.8302 - val_loss: 2.4404\n",
            "Epoch 3715/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.8165 - val_loss: 3.0323\n",
            "Epoch 3716/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1771 - val_loss: 2.3833\n",
            "Epoch 3717/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7562 - val_loss: 2.1535\n",
            "Epoch 3718/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0505 - val_loss: 2.4063\n",
            "Epoch 3719/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0421 - val_loss: 2.2403\n",
            "Epoch 3720/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8370 - val_loss: 2.3721\n",
            "Epoch 3721/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.8975 - val_loss: 2.5829\n",
            "Epoch 3722/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.2023 - val_loss: 2.8825\n",
            "Epoch 3723/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.3349 - val_loss: 5.3872\n",
            "Epoch 3724/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.3508 - val_loss: 3.0881\n",
            "Epoch 3725/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8922 - val_loss: 2.4644\n",
            "Epoch 3726/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9252 - val_loss: 2.1303\n",
            "Epoch 3727/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0202 - val_loss: 1.5178\n",
            "Epoch 3728/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.9012 - val_loss: 2.9041\n",
            "Epoch 3729/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0257 - val_loss: 3.1333\n",
            "Epoch 3730/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0546 - val_loss: 2.1051\n",
            "Epoch 3731/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2399 - val_loss: 2.8849\n",
            "Epoch 3732/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9396 - val_loss: 2.4987\n",
            "Epoch 3733/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.0642 - val_loss: 3.2291\n",
            "Epoch 3734/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.0536 - val_loss: 3.1076\n",
            "Epoch 3735/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2295 - val_loss: 2.3450\n",
            "Epoch 3736/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0393 - val_loss: 2.3502\n",
            "Epoch 3737/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9200 - val_loss: 9.2301\n",
            "Epoch 3738/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.5621 - val_loss: 2.5295\n",
            "Epoch 3739/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.4701 - val_loss: 2.7143\n",
            "Epoch 3740/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2743 - val_loss: 2.1975\n",
            "Epoch 3741/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8573 - val_loss: 2.3044\n",
            "Epoch 3742/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1922 - val_loss: 4.4776\n",
            "Epoch 3743/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1624 - val_loss: 2.8694\n",
            "Epoch 3744/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0745 - val_loss: 3.0685\n",
            "Epoch 3745/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9639 - val_loss: 7.7105\n",
            "Epoch 3746/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8871 - val_loss: 4.0357\n",
            "Epoch 3747/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9336 - val_loss: 4.7169\n",
            "Epoch 3748/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.1087 - val_loss: 2.2443\n",
            "Epoch 3749/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8123 - val_loss: 2.3152\n",
            "Epoch 3750/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0612 - val_loss: 6.3910\n",
            "Epoch 3751/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0090 - val_loss: 11.7046\n",
            "Epoch 3752/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7684 - val_loss: 3.9298\n",
            "Epoch 3753/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1936 - val_loss: 7.8160\n",
            "Epoch 3754/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0122 - val_loss: 2.8570\n",
            "Epoch 3755/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.1061 - val_loss: 3.0617\n",
            "Epoch 3756/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.9881 - val_loss: 1.8704\n",
            "Epoch 3757/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1982 - val_loss: 3.0127\n",
            "Epoch 3758/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.0418 - val_loss: 3.5576\n",
            "Epoch 3759/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.1488 - val_loss: 2.4822\n",
            "Epoch 3760/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.7504 - val_loss: 3.4561\n",
            "Epoch 3761/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2241 - val_loss: 4.0683\n",
            "Epoch 3762/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9474 - val_loss: 2.5955\n",
            "Epoch 3763/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.3640 - val_loss: 4.0571\n",
            "Epoch 3764/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8178 - val_loss: 14.6461\n",
            "Epoch 3765/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0022 - val_loss: 4.1323\n",
            "Epoch 3766/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.2880 - val_loss: 2.7478\n",
            "Epoch 3767/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.8657 - val_loss: 2.0269\n",
            "Epoch 3768/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.1408 - val_loss: 2.7674\n",
            "Epoch 3769/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8174 - val_loss: 6.3358\n",
            "Epoch 3770/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2128 - val_loss: 6.9329\n",
            "Epoch 3771/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.2341 - val_loss: 3.3339\n",
            "Epoch 3772/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9316 - val_loss: 5.5889\n",
            "Epoch 3773/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1672 - val_loss: 4.1027\n",
            "Epoch 3774/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0013 - val_loss: 2.1148\n",
            "Epoch 3775/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.9731 - val_loss: 2.3525\n",
            "Epoch 3776/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7836 - val_loss: 4.5302\n",
            "Epoch 3777/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.5227 - val_loss: 2.5976\n",
            "Epoch 3778/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0477 - val_loss: 4.6933\n",
            "Epoch 3779/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9599 - val_loss: 2.5792\n",
            "Epoch 3780/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9994 - val_loss: 3.1010\n",
            "Epoch 3781/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1319 - val_loss: 5.2946\n",
            "Epoch 3782/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9511 - val_loss: 3.5293\n",
            "Epoch 3783/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0401 - val_loss: 2.0412\n",
            "Epoch 3784/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8498 - val_loss: 2.1237\n",
            "Epoch 3785/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.7811 - val_loss: 2.1603\n",
            "Epoch 3786/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.0212 - val_loss: 3.5389\n",
            "Epoch 3787/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7865 - val_loss: 5.8719\n",
            "Epoch 3788/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1020 - val_loss: 2.7742\n",
            "Epoch 3789/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 2.5779 - val_loss: 1.8151\n",
            "Epoch 3790/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.4306 - val_loss: 2.2710\n",
            "Epoch 3791/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.0148 - val_loss: 4.6724\n",
            "Epoch 3792/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1589 - val_loss: 3.2740\n",
            "Epoch 3793/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.6034 - val_loss: 2.5000\n",
            "Epoch 3794/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.7440 - val_loss: 10.7669\n",
            "Epoch 3795/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2028 - val_loss: 4.9506\n",
            "Epoch 3796/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.5065 - val_loss: 4.0160\n",
            "Epoch 3797/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8812 - val_loss: 2.4351\n",
            "Epoch 3798/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8263 - val_loss: 4.0978\n",
            "Epoch 3799/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0933 - val_loss: 3.0849\n",
            "Epoch 3800/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9436 - val_loss: 4.7134\n",
            "Epoch 3801/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2077 - val_loss: 3.3705\n",
            "Epoch 3802/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7484 - val_loss: 4.2170\n",
            "Epoch 3803/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.5293 - val_loss: 3.0742\n",
            "Epoch 3804/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9054 - val_loss: 4.0589\n",
            "Epoch 3805/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.5004 - val_loss: 3.8233\n",
            "Epoch 3806/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.3128 - val_loss: 2.8160\n",
            "Epoch 3807/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8686 - val_loss: 3.9684\n",
            "Epoch 3808/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1529 - val_loss: 6.7315\n",
            "Epoch 3809/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8037 - val_loss: 4.2654\n",
            "Epoch 3810/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9324 - val_loss: 2.6299\n",
            "Epoch 3811/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7790 - val_loss: 4.8690\n",
            "Epoch 3812/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.2308 - val_loss: 3.6170\n",
            "Epoch 3813/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.9015 - val_loss: 1.9922\n",
            "Epoch 3814/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6833 - val_loss: 6.1494\n",
            "Epoch 3815/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1702 - val_loss: 3.0318\n",
            "Epoch 3816/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.7498 - val_loss: 2.3216\n",
            "Epoch 3817/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9476 - val_loss: 5.5485\n",
            "Epoch 3818/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.9579 - val_loss: 4.2500\n",
            "Epoch 3819/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.0020 - val_loss: 2.6118\n",
            "Epoch 3820/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8950 - val_loss: 2.3800\n",
            "Epoch 3821/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2264 - val_loss: 4.8910\n",
            "Epoch 3822/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2708 - val_loss: 4.4490\n",
            "Epoch 3823/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.9139 - val_loss: 2.6378\n",
            "Epoch 3824/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.2460 - val_loss: 2.6836\n",
            "Epoch 3825/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.4064 - val_loss: 3.6714\n",
            "Epoch 3826/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.8837 - val_loss: 5.1081\n",
            "Epoch 3827/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7475 - val_loss: 9.0452\n",
            "Epoch 3828/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.4839 - val_loss: 3.6848\n",
            "Epoch 3829/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0810 - val_loss: 2.9666\n",
            "Epoch 3830/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.0773 - val_loss: 3.1381\n",
            "Epoch 3831/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0862 - val_loss: 4.6670\n",
            "Epoch 3832/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9961 - val_loss: 3.9652\n",
            "Epoch 3833/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.3710 - val_loss: 4.6100\n",
            "Epoch 3834/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.7902 - val_loss: 6.2647\n",
            "Epoch 3835/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0511 - val_loss: 2.6503\n",
            "Epoch 3836/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9966 - val_loss: 4.1003\n",
            "Epoch 3837/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1421 - val_loss: 6.0432\n",
            "Epoch 3838/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.5083 - val_loss: 4.5869\n",
            "Epoch 3839/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.8885 - val_loss: 2.8406\n",
            "Epoch 3840/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.9568 - val_loss: 1.9740\n",
            "Epoch 3841/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.8522 - val_loss: 3.8248\n",
            "Epoch 3842/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.8291 - val_loss: 3.0190\n",
            "Epoch 3843/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.9431 - val_loss: 4.0309\n",
            "Epoch 3844/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.7262 - val_loss: 3.3978\n",
            "Epoch 3845/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.9043 - val_loss: 4.4985\n",
            "Epoch 3846/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7311 - val_loss: 3.3875\n",
            "Epoch 3847/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.4658 - val_loss: 5.3596\n",
            "Epoch 3848/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2026 - val_loss: 3.3602\n",
            "Epoch 3849/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.0655 - val_loss: 3.7340\n",
            "Epoch 3850/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9757 - val_loss: 2.5109\n",
            "Epoch 3851/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8408 - val_loss: 3.2498\n",
            "Epoch 3852/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.4406 - val_loss: 1.9682\n",
            "Epoch 3853/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8215 - val_loss: 6.8103\n",
            "Epoch 3854/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.7706 - val_loss: 2.7968\n",
            "Epoch 3855/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9009 - val_loss: 3.0089\n",
            "Epoch 3856/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0473 - val_loss: 3.5882\n",
            "Epoch 3857/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7930 - val_loss: 2.8664\n",
            "Epoch 3858/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9582 - val_loss: 2.1990\n",
            "Epoch 3859/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8280 - val_loss: 3.2404\n",
            "Epoch 3860/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.6497 - val_loss: 3.9180\n",
            "Epoch 3861/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8141 - val_loss: 2.9157\n",
            "Epoch 3862/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.8439 - val_loss: 3.5660\n",
            "Epoch 3863/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8403 - val_loss: 3.3468\n",
            "Epoch 3864/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7754 - val_loss: 4.4856\n",
            "Epoch 3865/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2727 - val_loss: 2.3759\n",
            "Epoch 3866/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8235 - val_loss: 4.2040\n",
            "Epoch 3867/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0016 - val_loss: 1.9600\n",
            "Epoch 3868/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2500 - val_loss: 3.3946\n",
            "Epoch 3869/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.4108 - val_loss: 1.9343\n",
            "Epoch 3870/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.3627 - val_loss: 3.5866\n",
            "Epoch 3871/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0256 - val_loss: 3.7965\n",
            "Epoch 3872/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.9297 - val_loss: 2.6486\n",
            "Epoch 3873/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7093 - val_loss: 2.6926\n",
            "Epoch 3874/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9601 - val_loss: 3.3348\n",
            "Epoch 3875/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7989 - val_loss: 2.1360\n",
            "Epoch 3876/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0578 - val_loss: 2.2251\n",
            "Epoch 3877/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.9591 - val_loss: 2.3899\n",
            "Epoch 3878/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.1033 - val_loss: 2.4875\n",
            "Epoch 3879/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.1509 - val_loss: 2.3571\n",
            "Epoch 3880/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6681 - val_loss: 2.8623\n",
            "Epoch 3881/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0823 - val_loss: 3.3577\n",
            "Epoch 3882/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.9752 - val_loss: 2.4087\n",
            "Epoch 3883/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7838 - val_loss: 4.2843\n",
            "Epoch 3884/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9521 - val_loss: 2.0745\n",
            "Epoch 3885/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2356 - val_loss: 2.1524\n",
            "Epoch 3886/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8725 - val_loss: 3.2313\n",
            "Epoch 3887/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9866 - val_loss: 9.8731\n",
            "Epoch 3888/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.8532 - val_loss: 4.4817\n",
            "Epoch 3889/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8426 - val_loss: 3.2001\n",
            "Epoch 3890/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2058 - val_loss: 5.7156\n",
            "Epoch 3891/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0669 - val_loss: 4.6244\n",
            "Epoch 3892/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9878 - val_loss: 2.1762\n",
            "Epoch 3893/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9896 - val_loss: 1.8799\n",
            "Epoch 3894/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.1351 - val_loss: 3.8535\n",
            "Epoch 3895/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7549 - val_loss: 3.8790\n",
            "Epoch 3896/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.1579 - val_loss: 7.0230\n",
            "Epoch 3897/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9522 - val_loss: 7.1681\n",
            "Epoch 3898/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0791 - val_loss: 3.2957\n",
            "Epoch 3899/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0473 - val_loss: 2.6261\n",
            "Epoch 3900/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2134 - val_loss: 2.8633\n",
            "Epoch 3901/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8932 - val_loss: 2.3985\n",
            "Epoch 3902/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9646 - val_loss: 3.6417\n",
            "Epoch 3903/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.4216 - val_loss: 3.2541\n",
            "Epoch 3904/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.4986 - val_loss: 5.7207\n",
            "Epoch 3905/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8095 - val_loss: 1.9711\n",
            "Epoch 3906/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9281 - val_loss: 3.6485\n",
            "Epoch 3907/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9844 - val_loss: 2.4498\n",
            "Epoch 3908/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9192 - val_loss: 2.5532\n",
            "Epoch 3909/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1074 - val_loss: 2.5057\n",
            "Epoch 3910/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.8249 - val_loss: 2.2281\n",
            "Epoch 3911/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.1875 - val_loss: 3.1560\n",
            "Epoch 3912/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.3127 - val_loss: 2.1234\n",
            "Epoch 3913/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.4472 - val_loss: 3.1370\n",
            "Epoch 3914/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.9920 - val_loss: 3.0617\n",
            "Epoch 3915/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8278 - val_loss: 2.8591\n",
            "Epoch 3916/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8881 - val_loss: 2.4594\n",
            "Epoch 3917/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0344 - val_loss: 3.3676\n",
            "Epoch 3918/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8879 - val_loss: 5.1879\n",
            "Epoch 3919/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8097 - val_loss: 4.5993\n",
            "Epoch 3920/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.8622 - val_loss: 3.2003\n",
            "Epoch 3921/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8910 - val_loss: 3.3271\n",
            "Epoch 3922/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0270 - val_loss: 2.4009\n",
            "Epoch 3923/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.9727 - val_loss: 2.2112\n",
            "Epoch 3924/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.0202 - val_loss: 3.5497\n",
            "Epoch 3925/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0429 - val_loss: 2.6448\n",
            "Epoch 3926/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.0266 - val_loss: 2.5654\n",
            "Epoch 3927/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.7937 - val_loss: 3.2996\n",
            "Epoch 3928/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.0296 - val_loss: 4.8122\n",
            "Epoch 3929/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8626 - val_loss: 3.9082\n",
            "Epoch 3930/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.4379 - val_loss: 3.2092\n",
            "Epoch 3931/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.3747 - val_loss: 17.1553\n",
            "Epoch 3932/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8560 - val_loss: 2.8818\n",
            "Epoch 3933/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8581 - val_loss: 4.0608\n",
            "Epoch 3934/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8323 - val_loss: 3.0146\n",
            "Epoch 3935/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8330 - val_loss: 4.2053\n",
            "Epoch 3936/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.1427 - val_loss: 3.1524\n",
            "Epoch 3937/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8321 - val_loss: 2.7808\n",
            "Epoch 3938/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9073 - val_loss: 3.7352\n",
            "Epoch 3939/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.9177 - val_loss: 1.9719\n",
            "Epoch 3940/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8087 - val_loss: 2.7538\n",
            "Epoch 3941/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8496 - val_loss: 2.1242\n",
            "Epoch 3942/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1170 - val_loss: 1.5979\n",
            "Epoch 3943/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0252 - val_loss: 5.9363\n",
            "Epoch 3944/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7489 - val_loss: 4.5200\n",
            "Epoch 3945/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8041 - val_loss: 3.5888\n",
            "Epoch 3946/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9504 - val_loss: 6.1310\n",
            "Epoch 3947/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.3833 - val_loss: 5.6383\n",
            "Epoch 3948/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9114 - val_loss: 2.3212\n",
            "Epoch 3949/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9004 - val_loss: 2.6280\n",
            "Epoch 3950/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.8085 - val_loss: 17.4965\n",
            "Epoch 3951/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7766 - val_loss: 2.1846\n",
            "Epoch 3952/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9685 - val_loss: 3.6225\n",
            "Epoch 3953/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8729 - val_loss: 6.5450\n",
            "Epoch 3954/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8594 - val_loss: 3.0938\n",
            "Epoch 3955/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.0919 - val_loss: 3.1887\n",
            "Epoch 3956/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.7971 - val_loss: 4.7029\n",
            "Epoch 3957/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8991 - val_loss: 2.4550\n",
            "Epoch 3958/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9613 - val_loss: 4.1431\n",
            "Epoch 3959/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0012 - val_loss: 1.6571\n",
            "Epoch 3960/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.8611 - val_loss: 6.1279\n",
            "Epoch 3961/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2030 - val_loss: 3.5764\n",
            "Epoch 3962/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.7809 - val_loss: 3.8954\n",
            "Epoch 3963/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8621 - val_loss: 2.4902\n",
            "Epoch 3964/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8126 - val_loss: 3.1447\n",
            "Epoch 3965/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8247 - val_loss: 2.3455\n",
            "Epoch 3966/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8939 - val_loss: 3.1579\n",
            "Epoch 3967/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9665 - val_loss: 2.5991\n",
            "Epoch 3968/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9911 - val_loss: 8.1531\n",
            "Epoch 3969/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9895 - val_loss: 2.5053\n",
            "Epoch 3970/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.3506 - val_loss: 2.0093\n",
            "Epoch 3971/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.7344 - val_loss: 3.4717\n",
            "Epoch 3972/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7586 - val_loss: 3.1399\n",
            "Epoch 3973/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7995 - val_loss: 4.3437\n",
            "Epoch 3974/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8110 - val_loss: 3.5052\n",
            "Epoch 3975/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7363 - val_loss: 2.1976\n",
            "Epoch 3976/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.8895 - val_loss: 6.5893\n",
            "Epoch 3977/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8929 - val_loss: 2.0758\n",
            "Epoch 3978/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0331 - val_loss: 6.7644\n",
            "Epoch 3979/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8961 - val_loss: 4.0439\n",
            "Epoch 3980/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8448 - val_loss: 1.7161\n",
            "Epoch 3981/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1942 - val_loss: 2.6336\n",
            "Epoch 3982/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.9173 - val_loss: 2.0899\n",
            "Epoch 3983/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8516 - val_loss: 3.9067\n",
            "Epoch 3984/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.3579 - val_loss: 3.4093\n",
            "Epoch 3985/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.8962 - val_loss: 2.9428\n",
            "Epoch 3986/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.7529 - val_loss: 9.5295\n",
            "Epoch 3987/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.9103 - val_loss: 3.8644\n",
            "Epoch 3988/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.3942 - val_loss: 2.7734\n",
            "Epoch 3989/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 9.9251 - val_loss: 3.4346\n",
            "Epoch 3990/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.8771 - val_loss: 1.9389\n",
            "Epoch 3991/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9205 - val_loss: 2.1222\n",
            "Epoch 3992/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0298 - val_loss: 5.2457\n",
            "Epoch 3993/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1030 - val_loss: 3.0196\n",
            "Epoch 3994/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9845 - val_loss: 2.5028\n",
            "Epoch 3995/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.8323 - val_loss: 2.8905\n",
            "Epoch 3996/5000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.9968 - val_loss: 4.0786\n",
            "Epoch 3997/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2007 - val_loss: 2.0847\n",
            "Epoch 3998/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9405 - val_loss: 3.7485\n",
            "Epoch 3999/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9102 - val_loss: 2.2091\n",
            "Epoch 4000/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9172 - val_loss: 2.6551\n",
            "Epoch 4001/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8534 - val_loss: 2.4552\n",
            "Epoch 4002/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9098 - val_loss: 1.7396\n",
            "Epoch 4003/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.4556 - val_loss: 2.7134\n",
            "Epoch 4004/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8136 - val_loss: 2.7877\n",
            "Epoch 4005/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.7798 - val_loss: 3.7348\n",
            "Epoch 4006/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7831 - val_loss: 2.6262\n",
            "Epoch 4007/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8217 - val_loss: 2.6254\n",
            "Epoch 4008/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2661 - val_loss: 2.0909\n",
            "Epoch 4009/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 4.0587 - val_loss: 4.4481\n",
            "Epoch 4010/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2804 - val_loss: 2.8992\n",
            "Epoch 4011/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8053 - val_loss: 2.5140\n",
            "Epoch 4012/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9191 - val_loss: 2.6047\n",
            "Epoch 4013/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6820 - val_loss: 3.6800\n",
            "Epoch 4014/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9007 - val_loss: 1.9961\n",
            "Epoch 4015/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8704 - val_loss: 2.6775\n",
            "Epoch 4016/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0957 - val_loss: 3.1111\n",
            "Epoch 4017/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.7825 - val_loss: 1.8210\n",
            "Epoch 4018/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.9107 - val_loss: 3.3229\n",
            "Epoch 4019/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2380 - val_loss: 2.7060\n",
            "Epoch 4020/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9664 - val_loss: 3.7220\n",
            "Epoch 4021/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0700 - val_loss: 3.8882\n",
            "Epoch 4022/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9158 - val_loss: 2.2325\n",
            "Epoch 4023/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.9556 - val_loss: 2.1123\n",
            "Epoch 4024/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0842 - val_loss: 2.4292\n",
            "Epoch 4025/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9113 - val_loss: 5.9499\n",
            "Epoch 4026/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8090 - val_loss: 3.9750\n",
            "Epoch 4027/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9176 - val_loss: 3.7760\n",
            "Epoch 4028/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2054 - val_loss: 7.6084\n",
            "Epoch 4029/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8017 - val_loss: 5.0394\n",
            "Epoch 4030/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8367 - val_loss: 6.8952\n",
            "Epoch 4031/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 2.5443 - val_loss: 2.2253\n",
            "Epoch 4032/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1047 - val_loss: 3.7572\n",
            "Epoch 4033/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9667 - val_loss: 5.9486\n",
            "Epoch 4034/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8304 - val_loss: 2.5223\n",
            "Epoch 4035/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0890 - val_loss: 2.2997\n",
            "Epoch 4036/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9329 - val_loss: 2.3378\n",
            "Epoch 4037/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8052 - val_loss: 3.3177\n",
            "Epoch 4038/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9248 - val_loss: 4.4348\n",
            "Epoch 4039/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1877 - val_loss: 3.1915\n",
            "Epoch 4040/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7901 - val_loss: 2.7995\n",
            "Epoch 4041/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2126 - val_loss: 5.2896\n",
            "Epoch 4042/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.5412 - val_loss: 3.9038\n",
            "Epoch 4043/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8855 - val_loss: 3.3941\n",
            "Epoch 4044/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.8300 - val_loss: 3.4084\n",
            "Epoch 4045/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0240 - val_loss: 2.2443\n",
            "Epoch 4046/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8421 - val_loss: 6.3454\n",
            "Epoch 4047/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2986 - val_loss: 2.4485\n",
            "Epoch 4048/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0045 - val_loss: 2.4523\n",
            "Epoch 4049/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8348 - val_loss: 4.1389\n",
            "Epoch 4050/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9396 - val_loss: 1.9544\n",
            "Epoch 4051/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8619 - val_loss: 4.8523\n",
            "Epoch 4052/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 2.7210 - val_loss: 4.6196\n",
            "Epoch 4053/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0701 - val_loss: 4.8481\n",
            "Epoch 4054/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6792 - val_loss: 2.1332\n",
            "Epoch 4055/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8333 - val_loss: 2.6823\n",
            "Epoch 4056/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7862 - val_loss: 2.1543\n",
            "Epoch 4057/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9743 - val_loss: 5.5946\n",
            "Epoch 4058/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9591 - val_loss: 2.9271\n",
            "Epoch 4059/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7754 - val_loss: 1.8867\n",
            "Epoch 4060/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7917 - val_loss: 2.4182\n",
            "Epoch 4061/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7687 - val_loss: 4.0868\n",
            "Epoch 4062/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.3246 - val_loss: 1.6465\n",
            "Epoch 4063/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8146 - val_loss: 2.2611\n",
            "Epoch 4064/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9220 - val_loss: 3.3501\n",
            "Epoch 4065/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.6511 - val_loss: 1.8883\n",
            "Epoch 4066/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.0609 - val_loss: 1.6356\n",
            "Epoch 4067/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.4481 - val_loss: 2.6678\n",
            "Epoch 4068/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.9700 - val_loss: 4.3192\n",
            "Epoch 4069/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.3744 - val_loss: 3.6233\n",
            "Epoch 4070/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0673 - val_loss: 2.2478\n",
            "Epoch 4071/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.8072 - val_loss: 3.1523\n",
            "Epoch 4072/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.9464 - val_loss: 3.2652\n",
            "Epoch 4073/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.9787 - val_loss: 2.8609\n",
            "Epoch 4074/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0093 - val_loss: 6.7998\n",
            "Epoch 4075/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.8965 - val_loss: 3.4212\n",
            "Epoch 4076/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.8591 - val_loss: 3.2973\n",
            "Epoch 4077/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.1726 - val_loss: 1.9320\n",
            "Epoch 4078/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.9568 - val_loss: 3.9164\n",
            "Epoch 4079/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.5147 - val_loss: 2.9723\n",
            "Epoch 4080/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.4920 - val_loss: 9.2565\n",
            "Epoch 4081/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.0597 - val_loss: 5.6388\n",
            "Epoch 4082/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2231 - val_loss: 2.7515\n",
            "Epoch 4083/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.9982 - val_loss: 2.6481\n",
            "Epoch 4084/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.5059 - val_loss: 5.1613\n",
            "Epoch 4085/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7881 - val_loss: 2.0109\n",
            "Epoch 4086/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0362 - val_loss: 3.5731\n",
            "Epoch 4087/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0103 - val_loss: 7.6313\n",
            "Epoch 4088/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.2431 - val_loss: 17.3983\n",
            "Epoch 4089/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8295 - val_loss: 3.3571\n",
            "Epoch 4090/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.7809 - val_loss: 3.1327\n",
            "Epoch 4091/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1177 - val_loss: 3.9966\n",
            "Epoch 4092/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1978 - val_loss: 4.3530\n",
            "Epoch 4093/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.3475 - val_loss: 3.1042\n",
            "Epoch 4094/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.9610 - val_loss: 3.5436\n",
            "Epoch 4095/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8748 - val_loss: 3.1749\n",
            "Epoch 4096/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8830 - val_loss: 3.8931\n",
            "Epoch 4097/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9369 - val_loss: 10.8902\n",
            "Epoch 4098/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.9751 - val_loss: 6.0210\n",
            "Epoch 4099/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0663 - val_loss: 3.0723\n",
            "Epoch 4100/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.0941 - val_loss: 1.8659\n",
            "Epoch 4101/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7940 - val_loss: 3.0815\n",
            "Epoch 4102/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7404 - val_loss: 3.0292\n",
            "Epoch 4103/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.8610 - val_loss: 2.3564\n",
            "Epoch 4104/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.1164 - val_loss: 5.8626\n",
            "Epoch 4105/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7845 - val_loss: 3.7835\n",
            "Epoch 4106/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0042 - val_loss: 2.9255\n",
            "Epoch 4107/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9621 - val_loss: 5.2963\n",
            "Epoch 4108/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0671 - val_loss: 4.9105\n",
            "Epoch 4109/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7470 - val_loss: 4.0322\n",
            "Epoch 4110/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.0241 - val_loss: 2.9197\n",
            "Epoch 4111/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9935 - val_loss: 2.6034\n",
            "Epoch 4112/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9711 - val_loss: 4.3586\n",
            "Epoch 4113/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.4055 - val_loss: 2.5489\n",
            "Epoch 4114/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.0559 - val_loss: 4.1493\n",
            "Epoch 4115/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8076 - val_loss: 2.2582\n",
            "Epoch 4116/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8995 - val_loss: 3.5233\n",
            "Epoch 4117/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8139 - val_loss: 3.8547\n",
            "Epoch 4118/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2713 - val_loss: 2.7848\n",
            "Epoch 4119/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7955 - val_loss: 9.3878\n",
            "Epoch 4120/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8959 - val_loss: 6.2243\n",
            "Epoch 4121/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9284 - val_loss: 3.0387\n",
            "Epoch 4122/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8951 - val_loss: 3.3263\n",
            "Epoch 4123/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9752 - val_loss: 3.4759\n",
            "Epoch 4124/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.9471 - val_loss: 5.0214\n",
            "Epoch 4125/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.7792 - val_loss: 3.5652\n",
            "Epoch 4126/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9484 - val_loss: 2.3736\n",
            "Epoch 4127/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7926 - val_loss: 2.5819\n",
            "Epoch 4128/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1304 - val_loss: 2.9937\n",
            "Epoch 4129/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.3532 - val_loss: 2.5611\n",
            "Epoch 4130/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.8927 - val_loss: 2.1041\n",
            "Epoch 4131/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.8103 - val_loss: 2.6589\n",
            "Epoch 4132/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8936 - val_loss: 2.6838\n",
            "Epoch 4133/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9862 - val_loss: 3.4601\n",
            "Epoch 4134/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9493 - val_loss: 3.0910\n",
            "Epoch 4135/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8598 - val_loss: 4.3434\n",
            "Epoch 4136/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1182 - val_loss: 2.1540\n",
            "Epoch 4137/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9959 - val_loss: 2.9771\n",
            "Epoch 4138/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.2967 - val_loss: 7.8421\n",
            "Epoch 4139/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.0109 - val_loss: 2.7468\n",
            "Epoch 4140/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.8199 - val_loss: 4.3742\n",
            "Epoch 4141/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9816 - val_loss: 5.7854\n",
            "Epoch 4142/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8065 - val_loss: 2.0761\n",
            "Epoch 4143/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8136 - val_loss: 2.7065\n",
            "Epoch 4144/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8022 - val_loss: 5.4017\n",
            "Epoch 4145/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.3069 - val_loss: 4.8887\n",
            "Epoch 4146/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9914 - val_loss: 3.4053\n",
            "Epoch 4147/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9155 - val_loss: 5.0201\n",
            "Epoch 4148/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7568 - val_loss: 2.3500\n",
            "Epoch 4149/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8140 - val_loss: 2.2616\n",
            "Epoch 4150/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.8476 - val_loss: 4.0812\n",
            "Epoch 4151/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1896 - val_loss: 2.4081\n",
            "Epoch 4152/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9213 - val_loss: 2.2873\n",
            "Epoch 4153/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1033 - val_loss: 3.8481\n",
            "Epoch 4154/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1263 - val_loss: 5.1018\n",
            "Epoch 4155/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7537 - val_loss: 3.5784\n",
            "Epoch 4156/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.3359 - val_loss: 3.3209\n",
            "Epoch 4157/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7881 - val_loss: 2.5621\n",
            "Epoch 4158/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 2.1412 - val_loss: 3.8911\n",
            "Epoch 4159/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8836 - val_loss: 2.3021\n",
            "Epoch 4160/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0172 - val_loss: 2.7746\n",
            "Epoch 4161/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0457 - val_loss: 2.3998\n",
            "Epoch 4162/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.9019 - val_loss: 3.0806\n",
            "Epoch 4163/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.3782 - val_loss: 4.5294\n",
            "Epoch 4164/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9361 - val_loss: 2.8989\n",
            "Epoch 4165/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9811 - val_loss: 2.0208\n",
            "Epoch 4166/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8676 - val_loss: 6.6795\n",
            "Epoch 4167/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.3440 - val_loss: 3.6839\n",
            "Epoch 4168/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.7623 - val_loss: 5.9606\n",
            "Epoch 4169/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7064 - val_loss: 4.8198\n",
            "Epoch 4170/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.5661 - val_loss: 3.8850\n",
            "Epoch 4171/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9915 - val_loss: 3.7497\n",
            "Epoch 4172/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0365 - val_loss: 2.9849\n",
            "Epoch 4173/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9432 - val_loss: 2.3870\n",
            "Epoch 4174/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8786 - val_loss: 3.2936\n",
            "Epoch 4175/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9008 - val_loss: 3.2311\n",
            "Epoch 4176/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2192 - val_loss: 2.3225\n",
            "Epoch 4177/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2580 - val_loss: 3.9188\n",
            "Epoch 4178/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9031 - val_loss: 4.5987\n",
            "Epoch 4179/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9179 - val_loss: 2.6940\n",
            "Epoch 4180/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2897 - val_loss: 2.3737\n",
            "Epoch 4181/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9072 - val_loss: 2.3084\n",
            "Epoch 4182/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8861 - val_loss: 3.2436\n",
            "Epoch 4183/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0896 - val_loss: 2.7275\n",
            "Epoch 4184/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7485 - val_loss: 2.3764\n",
            "Epoch 4185/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0938 - val_loss: 11.0956\n",
            "Epoch 4186/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8549 - val_loss: 2.6608\n",
            "Epoch 4187/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.8927 - val_loss: 4.3427\n",
            "Epoch 4188/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9431 - val_loss: 2.5676\n",
            "Epoch 4189/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0370 - val_loss: 3.8170\n",
            "Epoch 4190/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9341 - val_loss: 1.8664\n",
            "Epoch 4191/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7735 - val_loss: 2.6942\n",
            "Epoch 4192/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0205 - val_loss: 2.4929\n",
            "Epoch 4193/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8246 - val_loss: 3.9225\n",
            "Epoch 4194/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.3116 - val_loss: 3.3087\n",
            "Epoch 4195/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9250 - val_loss: 3.3659\n",
            "Epoch 4196/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9261 - val_loss: 2.9819\n",
            "Epoch 4197/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7735 - val_loss: 1.9799\n",
            "Epoch 4198/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.1257 - val_loss: 5.1216\n",
            "Epoch 4199/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7579 - val_loss: 4.1128\n",
            "Epoch 4200/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8431 - val_loss: 4.9454\n",
            "Epoch 4201/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8798 - val_loss: 2.5553\n",
            "Epoch 4202/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8054 - val_loss: 6.7430\n",
            "Epoch 4203/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0983 - val_loss: 3.1075\n",
            "Epoch 4204/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2350 - val_loss: 4.1090\n",
            "Epoch 4205/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0182 - val_loss: 2.9202\n",
            "Epoch 4206/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2850 - val_loss: 2.6603\n",
            "Epoch 4207/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.5741 - val_loss: 4.3418\n",
            "Epoch 4208/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.9472 - val_loss: 5.3256\n",
            "Epoch 4209/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.9277 - val_loss: 4.1526\n",
            "Epoch 4210/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.8181 - val_loss: 8.8240\n",
            "Epoch 4211/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.8319 - val_loss: 2.3597\n",
            "Epoch 4212/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7533 - val_loss: 6.4902\n",
            "Epoch 4213/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9634 - val_loss: 1.8793\n",
            "Epoch 4214/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.8623 - val_loss: 4.4019\n",
            "Epoch 4215/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0232 - val_loss: 1.8384\n",
            "Epoch 4216/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7904 - val_loss: 3.6441\n",
            "Epoch 4217/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0437 - val_loss: 4.2746\n",
            "Epoch 4218/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.9113 - val_loss: 2.4521\n",
            "Epoch 4219/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0888 - val_loss: 2.9736\n",
            "Epoch 4220/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2282 - val_loss: 3.0053\n",
            "Epoch 4221/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9286 - val_loss: 1.9405\n",
            "Epoch 4222/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1226 - val_loss: 3.1679\n",
            "Epoch 4223/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9905 - val_loss: 4.2436\n",
            "Epoch 4224/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7234 - val_loss: 1.7704\n",
            "Epoch 4225/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8691 - val_loss: 2.8794\n",
            "Epoch 4226/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1288 - val_loss: 8.1345\n",
            "Epoch 4227/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2174 - val_loss: 2.8433\n",
            "Epoch 4228/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1872 - val_loss: 2.9262\n",
            "Epoch 4229/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1252 - val_loss: 2.1111\n",
            "Epoch 4230/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9630 - val_loss: 2.2997\n",
            "Epoch 4231/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.1500 - val_loss: 3.1015\n",
            "Epoch 4232/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8735 - val_loss: 2.3352\n",
            "Epoch 4233/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0153 - val_loss: 3.1413\n",
            "Epoch 4234/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9347 - val_loss: 2.4449\n",
            "Epoch 4235/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8874 - val_loss: 3.2790\n",
            "Epoch 4236/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.9078 - val_loss: 4.8301\n",
            "Epoch 4237/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.9120 - val_loss: 2.6025\n",
            "Epoch 4238/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0400 - val_loss: 2.3516\n",
            "Epoch 4239/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0410 - val_loss: 3.9538\n",
            "Epoch 4240/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8280 - val_loss: 3.3103\n",
            "Epoch 4241/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2722 - val_loss: 4.6140\n",
            "Epoch 4242/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.9539 - val_loss: 7.0015\n",
            "Epoch 4243/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2063 - val_loss: 2.6963\n",
            "Epoch 4244/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6608 - val_loss: 2.6017\n",
            "Epoch 4245/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2542 - val_loss: 4.0467\n",
            "Epoch 4246/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.0749 - val_loss: 2.1415\n",
            "Epoch 4247/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1636 - val_loss: 3.7007\n",
            "Epoch 4248/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0025 - val_loss: 8.7533\n",
            "Epoch 4249/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8344 - val_loss: 5.1495\n",
            "Epoch 4250/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.0770 - val_loss: 3.8612\n",
            "Epoch 4251/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2991 - val_loss: 2.7524\n",
            "Epoch 4252/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0677 - val_loss: 2.8863\n",
            "Epoch 4253/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9147 - val_loss: 3.4371\n",
            "Epoch 4254/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9143 - val_loss: 3.9079\n",
            "Epoch 4255/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9064 - val_loss: 6.2402\n",
            "Epoch 4256/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.4793 - val_loss: 3.3460\n",
            "Epoch 4257/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9302 - val_loss: 3.1578\n",
            "Epoch 4258/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2798 - val_loss: 6.7499\n",
            "Epoch 4259/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.9347 - val_loss: 4.1085\n",
            "Epoch 4260/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.1511 - val_loss: 2.9418\n",
            "Epoch 4261/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.9365 - val_loss: 3.0358\n",
            "Epoch 4262/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 2.0399 - val_loss: 6.2746\n",
            "Epoch 4263/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.7498 - val_loss: 4.4959\n",
            "Epoch 4264/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.1139 - val_loss: 5.6032\n",
            "Epoch 4265/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9508 - val_loss: 10.2330\n",
            "Epoch 4266/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9992 - val_loss: 2.6179\n",
            "Epoch 4267/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7881 - val_loss: 4.3356\n",
            "Epoch 4268/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.9146 - val_loss: 2.9823\n",
            "Epoch 4269/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7431 - val_loss: 2.5442\n",
            "Epoch 4270/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.9469 - val_loss: 9.8965\n",
            "Epoch 4271/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.9181 - val_loss: 4.1480\n",
            "Epoch 4272/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9964 - val_loss: 4.0646\n",
            "Epoch 4273/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0842 - val_loss: 4.9120\n",
            "Epoch 4274/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.0649 - val_loss: 2.3511\n",
            "Epoch 4275/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1534 - val_loss: 3.4554\n",
            "Epoch 4276/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1604 - val_loss: 5.7850\n",
            "Epoch 4277/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0872 - val_loss: 4.6307\n",
            "Epoch 4278/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9979 - val_loss: 2.8425\n",
            "Epoch 4279/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8753 - val_loss: 3.2431\n",
            "Epoch 4280/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2048 - val_loss: 3.4393\n",
            "Epoch 4281/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9950 - val_loss: 2.6263\n",
            "Epoch 4282/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.3221 - val_loss: 3.0517\n",
            "Epoch 4283/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.0897 - val_loss: 3.8944\n",
            "Epoch 4284/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.7705 - val_loss: 2.8761\n",
            "Epoch 4285/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6491 - val_loss: 2.9887\n",
            "Epoch 4286/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9738 - val_loss: 2.9934\n",
            "Epoch 4287/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8479 - val_loss: 3.3430\n",
            "Epoch 4288/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8500 - val_loss: 3.9684\n",
            "Epoch 4289/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8716 - val_loss: 4.8740\n",
            "Epoch 4290/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.3038 - val_loss: 2.5322\n",
            "Epoch 4291/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9652 - val_loss: 8.1380\n",
            "Epoch 4292/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.3575 - val_loss: 3.7438\n",
            "Epoch 4293/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.1211 - val_loss: 3.2750\n",
            "Epoch 4294/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.0895 - val_loss: 3.6544\n",
            "Epoch 4295/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.4050 - val_loss: 4.8203\n",
            "Epoch 4296/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2667 - val_loss: 2.5543\n",
            "Epoch 4297/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8305 - val_loss: 2.5064\n",
            "Epoch 4298/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0815 - val_loss: 2.4512\n",
            "Epoch 4299/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2325 - val_loss: 3.5187\n",
            "Epoch 4300/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.2401 - val_loss: 5.2258\n",
            "Epoch 4301/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1881 - val_loss: 4.5466\n",
            "Epoch 4302/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.7654 - val_loss: 2.5324\n",
            "Epoch 4303/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1493 - val_loss: 2.6706\n",
            "Epoch 4304/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0857 - val_loss: 2.2864\n",
            "Epoch 4305/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0200 - val_loss: 4.4098\n",
            "Epoch 4306/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8641 - val_loss: 3.3631\n",
            "Epoch 4307/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9577 - val_loss: 4.3647\n",
            "Epoch 4308/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1166 - val_loss: 2.0192\n",
            "Epoch 4309/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8705 - val_loss: 4.4752\n",
            "Epoch 4310/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8841 - val_loss: 2.6855\n",
            "Epoch 4311/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9447 - val_loss: 2.5725\n",
            "Epoch 4312/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1763 - val_loss: 3.1424\n",
            "Epoch 4313/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1082 - val_loss: 2.4546\n",
            "Epoch 4314/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.2391 - val_loss: 3.7183\n",
            "Epoch 4315/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1877 - val_loss: 5.3577\n",
            "Epoch 4316/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.2089 - val_loss: 3.7713\n",
            "Epoch 4317/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8177 - val_loss: 7.5756\n",
            "Epoch 4318/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7294 - val_loss: 12.2669\n",
            "Epoch 4319/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.6803 - val_loss: 4.6052\n",
            "Epoch 4320/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8032 - val_loss: 4.0954\n",
            "Epoch 4321/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2880 - val_loss: 5.7158\n",
            "Epoch 4322/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.1185 - val_loss: 1.9381\n",
            "Epoch 4323/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7243 - val_loss: 4.4112\n",
            "Epoch 4324/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7713 - val_loss: 3.3433\n",
            "Epoch 4325/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8650 - val_loss: 4.5245\n",
            "Epoch 4326/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7893 - val_loss: 2.7127\n",
            "Epoch 4327/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7193 - val_loss: 1.6140\n",
            "Epoch 4328/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2991 - val_loss: 2.6688\n",
            "Epoch 4329/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9352 - val_loss: 3.9605\n",
            "Epoch 4330/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0823 - val_loss: 4.2042\n",
            "Epoch 4331/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8790 - val_loss: 2.4684\n",
            "Epoch 4332/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9627 - val_loss: 2.9619\n",
            "Epoch 4333/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9093 - val_loss: 2.8903\n",
            "Epoch 4334/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0347 - val_loss: 2.4924\n",
            "Epoch 4335/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0061 - val_loss: 5.5695\n",
            "Epoch 4336/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7980 - val_loss: 2.4494\n",
            "Epoch 4337/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7975 - val_loss: 4.0440\n",
            "Epoch 4338/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.9099 - val_loss: 3.7139\n",
            "Epoch 4339/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.0280 - val_loss: 3.1322\n",
            "Epoch 4340/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.1001 - val_loss: 3.9859\n",
            "Epoch 4341/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.7418 - val_loss: 2.5055\n",
            "Epoch 4342/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8538 - val_loss: 3.0174\n",
            "Epoch 4343/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8887 - val_loss: 2.5888\n",
            "Epoch 4344/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9074 - val_loss: 2.7383\n",
            "Epoch 4345/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.9720 - val_loss: 2.4390\n",
            "Epoch 4346/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.1401 - val_loss: 3.5813\n",
            "Epoch 4347/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.7638 - val_loss: 2.7344\n",
            "Epoch 4348/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.8976 - val_loss: 2.5916\n",
            "Epoch 4349/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.6409 - val_loss: 2.3544\n",
            "Epoch 4350/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.1235 - val_loss: 2.9769\n",
            "Epoch 4351/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.3517 - val_loss: 7.5030\n",
            "Epoch 4352/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8887 - val_loss: 4.1263\n",
            "Epoch 4353/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9398 - val_loss: 3.4661\n",
            "Epoch 4354/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2313 - val_loss: 16.0693\n",
            "Epoch 4355/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1701 - val_loss: 4.0661\n",
            "Epoch 4356/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.7704 - val_loss: 3.3630\n",
            "Epoch 4357/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.3393 - val_loss: 2.0958\n",
            "Epoch 4358/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.9684 - val_loss: 2.1465\n",
            "Epoch 4359/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7702 - val_loss: 4.7574\n",
            "Epoch 4360/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.2496 - val_loss: 2.6150\n",
            "Epoch 4361/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.9689 - val_loss: 2.5334\n",
            "Epoch 4362/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.9875 - val_loss: 3.4514\n",
            "Epoch 4363/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9553 - val_loss: 3.5480\n",
            "Epoch 4364/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.1378 - val_loss: 3.9590\n",
            "Epoch 4365/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7757 - val_loss: 6.6307\n",
            "Epoch 4366/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1131 - val_loss: 2.3968\n",
            "Epoch 4367/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9419 - val_loss: 3.4049\n",
            "Epoch 4368/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7535 - val_loss: 3.2492\n",
            "Epoch 4369/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8117 - val_loss: 3.8401\n",
            "Epoch 4370/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9716 - val_loss: 4.9064\n",
            "Epoch 4371/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9141 - val_loss: 5.0432\n",
            "Epoch 4372/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8543 - val_loss: 6.0619\n",
            "Epoch 4373/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2243 - val_loss: 2.9574\n",
            "Epoch 4374/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8670 - val_loss: 3.1303\n",
            "Epoch 4375/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 2.0679 - val_loss: 2.3362\n",
            "Epoch 4376/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.1532 - val_loss: 2.6207\n",
            "Epoch 4377/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1897 - val_loss: 2.3413\n",
            "Epoch 4378/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8833 - val_loss: 2.5091\n",
            "Epoch 4379/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9520 - val_loss: 4.6219\n",
            "Epoch 4380/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2557 - val_loss: 2.3232\n",
            "Epoch 4381/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7916 - val_loss: 7.4497\n",
            "Epoch 4382/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0557 - val_loss: 2.1579\n",
            "Epoch 4383/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.3891 - val_loss: 10.3918\n",
            "Epoch 4384/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1212 - val_loss: 3.4638\n",
            "Epoch 4385/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.4902 - val_loss: 3.8155\n",
            "Epoch 4386/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1207 - val_loss: 3.1995\n",
            "Epoch 4387/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7992 - val_loss: 2.2067\n",
            "Epoch 4388/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1569 - val_loss: 5.5424\n",
            "Epoch 4389/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0058 - val_loss: 3.5038\n",
            "Epoch 4390/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.3427 - val_loss: 2.8313\n",
            "Epoch 4391/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0152 - val_loss: 2.1293\n",
            "Epoch 4392/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.1668 - val_loss: 2.2297\n",
            "Epoch 4393/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1519 - val_loss: 4.0943\n",
            "Epoch 4394/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1785 - val_loss: 5.2081\n",
            "Epoch 4395/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7976 - val_loss: 2.5826\n",
            "Epoch 4396/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.8542 - val_loss: 4.5511\n",
            "Epoch 4397/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.0440 - val_loss: 2.1982\n",
            "Epoch 4398/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.8704 - val_loss: 9.3122\n",
            "Epoch 4399/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1039 - val_loss: 2.9698\n",
            "Epoch 4400/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.7966 - val_loss: 3.6458\n",
            "Epoch 4401/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7779 - val_loss: 4.5407\n",
            "Epoch 4402/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0084 - val_loss: 3.4726\n",
            "Epoch 4403/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0344 - val_loss: 3.9795\n",
            "Epoch 4404/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9607 - val_loss: 3.7884\n",
            "Epoch 4405/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7873 - val_loss: 2.5757\n",
            "Epoch 4406/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0085 - val_loss: 2.8273\n",
            "Epoch 4407/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1904 - val_loss: 3.5485\n",
            "Epoch 4408/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.1062 - val_loss: 3.4055\n",
            "Epoch 4409/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7216 - val_loss: 3.5913\n",
            "Epoch 4410/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1032 - val_loss: 3.1061\n",
            "Epoch 4411/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0615 - val_loss: 2.4301\n",
            "Epoch 4412/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8403 - val_loss: 2.7391\n",
            "Epoch 4413/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9478 - val_loss: 3.2006\n",
            "Epoch 4414/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7449 - val_loss: 4.0700\n",
            "Epoch 4415/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8254 - val_loss: 3.0397\n",
            "Epoch 4416/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0599 - val_loss: 5.0662\n",
            "Epoch 4417/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.3864 - val_loss: 5.2179\n",
            "Epoch 4418/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9335 - val_loss: 2.9302\n",
            "Epoch 4419/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.0265 - val_loss: 3.4136\n",
            "Epoch 4420/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7880 - val_loss: 2.3751\n",
            "Epoch 4421/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8385 - val_loss: 4.6374\n",
            "Epoch 4422/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8511 - val_loss: 4.3224\n",
            "Epoch 4423/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7622 - val_loss: 4.2848\n",
            "Epoch 4424/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9325 - val_loss: 5.5945\n",
            "Epoch 4425/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8528 - val_loss: 3.5851\n",
            "Epoch 4426/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1422 - val_loss: 4.7947\n",
            "Epoch 4427/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9346 - val_loss: 2.0944\n",
            "Epoch 4428/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8963 - val_loss: 2.2937\n",
            "Epoch 4429/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1844 - val_loss: 3.4472\n",
            "Epoch 4430/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8674 - val_loss: 6.0810\n",
            "Epoch 4431/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8906 - val_loss: 3.7059\n",
            "Epoch 4432/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8917 - val_loss: 13.5334\n",
            "Epoch 4433/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8806 - val_loss: 3.4913\n",
            "Epoch 4434/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.4572 - val_loss: 4.9570\n",
            "Epoch 4435/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9962 - val_loss: 3.3131\n",
            "Epoch 4436/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0787 - val_loss: 4.1005\n",
            "Epoch 4437/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1080 - val_loss: 6.1427\n",
            "Epoch 4438/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7931 - val_loss: 3.0194\n",
            "Epoch 4439/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9034 - val_loss: 4.0378\n",
            "Epoch 4440/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0616 - val_loss: 3.4964\n",
            "Epoch 4441/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9516 - val_loss: 4.3118\n",
            "Epoch 4442/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8771 - val_loss: 4.4057\n",
            "Epoch 4443/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9075 - val_loss: 3.1670\n",
            "Epoch 4444/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8461 - val_loss: 3.7321\n",
            "Epoch 4445/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2699 - val_loss: 2.5591\n",
            "Epoch 4446/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0936 - val_loss: 3.1162\n",
            "Epoch 4447/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9767 - val_loss: 2.6455\n",
            "Epoch 4448/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9848 - val_loss: 5.0946\n",
            "Epoch 4449/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8920 - val_loss: 2.4343\n",
            "Epoch 4450/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0415 - val_loss: 3.4982\n",
            "Epoch 4451/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7001 - val_loss: 3.8881\n",
            "Epoch 4452/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8201 - val_loss: 5.0164\n",
            "Epoch 4453/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7217 - val_loss: 3.5560\n",
            "Epoch 4454/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8808 - val_loss: 3.2015\n",
            "Epoch 4455/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7962 - val_loss: 4.1152\n",
            "Epoch 4456/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7157 - val_loss: 2.5261\n",
            "Epoch 4457/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1461 - val_loss: 5.5475\n",
            "Epoch 4458/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1895 - val_loss: 6.4609\n",
            "Epoch 4459/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9989 - val_loss: 2.0428\n",
            "Epoch 4460/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8371 - val_loss: 2.8876\n",
            "Epoch 4461/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0711 - val_loss: 2.2851\n",
            "Epoch 4462/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0840 - val_loss: 2.5718\n",
            "Epoch 4463/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0309 - val_loss: 3.0495\n",
            "Epoch 4464/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7692 - val_loss: 1.9890\n",
            "Epoch 4465/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0710 - val_loss: 3.1450\n",
            "Epoch 4466/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1803 - val_loss: 6.2536\n",
            "Epoch 4467/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9851 - val_loss: 3.3321\n",
            "Epoch 4468/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8769 - val_loss: 2.8886\n",
            "Epoch 4469/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8542 - val_loss: 4.0709\n",
            "Epoch 4470/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0839 - val_loss: 3.1569\n",
            "Epoch 4471/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9769 - val_loss: 6.4072\n",
            "Epoch 4472/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1929 - val_loss: 6.2825\n",
            "Epoch 4473/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0495 - val_loss: 2.5994\n",
            "Epoch 4474/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8341 - val_loss: 5.9136\n",
            "Epoch 4475/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8882 - val_loss: 4.0402\n",
            "Epoch 4476/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.4143 - val_loss: 3.8555\n",
            "Epoch 4477/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1500 - val_loss: 3.2031\n",
            "Epoch 4478/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8141 - val_loss: 4.9435\n",
            "Epoch 4479/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8157 - val_loss: 3.1411\n",
            "Epoch 4480/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9406 - val_loss: 3.2161\n",
            "Epoch 4481/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8407 - val_loss: 2.9466\n",
            "Epoch 4482/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9271 - val_loss: 3.3138\n",
            "Epoch 4483/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7766 - val_loss: 4.5622\n",
            "Epoch 4484/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2477 - val_loss: 5.3673\n",
            "Epoch 4485/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8247 - val_loss: 3.2438\n",
            "Epoch 4486/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2317 - val_loss: 2.7335\n",
            "Epoch 4487/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8002 - val_loss: 4.5626\n",
            "Epoch 4488/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2127 - val_loss: 2.8663\n",
            "Epoch 4489/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.3164 - val_loss: 3.8277\n",
            "Epoch 4490/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.3063 - val_loss: 3.0304\n",
            "Epoch 4491/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0085 - val_loss: 2.1131\n",
            "Epoch 4492/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1457 - val_loss: 4.4090\n",
            "Epoch 4493/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8794 - val_loss: 2.9593\n",
            "Epoch 4494/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.3700 - val_loss: 3.6264\n",
            "Epoch 4495/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9157 - val_loss: 5.1434\n",
            "Epoch 4496/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0057 - val_loss: 4.0949\n",
            "Epoch 4497/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9767 - val_loss: 3.8240\n",
            "Epoch 4498/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0627 - val_loss: 2.4894\n",
            "Epoch 4499/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8412 - val_loss: 3.7258\n",
            "Epoch 4500/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.8247 - val_loss: 3.3654\n",
            "Epoch 4501/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8315 - val_loss: 2.6743\n",
            "Epoch 4502/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9212 - val_loss: 2.9125\n",
            "Epoch 4503/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8903 - val_loss: 2.6005\n",
            "Epoch 4504/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1667 - val_loss: 8.3407\n",
            "Epoch 4505/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9262 - val_loss: 4.0367\n",
            "Epoch 4506/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7796 - val_loss: 4.4000\n",
            "Epoch 4507/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9488 - val_loss: 4.4823\n",
            "Epoch 4508/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0285 - val_loss: 3.4470\n",
            "Epoch 4509/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.4119 - val_loss: 4.4855\n",
            "Epoch 4510/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9108 - val_loss: 3.0367\n",
            "Epoch 4511/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8358 - val_loss: 4.0286\n",
            "Epoch 4512/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8084 - val_loss: 3.3244\n",
            "Epoch 4513/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9193 - val_loss: 2.5291\n",
            "Epoch 4514/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0560 - val_loss: 4.2292\n",
            "Epoch 4515/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9401 - val_loss: 2.6195\n",
            "Epoch 4516/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0395 - val_loss: 5.2720\n",
            "Epoch 4517/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.6855 - val_loss: 3.7831\n",
            "Epoch 4518/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.4404 - val_loss: 5.2314\n",
            "Epoch 4519/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0045 - val_loss: 3.4311\n",
            "Epoch 4520/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0020 - val_loss: 2.1160\n",
            "Epoch 4521/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.8657 - val_loss: 4.4423\n",
            "Epoch 4522/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1997 - val_loss: 2.6265\n",
            "Epoch 4523/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.3757 - val_loss: 2.2895\n",
            "Epoch 4524/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0939 - val_loss: 9.5020\n",
            "Epoch 4525/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0422 - val_loss: 7.3644\n",
            "Epoch 4526/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6581 - val_loss: 3.6836\n",
            "Epoch 4527/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9398 - val_loss: 2.9595\n",
            "Epoch 4528/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2463 - val_loss: 3.3524\n",
            "Epoch 4529/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9260 - val_loss: 3.6595\n",
            "Epoch 4530/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0005 - val_loss: 2.5821\n",
            "Epoch 4531/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8274 - val_loss: 2.6373\n",
            "Epoch 4532/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.4265 - val_loss: 2.6494\n",
            "Epoch 4533/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8008 - val_loss: 3.5011\n",
            "Epoch 4534/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.4116 - val_loss: 3.2789\n",
            "Epoch 4535/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7934 - val_loss: 3.7540\n",
            "Epoch 4536/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1912 - val_loss: 3.6945\n",
            "Epoch 4537/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7712 - val_loss: 4.2780\n",
            "Epoch 4538/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.1340 - val_loss: 5.1990\n",
            "Epoch 4539/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8775 - val_loss: 2.7775\n",
            "Epoch 4540/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.9494 - val_loss: 2.6102\n",
            "Epoch 4541/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.7936 - val_loss: 3.6219\n",
            "Epoch 4542/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1070 - val_loss: 2.3177\n",
            "Epoch 4543/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 2.3911 - val_loss: 5.4938\n",
            "Epoch 4544/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6402 - val_loss: 4.7206\n",
            "Epoch 4545/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9284 - val_loss: 3.5611\n",
            "Epoch 4546/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9509 - val_loss: 5.7438\n",
            "Epoch 4547/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7043 - val_loss: 3.4862\n",
            "Epoch 4548/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8001 - val_loss: 3.6483\n",
            "Epoch 4549/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0361 - val_loss: 3.6999\n",
            "Epoch 4550/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7890 - val_loss: 5.8391\n",
            "Epoch 4551/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8500 - val_loss: 4.9449\n",
            "Epoch 4552/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8827 - val_loss: 4.6091\n",
            "Epoch 4553/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8199 - val_loss: 5.1157\n",
            "Epoch 4554/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8914 - val_loss: 11.7558\n",
            "Epoch 4555/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.0073 - val_loss: 3.0989\n",
            "Epoch 4556/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8909 - val_loss: 5.6811\n",
            "Epoch 4557/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7768 - val_loss: 3.7903\n",
            "Epoch 4558/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0701 - val_loss: 4.1878\n",
            "Epoch 4559/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8154 - val_loss: 6.5026\n",
            "Epoch 4560/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.0650 - val_loss: 2.6419\n",
            "Epoch 4561/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2404 - val_loss: 4.8260\n",
            "Epoch 4562/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.2928 - val_loss: 3.1594\n",
            "Epoch 4563/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.0358 - val_loss: 4.8082\n",
            "Epoch 4564/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8365 - val_loss: 5.3362\n",
            "Epoch 4565/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0182 - val_loss: 3.1479\n",
            "Epoch 4566/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1689 - val_loss: 5.1911\n",
            "Epoch 4567/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9692 - val_loss: 2.7977\n",
            "Epoch 4568/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 2.7633 - val_loss: 6.7451\n",
            "Epoch 4569/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9186 - val_loss: 1.7802\n",
            "Epoch 4570/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.9776 - val_loss: 2.9853\n",
            "Epoch 4571/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2195 - val_loss: 3.0118\n",
            "Epoch 4572/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0329 - val_loss: 2.3249\n",
            "Epoch 4573/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.8829 - val_loss: 4.0320\n",
            "Epoch 4574/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.8606 - val_loss: 5.0988\n",
            "Epoch 4575/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9476 - val_loss: 2.5722\n",
            "Epoch 4576/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0539 - val_loss: 5.1331\n",
            "Epoch 4577/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.3495 - val_loss: 3.5851\n",
            "Epoch 4578/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9713 - val_loss: 2.5870\n",
            "Epoch 4579/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9336 - val_loss: 5.4514\n",
            "Epoch 4580/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9793 - val_loss: 3.1681\n",
            "Epoch 4581/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0265 - val_loss: 4.5577\n",
            "Epoch 4582/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8193 - val_loss: 2.2597\n",
            "Epoch 4583/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9076 - val_loss: 7.6609\n",
            "Epoch 4584/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9690 - val_loss: 5.2820\n",
            "Epoch 4585/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8968 - val_loss: 3.6315\n",
            "Epoch 4586/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9611 - val_loss: 4.3161\n",
            "Epoch 4587/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9998 - val_loss: 2.8965\n",
            "Epoch 4588/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2075 - val_loss: 3.2651\n",
            "Epoch 4589/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.3027 - val_loss: 4.7795\n",
            "Epoch 4590/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6949 - val_loss: 10.3859\n",
            "Epoch 4591/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8625 - val_loss: 4.0418\n",
            "Epoch 4592/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.3911 - val_loss: 2.4354\n",
            "Epoch 4593/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0449 - val_loss: 3.1705\n",
            "Epoch 4594/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.8503 - val_loss: 5.2098\n",
            "Epoch 4595/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2041 - val_loss: 2.4865\n",
            "Epoch 4596/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.8449 - val_loss: 2.5713\n",
            "Epoch 4597/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2789 - val_loss: 2.5993\n",
            "Epoch 4598/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7944 - val_loss: 5.0382\n",
            "Epoch 4599/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1604 - val_loss: 4.0690\n",
            "Epoch 4600/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9993 - val_loss: 3.5668\n",
            "Epoch 4601/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8896 - val_loss: 3.9152\n",
            "Epoch 4602/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9916 - val_loss: 2.8271\n",
            "Epoch 4603/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.7663 - val_loss: 5.1176\n",
            "Epoch 4604/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9731 - val_loss: 3.5331\n",
            "Epoch 4605/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1450 - val_loss: 3.0865\n",
            "Epoch 4606/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0653 - val_loss: 2.6638\n",
            "Epoch 4607/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7835 - val_loss: 5.5489\n",
            "Epoch 4608/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2715 - val_loss: 7.6167\n",
            "Epoch 4609/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.4345 - val_loss: 3.3412\n",
            "Epoch 4610/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0089 - val_loss: 2.7054\n",
            "Epoch 4611/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9190 - val_loss: 2.8811\n",
            "Epoch 4612/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0329 - val_loss: 3.1367\n",
            "Epoch 4613/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8047 - val_loss: 2.6673\n",
            "Epoch 4614/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7705 - val_loss: 5.8098\n",
            "Epoch 4615/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9213 - val_loss: 4.0123\n",
            "Epoch 4616/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7026 - val_loss: 3.6378\n",
            "Epoch 4617/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8562 - val_loss: 5.9135\n",
            "Epoch 4618/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8006 - val_loss: 3.9235\n",
            "Epoch 4619/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.1289 - val_loss: 2.8499\n",
            "Epoch 4620/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7974 - val_loss: 3.0940\n",
            "Epoch 4621/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8483 - val_loss: 3.9321\n",
            "Epoch 4622/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0651 - val_loss: 3.2118\n",
            "Epoch 4623/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8690 - val_loss: 4.4305\n",
            "Epoch 4624/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9892 - val_loss: 3.1438\n",
            "Epoch 4625/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9337 - val_loss: 4.5948\n",
            "Epoch 4626/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0898 - val_loss: 4.4997\n",
            "Epoch 4627/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 2.9217 - val_loss: 12.1718\n",
            "Epoch 4628/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0717 - val_loss: 3.4200\n",
            "Epoch 4629/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.0959 - val_loss: 4.7745\n",
            "Epoch 4630/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0059 - val_loss: 3.4860\n",
            "Epoch 4631/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.0950 - val_loss: 2.9045\n",
            "Epoch 4632/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9321 - val_loss: 4.1472\n",
            "Epoch 4633/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1001 - val_loss: 2.2558\n",
            "Epoch 4634/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.1970 - val_loss: 7.5565\n",
            "Epoch 4635/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9905 - val_loss: 2.6130\n",
            "Epoch 4636/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1055 - val_loss: 2.2066\n",
            "Epoch 4637/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.5910 - val_loss: 14.9648\n",
            "Epoch 4638/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8495 - val_loss: 3.1689\n",
            "Epoch 4639/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9956 - val_loss: 3.2299\n",
            "Epoch 4640/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9931 - val_loss: 4.8129\n",
            "Epoch 4641/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1540 - val_loss: 6.3302\n",
            "Epoch 4642/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9349 - val_loss: 3.2172\n",
            "Epoch 4643/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8634 - val_loss: 3.5573\n",
            "Epoch 4644/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.9624 - val_loss: 3.3263\n",
            "Epoch 4645/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1181 - val_loss: 6.3258\n",
            "Epoch 4646/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.9614 - val_loss: 4.2531\n",
            "Epoch 4647/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.2598 - val_loss: 3.7145\n",
            "Epoch 4648/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1276 - val_loss: 5.7631\n",
            "Epoch 4649/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0812 - val_loss: 2.4217\n",
            "Epoch 4650/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0653 - val_loss: 4.3293\n",
            "Epoch 4651/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7353 - val_loss: 5.4150\n",
            "Epoch 4652/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7493 - val_loss: 4.1512\n",
            "Epoch 4653/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.8288 - val_loss: 4.8450\n",
            "Epoch 4654/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0088 - val_loss: 4.2446\n",
            "Epoch 4655/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9306 - val_loss: 3.3200\n",
            "Epoch 4656/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8651 - val_loss: 3.8603\n",
            "Epoch 4657/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.4088 - val_loss: 4.3496\n",
            "Epoch 4658/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8461 - val_loss: 2.5713\n",
            "Epoch 4659/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1792 - val_loss: 2.8894\n",
            "Epoch 4660/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2707 - val_loss: 4.7232\n",
            "Epoch 4661/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1701 - val_loss: 2.8710\n",
            "Epoch 4662/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8599 - val_loss: 4.7190\n",
            "Epoch 4663/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8499 - val_loss: 4.1590\n",
            "Epoch 4664/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9705 - val_loss: 5.5672\n",
            "Epoch 4665/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9948 - val_loss: 10.1520\n",
            "Epoch 4666/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7586 - val_loss: 5.9422\n",
            "Epoch 4667/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0149 - val_loss: 2.5561\n",
            "Epoch 4668/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7315 - val_loss: 8.2332\n",
            "Epoch 4669/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0460 - val_loss: 4.2108\n",
            "Epoch 4670/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7915 - val_loss: 2.1909\n",
            "Epoch 4671/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8545 - val_loss: 3.0347\n",
            "Epoch 4672/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.6447 - val_loss: 4.7302\n",
            "Epoch 4673/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.4760 - val_loss: 2.4881\n",
            "Epoch 4674/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7869 - val_loss: 2.1812\n",
            "Epoch 4675/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.3186 - val_loss: 3.8479\n",
            "Epoch 4676/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.1036 - val_loss: 5.2740\n",
            "Epoch 4677/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8561 - val_loss: 2.8445\n",
            "Epoch 4678/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.9020 - val_loss: 4.9835\n",
            "Epoch 4679/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8275 - val_loss: 2.7582\n",
            "Epoch 4680/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.8540 - val_loss: 2.6304\n",
            "Epoch 4681/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1584 - val_loss: 3.5718\n",
            "Epoch 4682/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2804 - val_loss: 2.7770\n",
            "Epoch 4683/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0077 - val_loss: 5.2216\n",
            "Epoch 4684/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1459 - val_loss: 2.3755\n",
            "Epoch 4685/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1159 - val_loss: 2.7635\n",
            "Epoch 4686/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.8432 - val_loss: 5.0321\n",
            "Epoch 4687/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8545 - val_loss: 2.8074\n",
            "Epoch 4688/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1273 - val_loss: 2.4056\n",
            "Epoch 4689/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9856 - val_loss: 3.2018\n",
            "Epoch 4690/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0201 - val_loss: 9.9844\n",
            "Epoch 4691/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9047 - val_loss: 3.5823\n",
            "Epoch 4692/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.8752 - val_loss: 2.8229\n",
            "Epoch 4693/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.1322 - val_loss: 4.5846\n",
            "Epoch 4694/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.0985 - val_loss: 4.6018\n",
            "Epoch 4695/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7602 - val_loss: 3.3773\n",
            "Epoch 4696/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.9944 - val_loss: 2.7840\n",
            "Epoch 4697/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.9157 - val_loss: 3.0929\n",
            "Epoch 4698/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8581 - val_loss: 2.4667\n",
            "Epoch 4699/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8319 - val_loss: 4.4889\n",
            "Epoch 4700/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9250 - val_loss: 2.4092\n",
            "Epoch 4701/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8376 - val_loss: 3.4587\n",
            "Epoch 4702/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8421 - val_loss: 3.8257\n",
            "Epoch 4703/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.9346 - val_loss: 5.2427\n",
            "Epoch 4704/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.9096 - val_loss: 8.9911\n",
            "Epoch 4705/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8758 - val_loss: 2.6275\n",
            "Epoch 4706/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0366 - val_loss: 2.4591\n",
            "Epoch 4707/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.0061 - val_loss: 3.5964\n",
            "Epoch 4708/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9819 - val_loss: 2.7862\n",
            "Epoch 4709/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7991 - val_loss: 2.7744\n",
            "Epoch 4710/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0833 - val_loss: 3.8068\n",
            "Epoch 4711/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0495 - val_loss: 5.3476\n",
            "Epoch 4712/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9206 - val_loss: 3.3783\n",
            "Epoch 4713/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.9001 - val_loss: 5.3646\n",
            "Epoch 4714/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.7923 - val_loss: 3.1903\n",
            "Epoch 4715/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.8380 - val_loss: 4.1577\n",
            "Epoch 4716/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7169 - val_loss: 4.0167\n",
            "Epoch 4717/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8750 - val_loss: 5.2157\n",
            "Epoch 4718/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.8443 - val_loss: 5.0793\n",
            "Epoch 4719/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9740 - val_loss: 4.4204\n",
            "Epoch 4720/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9620 - val_loss: 4.5301\n",
            "Epoch 4721/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.8375 - val_loss: 4.6829\n",
            "Epoch 4722/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.9186 - val_loss: 3.3245\n",
            "Epoch 4723/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.8374 - val_loss: 4.6348\n",
            "Epoch 4724/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.7573 - val_loss: 8.5710\n",
            "Epoch 4725/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.2497 - val_loss: 5.4541\n",
            "Epoch 4726/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.9052 - val_loss: 3.1902\n",
            "Epoch 4727/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0044 - val_loss: 5.4437\n",
            "Epoch 4728/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.9445 - val_loss: 3.4954\n",
            "Epoch 4729/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8249 - val_loss: 3.1931\n",
            "Epoch 4730/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8320 - val_loss: 4.9790\n",
            "Epoch 4731/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1202 - val_loss: 5.8943\n",
            "Epoch 4732/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.1069 - val_loss: 2.5320\n",
            "Epoch 4733/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9797 - val_loss: 3.9322\n",
            "Epoch 4734/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1542 - val_loss: 5.3143\n",
            "Epoch 4735/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0517 - val_loss: 13.2387\n",
            "Epoch 4736/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1469 - val_loss: 4.8347\n",
            "Epoch 4737/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9346 - val_loss: 3.6871\n",
            "Epoch 4738/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.9915 - val_loss: 3.2077\n",
            "Epoch 4739/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.0864 - val_loss: 9.8431\n",
            "Epoch 4740/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9550 - val_loss: 3.8144\n",
            "Epoch 4741/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9091 - val_loss: 5.3674\n",
            "Epoch 4742/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.1960 - val_loss: 5.9409\n",
            "Epoch 4743/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2382 - val_loss: 3.2385\n",
            "Epoch 4744/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7317 - val_loss: 2.9508\n",
            "Epoch 4745/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0613 - val_loss: 6.3558\n",
            "Epoch 4746/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9908 - val_loss: 5.7205\n",
            "Epoch 4747/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7936 - val_loss: 2.4325\n",
            "Epoch 4748/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.7843 - val_loss: 4.3805\n",
            "Epoch 4749/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9537 - val_loss: 3.6384\n",
            "Epoch 4750/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9306 - val_loss: 4.6964\n",
            "Epoch 4751/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8196 - val_loss: 2.0331\n",
            "Epoch 4752/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0530 - val_loss: 2.9673\n",
            "Epoch 4753/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7417 - val_loss: 11.7405\n",
            "Epoch 4754/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2203 - val_loss: 2.6561\n",
            "Epoch 4755/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8168 - val_loss: 4.1739\n",
            "Epoch 4756/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1237 - val_loss: 4.7395\n",
            "Epoch 4757/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0700 - val_loss: 10.7768\n",
            "Epoch 4758/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.8799 - val_loss: 3.8395\n",
            "Epoch 4759/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0094 - val_loss: 3.0554\n",
            "Epoch 4760/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0246 - val_loss: 4.6384\n",
            "Epoch 4761/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7180 - val_loss: 4.5453\n",
            "Epoch 4762/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9554 - val_loss: 9.1253\n",
            "Epoch 4763/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1873 - val_loss: 5.0487\n",
            "Epoch 4764/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8615 - val_loss: 6.2811\n",
            "Epoch 4765/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2702 - val_loss: 4.4063\n",
            "Epoch 4766/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7482 - val_loss: 9.5516\n",
            "Epoch 4767/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9814 - val_loss: 4.0282\n",
            "Epoch 4768/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.9517 - val_loss: 4.7963\n",
            "Epoch 4769/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.9373 - val_loss: 3.5760\n",
            "Epoch 4770/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.0261 - val_loss: 14.1787\n",
            "Epoch 4771/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.0120 - val_loss: 4.1335\n",
            "Epoch 4772/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.8564 - val_loss: 4.1141\n",
            "Epoch 4773/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0174 - val_loss: 3.5090\n",
            "Epoch 4774/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0164 - val_loss: 3.5842\n",
            "Epoch 4775/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.4652 - val_loss: 3.4355\n",
            "Epoch 4776/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.9205 - val_loss: 4.9999\n",
            "Epoch 4777/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0635 - val_loss: 2.8602\n",
            "Epoch 4778/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8460 - val_loss: 4.1671\n",
            "Epoch 4779/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7500 - val_loss: 3.7724\n",
            "Epoch 4780/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.9768 - val_loss: 6.0328\n",
            "Epoch 4781/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9038 - val_loss: 5.5186\n",
            "Epoch 4782/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8773 - val_loss: 3.5750\n",
            "Epoch 4783/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 2.0306 - val_loss: 2.8180\n",
            "Epoch 4784/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7588 - val_loss: 4.0525\n",
            "Epoch 4785/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8303 - val_loss: 5.9874\n",
            "Epoch 4786/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9246 - val_loss: 3.5978\n",
            "Epoch 4787/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7728 - val_loss: 3.5221\n",
            "Epoch 4788/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7356 - val_loss: 8.4016\n",
            "Epoch 4789/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.3402 - val_loss: 5.4747\n",
            "Epoch 4790/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7322 - val_loss: 6.8411\n",
            "Epoch 4791/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9104 - val_loss: 3.5517\n",
            "Epoch 4792/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0612 - val_loss: 5.3333\n",
            "Epoch 4793/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8931 - val_loss: 3.1025\n",
            "Epoch 4794/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0204 - val_loss: 8.2167\n",
            "Epoch 4795/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.8775 - val_loss: 3.8482\n",
            "Epoch 4796/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9491 - val_loss: 4.7334\n",
            "Epoch 4797/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9222 - val_loss: 3.3827\n",
            "Epoch 4798/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8717 - val_loss: 5.8135\n",
            "Epoch 4799/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9832 - val_loss: 5.1588\n",
            "Epoch 4800/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.8175 - val_loss: 3.4139\n",
            "Epoch 4801/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1422 - val_loss: 9.9630\n",
            "Epoch 4802/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9108 - val_loss: 3.4041\n",
            "Epoch 4803/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0756 - val_loss: 7.1237\n",
            "Epoch 4804/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8832 - val_loss: 6.5341\n",
            "Epoch 4805/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7651 - val_loss: 2.4476\n",
            "Epoch 4806/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7538 - val_loss: 3.6972\n",
            "Epoch 4807/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2309 - val_loss: 2.5366\n",
            "Epoch 4808/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9597 - val_loss: 3.5739\n",
            "Epoch 4809/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.7154 - val_loss: 3.3745\n",
            "Epoch 4810/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0109 - val_loss: 6.2101\n",
            "Epoch 4811/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0331 - val_loss: 6.3197\n",
            "Epoch 4812/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9497 - val_loss: 4.0093\n",
            "Epoch 4813/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2435 - val_loss: 3.5881\n",
            "Epoch 4814/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8604 - val_loss: 6.2257\n",
            "Epoch 4815/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.8602 - val_loss: 4.0954\n",
            "Epoch 4816/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8862 - val_loss: 4.7563\n",
            "Epoch 4817/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2422 - val_loss: 4.2581\n",
            "Epoch 4818/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0141 - val_loss: 3.3538\n",
            "Epoch 4819/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0334 - val_loss: 8.9904\n",
            "Epoch 4820/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8020 - val_loss: 4.3939\n",
            "Epoch 4821/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1956 - val_loss: 4.0142\n",
            "Epoch 4822/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8871 - val_loss: 2.8035\n",
            "Epoch 4823/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9515 - val_loss: 8.4619\n",
            "Epoch 4824/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8413 - val_loss: 4.4763\n",
            "Epoch 4825/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0785 - val_loss: 3.7417\n",
            "Epoch 4826/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9747 - val_loss: 3.3385\n",
            "Epoch 4827/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7509 - val_loss: 3.4755\n",
            "Epoch 4828/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1082 - val_loss: 3.8099\n",
            "Epoch 4829/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8382 - val_loss: 7.3409\n",
            "Epoch 4830/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9610 - val_loss: 8.2745\n",
            "Epoch 4831/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8247 - val_loss: 3.8636\n",
            "Epoch 4832/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1713 - val_loss: 6.4187\n",
            "Epoch 4833/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8637 - val_loss: 6.7147\n",
            "Epoch 4834/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1007 - val_loss: 4.9073\n",
            "Epoch 4835/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8769 - val_loss: 3.2014\n",
            "Epoch 4836/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8112 - val_loss: 4.7864\n",
            "Epoch 4837/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.8051 - val_loss: 2.7388\n",
            "Epoch 4838/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9596 - val_loss: 5.6434\n",
            "Epoch 4839/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.3691 - val_loss: 2.7865\n",
            "Epoch 4840/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9434 - val_loss: 2.6854\n",
            "Epoch 4841/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1266 - val_loss: 5.1128\n",
            "Epoch 4842/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8982 - val_loss: 2.3203\n",
            "Epoch 4843/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 2.4827 - val_loss: 6.8290\n",
            "Epoch 4844/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9267 - val_loss: 5.4860\n",
            "Epoch 4845/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.1764 - val_loss: 3.9406\n",
            "Epoch 4846/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9018 - val_loss: 4.1881\n",
            "Epoch 4847/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.7517 - val_loss: 3.8223\n",
            "Epoch 4848/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9955 - val_loss: 2.7325\n",
            "Epoch 4849/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2612 - val_loss: 2.7950\n",
            "Epoch 4850/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.1506 - val_loss: 4.0319\n",
            "Epoch 4851/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9371 - val_loss: 8.5676\n",
            "Epoch 4852/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8036 - val_loss: 3.8452\n",
            "Epoch 4853/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.8554 - val_loss: 4.0653\n",
            "Epoch 4854/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7991 - val_loss: 3.0444\n",
            "Epoch 4855/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1532 - val_loss: 5.6117\n",
            "Epoch 4856/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9374 - val_loss: 5.3502\n",
            "Epoch 4857/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1365 - val_loss: 5.8267\n",
            "Epoch 4858/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9761 - val_loss: 3.1116\n",
            "Epoch 4859/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.8306 - val_loss: 2.9299\n",
            "Epoch 4860/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8239 - val_loss: 5.0262\n",
            "Epoch 4861/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9247 - val_loss: 3.9980\n",
            "Epoch 4862/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0791 - val_loss: 4.6803\n",
            "Epoch 4863/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.3620 - val_loss: 3.9482\n",
            "Epoch 4864/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6200 - val_loss: 4.0264\n",
            "Epoch 4865/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9593 - val_loss: 3.6689\n",
            "Epoch 4866/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0040 - val_loss: 4.6368\n",
            "Epoch 4867/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7364 - val_loss: 3.9226\n",
            "Epoch 4868/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 2.7965 - val_loss: 3.5638\n",
            "Epoch 4869/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8063 - val_loss: 3.2597\n",
            "Epoch 4870/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8099 - val_loss: 3.1535\n",
            "Epoch 4871/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0384 - val_loss: 4.7087\n",
            "Epoch 4872/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1771 - val_loss: 4.2639\n",
            "Epoch 4873/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7531 - val_loss: 14.2720\n",
            "Epoch 4874/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9661 - val_loss: 8.4425\n",
            "Epoch 4875/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9390 - val_loss: 3.3372\n",
            "Epoch 4876/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.9385 - val_loss: 2.9855\n",
            "Epoch 4877/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7107 - val_loss: 3.4570\n",
            "Epoch 4878/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8686 - val_loss: 5.9195\n",
            "Epoch 4879/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0101 - val_loss: 17.6623\n",
            "Epoch 4880/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0117 - val_loss: 6.0970\n",
            "Epoch 4881/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7025 - val_loss: 3.4433\n",
            "Epoch 4882/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1437 - val_loss: 4.4659\n",
            "Epoch 4883/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9657 - val_loss: 4.5299\n",
            "Epoch 4884/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1958 - val_loss: 4.9559\n",
            "Epoch 4885/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9205 - val_loss: 2.8611\n",
            "Epoch 4886/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8787 - val_loss: 3.1717\n",
            "Epoch 4887/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0869 - val_loss: 3.8583\n",
            "Epoch 4888/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8810 - val_loss: 3.9437\n",
            "Epoch 4889/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.0857 - val_loss: 2.6043\n",
            "Epoch 4890/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7492 - val_loss: 4.0764\n",
            "Epoch 4891/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.4525 - val_loss: 6.8938\n",
            "Epoch 4892/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7312 - val_loss: 4.0010\n",
            "Epoch 4893/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7948 - val_loss: 2.7134\n",
            "Epoch 4894/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7902 - val_loss: 11.9695\n",
            "Epoch 4895/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1553 - val_loss: 3.3151\n",
            "Epoch 4896/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.4415 - val_loss: 9.9966\n",
            "Epoch 4897/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0452 - val_loss: 4.9302\n",
            "Epoch 4898/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9117 - val_loss: 3.8467\n",
            "Epoch 4899/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.7676 - val_loss: 9.9455\n",
            "Epoch 4900/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.1773 - val_loss: 2.8153\n",
            "Epoch 4901/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.9106 - val_loss: 4.1173\n",
            "Epoch 4902/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.8633 - val_loss: 9.3300\n",
            "Epoch 4903/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0921 - val_loss: 3.2112\n",
            "Epoch 4904/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1146 - val_loss: 4.4058\n",
            "Epoch 4905/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0179 - val_loss: 5.5787\n",
            "Epoch 4906/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9348 - val_loss: 3.9431\n",
            "Epoch 4907/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0994 - val_loss: 5.0013\n",
            "Epoch 4908/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9946 - val_loss: 3.9335\n",
            "Epoch 4909/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.8387 - val_loss: 5.0397\n",
            "Epoch 4910/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.1385 - val_loss: 4.4788\n",
            "Epoch 4911/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.8316 - val_loss: 3.1135\n",
            "Epoch 4912/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.9142 - val_loss: 3.8777\n",
            "Epoch 4913/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1064 - val_loss: 2.1943\n",
            "Epoch 4914/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8721 - val_loss: 2.3023\n",
            "Epoch 4915/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8571 - val_loss: 3.3979\n",
            "Epoch 4916/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.7234 - val_loss: 3.7406\n",
            "Epoch 4917/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8885 - val_loss: 7.9803\n",
            "Epoch 4918/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0472 - val_loss: 4.5108\n",
            "Epoch 4919/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8534 - val_loss: 5.4707\n",
            "Epoch 4920/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.5864 - val_loss: 3.5792\n",
            "Epoch 4921/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.3677 - val_loss: 5.9100\n",
            "Epoch 4922/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9231 - val_loss: 3.7726\n",
            "Epoch 4923/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9969 - val_loss: 5.7209\n",
            "Epoch 4924/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8452 - val_loss: 2.9553\n",
            "Epoch 4925/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8404 - val_loss: 2.2587\n",
            "Epoch 4926/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7829 - val_loss: 4.1528\n",
            "Epoch 4927/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1760 - val_loss: 3.3210\n",
            "Epoch 4928/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0174 - val_loss: 8.3559\n",
            "Epoch 4929/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0033 - val_loss: 1.9514\n",
            "Epoch 4930/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.0975 - val_loss: 4.4130\n",
            "Epoch 4931/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2995 - val_loss: 5.9437\n",
            "Epoch 4932/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6641 - val_loss: 5.4351\n",
            "Epoch 4933/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0476 - val_loss: 4.3102\n",
            "Epoch 4934/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.0033 - val_loss: 2.5344\n",
            "Epoch 4935/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.7840 - val_loss: 3.4840\n",
            "Epoch 4936/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 2.0352 - val_loss: 2.5914\n",
            "Epoch 4937/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8272 - val_loss: 3.1668\n",
            "Epoch 4938/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.1706 - val_loss: 4.5298\n",
            "Epoch 4939/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.8516 - val_loss: 3.2642\n",
            "Epoch 4940/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.8709 - val_loss: 2.8061\n",
            "Epoch 4941/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.5869 - val_loss: 13.1547\n",
            "Epoch 4942/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2025 - val_loss: 2.3562\n",
            "Epoch 4943/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2050 - val_loss: 5.7087\n",
            "Epoch 4944/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0358 - val_loss: 3.0910\n",
            "Epoch 4945/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6338 - val_loss: 7.2533\n",
            "Epoch 4946/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9616 - val_loss: 4.8670\n",
            "Epoch 4947/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0736 - val_loss: 2.7884\n",
            "Epoch 4948/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.7587 - val_loss: 3.0667\n",
            "Epoch 4949/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7521 - val_loss: 8.9860\n",
            "Epoch 4950/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7060 - val_loss: 5.5912\n",
            "Epoch 4951/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7316 - val_loss: 2.1855\n",
            "Epoch 4952/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9010 - val_loss: 2.9496\n",
            "Epoch 4953/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7660 - val_loss: 4.0555\n",
            "Epoch 4954/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.3030 - val_loss: 2.9070\n",
            "Epoch 4955/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0292 - val_loss: 5.7646\n",
            "Epoch 4956/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.9531 - val_loss: 3.2407\n",
            "Epoch 4957/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.8712 - val_loss: 2.1821\n",
            "Epoch 4958/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.0968 - val_loss: 3.2883\n",
            "Epoch 4959/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2434 - val_loss: 4.1744\n",
            "Epoch 4960/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.8963 - val_loss: 2.5940\n",
            "Epoch 4961/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.3670 - val_loss: 6.4828\n",
            "Epoch 4962/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1205 - val_loss: 4.3458\n",
            "Epoch 4963/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2122 - val_loss: 3.5434\n",
            "Epoch 4964/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9213 - val_loss: 3.7149\n",
            "Epoch 4965/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.1709 - val_loss: 7.2664\n",
            "Epoch 4966/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.9613 - val_loss: 3.1490\n",
            "Epoch 4967/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0977 - val_loss: 4.4493\n",
            "Epoch 4968/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7751 - val_loss: 2.9561\n",
            "Epoch 4969/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8618 - val_loss: 8.2802\n",
            "Epoch 4970/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.9309 - val_loss: 2.9178\n",
            "Epoch 4971/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1012 - val_loss: 10.8349\n",
            "Epoch 4972/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1162 - val_loss: 13.7204\n",
            "Epoch 4973/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.8951 - val_loss: 2.3678\n",
            "Epoch 4974/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.3096 - val_loss: 5.5803\n",
            "Epoch 4975/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.2224 - val_loss: 3.9143\n",
            "Epoch 4976/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8189 - val_loss: 4.0275\n",
            "Epoch 4977/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.9172 - val_loss: 2.9006\n",
            "Epoch 4978/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8798 - val_loss: 4.6556\n",
            "Epoch 4979/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8009 - val_loss: 6.6299\n",
            "Epoch 4980/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9525 - val_loss: 3.7487\n",
            "Epoch 4981/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.3818 - val_loss: 4.9022\n",
            "Epoch 4982/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.2618 - val_loss: 5.7746\n",
            "Epoch 4983/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8272 - val_loss: 3.5462\n",
            "Epoch 4984/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2079 - val_loss: 3.0423\n",
            "Epoch 4985/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7722 - val_loss: 12.1727\n",
            "Epoch 4986/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9148 - val_loss: 2.4061\n",
            "Epoch 4987/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8188 - val_loss: 6.1659\n",
            "Epoch 4988/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0645 - val_loss: 4.3278\n",
            "Epoch 4989/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7682 - val_loss: 5.5671\n",
            "Epoch 4990/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.3386 - val_loss: 3.3160\n",
            "Epoch 4991/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9463 - val_loss: 3.0721\n",
            "Epoch 4992/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0262 - val_loss: 5.2724\n",
            "Epoch 4993/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2457 - val_loss: 4.9356\n",
            "Epoch 4994/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.9722 - val_loss: 4.0271\n",
            "Epoch 4995/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.0155 - val_loss: 4.7793\n",
            "Epoch 4996/5000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.7757 - val_loss: 5.9648\n",
            "Epoch 4997/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9420 - val_loss: 3.0860\n",
            "Epoch 4998/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7251 - val_loss: 3.1530\n",
            "Epoch 4999/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1754 - val_loss: 3.3678\n",
            "Epoch 5000/5000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1055 - val_loss: 4.2837\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_1157772/719499732.py:9: UserWarning: Attempt to set non-positive ylim on a log-scaled axis will be ignored.\n",
            "  plt.ylim((0, 10))\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 19ms/step - loss: 2.4780\n",
            "EXPECTED:\n",
            "   d18O_cel_mean  d18O_cel_variance\n",
            "0      27.559140           0.780698\n",
            "1      27.260748           0.830341\n",
            "2      24.777670           0.736571\n",
            "3      25.987815           5.280825\n",
            "4      25.551850           0.312355\n",
            "5      25.115885           0.033519\n",
            "6      24.132031           0.389042\n",
            "7      25.120750           0.844007\n",
            "\n",
            "PREDICTED:\n",
            "   d18O_cel_mean  d18O_cel_variance\n",
            "0      24.159121           7.433133\n",
            "1      24.157381           7.430043\n",
            "2      28.598915          10.596899\n",
            "3      28.551065          16.280989\n",
            "4      28.601629          15.815095\n",
            "5      28.578148          15.783205\n",
            "6      28.601498          15.814261\n",
            "7      29.434641           5.329280\n",
            "RMSE: 3.574866901958459\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2023-07-27 15:24:23.098703: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype double and shape [8,12]\n",
            "\t [[{{node Placeholder/_0}}]]\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}