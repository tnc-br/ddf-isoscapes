{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tnc-br/ddf-isoscapes/blob/org_name/data_ingestion.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Ingestion"
      ],
      "metadata": {
        "id": "FrM0-qSAGbC7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Imports and modules.\n",
        "%pip install opencv-python\n",
        "%pip install matplotlib\n",
        "%pip install pandas\n",
        "\n",
        "from osgeo import gdal, gdal_array\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from dataclasses import dataclass\n",
        "import matplotlib.animation as animation\n",
        "from matplotlib import rc\n",
        "from typing import List\n",
        "from numpy.random import MT19937, RandomState, SeedSequence\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from io import StringIO\n",
        "import xgboost as xgb\n",
        "import os\n",
        "import math\n",
        "import glob\n",
        "\n",
        "rc('animation', html='jshtml')\n",
        "\n",
        "import sys\n",
        "!if [ ! -d \"/content/ddf_common_stub\" ] ; then git clone -b test https://github.com/tnc-br/ddf_common_stub.git; fi\n",
        "sys.path.append(\"/content/ddf_common_stub/\")\n",
        "import ddfimport\n",
        "# ddfimport.ddf_source_control_pane()\n",
        "ddfimport.ddf_import_common()\n",
        "\n",
        "import dataset\n",
        "import raster"
      ],
      "metadata": {
        "id": "n_kIR1epXirP",
        "outputId": "6a23d82d-3a03-4049-88d0-522daa6659ee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.8.0.76)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python) (1.23.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.42.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.5)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (23.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.3.post1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.23.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
            "Cloning into 'ddf_common_stub'...\n",
            "remote: Enumerating objects: 14, done.\u001b[K\n",
            "remote: Counting objects: 100% (14/14), done.\u001b[K\n",
            "remote: Compressing objects: 100% (14/14), done.\u001b[K\n",
            "remote: Total 14 (delta 5), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (14/14), 6.14 KiB | 6.14 MiB/s, done.\n",
            "Resolving deltas: 100% (5/5), done.\n",
            "executing checkout_branch ...\n",
            "b''\n",
            "main branch checked out as readonly. You may now use ddf_common imports\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load dataset"
      ],
      "metadata": {
        "id": "es3lK6jEJxxi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Please select the source of your data to process. Only SAMPLE_CSV_PATH will be used if SAMPLE_SOURCE is set to \"GOOGLE DRIVE\":"
      ],
      "metadata": {
        "id": "7twZEM5fCSJK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import ipywidgets as widgets\n",
        "\n",
        "SAMPLE_SOURCE = \"TIMBERID\" #@param [\"TIMBERID\", \"GOOGLE DRIVE\"]\n",
        "ORG_NAME = \"USP\" #@param [\"USP\"]\n",
        "SAMPLE_CSV_PATH = \"2023_06_23_Results_Google.csv\" #@param\n",
        "\n",
        "if SAMPLE_SOURCE == \"TIMBERID\":\n",
        "  df = dataset.load_reference_samples(org_name=ORG_NAME,\n",
        "                                      filters=[],\n",
        "                                      test_environment=False)\n",
        "elif SAMPLE_SOURCE == \"GOOGLE DRIVE\":\n",
        "  raster.mount_gdrive()\n",
        "  df = pd.read_csv(raster.get_sample_db_path(SAMPLE_CSV_PATH), encoding=\"ISO-8859-1\", sep=',')\n",
        "\n",
        "data = df.columns\n",
        "checkboxes = [widgets.Checkbox(value=False, description=label) for label in data]\n",
        "output = widgets.VBox(children=checkboxes)\n",
        "print(\"Select the features for your model:\")\n",
        "display(output)"
      ],
      "metadata": {
        "id": "PlKLE9g5B2WH",
        "outputId": "a814c6b3-dd85-4b5e-d97a-cbd9d241891c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 477
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "error",
          "ename": "EEException",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mHttpError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ee/data.py\u001b[0m in \u001b[0;36m_execute_cloud_call\u001b[0;34m(call, num_retries)\u001b[0m\n\u001b[1;32m    351\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 352\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_retries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_retries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    353\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mgoogleapiclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHttpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/googleapiclient/_helpers.py\u001b[0m in \u001b[0;36mpositional_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    129\u001b[0m                     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/googleapiclient/http.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, http, num_retries)\u001b[0m\n\u001b[1;32m    937\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 938\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mHttpError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muri\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muri\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    939\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpostproc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mHttpError\u001b[0m: <HttpError 400 when requesting https://earthengine-highvolume.googleapis.com/v1/projects/timberid-prd/value:compute?prettyPrint=false&alt=json returned \"Collection.loadTable: Collection asset 'projects/timberid-prd/assets/ee_org/USP/trusted_samples' not found.\". Details: \"Collection.loadTable: Collection asset 'projects/timberid-prd/assets/ee_org/USP/trusted_samples' not found.\">",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mEEException\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-614be945330d>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mSAMPLE_SOURCE\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"TIMBERID\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m   df = dataset.load_reference_samples(org_name=ORG_NAME,\n\u001b[0m\u001b[1;32m      9\u001b[0m                                       \u001b[0mfilters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m                                       test_environment=False)\n",
            "\u001b[0;32m/tmp/ddf_common/dataset.py\u001b[0m in \u001b[0;36mload_reference_samples\u001b[0;34m(org_name, filters, test_environment)\u001b[0m\n\u001b[1;32m    261\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mfilter_fc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfilters\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m     \u001b[0mfc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilter_fc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 263\u001b[0;31m   \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetInfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    264\u001b[0m   \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'features'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m   \u001b[0mdictarr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ee/collection.py\u001b[0m in \u001b[0;36mgetInfo\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    139\u001b[0m            \u001b[0mproperties\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m     \"\"\"\n\u001b[0;32m--> 141\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetInfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m   def limit(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ee/computedobject.py\u001b[0m in \u001b[0;36mgetInfo\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    101\u001b[0m       \u001b[0mThe\u001b[0m \u001b[0mobject\u001b[0m \u001b[0mcan\u001b[0m \u001b[0mevaluate\u001b[0m \u001b[0mto\u001b[0m \u001b[0manything\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \"\"\"\n\u001b[0;32m--> 103\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomputeValue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ee/data.py\u001b[0m in \u001b[0;36mcomputeValue\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m    969\u001b[0m   \u001b[0m_maybe_populate_workload_tag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    970\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 971\u001b[0;31m   return _execute_cloud_call(\n\u001b[0m\u001b[1;32m    972\u001b[0m       \u001b[0m_get_cloud_projects\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    973\u001b[0m       \u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ee/data.py\u001b[0m in \u001b[0;36m_execute_cloud_call\u001b[0;34m(call, num_retries)\u001b[0m\n\u001b[1;32m    352\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_retries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_retries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mgoogleapiclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHttpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0m_translate_cloud_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=raise-missing-from\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    355\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mEEException\u001b[0m: Collection.loadTable: Collection asset 'projects/timberid-prd/assets/ee_org/USP/trusted_samples' not found."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "selected_data = []\n",
        "for i in range(0, len(checkboxes)):\n",
        "    if checkboxes[i].value == True:\n",
        "        selected_data = selected_data + [checkboxes[i].description]\n",
        "print(\"Selected features: \", selected_data)\n",
        "FEATURE_COLUMNS = selected_data\n",
        "\n",
        "data = df.columns\n",
        "checkboxes = [widgets.Checkbox(value=False, description=label) for label in data]\n",
        "output = widgets.VBox(children=checkboxes)\n",
        "print(\"Select the labels of your model:\")\n",
        "display(output)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "-nsDNMtHD6yf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run the following cell to finalize selecting labels:"
      ],
      "metadata": {
        "id": "ZufVlRl1HPvQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "selected_data = []\n",
        "for i in range(0, len(checkboxes)):\n",
        "    if checkboxes[i].value == True:\n",
        "        assert(checkboxes[i].description not in FEATURE_COLUMNS)\n",
        "        selected_data = selected_data + [checkboxes[i].description]\n",
        "print(\"Selected labels: \", selected_data)\n",
        "LABEL_COLUMNS = selected_data"
      ],
      "metadata": {
        "cellView": "form",
        "id": "3EhJEAHnCWv9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Partition Data\n",
        "\n",
        "Based on the columns available, you'll select the keys by which we'll split your data into training, validation and test splits. This will make sure that there's a single group of measurements in either of the splits, and not an incomplete unit across many partitions.\n",
        "\n",
        "PARTITION_STRATEGY: The columns that will be used to group the dataset to calculate means and variance on LABEL_COLUMNS. Values can be\n",
        "- FIXED\n",
        "- RANDOM"
      ],
      "metadata": {
        "id": "d66Eth4ZHzz6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "PARTITION_STRATEGY = \"FIXED\" #@param [\"FIXED\", \"RANDOM\"] {allow-input:true}\n",
        "\n",
        "data = FEATURE_COLUMNS\n",
        "checkboxes = [widgets.Checkbox(value=False, description=label) for label in data]\n",
        "output = widgets.VBox(children=checkboxes)\n",
        "print(\"Select the columns to group samples with for partitions:\")\n",
        "display(output)"
      ],
      "metadata": {
        "id": "ZvBKf_9hGM36"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "KEEP_GROUPING: If True, the rows will remain unique GROUPING_COLUMNS values. Otherwise\n",
        "we merge the grouping columns aggregates with the original dataset."
      ],
      "metadata": {
        "id": "KA4Rq88XJWMa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "selected_data = []\n",
        "for i in range(0, len(checkboxes)):\n",
        "    if checkboxes[i].value == True:\n",
        "        selected_data = selected_data + [checkboxes[i].description]\n",
        "print(\"Selected grouping columns: \", selected_data)\n",
        "GROUPING_COLUMNS = selected_data\n",
        "\n",
        "KEEP_GROUPING = True #@param"
      ],
      "metadata": {
        "id": "Us2-lRsEUBru",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "print(\"This is the configuration you have chosen for pre-processing and partitioning data.\\n\"\n",
        "      \"Re-run the previous steps again if needed.\\n\\n\")\n",
        "print(\"PARTITION_STRATGY: \", PARTITION_STRATEGY)\n",
        "print(\"KEEP_GROUPING: \", KEEP_GROUPING)\n",
        "print(\"FEATURE_COLUMNS: \", FEATURE_COLUMNS)\n",
        "print(\"LABEL_COLUMNS: \", LABEL_COLUMNS)\n",
        "print(\"GROUPING_COLUMNS: \", GROUPING_COLUMNS)\n",
        "print(\"KEEP_GROUPING: \", KEEP_GROUPING)"
      ],
      "metadata": {
        "id": "_ATnMhltLiLm",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pre-Process and Split Data"
      ],
      "metadata": {
        "id": "TuoHc5wfMsgV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import partitioned_dataset"
      ],
      "metadata": {
        "id": "L81QtWKV6wPC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import dataset"
      ],
      "metadata": {
        "id": "xCpPkFTV8H17"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import importlib\n",
        "importlib.reload(dataset)\n",
        "importlib.reload(partitioned_dataset)\n",
        "import dataset\n",
        "import partitioned_dataset"
      ],
      "metadata": {
        "id": "YFrWLFIF6jed"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from partitioned_dataset import PartitionStrategy"
      ],
      "metadata": {
        "id": "0gq4S8TJ64I-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Run this cell to pre-process and split data\n",
        "\n",
        "for column in LABEL_COLUMNS:\n",
        "  df[column] = df[column].astype(float)\n",
        "\n",
        "sample_data = dataset.preprocess_sample_data(df, FEATURE_COLUMNS, LABEL_COLUMNS, GROUPING_COLUMNS, KEEP_GROUPING)\n",
        "\n",
        "resulting_dataset = None\n",
        "if PARTITION_STRATEGY == \"FIXED\":\n",
        "  resulting_dataset = partitioned_dataset.partition(sample_data, PartitionStrategy.FIXED)\n",
        "elif PARTITION_STRATEGY == \"RANDOM\":\n",
        "  resulting_dataset = partitioned_dataset.partition(sample_data, PartitionStrategy.RANDOM)\n",
        "else:\n",
        "  raise ValueError(f\"Unknown partition strategy: {PARTITION_STRATEGY}\")\n",
        "\n",
        "train_data = resulting_dataset.train\n",
        "validation_data = resulting_dataset.validation\n",
        "test_data = resulting_dataset.test"
      ],
      "metadata": {
        "id": "fnBXzjLYDC35"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## (Optional) Visualize data"
      ],
      "metadata": {
        "id": "s1RWPmocPYAc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Run this cell to visualize your partitioned data.\n",
        "print(\"Rows in training set:\", train_data.shape[0])\n",
        "print(\"Rows in validation set: \", validation_data.shape[0])\n",
        "print(\"Rows in test set:\", test_data.shape[0])\n",
        "\n",
        "# Optional (plot splits)\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.scatter(train_data[\"lat\"], train_data[\"long\"], label=\"train\", alpha=0.2)\n",
        "plt.scatter(validation_data[\"lat\"], validation_data[\"long\"], label=\"validation\", alpha=0.2)\n",
        "plt.scatter(test_data[\"lat\"], test_data[\"long\"], label=\"test\", alpha=0.2)\n",
        "plt.xlabel('Lattitude')\n",
        "plt.ylabel('Longitude')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ZoWixaV5hPXv",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Export processed dataset"
      ],
      "metadata": {
        "id": "PS6Ke_0AKyIf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "OUTPUT_DATASET_NAME=\"new_davis_furthest_points_5\" #@param\n",
        "OUTPUT_DATASET_ROOT = \"\" #@param\n",
        "GROUPING_STR = \"grouped\" if KEEP_GROUPING else \"ungrouped\"\n",
        "\n",
        "OUTPUT_TRAIN_CSV_PATH = f\"{OUTPUT_DATASET_ROOT}{OUTPUT_DATASET_NAME}_train_{PARTITION_STRATEGY.lower()}_{GROUPING_STR}.csv\"\n",
        "OUTPUT_VALIDATION_CSV_PATH = f\"{OUTPUT_DATASET_ROOT}{OUTPUT_DATASET_NAME}_validation_{PARTITION_STRATEGY.lower()}_{GROUPING_STR}.csv\"\n",
        "OUTPUT_TEST_CSV_PATH = f\"{OUTPUT_DATASET_ROOT}{OUTPUT_DATASET_NAME}_test_{PARTITION_STRATEGY.lower()}_{GROUPING_STR}.csv\"\n",
        "\n",
        "print(\"OUTPUT_TRAIN_CSV_PATH: \", raster.get_sample_db_path(\n",
        "    OUTPUT_TRAIN_CSV_PATH))\n",
        "print(\"OUTPUT_VALIDATION_CSV_PATH: \", raster.get_sample_db_path(\n",
        "    OUTPUT_VALIDATION_CSV_PATH))\n",
        "print(\"OUTPUT_TEST_CSV_PATH: \", raster.get_sample_db_path(\n",
        "    OUTPUT_TEST_CSV_PATH))\n",
        "\n",
        "train_data.to_csv(raster.get_sample_db_path(OUTPUT_TRAIN_CSV_PATH))\n",
        "validation_data.to_csv(raster.get_sample_db_path(OUTPUT_VALIDATION_CSV_PATH))\n",
        "test_data.to_csv(raster.get_sample_db_path(OUTPUT_TEST_CSV_PATH))"
      ],
      "metadata": {
        "id": "f4vBnCNRwc9F",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}