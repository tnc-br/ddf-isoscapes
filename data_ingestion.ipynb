{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tnc-br/ddf-isoscapes/blob/create_if_not_exists/data_ingestion.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Ingestion"
      ],
      "metadata": {
        "id": "FrM0-qSAGbC7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Imports and modules.\n",
        "%pip install opencv-python\n",
        "%pip install matplotlib\n",
        "%pip install pandas\n",
        "\n",
        "from osgeo import gdal, gdal_array\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from dataclasses import dataclass\n",
        "import matplotlib.animation as animation\n",
        "from matplotlib import rc\n",
        "from typing import List\n",
        "from numpy.random import MT19937, RandomState, SeedSequence\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from io import StringIO\n",
        "import xgboost as xgb\n",
        "import os\n",
        "import math\n",
        "import glob\n",
        "\n",
        "rc('animation', html='jshtml')\n",
        "\n",
        "import sys\n",
        "!if [ ! -d \"/content/ddf_common_stub\" ] ; then git clone -b test https://github.com/tnc-br/ddf_common_stub.git; fi\n",
        "sys.path.append(\"/content/ddf_common_stub/\")\n",
        "import ddfimport\n",
        "# ddfimport.ddf_source_control_pane()\n",
        "ddfimport.ddf_import_common()\n",
        "\n",
        "import dataset\n",
        "import raster"
      ],
      "metadata": {
        "id": "n_kIR1epXirP",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load dataset"
      ],
      "metadata": {
        "id": "es3lK6jEJxxi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Please select the source of your data to process. Only SAMPLE_CSV_PATH will be used if SAMPLE_SOURCE is set to \"GOOGLE DRIVE\":"
      ],
      "metadata": {
        "id": "7twZEM5fCSJK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import ipywidgets as widgets\n",
        "\n",
        "#@markdown ## Data Source\n",
        "\n",
        "SAMPLE_SOURCE = \"GOOGLE DRIVE\" #@param [\"TIMBERID\", \"GOOGLE DRIVE\"]\n",
        "\n",
        "#@markdown For TIMERBID SAMPLE_SOURCE only\n",
        "ORG_NAME = \"google\" #@param [\"google\", \"USP\"]\n",
        "TEST_ENVIRONMENT = True #@param {type:\"boolean\"}\n",
        "#@markdown For GOOGLE DRIVE SAMPLE_SOURCE only\n",
        "SAMPLE_CSV_PATH = \"canonical/2023_07_27_Results_google_relabeled.csv\" #@param\n",
        "SHARED_DRIVE = True #@param {type:\"boolean\"}\n",
        "\n",
        "if SAMPLE_SOURCE == \"TIMBERID\":\n",
        "  df = dataset.load_reference_samples(org_name=ORG_NAME,\n",
        "                                      filters=[],\n",
        "                                      test_environment=TEST_ENVIRONMENT)\n",
        "elif SAMPLE_SOURCE == \"GOOGLE DRIVE\":\n",
        "  raster.mount_gdrive()\n",
        "  if SHARED_DRIVE:\n",
        "    df = pd.read_csv(\n",
        "        os.path.join(\"/content/gdrive/Shareddrives/TNC Fellowship ðŸŒ³/4. Isotope Research & Signals/code/amazon_rainforest_files/amazon_sample_data\",\n",
        "                     SAMPLE_CSV_PATH),\n",
        "                     encoding=\"ISO-8859-1\",\n",
        "                     sep=',')\n",
        "  else:\n",
        "    df = pd.read_csv(raster.get_sample_db_path(SAMPLE_CSV_PATH),\n",
        "                     encoding=\"ISO-8859-1\", sep=',')\n",
        "\n",
        "#@markdown For both sample sources\n",
        "MANUAL_OVERRIDE_COLUMNS = False #@param {type: \"boolean\"}\n",
        "\n",
        "# Internal. The values to select by default\n",
        "default_values = {\n",
        "    'Code': True,\n",
        "    'lat': True,\n",
        "    'long': True,\n",
        "    'VPD': True,\n",
        "    'RH': True,\n",
        "    'DEM': True,\n",
        "    'PA': True,\n",
        "    'PET': True,\n",
        "    'Mean Annual Temperature': True,\n",
        "    'Mean Annual Precipitation': True,\n",
        "    'Iso_Oxi_Stack_mean_TERZER': True,\n",
        "    'predkrig_br_lat_ISORG': True,\n",
        "    'brisoscape_mean_ISORIX': True,\n",
        "    'isoscape_fullmodel_d18O_prec_REGRESSION': True\n",
        "}\n",
        "data = df.columns\n",
        "feature_checkboxes = [widgets.Checkbox(value=False, description=label) for label in data]\n",
        "for i in range(0, len(feature_checkboxes)):\n",
        "    if feature_checkboxes[i].description in default_values:\n",
        "      feature_checkboxes[i].value = True\n",
        "      default_values.pop(feature_checkboxes[i].description)\n",
        "if MANUAL_OVERRIDE_COLUMNS:\n",
        "  output = widgets.VBox(children=feature_checkboxes)\n",
        "  print(\"Select the features for your model:\")\n",
        "  display(output)\n",
        "else:\n",
        "  if len(default_values) > 0:\n",
        "    print(\"Warning: The following columns were not found:\",\n",
        "            list(default_values.keys()))\n",
        "\n",
        "\n",
        "data = df.columns\n",
        "default_values = {\n",
        "    'd18O_cel': True\n",
        "}\n",
        "label_checkboxes = [widgets.Checkbox(value=False, description=label) for label in data]\n",
        "for i in range(0, len(label_checkboxes)):\n",
        "    if label_checkboxes[i].description in default_values:\n",
        "      label_checkboxes[i].value = True\n",
        "      default_values.pop(label_checkboxes[i].description)\n",
        "if MANUAL_OVERRIDE_COLUMNS:\n",
        "  output = widgets.VBox(children=label_checkboxes)\n",
        "  print(\"Select the labels of your model:\")\n",
        "  display(output)\n",
        "else:\n",
        "  if len(default_values) > 0:\n",
        "    print(\"Warning: The following columns were not found:\",\n",
        "            list(default_values.keys()))\n",
        "\n",
        "#@markdown ## Partition Data\n",
        "#\n",
        "#@markdown Based on the columns available, you'll select the keys by which we'll split your data into training, validation and test splits. This will make sure that there's a single group of measurements in either of the splits, and not an incomplete unit across many partitions.\n",
        "#\n",
        "#@markdown PARTITION_STRATEGY: The columns that will be used to group the dataset to calculate means and variance on LABEL_COLUMNS. Values can be\n",
        "#@markdown - FIXED\n",
        "#@markdown - RANDOM\n",
        "\n",
        "PARTITION_STRATEGY = \"FIXED\" #@param [\"FIXED\", \"RANDOM\"]\n",
        "GROUPING_COLUMNS = [\"Code\", \"lat\", \"long\"] #@param\n",
        "\n",
        "#@markdown KEEP_GROUPING: If True, the exported rows will have unique values of the grouping columns selected above. If False, the exported rows will still contain the mean, variance, and other statistics for each group, but the original set of rows will be exported without combining any rows.\n",
        "\n",
        "KEEP_GROUPING = True #@param {type: \"boolean\"}"
      ],
      "metadata": {
        "id": "PlKLE9g5B2WH",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "selected_data = []\n",
        "for i in range(0, len(feature_checkboxes)):\n",
        "    if feature_checkboxes[i].value == True:\n",
        "        selected_data = selected_data + [feature_checkboxes[i].description]\n",
        "print(\"Selected features: \", selected_data)\n",
        "FEATURE_COLUMNS = selected_data\n",
        "\n",
        "selected_data = []\n",
        "for i in range(0, len(label_checkboxes)):\n",
        "    if label_checkboxes[i].value == True:\n",
        "        assert(label_checkboxes[i].description not in FEATURE_COLUMNS)\n",
        "        selected_data = selected_data + [label_checkboxes[i].description]\n",
        "print(\"Selected labels: \", selected_data)\n",
        "LABEL_COLUMNS = selected_data\n",
        "\n",
        "print(\"Partitioning strategy: \", PARTITION_STRATEGY)\n",
        "print(\"Grouping columns:\", GROUPING_COLUMNS)"
      ],
      "metadata": {
        "id": "-nsDNMtHD6yf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pre-Process and Split Data"
      ],
      "metadata": {
        "id": "TuoHc5wfMsgV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Run this cell to pre-process and split data\n",
        "import partitioned_dataset\n",
        "import dataset\n",
        "\n",
        "import importlib\n",
        "importlib.reload(dataset)\n",
        "importlib.reload(partitioned_dataset)\n",
        "import dataset\n",
        "import partitioned_dataset\n",
        "\n",
        "from partitioned_dataset import PartitionStrategy\n",
        "\n",
        "for column in LABEL_COLUMNS:\n",
        "  df[column] = df[column].astype(float)\n",
        "\n",
        "sample_data = dataset.preprocess_sample_data(df, FEATURE_COLUMNS, LABEL_COLUMNS, GROUPING_COLUMNS, KEEP_GROUPING)\n",
        "\n",
        "resulting_dataset = None\n",
        "if PARTITION_STRATEGY == \"FIXED\":\n",
        "  resulting_dataset = partitioned_dataset.partition(sample_data, PartitionStrategy.FIXED)\n",
        "elif PARTITION_STRATEGY == \"RANDOM\":\n",
        "  resulting_dataset = partitioned_dataset.partition(sample_data, PartitionStrategy.RANDOM)\n",
        "else:\n",
        "  raise ValueError(f\"Unknown partition strategy: {PARTITION_STRATEGY}\")\n",
        "\n",
        "train_data = resulting_dataset.train\n",
        "validation_data = resulting_dataset.validation\n",
        "test_data = resulting_dataset.test"
      ],
      "metadata": {
        "id": "fnBXzjLYDC35",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## (Optional) Visualize data"
      ],
      "metadata": {
        "id": "s1RWPmocPYAc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Run this cell to visualize your partitioned data.\n",
        "print(\"Rows in training set:\", train_data.shape[0])\n",
        "print(\"Rows in validation set: \", validation_data.shape[0])\n",
        "print(\"Rows in test set:\", test_data.shape[0])\n",
        "\n",
        "# Optional (plot splits)\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.scatter(train_data[\"lat\"], train_data[\"long\"], label=\"train\", alpha=0.2)\n",
        "plt.scatter(validation_data[\"lat\"], validation_data[\"long\"], label=\"validation\", alpha=0.2)\n",
        "plt.scatter(test_data[\"lat\"], test_data[\"long\"], label=\"test\", alpha=0.2)\n",
        "plt.xlabel('Lattitude')\n",
        "plt.ylabel('Longitude')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ZoWixaV5hPXv",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Export processed dataset"
      ],
      "metadata": {
        "id": "PS6Ke_0AKyIf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "OUTPUT_DATASET_NAME=\"demo\" #@param\n",
        "OUTPUT_DATASET_ROOT = \"local_test/\" #@param\n",
        "\n",
        "GROUPING_STR = \"grouped\" if KEEP_GROUPING else \"ungrouped\"\n",
        "\n",
        "SHARED_DRIVE = True #@param {type:\"boolean\"}\n",
        "CREATE_PATH_IF_NOT_EXISTS = True #@param {type:\"boolean\"}\n",
        "\n",
        "dataset_root = OUTPUT_DATASET_ROOT\n",
        "if SHARED_DRIVE:\n",
        "  dataset_root = os.path.join(\n",
        "      \"/content/gdrive/Shareddrives/TNC Fellowship ðŸŒ³/4. Isotope Research & Signals/code/amazon_rainforest_files/amazon_sample_data\",\n",
        "      dataset_root\n",
        "  )\n",
        "else:\n",
        "  dataset_root = raster.get_sample_db_path(dataset_root)\n",
        "\n",
        "if (CREATE_PATH_IF_NOT_EXISTS and\n",
        "      not os.path.exists(dataset_root)):\n",
        "  os.mkdir(dataset_root)\n",
        "  print(\"Created directory path at:\", dataset_root)\n",
        "\n",
        "OUTPUT_TRAIN_CSV_PATH = f\"{dataset_root}{OUTPUT_DATASET_NAME}_train_{PARTITION_STRATEGY.lower()}_{GROUPING_STR}.csv\"\n",
        "OUTPUT_VALIDATION_CSV_PATH = f\"{dataset_root}{OUTPUT_DATASET_NAME}_validation_{PARTITION_STRATEGY.lower()}_{GROUPING_STR}.csv\"\n",
        "OUTPUT_TEST_CSV_PATH = f\"{dataset_root}{OUTPUT_DATASET_NAME}_test_{PARTITION_STRATEGY.lower()}_{GROUPING_STR}.csv\"\n",
        "\n",
        "print(\"OUTPUT_TRAIN_CSV_PATH: \", OUTPUT_TRAIN_CSV_PATH)\n",
        "print(\"OUTPUT_VALIDATION_CSV_PATH: \", OUTPUT_VALIDATION_CSV_PATH)\n",
        "print(\"OUTPUT_TEST_CSV_PATH: \", OUTPUT_TEST_CSV_PATH)\n",
        "\n",
        "train_data.to_csv(OUTPUT_TRAIN_CSV_PATH)\n",
        "validation_data.to_csv(OUTPUT_VALIDATION_CSV_PATH)\n",
        "test_data.to_csv(OUTPUT_TEST_CSV_PATH)"
      ],
      "metadata": {
        "id": "f4vBnCNRwc9F"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}